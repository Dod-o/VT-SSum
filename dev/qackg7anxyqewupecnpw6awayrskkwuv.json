{
    "id": "qackg7anxyqewupecnpw6awayrskkwuv",
    "title": "Using Richer Models for Articulated Pose Estimation of Footballers",
    "info": {
        "author": [
            "Vahid Kazemi, KTH - Royal Institute of Technology"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_kazemi_pose_estimation/",
    "segmentation": [
        [
            "I'm the head cosmian.",
            "I'm going to present you the paper using richer models for articulated pose estimation.",
            "For footballers."
        ],
        [
            "So the focus of this paper and this work is about accurate 2D pose estimation.",
            "So what we want to do is, given an image of a football player.",
            "For example, we want to localize a set of joint body joint locations on the image in 2D.",
            "So why you want to do this because?"
        ],
        [
            "If we have accurate 2D joint locations across multiple frames, then we can combine this information and get it ready.",
            "Reconstruction, which is actually our final goal."
        ],
        [
            "So how do we do it?",
            "In a nutshell, we generate a set of potential candidates for the pose of the person, and then we learn a ranking function that can identify the best candidate between these.",
            "Set of configurations so we can see that we have like our simple simplified model in the first phase with pairwise terms and three models and everything, and then we have higher order more complicated models on the second phase.",
            "So I'm going to describe this in."
        ],
        [
            "To.",
            "So for efficient pose estimation, there's been a lot of work starting from the picture researchers.",
            "And this model is especially important because we know that with a set of assumptions we can do very fast inference using dynamic programming and distance transform.",
            "So people have worked a lot on this and try to improve this.",
            "For example, using descriptive project learning and for example compensating for in accuracies in annotations.",
            "But our work is mainly based on the last work, which is based on this work, it's called."
        ],
        [
            "Flexible mixture parts model.",
            "So the objective in this model is to maximize this scoring function.",
            "So first I have to say that the difference between this model and the picture assertion model is that they introduced the concept of templates, so they divide the object into multiple parts, but each part itself is also modeled with a set of templates and they want to maximize this objective function, which is basically a sum over the appearance score, the deformation score and completely compatibility is called.",
            "Of these part types.",
            "So the appearance score is basically a linear filter over hog descriptors.",
            "There's a quadratic deformation function, and there's a compatibility score which is basically tries to give a higher score 2 compatible, more compatible types."
        ],
        [
            "OK.",
            "So if we run this model MP on this is a state of the art, and if you run this on our data set for example on our football laser set, you get some good results and some bad.",
            "So here for example 2 examples."
        ],
        [
            "Problems usually come from double counting of the limbs.",
            "For example, here I highlighted it also if there is."
        ],
        [
            "Like lack of strong descriptive edge features, for example for arms.",
            "Here we are not able to detect the part."
        ],
        [
            "But interesting observation here.",
            "That is the main motive behind this paper is that if you not just look at the first configuration, not just the top scoring configuration, but like a set of high scoring configurations, for example, here top 30 configurations, you can see that the true true configuration might actually be somewhere in there.",
            "So for example here the 12 configuration is true.",
            "So this is not an."
        ],
        [
            "Incidence and if you try this on the whole test data use.",
            "We have observed that.",
            "Proving that true configuration is the first top scoring one is 36%.",
            "But if you look at the top 1000 configurations with the 88% chance that stirs their configuration, which is correct?",
            "So if you lower the threshold, say that it's OK if one part is missed.",
            "Then it goes from 68% to 98%."
        ],
        [
            "So.",
            "So basically what we do is to limit our search space to this topic scoring configuration that we get from our simplified model and then we can try our arbitrarily complex model on this set of operations.",
            "So what are the elements of this complicated function that we want to have?",
            "Firstly, we don't have the limitation of a tree, so we can have.",
            "We can model the deformation between unconnected parts in the tree structure.",
            "We also want to penalize for like unexplained foreground pixels and avoid double counting, which I will describe all of these in detail so."
        ],
        [
            "For modeling the information.",
            "Yeah, we basically we just introduced a lot of factors over the non connected parts in the tree structure."
        ],
        [
            "So to motivate that why we want to do the foreground background modeling.",
            "I showed the picture here that shows the top scoring again the top scoring configuration from the SMP.",
            "But what if you just look at the color distribution?",
            "You can see that it's obvious that one of the parts is missed.",
            "So we want to use this information and we want to sort of penalize this configuration because it's not.",
            "Sort of describing the whole.",
            "Image."
        ],
        [
            "So what we do is to use a set of top scoring configurations and then we sort of rasterize these configurations.",
            "A set of bounding boxes for each word and then we just merge them together and we get this.",
            "Mask segmentation initial segmentation mask on the left and then we do a thresholding on that to get a heart of over segmentation and under segmentation and we fit two function mixture models.",
            "Yeah, OK, so I try to.",
            "I don't know how loud I should be OK.",
            "So basically we feed two Gaussian mixture models to foreground and background pixels and then we just evaluate it on all the pixels and we get this segmentation mask.",
            "We don't care about the continuity really in this problem.",
            "And then we evaluate for each pose we again rasterize it, evaluate all the pixels and give a score based on how it's how compatible it is with our segmentation map."
        ],
        [
            "So we have another mechanism for avoiding double counting.",
            "So it's based on the observation that in a typical pictorial structure algorithm, we assume that appearance of different parts are independent.",
            "It is not true entirely in the flexible Mr Parts model.",
            "They have something there to compensate for that, but still like.",
            "Between different non connected parts, still we ignore all the sort of the correlation between all the appearances.",
            "But the observation here is that this is not true if you have."
        ],
        [
            "Overlaps if a lot of parts are overlapping and one of them is only visible, we should not like count all of them.",
            "So we just want to take the likelihood of the one that is visible, but we don't know which one is visible.",
            "So we take an average a weighted average of that.",
            "So in practice."
        ],
        [
            "We assume that priors are also equal, so we just basically take an average if parts overlap and otherwise we take the sum of this course."
        ],
        [
            "Then we learn a re ranking function that is able to re rank this configurations to give a higher rank to the one that is closest to the ground truth.",
            "So for doing that we use this SVM rank formulation.",
            "It's very similar similar to linear SVM, but the difference is that it is the.",
            "Like putting everything over one and minus one.",
            "We say that we want to just give higher rank higher rank to the one that is closer to the ground truth.",
            "So basically we have pairwise inequalities like pairs of inequalities between all the success of configurations."
        ],
        [
            "So.",
            "We create a feature vector based on the joint appearance.",
            "All of the terms that we had in the flexible mixture parts in addition to.",
            "Like our segmentation scores and additional factors that we introduce an.",
            "For the labels, we just used a PC PS core which basically says how many parts in this image, like in this configuration are correctly sort of identified."
        ],
        [
            "So why we didn't use the?",
            "Linear is when we tried and it didn't work as well, but I think that it's.",
            "For our problem, SVM rank is more suitable becausw.",
            "These scores that we get from different images are not really compareable, so we don't care and we don't care really about the absolute value of this score.",
            "We just care about the ordering.",
            "So SCM rank, I think for our problem is most."
        ],
        [
            "So to test this algorithm, we annotated a set of 800 images, football players and one focus for training the rest for testing."
        ],
        [
            "And here is what we get.",
            "So if it's based on this PC PS score, you can see we can get a somewhat an improvement over the flexible nature part model.",
            "That and the final one is the an Oracle ranking function which basically knows which one of these top 1000 configurations is correct one.",
            "So that's sort of an upper bound.",
            "Performance."
        ],
        [
            "So if you look at the cumulative histogram of the rank of 1st correctly predicted polls.",
            "You get something like this, so basically says that what's the probability of like the correct configuration being in the first 100 configurations or first 1000, or like just one.",
            "But if you look at look at it."
        ],
        [
            "Closely.",
            "And the first one, for example, you can see higher improvement, so the probability of a configuration being through the top scoring configuration.",
            "Being the correct configuration, using the flexible Mr Parts model is 36%.",
            "After doing the re ranking it goes higher as 251."
        ],
        [
            "So in many cases we can solve the double counting problem.",
            "As you can see here.",
            "The middle one is our results and the last one is the results that you get.",
            "The closest one between this set of top scoring configurations."
        ],
        [
            "But it's still there is a problem with flipping ambiguity when we cannot identify the left and right.",
            "For example limbs.",
            "For example here program background model says that this is a very good configuration, but then that's not really the correct one.",
            "The right one is the correct."
        ],
        [
            "And if we have sort of self occlusion, it can confuse our model as well."
        ],
        [
            "So getting all these two D results, we want to get to reconstruct.",
            "Location of the joints in 3D."
        ],
        [
            "So as I said, our model AS2D model cannot distinguish between left and right arms and legs, and so we have to put them in correspondence between Fort reviews.",
            "There is only 32 possible configuration for arms and legs, so we just like do an exhaustive search over all of that."
        ],
        [
            "For during the trigger construction, we just use this factorization algorithm to find an initial estimate for the camera parameters and the location of the three joints in 3D, and then we."
        ],
        [
            "Do a rectification process where we look for an affine transformation that can transform these matrices to the true camera matrices, so this is done in an optimization process where."
        ],
        [
            "We optimize where we try to minimize the Mahalanobis distance of the limb limb lengths from their mean.",
            "Anne."
        ],
        [
            "That's it, basically.",
            "This is the result that we get.",
            "And you can see that if we have sort of correct configurations across 3 views.",
            "We can get a fairly good trigger construction.",
            "And that's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm the head cosmian.",
                    "label": 0
                },
                {
                    "sent": "I'm going to present you the paper using richer models for articulated pose estimation.",
                    "label": 1
                },
                {
                    "sent": "For footballers.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the focus of this paper and this work is about accurate 2D pose estimation.",
                    "label": 1
                },
                {
                    "sent": "So what we want to do is, given an image of a football player.",
                    "label": 0
                },
                {
                    "sent": "For example, we want to localize a set of joint body joint locations on the image in 2D.",
                    "label": 0
                },
                {
                    "sent": "So why you want to do this because?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we have accurate 2D joint locations across multiple frames, then we can combine this information and get it ready.",
                    "label": 0
                },
                {
                    "sent": "Reconstruction, which is actually our final goal.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do it?",
                    "label": 0
                },
                {
                    "sent": "In a nutshell, we generate a set of potential candidates for the pose of the person, and then we learn a ranking function that can identify the best candidate between these.",
                    "label": 1
                },
                {
                    "sent": "Set of configurations so we can see that we have like our simple simplified model in the first phase with pairwise terms and three models and everything, and then we have higher order more complicated models on the second phase.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to describe this in.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To.",
                    "label": 0
                },
                {
                    "sent": "So for efficient pose estimation, there's been a lot of work starting from the picture researchers.",
                    "label": 1
                },
                {
                    "sent": "And this model is especially important because we know that with a set of assumptions we can do very fast inference using dynamic programming and distance transform.",
                    "label": 1
                },
                {
                    "sent": "So people have worked a lot on this and try to improve this.",
                    "label": 0
                },
                {
                    "sent": "For example, using descriptive project learning and for example compensating for in accuracies in annotations.",
                    "label": 0
                },
                {
                    "sent": "But our work is mainly based on the last work, which is based on this work, it's called.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Flexible mixture parts model.",
                    "label": 0
                },
                {
                    "sent": "So the objective in this model is to maximize this scoring function.",
                    "label": 1
                },
                {
                    "sent": "So first I have to say that the difference between this model and the picture assertion model is that they introduced the concept of templates, so they divide the object into multiple parts, but each part itself is also modeled with a set of templates and they want to maximize this objective function, which is basically a sum over the appearance score, the deformation score and completely compatibility is called.",
                    "label": 1
                },
                {
                    "sent": "Of these part types.",
                    "label": 0
                },
                {
                    "sent": "So the appearance score is basically a linear filter over hog descriptors.",
                    "label": 0
                },
                {
                    "sent": "There's a quadratic deformation function, and there's a compatibility score which is basically tries to give a higher score 2 compatible, more compatible types.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if we run this model MP on this is a state of the art, and if you run this on our data set for example on our football laser set, you get some good results and some bad.",
                    "label": 0
                },
                {
                    "sent": "So here for example 2 examples.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems usually come from double counting of the limbs.",
                    "label": 0
                },
                {
                    "sent": "For example, here I highlighted it also if there is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like lack of strong descriptive edge features, for example for arms.",
                    "label": 0
                },
                {
                    "sent": "Here we are not able to detect the part.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But interesting observation here.",
                    "label": 0
                },
                {
                    "sent": "That is the main motive behind this paper is that if you not just look at the first configuration, not just the top scoring configuration, but like a set of high scoring configurations, for example, here top 30 configurations, you can see that the true true configuration might actually be somewhere in there.",
                    "label": 0
                },
                {
                    "sent": "So for example here the 12 configuration is true.",
                    "label": 0
                },
                {
                    "sent": "So this is not an.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Incidence and if you try this on the whole test data use.",
                    "label": 0
                },
                {
                    "sent": "We have observed that.",
                    "label": 0
                },
                {
                    "sent": "Proving that true configuration is the first top scoring one is 36%.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the top 1000 configurations with the 88% chance that stirs their configuration, which is correct?",
                    "label": 0
                },
                {
                    "sent": "So if you lower the threshold, say that it's OK if one part is missed.",
                    "label": 0
                },
                {
                    "sent": "Then it goes from 68% to 98%.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So basically what we do is to limit our search space to this topic scoring configuration that we get from our simplified model and then we can try our arbitrarily complex model on this set of operations.",
                    "label": 1
                },
                {
                    "sent": "So what are the elements of this complicated function that we want to have?",
                    "label": 0
                },
                {
                    "sent": "Firstly, we don't have the limitation of a tree, so we can have.",
                    "label": 0
                },
                {
                    "sent": "We can model the deformation between unconnected parts in the tree structure.",
                    "label": 1
                },
                {
                    "sent": "We also want to penalize for like unexplained foreground pixels and avoid double counting, which I will describe all of these in detail so.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For modeling the information.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we basically we just introduced a lot of factors over the non connected parts in the tree structure.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to motivate that why we want to do the foreground background modeling.",
                    "label": 0
                },
                {
                    "sent": "I showed the picture here that shows the top scoring again the top scoring configuration from the SMP.",
                    "label": 0
                },
                {
                    "sent": "But what if you just look at the color distribution?",
                    "label": 0
                },
                {
                    "sent": "You can see that it's obvious that one of the parts is missed.",
                    "label": 0
                },
                {
                    "sent": "So we want to use this information and we want to sort of penalize this configuration because it's not.",
                    "label": 0
                },
                {
                    "sent": "Sort of describing the whole.",
                    "label": 0
                },
                {
                    "sent": "Image.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we do is to use a set of top scoring configurations and then we sort of rasterize these configurations.",
                    "label": 0
                },
                {
                    "sent": "A set of bounding boxes for each word and then we just merge them together and we get this.",
                    "label": 0
                },
                {
                    "sent": "Mask segmentation initial segmentation mask on the left and then we do a thresholding on that to get a heart of over segmentation and under segmentation and we fit two function mixture models.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so I try to.",
                    "label": 0
                },
                {
                    "sent": "I don't know how loud I should be OK.",
                    "label": 0
                },
                {
                    "sent": "So basically we feed two Gaussian mixture models to foreground and background pixels and then we just evaluate it on all the pixels and we get this segmentation mask.",
                    "label": 1
                },
                {
                    "sent": "We don't care about the continuity really in this problem.",
                    "label": 0
                },
                {
                    "sent": "And then we evaluate for each pose we again rasterize it, evaluate all the pixels and give a score based on how it's how compatible it is with our segmentation map.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have another mechanism for avoiding double counting.",
                    "label": 0
                },
                {
                    "sent": "So it's based on the observation that in a typical pictorial structure algorithm, we assume that appearance of different parts are independent.",
                    "label": 0
                },
                {
                    "sent": "It is not true entirely in the flexible Mr Parts model.",
                    "label": 0
                },
                {
                    "sent": "They have something there to compensate for that, but still like.",
                    "label": 0
                },
                {
                    "sent": "Between different non connected parts, still we ignore all the sort of the correlation between all the appearances.",
                    "label": 0
                },
                {
                    "sent": "But the observation here is that this is not true if you have.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overlaps if a lot of parts are overlapping and one of them is only visible, we should not like count all of them.",
                    "label": 1
                },
                {
                    "sent": "So we just want to take the likelihood of the one that is visible, but we don't know which one is visible.",
                    "label": 1
                },
                {
                    "sent": "So we take an average a weighted average of that.",
                    "label": 0
                },
                {
                    "sent": "So in practice.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We assume that priors are also equal, so we just basically take an average if parts overlap and otherwise we take the sum of this course.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we learn a re ranking function that is able to re rank this configurations to give a higher rank to the one that is closest to the ground truth.",
                    "label": 0
                },
                {
                    "sent": "So for doing that we use this SVM rank formulation.",
                    "label": 0
                },
                {
                    "sent": "It's very similar similar to linear SVM, but the difference is that it is the.",
                    "label": 0
                },
                {
                    "sent": "Like putting everything over one and minus one.",
                    "label": 0
                },
                {
                    "sent": "We say that we want to just give higher rank higher rank to the one that is closer to the ground truth.",
                    "label": 1
                },
                {
                    "sent": "So basically we have pairwise inequalities like pairs of inequalities between all the success of configurations.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We create a feature vector based on the joint appearance.",
                    "label": 1
                },
                {
                    "sent": "All of the terms that we had in the flexible mixture parts in addition to.",
                    "label": 0
                },
                {
                    "sent": "Like our segmentation scores and additional factors that we introduce an.",
                    "label": 0
                },
                {
                    "sent": "For the labels, we just used a PC PS core which basically says how many parts in this image, like in this configuration are correctly sort of identified.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why we didn't use the?",
                    "label": 0
                },
                {
                    "sent": "Linear is when we tried and it didn't work as well, but I think that it's.",
                    "label": 0
                },
                {
                    "sent": "For our problem, SVM rank is more suitable becausw.",
                    "label": 1
                },
                {
                    "sent": "These scores that we get from different images are not really compareable, so we don't care and we don't care really about the absolute value of this score.",
                    "label": 1
                },
                {
                    "sent": "We just care about the ordering.",
                    "label": 0
                },
                {
                    "sent": "So SCM rank, I think for our problem is most.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to test this algorithm, we annotated a set of 800 images, football players and one focus for training the rest for testing.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here is what we get.",
                    "label": 0
                },
                {
                    "sent": "So if it's based on this PC PS score, you can see we can get a somewhat an improvement over the flexible nature part model.",
                    "label": 0
                },
                {
                    "sent": "That and the final one is the an Oracle ranking function which basically knows which one of these top 1000 configurations is correct one.",
                    "label": 1
                },
                {
                    "sent": "So that's sort of an upper bound.",
                    "label": 0
                },
                {
                    "sent": "Performance.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you look at the cumulative histogram of the rank of 1st correctly predicted polls.",
                    "label": 1
                },
                {
                    "sent": "You get something like this, so basically says that what's the probability of like the correct configuration being in the first 100 configurations or first 1000, or like just one.",
                    "label": 0
                },
                {
                    "sent": "But if you look at look at it.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Closely.",
                    "label": 0
                },
                {
                    "sent": "And the first one, for example, you can see higher improvement, so the probability of a configuration being through the top scoring configuration.",
                    "label": 0
                },
                {
                    "sent": "Being the correct configuration, using the flexible Mr Parts model is 36%.",
                    "label": 1
                },
                {
                    "sent": "After doing the re ranking it goes higher as 251.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in many cases we can solve the double counting problem.",
                    "label": 1
                },
                {
                    "sent": "As you can see here.",
                    "label": 0
                },
                {
                    "sent": "The middle one is our results and the last one is the results that you get.",
                    "label": 0
                },
                {
                    "sent": "The closest one between this set of top scoring configurations.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it's still there is a problem with flipping ambiguity when we cannot identify the left and right.",
                    "label": 1
                },
                {
                    "sent": "For example limbs.",
                    "label": 0
                },
                {
                    "sent": "For example here program background model says that this is a very good configuration, but then that's not really the correct one.",
                    "label": 0
                },
                {
                    "sent": "The right one is the correct.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if we have sort of self occlusion, it can confuse our model as well.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So getting all these two D results, we want to get to reconstruct.",
                    "label": 0
                },
                {
                    "sent": "Location of the joints in 3D.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I said, our model AS2D model cannot distinguish between left and right arms and legs, and so we have to put them in correspondence between Fort reviews.",
                    "label": 0
                },
                {
                    "sent": "There is only 32 possible configuration for arms and legs, so we just like do an exhaustive search over all of that.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For during the trigger construction, we just use this factorization algorithm to find an initial estimate for the camera parameters and the location of the three joints in 3D, and then we.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do a rectification process where we look for an affine transformation that can transform these matrices to the true camera matrices, so this is done in an optimization process where.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We optimize where we try to minimize the Mahalanobis distance of the limb limb lengths from their mean.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, basically.",
                    "label": 0
                },
                {
                    "sent": "This is the result that we get.",
                    "label": 0
                },
                {
                    "sent": "And you can see that if we have sort of correct configurations across 3 views.",
                    "label": 0
                },
                {
                    "sent": "We can get a fairly good trigger construction.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}