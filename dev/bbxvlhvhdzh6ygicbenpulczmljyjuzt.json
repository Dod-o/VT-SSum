{
    "id": "bbxvlhvhdzh6ygicbenpulczmljyjuzt",
    "title": "Semi-supervised tree learning",
    "info": {
        "author": [
            "Dragi Kocev, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 31, 2017",
        "recorded": "September 2016",
        "category": [
            "Top->Computer Science",
            "Top->Data Science"
        ]
    },
    "url": "http://videolectures.net/miningdata2016_kocev_tree_learning/",
    "segmentation": [
        [
            "First, on several of these competitions.",
            "But we thought that it may fit.",
            "Benefit might be beneficial if we somehow knew to exploit the information hidden in the in the.",
            "Tested images without using their labels and this drives us.",
            "Or Speaking of semi supervised learning and then you kill Angela came in his background in school training and we started talking about these different issues that may arise and from that point on couple couple of years after that weekend my assistant.",
            "So the work that I presented here is mainly the work of our field we students during the level which this is.",
            "Of five of his PhD thesis and I will."
        ],
        [
            "Start by briefly introducing and motivating the problem.",
            "Then really, really, briefly repeat what Sasha earlier presented about the predictive clustering framework.",
            "Then I will present our approach that is based on different definitions of distances and then provide some conclusions and ideas for further work."
        ],
        [
            "So as such, over dimensional typically machine learning, we have two two types of tasks, the first one being supervised learning, where we have examples that have labels and these are the tasks classification and regression or are supervised learning where we have just examples without labels and there the goal is to either to perform dimensionality reduction or to cluster these examples into clusters.",
            "In cases when we have labeled both labeled and unlabeled data, then we have supervised semi supervised learning."
        ],
        [
            "White why this is relevant?",
            "This is relevant because labeling can be very expensive and laborious, tedious and tedious work.",
            "Imagine if you have some of the experiments that Sasha was mentioning about patients.",
            "Obtaining a label for each patient can be really costly.",
            "Doing all the tests and all the all the lab work, but having this general background before about the patient is not that difficult to obtain.",
            "This.",
            "This issue is even more pronounced in the case of structured output prediction, where we have multiple.",
            "Typically we have multiple labels to obtain.",
            "I will now briefly mention the tasks that we consider within within this work."
        ],
        [
            "So this is the cycle, the slide that you already seen it, the same supervised classification.",
            "We have descriptive spaces, equal variables and output variables, and some of the values for the output variables are busy."
        ],
        [
            "Supervisor regression, where the output variable now is a numeric value and again some of its values are missing.",
            "Then we."
        ],
        [
            "Can have semi supervised move to label classification where the labels are provided for some of the examples.",
            "And again we don't have labels for the other part."
        ],
        [
            "Semi supervised multi target regression with a similar similar property.",
            "Now how do we approach these tasks?",
            "Or in general how these tasks can be approached can be."
        ],
        [
            "Urged by either learning global models or local models.",
            "Global models construct a single model that are valid for the all of the outputs.",
            "That means I have a single model and I get a prediction for all of the variables.",
            "The most simple end.",
            "A trivial approach to both of tracking photos is the local local models paradigm, where I can learn a model for each of the target separately.",
            "At the end, however, learning local models can often be.",
            "Infeasible.",
            "Easily we have domains with hundreds or even thousands of labels, so constructing thousands and thousands of predictive models sometimes is really expensive.",
            "Moreover, global models are able to catch the interesting dependencies that may exist between the different labels between the different targets.",
            "These elite to smoothing the prediction function and avoid large discrete to discontinue discontinue.",
            "It is in that in the in the prediction function.",
            "We have studies performance studies that show that constructed constructive global models leads to better predictive performance.",
            "Computationally are more efficient.",
            "The models are simpler and they tend to overfit less than the local models.",
            "Now, within the same supervised learning."
        ],
        [
            "We heavily exploit the smoothness of the prediction function assumption.",
            "What do we mean when we say smoothness of the prediction function?",
            "Consider the example given below.",
            "The X is marked the labeled data, the dots map unlabeled data are making.",
            "Assumption is that if 2 examples are closed in a dense region, then their prediction must be closed also.",
            "A day."
        ],
        [
            "Alarm.",
            "Several approaches that that.",
            "The tackle this issue, but mainly they are focused on the tasks of simple classification.",
            "There are already some works that do semi supervised regression, but even rarer are works that do semisupervised learning for structured output prediction.",
            "Typically there are a couple of methods that are based on kernel learning and then there are graph based methods for setting supervised learning and some other sporadic attempts to approach this task, but the.",
            "A severe limitations in several aspects."
        ],
        [
            "First of all, they have high computational costs.",
            "This is even more pronounced in domains with large number, number of examples and domains with large number of output labels.",
            "That is, if you have 1000 of.",
            "Target variables over 10s of thousands of examples.",
            "This can lead to intractable solutions.",
            "The next the next issue is the interpretability of the obtained models.",
            "All of the methods that I mentioned earlier are not interpretable by a domain expert.",
            "They can only see the predictions and assess the quality of the predictions, but not assess the model and its relation to the knowledge about the domain.",
            "Next, all of these focus on a specific type of output.",
            "If you have some savings supervised learning method, it is either tailored for multi label classification or tailored for predicting multiple numeric variables or learning sequences.",
            "And finally the evaluation of these methods is even more focused, and it's typically focused on a single domain.",
            "For instance, you can have semi supervised learning for hierarchical.",
            "Older label classification for text documents and that is the only domain where this approach is being evaluated within my."
        ],
        [
            "Extra we strive to address all of these shortcomings of the existing approaches, and we built upon the predicted clustering framework.",
            "This framework was shown to be effective, efficient.",
            "Into solving a variety of structured output prediction tasks and we are able to obtain predictive models with state of the art predicting performance.",
            "Now, briefly."
        ],
        [
            "I will you straight part is what we mean when we say predictive clustering and I will just.",
            "Even repeat some of the.",
            "Some of the work, some of the slides social said, but I will be a bit more technical so."
        ],
        [
            "This figure illustrates.",
            "The advantage of predictive clustering.",
            "We have three graphs on each of the graphs on the X axis we have the descriptive space and on the Y axis we have the target space.",
            "If we see this problem from the point of view of predictive modeling, that means that we're only focused in the target space, and we're able to identify two clusters of data.",
            "If we see this problem from a clustering perspective, that means we're only focusing on the descriptive space.",
            "We identify these two clusters of data.",
            "But within effective clustering, since we're able to look both at the descriptive and the target space, we are able to identify these three clusters of data, and this is the main advantage that we have, and this is the main adventure that we exploit in our method."
        ],
        [
            "The method that we use this is based on the predictive clustering.",
            "Please and Sasha said this is.",
            "These are ordinary trees with the two little tricks."
        ],
        [
            "The first one key definition of variance function that is tailored for a specific task and also definition of a specific program type function that is tailored for a specific task.",
            "We have extended."
        ],
        [
            "Random.",
            "The variance of product by functions for several different tasks.",
            "And here I just mentioned these four tasks, the first one being moved to target regression, where we use the.",
            "The body of the where the prototype is calculated as the average of the values and variances.",
            "Some of the variances to pull the target.",
            "Then we have multivalued classification multi label classification.",
            "Whereas default we used some of the gene.",
            "This is per label and then for hierarchical multi label classification the prototype is averaging.",
            "With applying a threshold for selecting class membership and obtaining and obeying the hierarchical constraint.",
            "And the variance is based on a weighted Euclidean distance which is aware about the structure of the."
        ],
        [
            "Now I will.",
            "I will explain what what we what we did and what.",
            "And how we improved or the primitive clustering framework?"
        ],
        [
            "This is an example of a predicted clustering tree.",
            "This is multi target regression tree.",
            "Actually this domain is predicting the abundance of.",
            "Of the items in Lake Prespa, the notes include chemical parameters.",
            "Beliefs include values of number of items that were involved encountered under these specific conditions.",
            "Space on the other side of the mountain.",
            "And."
        ],
        [
            "Here, as I said, the goal is to maximize the variance reduction and the maximization of the balance reduction is illustrated with this heuristic score that is given here.",
            "Here we have the variance of the parent node, for instance here and then subtracted the variances in the children nodes."
        ],
        [
            "We do this for each of the targets and then we get the overall variance, so this is relatively straightforward, no?",
            "No big tricks here, because this is only calculated in the target space, so this is completely predictive setting.",
            "What we do now."
        ],
        [
            "Alice.",
            "We move this to the same supervised context and we extend these various by including a term that refers to the descriptive space.",
            "So these are the variances in the descriptive space.",
            "Moreover, we introduced a parameter W that controls the amount of supervision.",
            "What do we mean when we say by supervision we say we mean the influence of the target space that has to be overall heuristic score calculation.",
            "If you select this W closer to 1, this means that we rely more on the target space.",
            "If we select if we select W closer to zero, that means that we rely more on the descriptive space of the data.",
            "So this is.",
            "And electively easier to see for the numeric case when we have only numeric variables.",
            "But we have also discrete variable."
        ],
        [
            "Present then this is extended as follows.",
            "We again have the input the output space and the input space.",
            "We again have the parameter for controlling the level of supervision.",
            "And the influence of the made variables and the.",
            "And the discrete variables is shown here, however."
        ],
        [
            "Here we can be potentially making a big mistake by mixing apples and oranges because the distances used in these two cases might be on different scales.",
            "Different properties, and it's not that easy just to add them up and and.",
            "And calculate the heuristic value."
        ],
        [
            "To this end, we normalize them, bring them to the same scale so they.",
            "Approximately measure the same, the same same thing.",
            "Now to be more graphic and to use it, what?",
            "What actually we're doing?"
        ],
        [
            "Let us look at this example that illustrates the same supervised learning problem.",
            "The green axis are the values of the target variables.",
            "And these are the only labeled examples that we know.",
            "And the dots are.",
            "Table so on the X axis we have descriptive on the Y axis we have the target space similarly as the previous example, if we consider a supervised learning algorithm that supervised learning algorithm will consider only the target space and we will find this line here as the ideal for split.",
            "For splitting the examples into two clusters.",
            "So these two clusters are.",
            "Oh the top three examples.",
            "And then the the lower 4 examples on the Y axis.",
            "Just to clarify, the access is enabled able.",
            "The big access the peak accesses the label data.",
            "Yeah, the X is the.",
            "Discrete accesses the labels.",
            "Yeah.",
            "All and this these are projections in the target space and projections in the input space.",
            "The unlabeled data, on the other hand, is given here.",
            "The dogs and these are.",
            "This is the distribution of the unlabeled data.",
            "And now if you have same supervised learning as I showed earlier, the same is supervised learning predefined two splits.",
            "These are the red, the red lines here.",
            "That means the same supervised learning algorithm decided to divide this data into three clusters.",
            "Log into two clusters.",
            "What happens more specifically here is."
        ],
        [
            "If I reveal the true labels of the unlabeled data that we had in the first example.",
            "They are distributed as shown here.",
            "So again, we have this values of that in the target space.",
            "That are projected here, we see that.",
            "And we have the prediction function for the from the supervised model given with the blue blue line and then the prediction function from the same supervised learning with given with the red dots, we see that the model that we have with semi supervised learning is far far better than the one in the supervised learning.",
            "Just as an illustration, these are real numbers, so this example is was really run using our algorithm.",
            "The mean squared error for the supervised method was zero point 5 four and for the same supervised was 0.09.",
            "So we're after this.",
            "This type of improvements that that.",
            "But the that can that can be extracted from the data."
        ],
        [
            "Within our work, we focused on four different extensions of the same supervised learning.",
            "Predicted class increase.",
            "The first one being moved to target regression.",
            "So we started with the multiplication because the definitions of distances here is more clear.",
            "It's not that complicated and then we move to these three different types of classification tasks.",
            "Enmu."
        ],
        [
            "Target regression we used to.",
            "We used simple variance calculation function which is.",
            "Which is shown on the slide.",
            "However, here we calculate the variance only on the examples with known labels with no value.",
            "If we have missing values, then it's.",
            "The missing values for that given attribute do not influence on its variance score, but what happens?"
        ],
        [
            "You could give.",
            "Examples that have none that have all of the values missing.",
            "Easily it can happen in the cases when we have selected.",
            "It usually happens when we select the W parameter to be closer to zero, that means.",
            "That means.",
            "Less and less supervision.",
            "This means that we have leaves of industry where all of the examples have no label, and then how can we make a prediction for relief with examples with no labels?",
            "To answer this."
        ],
        [
            "We tested three variants and the first one is to be used as variance estimate for that lift.",
            "The various in the parent node and this is some somewhat a compromise solution because they this means that for this life we only exploit the information that we know best to that point in the model construction II approaches, we estimate this variance with the virus of the whole training set.",
            "Now consider that the variance of the whole training set is.",
            "The larger this will lead in turn to smaller trees.",
            "And the other extremists simply ignore these attributes.",
            "Then this will allow that reconstruction to build even larger trees.",
            "We tested all these variables.",
            "All these solutions and also we."
        ],
        [
            "We encountered another issue is when when we're used, mixing descriptive and the target space.",
            "Typically the descriptive space is very large, it can overcome its influence and then you have.",
            "You can have redundant variables in the descriptive space and this can hurt the overall performance of the end.",
            "To cope with that, we further extend the definition of the variance reduction by including this Sigma wait here.",
            "Which is actually the future elements for that given activity.",
            "So All in all."
        ],
        [
            "We have 6 variants of same supervised predicted clustering trees.",
            "That means 3.",
            "The three cases, the three extreme cases that that that I mentioned times whether we use or not feature ranking.",
            "So in total six we perform we performed experimental evaluation on 10 benchmarking.",
            "Pull the target regression datasets and we compare the performance of service supervised the cities to a standard supervised PCP that is learned on the same amount of labeled data.",
            "And a supervised counterpart of Semi supervised visit is is.",
            "Is this the same algorithm but without exploiting the unlabeled data, just the label data?",
            "Also, we conduct two different sets of experiments.",
            "In the first one, we consider absolute number of labeled examples.",
            "That is, we have 25 labeled examples 51120 and in the second case we use a relative number of labeled examples in each of the experiments as to the size of the domain that we're looking.",
            "The first, the first approach, the use of the absolute.",
            "Absolute value is actually.",
            "Closer to the real applications because typically if you have an expert he has an amount of labeled data 5100 and the size of domains of the potential potential domain is unknown.",
            "You cannot.",
            "You cannot always know the number of unlabeled data available.",
            "The evaluation is done in the transductive learning scenario.",
            "That means that the goal is to obtain predictions for the unlabeled part of the data and to avoid.",
            "Alleviate the influence of the random selections in the label data in the division of the data into labeled and unlabeled.",
            "We repeated all the experiments 10 times with different random initializations.",
            "Briefly, I will explain I will give the results."
        ],
        [
            "Perform.",
            "We show that every track diagrams these are these four average run diagrams for each of the amount of labeled data that we consider this.",
            "These diagrams show the relative performance of the proposed method and there they are read as follows.",
            "It's an axis from one to six because we have six methods.",
            "One being closer to 1, being better closer to fix mean mean.",
            "Worse, and we can see all over all of the.",
            "For this 4 settings."
        ],
        [
            "Using the estimates from the parent note seems to be overall the best solution.",
            "The most acceptable solution?",
            "And we know that in this case feature rating does not help much.",
            "While if we move to the."
        ],
        [
            "Relative number of labeled examples.",
            "Again, we have the same average diagram."
        ],
        [
            "We see that if we ignore if you apply feature ranking helps but and also in this case if we ignore this.",
            "Uh, if you ignore the examples with missing with not missing with.",
            "If you ignore the examples that have all of the values missing attributes with all of the values missing, that is the most stringent condition we get.",
            "Somewhat maybe the best result.",
            "This is true."
        ],
        [
            "State what happens in the graphs.",
            "These are four graphs where we showed that same in supervised learning.",
            "Helps a lot on the X axis.",
            "We have the number of labeled examples on the Y axis.",
            "We have the performance measure and we see that same as supervised learning is especially beneficial in cases where the number of labeled examples is smaller.",
            "So when we have only small parts of label of labeled data then we are able to achieve.",
            "Better, better, better predictive performance.",
            "Is some."
        ],
        [
            "The datasets we are somewhat better and this summer better is around 2550 examples and then we cannot improve much after that answer."
        ],
        [
            "Sometimes we we are simply.",
            "Same as the supervised learning.",
            "Why is this?",
            "This."
        ],
        [
            "Mainly because of this parameter W that I was mentioning.",
            "This parameter is very crucial for us because it provides a mechanism to protect our algorithm from degrading performance from the supervised learning.",
            "In essence, we try several values for this parameter and then with internal proof three fold cross validation.",
            "We select the optimal.",
            "Value for the double parameter.",
            "This prevents form from the degrading the performance of our method just to use."
        ],
        [
            "Take this.",
            "Consider this graph on the X axis.",
            "We have the number of labeled data and here on the top is the value of this Omega parameter and on the axis on the Y axis is the performance because this is way too please correct error, lower feels better.",
            "And the amount of supervision moves from left to right.",
            "So this means fully supervised.",
            "This needs fully unsupervised.",
            "This is fully supervised and unsupervised in this.",
            "For this data set, our algorithm selected to use very little supervision.",
            "So practically it focused more on the descriptive part and was able to correctly select the best W values that are available.",
            "In next scenario."
        ],
        [
            "So we see very this very nice graph for this different for this.",
            "Second data set.",
            "But the selection of formal gates, again very good, and that the most interesting part is that first it is able to find even this small improvements, but here it prevented our algorithm to the grade as you see, the performance of the same is supervised."
        ],
        [
            "The second performance with the same supervisor is somewhat worse than the supervised and then it selected just to use the supervised, that is, select W equals one, that means.",
            "We are not worse than the supervised method.",
            "Another set of experiments that we performed that we are very happy."
        ],
        [
            "About is the amount of unlabeled data that is pulled into the algorithm.",
            "Typically you can.",
            "There are.",
            "Very well there are several.",
            "The references from the literature that state oh, because we have the abundance of the unlabeled part, we can exploit all of them and build better models.",
            "We tried finding the amount of unlabeled data that we used to our algorithm and we see that actually this leads to.",
            "Do saturation after nearly 1000 examples.",
            "It doesn't matter anymore to have more unlabeled data in terms of predicted performance.",
            "Furthermore, if we look at the trees that we get at the end, because as you recall, as I said, interpret abilities really important.",
            "Part of the of the tasks that we're looking at."
        ],
        [
            "I was taking a two piece.",
            "It is obtained on a data set.",
            "The left one is obtained from using 50 labeled examples, just 50 labeled examples, and it yielded.",
            "A3 With 9 notes and that estimated to be squared error of zero point 96.",
            "The best possible treatment in this domain.",
            "That means use all of the available labeled data.",
            "Is we basically spent error of 0.51 and but it is enormous.",
            "So if this is non non interpretable for domain extent, the decision that the pieces that we obtained is."
        ],
        [
            "Very nice compromise between these two.",
            "It has 23 nodes.",
            "This is still manageable by a domain expert or domain expert.",
            "Can look at it and draw some conclusions and it gets very good very quickly, squared error.",
            "It's zero point 71 this is somewhere halfway to the best possible tree."
        ],
        [
            "In summary uh?",
            "This is for safety.",
            "Supervised learning in discount for the task of multi target regression.",
            "They are global and easily interpretable models.",
            "Can and often improve the predictive performance of supervised by cities?",
            "And they are most effective in scenarios where the amount of labeled data is severely limited.",
            "The performance of supervised.",
            "The performance.",
            "Of over the performance of saving supervised species seldomly that generates the performance of the supervised the cities.",
            "Finally we observed performance situation only adding up after adding only 1000 are labeled examples.",
            "That means we don't need too much unlabeled examples, which in turn means that our methods can be more efficient into obtaining data.",
            "The best possible models.",
            "Further"
        ],
        [
            "For which we evaluated our method.",
            "In a discrete classification, tasks in this and we used 12 binary classification datasets, then multiclass classification datasets and 14 move little fication datasets.",
            "All of these are downloaded either from UCI, either from open email repository.",
            "We performed evaluation both as I described earlier in a single three setting, but here we also a special mention.",
            "We have the freedom to give.",
            "To learn also examples, we also investigated the possibility of refractive assembles in this setting.",
            "Explore the influence of different amounts of label data.",
            "Again, it's pretty much the same experimental setup that we had earlier.",
            "Do you?"
        ],
        [
            "Take the results here on the X axis.",
            "Again, we have the amount of labeled data, amount of labeled data and on the Y axis is the accuracy.",
            "So this means more is better.",
            "And we're comparing.",
            "First, we're comparing a single positive, the red line over the black line that is, the red line is the same is supervised by city.",
            "The Black Line is the supervised by city, and we see that in the first case we are able to improve across all the number of unlabeled data.",
            "In the second case, we're not that bad.",
            "Better than the supervised counterpart, and on the third case.",
            "All of the methods perform equally well.",
            "If we focus on the assembles, we see that we we tested three variants of the samples, the first one being supervised random forests, the second one being same as supervised random forests of our facilities, and the third one will be another approach for semi supervised learning that is based on self training.",
            "And we see that often the same supervised random forests are able to outperform the Super computing methods.",
            "Now two things are.",
            "Evident here that.",
            "If uh based semi supervised the city outperforms the supervised pre city.",
            "This does not mean that the ensemble counterpart will also keep the same performance advantage.",
            "Moreover we know that it's difficult to improve the predictive performance in domains where there is already a good predictive performance.",
            "For instance, here the predictive performance is in the scale of 0.99 zero point 19, and you cannot go much better than that whatever you do.",
            "We also perform.",
            "We performed a build up some statistical tests across the datasets that we used to show how to investigate power made it how the methods behave.",
            "Glasses mean that glasses here mean that the same is supervised.",
            "Methods are better.",
            "The bold, bold ones indicate statistically significantly better performance, and we see that.",
            "All of these are classes.",
            "That means that the same is supervised method.",
            "Generally, overall of the datasets and very often in this improvement for statistically significant.",
            "We"
        ],
        [
            "Make the same seem a little positive observations for the multiclass classification datasets.",
            "Again, we have the same.",
            "Graphs and.",
            "The conclusions are very similar, with the notion that he.",
            "That here we can also investigate other different Maia evaluation measures, and we can have more complex scenarios.",
            "The focus on the on the elect interpret interpret ability."
        ],
        [
            "You stated this with the following models.",
            "We have two facilities.",
            "The left one is constructed using 100 label examples in a supervised way.",
            "This produced three with 17 nodes and accuracy of 69%.",
            "Our method was able to obtain slightly smaller three with 50 nodes or one split less and the accuracy was 72%.",
            "If we."
        ],
        [
            "Look at the same example for multiclass classification, again on the left hand side we have the supervised PCT.",
            "Here we have supervised visits with 11 modes and accuracy of 81%.",
            "The same is supervised.",
            "However, has accuracy of 92%, which is a slightly smaller and this improvement is very significant and very.",
            "Very significant.",
            "What are?"
        ],
        [
            "I mean key points here.",
            "We observe that the improvement does not usually saturate with the increase of the amount of the label.",
            "Examples that we kept again, which may indicate that we need to consider even larger amounts of unlabeled data.",
            "Why is this important?",
            "Is important because this is behavior that we observed in the multi target regression case and not here.",
            "Semi supervised learning does not help for domains where we are able to learn very good models, which is somewhat logical and expected.",
            "The performance increase that we obtain in your place predicted models does not carry over into the ensemble setting.",
            "And we were able to obtain smaller, interpretable models that have better objective performance.",
            "Finally."
        ],
        [
            "I will just briefly.",
            "The show the results that we got from us for semi supervised multilabel classification.",
            "So we still haven't fully explored this setting because of of the complexity that it entails.",
            "The complexities?",
            "Made many, many coming from the different possibilities of definitions of distance functions and evaluation functions, and this is not easy to address and tackle, so this is just to say how many different evaluation functions we can have an optimized.",
            "We tried on couple of data."
        ],
        [
            "Sense and these are the results.",
            "Did the results are?",
            "Validated using Hamming loss as loss function as a revelation fashion and then on the X axis we again we have the number of tables.",
            "Examples here, less is better and we see that the same is supervised by cities, are able to improve over the supervised counterparts, but this this comparison needs to be done in a much more multi dimensional method.",
            "Wait, we will save the performances in different measures and to try different distance functions for.",
            "For constructing the trees.",
            "Finally."
        ],
        [
            "I will conclude by.",
            "Saying that we developed global methods for saving supervised learning that are flexible and able to address several tasks.",
            "We show that we can improve the performance of supervised predicted clustering trees, especially in domains where the availability of labeled examples is limited.",
            "The performance of our supervisor, primitive clustering trees seldomly generates over the performance of supervised predictive clustering trees and as you stated on on this couple of examples, to obtain models are easy.",
            "Interpreted by a domain expert.",
            "Where?"
        ],
        [
            "Where we will pursue this this topic further.",
            "First, we will consider additional tasks.",
            "We will consider the task of hierarchical multi label classification in the task of Time series prediction.",
            "Why we will leave this as one of the last steps?",
            "We will never please because of the complexity of the distances in this for this specific tasks, it is not that trivial to device variance functions for this specific specific cases.",
            "A special dimension we can easily now do unsupervised learning for data with mixed variable types we can easily employ the same variance function and just calculate calculate the variance deductions and then we can have a really nice.",
            "Really nice property, that is, we are able to learn models from partially labeled data.",
            "That means that data where the labels are incomplete and the order they have two small case studies.",
            "Phone in this setting, the first one being for qsar modeling of compounds, and the second one is.",
            "Spell function modeling, and finally this.",
            "This algorithm actually enables us to perform feature ranking in a variety of settings.",
            "So now we are able to use this algorithm to do feature ranking for a supervised learning feature ranking for semi supervised feature ranking for partially and we addressed this line of complexity within my extra.",
            "So with that I'll thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, on several of these competitions.",
                    "label": 0
                },
                {
                    "sent": "But we thought that it may fit.",
                    "label": 0
                },
                {
                    "sent": "Benefit might be beneficial if we somehow knew to exploit the information hidden in the in the.",
                    "label": 0
                },
                {
                    "sent": "Tested images without using their labels and this drives us.",
                    "label": 0
                },
                {
                    "sent": "Or Speaking of semi supervised learning and then you kill Angela came in his background in school training and we started talking about these different issues that may arise and from that point on couple couple of years after that weekend my assistant.",
                    "label": 0
                },
                {
                    "sent": "So the work that I presented here is mainly the work of our field we students during the level which this is.",
                    "label": 0
                },
                {
                    "sent": "Of five of his PhD thesis and I will.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Start by briefly introducing and motivating the problem.",
                    "label": 0
                },
                {
                    "sent": "Then really, really, briefly repeat what Sasha earlier presented about the predictive clustering framework.",
                    "label": 1
                },
                {
                    "sent": "Then I will present our approach that is based on different definitions of distances and then provide some conclusions and ideas for further work.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as such, over dimensional typically machine learning, we have two two types of tasks, the first one being supervised learning, where we have examples that have labels and these are the tasks classification and regression or are supervised learning where we have just examples without labels and there the goal is to either to perform dimensionality reduction or to cluster these examples into clusters.",
                    "label": 0
                },
                {
                    "sent": "In cases when we have labeled both labeled and unlabeled data, then we have supervised semi supervised learning.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "White why this is relevant?",
                    "label": 0
                },
                {
                    "sent": "This is relevant because labeling can be very expensive and laborious, tedious and tedious work.",
                    "label": 1
                },
                {
                    "sent": "Imagine if you have some of the experiments that Sasha was mentioning about patients.",
                    "label": 0
                },
                {
                    "sent": "Obtaining a label for each patient can be really costly.",
                    "label": 0
                },
                {
                    "sent": "Doing all the tests and all the all the lab work, but having this general background before about the patient is not that difficult to obtain.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "This issue is even more pronounced in the case of structured output prediction, where we have multiple.",
                    "label": 0
                },
                {
                    "sent": "Typically we have multiple labels to obtain.",
                    "label": 0
                },
                {
                    "sent": "I will now briefly mention the tasks that we consider within within this work.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the cycle, the slide that you already seen it, the same supervised classification.",
                    "label": 0
                },
                {
                    "sent": "We have descriptive spaces, equal variables and output variables, and some of the values for the output variables are busy.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Supervisor regression, where the output variable now is a numeric value and again some of its values are missing.",
                    "label": 0
                },
                {
                    "sent": "Then we.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can have semi supervised move to label classification where the labels are provided for some of the examples.",
                    "label": 0
                },
                {
                    "sent": "And again we don't have labels for the other part.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Semi supervised multi target regression with a similar similar property.",
                    "label": 0
                },
                {
                    "sent": "Now how do we approach these tasks?",
                    "label": 0
                },
                {
                    "sent": "Or in general how these tasks can be approached can be.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Urged by either learning global models or local models.",
                    "label": 1
                },
                {
                    "sent": "Global models construct a single model that are valid for the all of the outputs.",
                    "label": 0
                },
                {
                    "sent": "That means I have a single model and I get a prediction for all of the variables.",
                    "label": 0
                },
                {
                    "sent": "The most simple end.",
                    "label": 0
                },
                {
                    "sent": "A trivial approach to both of tracking photos is the local local models paradigm, where I can learn a model for each of the target separately.",
                    "label": 1
                },
                {
                    "sent": "At the end, however, learning local models can often be.",
                    "label": 0
                },
                {
                    "sent": "Infeasible.",
                    "label": 0
                },
                {
                    "sent": "Easily we have domains with hundreds or even thousands of labels, so constructing thousands and thousands of predictive models sometimes is really expensive.",
                    "label": 0
                },
                {
                    "sent": "Moreover, global models are able to catch the interesting dependencies that may exist between the different labels between the different targets.",
                    "label": 0
                },
                {
                    "sent": "These elite to smoothing the prediction function and avoid large discrete to discontinue discontinue.",
                    "label": 1
                },
                {
                    "sent": "It is in that in the in the prediction function.",
                    "label": 0
                },
                {
                    "sent": "We have studies performance studies that show that constructed constructive global models leads to better predictive performance.",
                    "label": 1
                },
                {
                    "sent": "Computationally are more efficient.",
                    "label": 0
                },
                {
                    "sent": "The models are simpler and they tend to overfit less than the local models.",
                    "label": 0
                },
                {
                    "sent": "Now, within the same supervised learning.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We heavily exploit the smoothness of the prediction function assumption.",
                    "label": 1
                },
                {
                    "sent": "What do we mean when we say smoothness of the prediction function?",
                    "label": 0
                },
                {
                    "sent": "Consider the example given below.",
                    "label": 1
                },
                {
                    "sent": "The X is marked the labeled data, the dots map unlabeled data are making.",
                    "label": 0
                },
                {
                    "sent": "Assumption is that if 2 examples are closed in a dense region, then their prediction must be closed also.",
                    "label": 0
                },
                {
                    "sent": "A day.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alarm.",
                    "label": 0
                },
                {
                    "sent": "Several approaches that that.",
                    "label": 0
                },
                {
                    "sent": "The tackle this issue, but mainly they are focused on the tasks of simple classification.",
                    "label": 0
                },
                {
                    "sent": "There are already some works that do semi supervised regression, but even rarer are works that do semisupervised learning for structured output prediction.",
                    "label": 0
                },
                {
                    "sent": "Typically there are a couple of methods that are based on kernel learning and then there are graph based methods for setting supervised learning and some other sporadic attempts to approach this task, but the.",
                    "label": 0
                },
                {
                    "sent": "A severe limitations in several aspects.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First of all, they have high computational costs.",
                    "label": 1
                },
                {
                    "sent": "This is even more pronounced in domains with large number, number of examples and domains with large number of output labels.",
                    "label": 0
                },
                {
                    "sent": "That is, if you have 1000 of.",
                    "label": 0
                },
                {
                    "sent": "Target variables over 10s of thousands of examples.",
                    "label": 0
                },
                {
                    "sent": "This can lead to intractable solutions.",
                    "label": 0
                },
                {
                    "sent": "The next the next issue is the interpretability of the obtained models.",
                    "label": 0
                },
                {
                    "sent": "All of the methods that I mentioned earlier are not interpretable by a domain expert.",
                    "label": 0
                },
                {
                    "sent": "They can only see the predictions and assess the quality of the predictions, but not assess the model and its relation to the knowledge about the domain.",
                    "label": 0
                },
                {
                    "sent": "Next, all of these focus on a specific type of output.",
                    "label": 1
                },
                {
                    "sent": "If you have some savings supervised learning method, it is either tailored for multi label classification or tailored for predicting multiple numeric variables or learning sequences.",
                    "label": 0
                },
                {
                    "sent": "And finally the evaluation of these methods is even more focused, and it's typically focused on a single domain.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can have semi supervised learning for hierarchical.",
                    "label": 0
                },
                {
                    "sent": "Older label classification for text documents and that is the only domain where this approach is being evaluated within my.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extra we strive to address all of these shortcomings of the existing approaches, and we built upon the predicted clustering framework.",
                    "label": 0
                },
                {
                    "sent": "This framework was shown to be effective, efficient.",
                    "label": 0
                },
                {
                    "sent": "Into solving a variety of structured output prediction tasks and we are able to obtain predictive models with state of the art predicting performance.",
                    "label": 0
                },
                {
                    "sent": "Now, briefly.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will you straight part is what we mean when we say predictive clustering and I will just.",
                    "label": 1
                },
                {
                    "sent": "Even repeat some of the.",
                    "label": 0
                },
                {
                    "sent": "Some of the work, some of the slides social said, but I will be a bit more technical so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This figure illustrates.",
                    "label": 0
                },
                {
                    "sent": "The advantage of predictive clustering.",
                    "label": 1
                },
                {
                    "sent": "We have three graphs on each of the graphs on the X axis we have the descriptive space and on the Y axis we have the target space.",
                    "label": 0
                },
                {
                    "sent": "If we see this problem from the point of view of predictive modeling, that means that we're only focused in the target space, and we're able to identify two clusters of data.",
                    "label": 0
                },
                {
                    "sent": "If we see this problem from a clustering perspective, that means we're only focusing on the descriptive space.",
                    "label": 0
                },
                {
                    "sent": "We identify these two clusters of data.",
                    "label": 0
                },
                {
                    "sent": "But within effective clustering, since we're able to look both at the descriptive and the target space, we are able to identify these three clusters of data, and this is the main advantage that we have, and this is the main adventure that we exploit in our method.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The method that we use this is based on the predictive clustering.",
                    "label": 0
                },
                {
                    "sent": "Please and Sasha said this is.",
                    "label": 0
                },
                {
                    "sent": "These are ordinary trees with the two little tricks.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first one key definition of variance function that is tailored for a specific task and also definition of a specific program type function that is tailored for a specific task.",
                    "label": 0
                },
                {
                    "sent": "We have extended.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Random.",
                    "label": 0
                },
                {
                    "sent": "The variance of product by functions for several different tasks.",
                    "label": 0
                },
                {
                    "sent": "And here I just mentioned these four tasks, the first one being moved to target regression, where we use the.",
                    "label": 0
                },
                {
                    "sent": "The body of the where the prototype is calculated as the average of the values and variances.",
                    "label": 0
                },
                {
                    "sent": "Some of the variances to pull the target.",
                    "label": 0
                },
                {
                    "sent": "Then we have multivalued classification multi label classification.",
                    "label": 0
                },
                {
                    "sent": "Whereas default we used some of the gene.",
                    "label": 0
                },
                {
                    "sent": "This is per label and then for hierarchical multi label classification the prototype is averaging.",
                    "label": 0
                },
                {
                    "sent": "With applying a threshold for selecting class membership and obtaining and obeying the hierarchical constraint.",
                    "label": 1
                },
                {
                    "sent": "And the variance is based on a weighted Euclidean distance which is aware about the structure of the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I will.",
                    "label": 0
                },
                {
                    "sent": "I will explain what what we what we did and what.",
                    "label": 0
                },
                {
                    "sent": "And how we improved or the primitive clustering framework?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an example of a predicted clustering tree.",
                    "label": 0
                },
                {
                    "sent": "This is multi target regression tree.",
                    "label": 0
                },
                {
                    "sent": "Actually this domain is predicting the abundance of.",
                    "label": 0
                },
                {
                    "sent": "Of the items in Lake Prespa, the notes include chemical parameters.",
                    "label": 0
                },
                {
                    "sent": "Beliefs include values of number of items that were involved encountered under these specific conditions.",
                    "label": 0
                },
                {
                    "sent": "Space on the other side of the mountain.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, as I said, the goal is to maximize the variance reduction and the maximization of the balance reduction is illustrated with this heuristic score that is given here.",
                    "label": 0
                },
                {
                    "sent": "Here we have the variance of the parent node, for instance here and then subtracted the variances in the children nodes.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do this for each of the targets and then we get the overall variance, so this is relatively straightforward, no?",
                    "label": 1
                },
                {
                    "sent": "No big tricks here, because this is only calculated in the target space, so this is completely predictive setting.",
                    "label": 1
                },
                {
                    "sent": "What we do now.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alice.",
                    "label": 0
                },
                {
                    "sent": "We move this to the same supervised context and we extend these various by including a term that refers to the descriptive space.",
                    "label": 0
                },
                {
                    "sent": "So these are the variances in the descriptive space.",
                    "label": 0
                },
                {
                    "sent": "Moreover, we introduced a parameter W that controls the amount of supervision.",
                    "label": 0
                },
                {
                    "sent": "What do we mean when we say by supervision we say we mean the influence of the target space that has to be overall heuristic score calculation.",
                    "label": 0
                },
                {
                    "sent": "If you select this W closer to 1, this means that we rely more on the target space.",
                    "label": 0
                },
                {
                    "sent": "If we select if we select W closer to zero, that means that we rely more on the descriptive space of the data.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "And electively easier to see for the numeric case when we have only numeric variables.",
                    "label": 0
                },
                {
                    "sent": "But we have also discrete variable.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Present then this is extended as follows.",
                    "label": 0
                },
                {
                    "sent": "We again have the input the output space and the input space.",
                    "label": 0
                },
                {
                    "sent": "We again have the parameter for controlling the level of supervision.",
                    "label": 0
                },
                {
                    "sent": "And the influence of the made variables and the.",
                    "label": 0
                },
                {
                    "sent": "And the discrete variables is shown here, however.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we can be potentially making a big mistake by mixing apples and oranges because the distances used in these two cases might be on different scales.",
                    "label": 1
                },
                {
                    "sent": "Different properties, and it's not that easy just to add them up and and.",
                    "label": 0
                },
                {
                    "sent": "And calculate the heuristic value.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To this end, we normalize them, bring them to the same scale so they.",
                    "label": 0
                },
                {
                    "sent": "Approximately measure the same, the same same thing.",
                    "label": 0
                },
                {
                    "sent": "Now to be more graphic and to use it, what?",
                    "label": 0
                },
                {
                    "sent": "What actually we're doing?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let us look at this example that illustrates the same supervised learning problem.",
                    "label": 0
                },
                {
                    "sent": "The green axis are the values of the target variables.",
                    "label": 0
                },
                {
                    "sent": "And these are the only labeled examples that we know.",
                    "label": 0
                },
                {
                    "sent": "And the dots are.",
                    "label": 0
                },
                {
                    "sent": "Table so on the X axis we have descriptive on the Y axis we have the target space similarly as the previous example, if we consider a supervised learning algorithm that supervised learning algorithm will consider only the target space and we will find this line here as the ideal for split.",
                    "label": 0
                },
                {
                    "sent": "For splitting the examples into two clusters.",
                    "label": 0
                },
                {
                    "sent": "So these two clusters are.",
                    "label": 0
                },
                {
                    "sent": "Oh the top three examples.",
                    "label": 0
                },
                {
                    "sent": "And then the the lower 4 examples on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "Just to clarify, the access is enabled able.",
                    "label": 0
                },
                {
                    "sent": "The big access the peak accesses the label data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the X is the.",
                    "label": 0
                },
                {
                    "sent": "Discrete accesses the labels.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "All and this these are projections in the target space and projections in the input space.",
                    "label": 1
                },
                {
                    "sent": "The unlabeled data, on the other hand, is given here.",
                    "label": 0
                },
                {
                    "sent": "The dogs and these are.",
                    "label": 0
                },
                {
                    "sent": "This is the distribution of the unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "And now if you have same supervised learning as I showed earlier, the same is supervised learning predefined two splits.",
                    "label": 0
                },
                {
                    "sent": "These are the red, the red lines here.",
                    "label": 0
                },
                {
                    "sent": "That means the same supervised learning algorithm decided to divide this data into three clusters.",
                    "label": 0
                },
                {
                    "sent": "Log into two clusters.",
                    "label": 0
                },
                {
                    "sent": "What happens more specifically here is.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If I reveal the true labels of the unlabeled data that we had in the first example.",
                    "label": 0
                },
                {
                    "sent": "They are distributed as shown here.",
                    "label": 0
                },
                {
                    "sent": "So again, we have this values of that in the target space.",
                    "label": 1
                },
                {
                    "sent": "That are projected here, we see that.",
                    "label": 0
                },
                {
                    "sent": "And we have the prediction function for the from the supervised model given with the blue blue line and then the prediction function from the same supervised learning with given with the red dots, we see that the model that we have with semi supervised learning is far far better than the one in the supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Just as an illustration, these are real numbers, so this example is was really run using our algorithm.",
                    "label": 0
                },
                {
                    "sent": "The mean squared error for the supervised method was zero point 5 four and for the same supervised was 0.09.",
                    "label": 0
                },
                {
                    "sent": "So we're after this.",
                    "label": 0
                },
                {
                    "sent": "This type of improvements that that.",
                    "label": 0
                },
                {
                    "sent": "But the that can that can be extracted from the data.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Within our work, we focused on four different extensions of the same supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Predicted class increase.",
                    "label": 0
                },
                {
                    "sent": "The first one being moved to target regression.",
                    "label": 0
                },
                {
                    "sent": "So we started with the multiplication because the definitions of distances here is more clear.",
                    "label": 0
                },
                {
                    "sent": "It's not that complicated and then we move to these three different types of classification tasks.",
                    "label": 0
                },
                {
                    "sent": "Enmu.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Target regression we used to.",
                    "label": 0
                },
                {
                    "sent": "We used simple variance calculation function which is.",
                    "label": 0
                },
                {
                    "sent": "Which is shown on the slide.",
                    "label": 0
                },
                {
                    "sent": "However, here we calculate the variance only on the examples with known labels with no value.",
                    "label": 1
                },
                {
                    "sent": "If we have missing values, then it's.",
                    "label": 1
                },
                {
                    "sent": "The missing values for that given attribute do not influence on its variance score, but what happens?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You could give.",
                    "label": 0
                },
                {
                    "sent": "Examples that have none that have all of the values missing.",
                    "label": 0
                },
                {
                    "sent": "Easily it can happen in the cases when we have selected.",
                    "label": 0
                },
                {
                    "sent": "It usually happens when we select the W parameter to be closer to zero, that means.",
                    "label": 0
                },
                {
                    "sent": "That means.",
                    "label": 0
                },
                {
                    "sent": "Less and less supervision.",
                    "label": 0
                },
                {
                    "sent": "This means that we have leaves of industry where all of the examples have no label, and then how can we make a prediction for relief with examples with no labels?",
                    "label": 0
                },
                {
                    "sent": "To answer this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We tested three variants and the first one is to be used as variance estimate for that lift.",
                    "label": 0
                },
                {
                    "sent": "The various in the parent node and this is some somewhat a compromise solution because they this means that for this life we only exploit the information that we know best to that point in the model construction II approaches, we estimate this variance with the virus of the whole training set.",
                    "label": 1
                },
                {
                    "sent": "Now consider that the variance of the whole training set is.",
                    "label": 0
                },
                {
                    "sent": "The larger this will lead in turn to smaller trees.",
                    "label": 0
                },
                {
                    "sent": "And the other extremists simply ignore these attributes.",
                    "label": 0
                },
                {
                    "sent": "Then this will allow that reconstruction to build even larger trees.",
                    "label": 0
                },
                {
                    "sent": "We tested all these variables.",
                    "label": 0
                },
                {
                    "sent": "All these solutions and also we.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We encountered another issue is when when we're used, mixing descriptive and the target space.",
                    "label": 0
                },
                {
                    "sent": "Typically the descriptive space is very large, it can overcome its influence and then you have.",
                    "label": 0
                },
                {
                    "sent": "You can have redundant variables in the descriptive space and this can hurt the overall performance of the end.",
                    "label": 0
                },
                {
                    "sent": "To cope with that, we further extend the definition of the variance reduction by including this Sigma wait here.",
                    "label": 0
                },
                {
                    "sent": "Which is actually the future elements for that given activity.",
                    "label": 0
                },
                {
                    "sent": "So All in all.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have 6 variants of same supervised predicted clustering trees.",
                    "label": 1
                },
                {
                    "sent": "That means 3.",
                    "label": 0
                },
                {
                    "sent": "The three cases, the three extreme cases that that that I mentioned times whether we use or not feature ranking.",
                    "label": 0
                },
                {
                    "sent": "So in total six we perform we performed experimental evaluation on 10 benchmarking.",
                    "label": 1
                },
                {
                    "sent": "Pull the target regression datasets and we compare the performance of service supervised the cities to a standard supervised PCP that is learned on the same amount of labeled data.",
                    "label": 1
                },
                {
                    "sent": "And a supervised counterpart of Semi supervised visit is is.",
                    "label": 1
                },
                {
                    "sent": "Is this the same algorithm but without exploiting the unlabeled data, just the label data?",
                    "label": 0
                },
                {
                    "sent": "Also, we conduct two different sets of experiments.",
                    "label": 0
                },
                {
                    "sent": "In the first one, we consider absolute number of labeled examples.",
                    "label": 0
                },
                {
                    "sent": "That is, we have 25 labeled examples 51120 and in the second case we use a relative number of labeled examples in each of the experiments as to the size of the domain that we're looking.",
                    "label": 0
                },
                {
                    "sent": "The first, the first approach, the use of the absolute.",
                    "label": 0
                },
                {
                    "sent": "Absolute value is actually.",
                    "label": 0
                },
                {
                    "sent": "Closer to the real applications because typically if you have an expert he has an amount of labeled data 5100 and the size of domains of the potential potential domain is unknown.",
                    "label": 0
                },
                {
                    "sent": "You cannot.",
                    "label": 0
                },
                {
                    "sent": "You cannot always know the number of unlabeled data available.",
                    "label": 1
                },
                {
                    "sent": "The evaluation is done in the transductive learning scenario.",
                    "label": 0
                },
                {
                    "sent": "That means that the goal is to obtain predictions for the unlabeled part of the data and to avoid.",
                    "label": 1
                },
                {
                    "sent": "Alleviate the influence of the random selections in the label data in the division of the data into labeled and unlabeled.",
                    "label": 0
                },
                {
                    "sent": "We repeated all the experiments 10 times with different random initializations.",
                    "label": 0
                },
                {
                    "sent": "Briefly, I will explain I will give the results.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Perform.",
                    "label": 0
                },
                {
                    "sent": "We show that every track diagrams these are these four average run diagrams for each of the amount of labeled data that we consider this.",
                    "label": 0
                },
                {
                    "sent": "These diagrams show the relative performance of the proposed method and there they are read as follows.",
                    "label": 0
                },
                {
                    "sent": "It's an axis from one to six because we have six methods.",
                    "label": 0
                },
                {
                    "sent": "One being closer to 1, being better closer to fix mean mean.",
                    "label": 0
                },
                {
                    "sent": "Worse, and we can see all over all of the.",
                    "label": 0
                },
                {
                    "sent": "For this 4 settings.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using the estimates from the parent note seems to be overall the best solution.",
                    "label": 0
                },
                {
                    "sent": "The most acceptable solution?",
                    "label": 0
                },
                {
                    "sent": "And we know that in this case feature rating does not help much.",
                    "label": 0
                },
                {
                    "sent": "While if we move to the.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relative number of labeled examples.",
                    "label": 0
                },
                {
                    "sent": "Again, we have the same average diagram.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We see that if we ignore if you apply feature ranking helps but and also in this case if we ignore this.",
                    "label": 0
                },
                {
                    "sent": "Uh, if you ignore the examples with missing with not missing with.",
                    "label": 0
                },
                {
                    "sent": "If you ignore the examples that have all of the values missing attributes with all of the values missing, that is the most stringent condition we get.",
                    "label": 0
                },
                {
                    "sent": "Somewhat maybe the best result.",
                    "label": 0
                },
                {
                    "sent": "This is true.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "State what happens in the graphs.",
                    "label": 0
                },
                {
                    "sent": "These are four graphs where we showed that same in supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Helps a lot on the X axis.",
                    "label": 1
                },
                {
                    "sent": "We have the number of labeled examples on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "We have the performance measure and we see that same as supervised learning is especially beneficial in cases where the number of labeled examples is smaller.",
                    "label": 0
                },
                {
                    "sent": "So when we have only small parts of label of labeled data then we are able to achieve.",
                    "label": 0
                },
                {
                    "sent": "Better, better, better predictive performance.",
                    "label": 0
                },
                {
                    "sent": "Is some.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The datasets we are somewhat better and this summer better is around 2550 examples and then we cannot improve much after that answer.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sometimes we we are simply.",
                    "label": 0
                },
                {
                    "sent": "Same as the supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Why is this?",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mainly because of this parameter W that I was mentioning.",
                    "label": 0
                },
                {
                    "sent": "This parameter is very crucial for us because it provides a mechanism to protect our algorithm from degrading performance from the supervised learning.",
                    "label": 1
                },
                {
                    "sent": "In essence, we try several values for this parameter and then with internal proof three fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "We select the optimal.",
                    "label": 0
                },
                {
                    "sent": "Value for the double parameter.",
                    "label": 0
                },
                {
                    "sent": "This prevents form from the degrading the performance of our method just to use.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take this.",
                    "label": 0
                },
                {
                    "sent": "Consider this graph on the X axis.",
                    "label": 0
                },
                {
                    "sent": "We have the number of labeled data and here on the top is the value of this Omega parameter and on the axis on the Y axis is the performance because this is way too please correct error, lower feels better.",
                    "label": 0
                },
                {
                    "sent": "And the amount of supervision moves from left to right.",
                    "label": 0
                },
                {
                    "sent": "So this means fully supervised.",
                    "label": 0
                },
                {
                    "sent": "This needs fully unsupervised.",
                    "label": 0
                },
                {
                    "sent": "This is fully supervised and unsupervised in this.",
                    "label": 0
                },
                {
                    "sent": "For this data set, our algorithm selected to use very little supervision.",
                    "label": 0
                },
                {
                    "sent": "So practically it focused more on the descriptive part and was able to correctly select the best W values that are available.",
                    "label": 0
                },
                {
                    "sent": "In next scenario.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we see very this very nice graph for this different for this.",
                    "label": 0
                },
                {
                    "sent": "Second data set.",
                    "label": 0
                },
                {
                    "sent": "But the selection of formal gates, again very good, and that the most interesting part is that first it is able to find even this small improvements, but here it prevented our algorithm to the grade as you see, the performance of the same is supervised.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second performance with the same supervisor is somewhat worse than the supervised and then it selected just to use the supervised, that is, select W equals one, that means.",
                    "label": 0
                },
                {
                    "sent": "We are not worse than the supervised method.",
                    "label": 0
                },
                {
                    "sent": "Another set of experiments that we performed that we are very happy.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About is the amount of unlabeled data that is pulled into the algorithm.",
                    "label": 1
                },
                {
                    "sent": "Typically you can.",
                    "label": 0
                },
                {
                    "sent": "There are.",
                    "label": 0
                },
                {
                    "sent": "Very well there are several.",
                    "label": 0
                },
                {
                    "sent": "The references from the literature that state oh, because we have the abundance of the unlabeled part, we can exploit all of them and build better models.",
                    "label": 0
                },
                {
                    "sent": "We tried finding the amount of unlabeled data that we used to our algorithm and we see that actually this leads to.",
                    "label": 0
                },
                {
                    "sent": "Do saturation after nearly 1000 examples.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter anymore to have more unlabeled data in terms of predicted performance.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, if we look at the trees that we get at the end, because as you recall, as I said, interpret abilities really important.",
                    "label": 0
                },
                {
                    "sent": "Part of the of the tasks that we're looking at.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I was taking a two piece.",
                    "label": 0
                },
                {
                    "sent": "It is obtained on a data set.",
                    "label": 0
                },
                {
                    "sent": "The left one is obtained from using 50 labeled examples, just 50 labeled examples, and it yielded.",
                    "label": 0
                },
                {
                    "sent": "A3 With 9 notes and that estimated to be squared error of zero point 96.",
                    "label": 0
                },
                {
                    "sent": "The best possible treatment in this domain.",
                    "label": 0
                },
                {
                    "sent": "That means use all of the available labeled data.",
                    "label": 0
                },
                {
                    "sent": "Is we basically spent error of 0.51 and but it is enormous.",
                    "label": 0
                },
                {
                    "sent": "So if this is non non interpretable for domain extent, the decision that the pieces that we obtained is.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very nice compromise between these two.",
                    "label": 0
                },
                {
                    "sent": "It has 23 nodes.",
                    "label": 0
                },
                {
                    "sent": "This is still manageable by a domain expert or domain expert.",
                    "label": 0
                },
                {
                    "sent": "Can look at it and draw some conclusions and it gets very good very quickly, squared error.",
                    "label": 0
                },
                {
                    "sent": "It's zero point 71 this is somewhere halfway to the best possible tree.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In summary uh?",
                    "label": 0
                },
                {
                    "sent": "This is for safety.",
                    "label": 0
                },
                {
                    "sent": "Supervised learning in discount for the task of multi target regression.",
                    "label": 1
                },
                {
                    "sent": "They are global and easily interpretable models.",
                    "label": 1
                },
                {
                    "sent": "Can and often improve the predictive performance of supervised by cities?",
                    "label": 0
                },
                {
                    "sent": "And they are most effective in scenarios where the amount of labeled data is severely limited.",
                    "label": 1
                },
                {
                    "sent": "The performance of supervised.",
                    "label": 0
                },
                {
                    "sent": "The performance.",
                    "label": 1
                },
                {
                    "sent": "Of over the performance of saving supervised species seldomly that generates the performance of the supervised the cities.",
                    "label": 0
                },
                {
                    "sent": "Finally we observed performance situation only adding up after adding only 1000 are labeled examples.",
                    "label": 0
                },
                {
                    "sent": "That means we don't need too much unlabeled examples, which in turn means that our methods can be more efficient into obtaining data.",
                    "label": 0
                },
                {
                    "sent": "The best possible models.",
                    "label": 0
                },
                {
                    "sent": "Further",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For which we evaluated our method.",
                    "label": 0
                },
                {
                    "sent": "In a discrete classification, tasks in this and we used 12 binary classification datasets, then multiclass classification datasets and 14 move little fication datasets.",
                    "label": 1
                },
                {
                    "sent": "All of these are downloaded either from UCI, either from open email repository.",
                    "label": 0
                },
                {
                    "sent": "We performed evaluation both as I described earlier in a single three setting, but here we also a special mention.",
                    "label": 0
                },
                {
                    "sent": "We have the freedom to give.",
                    "label": 0
                },
                {
                    "sent": "To learn also examples, we also investigated the possibility of refractive assembles in this setting.",
                    "label": 1
                },
                {
                    "sent": "Explore the influence of different amounts of label data.",
                    "label": 0
                },
                {
                    "sent": "Again, it's pretty much the same experimental setup that we had earlier.",
                    "label": 0
                },
                {
                    "sent": "Do you?",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take the results here on the X axis.",
                    "label": 0
                },
                {
                    "sent": "Again, we have the amount of labeled data, amount of labeled data and on the Y axis is the accuracy.",
                    "label": 0
                },
                {
                    "sent": "So this means more is better.",
                    "label": 0
                },
                {
                    "sent": "And we're comparing.",
                    "label": 0
                },
                {
                    "sent": "First, we're comparing a single positive, the red line over the black line that is, the red line is the same is supervised by city.",
                    "label": 0
                },
                {
                    "sent": "The Black Line is the supervised by city, and we see that in the first case we are able to improve across all the number of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "In the second case, we're not that bad.",
                    "label": 0
                },
                {
                    "sent": "Better than the supervised counterpart, and on the third case.",
                    "label": 0
                },
                {
                    "sent": "All of the methods perform equally well.",
                    "label": 0
                },
                {
                    "sent": "If we focus on the assembles, we see that we we tested three variants of the samples, the first one being supervised random forests, the second one being same as supervised random forests of our facilities, and the third one will be another approach for semi supervised learning that is based on self training.",
                    "label": 0
                },
                {
                    "sent": "And we see that often the same supervised random forests are able to outperform the Super computing methods.",
                    "label": 0
                },
                {
                    "sent": "Now two things are.",
                    "label": 0
                },
                {
                    "sent": "Evident here that.",
                    "label": 0
                },
                {
                    "sent": "If uh based semi supervised the city outperforms the supervised pre city.",
                    "label": 0
                },
                {
                    "sent": "This does not mean that the ensemble counterpart will also keep the same performance advantage.",
                    "label": 0
                },
                {
                    "sent": "Moreover we know that it's difficult to improve the predictive performance in domains where there is already a good predictive performance.",
                    "label": 0
                },
                {
                    "sent": "For instance, here the predictive performance is in the scale of 0.99 zero point 19, and you cannot go much better than that whatever you do.",
                    "label": 0
                },
                {
                    "sent": "We also perform.",
                    "label": 0
                },
                {
                    "sent": "We performed a build up some statistical tests across the datasets that we used to show how to investigate power made it how the methods behave.",
                    "label": 0
                },
                {
                    "sent": "Glasses mean that glasses here mean that the same is supervised.",
                    "label": 0
                },
                {
                    "sent": "Methods are better.",
                    "label": 0
                },
                {
                    "sent": "The bold, bold ones indicate statistically significantly better performance, and we see that.",
                    "label": 0
                },
                {
                    "sent": "All of these are classes.",
                    "label": 0
                },
                {
                    "sent": "That means that the same is supervised method.",
                    "label": 0
                },
                {
                    "sent": "Generally, overall of the datasets and very often in this improvement for statistically significant.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Make the same seem a little positive observations for the multiclass classification datasets.",
                    "label": 1
                },
                {
                    "sent": "Again, we have the same.",
                    "label": 0
                },
                {
                    "sent": "Graphs and.",
                    "label": 0
                },
                {
                    "sent": "The conclusions are very similar, with the notion that he.",
                    "label": 0
                },
                {
                    "sent": "That here we can also investigate other different Maia evaluation measures, and we can have more complex scenarios.",
                    "label": 0
                },
                {
                    "sent": "The focus on the on the elect interpret interpret ability.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You stated this with the following models.",
                    "label": 0
                },
                {
                    "sent": "We have two facilities.",
                    "label": 0
                },
                {
                    "sent": "The left one is constructed using 100 label examples in a supervised way.",
                    "label": 0
                },
                {
                    "sent": "This produced three with 17 nodes and accuracy of 69%.",
                    "label": 0
                },
                {
                    "sent": "Our method was able to obtain slightly smaller three with 50 nodes or one split less and the accuracy was 72%.",
                    "label": 0
                },
                {
                    "sent": "If we.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at the same example for multiclass classification, again on the left hand side we have the supervised PCT.",
                    "label": 0
                },
                {
                    "sent": "Here we have supervised visits with 11 modes and accuracy of 81%.",
                    "label": 0
                },
                {
                    "sent": "The same is supervised.",
                    "label": 0
                },
                {
                    "sent": "However, has accuracy of 92%, which is a slightly smaller and this improvement is very significant and very.",
                    "label": 0
                },
                {
                    "sent": "Very significant.",
                    "label": 0
                },
                {
                    "sent": "What are?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean key points here.",
                    "label": 0
                },
                {
                    "sent": "We observe that the improvement does not usually saturate with the increase of the amount of the label.",
                    "label": 1
                },
                {
                    "sent": "Examples that we kept again, which may indicate that we need to consider even larger amounts of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "Why is this important?",
                    "label": 0
                },
                {
                    "sent": "Is important because this is behavior that we observed in the multi target regression case and not here.",
                    "label": 1
                },
                {
                    "sent": "Semi supervised learning does not help for domains where we are able to learn very good models, which is somewhat logical and expected.",
                    "label": 0
                },
                {
                    "sent": "The performance increase that we obtain in your place predicted models does not carry over into the ensemble setting.",
                    "label": 1
                },
                {
                    "sent": "And we were able to obtain smaller, interpretable models that have better objective performance.",
                    "label": 0
                },
                {
                    "sent": "Finally.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will just briefly.",
                    "label": 0
                },
                {
                    "sent": "The show the results that we got from us for semi supervised multilabel classification.",
                    "label": 0
                },
                {
                    "sent": "So we still haven't fully explored this setting because of of the complexity that it entails.",
                    "label": 0
                },
                {
                    "sent": "The complexities?",
                    "label": 0
                },
                {
                    "sent": "Made many, many coming from the different possibilities of definitions of distance functions and evaluation functions, and this is not easy to address and tackle, so this is just to say how many different evaluation functions we can have an optimized.",
                    "label": 0
                },
                {
                    "sent": "We tried on couple of data.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sense and these are the results.",
                    "label": 0
                },
                {
                    "sent": "Did the results are?",
                    "label": 0
                },
                {
                    "sent": "Validated using Hamming loss as loss function as a revelation fashion and then on the X axis we again we have the number of tables.",
                    "label": 0
                },
                {
                    "sent": "Examples here, less is better and we see that the same is supervised by cities, are able to improve over the supervised counterparts, but this this comparison needs to be done in a much more multi dimensional method.",
                    "label": 0
                },
                {
                    "sent": "Wait, we will save the performances in different measures and to try different distance functions for.",
                    "label": 0
                },
                {
                    "sent": "For constructing the trees.",
                    "label": 0
                },
                {
                    "sent": "Finally.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will conclude by.",
                    "label": 0
                },
                {
                    "sent": "Saying that we developed global methods for saving supervised learning that are flexible and able to address several tasks.",
                    "label": 0
                },
                {
                    "sent": "We show that we can improve the performance of supervised predicted clustering trees, especially in domains where the availability of labeled examples is limited.",
                    "label": 1
                },
                {
                    "sent": "The performance of our supervisor, primitive clustering trees seldomly generates over the performance of supervised predictive clustering trees and as you stated on on this couple of examples, to obtain models are easy.",
                    "label": 1
                },
                {
                    "sent": "Interpreted by a domain expert.",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where we will pursue this this topic further.",
                    "label": 0
                },
                {
                    "sent": "First, we will consider additional tasks.",
                    "label": 1
                },
                {
                    "sent": "We will consider the task of hierarchical multi label classification in the task of Time series prediction.",
                    "label": 0
                },
                {
                    "sent": "Why we will leave this as one of the last steps?",
                    "label": 0
                },
                {
                    "sent": "We will never please because of the complexity of the distances in this for this specific tasks, it is not that trivial to device variance functions for this specific specific cases.",
                    "label": 0
                },
                {
                    "sent": "A special dimension we can easily now do unsupervised learning for data with mixed variable types we can easily employ the same variance function and just calculate calculate the variance deductions and then we can have a really nice.",
                    "label": 0
                },
                {
                    "sent": "Really nice property, that is, we are able to learn models from partially labeled data.",
                    "label": 1
                },
                {
                    "sent": "That means that data where the labels are incomplete and the order they have two small case studies.",
                    "label": 1
                },
                {
                    "sent": "Phone in this setting, the first one being for qsar modeling of compounds, and the second one is.",
                    "label": 0
                },
                {
                    "sent": "Spell function modeling, and finally this.",
                    "label": 0
                },
                {
                    "sent": "This algorithm actually enables us to perform feature ranking in a variety of settings.",
                    "label": 0
                },
                {
                    "sent": "So now we are able to use this algorithm to do feature ranking for a supervised learning feature ranking for semi supervised feature ranking for partially and we addressed this line of complexity within my extra.",
                    "label": 0
                },
                {
                    "sent": "So with that I'll thank you.",
                    "label": 0
                }
            ]
        }
    }
}