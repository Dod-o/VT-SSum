{
    "id": "6tyv6rup6za52ft374cylhldnoqziwfi",
    "title": "Shape Sharing for Object Segmentation",
    "info": {
        "author": [
            "Jaechul Kim, Department of Computer Science, University of Texas at Austin"
        ],
        "chairman": [
            "Tinne Tuytelaars, Faculty of Engineering, KU Leuven",
            "Serge J. Belongie, University of California, San Diego"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Shape Analysis"
        ]
    },
    "url": "http://videolectures.net/eccv2012_kim_shape/",
    "segmentation": [
        [
            "Hi, my name is Chester from University of Texas at Austin TC joint work with my advisor Christine."
        ],
        [
            "Amen.",
            "In this talk I'll address the category independent object segmentation problem.",
            "That means we're not delineates objects from the images, regardless of their object categories."
        ],
        [
            "There's a lot of previous works for object segmentation, and most of them can be clustered into 2 extreme ends of the spectrum.",
            "Bottom Up in class specific.",
            "Bottom approaches use only appearance cues like color or textures for segment images, without assuming any top down category specific prior knowledge on the objects so they can be applied to any generic categories.",
            "However, their lack of top down shape knowledge will top down knowledge on the object make it very hard to capture the true object boundaries.",
            "On the other hand, cross special approach can prevent the over or under segmentation problem by typical appearance based approaches by bringing some top down knowledge, mostly top down shape cues into the bottom appearance cues.",
            "However, their top down shape model, mostly the people in specific and they require some prior knowledge on the object to bring such a top down model so they have limited application.",
            "So at this point, the natural question to ask is how about taking only good points from both point both sides?",
            "That is, we only use top down shape Q without assuming any category specific prior knowledge on the objects.",
            "However, at first glance those two goals top down an categories independent seems to be in conflict.",
            "So key question in our work is how to resolve those two seemingly conflicting goal from both approaches.",
            "Traders discussion we proposed."
        ],
        [
            "Keep sharing idea.",
            "Cheap shooting means object shapes are shared among different categories.",
            "One could easily imagine that the shapes are shared among semantically very close classes like Pickles or animals, but they also told that the shapes are shared among semantical ability from classes like person and Bhutto shown in this example.",
            "We also use this shape sharing phenomenon to transfer a shape from one class to possibly on another class.",
            "We don't assuming any category specific prior knowledge on the object.",
            "Thus, the key technical question about the ship shooting would be how to ID."
        ],
        [
            "Apply and transport the shared shape between images to dissent.",
            "We propose a nonparametric partial shame matching method.",
            "So keep an example and test image where example has a ground to subject annotation.",
            "We first identify strong partial chain matching between test and example and transfer the ground truth object invasion in the test image to the example image to the test image.",
            "Without assuming any category specific prior knowledge on the object, here we can see that the shape of Bolt actually shared with the shape of person and we did not assume any category specific prior knowledge on those objects."
        ],
        [
            "Now I'll define our technical details.",
            "Our method consists of three major steps and the first step is shape projection."
        ],
        [
            "So given test image.",
            "We first extract the local shapes."
        ],
        [
            "To extract this local shapes from the image, we use a boundary preserving localism detector.",
            "The PPL detector PPL detector is designed to capture the distinctive object local shape and provides better repeatability across the image parations compared to other recent detection method like a super pixels.",
            "So we use these PPLS for robust shape matching."
        ],
        [
            "Any extracted same PR from the exam process where example I also has a Crown to subject annotate."
        ],
        [
            "An find swampier matches between testing examples.",
            "For each established PPL matches but by height.",
            "Here we transfer the global ground truth object boundaries in the example to the test image based on the similarity transformer match the PPL by similarity transform.",
            "I mean I use a scale and location of two best PPL regions.",
            "An I repeat the same procedure for every matchup, Euro, finally obtaining multiple shape hypothesis on the objects in the test image."
        ],
        [
            "However.",
            "All of the shape projections are not exactly online with the bottom of image controls due to some noise in matching or.",
            "Deformation between different categories.",
            "So we want to align this projected control into the bottom of image control, where we represented this bottom contours by super pixels marked by blue.",
            "Here to align we use the jigsaw of super pixel technique by check.",
            "So I mean I can merge the Super pixels whose majority of pixels are included in the overall projection regions as shown in this example by Jigsaw.",
            "We can snap the projected control into the bottom of control while preserving the original shape as much as possible."
        ],
        [
            "Now I go into the second step.",
            "The second step is aggregation.",
            "So given multiple shape projections from PPR matches.",
            "We group those shape projections that are highly over each other.",
            "The purpose of this aggregation step is to.",
            "Integrate the partial chain matching information from different examples.",
            "For example, in this Red Group.",
            "You can see none of the shape projections are not exactly align with the entire object boundary.",
            "However, each of them provides very reliable partial shade matching to the object parts like Head Valley back.",
            "So we are combined those reliable partial matching information to enhance the quality of shape estimation.",
            "And here again we can see that the shape sharing actually happens from different classes of examples like horse, dog and person.",
            "To estimate the shape of the cat in the test image."
        ],
        [
            "The last step is the segmentation from the previous steps.",
            "The aggregation step.",
            "We obtain multiple groups of shape projections.",
            "And for each group shape projections.",
            "We build a segmentation model that estimates the shape and color of the object predicted by this group.",
            "To this end, we first compute the intersection and Union Objet projections and assign higher foreground right glued to the pixels inside the intersection of the two J projections marked by white.",
            "Because all of the projections or grid in this region.",
            "On the other hand, we assign higher background probability to the pixels outside the Union because none of the none of the shape projections are not agreed in this region marked by black and pixels in between them.",
            "Great pixels have no bias, told foreground or background.",
            "When you also estimates the color distribution of the object from by building the foreground and background colors ram from those regions.",
            "This segmentation model is then imported into the collaboration.",
            "Graphical formulation consists of the data term and smooth system.",
            "They don't defines the likelihood of labeling pixels, either foreground or background, and smooth system regularizer solution that prepares the same labeling between nearby pixels.",
            "This is a conventional graphical formulation for object segmentation.",
            "However, what we focus on here is the data term where we define the data term by combining shape and color include estimated from our segmentation model.",
            "By this way.",
            "We effectively encode the global range of shape estimation by our shape prior into the graphic formulation in a very simple form."
        ],
        [
            "Having defined the data term in this way, we finally argument this date and by adding a control parameter that adjust the bias, told foreground or background.",
            "This actually follows very well known multiparametric graphical approach by Karen Smith.",
            "Cisco, the previous previous speaker, the CPM's method.",
            "By pairing this control parameter, we finally obtain a series over multiple figure ground hypothesis on the object of a given group, and we repeat the same procedure for every groups.",
            "So finally obtaining multiple figure ground hypothesis on the objects estimated by all groups of shape projections."
        ],
        [
            "So for experiment.",
            "We take the example database from the past called segmentation training data set and applied it into two different datasets, including the possible segmentation validation data set and Buckley segmentation data set.",
            "We make extensive evaluations using very strong baselines all over each other state of the art.",
            "Multiple segmentation method for generating the object segments.",
            "However, all of these previous method only rely on the bottom of appearance cues.",
            "So what we focus on here is to show the impact of our shape cube by sharing idea compared to these pure bottom up appearance based approaches.",
            "For evaluating the segmentation quality.",
            "We adopt the best covering score by best covering score.",
            "I mean I pick the best segment or more pull over the generator segments that are mostly overlap with the ground truth object.",
            "Annotation at the same time we consider the number of the general segments so higher covering score with less number of the general segments is better under this metric.",
            "This table summarizes the result.",
            "We see that hours."
        ],
        [
            "Performs all the baselines and the canes statically.",
            "Very significant considering the number of huge number of pixels involved in this operation, which I know I want to note.",
            "The result in Berkeley.",
            "Segmentation data set where the test data set the Buckley doesn't share much of the class label with the example Pascal data set.",
            "That means sharing actually happens even when the class labels from example and tests are disjoint.",
            "In the previous slides, we show the impact of shape sharing as in terms of."
        ],
        [
            "Risk or over the entire data set.",
            "However, this every school loan may not fully reveals the impact of shape sharing.",
            "So in this life I wanna show more deeper analysis on when NY shape sharing are actually useful.",
            "To this end, we define it.",
            "Gain of our shape showing over the baseline function as a baseline method as a function of color agents.",
            "An object size.",
            "College is basically means how easily well how accurately we can do the segmentation using only color information we define this color regions in a quantitative way, but I skip the details.",
            "Please refer to the paper if you're interested in.",
            "This graph summarizes the result.",
            "We see that the add color agent is getting low against is increasing.",
            "In fact, at the leftmost point, where the color region is most hardest, organis as much as 15 point, which is really huge in this benchmark.",
            "Also we see that as object sizes getting gross or gains is also increased.",
            "In fact to any removed very small size of objects like which is less than probably 40 by 40 pixels, which is really small, we achieved twice again.",
            "This is very intuitive.",
            "Becausw adds objects, eyes are getting.",
            "Bigger is shapes become more evident and easier to detect."
        ],
        [
            "We also analyzed which classes are actually sharing each other.",
            "This sharing metrics counts how many times example classes are used to generate the best segments for each test class.",
            "As expected, semantically similar classes like animals or vehicles show very strong sharing.",
            "However, we also observed that the semantical very different classes like personal photo show very strong sharing as well.",
            "And Interestingly, symmetrical ability from classes like here, the motorbike and talk.",
            "Sometimes you cover the very unexpected push variations which cannot be seen in the semantically very similar classes."
        ],
        [
            "Finally, I'll show some qualitative example results.",
            "We see that shape showing is very useful when objects consists of heterogeneous color textures.",
            "In the first image, for example, we can't eliminate the person successfully who wears the different colors, overheads closing, and different skin colors.",
            "Also, sharing is useful when object."
        ],
        [
            "Confused by similar surrounding colors.",
            "For example, in the first image with Eliminators so far, single instance of Sofa, Peach is confused by the nearby sofas or similar colors."
        ],
        [
            "This shows some failure cases.",
            "Shape showing sometimes fails when object size is very small like in the first or second image.",
            "Also sharing doesn't work when object doesn't have any shapes like truncated so far in the solid image.",
            "Here in the third image, the target object is super, not dog, so and the sofa is truncated so.",
            "Have no any meaningful outer boundaries."
        ],
        [
            "In conclusion, we propose a shape sharing idea that enables to use top down shape cube without assuming any category specific prior knowledge on the objects.",
            "Thus we can enhance the second segmentation quality or unseen or Noble objects.",
            "Thank you.",
            "How do you decide like the number of groups from one image is automatically determined?",
            "I actually the groups the shape projections that are.",
            "That overlap of the 15% measures.",
            "So when the segments overlap each other more than half of them overlapping score is over, then have by overlapping score I mean the intersection divided by Union.",
            "The typical classical segmentation measure.",
            "In that case we.",
            "The group then in overall motivation, so we do the automotive segmentation based on that metric.",
            "OK, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Chester from University of Texas at Austin TC joint work with my advisor Christine.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Amen.",
                    "label": 0
                },
                {
                    "sent": "In this talk I'll address the category independent object segmentation problem.",
                    "label": 1
                },
                {
                    "sent": "That means we're not delineates objects from the images, regardless of their object categories.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a lot of previous works for object segmentation, and most of them can be clustered into 2 extreme ends of the spectrum.",
                    "label": 0
                },
                {
                    "sent": "Bottom Up in class specific.",
                    "label": 0
                },
                {
                    "sent": "Bottom approaches use only appearance cues like color or textures for segment images, without assuming any top down category specific prior knowledge on the objects so they can be applied to any generic categories.",
                    "label": 0
                },
                {
                    "sent": "However, their lack of top down shape knowledge will top down knowledge on the object make it very hard to capture the true object boundaries.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, cross special approach can prevent the over or under segmentation problem by typical appearance based approaches by bringing some top down knowledge, mostly top down shape cues into the bottom appearance cues.",
                    "label": 0
                },
                {
                    "sent": "However, their top down shape model, mostly the people in specific and they require some prior knowledge on the object to bring such a top down model so they have limited application.",
                    "label": 0
                },
                {
                    "sent": "So at this point, the natural question to ask is how about taking only good points from both point both sides?",
                    "label": 0
                },
                {
                    "sent": "That is, we only use top down shape Q without assuming any category specific prior knowledge on the objects.",
                    "label": 0
                },
                {
                    "sent": "However, at first glance those two goals top down an categories independent seems to be in conflict.",
                    "label": 0
                },
                {
                    "sent": "So key question in our work is how to resolve those two seemingly conflicting goal from both approaches.",
                    "label": 0
                },
                {
                    "sent": "Traders discussion we proposed.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Keep sharing idea.",
                    "label": 0
                },
                {
                    "sent": "Cheap shooting means object shapes are shared among different categories.",
                    "label": 1
                },
                {
                    "sent": "One could easily imagine that the shapes are shared among semantically very close classes like Pickles or animals, but they also told that the shapes are shared among semantical ability from classes like person and Bhutto shown in this example.",
                    "label": 1
                },
                {
                    "sent": "We also use this shape sharing phenomenon to transfer a shape from one class to possibly on another class.",
                    "label": 0
                },
                {
                    "sent": "We don't assuming any category specific prior knowledge on the object.",
                    "label": 0
                },
                {
                    "sent": "Thus, the key technical question about the ship shooting would be how to ID.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apply and transport the shared shape between images to dissent.",
                    "label": 0
                },
                {
                    "sent": "We propose a nonparametric partial shame matching method.",
                    "label": 0
                },
                {
                    "sent": "So keep an example and test image where example has a ground to subject annotation.",
                    "label": 0
                },
                {
                    "sent": "We first identify strong partial chain matching between test and example and transfer the ground truth object invasion in the test image to the example image to the test image.",
                    "label": 1
                },
                {
                    "sent": "Without assuming any category specific prior knowledge on the object, here we can see that the shape of Bolt actually shared with the shape of person and we did not assume any category specific prior knowledge on those objects.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'll define our technical details.",
                    "label": 0
                },
                {
                    "sent": "Our method consists of three major steps and the first step is shape projection.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given test image.",
                    "label": 0
                },
                {
                    "sent": "We first extract the local shapes.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To extract this local shapes from the image, we use a boundary preserving localism detector.",
                    "label": 0
                },
                {
                    "sent": "The PPL detector PPL detector is designed to capture the distinctive object local shape and provides better repeatability across the image parations compared to other recent detection method like a super pixels.",
                    "label": 0
                },
                {
                    "sent": "So we use these PPLS for robust shape matching.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any extracted same PR from the exam process where example I also has a Crown to subject annotate.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An find swampier matches between testing examples.",
                    "label": 0
                },
                {
                    "sent": "For each established PPL matches but by height.",
                    "label": 0
                },
                {
                    "sent": "Here we transfer the global ground truth object boundaries in the example to the test image based on the similarity transformer match the PPL by similarity transform.",
                    "label": 1
                },
                {
                    "sent": "I mean I use a scale and location of two best PPL regions.",
                    "label": 0
                },
                {
                    "sent": "An I repeat the same procedure for every matchup, Euro, finally obtaining multiple shape hypothesis on the objects in the test image.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "All of the shape projections are not exactly online with the bottom of image controls due to some noise in matching or.",
                    "label": 0
                },
                {
                    "sent": "Deformation between different categories.",
                    "label": 0
                },
                {
                    "sent": "So we want to align this projected control into the bottom of image control, where we represented this bottom contours by super pixels marked by blue.",
                    "label": 0
                },
                {
                    "sent": "Here to align we use the jigsaw of super pixel technique by check.",
                    "label": 0
                },
                {
                    "sent": "So I mean I can merge the Super pixels whose majority of pixels are included in the overall projection regions as shown in this example by Jigsaw.",
                    "label": 1
                },
                {
                    "sent": "We can snap the projected control into the bottom of control while preserving the original shape as much as possible.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I go into the second step.",
                    "label": 0
                },
                {
                    "sent": "The second step is aggregation.",
                    "label": 0
                },
                {
                    "sent": "So given multiple shape projections from PPR matches.",
                    "label": 0
                },
                {
                    "sent": "We group those shape projections that are highly over each other.",
                    "label": 0
                },
                {
                    "sent": "The purpose of this aggregation step is to.",
                    "label": 0
                },
                {
                    "sent": "Integrate the partial chain matching information from different examples.",
                    "label": 0
                },
                {
                    "sent": "For example, in this Red Group.",
                    "label": 0
                },
                {
                    "sent": "You can see none of the shape projections are not exactly align with the entire object boundary.",
                    "label": 0
                },
                {
                    "sent": "However, each of them provides very reliable partial shade matching to the object parts like Head Valley back.",
                    "label": 0
                },
                {
                    "sent": "So we are combined those reliable partial matching information to enhance the quality of shape estimation.",
                    "label": 0
                },
                {
                    "sent": "And here again we can see that the shape sharing actually happens from different classes of examples like horse, dog and person.",
                    "label": 0
                },
                {
                    "sent": "To estimate the shape of the cat in the test image.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last step is the segmentation from the previous steps.",
                    "label": 0
                },
                {
                    "sent": "The aggregation step.",
                    "label": 0
                },
                {
                    "sent": "We obtain multiple groups of shape projections.",
                    "label": 0
                },
                {
                    "sent": "And for each group shape projections.",
                    "label": 0
                },
                {
                    "sent": "We build a segmentation model that estimates the shape and color of the object predicted by this group.",
                    "label": 0
                },
                {
                    "sent": "To this end, we first compute the intersection and Union Objet projections and assign higher foreground right glued to the pixels inside the intersection of the two J projections marked by white.",
                    "label": 0
                },
                {
                    "sent": "Because all of the projections or grid in this region.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we assign higher background probability to the pixels outside the Union because none of the none of the shape projections are not agreed in this region marked by black and pixels in between them.",
                    "label": 0
                },
                {
                    "sent": "Great pixels have no bias, told foreground or background.",
                    "label": 0
                },
                {
                    "sent": "When you also estimates the color distribution of the object from by building the foreground and background colors ram from those regions.",
                    "label": 0
                },
                {
                    "sent": "This segmentation model is then imported into the collaboration.",
                    "label": 0
                },
                {
                    "sent": "Graphical formulation consists of the data term and smooth system.",
                    "label": 1
                },
                {
                    "sent": "They don't defines the likelihood of labeling pixels, either foreground or background, and smooth system regularizer solution that prepares the same labeling between nearby pixels.",
                    "label": 0
                },
                {
                    "sent": "This is a conventional graphical formulation for object segmentation.",
                    "label": 0
                },
                {
                    "sent": "However, what we focus on here is the data term where we define the data term by combining shape and color include estimated from our segmentation model.",
                    "label": 0
                },
                {
                    "sent": "By this way.",
                    "label": 0
                },
                {
                    "sent": "We effectively encode the global range of shape estimation by our shape prior into the graphic formulation in a very simple form.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Having defined the data term in this way, we finally argument this date and by adding a control parameter that adjust the bias, told foreground or background.",
                    "label": 0
                },
                {
                    "sent": "This actually follows very well known multiparametric graphical approach by Karen Smith.",
                    "label": 0
                },
                {
                    "sent": "Cisco, the previous previous speaker, the CPM's method.",
                    "label": 0
                },
                {
                    "sent": "By pairing this control parameter, we finally obtain a series over multiple figure ground hypothesis on the object of a given group, and we repeat the same procedure for every groups.",
                    "label": 0
                },
                {
                    "sent": "So finally obtaining multiple figure ground hypothesis on the objects estimated by all groups of shape projections.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for experiment.",
                    "label": 0
                },
                {
                    "sent": "We take the example database from the past called segmentation training data set and applied it into two different datasets, including the possible segmentation validation data set and Buckley segmentation data set.",
                    "label": 0
                },
                {
                    "sent": "We make extensive evaluations using very strong baselines all over each other state of the art.",
                    "label": 0
                },
                {
                    "sent": "Multiple segmentation method for generating the object segments.",
                    "label": 0
                },
                {
                    "sent": "However, all of these previous method only rely on the bottom of appearance cues.",
                    "label": 0
                },
                {
                    "sent": "So what we focus on here is to show the impact of our shape cube by sharing idea compared to these pure bottom up appearance based approaches.",
                    "label": 0
                },
                {
                    "sent": "For evaluating the segmentation quality.",
                    "label": 0
                },
                {
                    "sent": "We adopt the best covering score by best covering score.",
                    "label": 1
                },
                {
                    "sent": "I mean I pick the best segment or more pull over the generator segments that are mostly overlap with the ground truth object.",
                    "label": 0
                },
                {
                    "sent": "Annotation at the same time we consider the number of the general segments so higher covering score with less number of the general segments is better under this metric.",
                    "label": 0
                },
                {
                    "sent": "This table summarizes the result.",
                    "label": 0
                },
                {
                    "sent": "We see that hours.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performs all the baselines and the canes statically.",
                    "label": 0
                },
                {
                    "sent": "Very significant considering the number of huge number of pixels involved in this operation, which I know I want to note.",
                    "label": 0
                },
                {
                    "sent": "The result in Berkeley.",
                    "label": 0
                },
                {
                    "sent": "Segmentation data set where the test data set the Buckley doesn't share much of the class label with the example Pascal data set.",
                    "label": 0
                },
                {
                    "sent": "That means sharing actually happens even when the class labels from example and tests are disjoint.",
                    "label": 0
                },
                {
                    "sent": "In the previous slides, we show the impact of shape sharing as in terms of.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Risk or over the entire data set.",
                    "label": 0
                },
                {
                    "sent": "However, this every school loan may not fully reveals the impact of shape sharing.",
                    "label": 0
                },
                {
                    "sent": "So in this life I wanna show more deeper analysis on when NY shape sharing are actually useful.",
                    "label": 0
                },
                {
                    "sent": "To this end, we define it.",
                    "label": 0
                },
                {
                    "sent": "Gain of our shape showing over the baseline function as a baseline method as a function of color agents.",
                    "label": 1
                },
                {
                    "sent": "An object size.",
                    "label": 0
                },
                {
                    "sent": "College is basically means how easily well how accurately we can do the segmentation using only color information we define this color regions in a quantitative way, but I skip the details.",
                    "label": 0
                },
                {
                    "sent": "Please refer to the paper if you're interested in.",
                    "label": 0
                },
                {
                    "sent": "This graph summarizes the result.",
                    "label": 0
                },
                {
                    "sent": "We see that the add color agent is getting low against is increasing.",
                    "label": 0
                },
                {
                    "sent": "In fact, at the leftmost point, where the color region is most hardest, organis as much as 15 point, which is really huge in this benchmark.",
                    "label": 0
                },
                {
                    "sent": "Also we see that as object sizes getting gross or gains is also increased.",
                    "label": 0
                },
                {
                    "sent": "In fact to any removed very small size of objects like which is less than probably 40 by 40 pixels, which is really small, we achieved twice again.",
                    "label": 0
                },
                {
                    "sent": "This is very intuitive.",
                    "label": 0
                },
                {
                    "sent": "Becausw adds objects, eyes are getting.",
                    "label": 0
                },
                {
                    "sent": "Bigger is shapes become more evident and easier to detect.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also analyzed which classes are actually sharing each other.",
                    "label": 1
                },
                {
                    "sent": "This sharing metrics counts how many times example classes are used to generate the best segments for each test class.",
                    "label": 0
                },
                {
                    "sent": "As expected, semantically similar classes like animals or vehicles show very strong sharing.",
                    "label": 0
                },
                {
                    "sent": "However, we also observed that the semantical very different classes like personal photo show very strong sharing as well.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, symmetrical ability from classes like here, the motorbike and talk.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you cover the very unexpected push variations which cannot be seen in the semantically very similar classes.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, I'll show some qualitative example results.",
                    "label": 1
                },
                {
                    "sent": "We see that shape showing is very useful when objects consists of heterogeneous color textures.",
                    "label": 0
                },
                {
                    "sent": "In the first image, for example, we can't eliminate the person successfully who wears the different colors, overheads closing, and different skin colors.",
                    "label": 0
                },
                {
                    "sent": "Also, sharing is useful when object.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Confused by similar surrounding colors.",
                    "label": 0
                },
                {
                    "sent": "For example, in the first image with Eliminators so far, single instance of Sofa, Peach is confused by the nearby sofas or similar colors.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This shows some failure cases.",
                    "label": 1
                },
                {
                    "sent": "Shape showing sometimes fails when object size is very small like in the first or second image.",
                    "label": 0
                },
                {
                    "sent": "Also sharing doesn't work when object doesn't have any shapes like truncated so far in the solid image.",
                    "label": 0
                },
                {
                    "sent": "Here in the third image, the target object is super, not dog, so and the sofa is truncated so.",
                    "label": 0
                },
                {
                    "sent": "Have no any meaningful outer boundaries.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In conclusion, we propose a shape sharing idea that enables to use top down shape cube without assuming any category specific prior knowledge on the objects.",
                    "label": 0
                },
                {
                    "sent": "Thus we can enhance the second segmentation quality or unseen or Noble objects.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "How do you decide like the number of groups from one image is automatically determined?",
                    "label": 0
                },
                {
                    "sent": "I actually the groups the shape projections that are.",
                    "label": 0
                },
                {
                    "sent": "That overlap of the 15% measures.",
                    "label": 0
                },
                {
                    "sent": "So when the segments overlap each other more than half of them overlapping score is over, then have by overlapping score I mean the intersection divided by Union.",
                    "label": 0
                },
                {
                    "sent": "The typical classical segmentation measure.",
                    "label": 0
                },
                {
                    "sent": "In that case we.",
                    "label": 0
                },
                {
                    "sent": "The group then in overall motivation, so we do the automotive segmentation based on that metric.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}