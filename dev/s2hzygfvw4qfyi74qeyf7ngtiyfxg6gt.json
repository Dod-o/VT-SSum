{
    "id": "s2hzygfvw4qfyi74qeyf7ngtiyfxg6gt",
    "title": "Finding a most biased coin with fewest flips",
    "info": {
        "author": [
            "Karthekeyan Chandrasekaran, Harvard School of Engineering and Applied Sciences, Harvard University"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/colt2014_chandrasekaran_finding/",
    "segmentation": [
        [
            "In this work, we address a variation of the multi armed bandit problem.",
            "In this variation we are given a collection of say N coins with bias probabilities Pi for coin I.",
            "The mapping from the collection of coins to the bias probabilities is unknown.",
            "You need step.",
            "We are allowed to pick one of the coins, toss it and note down the toss outcome.",
            "The goal is to find a coin with large bias.",
            "One whose bias is at least is at most epsilon away from the optimum, with probability at least one minus Delta.",
            "Does there exist a strategy to pick coins to toss?",
            "So that the expected number of tosses needed to achieve this goal is minimized.",
            "We will make an additional assumption that the top two bias probabilities differ by at least epsilon.",
            "This is known as the indifferent zone assumption in the literature."
        ],
        [
            "A naive nonadaptive strategy for this problem would be to toss each coin a certain number of times and output the coin with the largest empirical bias.",
            "Standard turnoff bound and union bound can be used to bound the number of coin tosses performed by such a non adaptive algorithm as shown here.",
            "In 2002, even their Manor and Monzo gave an adaptive algorithm that saved on the number of coin tosses.",
            "Their algorithm performs order N over epsilon squared log one over Delta tosses in expectation.",
            "A matching lower bound was shown by Manoharan Tsitsiklis in 2004.",
            "As you can see, the upper and lower bounds differ only by a constant factor, even though this constant is not huge, we would like to avoid such constant factor gaps if possible.",
            "In this work, we take a first step towards bridging this constant factor gap.",
            "For this we address the problem from a decision theoretic perspective."
        ],
        [
            "In the decision theoretic perspective, we start with a given history of toss outcomes.",
            "We would like to determine the coin to toss in the next step so that the expected future number of tosses to find a large biased coin is minimized.",
            "So we are seeking an optimum decision in each step.",
            "On first thoughts, it is unclear whether such a strategy even exists.",
            "But if it exists, and if we can implement it efficiently, then this would resolve the constant factor gap question.",
            "The status of this decision theoretic question is unresolved even for very simple settings of the problem.",
            "In this work, we give a decision theoretic optimal strategy for a very particular special setting.",
            "Our strategy is an obvious straightforward one.",
            "The non trivial aspect of our work is in showing that this strategy is indeed an optimal strategy."
        ],
        [
            "Here is the special setting of the problem that we address.",
            "We simplify the indifferent zone assumption further.",
            "And consider the setting with only two types of coins.",
            "Each coin is either most biased, which means it's biases P plus epsilon or second most biased, which means it's biases, B minus epsilon.",
            "The values of P and epsilon are known to us.",
            "For notational convenience I will denote a most biased coin as a heavy coin and a second most biased coin as a non heavy coin.",
            "We also assume an infinite supply of coins with a probabilistic prior over the probabilistic prior for the coins being heavy.",
            "This can be imagined as follows.",
            "We have a bag containing infinitely many coins.",
            "Alpha fraction of the coins are heavy, 1 minus Alpha fraction of the coins are non heavy.",
            "Whenever we ask for a fresh coin, a coin is drawn randomly from the bag and presented to us.",
            "Such a coin will be heavy with probability Alpha and non heavy with probability 1 minus Alpha.",
            "The algorithm is allowed to toss coins adaptively, request fresh coins adaptively.",
            "It has to output a coin whose posterior probability of being heavy is at least one minus Delta.",
            "This is the problem setting."
        ],
        [
            "Our main result here is an optimal strategy for this very particular setting.",
            "A strategy is decision theoretically optimal in each step.",
            "The strategy picks a coin toss so that the expected future number of tosses is minimized.",
            "Our strategy is also optimal even if we start with an arbitrary history.",
            "For a finite collection of the coins.",
            "Just to get a feel for the performance of our strategy, we also bound the expected number of coin tosses as shown here."
        ],
        [
            "Next, let me describe the strategy."
        ],
        [
            "This let us define the likelihood ratio.",
            "For a coin with a given history.",
            "The likelihood ratio is the ratio between the probability of the history.",
            "Given that the coin is heavy and the probability of the history given that the coin is non heavy.",
            "This can be rewritten as shown here.",
            "Now here is a very simple observation about the likelihood ratio.",
            "For any coin, the posterior probability that the coin is heavy is at least one minus Delta if and only if it's likelihood ratio is at least one minus Delta divided by Delta times 1 minus Alpha divided by Alpha.",
            "This is a simple consequence of Bayes theorem.",
            "Now, this observation immediately suggests a natural algorithm.",
            "Why not try to be greedy on the likelihood ratio?",
            "This."
        ],
        [
            "Is our strategy.",
            "We initialize all likelihoods to be one.",
            "This is a valid choice since the starting history is empty.",
            "If we have some history for a finite collection of the coins, then we would initialize the likelihoods accordingly.",
            "While the likelihood of all coins are at most this quantity, we pick a coin with the largest likelihood, toss it.",
            "Based on the toss outcome, we update the likelihood of this coin.",
            "If the toss outcome is ahead, then the likelihood changes by multiplicative factor of P plus epsilon divided by P minus epsilon, and if the toss outcome is a tale, then the likelihood changes by multiplicative factor of 1 -- 3 minus epsilon divided by 1 -- P plus epsilon.",
            "So we repeatedly toss a coin with the largest likelihood until there is this, a coin whose likelihood is larger than this quantity.",
            "At which point we dominate and output that coin.",
            "This is the complete description of our strategy.",
            "Fur."
        ],
        [
            "Of all, what is the correctness probability of this strategy?",
            "Well, if a coin is output by this strategy, then the likelihood ratio is larger than one minus Delta divided by Delta times 1 minus Alpha divided by Alpha.",
            "By the observation, we know that if the likelihood ratio is larger than this quantity, then the posterior probability of the coin being heavy is at least one minus Delta.",
            "So we have the correctness probability of at least one minus Delta."
        ],
        [
            "The rest of the talk will be focused towards sketching a proof that this greedy strategy is indeed an optimal strategy.",
            "For this."
        ],
        [
            "Let us take an alternate view of the algorithm.",
            "Let XI denote the log of the likelihood of coin I.",
            "Initially, the likelihoods of all coins are one, so the log likelihoods of all coins are zero.",
            "Savior in some step, we choose to toss a coin I with log likelihood XI.",
            "The influence of the coin toss on the log likelihood is a random step.",
            "If the toss outcome is ahead, then the log likelihood takes a forward step.",
            "If the toss outcome is a tail, then the log likelihood takes a backward step.",
            "The change in the log likelihood is precisely quantified by these two quantities.",
            "Delta H and Delta T. Moreover, the toss outcome will be ahead with probability exactly equal to the probability of heads given the current log likelihood.",
            "And it will be a tail with the remaining probability.",
            "And this probability of heads given the current log likelihood can be returned by the principle of mutual exclusion as shown here.",
            "So the transition probability depends only on the para meters P, epsilon, Alpha and the current state XI.",
            "So the toss outcomes lead to a 1 dimensional random walk of the log likelihood function associated with the coin.",
            "Observe that the transition probabilities here depends on the current state XI.",
            "Moreover, we stop tossing as soon as the log likelihood crosses this barrier B.",
            "So the random walk has an absorbing barrier at B.",
            "Finally, observe that the random walks performed by different coins are independent of each other.",
            "This is becausw the prior probabilities of being heavy are independent."
        ],
        [
            "So we have infinitely many identical Markov systems.",
            "Each one has a start state, zero target state B.",
            "A strategy to pick a coin to toss is equivalent to picking one of the Markov systems.",
            "The toss outcome leads to the corresponding Markov system taking a random step obeying its transition probability.",
            "The goal of minimizing the number of tosses is equivalent to minimizing the number of steps for one of the Markov systems to reach the target state.",
            "We will first see a generalization of this formulation and an optimum strategy for the generalization.",
            "The general."
        ],
        [
            "Position is known as a multi token Markov game."
        ],
        [
            "In a multi token Markov game, we have multiple Markov systems, not necessarily identical.",
            "Each one has a start state, says wonders two and a target state set T1 and T2.",
            "There is also a cost associated with each state of each system.",
            "Each system also has a token.",
            "In the beginning, the tokens are placed on the start state.",
            "In each step, the player has to pick one of the tokens.",
            "In order to pick a token, the player has to pay the cost of the current state of that token.",
            "Upon choosing a token, the token takes a random step in its system, obeying the transition probability.",
            "The game terminates as soon as one of the tokens reach the target.",
            "The goal of the player is to devise a strategy to pick tokens in each step.",
            "So that the cost for one of the tokens to reach the target is minimized.",
            "Such a game is known as a multi token Markov game.",
            "The cost of the game is defined to be the minimum expected cost over all possible strategies.",
            "Here the expectation is over the randomness in the system as well as the strategy.",
            "Note that the strategy can be randomized."
        ],
        [
            "Such multi token Markov games were studied by Demetrio Talion Winkler in 2003.",
            "They showed that every such game has an optimal strategy that is completely determined by the current states of the tokens.",
            "They were also able to characterize the optimal strategy.",
            "They showed that the best strategy is to pick the token that is in a state with the least grade.",
            "Grade is a function from the state space of the Markov system to the reals.",
            "Due to time constraints, I won't be able to describe this function.",
            "Just remember that the optimal strategy is to pick the token that is in a state with the least grade."
        ],
        [
            "Now recall that our goal is to show that the greedy strategy of picking a coin with the largest likelihood to toss is an optimal strategy.",
            "The state space in our Markov systems are all real values that are at most B.",
            "Since these correspond to the values that the log likelihood can take.",
            "Be sure that grade is not increasing as log likelihood increases.",
            "By the results of Dimitrio at all, we know that picking the token with the least grade is an optimal strategy.",
            "So tossing the coin with maximum like log likelihood is an optimal strategy.",
            "Which means the greedy strategy is optimal.",
            "Once again, due to time constraints, I won't delve into the details of the proof of the lemma.",
            "I invite you to read the paper.",
            "It is a short proof."
        ],
        [
            "I would like to conclude by presenting some open questions.",
            "An immediate question is whether we can address the three coin setting.",
            "Each coin has bias, either P plus epsilon P or P minus epsilon.",
            "We still have an infinite supply of coins with the probabilistic prior.",
            "Is that a decision theoretic optimal strategy to identify a most biased coin?",
            "Another question is to address the two coins setting under dependent priors.",
            "For example, say we have a finite collection of coins, with the guarantee that exactly one of the coins is heavy.",
            "Is there a decision theoretic optimal strategy to identify this heavy coin?",
            "It would be nice to see what other prior models for the two coins setting can be handled.",
            "Thank you very much for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this work, we address a variation of the multi armed bandit problem.",
                    "label": 0
                },
                {
                    "sent": "In this variation we are given a collection of say N coins with bias probabilities Pi for coin I.",
                    "label": 1
                },
                {
                    "sent": "The mapping from the collection of coins to the bias probabilities is unknown.",
                    "label": 0
                },
                {
                    "sent": "You need step.",
                    "label": 0
                },
                {
                    "sent": "We are allowed to pick one of the coins, toss it and note down the toss outcome.",
                    "label": 0
                },
                {
                    "sent": "The goal is to find a coin with large bias.",
                    "label": 1
                },
                {
                    "sent": "One whose bias is at least is at most epsilon away from the optimum, with probability at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "Does there exist a strategy to pick coins to toss?",
                    "label": 0
                },
                {
                    "sent": "So that the expected number of tosses needed to achieve this goal is minimized.",
                    "label": 1
                },
                {
                    "sent": "We will make an additional assumption that the top two bias probabilities differ by at least epsilon.",
                    "label": 1
                },
                {
                    "sent": "This is known as the indifferent zone assumption in the literature.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A naive nonadaptive strategy for this problem would be to toss each coin a certain number of times and output the coin with the largest empirical bias.",
                    "label": 0
                },
                {
                    "sent": "Standard turnoff bound and union bound can be used to bound the number of coin tosses performed by such a non adaptive algorithm as shown here.",
                    "label": 0
                },
                {
                    "sent": "In 2002, even their Manor and Monzo gave an adaptive algorithm that saved on the number of coin tosses.",
                    "label": 1
                },
                {
                    "sent": "Their algorithm performs order N over epsilon squared log one over Delta tosses in expectation.",
                    "label": 1
                },
                {
                    "sent": "A matching lower bound was shown by Manoharan Tsitsiklis in 2004.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the upper and lower bounds differ only by a constant factor, even though this constant is not huge, we would like to avoid such constant factor gaps if possible.",
                    "label": 1
                },
                {
                    "sent": "In this work, we take a first step towards bridging this constant factor gap.",
                    "label": 1
                },
                {
                    "sent": "For this we address the problem from a decision theoretic perspective.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the decision theoretic perspective, we start with a given history of toss outcomes.",
                    "label": 0
                },
                {
                    "sent": "We would like to determine the coin to toss in the next step so that the expected future number of tosses to find a large biased coin is minimized.",
                    "label": 1
                },
                {
                    "sent": "So we are seeking an optimum decision in each step.",
                    "label": 0
                },
                {
                    "sent": "On first thoughts, it is unclear whether such a strategy even exists.",
                    "label": 0
                },
                {
                    "sent": "But if it exists, and if we can implement it efficiently, then this would resolve the constant factor gap question.",
                    "label": 0
                },
                {
                    "sent": "The status of this decision theoretic question is unresolved even for very simple settings of the problem.",
                    "label": 0
                },
                {
                    "sent": "In this work, we give a decision theoretic optimal strategy for a very particular special setting.",
                    "label": 0
                },
                {
                    "sent": "Our strategy is an obvious straightforward one.",
                    "label": 0
                },
                {
                    "sent": "The non trivial aspect of our work is in showing that this strategy is indeed an optimal strategy.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is the special setting of the problem that we address.",
                    "label": 0
                },
                {
                    "sent": "We simplify the indifferent zone assumption further.",
                    "label": 0
                },
                {
                    "sent": "And consider the setting with only two types of coins.",
                    "label": 0
                },
                {
                    "sent": "Each coin is either most biased, which means it's biases P plus epsilon or second most biased, which means it's biases, B minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "The values of P and epsilon are known to us.",
                    "label": 0
                },
                {
                    "sent": "For notational convenience I will denote a most biased coin as a heavy coin and a second most biased coin as a non heavy coin.",
                    "label": 0
                },
                {
                    "sent": "We also assume an infinite supply of coins with a probabilistic prior over the probabilistic prior for the coins being heavy.",
                    "label": 1
                },
                {
                    "sent": "This can be imagined as follows.",
                    "label": 0
                },
                {
                    "sent": "We have a bag containing infinitely many coins.",
                    "label": 0
                },
                {
                    "sent": "Alpha fraction of the coins are heavy, 1 minus Alpha fraction of the coins are non heavy.",
                    "label": 0
                },
                {
                    "sent": "Whenever we ask for a fresh coin, a coin is drawn randomly from the bag and presented to us.",
                    "label": 0
                },
                {
                    "sent": "Such a coin will be heavy with probability Alpha and non heavy with probability 1 minus Alpha.",
                    "label": 1
                },
                {
                    "sent": "The algorithm is allowed to toss coins adaptively, request fresh coins adaptively.",
                    "label": 1
                },
                {
                    "sent": "It has to output a coin whose posterior probability of being heavy is at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "This is the problem setting.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our main result here is an optimal strategy for this very particular setting.",
                    "label": 0
                },
                {
                    "sent": "A strategy is decision theoretically optimal in each step.",
                    "label": 0
                },
                {
                    "sent": "The strategy picks a coin toss so that the expected future number of tosses is minimized.",
                    "label": 1
                },
                {
                    "sent": "Our strategy is also optimal even if we start with an arbitrary history.",
                    "label": 1
                },
                {
                    "sent": "For a finite collection of the coins.",
                    "label": 0
                },
                {
                    "sent": "Just to get a feel for the performance of our strategy, we also bound the expected number of coin tosses as shown here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next, let me describe the strategy.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This let us define the likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "For a coin with a given history.",
                    "label": 1
                },
                {
                    "sent": "The likelihood ratio is the ratio between the probability of the history.",
                    "label": 0
                },
                {
                    "sent": "Given that the coin is heavy and the probability of the history given that the coin is non heavy.",
                    "label": 0
                },
                {
                    "sent": "This can be rewritten as shown here.",
                    "label": 0
                },
                {
                    "sent": "Now here is a very simple observation about the likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "For any coin, the posterior probability that the coin is heavy is at least one minus Delta if and only if it's likelihood ratio is at least one minus Delta divided by Delta times 1 minus Alpha divided by Alpha.",
                    "label": 1
                },
                {
                    "sent": "This is a simple consequence of Bayes theorem.",
                    "label": 0
                },
                {
                    "sent": "Now, this observation immediately suggests a natural algorithm.",
                    "label": 0
                },
                {
                    "sent": "Why not try to be greedy on the likelihood ratio?",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is our strategy.",
                    "label": 0
                },
                {
                    "sent": "We initialize all likelihoods to be one.",
                    "label": 0
                },
                {
                    "sent": "This is a valid choice since the starting history is empty.",
                    "label": 0
                },
                {
                    "sent": "If we have some history for a finite collection of the coins, then we would initialize the likelihoods accordingly.",
                    "label": 0
                },
                {
                    "sent": "While the likelihood of all coins are at most this quantity, we pick a coin with the largest likelihood, toss it.",
                    "label": 0
                },
                {
                    "sent": "Based on the toss outcome, we update the likelihood of this coin.",
                    "label": 1
                },
                {
                    "sent": "If the toss outcome is ahead, then the likelihood changes by multiplicative factor of P plus epsilon divided by P minus epsilon, and if the toss outcome is a tale, then the likelihood changes by multiplicative factor of 1 -- 3 minus epsilon divided by 1 -- P plus epsilon.",
                    "label": 0
                },
                {
                    "sent": "So we repeatedly toss a coin with the largest likelihood until there is this, a coin whose likelihood is larger than this quantity.",
                    "label": 0
                },
                {
                    "sent": "At which point we dominate and output that coin.",
                    "label": 0
                },
                {
                    "sent": "This is the complete description of our strategy.",
                    "label": 0
                },
                {
                    "sent": "Fur.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of all, what is the correctness probability of this strategy?",
                    "label": 1
                },
                {
                    "sent": "Well, if a coin is output by this strategy, then the likelihood ratio is larger than one minus Delta divided by Delta times 1 minus Alpha divided by Alpha.",
                    "label": 1
                },
                {
                    "sent": "By the observation, we know that if the likelihood ratio is larger than this quantity, then the posterior probability of the coin being heavy is at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "So we have the correctness probability of at least one minus Delta.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The rest of the talk will be focused towards sketching a proof that this greedy strategy is indeed an optimal strategy.",
                    "label": 0
                },
                {
                    "sent": "For this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let us take an alternate view of the algorithm.",
                    "label": 1
                },
                {
                    "sent": "Let XI denote the log of the likelihood of coin I.",
                    "label": 0
                },
                {
                    "sent": "Initially, the likelihoods of all coins are one, so the log likelihoods of all coins are zero.",
                    "label": 0
                },
                {
                    "sent": "Savior in some step, we choose to toss a coin I with log likelihood XI.",
                    "label": 0
                },
                {
                    "sent": "The influence of the coin toss on the log likelihood is a random step.",
                    "label": 0
                },
                {
                    "sent": "If the toss outcome is ahead, then the log likelihood takes a forward step.",
                    "label": 0
                },
                {
                    "sent": "If the toss outcome is a tail, then the log likelihood takes a backward step.",
                    "label": 0
                },
                {
                    "sent": "The change in the log likelihood is precisely quantified by these two quantities.",
                    "label": 0
                },
                {
                    "sent": "Delta H and Delta T. Moreover, the toss outcome will be ahead with probability exactly equal to the probability of heads given the current log likelihood.",
                    "label": 0
                },
                {
                    "sent": "And it will be a tail with the remaining probability.",
                    "label": 0
                },
                {
                    "sent": "And this probability of heads given the current log likelihood can be returned by the principle of mutual exclusion as shown here.",
                    "label": 0
                },
                {
                    "sent": "So the transition probability depends only on the para meters P, epsilon, Alpha and the current state XI.",
                    "label": 0
                },
                {
                    "sent": "So the toss outcomes lead to a 1 dimensional random walk of the log likelihood function associated with the coin.",
                    "label": 0
                },
                {
                    "sent": "Observe that the transition probabilities here depends on the current state XI.",
                    "label": 0
                },
                {
                    "sent": "Moreover, we stop tossing as soon as the log likelihood crosses this barrier B.",
                    "label": 0
                },
                {
                    "sent": "So the random walk has an absorbing barrier at B.",
                    "label": 0
                },
                {
                    "sent": "Finally, observe that the random walks performed by different coins are independent of each other.",
                    "label": 0
                },
                {
                    "sent": "This is becausw the prior probabilities of being heavy are independent.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have infinitely many identical Markov systems.",
                    "label": 0
                },
                {
                    "sent": "Each one has a start state, zero target state B.",
                    "label": 0
                },
                {
                    "sent": "A strategy to pick a coin to toss is equivalent to picking one of the Markov systems.",
                    "label": 0
                },
                {
                    "sent": "The toss outcome leads to the corresponding Markov system taking a random step obeying its transition probability.",
                    "label": 0
                },
                {
                    "sent": "The goal of minimizing the number of tosses is equivalent to minimizing the number of steps for one of the Markov systems to reach the target state.",
                    "label": 0
                },
                {
                    "sent": "We will first see a generalization of this formulation and an optimum strategy for the generalization.",
                    "label": 0
                },
                {
                    "sent": "The general.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Position is known as a multi token Markov game.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a multi token Markov game, we have multiple Markov systems, not necessarily identical.",
                    "label": 0
                },
                {
                    "sent": "Each one has a start state, says wonders two and a target state set T1 and T2.",
                    "label": 0
                },
                {
                    "sent": "There is also a cost associated with each state of each system.",
                    "label": 0
                },
                {
                    "sent": "Each system also has a token.",
                    "label": 0
                },
                {
                    "sent": "In the beginning, the tokens are placed on the start state.",
                    "label": 0
                },
                {
                    "sent": "In each step, the player has to pick one of the tokens.",
                    "label": 0
                },
                {
                    "sent": "In order to pick a token, the player has to pay the cost of the current state of that token.",
                    "label": 0
                },
                {
                    "sent": "Upon choosing a token, the token takes a random step in its system, obeying the transition probability.",
                    "label": 0
                },
                {
                    "sent": "The game terminates as soon as one of the tokens reach the target.",
                    "label": 0
                },
                {
                    "sent": "The goal of the player is to devise a strategy to pick tokens in each step.",
                    "label": 0
                },
                {
                    "sent": "So that the cost for one of the tokens to reach the target is minimized.",
                    "label": 0
                },
                {
                    "sent": "Such a game is known as a multi token Markov game.",
                    "label": 0
                },
                {
                    "sent": "The cost of the game is defined to be the minimum expected cost over all possible strategies.",
                    "label": 0
                },
                {
                    "sent": "Here the expectation is over the randomness in the system as well as the strategy.",
                    "label": 0
                },
                {
                    "sent": "Note that the strategy can be randomized.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such multi token Markov games were studied by Demetrio Talion Winkler in 2003.",
                    "label": 0
                },
                {
                    "sent": "They showed that every such game has an optimal strategy that is completely determined by the current states of the tokens.",
                    "label": 0
                },
                {
                    "sent": "They were also able to characterize the optimal strategy.",
                    "label": 0
                },
                {
                    "sent": "They showed that the best strategy is to pick the token that is in a state with the least grade.",
                    "label": 0
                },
                {
                    "sent": "Grade is a function from the state space of the Markov system to the reals.",
                    "label": 0
                },
                {
                    "sent": "Due to time constraints, I won't be able to describe this function.",
                    "label": 0
                },
                {
                    "sent": "Just remember that the optimal strategy is to pick the token that is in a state with the least grade.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now recall that our goal is to show that the greedy strategy of picking a coin with the largest likelihood to toss is an optimal strategy.",
                    "label": 0
                },
                {
                    "sent": "The state space in our Markov systems are all real values that are at most B.",
                    "label": 1
                },
                {
                    "sent": "Since these correspond to the values that the log likelihood can take.",
                    "label": 0
                },
                {
                    "sent": "Be sure that grade is not increasing as log likelihood increases.",
                    "label": 0
                },
                {
                    "sent": "By the results of Dimitrio at all, we know that picking the token with the least grade is an optimal strategy.",
                    "label": 1
                },
                {
                    "sent": "So tossing the coin with maximum like log likelihood is an optimal strategy.",
                    "label": 1
                },
                {
                    "sent": "Which means the greedy strategy is optimal.",
                    "label": 0
                },
                {
                    "sent": "Once again, due to time constraints, I won't delve into the details of the proof of the lemma.",
                    "label": 0
                },
                {
                    "sent": "I invite you to read the paper.",
                    "label": 0
                },
                {
                    "sent": "It is a short proof.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I would like to conclude by presenting some open questions.",
                    "label": 0
                },
                {
                    "sent": "An immediate question is whether we can address the three coin setting.",
                    "label": 0
                },
                {
                    "sent": "Each coin has bias, either P plus epsilon P or P minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "We still have an infinite supply of coins with the probabilistic prior.",
                    "label": 1
                },
                {
                    "sent": "Is that a decision theoretic optimal strategy to identify a most biased coin?",
                    "label": 0
                },
                {
                    "sent": "Another question is to address the two coins setting under dependent priors.",
                    "label": 0
                },
                {
                    "sent": "For example, say we have a finite collection of coins, with the guarantee that exactly one of the coins is heavy.",
                    "label": 0
                },
                {
                    "sent": "Is there a decision theoretic optimal strategy to identify this heavy coin?",
                    "label": 0
                },
                {
                    "sent": "It would be nice to see what other prior models for the two coins setting can be handled.",
                    "label": 1
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                }
            ]
        }
    }
}