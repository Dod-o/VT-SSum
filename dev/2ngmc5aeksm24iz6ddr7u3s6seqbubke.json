{
    "id": "2ngmc5aeksm24iz6ddr7u3s6seqbubke",
    "title": "Zhishi.lemon\uff1aOn Publishing Zhishi.me as Linguistic Linked Open Data",
    "info": {
        "author": [
            "Zhijia Fang, East China University of Science and Technology (ECUST)"
        ],
        "published": "Nov. 10, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2016_fang_open_data/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "This is just a phone from East China University of Science and Technology and this is joint work with George and Julio from the Ontology Engineering Group in Spain and in this paper we published Dot Limo, which is a linguistic resources to the linguistic linked open data.",
            "And before I talk about this data set"
        ],
        [
            "I want to say something about just me and the linguistic link open data."
        ],
        [
            "As we all know, with the development of the semantic Web, a growing number of structured data in the form of ideas triples have been published.",
            "And in the year 2011, our group."
        ],
        [
            "First published the data set just me which is the first effort to publish large scale Chinese semantic data and link them as the Chinese linked open Data Cloud.",
            "Currently it has gathers over 8 million distinct instances and over 200 million RDF triples in this data set.",
            "And it has three main sources, which is from the three largest encyclopedia website.",
            "In China, which is called by doing Cyclopedia, who don't encyclopedia, and the Wikipedia Chinese versions."
        ],
        [
            "And we also know the LOD cloud could be classified into some fine grained groups."
        ],
        [
            "And the linguistic linked open data is one of them.",
            "In this cloud, linguistic resources in different languages have been published and interlinked together.",
            "And since Chinese is one of the most spoken languages in the world, we also want to contribute to this cloud."
        ],
        [
            "So here is the data set, just not lemon.",
            "It is and you need A to develop data set which consisted lexicon realization of just me, and it currently supports for street languages.",
            "Chinese, Spanish and English.",
            "Also we provide links from just me to the DP pedia.",
            "An fable net."
        ],
        [
            "And why we and why we choose to build this data set first, is the capacity compared with the English and other prevalent languages.",
            "Chinese resource in this cloud is really scarce at the current time.",
            "Here we take the DV Pedia as examples.",
            "In English instances in DB Pedia occupies over 3.5 million and Spanish is about 1 million.",
            "And how about Chinese?",
            "It only covers 100,000."
        ],
        [
            "And since we have the dish me, which is a compatible resources to both DB pedia and all the girls will also want to link this data set to the linguistic open data.",
            "And we hope we can enrich the whole cloud with additional Chinese entries.",
            "And last but not least is that this data set could benefit both academia and industrial use in the futures.",
            "Anyone who are interested in Chinese.",
            "We could leverage this data set to build more real world applications."
        ],
        [
            "And to build jalomo, we first start from the dish me."
        ],
        [
            "And linked it."
        ],
        [
            "Through the DB pedia.",
            "DB Pedia has made and it is still making a large impact on the linguistic linked open data and things.",
            "Just me has the Chinese Wikipedia as one of its sources and interlinks its sources to the other equivalent ones, Baidu Encyclopedia and who don't encyclopedia the Chinese.",
            "Wikipedia can serve as the bridge to help detect equivalence from just me to the DPP.",
            "Yeah."
        ],
        [
            "And also we provide links from GCM to diboll.",
            "Net and I'm processing of linking.",
            "Just meet people.",
            "Net, we found that the Chinese entries usually can be found more than one Babel thinset."
        ],
        [
            "To overcome this difficulties, we mainly leverage the category information to overcome.",
            "And the just thought lemon can constitute all of the links."
        ],
        [
            "Here."
        ],
        [
            "And we have the links here.",
            "Here remains another problem is that how to put represent this data?"
        ],
        [
            "In this work, we choose to use the lemma Ontology."
        ],
        [
            "Which is also known as lexical model for ontologies.",
            "There are two advantages of us to choose lemma."
        ],
        [
            "First years it can bridge the gap between lexical and conceptual informations, and it is currently in now a defect code standards for representing and publishing lexical resources in this cloud."
        ],
        [
            "And also there are a lot of practical use of lemon."
        ],
        [
            "Such as the Optum Wernette DB Pedia, Wiktionary and Bible net."
        ],
        [
            "And the in level it has mainly of six components, namely lexical, lexical entry, lexical sense, reference form, and representations.",
            "I will give an example of juice dot lemon on how we use these components."
        ],
        [
            "Here I want to give the ontology overview of our datasets."
        ],
        [
            "As guided in the Lemon tutorials, we create a monolingual lexicon."
        ],
        [
            "For each language, Chinese, Spanish and English, each is built to gather newly added resources of the same languages in just at Lambeau."
        ],
        [
            "And how we choose the lexical entries injection me the title of the Articles Encyclopedia website are labeled are modeled as the label of an entities, and these labels could be used directly in the Jewish dot lemon as lexical entries."
        ],
        [
            "However, the lexical entries is not semantically disaggregated until an ontology."
        ],
        [
            "Reference provides the semantics, so in this mode."
        ],
        [
            "So each lexical essence will be given an identical ontology reference from Jimmy.",
            "And given the fact that we are not modifying both, just me and the two equivalent resources people net and DB pedia equivalent, ontology entities should be declared at the semantic layer which we use.",
            "Same as relations."
        ],
        [
            "To descri."
        ],
        [
            "The equivalence."
        ],
        [
            "And The thing is, just learn more user data set, mainly focus on the Chinese resources.",
            "We also added some Chinese features."
        ],
        [
            "As we all know, Chinese Chinese forms had to return form the traditional ones, and the simplified ones.",
            "Both Chinese characters are modified in this model and we use different language text to distinguish them."
        ],
        [
            "Also, we found the romanization of Chinese is another interesting phenomenon.",
            "We also want to model."
        ],
        [
            "This phenomenon phenomenon is in this model.",
            "And we think this data could benefit the linguistic link linked open data more if someone are interested in Chinese, and I think this data could benefit him and to help him read the Chinese words.",
            "Also we provide an identical code to distinguish them."
        ],
        [
            "And for the representation of this model, we simply use the translation module provided in Lemon."
        ],
        [
            "Translation relations can be inferred from the terms in different languages when they refer to the same real world real world."
        ],
        [
            "Object."
        ],
        [
            "And we also didn't.",
            "Several different translation set.",
            "These sets are facilities for querying.",
            "Given an example that if someone wants to retrieve a term or Spanish from a certain Chinese terms he only wants, he only needs to query the Chinese and Spanish translation set instead of the whole data set."
        ],
        [
            "And here I want to give some statics about this data set.",
            "We create links to the Babel net to the pedia and also the dish me.",
            "And then there are totally 300,000 translations in this data set and over 7 million triples.",
            "And during the experiment we found the closest work to us is the Chinese word net.",
            "The main difference is Chinese were not focus on more focused more on the concept towards alignment.",
            "However, just thought Lemon focus on the real world object alignment and we think that cross lingual alignment between real world objects may benefit more to the linguistically open data and also compared to the word Chinese word net.",
            "Just start Lemon, achieve a large scales in both of the in order of the three types of elements.",
            "Namely, Lexicon entry lacks common sense and translations."
        ],
        [
            "And to publish just start l'amour.",
            "We design A platform including both look up services Ann and Sparkle endpoint.",
            "We use Gina TBS to store the extracted triples and provide querying's capabilities."
        ],
        [
            "You can visit the following URLs to visit our demos."
        ],
        [
            "Also, if you want to use our data set, they are all uploaded to the data hub.",
            "And to conclude, this paper in this paper we mainly introduce a new data, a newly developed data set which is called just lemon.",
            "It is currently supports for three languages.",
            "Chinese, Spanish and English.",
            "Also we provide links from China.",
            "We also provide links from just me to DB Pedia and Babel net."
        ],
        [
            "And in the future we want to transform more Chinese resources into different languages and integrate them introduced at Lambeau and use this data set to build more real world applications.",
            "And after this, this work was accepted.",
            "We are currently doing some more.",
            "We are transforming the Chinese symptoms to the English wines and we tried to link just me to another well known data set which is called.",
            "Umm hours.",
            "I think this will benefit them.",
            "I think this will benefit this data set in the near future."
        ],
        [
            "And thanks for questions.",
            "So it's really about what kind of kind of resource faces in particular.",
            "If it's a terminology or lexical resource.",
            "So do you have deeper grammatical information like part of speech or I guess in their morphology in Chinese, but information about grammatical usage of this words?",
            "Or is it more deep list of terms that are used in Chinese?",
            "Actually the part of speech or the other related informations are included.",
            "In addition, me and Jimmy is linked to the.",
            "Just thought Lamo so we do not declare this informations in this data set, but it includes in the Jimmy datasets.",
            "When you first start with me, you start with the methods you have between the Chinese Wikipedia and the English Wikipedia.",
            "What about the terms in Chinese?",
            "We can figure that don't have an opposite or counterpart in English one, so how do you think that that would be divided into several steps?",
            "First, we use the Bible net to identify those are not in the Wikipedia, and also interesting me.",
            "We have some.",
            "English transform English.",
            "English translations of certain Chinese words, and we can use this kind of resource to linked from Jimmy to other existing datasets.",
            "How large is this fraction?",
            "Actually?",
            "It is not so large currently, but in the near near updates as I talk about the Chinese symptoms linking procedures we are trying used sequence to sequence module to overcome.",
            "This this difficulties.",
            "Anymore questions.",
            "Hi I wanted to ask if Lemon Ontology covers all the intricacies of Chinese language.",
            "Are there some for example grammatical phenomenon that you that you cannot really model though is it?",
            "Is it sufficient for you?",
            "To use lemma ontologies, we found we actually found some problems when it applied it to the Chinese resources.",
            "So when we do this work, we we designed different language codes to represent the specific Chinese terms that what we do different to the Lemon Ontology.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "This is just a phone from East China University of Science and Technology and this is joint work with George and Julio from the Ontology Engineering Group in Spain and in this paper we published Dot Limo, which is a linguistic resources to the linguistic linked open data.",
                    "label": 1
                },
                {
                    "sent": "And before I talk about this data set",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to say something about just me and the linguistic link open data.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we all know, with the development of the semantic Web, a growing number of structured data in the form of ideas triples have been published.",
                    "label": 0
                },
                {
                    "sent": "And in the year 2011, our group.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First published the data set just me which is the first effort to publish large scale Chinese semantic data and link them as the Chinese linked open Data Cloud.",
                    "label": 1
                },
                {
                    "sent": "Currently it has gathers over 8 million distinct instances and over 200 million RDF triples in this data set.",
                    "label": 0
                },
                {
                    "sent": "And it has three main sources, which is from the three largest encyclopedia website.",
                    "label": 0
                },
                {
                    "sent": "In China, which is called by doing Cyclopedia, who don't encyclopedia, and the Wikipedia Chinese versions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also know the LOD cloud could be classified into some fine grained groups.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the linguistic linked open data is one of them.",
                    "label": 1
                },
                {
                    "sent": "In this cloud, linguistic resources in different languages have been published and interlinked together.",
                    "label": 0
                },
                {
                    "sent": "And since Chinese is one of the most spoken languages in the world, we also want to contribute to this cloud.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the data set, just not lemon.",
                    "label": 0
                },
                {
                    "sent": "It is and you need A to develop data set which consisted lexicon realization of just me, and it currently supports for street languages.",
                    "label": 0
                },
                {
                    "sent": "Chinese, Spanish and English.",
                    "label": 0
                },
                {
                    "sent": "Also we provide links from just me to the DP pedia.",
                    "label": 0
                },
                {
                    "sent": "An fable net.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And why we and why we choose to build this data set first, is the capacity compared with the English and other prevalent languages.",
                    "label": 1
                },
                {
                    "sent": "Chinese resource in this cloud is really scarce at the current time.",
                    "label": 0
                },
                {
                    "sent": "Here we take the DV Pedia as examples.",
                    "label": 0
                },
                {
                    "sent": "In English instances in DB Pedia occupies over 3.5 million and Spanish is about 1 million.",
                    "label": 0
                },
                {
                    "sent": "And how about Chinese?",
                    "label": 0
                },
                {
                    "sent": "It only covers 100,000.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And since we have the dish me, which is a compatible resources to both DB pedia and all the girls will also want to link this data set to the linguistic open data.",
                    "label": 0
                },
                {
                    "sent": "And we hope we can enrich the whole cloud with additional Chinese entries.",
                    "label": 1
                },
                {
                    "sent": "And last but not least is that this data set could benefit both academia and industrial use in the futures.",
                    "label": 0
                },
                {
                    "sent": "Anyone who are interested in Chinese.",
                    "label": 0
                },
                {
                    "sent": "We could leverage this data set to build more real world applications.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to build jalomo, we first start from the dish me.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And linked it.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through the DB pedia.",
                    "label": 0
                },
                {
                    "sent": "DB Pedia has made and it is still making a large impact on the linguistic linked open data and things.",
                    "label": 0
                },
                {
                    "sent": "Just me has the Chinese Wikipedia as one of its sources and interlinks its sources to the other equivalent ones, Baidu Encyclopedia and who don't encyclopedia the Chinese.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia can serve as the bridge to help detect equivalence from just me to the DPP.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we provide links from GCM to diboll.",
                    "label": 0
                },
                {
                    "sent": "Net and I'm processing of linking.",
                    "label": 0
                },
                {
                    "sent": "Just meet people.",
                    "label": 0
                },
                {
                    "sent": "Net, we found that the Chinese entries usually can be found more than one Babel thinset.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To overcome this difficulties, we mainly leverage the category information to overcome.",
                    "label": 0
                },
                {
                    "sent": "And the just thought lemon can constitute all of the links.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have the links here.",
                    "label": 0
                },
                {
                    "sent": "Here remains another problem is that how to put represent this data?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this work, we choose to use the lemma Ontology.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is also known as lexical model for ontologies.",
                    "label": 0
                },
                {
                    "sent": "There are two advantages of us to choose lemma.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First years it can bridge the gap between lexical and conceptual informations, and it is currently in now a defect code standards for representing and publishing lexical resources in this cloud.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also there are a lot of practical use of lemon.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such as the Optum Wernette DB Pedia, Wiktionary and Bible net.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the in level it has mainly of six components, namely lexical, lexical entry, lexical sense, reference form, and representations.",
                    "label": 0
                },
                {
                    "sent": "I will give an example of juice dot lemon on how we use these components.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I want to give the ontology overview of our datasets.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As guided in the Lemon tutorials, we create a monolingual lexicon.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For each language, Chinese, Spanish and English, each is built to gather newly added resources of the same languages in just at Lambeau.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how we choose the lexical entries injection me the title of the Articles Encyclopedia website are labeled are modeled as the label of an entities, and these labels could be used directly in the Jewish dot lemon as lexical entries.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, the lexical entries is not semantically disaggregated until an ontology.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reference provides the semantics, so in this mode.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So each lexical essence will be given an identical ontology reference from Jimmy.",
                    "label": 1
                },
                {
                    "sent": "And given the fact that we are not modifying both, just me and the two equivalent resources people net and DB pedia equivalent, ontology entities should be declared at the semantic layer which we use.",
                    "label": 0
                },
                {
                    "sent": "Same as relations.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To descri.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The equivalence.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And The thing is, just learn more user data set, mainly focus on the Chinese resources.",
                    "label": 0
                },
                {
                    "sent": "We also added some Chinese features.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As we all know, Chinese Chinese forms had to return form the traditional ones, and the simplified ones.",
                    "label": 0
                },
                {
                    "sent": "Both Chinese characters are modified in this model and we use different language text to distinguish them.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, we found the romanization of Chinese is another interesting phenomenon.",
                    "label": 0
                },
                {
                    "sent": "We also want to model.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This phenomenon phenomenon is in this model.",
                    "label": 0
                },
                {
                    "sent": "And we think this data could benefit the linguistic link linked open data more if someone are interested in Chinese, and I think this data could benefit him and to help him read the Chinese words.",
                    "label": 0
                },
                {
                    "sent": "Also we provide an identical code to distinguish them.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the representation of this model, we simply use the translation module provided in Lemon.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Translation relations can be inferred from the terms in different languages when they refer to the same real world real world.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Object.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also didn't.",
                    "label": 0
                },
                {
                    "sent": "Several different translation set.",
                    "label": 0
                },
                {
                    "sent": "These sets are facilities for querying.",
                    "label": 0
                },
                {
                    "sent": "Given an example that if someone wants to retrieve a term or Spanish from a certain Chinese terms he only wants, he only needs to query the Chinese and Spanish translation set instead of the whole data set.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here I want to give some statics about this data set.",
                    "label": 0
                },
                {
                    "sent": "We create links to the Babel net to the pedia and also the dish me.",
                    "label": 0
                },
                {
                    "sent": "And then there are totally 300,000 translations in this data set and over 7 million triples.",
                    "label": 0
                },
                {
                    "sent": "And during the experiment we found the closest work to us is the Chinese word net.",
                    "label": 0
                },
                {
                    "sent": "The main difference is Chinese were not focus on more focused more on the concept towards alignment.",
                    "label": 0
                },
                {
                    "sent": "However, just thought Lemon focus on the real world object alignment and we think that cross lingual alignment between real world objects may benefit more to the linguistically open data and also compared to the word Chinese word net.",
                    "label": 1
                },
                {
                    "sent": "Just start Lemon, achieve a large scales in both of the in order of the three types of elements.",
                    "label": 0
                },
                {
                    "sent": "Namely, Lexicon entry lacks common sense and translations.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to publish just start l'amour.",
                    "label": 0
                },
                {
                    "sent": "We design A platform including both look up services Ann and Sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "We use Gina TBS to store the extracted triples and provide querying's capabilities.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can visit the following URLs to visit our demos.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, if you want to use our data set, they are all uploaded to the data hub.",
                    "label": 0
                },
                {
                    "sent": "And to conclude, this paper in this paper we mainly introduce a new data, a newly developed data set which is called just lemon.",
                    "label": 0
                },
                {
                    "sent": "It is currently supports for three languages.",
                    "label": 0
                },
                {
                    "sent": "Chinese, Spanish and English.",
                    "label": 0
                },
                {
                    "sent": "Also we provide links from China.",
                    "label": 0
                },
                {
                    "sent": "We also provide links from just me to DB Pedia and Babel net.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the future we want to transform more Chinese resources into different languages and integrate them introduced at Lambeau and use this data set to build more real world applications.",
                    "label": 0
                },
                {
                    "sent": "And after this, this work was accepted.",
                    "label": 0
                },
                {
                    "sent": "We are currently doing some more.",
                    "label": 0
                },
                {
                    "sent": "We are transforming the Chinese symptoms to the English wines and we tried to link just me to another well known data set which is called.",
                    "label": 0
                },
                {
                    "sent": "Umm hours.",
                    "label": 0
                },
                {
                    "sent": "I think this will benefit them.",
                    "label": 0
                },
                {
                    "sent": "I think this will benefit this data set in the near future.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And thanks for questions.",
                    "label": 0
                },
                {
                    "sent": "So it's really about what kind of kind of resource faces in particular.",
                    "label": 0
                },
                {
                    "sent": "If it's a terminology or lexical resource.",
                    "label": 0
                },
                {
                    "sent": "So do you have deeper grammatical information like part of speech or I guess in their morphology in Chinese, but information about grammatical usage of this words?",
                    "label": 0
                },
                {
                    "sent": "Or is it more deep list of terms that are used in Chinese?",
                    "label": 0
                },
                {
                    "sent": "Actually the part of speech or the other related informations are included.",
                    "label": 0
                },
                {
                    "sent": "In addition, me and Jimmy is linked to the.",
                    "label": 0
                },
                {
                    "sent": "Just thought Lamo so we do not declare this informations in this data set, but it includes in the Jimmy datasets.",
                    "label": 0
                },
                {
                    "sent": "When you first start with me, you start with the methods you have between the Chinese Wikipedia and the English Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "What about the terms in Chinese?",
                    "label": 0
                },
                {
                    "sent": "We can figure that don't have an opposite or counterpart in English one, so how do you think that that would be divided into several steps?",
                    "label": 0
                },
                {
                    "sent": "First, we use the Bible net to identify those are not in the Wikipedia, and also interesting me.",
                    "label": 0
                },
                {
                    "sent": "We have some.",
                    "label": 0
                },
                {
                    "sent": "English transform English.",
                    "label": 0
                },
                {
                    "sent": "English translations of certain Chinese words, and we can use this kind of resource to linked from Jimmy to other existing datasets.",
                    "label": 0
                },
                {
                    "sent": "How large is this fraction?",
                    "label": 0
                },
                {
                    "sent": "Actually?",
                    "label": 0
                },
                {
                    "sent": "It is not so large currently, but in the near near updates as I talk about the Chinese symptoms linking procedures we are trying used sequence to sequence module to overcome.",
                    "label": 0
                },
                {
                    "sent": "This this difficulties.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "Hi I wanted to ask if Lemon Ontology covers all the intricacies of Chinese language.",
                    "label": 0
                },
                {
                    "sent": "Are there some for example grammatical phenomenon that you that you cannot really model though is it?",
                    "label": 0
                },
                {
                    "sent": "Is it sufficient for you?",
                    "label": 0
                },
                {
                    "sent": "To use lemma ontologies, we found we actually found some problems when it applied it to the Chinese resources.",
                    "label": 0
                },
                {
                    "sent": "So when we do this work, we we designed different language codes to represent the specific Chinese terms that what we do different to the Lemon Ontology.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}