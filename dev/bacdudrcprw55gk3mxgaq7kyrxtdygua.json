{
    "id": "bacdudrcprw55gk3mxgaq7kyrxtdygua",
    "title": "A Compact In-Memory Dictionary for RDF data",
    "info": {
        "author": [
            "Hamid R. Bazoobandi, Department of Computer Science, Vrije Universiteit Amsterdam (VU)"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_bazoobandi_rdf_data/",
    "segmentation": [
        [
            "OK, so I'm going to give it talk about our research in making a compact in memory dictionary for RDF data."
        ],
        [
            "So many almost all of existing art.",
            "If applications use a simple trick, but simple yet effective trick is called a dictionary encoding to compress the data.",
            "So the idea here is very simple.",
            "Replacing long string representation of terms with short numerical IDs.",
            "And thank you.",
            "So this is very effective method because these numerical ideas usually occupy much less space both on disk or in memory than this long string representation of terms.",
            "So this effective method can compress the data considerably, but we have to note that dictionary encoding is used to compress the data, but the dictionary itself is usually not compressed.",
            "And actually there are reports from cases where the size of dictionary is even larger than the whole size of encoded data, so this is a serious issue.",
            "And therefore it's been studied recently."
        ],
        [
            "For instance, a popular cases the depart of HD, which is a complex dictionary and we just saw that.",
            "So we analyze the size of HTT and you see that it's doing pretty good job in compressing the dictionary.",
            "And.",
            "But we have to keep in mind that.",
            "The fact that it's doing it's compressing the dictionary so well is that it's doing this on the static data, so the whole data is available when you process or recompress the dictionary."
        ],
        [
            "But the problem of dictionary size is less important for applications that work with static data, because they usually do the dictionary encoding and decoding as preprocessing and postprocessing phases.",
            "So they take the whole data and then they compress it.",
            "They encode the data and then upload the dictionary on disk and then do the actual processing or the encoded data.",
            "And then after the processing is over, they decode it.",
            "In the post processing phase, but this problem becomes much more interesting when we have we are working with dynamic or stream of data.",
            "So for such applications the problem becomes much worse because they have to maintain the dictionary because they have to apply frequent updates to the dictionary and therefore they have to keep the dictionary in memory to be able to apply these changes.",
            "So there the size of dictionary can become a major limitation for the amount of data that we can process on a single machine."
        ],
        [
            "So the goal of this research was to create a compact dictionary.",
            "A foreigner use cases that supports frequent updates.",
            "And."
        ],
        [
            "To do that, we had two ideas.",
            "First, minimize overhead of data structure that we are using.",
            "And possibly minimize the number of data structures that is used in the structure of dictionary and 2nd.",
            "Minimize the storage of common prefixes so we all know that artist terms are full of common prefixes and by common prefix I mean that.",
            "The prefixes that appear more than once in more than one term."
        ],
        [
            "We did kind of study about how much we can gain if we.",
            "Now minimize the storage of common prefixes, so in this figure, what you see is how much of.",
            "The total space that is needed to store all unique terms in this datasets is occupied by prefixes that appear more than once, so the results are promising.",
            "We see that we can actually gain a lot of compression.",
            "Or memory saving if we minimize the storage of this.",
            "Common prefixes.",
            "And what is especially interesting is that this common prefixes are not limited to.",
            "I rise as many people think, but we see that actually we can gain the same almost similar compression if we apply that on literal as well.",
            "So."
        ],
        [
            "So based on that we decided to use trie data structure for building a compact inner dictionary.",
            "Trees are usually used in this kind of cases, and there are interesting data structures they have.",
            "Of course many names.",
            "Some people like to call it radics tree or prefix tree, but we use the Tri as a general term.",
            "So they have many interesting features, but we are particularly interested in two features.",
            "One is the fact that keys are stored in tries implicitly rather than explicitly, and if you don't understand this, I come back to this soon and then the fact that insertion and lookup operations in try data structures are.",
            "Proportional like the time complexity, is proportional to the length of the string and independent.",
            "Of the number of items that are stored in the try.",
            "So this is a very interesting feature."
        ],
        [
            "Um so.",
            "Here is an example that I want to show.",
            "So we have two strings and we want to store them in a try this standard dry.",
            "So in Tri each.",
            "Generally each node is essentially an array of pointers.",
            "And we use the.",
            "Each character of the string as an index in this pointer to find the next note.",
            "For instance, here we use A and we find the pointer we go to B use B as index find.",
            "Then next node and the same for the second string.",
            "So these two strings share a common prefix, and that is a.",
            "And as you can see, they also share the node that represents a.",
            "So this simple example is showing 2 interesting features.",
            "First, keys are not stored explicitly, rather.",
            "The pointers that are followed in the data structure represent the keys.",
            "And also these two string that share.",
            "A part of the string they share.",
            "Also part of the path that they follow, so prefixes automatically.",
            "The common prefix is automatically stored only once.",
            "And the other very interesting feature of this data structure is that if we traverse this data structure upward, we can reconstruct the keys in the time complexity that is proportional to the length of the string.",
            "So this is also very interesting, so the idea that we have is to use this data structure for building compact dictionary.",
            "And we use this data structure both for encoding and decoding.",
            "So because we limit our work only in in memory use cases.",
            "We decided to map each string not to a calculated ID, but to the pointer or the memory address of the last node in the try.",
            "So for example, in this case we map ABC, not to calculate ID but to the memory address of the last node in the Tri.",
            "So when we dereference that pointer we get to that node and through upward travel so we can reconstruct the.",
            "String so this way we eliminate the decoding data structure and therefore we compacted data the whole dictionary.",
            "And also this features structure helps us in minimizing the storage of common prefixes.",
            "But the problem that we had with this data structure is that tries are extremely bad in memory efficiency.",
            "This is especially because you see in this picture that only few pointers are used, so we have this long pointer arrays, but most of them are unused.",
            "So this problem becomes a lot worse when we.",
            "We have large tries.",
            "There are a bunch of up."
        ],
        [
            "Positions that people proposed for this one is called path compression and the other one is called lazy expansion.",
            "So the oral idea is that if a node has only one child, it has to be merged with this child to reduce the number of nodes in the Tri.",
            "We call such a try compact try."
        ],
        [
            "So we analyze the memory efficiency of compact try and it is disappointing.",
            "You see that when we store RDF data in a compact try less than 2% of pointers are actually used, so 98% percent of pointers.",
            "Were left on you so it is like very bad memory efficiency so there is no way that we can use."
        ],
        [
            "This so we went to more advanced data structures like adaptive Radix trie which is more recent in 2013.",
            "So the idea of this data structure that is it adaptively changes the size of pointer arrays to minimize the number of unused pointers.",
            "And we stored already."
        ],
        [
            "Design it and we found that it actually significantly improves the more efficiency, but still less than half of pointers are used, so that is also not going to help us with building anything compact."
        ],
        [
            "We also considered using Burst try which is hybrid.",
            "Try data structure it has.",
            "Some try nodes and some least know linked list to minimize the number of unused pointer the problem and also there is also this hat trie which uses hash tables instead of linked lists.",
            "And it is also more compact and also faster.",
            "But the problem with this data structure is its content constantly restructures itself, therefore the pointers to nodes constantly change.",
            "Then we cannot return any pointer as an ID because these pointers are constantly changing, so we cannot use this.",
            "For unifying the encoding and decoding data structure, if we were going to use any of these two data structures, we need to have a decoding data structure independent of the encoding data structure.",
            "So we decided not to use this as well.",
            "So we were running out of ideas at some point."
        ],
        [
            "Until we stumbled over this prehistoric data structure, it is proposing a paper written in 1959.",
            "And the the idea of this try is that it.",
            "It's not using pointer arrays for keeping track of children, it's using linkedlist instead, so it is very efficient because it has no unused pointers.",
            "But it is also extremely slow in general cases, so we need an example like quick test.",
            "With this we store the lower case English words in an alphabet.",
            "In this, try and compare the performance and memory efficiency compact try.",
            "So it turned out actually that this data structure was more than two times slower.",
            "Even for this short English words, but it uses 6 times less memory.",
            "So.",
            "It's not surprising that no one is using this.",
            "But we thought that this data structure has all the features that we want, so it if we try to traverse the data structure upward, we can reconstruct the keys.",
            "We can return the pointers.",
            "In the in this data structured only problem is is very slow.",
            "So maybe we could find a way to solve this problem."
        ],
        [
            "So we check the number of children in each try.",
            "Note we found that actually most of nodes in the Tri have only few children, so you see that for something around 60%.",
            "They have less than four children, so for such cases it doesn't really matter what data structure using that performance will be generally good, but there are also few nodes that have more than they have.",
            "Let's say a lot of children.",
            "So we had to find a solution for those cases, unfortunately."
        ],
        [
            "One of the key features of RDF data, and that's the high level of skewness, can help us with this, so we all know that RDF terms or art if data is highly skewed, meaning that few patterns.",
            "Appear a lot of times in the data, so with that in mind we we decided to do a very trivial, simple trick which would be really effective in this case, and that is called a move to front policy so that."
        ],
        [
            "Data structure that we decided to use at the end was a compact list.",
            "Try which is.",
            "We apply the path compression and lazy expansion optimization onelist try and also we added this move to front policy.",
            "So we move the last accessed children to the front of the list.",
            "Therefore after few iterations.",
            "The front nodes of the list become populated with more popular.",
            "Notes.",
            "So this was a data structure we use.",
            "We had to also overcome another."
        ],
        [
            "Challenge which was making sure that if we assign a pointer to one string after the restructure of the paper, every structure of the try that pointer is still valid.",
            "So I'm not going to all the details about this, but you can find them in the paper."
        ],
        [
            "So then we implement this data structure in Java.",
            "We also implemented.",
            "Conventional dictionary, as we call it.",
            "In Java we used new throw hashtable for implementing the conventional Java.",
            "We use the default configuration for the hash table.",
            "And then we analyze the memory efficiency and the performance.",
            "So as you see in this picture, by the way, we call the our Implementation artist Vault.",
            "So you see that the the memory consumption of our default is considerably less.",
            "For example, in case of DV PEDIA or billion people challenge the whole memory that our default consumes is.",
            "Less than the overall memory consumption of strings in.",
            "Conventional dictionary, so we really.",
            "This is really compact dictionary."
        ],
        [
            "And also it is interesting to see that.",
            "We actually managed to compress literals as well.",
            "So in case of even literals we have good compactness.",
            "Um?",
            "So."
        ],
        [
            "And in terms of performance.",
            "Encoding performance is our default is really competitive and in case of bioportal it encodes data even faster than conventional dictionary.",
            "But in terms of decoding we are slower.",
            "So the conventional dictionary is.",
            "Faster than our default, but the you have to consider that if we just talk about theory, these two data structures have equal time complexity for.",
            "In for decoding because in terms of conventional dictionary, it is just a single hash look up, therefore it has to calculate the hash code and it is ON complexity and in terms of.",
            "Our default we have to concatenate the string because we have to traverse the Tri up Ward and therefore both have all in complexity for retrieving the data.",
            "But it turns out in practice that concatenating strings is a lot more time consuming that then.",
            "Hashcode calculation so maybe in the future with more optimized string concatenation we can.",
            "I do better with the code."
        ],
        [
            "And also we analyze the effectiveness of this simple trick move to front policy.",
            "So as you see here, if we disable this feature, suddenly the encoding performance drops up to three times or more than three times.",
            "So this hypothesis that highest cuteness of RDF data can really help us using this slow data structure and make it fast is really important.",
            "So it's doing.",
            "This simple trick is working quite good for us."
        ],
        [
            "So in conclusion.",
            "We aimed at building a compact.",
            "In memory dictionary for RDF data, we decided to use trie data structure for doing this.",
            "And we analyzed many existing.",
            "Try implementations and designs and at the end we realize that an abandoned and almost dead data structure can work best for us.",
            "But if we use the unique features and characteristics of RDF data.",
            "So the code of our work is available online, so if you're planning to use any string processing or doing any dynamic artist processing, please do use it and let others know about that.",
            "So that's it.",
            "And if you have any comments or questions, I'm more than happy to answer.",
            "Do we have?",
            "Yes, we do have questions.",
            "Yeah, well, I am very interesting with work so I know that you are focused more on Dynamic City, but have you test the performance on this page results with some compression statically like HTT.",
            "Well, actually I worked a lot with HTT and but.",
            "You mean in terms of performance?",
            "Well in terms of space.",
            "If you look at this, of course we cannot compete over them.",
            "That's a good point because we cannot compete with static data compression because.",
            "There you have all the data available.",
            "You can do all this clustering, like in HTT you use.",
            "Play things in this for section dictionary and.",
            "So we cannot do anything.",
            "We can't make any assumption about the data, so definitely the the confirmation that we have here is a lot worse.",
            "I think the if you have this interesting thing here.",
            "Well here, so you see that HD part of HTT is doing quite a good job in compressing, so we cannot reach that point.",
            "It's compared to the unique terms.",
            "But you see, it's like 2 times less than the.",
            "Unique terms, so it's doing a lot better than what we do, so it's just for dynamic and stream.",
            "Pressing actually is a strongly related to the previous question.",
            "I see we've been using Milton front.",
            "That is one of the methods employed were in some non dictionary based systems like along with Burrows, Wheeler, Transform's and run length encoding.",
            "So was wondering if you're looking forward.",
            "You also tried bringing in some other non strictly database methods for stream processing.",
            "I assume Burrows Wheeler cannot apply to stream process data right?",
            "Yes, I've been trying others like run length and Huffman tables, maybe, maybe not.",
            "Well, it's it's a matter of actually we did some tests with to try to compress the text more.",
            "Especially because we usually have this small portion of each string stored in a node.",
            "So we thought even about compressing that small portion of the string.",
            "But The thing is, because they are usually very small text, then these techniques don't really work that much, but they add a lot of overhead, so we were almost, you know, we wanted to have a good tradeoff between performance and the space.",
            "Efficiency, so you're right, we can add more compression techniques which help definitely to reach better compression, but we since we target dynamic and stream processing then the performance also matters a lot, so we try to find the balance between these two.",
            "But I totally agree with you.",
            "We can use those techniques as well, but we didn't implement.",
            "We just implemented one.",
            "I don't remember which one was.",
            "Further, it considerably slowed down everything, so we just dropped the project.",
            "Looking forward to it.",
            "Anyway, thank you.",
            "So very nice work.",
            "Thanks a lot.",
            "So my question is, do you have any thoughts if you can still improve the coding part or if I if we can tweak somehow your structure to like sacrifice a bit memory consumption for performance you mean the coding?",
            "Perform decoding performs well, actually I did my best to optimize this string concatenation because that is the main part.",
            "And.",
            "I I don't know if that's just a problem with Java or something else, but or maybe just hash tables are too fast in calculating so with a lot of work and improving that we wrote exotic code now just 24.",
            "The for concatenating string, but still it's not as fast as hashcode calculation, so I don't know.",
            "Maybe if we implement this in C we can use some CPU features for improving this, But in Java we're almost done with that.",
            "Yeah, nice lights in last night's presentation, thanks.",
            "It seems to me that the decoding complexity won't be or N because you would have a linear search at each level of the tree of user list.",
            "Now we added actually direct pointer for parents so it is not.",
            "It's not going through the list anymore so it just goes directly to upper level and so it's all in essentially because it has to.",
            "It just gets the last part, concatenates with the water.",
            "As an the parents, we have a direct link to the parent so it is slow and so we don't go through the list anymore.",
            "Is it doesn't answer your question.",
            "OK.",
            "Yes, I'll ask questions regarding the IDs because usually when once you have the ideas used for something to code the graph or something.",
            "So for instance, for us it's important the range of ideas.",
            "So as you are you have pointers to the memory, so I guess the let's say the length of the of the rent and also the lens of the printer is quite beef.",
            "Can you give some work that is actually a valid point so?",
            "The idea is that we have their reference or pointers, so if we consider that in C or in also in Java, I think there are 8 bytes.",
            "So that is true that if we you have if you calculate ideas, you can give, let's say to popular terms.",
            "Very small ideas and then you can do all this bitmap compression to compress the results.",
            "So in this case we can do that, but you have to keep in mind that the in C the in theory pointers are 8 bytes but the CPU is not using all the 8 bytes, so they only use five bites of that.",
            "And therefore three bites.",
            "You can easily zero out of that, and you have only 5 bytes left.",
            "With that.",
            "The only thing we can't do is to assign lower values to more popular terms, which is.",
            "I think for some people it's a high cost to pay.",
            "Uh, but we decided to do that anyway and also.",
            "We thought that for large amounts of data we have enough terms to fill 5 bytes.",
            "So I understand your concern, but I think this is a reasonable price to pay for that.",
            "I have on my question did you study?",
            "The effect of the order in which you at this idea of terms into the dictionary that does that.",
            "Does this have an effect?",
            "Yes, that definitely has an effect, so we use the natural order.",
            "So the order in which the terms appeared in.",
            "In the data.",
            "So if we the closer the order becomes too sorted threefold sorted terms, the faster the algorithm becomes, so the coding performance is we're talking only about encoding performance, so decoding performance results, so it's independent of the order in this is independent of how many items we have.",
            "It's the result doesn't change, but encoding performance if the results if the data is sorted it becomes.",
            "Extremely fast.",
            "It becomes even faster than hash table I think.",
            "But if we shuffle around everything.",
            "Then the results become something around 30 to 40% slower.",
            "So if the random is totally shuffle, if the order is totally shuffled on random.",
            "Yes, does it have an effect on the memories that's required?",
            "I don't think so, no.",
            "It's just the order of trie data.",
            "Structure is always the same, so.",
            "It's independent of how you insert terms in it.",
            "Any other questions?",
            "OK so thanks, thanks to the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to give it talk about our research in making a compact in memory dictionary for RDF data.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So many almost all of existing art.",
                    "label": 0
                },
                {
                    "sent": "If applications use a simple trick, but simple yet effective trick is called a dictionary encoding to compress the data.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is very simple.",
                    "label": 0
                },
                {
                    "sent": "Replacing long string representation of terms with short numerical IDs.",
                    "label": 0
                },
                {
                    "sent": "And thank you.",
                    "label": 0
                },
                {
                    "sent": "So this is very effective method because these numerical ideas usually occupy much less space both on disk or in memory than this long string representation of terms.",
                    "label": 0
                },
                {
                    "sent": "So this effective method can compress the data considerably, but we have to note that dictionary encoding is used to compress the data, but the dictionary itself is usually not compressed.",
                    "label": 1
                },
                {
                    "sent": "And actually there are reports from cases where the size of dictionary is even larger than the whole size of encoded data, so this is a serious issue.",
                    "label": 0
                },
                {
                    "sent": "And therefore it's been studied recently.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For instance, a popular cases the depart of HD, which is a complex dictionary and we just saw that.",
                    "label": 0
                },
                {
                    "sent": "So we analyze the size of HTT and you see that it's doing pretty good job in compressing the dictionary.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "But we have to keep in mind that.",
                    "label": 0
                },
                {
                    "sent": "The fact that it's doing it's compressing the dictionary so well is that it's doing this on the static data, so the whole data is available when you process or recompress the dictionary.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the problem of dictionary size is less important for applications that work with static data, because they usually do the dictionary encoding and decoding as preprocessing and postprocessing phases.",
                    "label": 0
                },
                {
                    "sent": "So they take the whole data and then they compress it.",
                    "label": 0
                },
                {
                    "sent": "They encode the data and then upload the dictionary on disk and then do the actual processing or the encoded data.",
                    "label": 0
                },
                {
                    "sent": "And then after the processing is over, they decode it.",
                    "label": 0
                },
                {
                    "sent": "In the post processing phase, but this problem becomes much more interesting when we have we are working with dynamic or stream of data.",
                    "label": 0
                },
                {
                    "sent": "So for such applications the problem becomes much worse because they have to maintain the dictionary because they have to apply frequent updates to the dictionary and therefore they have to keep the dictionary in memory to be able to apply these changes.",
                    "label": 1
                },
                {
                    "sent": "So there the size of dictionary can become a major limitation for the amount of data that we can process on a single machine.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal of this research was to create a compact dictionary.",
                    "label": 1
                },
                {
                    "sent": "A foreigner use cases that supports frequent updates.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do that, we had two ideas.",
                    "label": 0
                },
                {
                    "sent": "First, minimize overhead of data structure that we are using.",
                    "label": 1
                },
                {
                    "sent": "And possibly minimize the number of data structures that is used in the structure of dictionary and 2nd.",
                    "label": 1
                },
                {
                    "sent": "Minimize the storage of common prefixes so we all know that artist terms are full of common prefixes and by common prefix I mean that.",
                    "label": 0
                },
                {
                    "sent": "The prefixes that appear more than once in more than one term.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We did kind of study about how much we can gain if we.",
                    "label": 0
                },
                {
                    "sent": "Now minimize the storage of common prefixes, so in this figure, what you see is how much of.",
                    "label": 1
                },
                {
                    "sent": "The total space that is needed to store all unique terms in this datasets is occupied by prefixes that appear more than once, so the results are promising.",
                    "label": 0
                },
                {
                    "sent": "We see that we can actually gain a lot of compression.",
                    "label": 0
                },
                {
                    "sent": "Or memory saving if we minimize the storage of this.",
                    "label": 1
                },
                {
                    "sent": "Common prefixes.",
                    "label": 1
                },
                {
                    "sent": "And what is especially interesting is that this common prefixes are not limited to.",
                    "label": 0
                },
                {
                    "sent": "I rise as many people think, but we see that actually we can gain the same almost similar compression if we apply that on literal as well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So based on that we decided to use trie data structure for building a compact inner dictionary.",
                    "label": 0
                },
                {
                    "sent": "Trees are usually used in this kind of cases, and there are interesting data structures they have.",
                    "label": 0
                },
                {
                    "sent": "Of course many names.",
                    "label": 0
                },
                {
                    "sent": "Some people like to call it radics tree or prefix tree, but we use the Tri as a general term.",
                    "label": 0
                },
                {
                    "sent": "So they have many interesting features, but we are particularly interested in two features.",
                    "label": 0
                },
                {
                    "sent": "One is the fact that keys are stored in tries implicitly rather than explicitly, and if you don't understand this, I come back to this soon and then the fact that insertion and lookup operations in try data structures are.",
                    "label": 0
                },
                {
                    "sent": "Proportional like the time complexity, is proportional to the length of the string and independent.",
                    "label": 1
                },
                {
                    "sent": "Of the number of items that are stored in the try.",
                    "label": 1
                },
                {
                    "sent": "So this is a very interesting feature.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um so.",
                    "label": 0
                },
                {
                    "sent": "Here is an example that I want to show.",
                    "label": 0
                },
                {
                    "sent": "So we have two strings and we want to store them in a try this standard dry.",
                    "label": 0
                },
                {
                    "sent": "So in Tri each.",
                    "label": 0
                },
                {
                    "sent": "Generally each node is essentially an array of pointers.",
                    "label": 0
                },
                {
                    "sent": "And we use the.",
                    "label": 0
                },
                {
                    "sent": "Each character of the string as an index in this pointer to find the next note.",
                    "label": 0
                },
                {
                    "sent": "For instance, here we use A and we find the pointer we go to B use B as index find.",
                    "label": 0
                },
                {
                    "sent": "Then next node and the same for the second string.",
                    "label": 0
                },
                {
                    "sent": "So these two strings share a common prefix, and that is a.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, they also share the node that represents a.",
                    "label": 0
                },
                {
                    "sent": "So this simple example is showing 2 interesting features.",
                    "label": 0
                },
                {
                    "sent": "First, keys are not stored explicitly, rather.",
                    "label": 0
                },
                {
                    "sent": "The pointers that are followed in the data structure represent the keys.",
                    "label": 0
                },
                {
                    "sent": "And also these two string that share.",
                    "label": 0
                },
                {
                    "sent": "A part of the string they share.",
                    "label": 0
                },
                {
                    "sent": "Also part of the path that they follow, so prefixes automatically.",
                    "label": 0
                },
                {
                    "sent": "The common prefix is automatically stored only once.",
                    "label": 0
                },
                {
                    "sent": "And the other very interesting feature of this data structure is that if we traverse this data structure upward, we can reconstruct the keys in the time complexity that is proportional to the length of the string.",
                    "label": 0
                },
                {
                    "sent": "So this is also very interesting, so the idea that we have is to use this data structure for building compact dictionary.",
                    "label": 0
                },
                {
                    "sent": "And we use this data structure both for encoding and decoding.",
                    "label": 0
                },
                {
                    "sent": "So because we limit our work only in in memory use cases.",
                    "label": 0
                },
                {
                    "sent": "We decided to map each string not to a calculated ID, but to the pointer or the memory address of the last node in the try.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this case we map ABC, not to calculate ID but to the memory address of the last node in the Tri.",
                    "label": 0
                },
                {
                    "sent": "So when we dereference that pointer we get to that node and through upward travel so we can reconstruct the.",
                    "label": 0
                },
                {
                    "sent": "String so this way we eliminate the decoding data structure and therefore we compacted data the whole dictionary.",
                    "label": 0
                },
                {
                    "sent": "And also this features structure helps us in minimizing the storage of common prefixes.",
                    "label": 0
                },
                {
                    "sent": "But the problem that we had with this data structure is that tries are extremely bad in memory efficiency.",
                    "label": 1
                },
                {
                    "sent": "This is especially because you see in this picture that only few pointers are used, so we have this long pointer arrays, but most of them are unused.",
                    "label": 0
                },
                {
                    "sent": "So this problem becomes a lot worse when we.",
                    "label": 0
                },
                {
                    "sent": "We have large tries.",
                    "label": 0
                },
                {
                    "sent": "There are a bunch of up.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Positions that people proposed for this one is called path compression and the other one is called lazy expansion.",
                    "label": 1
                },
                {
                    "sent": "So the oral idea is that if a node has only one child, it has to be merged with this child to reduce the number of nodes in the Tri.",
                    "label": 0
                },
                {
                    "sent": "We call such a try compact try.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we analyze the memory efficiency of compact try and it is disappointing.",
                    "label": 1
                },
                {
                    "sent": "You see that when we store RDF data in a compact try less than 2% of pointers are actually used, so 98% percent of pointers.",
                    "label": 0
                },
                {
                    "sent": "Were left on you so it is like very bad memory efficiency so there is no way that we can use.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This so we went to more advanced data structures like adaptive Radix trie which is more recent in 2013.",
                    "label": 0
                },
                {
                    "sent": "So the idea of this data structure that is it adaptively changes the size of pointer arrays to minimize the number of unused pointers.",
                    "label": 0
                },
                {
                    "sent": "And we stored already.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Design it and we found that it actually significantly improves the more efficiency, but still less than half of pointers are used, so that is also not going to help us with building anything compact.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also considered using Burst try which is hybrid.",
                    "label": 0
                },
                {
                    "sent": "Try data structure it has.",
                    "label": 0
                },
                {
                    "sent": "Some try nodes and some least know linked list to minimize the number of unused pointer the problem and also there is also this hat trie which uses hash tables instead of linked lists.",
                    "label": 0
                },
                {
                    "sent": "And it is also more compact and also faster.",
                    "label": 0
                },
                {
                    "sent": "But the problem with this data structure is its content constantly restructures itself, therefore the pointers to nodes constantly change.",
                    "label": 0
                },
                {
                    "sent": "Then we cannot return any pointer as an ID because these pointers are constantly changing, so we cannot use this.",
                    "label": 0
                },
                {
                    "sent": "For unifying the encoding and decoding data structure, if we were going to use any of these two data structures, we need to have a decoding data structure independent of the encoding data structure.",
                    "label": 0
                },
                {
                    "sent": "So we decided not to use this as well.",
                    "label": 0
                },
                {
                    "sent": "So we were running out of ideas at some point.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Until we stumbled over this prehistoric data structure, it is proposing a paper written in 1959.",
                    "label": 0
                },
                {
                    "sent": "And the the idea of this try is that it.",
                    "label": 0
                },
                {
                    "sent": "It's not using pointer arrays for keeping track of children, it's using linkedlist instead, so it is very efficient because it has no unused pointers.",
                    "label": 0
                },
                {
                    "sent": "But it is also extremely slow in general cases, so we need an example like quick test.",
                    "label": 0
                },
                {
                    "sent": "With this we store the lower case English words in an alphabet.",
                    "label": 0
                },
                {
                    "sent": "In this, try and compare the performance and memory efficiency compact try.",
                    "label": 0
                },
                {
                    "sent": "So it turned out actually that this data structure was more than two times slower.",
                    "label": 0
                },
                {
                    "sent": "Even for this short English words, but it uses 6 times less memory.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's not surprising that no one is using this.",
                    "label": 1
                },
                {
                    "sent": "But we thought that this data structure has all the features that we want, so it if we try to traverse the data structure upward, we can reconstruct the keys.",
                    "label": 0
                },
                {
                    "sent": "We can return the pointers.",
                    "label": 1
                },
                {
                    "sent": "In the in this data structured only problem is is very slow.",
                    "label": 0
                },
                {
                    "sent": "So maybe we could find a way to solve this problem.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we check the number of children in each try.",
                    "label": 0
                },
                {
                    "sent": "Note we found that actually most of nodes in the Tri have only few children, so you see that for something around 60%.",
                    "label": 0
                },
                {
                    "sent": "They have less than four children, so for such cases it doesn't really matter what data structure using that performance will be generally good, but there are also few nodes that have more than they have.",
                    "label": 0
                },
                {
                    "sent": "Let's say a lot of children.",
                    "label": 0
                },
                {
                    "sent": "So we had to find a solution for those cases, unfortunately.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the key features of RDF data, and that's the high level of skewness, can help us with this, so we all know that RDF terms or art if data is highly skewed, meaning that few patterns.",
                    "label": 0
                },
                {
                    "sent": "Appear a lot of times in the data, so with that in mind we we decided to do a very trivial, simple trick which would be really effective in this case, and that is called a move to front policy so that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data structure that we decided to use at the end was a compact list.",
                    "label": 1
                },
                {
                    "sent": "Try which is.",
                    "label": 0
                },
                {
                    "sent": "We apply the path compression and lazy expansion optimization onelist try and also we added this move to front policy.",
                    "label": 0
                },
                {
                    "sent": "So we move the last accessed children to the front of the list.",
                    "label": 0
                },
                {
                    "sent": "Therefore after few iterations.",
                    "label": 0
                },
                {
                    "sent": "The front nodes of the list become populated with more popular.",
                    "label": 0
                },
                {
                    "sent": "Notes.",
                    "label": 0
                },
                {
                    "sent": "So this was a data structure we use.",
                    "label": 0
                },
                {
                    "sent": "We had to also overcome another.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Challenge which was making sure that if we assign a pointer to one string after the restructure of the paper, every structure of the try that pointer is still valid.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to all the details about this, but you can find them in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we implement this data structure in Java.",
                    "label": 0
                },
                {
                    "sent": "We also implemented.",
                    "label": 0
                },
                {
                    "sent": "Conventional dictionary, as we call it.",
                    "label": 0
                },
                {
                    "sent": "In Java we used new throw hashtable for implementing the conventional Java.",
                    "label": 0
                },
                {
                    "sent": "We use the default configuration for the hash table.",
                    "label": 0
                },
                {
                    "sent": "And then we analyze the memory efficiency and the performance.",
                    "label": 0
                },
                {
                    "sent": "So as you see in this picture, by the way, we call the our Implementation artist Vault.",
                    "label": 0
                },
                {
                    "sent": "So you see that the the memory consumption of our default is considerably less.",
                    "label": 0
                },
                {
                    "sent": "For example, in case of DV PEDIA or billion people challenge the whole memory that our default consumes is.",
                    "label": 0
                },
                {
                    "sent": "Less than the overall memory consumption of strings in.",
                    "label": 0
                },
                {
                    "sent": "Conventional dictionary, so we really.",
                    "label": 0
                },
                {
                    "sent": "This is really compact dictionary.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also it is interesting to see that.",
                    "label": 0
                },
                {
                    "sent": "We actually managed to compress literals as well.",
                    "label": 0
                },
                {
                    "sent": "So in case of even literals we have good compactness.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in terms of performance.",
                    "label": 0
                },
                {
                    "sent": "Encoding performance is our default is really competitive and in case of bioportal it encodes data even faster than conventional dictionary.",
                    "label": 0
                },
                {
                    "sent": "But in terms of decoding we are slower.",
                    "label": 0
                },
                {
                    "sent": "So the conventional dictionary is.",
                    "label": 0
                },
                {
                    "sent": "Faster than our default, but the you have to consider that if we just talk about theory, these two data structures have equal time complexity for.",
                    "label": 0
                },
                {
                    "sent": "In for decoding because in terms of conventional dictionary, it is just a single hash look up, therefore it has to calculate the hash code and it is ON complexity and in terms of.",
                    "label": 0
                },
                {
                    "sent": "Our default we have to concatenate the string because we have to traverse the Tri up Ward and therefore both have all in complexity for retrieving the data.",
                    "label": 0
                },
                {
                    "sent": "But it turns out in practice that concatenating strings is a lot more time consuming that then.",
                    "label": 0
                },
                {
                    "sent": "Hashcode calculation so maybe in the future with more optimized string concatenation we can.",
                    "label": 0
                },
                {
                    "sent": "I do better with the code.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we analyze the effectiveness of this simple trick move to front policy.",
                    "label": 0
                },
                {
                    "sent": "So as you see here, if we disable this feature, suddenly the encoding performance drops up to three times or more than three times.",
                    "label": 0
                },
                {
                    "sent": "So this hypothesis that highest cuteness of RDF data can really help us using this slow data structure and make it fast is really important.",
                    "label": 0
                },
                {
                    "sent": "So it's doing.",
                    "label": 0
                },
                {
                    "sent": "This simple trick is working quite good for us.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion.",
                    "label": 0
                },
                {
                    "sent": "We aimed at building a compact.",
                    "label": 0
                },
                {
                    "sent": "In memory dictionary for RDF data, we decided to use trie data structure for doing this.",
                    "label": 0
                },
                {
                    "sent": "And we analyzed many existing.",
                    "label": 0
                },
                {
                    "sent": "Try implementations and designs and at the end we realize that an abandoned and almost dead data structure can work best for us.",
                    "label": 0
                },
                {
                    "sent": "But if we use the unique features and characteristics of RDF data.",
                    "label": 0
                },
                {
                    "sent": "So the code of our work is available online, so if you're planning to use any string processing or doing any dynamic artist processing, please do use it and let others know about that.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "And if you have any comments or questions, I'm more than happy to answer.",
                    "label": 0
                },
                {
                    "sent": "Do we have?",
                    "label": 0
                },
                {
                    "sent": "Yes, we do have questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, I am very interesting with work so I know that you are focused more on Dynamic City, but have you test the performance on this page results with some compression statically like HTT.",
                    "label": 0
                },
                {
                    "sent": "Well, actually I worked a lot with HTT and but.",
                    "label": 0
                },
                {
                    "sent": "You mean in terms of performance?",
                    "label": 0
                },
                {
                    "sent": "Well in terms of space.",
                    "label": 0
                },
                {
                    "sent": "If you look at this, of course we cannot compete over them.",
                    "label": 0
                },
                {
                    "sent": "That's a good point because we cannot compete with static data compression because.",
                    "label": 0
                },
                {
                    "sent": "There you have all the data available.",
                    "label": 0
                },
                {
                    "sent": "You can do all this clustering, like in HTT you use.",
                    "label": 0
                },
                {
                    "sent": "Play things in this for section dictionary and.",
                    "label": 0
                },
                {
                    "sent": "So we cannot do anything.",
                    "label": 0
                },
                {
                    "sent": "We can't make any assumption about the data, so definitely the the confirmation that we have here is a lot worse.",
                    "label": 0
                },
                {
                    "sent": "I think the if you have this interesting thing here.",
                    "label": 0
                },
                {
                    "sent": "Well here, so you see that HD part of HTT is doing quite a good job in compressing, so we cannot reach that point.",
                    "label": 0
                },
                {
                    "sent": "It's compared to the unique terms.",
                    "label": 0
                },
                {
                    "sent": "But you see, it's like 2 times less than the.",
                    "label": 0
                },
                {
                    "sent": "Unique terms, so it's doing a lot better than what we do, so it's just for dynamic and stream.",
                    "label": 0
                },
                {
                    "sent": "Pressing actually is a strongly related to the previous question.",
                    "label": 0
                },
                {
                    "sent": "I see we've been using Milton front.",
                    "label": 0
                },
                {
                    "sent": "That is one of the methods employed were in some non dictionary based systems like along with Burrows, Wheeler, Transform's and run length encoding.",
                    "label": 0
                },
                {
                    "sent": "So was wondering if you're looking forward.",
                    "label": 0
                },
                {
                    "sent": "You also tried bringing in some other non strictly database methods for stream processing.",
                    "label": 0
                },
                {
                    "sent": "I assume Burrows Wheeler cannot apply to stream process data right?",
                    "label": 0
                },
                {
                    "sent": "Yes, I've been trying others like run length and Huffman tables, maybe, maybe not.",
                    "label": 0
                },
                {
                    "sent": "Well, it's it's a matter of actually we did some tests with to try to compress the text more.",
                    "label": 0
                },
                {
                    "sent": "Especially because we usually have this small portion of each string stored in a node.",
                    "label": 0
                },
                {
                    "sent": "So we thought even about compressing that small portion of the string.",
                    "label": 0
                },
                {
                    "sent": "But The thing is, because they are usually very small text, then these techniques don't really work that much, but they add a lot of overhead, so we were almost, you know, we wanted to have a good tradeoff between performance and the space.",
                    "label": 0
                },
                {
                    "sent": "Efficiency, so you're right, we can add more compression techniques which help definitely to reach better compression, but we since we target dynamic and stream processing then the performance also matters a lot, so we try to find the balance between these two.",
                    "label": 0
                },
                {
                    "sent": "But I totally agree with you.",
                    "label": 0
                },
                {
                    "sent": "We can use those techniques as well, but we didn't implement.",
                    "label": 0
                },
                {
                    "sent": "We just implemented one.",
                    "label": 0
                },
                {
                    "sent": "I don't remember which one was.",
                    "label": 0
                },
                {
                    "sent": "Further, it considerably slowed down everything, so we just dropped the project.",
                    "label": 0
                },
                {
                    "sent": "Looking forward to it.",
                    "label": 0
                },
                {
                    "sent": "Anyway, thank you.",
                    "label": 0
                },
                {
                    "sent": "So very nice work.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot.",
                    "label": 0
                },
                {
                    "sent": "So my question is, do you have any thoughts if you can still improve the coding part or if I if we can tweak somehow your structure to like sacrifice a bit memory consumption for performance you mean the coding?",
                    "label": 0
                },
                {
                    "sent": "Perform decoding performs well, actually I did my best to optimize this string concatenation because that is the main part.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I I don't know if that's just a problem with Java or something else, but or maybe just hash tables are too fast in calculating so with a lot of work and improving that we wrote exotic code now just 24.",
                    "label": 0
                },
                {
                    "sent": "The for concatenating string, but still it's not as fast as hashcode calculation, so I don't know.",
                    "label": 0
                },
                {
                    "sent": "Maybe if we implement this in C we can use some CPU features for improving this, But in Java we're almost done with that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, nice lights in last night's presentation, thanks.",
                    "label": 0
                },
                {
                    "sent": "It seems to me that the decoding complexity won't be or N because you would have a linear search at each level of the tree of user list.",
                    "label": 0
                },
                {
                    "sent": "Now we added actually direct pointer for parents so it is not.",
                    "label": 0
                },
                {
                    "sent": "It's not going through the list anymore so it just goes directly to upper level and so it's all in essentially because it has to.",
                    "label": 0
                },
                {
                    "sent": "It just gets the last part, concatenates with the water.",
                    "label": 0
                },
                {
                    "sent": "As an the parents, we have a direct link to the parent so it is slow and so we don't go through the list anymore.",
                    "label": 0
                },
                {
                    "sent": "Is it doesn't answer your question.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Yes, I'll ask questions regarding the IDs because usually when once you have the ideas used for something to code the graph or something.",
                    "label": 0
                },
                {
                    "sent": "So for instance, for us it's important the range of ideas.",
                    "label": 0
                },
                {
                    "sent": "So as you are you have pointers to the memory, so I guess the let's say the length of the of the rent and also the lens of the printer is quite beef.",
                    "label": 0
                },
                {
                    "sent": "Can you give some work that is actually a valid point so?",
                    "label": 0
                },
                {
                    "sent": "The idea is that we have their reference or pointers, so if we consider that in C or in also in Java, I think there are 8 bytes.",
                    "label": 0
                },
                {
                    "sent": "So that is true that if we you have if you calculate ideas, you can give, let's say to popular terms.",
                    "label": 0
                },
                {
                    "sent": "Very small ideas and then you can do all this bitmap compression to compress the results.",
                    "label": 0
                },
                {
                    "sent": "So in this case we can do that, but you have to keep in mind that the in C the in theory pointers are 8 bytes but the CPU is not using all the 8 bytes, so they only use five bites of that.",
                    "label": 0
                },
                {
                    "sent": "And therefore three bites.",
                    "label": 0
                },
                {
                    "sent": "You can easily zero out of that, and you have only 5 bytes left.",
                    "label": 0
                },
                {
                    "sent": "With that.",
                    "label": 0
                },
                {
                    "sent": "The only thing we can't do is to assign lower values to more popular terms, which is.",
                    "label": 0
                },
                {
                    "sent": "I think for some people it's a high cost to pay.",
                    "label": 0
                },
                {
                    "sent": "Uh, but we decided to do that anyway and also.",
                    "label": 0
                },
                {
                    "sent": "We thought that for large amounts of data we have enough terms to fill 5 bytes.",
                    "label": 0
                },
                {
                    "sent": "So I understand your concern, but I think this is a reasonable price to pay for that.",
                    "label": 0
                },
                {
                    "sent": "I have on my question did you study?",
                    "label": 0
                },
                {
                    "sent": "The effect of the order in which you at this idea of terms into the dictionary that does that.",
                    "label": 0
                },
                {
                    "sent": "Does this have an effect?",
                    "label": 0
                },
                {
                    "sent": "Yes, that definitely has an effect, so we use the natural order.",
                    "label": 0
                },
                {
                    "sent": "So the order in which the terms appeared in.",
                    "label": 0
                },
                {
                    "sent": "In the data.",
                    "label": 0
                },
                {
                    "sent": "So if we the closer the order becomes too sorted threefold sorted terms, the faster the algorithm becomes, so the coding performance is we're talking only about encoding performance, so decoding performance results, so it's independent of the order in this is independent of how many items we have.",
                    "label": 0
                },
                {
                    "sent": "It's the result doesn't change, but encoding performance if the results if the data is sorted it becomes.",
                    "label": 0
                },
                {
                    "sent": "Extremely fast.",
                    "label": 0
                },
                {
                    "sent": "It becomes even faster than hash table I think.",
                    "label": 0
                },
                {
                    "sent": "But if we shuffle around everything.",
                    "label": 0
                },
                {
                    "sent": "Then the results become something around 30 to 40% slower.",
                    "label": 0
                },
                {
                    "sent": "So if the random is totally shuffle, if the order is totally shuffled on random.",
                    "label": 0
                },
                {
                    "sent": "Yes, does it have an effect on the memories that's required?",
                    "label": 0
                },
                {
                    "sent": "I don't think so, no.",
                    "label": 0
                },
                {
                    "sent": "It's just the order of trie data.",
                    "label": 0
                },
                {
                    "sent": "Structure is always the same, so.",
                    "label": 0
                },
                {
                    "sent": "It's independent of how you insert terms in it.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK so thanks, thanks to the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}