{
    "id": "4y4dmwrfdu4t3gp7zzlxhiuvawym7r7g",
    "title": "RDFS Reasoning on Massively Parallel Hardware",
    "info": {
        "author": [
            "Norman Heino, University of Leipzig"
        ],
        "published": "Dec. 3, 2012",
        "recorded": "November 2012",
        "category": [
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework"
        ]
    },
    "url": "http://videolectures.net/iswc2012_heino_parallel_hardware/",
    "segmentation": [
        [
            "Yeah, hello, my name is Norman.",
            "I'm from Leipsic and I would like to present the joint work I did with Jeff Pan from Aberdeen, in which we tackled the problem of RDS reasoning on massively parallel hardware."
        ],
        [
            "Short recap on what is RDF S and how can you reason with it?",
            "Or if it is a lightweight ontology language and.",
            "If you start to interpret this vocabulary, then you can create actually new troubles and it is defined in the RDF semantics document and also there is defined a set of rules that you can use which is unfortunately incomplete.",
            "If you apply to a standard RDF graph, but there is an easy solution if you just allow a more general definition of graphs in which you allow blank nodes at the predicate precision, then you can.",
            "Actually make the set of rules complete.",
            "In this."
        ],
        [
            "Work we do not use all of the rules that are given in the specification we.",
            "Use only those rules that have exactly 2 antecedents."
        ],
        [
            "And this is what they are.",
            "We in in particular, really."
        ],
        [
            "Without rules with trivial entailments, which means rules that only have a single antecedent and can be computed in linear time."
        ],
        [
            "We also leave out non authorative statements by which we mean statements whose subject is from the F4 or F's vocabulary.",
            "This has is unfortunately forgotten in the paper and has already caused some confusion.",
            "And this is also."
        ],
        [
            "And in the literature we obtain our results.",
            "By not including the axiomatic triples, and, in particular because we don't use the.",
            "Containing membership property, which is which is only a single antecedent, we don't need the infinite number of.",
            "Axiomatic container membership triples.",
            "So if you look a bit closer, those rules we can actually make our two different kinds of rules that I have grouped here in the upper and lower part in the upper Part, Rule 5 and 11, they actually compute the transitive closure of the property.",
            "Which are the property of in the subclass of properties?",
            "And in the lower part we have rules that compute something like a database join.",
            "If you look for instance April 2.",
            "Where we complete a joint between the predicate of a.",
            "Instance triple on the left and this subject of a schema triple.",
            "And this is also true for Rule 3 and seven.",
            "Andrew 9 is a bit different.",
            "There we compute the drawing between the object of a.",
            "Instance triple and the subject of a schema triple again.",
            "Now if you look at Rule 7.",
            "It's a bit tricky because.",
            "It can actually produce arbitrary triples.",
            "So there are a few special case."
        ],
        [
            "This.",
            "We've called them 71274 and they are actually different in what kind of data you apply to the rule.",
            "Is it either pure instance triples or or it's some form of properties from the schema vocabulary which we call language properties in this case.",
            "So Route 7 one and two.",
            "Are actually non authorative."
        ],
        [
            "So we don't deal with them in this work.",
            "Rule 7 Four is the simple case with only instance triples.",
            "Which is also unproblematic, but we need.",
            "To pay special attention to the third case, and I will come to back in a minute."
        ],
        [
            "In a minute.",
            "Now if you look at parallel or if it's freezing in the literature, it has already been done for quite some time."
        ],
        [
            "There are basically two camps.",
            "One is that people have used large clusters of commodity hardware to perform reasoning and as important work from or Bonnie at all who used a map reduce.",
            "He used the map reduce framework on a cluster of compute nodes.",
            "Then Cody implemented or if it's freezing on top of a distributed hash table and we were in Handler, did it on a peer network.",
            "There's also some."
        ],
        [
            "Work in the high performance computing.",
            "World.",
            "Which was done by Goodman and Mizell in 2010 and they implemented audio freezing on the massively parallel Cray XMT supercomputer.",
            "Now in our work, would we want to focus on this actually?",
            "Taking the best of both worlds."
        ],
        [
            "This means we want to use massively parallel hardware, but we don't want to do some supercomputer with commodity hardware, and it's the GPU, the graphics card, which is highly parallel at the in modern hardware.",
            "And the challenge there is to develop an algorithm such that it allows for fine grained parallelism.",
            "That is that this can exploit this hardware."
        ],
        [
            "We want to base our implementation open CL or it is based on open CL which is a vendor agnostic.",
            "Platform and model for heterogeneous parallel computation.",
            "It has been standardized, but Khronos Group, which is also known for Open GL, another graphics related standards.",
            "It is a well defined memory model.",
            "Which I will explain in a second.",
            "And this memory model webmaps very well to the GPU.",
            "But the nice thing about oversee Ellis that it also runs on Jelly beans, which means standard PC hardware and the compute kernels in open CL are written in a C 99 subset."
        ],
        [
            "And parallel programs are.",
            "Implemented in device so called device kernels that run on the specialized hardware or on the parallel hardware and the host program is used to drive these kernels.",
            "Um?",
            "An open CL, an running instance of such a kernel is called a work item.",
            "And work items can be grouped into work groups.",
            "And all of the items in Workgroup have access to some low latency local memory.",
            "Which is only shared between the workgroup and also there's some global memory to which all the items have access algorithm with a higher latency.",
            "The typical size of such a workgroup is not 16, is in this graphic, it's rather 128 or 22156.",
            "One important thing is that in open CL on the device there is no dynamic memory management.",
            "That means all the memory that you need in the kernel needs to be allocated before the kernel is invoked."
        ],
        [
            "The big picture of our approach."
        ],
        [
            "First, we do the parsing, of course."
        ],
        [
            "Then we encode all the values using a dictionary in which we assign in between.",
            "Give each term which is an issuer Ind string rather 64 bit integer.",
            "This serves for.",
            "So we have each value has a fixed length, and so we can implement similar data structures.",
            "It allows first faster comparison and also we do some form of compression because integers are typically but smaller than strings.",
            "We then."
        ],
        [
            "Store all the values in a custom in memory store views.",
            "Actually one C++ vector per column and by column I mean single array of all the subjects of all triples or predicates or objects.",
            "We store something that is quite similar to what.",
            "Column stores put on the disk actually.",
            "And this allows us to do a cache efficient retrieval of the whole column at once, because we only need single columns.",
            "I'm for the reasoning.",
            "And we index our.",
            "Storage in a hashtable that is indexed by the whole triple.",
            "So concrete we can relatively quickly determine whether it triples already there or not."
        ],
        [
            "Then we need to copy the data.",
            "To the device over the PCI Express bus."
        ],
        [
            "We run a rule on the device and we."
        ],
        [
            "Copy the results back.",
            "Install the results and the last three points are actually repeated for each of the rules, or for each of those rules that one device."
        ],
        [
            "This is how our roots are implemented.",
            "So.",
            "We have basically 4 passes.",
            "Be combined with five and 7:00 and 9:11 and we will run with two and three separately.",
            "This is based actually on the rule ordering that was found by Ronnie.",
            "We did a little modification here.",
            "We do the fixed point iteration with five and seven in order to account for this special case that I mentioned for Rule 7, the.",
            "7 three.",
            "That I mentioned earlier and.",
            "Actually, Rule 3 and two could be run in parallel because they are independent of one another.",
            "But if you have enough triples to fill the device, you don't need to run at the same time.",
            "The."
        ],
        [
            "Transitive closure based rules, which is 5 and 11.",
            "Are implemented.",
            "Or in parallel are typically implemented using the washer algorithm, which runs in quadratic time critic space truly cubic time, but that's in our case infeasible because if you look at, for instance, Jago core.",
            "Which has like about 360,000 vertices taking part in this subclass of relation.",
            "But only three about 3.4 million in the full subclass of closure.",
            "But the quadratic matrix has about 130 billion entries, so that would be a huge waste of space and actually infusible.",
            "And in the case of Yagor.",
            "So what we do is we use.",
            "Implementation proposed by new dealer.",
            "From the 90s and it's run is running serial on the host."
        ],
        [
            "The join rules.",
            "Are actually running on the device.",
            "And.",
            "In open CL, it's a way that each thread is assigned a global identifier, which also proposes a scheduling order, and we use that identifier too.",
            "To assign a single triple to each thread.",
            "Then we create a hash table from the schema triples that we want to match against, and so each thread just needs to compute the hash of the.",
            "Term that it wants to match against, which is the predicate or the object, and then look up in the hash table to find.",
            "Whether there's a Metro or not.",
            "Now, as you can see in the lower picture, this is an example of our hash hash table and she can see some buckets can actually contain more than one value.",
            "So we would need to materialize three triples in this case.",
            "But as I said earlier in open CL.",
            "There's no dynamic memory management, so this would not be possible.",
            "So what we actually do is we perform the those rules in two passes.",
            "We in the first pass we actually count the, so each thread only stores the number of triples it would produce, and thereafter we count all them can allocate the memory on the host and then in the second pass the triples are materialized.",
            "If you would do it like this."
        ],
        [
            "We would have maybe slight problem because in RFS.",
            "There are a lot of duplicates.",
            "So if you look for instance at line four and eight.",
            "Of this example graph, and if we apply Rule 2 to it.",
            "We would create."
        ],
        [
            "Triple that A is an instance of C three times, and that's because the in decedent of the rule actually exists three times in the data.",
            "So.",
            "Since this rule.",
            "These duplicates are created by the same rule we call them local duplicates.",
            "If we."
        ],
        [
            "Now look at Line 6 and 8.",
            "And together with Rule 5.",
            "We would entail something similar to line 8, but replace the property with R, and if you then thereafter combine it with line 5 and apply Rule 2.",
            "We would entail.",
            "That is also an instance of D three times.",
            "And if you then."
        ],
        [
            "Apply Rule 9 to everything we would entail.",
            "Again, that is an instance of type of the.",
            "So in this case the duplicate is actually.",
            "Because.",
            "It's actually a duplicate because it was already created by some other rule and these kind of duplicates we call global duplicates.",
            "In order to understand the problem a bit."
        ],
        [
            "Better we looked at two datasets.",
            "Then we computed the duplicates for each of the rules.",
            "And as you can see, with two and three.",
            "Are actually diverse in both datasets, so in for ya go for DBP for instance.",
            "Word two creates 20 times as much.",
            "Duplicates as it creates unique triples.",
            "And forward three.",
            "It's about 9 times as much."
        ],
        [
            "So we want to focus on these two rules.",
            "By devising two schemes, how we can actually deal?"
        ],
        [
            "So for the global rules.",
            "What we actually need is for each thread we need some global knowledge about all the duplicates that have been created by other rules and we do it by safe storing a hash table on the device in global memory.",
            "That contains each of the triples that have been created by previous rules, and so each thread before it materializes.",
            "It's true, but it just looks in the hash table and determines whether it should material something or not.",
            "No, because writes to the global memory in open CS cannot be synchronized.",
            "This hashtable is static, so there are no updates during a during a run of the single rule."
        ],
        [
            "For local duplicates, dealing with them is actually a bit more involved.",
            "We remove them after they have been materialized, but still on the device in parallel.",
            "And we do that by actually counting adjacent duplicates.",
            "By having each thread look at its neighbor neighbors value and counting the number of times they both equal.",
            "And then we calculate a new index for each value that it would have.",
            "If it would not be preceded by any duplicates.",
            "And thereafter we just zero of the duplicates and rearranged the unique values."
        ],
        [
            "So here's a short example of how this works."
        ],
        [
            "We start with a simple vector and these are just integers, but imagine it would be triples.",
            "So we have here a number of public.",
            "It's the first thing we do."
        ],
        [
            "So we sort them.",
            "And this vector I call D. Then we have each thread look at its neighbor and write a one."
        ],
        [
            "To an index vector, if the value of the neighbors actually the same.",
            "Then we compute a. Prefix sum"
        ],
        [
            "Over this index vector and that means that we compute the sum.",
            "Starting from the lowest index.",
            "And at each index we write the sum of.",
            "Indexes at lower precisions.",
            "And we use.",
            "We use this vector.",
            "To rearrange the data and what we actually want to have is."
        ],
        [
            "That on each.",
            "Index in the result vector.",
            "We want to have the.",
            "Value from vector D at position I.",
            "Plus the.",
            "Value from the index vector at Ki.",
            "If.",
            "The computed index is smaller than the.",
            "Then the number of items in the vector and 0 otherwise.",
            "So what we end up with."
        ],
        [
            "Is.",
            "This nicely laid out data and we don't have any duplicates.",
            "So that's where we want it.",
            "In order to.",
            "Evaluate our approach."
        ],
        [
            "We have performed some experiments.",
            "And to study scalability, we have used a.",
            "Four CPU server with 32.",
            "Course or compute units in open CL parlance we have.",
            "In the second experiment, we wanted to study the efficacy.",
            "Of our.",
            "Typically room with the strategies and in the third experiment we want to compare with previous work."
        ],
        [
            "So these are the datasets that we used.",
            "We used the from DB pedia.",
            "We compiled something from with about 60 million 26 million triples.",
            "Which entails 1.7 new closure triples from yoga 2 core.",
            "We get used 36 million triples.",
            "And the closure contains 46 million new triples.",
            "And we scale both data sets to 1/2, one 4th, one 8th and 116th of the size of the index triples and combine them with all of this of the schema trends in each case."
        ],
        [
            "Yeah Dave results for the first experiment.",
            "On the left, Procede pedia on the right.",
            "We see ya go.",
            "And this up to 16 cores.",
            "It looks really nice.",
            "But then there's something interesting happening.",
            "If you use 32 cores, it actually gets a little bit slower and one possible explanation for this is that the even though we were using AMD CPU here, they also have something similar to the Hyperthreading feature in Intel processors where disappear two cores actually share some CPU resources.",
            "And.",
            "It might be, I think, an MD.",
            "They share the fetch unit and so if we have quite simple instructions that can be executed in this in a single cycle, then the fetch unit actually congests because the true cores are faster than fetching it can fetch new instructions.",
            "This."
        ],
        [
            "Experiment.",
            "We compared all of our.",
            "Duplicate remove the strategies and we can see that the local strategy.",
            "Is a.",
            "A.",
            "Increases their counter running time on the device.",
            "By about four to seven times.",
            "But at the same time, is able to reduce the applicants by 13 or 10%."
        ],
        [
            "To compare with previous work, we performed the experiments done by Damasio last years I Subsea.",
            "And also, Interestingly, the T6 was performed by were Bonnie on the map reduce cluster, but since this is a really small data set.",
            "We were actually faster than reproduce because the only overhead of this framework, so it would actually be only useful to compare with this in a much huger data set, but it doesn't fit in our in memory storage.",
            "So last."
        ],
        [
            "We also compared running times on CPU and GPU and as you can see the kernel execution time is actually quite faster, about five times as fast as on the CPU, but it does not translate to faster execution in total, and that's partly because we need to copy the data over the PCI bus.",
            "And also because RFS reason turns out to have a.",
            "Quite low eluta fetch ratio, so to conclude."
        ],
        [
            "We were able to perform artifacts raising massively in parallel, albeit with some limitations.",
            "We were able to use shared memory efficiently for removing duplicates and below eluta factory ratio of or EFS reason is actually in favorable for GPU devices.",
            "For future work we want to try and compress data so that we can improve on the time that is needed for copying over the PCI bus.",
            "We want to try to run on several devices at the same time.",
            "One idea would be to perform reasoning on.",
            "Using the FPU by kind of annotating all the triples with some float data.",
            "And we would like to.",
            "Provide a actually compute implementation with respect to the audience.",
            "Standard semantics.",
            "Thank you, thank you for that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, hello, my name is Norman.",
                    "label": 0
                },
                {
                    "sent": "I'm from Leipsic and I would like to present the joint work I did with Jeff Pan from Aberdeen, in which we tackled the problem of RDS reasoning on massively parallel hardware.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Short recap on what is RDF S and how can you reason with it?",
                    "label": 0
                },
                {
                    "sent": "Or if it is a lightweight ontology language and.",
                    "label": 0
                },
                {
                    "sent": "If you start to interpret this vocabulary, then you can create actually new troubles and it is defined in the RDF semantics document and also there is defined a set of rules that you can use which is unfortunately incomplete.",
                    "label": 1
                },
                {
                    "sent": "If you apply to a standard RDF graph, but there is an easy solution if you just allow a more general definition of graphs in which you allow blank nodes at the predicate precision, then you can.",
                    "label": 0
                },
                {
                    "sent": "Actually make the set of rules complete.",
                    "label": 0
                },
                {
                    "sent": "In this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work we do not use all of the rules that are given in the specification we.",
                    "label": 0
                },
                {
                    "sent": "Use only those rules that have exactly 2 antecedents.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what they are.",
                    "label": 0
                },
                {
                    "sent": "We in in particular, really.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Without rules with trivial entailments, which means rules that only have a single antecedent and can be computed in linear time.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also leave out non authorative statements by which we mean statements whose subject is from the F4 or F's vocabulary.",
                    "label": 0
                },
                {
                    "sent": "This has is unfortunately forgotten in the paper and has already caused some confusion.",
                    "label": 0
                },
                {
                    "sent": "And this is also.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in the literature we obtain our results.",
                    "label": 0
                },
                {
                    "sent": "By not including the axiomatic triples, and, in particular because we don't use the.",
                    "label": 0
                },
                {
                    "sent": "Containing membership property, which is which is only a single antecedent, we don't need the infinite number of.",
                    "label": 0
                },
                {
                    "sent": "Axiomatic container membership triples.",
                    "label": 0
                },
                {
                    "sent": "So if you look a bit closer, those rules we can actually make our two different kinds of rules that I have grouped here in the upper and lower part in the upper Part, Rule 5 and 11, they actually compute the transitive closure of the property.",
                    "label": 1
                },
                {
                    "sent": "Which are the property of in the subclass of properties?",
                    "label": 1
                },
                {
                    "sent": "And in the lower part we have rules that compute something like a database join.",
                    "label": 0
                },
                {
                    "sent": "If you look for instance April 2.",
                    "label": 1
                },
                {
                    "sent": "Where we complete a joint between the predicate of a.",
                    "label": 0
                },
                {
                    "sent": "Instance triple on the left and this subject of a schema triple.",
                    "label": 0
                },
                {
                    "sent": "And this is also true for Rule 3 and seven.",
                    "label": 1
                },
                {
                    "sent": "Andrew 9 is a bit different.",
                    "label": 0
                },
                {
                    "sent": "There we compute the drawing between the object of a.",
                    "label": 1
                },
                {
                    "sent": "Instance triple and the subject of a schema triple again.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at Rule 7.",
                    "label": 0
                },
                {
                    "sent": "It's a bit tricky because.",
                    "label": 0
                },
                {
                    "sent": "It can actually produce arbitrary triples.",
                    "label": 0
                },
                {
                    "sent": "So there are a few special case.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "We've called them 71274 and they are actually different in what kind of data you apply to the rule.",
                    "label": 0
                },
                {
                    "sent": "Is it either pure instance triples or or it's some form of properties from the schema vocabulary which we call language properties in this case.",
                    "label": 0
                },
                {
                    "sent": "So Route 7 one and two.",
                    "label": 0
                },
                {
                    "sent": "Are actually non authorative.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we don't deal with them in this work.",
                    "label": 0
                },
                {
                    "sent": "Rule 7 Four is the simple case with only instance triples.",
                    "label": 0
                },
                {
                    "sent": "Which is also unproblematic, but we need.",
                    "label": 0
                },
                {
                    "sent": "To pay special attention to the third case, and I will come to back in a minute.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a minute.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at parallel or if it's freezing in the literature, it has already been done for quite some time.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are basically two camps.",
                    "label": 0
                },
                {
                    "sent": "One is that people have used large clusters of commodity hardware to perform reasoning and as important work from or Bonnie at all who used a map reduce.",
                    "label": 0
                },
                {
                    "sent": "He used the map reduce framework on a cluster of compute nodes.",
                    "label": 0
                },
                {
                    "sent": "Then Cody implemented or if it's freezing on top of a distributed hash table and we were in Handler, did it on a peer network.",
                    "label": 0
                },
                {
                    "sent": "There's also some.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work in the high performance computing.",
                    "label": 0
                },
                {
                    "sent": "World.",
                    "label": 0
                },
                {
                    "sent": "Which was done by Goodman and Mizell in 2010 and they implemented audio freezing on the massively parallel Cray XMT supercomputer.",
                    "label": 1
                },
                {
                    "sent": "Now in our work, would we want to focus on this actually?",
                    "label": 0
                },
                {
                    "sent": "Taking the best of both worlds.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This means we want to use massively parallel hardware, but we don't want to do some supercomputer with commodity hardware, and it's the GPU, the graphics card, which is highly parallel at the in modern hardware.",
                    "label": 0
                },
                {
                    "sent": "And the challenge there is to develop an algorithm such that it allows for fine grained parallelism.",
                    "label": 0
                },
                {
                    "sent": "That is that this can exploit this hardware.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We want to base our implementation open CL or it is based on open CL which is a vendor agnostic.",
                    "label": 0
                },
                {
                    "sent": "Platform and model for heterogeneous parallel computation.",
                    "label": 1
                },
                {
                    "sent": "It has been standardized, but Khronos Group, which is also known for Open GL, another graphics related standards.",
                    "label": 0
                },
                {
                    "sent": "It is a well defined memory model.",
                    "label": 0
                },
                {
                    "sent": "Which I will explain in a second.",
                    "label": 0
                },
                {
                    "sent": "And this memory model webmaps very well to the GPU.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing about oversee Ellis that it also runs on Jelly beans, which means standard PC hardware and the compute kernels in open CL are written in a C 99 subset.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And parallel programs are.",
                    "label": 0
                },
                {
                    "sent": "Implemented in device so called device kernels that run on the specialized hardware or on the parallel hardware and the host program is used to drive these kernels.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "An open CL, an running instance of such a kernel is called a work item.",
                    "label": 1
                },
                {
                    "sent": "And work items can be grouped into work groups.",
                    "label": 1
                },
                {
                    "sent": "And all of the items in Workgroup have access to some low latency local memory.",
                    "label": 0
                },
                {
                    "sent": "Which is only shared between the workgroup and also there's some global memory to which all the items have access algorithm with a higher latency.",
                    "label": 0
                },
                {
                    "sent": "The typical size of such a workgroup is not 16, is in this graphic, it's rather 128 or 22156.",
                    "label": 0
                },
                {
                    "sent": "One important thing is that in open CL on the device there is no dynamic memory management.",
                    "label": 0
                },
                {
                    "sent": "That means all the memory that you need in the kernel needs to be allocated before the kernel is invoked.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The big picture of our approach.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, we do the parsing, of course.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we encode all the values using a dictionary in which we assign in between.",
                    "label": 0
                },
                {
                    "sent": "Give each term which is an issuer Ind string rather 64 bit integer.",
                    "label": 0
                },
                {
                    "sent": "This serves for.",
                    "label": 0
                },
                {
                    "sent": "So we have each value has a fixed length, and so we can implement similar data structures.",
                    "label": 0
                },
                {
                    "sent": "It allows first faster comparison and also we do some form of compression because integers are typically but smaller than strings.",
                    "label": 0
                },
                {
                    "sent": "We then.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Store all the values in a custom in memory store views.",
                    "label": 0
                },
                {
                    "sent": "Actually one C++ vector per column and by column I mean single array of all the subjects of all triples or predicates or objects.",
                    "label": 1
                },
                {
                    "sent": "We store something that is quite similar to what.",
                    "label": 0
                },
                {
                    "sent": "Column stores put on the disk actually.",
                    "label": 0
                },
                {
                    "sent": "And this allows us to do a cache efficient retrieval of the whole column at once, because we only need single columns.",
                    "label": 0
                },
                {
                    "sent": "I'm for the reasoning.",
                    "label": 0
                },
                {
                    "sent": "And we index our.",
                    "label": 0
                },
                {
                    "sent": "Storage in a hashtable that is indexed by the whole triple.",
                    "label": 1
                },
                {
                    "sent": "So concrete we can relatively quickly determine whether it triples already there or not.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we need to copy the data.",
                    "label": 0
                },
                {
                    "sent": "To the device over the PCI Express bus.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We run a rule on the device and we.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Copy the results back.",
                    "label": 0
                },
                {
                    "sent": "Install the results and the last three points are actually repeated for each of the rules, or for each of those rules that one device.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is how our roots are implemented.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have basically 4 passes.",
                    "label": 0
                },
                {
                    "sent": "Be combined with five and 7:00 and 9:11 and we will run with two and three separately.",
                    "label": 0
                },
                {
                    "sent": "This is based actually on the rule ordering that was found by Ronnie.",
                    "label": 0
                },
                {
                    "sent": "We did a little modification here.",
                    "label": 0
                },
                {
                    "sent": "We do the fixed point iteration with five and seven in order to account for this special case that I mentioned for Rule 7, the.",
                    "label": 0
                },
                {
                    "sent": "7 three.",
                    "label": 0
                },
                {
                    "sent": "That I mentioned earlier and.",
                    "label": 0
                },
                {
                    "sent": "Actually, Rule 3 and two could be run in parallel because they are independent of one another.",
                    "label": 0
                },
                {
                    "sent": "But if you have enough triples to fill the device, you don't need to run at the same time.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transitive closure based rules, which is 5 and 11.",
                    "label": 0
                },
                {
                    "sent": "Are implemented.",
                    "label": 0
                },
                {
                    "sent": "Or in parallel are typically implemented using the washer algorithm, which runs in quadratic time critic space truly cubic time, but that's in our case infeasible because if you look at, for instance, Jago core.",
                    "label": 0
                },
                {
                    "sent": "Which has like about 360,000 vertices taking part in this subclass of relation.",
                    "label": 0
                },
                {
                    "sent": "But only three about 3.4 million in the full subclass of closure.",
                    "label": 0
                },
                {
                    "sent": "But the quadratic matrix has about 130 billion entries, so that would be a huge waste of space and actually infusible.",
                    "label": 0
                },
                {
                    "sent": "And in the case of Yagor.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we use.",
                    "label": 0
                },
                {
                    "sent": "Implementation proposed by new dealer.",
                    "label": 0
                },
                {
                    "sent": "From the 90s and it's run is running serial on the host.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The join rules.",
                    "label": 0
                },
                {
                    "sent": "Are actually running on the device.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In open CL, it's a way that each thread is assigned a global identifier, which also proposes a scheduling order, and we use that identifier too.",
                    "label": 0
                },
                {
                    "sent": "To assign a single triple to each thread.",
                    "label": 0
                },
                {
                    "sent": "Then we create a hash table from the schema triples that we want to match against, and so each thread just needs to compute the hash of the.",
                    "label": 0
                },
                {
                    "sent": "Term that it wants to match against, which is the predicate or the object, and then look up in the hash table to find.",
                    "label": 0
                },
                {
                    "sent": "Whether there's a Metro or not.",
                    "label": 0
                },
                {
                    "sent": "Now, as you can see in the lower picture, this is an example of our hash hash table and she can see some buckets can actually contain more than one value.",
                    "label": 0
                },
                {
                    "sent": "So we would need to materialize three triples in this case.",
                    "label": 1
                },
                {
                    "sent": "But as I said earlier in open CL.",
                    "label": 0
                },
                {
                    "sent": "There's no dynamic memory management, so this would not be possible.",
                    "label": 0
                },
                {
                    "sent": "So what we actually do is we perform the those rules in two passes.",
                    "label": 1
                },
                {
                    "sent": "We in the first pass we actually count the, so each thread only stores the number of triples it would produce, and thereafter we count all them can allocate the memory on the host and then in the second pass the triples are materialized.",
                    "label": 0
                },
                {
                    "sent": "If you would do it like this.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We would have maybe slight problem because in RFS.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of duplicates.",
                    "label": 0
                },
                {
                    "sent": "So if you look for instance at line four and eight.",
                    "label": 0
                },
                {
                    "sent": "Of this example graph, and if we apply Rule 2 to it.",
                    "label": 0
                },
                {
                    "sent": "We would create.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triple that A is an instance of C three times, and that's because the in decedent of the rule actually exists three times in the data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Since this rule.",
                    "label": 0
                },
                {
                    "sent": "These duplicates are created by the same rule we call them local duplicates.",
                    "label": 0
                },
                {
                    "sent": "If we.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now look at Line 6 and 8.",
                    "label": 0
                },
                {
                    "sent": "And together with Rule 5.",
                    "label": 0
                },
                {
                    "sent": "We would entail something similar to line 8, but replace the property with R, and if you then thereafter combine it with line 5 and apply Rule 2.",
                    "label": 0
                },
                {
                    "sent": "We would entail.",
                    "label": 0
                },
                {
                    "sent": "That is also an instance of D three times.",
                    "label": 0
                },
                {
                    "sent": "And if you then.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apply Rule 9 to everything we would entail.",
                    "label": 0
                },
                {
                    "sent": "Again, that is an instance of type of the.",
                    "label": 0
                },
                {
                    "sent": "So in this case the duplicate is actually.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                },
                {
                    "sent": "It's actually a duplicate because it was already created by some other rule and these kind of duplicates we call global duplicates.",
                    "label": 0
                },
                {
                    "sent": "In order to understand the problem a bit.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Better we looked at two datasets.",
                    "label": 0
                },
                {
                    "sent": "Then we computed the duplicates for each of the rules.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, with two and three.",
                    "label": 0
                },
                {
                    "sent": "Are actually diverse in both datasets, so in for ya go for DBP for instance.",
                    "label": 0
                },
                {
                    "sent": "Word two creates 20 times as much.",
                    "label": 0
                },
                {
                    "sent": "Duplicates as it creates unique triples.",
                    "label": 0
                },
                {
                    "sent": "And forward three.",
                    "label": 0
                },
                {
                    "sent": "It's about 9 times as much.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want to focus on these two rules.",
                    "label": 0
                },
                {
                    "sent": "By devising two schemes, how we can actually deal?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the global rules.",
                    "label": 0
                },
                {
                    "sent": "What we actually need is for each thread we need some global knowledge about all the duplicates that have been created by other rules and we do it by safe storing a hash table on the device in global memory.",
                    "label": 1
                },
                {
                    "sent": "That contains each of the triples that have been created by previous rules, and so each thread before it materializes.",
                    "label": 1
                },
                {
                    "sent": "It's true, but it just looks in the hash table and determines whether it should material something or not.",
                    "label": 0
                },
                {
                    "sent": "No, because writes to the global memory in open CS cannot be synchronized.",
                    "label": 1
                },
                {
                    "sent": "This hashtable is static, so there are no updates during a during a run of the single rule.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For local duplicates, dealing with them is actually a bit more involved.",
                    "label": 0
                },
                {
                    "sent": "We remove them after they have been materialized, but still on the device in parallel.",
                    "label": 0
                },
                {
                    "sent": "And we do that by actually counting adjacent duplicates.",
                    "label": 1
                },
                {
                    "sent": "By having each thread look at its neighbor neighbors value and counting the number of times they both equal.",
                    "label": 0
                },
                {
                    "sent": "And then we calculate a new index for each value that it would have.",
                    "label": 0
                },
                {
                    "sent": "If it would not be preceded by any duplicates.",
                    "label": 1
                },
                {
                    "sent": "And thereafter we just zero of the duplicates and rearranged the unique values.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a short example of how this works.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We start with a simple vector and these are just integers, but imagine it would be triples.",
                    "label": 0
                },
                {
                    "sent": "So we have here a number of public.",
                    "label": 0
                },
                {
                    "sent": "It's the first thing we do.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we sort them.",
                    "label": 0
                },
                {
                    "sent": "And this vector I call D. Then we have each thread look at its neighbor and write a one.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To an index vector, if the value of the neighbors actually the same.",
                    "label": 0
                },
                {
                    "sent": "Then we compute a. Prefix sum",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over this index vector and that means that we compute the sum.",
                    "label": 0
                },
                {
                    "sent": "Starting from the lowest index.",
                    "label": 0
                },
                {
                    "sent": "And at each index we write the sum of.",
                    "label": 0
                },
                {
                    "sent": "Indexes at lower precisions.",
                    "label": 0
                },
                {
                    "sent": "And we use.",
                    "label": 0
                },
                {
                    "sent": "We use this vector.",
                    "label": 0
                },
                {
                    "sent": "To rearrange the data and what we actually want to have is.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That on each.",
                    "label": 0
                },
                {
                    "sent": "Index in the result vector.",
                    "label": 0
                },
                {
                    "sent": "We want to have the.",
                    "label": 0
                },
                {
                    "sent": "Value from vector D at position I.",
                    "label": 0
                },
                {
                    "sent": "Plus the.",
                    "label": 0
                },
                {
                    "sent": "Value from the index vector at Ki.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                },
                {
                    "sent": "The computed index is smaller than the.",
                    "label": 0
                },
                {
                    "sent": "Then the number of items in the vector and 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "So what we end up with.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "This nicely laid out data and we don't have any duplicates.",
                    "label": 0
                },
                {
                    "sent": "So that's where we want it.",
                    "label": 0
                },
                {
                    "sent": "In order to.",
                    "label": 0
                },
                {
                    "sent": "Evaluate our approach.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have performed some experiments.",
                    "label": 0
                },
                {
                    "sent": "And to study scalability, we have used a.",
                    "label": 0
                },
                {
                    "sent": "Four CPU server with 32.",
                    "label": 1
                },
                {
                    "sent": "Course or compute units in open CL parlance we have.",
                    "label": 0
                },
                {
                    "sent": "In the second experiment, we wanted to study the efficacy.",
                    "label": 0
                },
                {
                    "sent": "Of our.",
                    "label": 0
                },
                {
                    "sent": "Typically room with the strategies and in the third experiment we want to compare with previous work.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are the datasets that we used.",
                    "label": 0
                },
                {
                    "sent": "We used the from DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We compiled something from with about 60 million 26 million triples.",
                    "label": 0
                },
                {
                    "sent": "Which entails 1.7 new closure triples from yoga 2 core.",
                    "label": 1
                },
                {
                    "sent": "We get used 36 million triples.",
                    "label": 0
                },
                {
                    "sent": "And the closure contains 46 million new triples.",
                    "label": 1
                },
                {
                    "sent": "And we scale both data sets to 1/2, one 4th, one 8th and 116th of the size of the index triples and combine them with all of this of the schema trends in each case.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah Dave results for the first experiment.",
                    "label": 0
                },
                {
                    "sent": "On the left, Procede pedia on the right.",
                    "label": 0
                },
                {
                    "sent": "We see ya go.",
                    "label": 0
                },
                {
                    "sent": "And this up to 16 cores.",
                    "label": 0
                },
                {
                    "sent": "It looks really nice.",
                    "label": 0
                },
                {
                    "sent": "But then there's something interesting happening.",
                    "label": 0
                },
                {
                    "sent": "If you use 32 cores, it actually gets a little bit slower and one possible explanation for this is that the even though we were using AMD CPU here, they also have something similar to the Hyperthreading feature in Intel processors where disappear two cores actually share some CPU resources.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It might be, I think, an MD.",
                    "label": 0
                },
                {
                    "sent": "They share the fetch unit and so if we have quite simple instructions that can be executed in this in a single cycle, then the fetch unit actually congests because the true cores are faster than fetching it can fetch new instructions.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiment.",
                    "label": 0
                },
                {
                    "sent": "We compared all of our.",
                    "label": 0
                },
                {
                    "sent": "Duplicate remove the strategies and we can see that the local strategy.",
                    "label": 0
                },
                {
                    "sent": "Is a.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "Increases their counter running time on the device.",
                    "label": 0
                },
                {
                    "sent": "By about four to seven times.",
                    "label": 0
                },
                {
                    "sent": "But at the same time, is able to reduce the applicants by 13 or 10%.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To compare with previous work, we performed the experiments done by Damasio last years I Subsea.",
                    "label": 0
                },
                {
                    "sent": "And also, Interestingly, the T6 was performed by were Bonnie on the map reduce cluster, but since this is a really small data set.",
                    "label": 0
                },
                {
                    "sent": "We were actually faster than reproduce because the only overhead of this framework, so it would actually be only useful to compare with this in a much huger data set, but it doesn't fit in our in memory storage.",
                    "label": 0
                },
                {
                    "sent": "So last.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also compared running times on CPU and GPU and as you can see the kernel execution time is actually quite faster, about five times as fast as on the CPU, but it does not translate to faster execution in total, and that's partly because we need to copy the data over the PCI bus.",
                    "label": 1
                },
                {
                    "sent": "And also because RFS reason turns out to have a.",
                    "label": 0
                },
                {
                    "sent": "Quite low eluta fetch ratio, so to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We were able to perform artifacts raising massively in parallel, albeit with some limitations.",
                    "label": 0
                },
                {
                    "sent": "We were able to use shared memory efficiently for removing duplicates and below eluta factory ratio of or EFS reason is actually in favorable for GPU devices.",
                    "label": 1
                },
                {
                    "sent": "For future work we want to try and compress data so that we can improve on the time that is needed for copying over the PCI bus.",
                    "label": 0
                },
                {
                    "sent": "We want to try to run on several devices at the same time.",
                    "label": 0
                },
                {
                    "sent": "One idea would be to perform reasoning on.",
                    "label": 0
                },
                {
                    "sent": "Using the FPU by kind of annotating all the triples with some float data.",
                    "label": 0
                },
                {
                    "sent": "And we would like to.",
                    "label": 0
                },
                {
                    "sent": "Provide a actually compute implementation with respect to the audience.",
                    "label": 0
                },
                {
                    "sent": "Standard semantics.",
                    "label": 0
                },
                {
                    "sent": "Thank you, thank you for that.",
                    "label": 0
                }
            ]
        }
    }
}