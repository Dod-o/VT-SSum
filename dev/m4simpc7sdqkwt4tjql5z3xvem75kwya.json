{
    "id": "m4simpc7sdqkwt4tjql5z3xvem75kwya",
    "title": "Cost-Sensitive Top-Down/Bottom-Up Inference for Multiscale Activity Recognition",
    "info": {
        "author": [
            "Mohamed Amer, Oregon State University"
        ],
        "chairman": [
            "Michael J. Black, Max Planck Institute for Intelligent Systems, Max Planck Institute",
            "Ivan Laptev, INRIA - The French National Institute for Research in Computer Science and Control"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Video Analysis"
        ]
    },
    "url": "http://videolectures.net/eccv2012_amer_recognition/",
    "segmentation": [
        [
            "This work is on activity.",
            "Recognition is done in collaboration with my advisor, professional Ravitch, and our collaborators in UCLA.",
            "Danjeon maintains a land function through."
        ],
        [
            "Our problem is defined as.",
            "Given high resolution video with many instances of people involved in individual actions and group activities.",
            "We would like to answer queries about what, where and when a group activity or individual action.",
            "At."
        ],
        [
            "Happens.",
            "Answering these queries in this domain becomes a very complex inference problem, and the video with this video resolution.",
            "It allows us to digital zoom in and zoom out, so zooming in to examine details and zooming out to examine context as needed for recognition.",
            "So for example, detecting group activity.",
            "I campus tour.",
            "We might want to zoom in on individuals talking or walking.",
            "And.",
            "For example, group of people standing in line we might want to zoom out to get the context, which is the food bus in this case."
        ],
        [
            "Our contributions are threefold.",
            "We have a new problem which is multi scale activity recognition which requires efficient activity or presentation inference and learning.",
            "We have a constant sensitive framework to be able to handle this large resolution videos.",
            "By rank them.",
            "Smallest amount of detectors.",
            "Since running all detectors would be prohibitively expensive.",
            "And we have collected a new data set that has multiple Co occurring activities.",
            "Since there are no other data sets that we are aware of that have this multiscale.",
            "High resolution.",
            "Activities."
        ],
        [
            "So prior work has handled the function or repetitive activities in.",
            "A single actor domain."
        ],
        [
            "Anna group domain.",
            "Also, structured activities where the structure is in the temporal aspect."
        ],
        [
            "For our approach, we use the unified hierarchal model.",
            "The model has to be expressive enough to be able to handle this wide range of activities and.",
            "Group activities individual actions.",
            "Also, since we are.",
            "Accounting for objects.",
            "So we have many things to model here.",
            "And we have interactions between human, human and human object.",
            "So we use and or graph since it's kept capable of representing all these activities and interactions.",
            "And our inferences made cost sensitive to efficiently detect and localize activities of interest using the minimum amount of detectors.",
            "As I mentioned before."
        ],
        [
            "So our approach builds up on.",
            "The work that has been done by Guanzhou in Ivy 1011.",
            "Where they use this work too.",
            "Detect faces since a phase consists of parts, eyes, nose and mouth.",
            "So in this case is very specific to face or an object.",
            "In our case it's more general since we handle three different semantic scales, which the first scale is a group activity as a second scale is individual actions and the third scale is object.",
            "Since the hierarchy of the Android graph, let us efficiently organize different semantic scales of the of our domain knowledge, we decide."
        ],
        [
            "Use and or graphs.",
            "And this is an overview of our model, so our model consists of terminal nodes, nonterminal nodes, edges and probabilities.",
            "Where?"
        ],
        [
            "Terminal nodes are the nodes that access pixels, so in this case will be our detectors and non terminal nodes such as the end or nodes in our graph.",
            "As for edges."
        ],
        [
            "Have three types of edges, edges connecting nodes of the same level.",
            "And edges connecting.",
            "And two hours and edges connected, or two ends where that decomposition edges ones connecting ends to or model particular configuration and switching edges which connect and or to an end.",
            "Models alternative configurations.",
            "And."
        ],
        [
            "Probabilities over all possible parts.",
            "Graphs where apart graph as I mentioned in this example, could be a tour group which consists of individual actors that are carrying, for example, backpacks."
        ],
        [
            "So our problem is.",
            "Having a world distribution all possible parts graph, we want to find all those.",
            "Parts graphs we assume that each parse graph is independent, then the other, and each of them is modeled as a Gibbs distribution.",
            "And the energy is a function of.",
            "All possible nodes and edges.",
            "Where again the edges are switching relational and decomposition."
        ],
        [
            "So I."
        ],
        [
            "And our inferences to find all possible parse graphs.",
            "And we simplify this problem by treating them independently and then concatenating.",
            "W the world distribution that we have.",
            "So using all the previous formulas, it's straightforward to derive."
        ],
        [
            "Log posterior over apart graph.",
            "I know this equation might look scary, but."
        ],
        [
            "I break it down to try to explain what's going on, so we have the structure which is.",
            "Or an endnote given and or node.",
            "And then we have."
        ],
        [
            "The theme is the current level.",
            "The current zoom level, the zoom in and zoom out, each of them has a detector associated with them that."
        ],
        [
            "Is connected at the terminal node."
        ],
        [
            "Then we have parent child relationships.",
            "This is.",
            "So we have a parent child relationship, an child, child relationship where we call the.",
            "The child child relationship as a beta process where it's bottom up binding of children.",
            "Two apparent and this is usually in the zoom in level.",
            "And the parent child is.",
            "It contributes to the likelihood of child of a node."
        ],
        [
            "Given experience, so having those three processes, we will recap on them.",
            "So Alpha is the process that runs a detector of an activity.",
            "Beta is a bottom up binding of parts of activity.",
            "An gamma is the top."
        ],
        [
            "One prediction of the children.",
            "So in the Alpha process we use three different detectors.",
            "At each level you can use any detectors, but we happen to choose those three.",
            "Since there is a."
        ],
        [
            "Of the art.",
            "As for the bit and gamma processes, we specify Gaussian distribution that models the location, scale and orientation.",
            "Offer the nodes of the relationship, but."
        ],
        [
            "The nodes where in the beta process we have child child relationship.",
            "So it's all pairs of."
        ],
        [
            "And.",
            "Connected to the parent and in the gamma process we have for each parent."
        ],
        [
            "To all the children it's connected to.",
            "Thought As for them.",
            "'cause like our inference is cost sensitive.",
            "So we decided to use a reinforcement based approach.",
            "Where we have an explore exploit strategy where here explore meaning run random detector and exploit means that run the detectors that has the best utility.",
            "Where we learned this utility for each detector at every node using Q.",
            "Learning to learn the optimal mover optimal detector to run."
        ],
        [
            "I'll walk you through an example so."
        ],
        [
            "This example we have an activity.",
            "Standing in line.",
            "I don't know if the image down there is clear, but.",
            "Let's follow through and see what will happen.",
            "So starting at the beginning our parse graph, the probability of the paragraph is zero since we don't have any detectors that we run.",
            "And we have maximum number of detectors to run a 7.",
            "So we limit our inference to exit this.",
            "Running detectors either when the path graph probability is high enough or when we don't have anymore detectors to run.",
            "So at this note we have.",
            "At this node we have four detectors that we could run of different activities.",
            "And with some certain utility that we have in the queue table.",
            "And then we flip a coin about coins that has a tradeoff between the explore and exploit."
        ],
        [
            "And in this case it was exploits to run the detector with the best.",
            "Utility.",
            "And we update.",
            "Probability of course graph.",
            "And then, since it's improving, then we accept this detector and then we move."
        ],
        [
            "1.",
            "And."
        ],
        [
            "Again, we flip a coin.",
            "It's Explorer, so we run random detectors.",
            "This random detector doesn't improve our product graph, so we discard it and so on."
        ],
        [
            "And we keep."
        ],
        [
            "Apply."
        ],
        [
            "Is the same approach."
        ],
        [
            "Till we."
        ],
        [
            "Either finish that."
        ],
        [
            "Sectors which."
        ],
        [
            "This case."
        ],
        [
            "And then we have."
        ],
        [
            "Final probability of parse graph, as in this case 0.6 four people standing in line and.",
            "As you can see, all the people standing in line are defected.",
            "As for the Q learning."
        ],
        [
            "I'm not going to go into details, but mainly we have states we have actions and we have rewards and transitions and.",
            "Where the reward favors the activities or the detectors that we run that improve the lock posterior of the sparse graph.",
            "In our evaluation of our inference, we varied our."
        ],
        [
            "Explore exploit from completely random.",
            "Run random detectors to completely greedy.",
            "And then the best tradeoff was between 0.6 and 0.8 where we achieve the best results for the first graph best probabilities.",
            "Also another evalua."
        ],
        [
            "And was to run number of detectors so we vary the number of detectors that we can run.",
            "As you can see after five detectors our approach is already selected.",
            "The best detectors and after that it's incremented minimal or smaller than the 1st jump.",
            "Thor."
        ],
        [
            "Move to our data set and Val.",
            "I'll show the final result, so we have collected a new data set of 106 minutes, 30 frames per second.",
            "Anna very high resolution.",
            "And we annotated the group activities, activities and their formation.",
            "Individual actions and poses and facing direction.",
            "And the object that the people interact with."
        ],
        [
            "That gives it the domain knowledge of six group activities, 10 individual actions and 17 objects."
        ],
        [
            "And this is an example from our annotations where those annotations were done using called bendrix and addition tool.",
            "Thank you called.",
            "It wouldn't have been possible without your annotation tool.",
            "And as you can see, there are so many things going on and this data set will be available around November 15th."
        ],
        [
            "So comparison with other available data sets, you can see that the resolution is probably the highest resolution for activity recognition.",
            "We have annotations for objects, individual actions and group activities.",
            "The background is cluttered.",
            "We have more than seven instances per frame and we have pools, annotations, an orientation annotations.",
            "Anne."
        ],
        [
            "This work is a part of a larger project.",
            "That process is natural language and visual cues.",
            "So in this example someone is querying who's walking and then this is the answer.",
            "And you can find all the instances of a person walking.",
            "It could be any query could be who is sitting where sitting could be a group setting or one person sitting."
        ],
        [
            "And this is our results on group query.",
            "And those are all possible groups.",
            "You can see there are some false detection there.",
            "Our 4th classifications.",
            "And this is our result on."
        ],
        [
            "Individual actions."
        ],
        [
            "And we have also evaluated our approach on the collective activity data set where we concatenated for.",
            "Four different videos, so we have multiple instances of the activities.",
            "Since collective activity that has mainly one or two activities per video that are happening at the same time and this our results on our data set and the rest of the results are in the paper.",
            "If you're interested to take a look at."
        ],
        [
            "So in conclusion, we have proposed a new problem with multi scale activity recognition.",
            "We have modeled it an using and and or graph and propose that cost sensitive reinforcement learning based inference.",
            "And then you data set."
        ],
        [
            "This work has been funded by DARPA and ONR and."
        ],
        [
            "If you have any questions.",
            "Question do you have any idea how you method compares to some baselines?",
            "So if you would run some hog 3D detector or some yes and the comparison we've done is on collective activity so we have multiple baselines for a single video.",
            "Also our approach I think would be an overkill for just having one instance in the video and we.",
            "Actually achieve similar results or.",
            "Anymore questions.",
            "OK, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work is on activity.",
                    "label": 0
                },
                {
                    "sent": "Recognition is done in collaboration with my advisor, professional Ravitch, and our collaborators in UCLA.",
                    "label": 0
                },
                {
                    "sent": "Danjeon maintains a land function through.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our problem is defined as.",
                    "label": 0
                },
                {
                    "sent": "Given high resolution video with many instances of people involved in individual actions and group activities.",
                    "label": 1
                },
                {
                    "sent": "We would like to answer queries about what, where and when a group activity or individual action.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happens.",
                    "label": 0
                },
                {
                    "sent": "Answering these queries in this domain becomes a very complex inference problem, and the video with this video resolution.",
                    "label": 0
                },
                {
                    "sent": "It allows us to digital zoom in and zoom out, so zooming in to examine details and zooming out to examine context as needed for recognition.",
                    "label": 0
                },
                {
                    "sent": "So for example, detecting group activity.",
                    "label": 0
                },
                {
                    "sent": "I campus tour.",
                    "label": 0
                },
                {
                    "sent": "We might want to zoom in on individuals talking or walking.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For example, group of people standing in line we might want to zoom out to get the context, which is the food bus in this case.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our contributions are threefold.",
                    "label": 0
                },
                {
                    "sent": "We have a new problem which is multi scale activity recognition which requires efficient activity or presentation inference and learning.",
                    "label": 0
                },
                {
                    "sent": "We have a constant sensitive framework to be able to handle this large resolution videos.",
                    "label": 0
                },
                {
                    "sent": "By rank them.",
                    "label": 0
                },
                {
                    "sent": "Smallest amount of detectors.",
                    "label": 0
                },
                {
                    "sent": "Since running all detectors would be prohibitively expensive.",
                    "label": 0
                },
                {
                    "sent": "And we have collected a new data set that has multiple Co occurring activities.",
                    "label": 0
                },
                {
                    "sent": "Since there are no other data sets that we are aware of that have this multiscale.",
                    "label": 0
                },
                {
                    "sent": "High resolution.",
                    "label": 0
                },
                {
                    "sent": "Activities.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So prior work has handled the function or repetitive activities in.",
                    "label": 0
                },
                {
                    "sent": "A single actor domain.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anna group domain.",
                    "label": 0
                },
                {
                    "sent": "Also, structured activities where the structure is in the temporal aspect.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For our approach, we use the unified hierarchal model.",
                    "label": 1
                },
                {
                    "sent": "The model has to be expressive enough to be able to handle this wide range of activities and.",
                    "label": 0
                },
                {
                    "sent": "Group activities individual actions.",
                    "label": 0
                },
                {
                    "sent": "Also, since we are.",
                    "label": 0
                },
                {
                    "sent": "Accounting for objects.",
                    "label": 0
                },
                {
                    "sent": "So we have many things to model here.",
                    "label": 0
                },
                {
                    "sent": "And we have interactions between human, human and human object.",
                    "label": 0
                },
                {
                    "sent": "So we use and or graph since it's kept capable of representing all these activities and interactions.",
                    "label": 0
                },
                {
                    "sent": "And our inferences made cost sensitive to efficiently detect and localize activities of interest using the minimum amount of detectors.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned before.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our approach builds up on.",
                    "label": 1
                },
                {
                    "sent": "The work that has been done by Guanzhou in Ivy 1011.",
                    "label": 0
                },
                {
                    "sent": "Where they use this work too.",
                    "label": 0
                },
                {
                    "sent": "Detect faces since a phase consists of parts, eyes, nose and mouth.",
                    "label": 0
                },
                {
                    "sent": "So in this case is very specific to face or an object.",
                    "label": 0
                },
                {
                    "sent": "In our case it's more general since we handle three different semantic scales, which the first scale is a group activity as a second scale is individual actions and the third scale is object.",
                    "label": 0
                },
                {
                    "sent": "Since the hierarchy of the Android graph, let us efficiently organize different semantic scales of the of our domain knowledge, we decide.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use and or graphs.",
                    "label": 0
                },
                {
                    "sent": "And this is an overview of our model, so our model consists of terminal nodes, nonterminal nodes, edges and probabilities.",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Terminal nodes are the nodes that access pixels, so in this case will be our detectors and non terminal nodes such as the end or nodes in our graph.",
                    "label": 0
                },
                {
                    "sent": "As for edges.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have three types of edges, edges connecting nodes of the same level.",
                    "label": 0
                },
                {
                    "sent": "And edges connecting.",
                    "label": 0
                },
                {
                    "sent": "And two hours and edges connected, or two ends where that decomposition edges ones connecting ends to or model particular configuration and switching edges which connect and or to an end.",
                    "label": 1
                },
                {
                    "sent": "Models alternative configurations.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probabilities over all possible parts.",
                    "label": 0
                },
                {
                    "sent": "Graphs where apart graph as I mentioned in this example, could be a tour group which consists of individual actors that are carrying, for example, backpacks.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our problem is.",
                    "label": 0
                },
                {
                    "sent": "Having a world distribution all possible parts graph, we want to find all those.",
                    "label": 0
                },
                {
                    "sent": "Parts graphs we assume that each parse graph is independent, then the other, and each of them is modeled as a Gibbs distribution.",
                    "label": 0
                },
                {
                    "sent": "And the energy is a function of.",
                    "label": 0
                },
                {
                    "sent": "All possible nodes and edges.",
                    "label": 0
                },
                {
                    "sent": "Where again the edges are switching relational and decomposition.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our inferences to find all possible parse graphs.",
                    "label": 0
                },
                {
                    "sent": "And we simplify this problem by treating them independently and then concatenating.",
                    "label": 0
                },
                {
                    "sent": "W the world distribution that we have.",
                    "label": 0
                },
                {
                    "sent": "So using all the previous formulas, it's straightforward to derive.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Log posterior over apart graph.",
                    "label": 0
                },
                {
                    "sent": "I know this equation might look scary, but.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I break it down to try to explain what's going on, so we have the structure which is.",
                    "label": 0
                },
                {
                    "sent": "Or an endnote given and or node.",
                    "label": 1
                },
                {
                    "sent": "And then we have.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The theme is the current level.",
                    "label": 0
                },
                {
                    "sent": "The current zoom level, the zoom in and zoom out, each of them has a detector associated with them that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is connected at the terminal node.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we have parent child relationships.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "So we have a parent child relationship, an child, child relationship where we call the.",
                    "label": 0
                },
                {
                    "sent": "The child child relationship as a beta process where it's bottom up binding of children.",
                    "label": 0
                },
                {
                    "sent": "Two apparent and this is usually in the zoom in level.",
                    "label": 0
                },
                {
                    "sent": "And the parent child is.",
                    "label": 0
                },
                {
                    "sent": "It contributes to the likelihood of child of a node.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given experience, so having those three processes, we will recap on them.",
                    "label": 0
                },
                {
                    "sent": "So Alpha is the process that runs a detector of an activity.",
                    "label": 0
                },
                {
                    "sent": "Beta is a bottom up binding of parts of activity.",
                    "label": 0
                },
                {
                    "sent": "An gamma is the top.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One prediction of the children.",
                    "label": 0
                },
                {
                    "sent": "So in the Alpha process we use three different detectors.",
                    "label": 0
                },
                {
                    "sent": "At each level you can use any detectors, but we happen to choose those three.",
                    "label": 0
                },
                {
                    "sent": "Since there is a.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the art.",
                    "label": 0
                },
                {
                    "sent": "As for the bit and gamma processes, we specify Gaussian distribution that models the location, scale and orientation.",
                    "label": 0
                },
                {
                    "sent": "Offer the nodes of the relationship, but.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The nodes where in the beta process we have child child relationship.",
                    "label": 0
                },
                {
                    "sent": "So it's all pairs of.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Connected to the parent and in the gamma process we have for each parent.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To all the children it's connected to.",
                    "label": 0
                },
                {
                    "sent": "Thought As for them.",
                    "label": 0
                },
                {
                    "sent": "'cause like our inference is cost sensitive.",
                    "label": 0
                },
                {
                    "sent": "So we decided to use a reinforcement based approach.",
                    "label": 0
                },
                {
                    "sent": "Where we have an explore exploit strategy where here explore meaning run random detector and exploit means that run the detectors that has the best utility.",
                    "label": 0
                },
                {
                    "sent": "Where we learned this utility for each detector at every node using Q.",
                    "label": 0
                },
                {
                    "sent": "Learning to learn the optimal mover optimal detector to run.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll walk you through an example so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This example we have an activity.",
                    "label": 0
                },
                {
                    "sent": "Standing in line.",
                    "label": 0
                },
                {
                    "sent": "I don't know if the image down there is clear, but.",
                    "label": 0
                },
                {
                    "sent": "Let's follow through and see what will happen.",
                    "label": 0
                },
                {
                    "sent": "So starting at the beginning our parse graph, the probability of the paragraph is zero since we don't have any detectors that we run.",
                    "label": 0
                },
                {
                    "sent": "And we have maximum number of detectors to run a 7.",
                    "label": 1
                },
                {
                    "sent": "So we limit our inference to exit this.",
                    "label": 0
                },
                {
                    "sent": "Running detectors either when the path graph probability is high enough or when we don't have anymore detectors to run.",
                    "label": 0
                },
                {
                    "sent": "So at this note we have.",
                    "label": 0
                },
                {
                    "sent": "At this node we have four detectors that we could run of different activities.",
                    "label": 0
                },
                {
                    "sent": "And with some certain utility that we have in the queue table.",
                    "label": 0
                },
                {
                    "sent": "And then we flip a coin about coins that has a tradeoff between the explore and exploit.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this case it was exploits to run the detector with the best.",
                    "label": 0
                },
                {
                    "sent": "Utility.",
                    "label": 0
                },
                {
                    "sent": "And we update.",
                    "label": 0
                },
                {
                    "sent": "Probability of course graph.",
                    "label": 0
                },
                {
                    "sent": "And then, since it's improving, then we accept this detector and then we move.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, we flip a coin.",
                    "label": 0
                },
                {
                    "sent": "It's Explorer, so we run random detectors.",
                    "label": 0
                },
                {
                    "sent": "This random detector doesn't improve our product graph, so we discard it and so on.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we keep.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apply.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the same approach.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Till we.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either finish that.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sectors which.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This case.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we have.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Final probability of parse graph, as in this case 0.6 four people standing in line and.",
                    "label": 0
                },
                {
                    "sent": "As you can see, all the people standing in line are defected.",
                    "label": 0
                },
                {
                    "sent": "As for the Q learning.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm not going to go into details, but mainly we have states we have actions and we have rewards and transitions and.",
                    "label": 0
                },
                {
                    "sent": "Where the reward favors the activities or the detectors that we run that improve the lock posterior of the sparse graph.",
                    "label": 0
                },
                {
                    "sent": "In our evaluation of our inference, we varied our.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Explore exploit from completely random.",
                    "label": 0
                },
                {
                    "sent": "Run random detectors to completely greedy.",
                    "label": 0
                },
                {
                    "sent": "And then the best tradeoff was between 0.6 and 0.8 where we achieve the best results for the first graph best probabilities.",
                    "label": 0
                },
                {
                    "sent": "Also another evalua.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And was to run number of detectors so we vary the number of detectors that we can run.",
                    "label": 0
                },
                {
                    "sent": "As you can see after five detectors our approach is already selected.",
                    "label": 0
                },
                {
                    "sent": "The best detectors and after that it's incremented minimal or smaller than the 1st jump.",
                    "label": 0
                },
                {
                    "sent": "Thor.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move to our data set and Val.",
                    "label": 0
                },
                {
                    "sent": "I'll show the final result, so we have collected a new data set of 106 minutes, 30 frames per second.",
                    "label": 0
                },
                {
                    "sent": "Anna very high resolution.",
                    "label": 0
                },
                {
                    "sent": "And we annotated the group activities, activities and their formation.",
                    "label": 0
                },
                {
                    "sent": "Individual actions and poses and facing direction.",
                    "label": 0
                },
                {
                    "sent": "And the object that the people interact with.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That gives it the domain knowledge of six group activities, 10 individual actions and 17 objects.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is an example from our annotations where those annotations were done using called bendrix and addition tool.",
                    "label": 0
                },
                {
                    "sent": "Thank you called.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't have been possible without your annotation tool.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, there are so many things going on and this data set will be available around November 15th.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So comparison with other available data sets, you can see that the resolution is probably the highest resolution for activity recognition.",
                    "label": 0
                },
                {
                    "sent": "We have annotations for objects, individual actions and group activities.",
                    "label": 0
                },
                {
                    "sent": "The background is cluttered.",
                    "label": 0
                },
                {
                    "sent": "We have more than seven instances per frame and we have pools, annotations, an orientation annotations.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work is a part of a larger project.",
                    "label": 0
                },
                {
                    "sent": "That process is natural language and visual cues.",
                    "label": 0
                },
                {
                    "sent": "So in this example someone is querying who's walking and then this is the answer.",
                    "label": 0
                },
                {
                    "sent": "And you can find all the instances of a person walking.",
                    "label": 0
                },
                {
                    "sent": "It could be any query could be who is sitting where sitting could be a group setting or one person sitting.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is our results on group query.",
                    "label": 0
                },
                {
                    "sent": "And those are all possible groups.",
                    "label": 0
                },
                {
                    "sent": "You can see there are some false detection there.",
                    "label": 0
                },
                {
                    "sent": "Our 4th classifications.",
                    "label": 0
                },
                {
                    "sent": "And this is our result on.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Individual actions.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have also evaluated our approach on the collective activity data set where we concatenated for.",
                    "label": 0
                },
                {
                    "sent": "Four different videos, so we have multiple instances of the activities.",
                    "label": 0
                },
                {
                    "sent": "Since collective activity that has mainly one or two activities per video that are happening at the same time and this our results on our data set and the rest of the results are in the paper.",
                    "label": 0
                },
                {
                    "sent": "If you're interested to take a look at.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we have proposed a new problem with multi scale activity recognition.",
                    "label": 0
                },
                {
                    "sent": "We have modeled it an using and and or graph and propose that cost sensitive reinforcement learning based inference.",
                    "label": 0
                },
                {
                    "sent": "And then you data set.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work has been funded by DARPA and ONR and.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have any questions.",
                    "label": 0
                },
                {
                    "sent": "Question do you have any idea how you method compares to some baselines?",
                    "label": 0
                },
                {
                    "sent": "So if you would run some hog 3D detector or some yes and the comparison we've done is on collective activity so we have multiple baselines for a single video.",
                    "label": 0
                },
                {
                    "sent": "Also our approach I think would be an overkill for just having one instance in the video and we.",
                    "label": 0
                },
                {
                    "sent": "Actually achieve similar results or.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}