{
    "id": "h726imn3gyz2dncgx6zd2q6opwho5ixs",
    "title": "Nonparametric Estimation of the Precision-Recall Curve",
    "info": {
        "author": [
            "Nicolas Vayatis, Centre de Math\u00e9matiques et de Leurs Applications, Ecole normale sup\u00e9rieure de Cachan"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_vayatis_nepr/",
    "segmentation": [
        [
            "OK, thank you so the title of my talk is nonparametric estimation of the precision recall curve.",
            "So what is the context of the study?",
            "Problem we are interested in is."
        ],
        [
            "Bye bye bipartite ranking and in this kind of problem.",
            "A common performance measure is this precision recall curve, so."
        ],
        [
            "In this talk, we assume that we already have some ranking rule for ranking the data, and we want to say something about the performance of this rule and in particular study the variability of results depending on the new data arriving.",
            "OK, so here is an illustration of what happens with this precision recall curves.",
            "So if we have this single ranking rule and we evaluate it on different sets of data, we have a huge variability.",
            "So this is for samples of the."
        ],
        [
            "Eyes like 200 and the question is can we say something about this phenomenon and try to control this variability?",
            "So for instance, can we design confidence bands for this realization here of of this process?",
            "So here in the black line it would be the truth and we want to say something about how this particular realization of this precision recall curves deviate from the from the truth.",
            "OK, so ideally would like to obtain such bands here around the truth and say that with high probability the realization will be within this this domain here."
        ],
        [
            "OK.",
            "So there has been some previous work on this topic for a different kind of performance measure.",
            "The Arosi curve, which is very popular also in this community and these works here, studied some problems about the statistical estimation of these functions.",
            "This function, like performance, measures OK, so there are some works that.",
            "Emphasize the parametric estimation that the like the work of CN Turnbull in the annals of statistics in 96 and Max Caskey an Provo on some coauthor here.",
            "In another paper they derive some bootstrap confidence bands for the RC curve, and more recently we studied with Patrick's birthday.",
            "And Stephen came also.",
            "And in a similar work, Horvat and Horvat Anjou, also gay."
        ],
        [
            "If some results that like the one we will get today for the arosi curve.",
            "But as we move to the precision recall curve as far as we know, we haven't found any.",
            "A theoretical result that would allow to derive confidence bands for precise."
        ],
        [
            "And recall curves.",
            "OK, so why focusing on this type of object?",
            "Well, an interesting aspect is that they provide some visual display of performance and the higher the curve is in the graph, then the better the ranking rule.",
            "OK, so this is the motivation for for considering our OC or precision recall curves.",
            "So what is so special?"
        ],
        [
            "About precision recall curves.",
            "Well, they have some at."
        ],
        [
            "Additional feature is that they are explicitly depending on the proportion of positive observations.",
            "OK, so we have two populations, the positive and the negative.",
            "P would be the proportion of plus ones and the RC curve is independent of this parameter of the distribution P while in arosi curve.",
            "Excuse me in precision recall curves, then you can get some insights.",
            "Also for populations where there are very few positive instances.",
            "OK, So what is the probabilistic model underlying the pro?"
        ],
        [
            "I blame the bipartite ranking problem.",
            "Well, they are like classification data, so here.",
            "I won't describe explicitly the classification problem, but I will only introduce the notations for the pair involved in the in the subsequent developments.",
            "Z Here is the score.",
            "OK, so as I said in the introduction, we assume that the scoring rule is the ranking rule is already known and it takes the form of a score and you give some score to each individual observation and this allows you to rank the data.",
            "OK.",
            "So here assume that we have done some pre testing and we we selected this ranking rule and now to evaluate the performance on new data we can consider that Z is just.",
            "Real valued random variable and Y is binary label and the distribution of despair is described by the conditional distributions for Z given Y.",
            "So denoted we denote the CDF here by F plus an F minus and we also need the proportion P that defines the mixture of positive and negative observations."
        ],
        [
            "Then what is the precision recall curve then?",
            "This is the plot of the precision, which is the probability of retrieving relevant documents.",
            "For instance, given among the relevant documents, and the recall is just the true positive rate.",
            "So the probability of having relevant documents among the ones retrieved.",
            "OK, so this is the.",
            "The the precision recall curve is just a parametric curve indexed by the threshold T here, which defines the level for retrieving the instances and so this is just the definition of the PR curve and using the previous notation, while 1 -- F plus is just the true positive rate and the precision here is the ratio of P 1 -- F plus.",
            "Divided by 1 minus FT, where F is the CDF for Z's OK.",
            "The unconditional CDF."
        ],
        [
            "OK, So what are the type of properties that you can state for such objects?",
            "Well, if the two populations are equal then there's no point in ranking them.",
            "And of course this can be observed on the curve and if they are exactly equal, these two distributions then you just observe a constant equal to P on the graph.",
            "OK, so P is the proportion of plus ones and also you can derive the limits.",
            "At the at zero and at one.",
            "So for this for this plot here.",
            "So when the threshold tends to minus Infinity then this corresponds to the X axis true positive rate equal to 1.",
            "Since you have all the guys and the precision, here is all the positive label which is equal to P. OK and when?",
            "You take the limit at plus Infinity for the threshold, then the true positive rate tends to zero and the precision tends to this ratio.",
            "Here, P, L, /, P, L plus 1 -- P, where L is the limit of the likelihood ratio.",
            "So for instance, if this likelihood ratio is bounded, then the limit is 1.",
            "And since we deal here with the true precision recalls, so we assume that we know the distribution.",
            "And if we have some additional assumptions on the distribution, then we have some additional properties for the plot.",
            "And for instance, we can say that the PR curve is decreasing, so this is deterministically decreasing if the likelihood ratio is monotone.",
            "OK, so these are quite simple properties and it's it just gives us some ideas about the the form of the shape of these curves."
        ],
        [
            "OK, so now to state the results I need to change a bit the representation of the curve and represent it as the as a function.",
            "So just by changing parameters and so we can denote by X the true positive rate and inverting the previous definition we can.",
            "See that the the the PR curve is just the PR curve is just the plot of this function here, so this is PX divided by P X + 1 -- P times Alpha.",
            "XX is in 01, so this corresponds to the levels for the true positive rates an Alpha X is some re parameterization of the false positive rate.",
            "OK at level X.",
            "So I'm doing this backwards, but so here this function here is just the conditional quantile function.",
            "So this is the generalized inverse for the positive distribution of the positive instances at level 1 -- X.",
            "And this is just the Alpha.",
            "X is just the true positive rate for the level, which is determined by the X.",
            "Here for this quantile function.",
            "OK so but this is just a re parameterization of the previous definition here, so set this XL two this equal to X and just replace T by.",
            "You can invert this formula in T and then replacing this you get some function which depends on X. OK so this is just a real valued function on 01.",
            "OK, so this was the true precision recall curve, but now if we have some sample, so assume that we have an IID."
        ],
        [
            "Example with diyi data and then we can plot the empirical version of this.",
            "Of this object and I need some extra annotations here for for dealing with this empirical version.",
            "So we denote by N plus the number of positive instances in the sample and the empirical false positive rate at X is just the empirical version of Alpha X obtained by plugging in the empirical CDF's instead of the true CDF's.",
            "OK, so the empirical precision recall function is just.",
            "The same as before, where we replace the proportion P by N + / N and then Alpha of X by Alpha hat."
        ],
        [
            "If X. OK, so remember the motivation which is controlling the deviations?",
            "How the empirical PR curves that we obtain in practice deviate from the truth.",
            "So we want to state some results about the fluctuation process.",
            "So here I take the normalized fluctuation process for the precision recall, which is just the pointwise deviation of the empirical version from the truth.",
            "With the scale factor of square root of N, which is the right normalization for this process here?",
            "And we will state some results for in terms of functional approximation.",
            "OK, so we need some metric to say how to describe the proximity between two curves and we will consider the uniform metric.",
            "So say the supremum of the deviation over the interval.",
            "But we need to exclude the extremities in the results and this is well I will explain later why we have this restriction here on the."
        ],
        [
            "Domain.",
            "So there are some technical assumptions about the distribution, so first we assume that the positive and negative labels have shared the same support and they are absolutely continuous with respect to LA Bag measure.",
            "So they have some density.",
            "So the CDF's are differentiable.",
            "We assume that these densities are strictly positive at the points.",
            "When we consider the inverses of of X by the quantile function.",
            "And the technical assumption which is required in stating the result is that the slope of the tangent of the curves of the function Alpha is bounded.",
            "OK, so this amounts to say something about the ratio of densities of conditional densities at the point F plus the inverse of F plus at X OK. And there is also a parameter here, gamma which controls this.",
            "This boundedness here and this also plays some role in the result."
        ],
        [
            "OK, so.",
            "Here is the 1st result, so this is a strong approximation result which is valid almost surely.",
            "And this provides an asymptotic approximation of the PR curve of these empirical PR curves.",
            "OK, this random realizations on some data and the 1st result is just a consistency result.",
            "Say that you have uniform convergence of the empirical function to the true precision recall function on this restricted domain, where we removed the zero and one.",
            "And the the 2nd result is that, well, the second part of this result is that you can.",
            "Either for the fluctuation process here an approximation with the process ZN of X plus some extra term here which is of the order of 1 / sqrt N up to some logarithmic factor, which is described here and depends on the gamma in the assumption."
        ],
        [
            "And the approximation here involves the underlying distribution, of course, and the densities and the marginal of this process are Gaussian, so we can state explicitly the form of.",
            "Well, this is a bit ugly, but it's just to point out that we have an explicit expression for this random process here, and this is some kind of combination of.",
            "A standard Gaussian here W and some Brownian bridges, so they have marginal distributions which look like Gaussian.",
            "So for instance, if you fix the X then the distribution is just a Gaussian.",
            "OK, so this is something which is complete."
        ],
        [
            "Explicit, but maybe this is not enough for our purpose, since everything depends on the unknown distribution.",
            "OK, so people who can."
        ],
        [
            "Sidered parametric approach.",
            "They say that OK, we can consider."
        ],
        [
            "The underlying distribution is a mixture of Gaussian and we just estimate the."
        ],
        [
            "Parameters and plug them in this formula and we can get.",
            "We can construct some confidence interval under this parametric assumption, but here I will very quickly state a nonparametric approach to this problem so."
        ],
        [
            "So this is just.",
            "Another way to look at the problem, and this is to consider for building this confidence interval to use a bootstrap's team estimate.",
            "So just resample the data available but the knife bootstrap.",
            "Since we have some quantile involved and we need to estimate this quantile is very slow, so we need to make some adjustments in order to make it work in practice.",
            "So PR star will be the empirical PR curve which is obtained on a bootstrap sample so.",
            "Assume we sample from the data.",
            "We built this empirical PR function on these different data sample an.",
            "This will be denoted by PR star and I will state Now some results for the Bootstrap PR fluctuation process.",
            "But I will explain first how we do the bootstrap.",
            "So there are basically two ideas.",
            "The first idea is that you should not re sample.",
            "Directly."
        ],
        [
            "From the available data, first you should apply some smoothing on this data.",
            "So this is just to make the quantile estimation part work, so you can do just some standard kernel smoothing on the histogram with some Gaussian kernel and the bandwidth here is denoted by H and the."
        ],
        [
            "Procedure in fact, we don't really need to do this in practice, it is enough to just re sample from the initial data.",
            "You get some Z prime eyes and just add some random Gaussian noise on on each of them and then this will give you the Z star White Star which will be the bootstrap sample.",
            "Or"
        ],
        [
            "OK, and the other idea is to do some.",
            "Apply some ideas from important sampling.",
            "Since we are dealing with these PR curves very often with very skewed distributions, and if we do resampling there maybe we won't catch any positive instance.",
            "So you need to make some correction in order to make this kind of estimate work, and this comes from important sampling, so you just.",
            "2."
        ],
        [
            "I mean 2.",
            "To do the re sampling here, here we only talked about the."
        ],
        [
            "Additional distribution, but you also modify the parameter.",
            "The mixture parameter P and you can take it equal to 1/2 so that you take an equal quantity of positive and negative instances and then there is just some correction in the estimate.",
            "Here through this important function.",
            "So this is very common idea in Monte Carlo.",
            "Most Monte Carlo methods for for very for estimate."
        ],
        [
            "Rare events.",
            "So we also have a second result which guarantees the validity of this procedure, so combining smoothing, an important sampling, and here the rate is by doing the right calibration on the on the size of the bandwidth, you get some error for the quantity, which is here, which allows you to build the confidence bands which will be of the order of N to the power minus 2/5 instead of North to the power minus 1/4, which would be the case if we had.",
            "Done a simple bootstrap."
        ],
        [
            "OK, so now to conclude, just very simple ideas from statistics that provides some grounds for studying this.",
            "These concepts coming from information retrieval applications.",
            "So we believe that it is very interesting and important to provide these results and for precision recall curves.",
            "This is just the very first result, but for."
        ],
        [
            "Orosi curve learning.",
            "We have developed.",
            "Some theories about the statistical estimation and learning these are OC curve and focusing on the on the function like performance measure and not on only on summaries like the AUC or the partially UC or other measures that I used in this Community.",
            "So thank you very much.",
            "Next yes.",
            "Questions, did this ring feminization?",
            "Yes.",
            "Are there other parametrizations you could use?",
            "This is something magical about that one.",
            "The assumptions that you make.",
            "I mean, I can imagine yeah.",
            "Is there an intuition behind them?",
            "I mean, do you feel that there's somehow intrinsic or is just a matter of the technicalities to get the proof?",
            "I mean the well there is one assumption which was not stated in the list in this list but stated before is the fact that we look at uniform convergence on epsilon 1 minus epsilon.",
            "I'm not sure about the 1 minus epsilon.",
            "I believe that we should get uniform results on epsilon one.",
            "Because also when you do the simulation you can see that the.",
            "I mean, you get better result the rate of convergence improves as you get closer to the value of 1, so I think this might be removed with maybe some different parameterization, or maybe looking at things a bit differently, so here.",
            "The other assumptions they are mainly due to this quantile estimation part and the fact that we want a very strong result because it's a uniform strong approximation almost sure.",
            "In uniform norm.",
            "So this is a very strong result and I think we need this type of assumptions so."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thank you so the title of my talk is nonparametric estimation of the precision recall curve.",
                    "label": 1
                },
                {
                    "sent": "So what is the context of the study?",
                    "label": 0
                },
                {
                    "sent": "Problem we are interested in is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bye bye bipartite ranking and in this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "A common performance measure is this precision recall curve, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this talk, we assume that we already have some ranking rule for ranking the data, and we want to say something about the performance of this rule and in particular study the variability of results depending on the new data arriving.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is an illustration of what happens with this precision recall curves.",
                    "label": 0
                },
                {
                    "sent": "So if we have this single ranking rule and we evaluate it on different sets of data, we have a huge variability.",
                    "label": 0
                },
                {
                    "sent": "So this is for samples of the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Eyes like 200 and the question is can we say something about this phenomenon and try to control this variability?",
                    "label": 0
                },
                {
                    "sent": "So for instance, can we design confidence bands for this realization here of of this process?",
                    "label": 1
                },
                {
                    "sent": "So here in the black line it would be the truth and we want to say something about how this particular realization of this precision recall curves deviate from the from the truth.",
                    "label": 0
                },
                {
                    "sent": "OK, so ideally would like to obtain such bands here around the truth and say that with high probability the realization will be within this this domain here.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So there has been some previous work on this topic for a different kind of performance measure.",
                    "label": 1
                },
                {
                    "sent": "The Arosi curve, which is very popular also in this community and these works here, studied some problems about the statistical estimation of these functions.",
                    "label": 0
                },
                {
                    "sent": "This function, like performance, measures OK, so there are some works that.",
                    "label": 0
                },
                {
                    "sent": "Emphasize the parametric estimation that the like the work of CN Turnbull in the annals of statistics in 96 and Max Caskey an Provo on some coauthor here.",
                    "label": 0
                },
                {
                    "sent": "In another paper they derive some bootstrap confidence bands for the RC curve, and more recently we studied with Patrick's birthday.",
                    "label": 0
                },
                {
                    "sent": "And Stephen came also.",
                    "label": 0
                },
                {
                    "sent": "And in a similar work, Horvat and Horvat Anjou, also gay.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If some results that like the one we will get today for the arosi curve.",
                    "label": 0
                },
                {
                    "sent": "But as we move to the precision recall curve as far as we know, we haven't found any.",
                    "label": 0
                },
                {
                    "sent": "A theoretical result that would allow to derive confidence bands for precise.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And recall curves.",
                    "label": 0
                },
                {
                    "sent": "OK, so why focusing on this type of object?",
                    "label": 0
                },
                {
                    "sent": "Well, an interesting aspect is that they provide some visual display of performance and the higher the curve is in the graph, then the better the ranking rule.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the motivation for for considering our OC or precision recall curves.",
                    "label": 0
                },
                {
                    "sent": "So what is so special?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About precision recall curves.",
                    "label": 0
                },
                {
                    "sent": "Well, they have some at.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Additional feature is that they are explicitly depending on the proportion of positive observations.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have two populations, the positive and the negative.",
                    "label": 0
                },
                {
                    "sent": "P would be the proportion of plus ones and the RC curve is independent of this parameter of the distribution P while in arosi curve.",
                    "label": 1
                },
                {
                    "sent": "Excuse me in precision recall curves, then you can get some insights.",
                    "label": 0
                },
                {
                    "sent": "Also for populations where there are very few positive instances.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the probabilistic model underlying the pro?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I blame the bipartite ranking problem.",
                    "label": 0
                },
                {
                    "sent": "Well, they are like classification data, so here.",
                    "label": 0
                },
                {
                    "sent": "I won't describe explicitly the classification problem, but I will only introduce the notations for the pair involved in the in the subsequent developments.",
                    "label": 0
                },
                {
                    "sent": "Z Here is the score.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I said in the introduction, we assume that the scoring rule is the ranking rule is already known and it takes the form of a score and you give some score to each individual observation and this allows you to rank the data.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here assume that we have done some pre testing and we we selected this ranking rule and now to evaluate the performance on new data we can consider that Z is just.",
                    "label": 0
                },
                {
                    "sent": "Real valued random variable and Y is binary label and the distribution of despair is described by the conditional distributions for Z given Y.",
                    "label": 1
                },
                {
                    "sent": "So denoted we denote the CDF here by F plus an F minus and we also need the proportion P that defines the mixture of positive and negative observations.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then what is the precision recall curve then?",
                    "label": 0
                },
                {
                    "sent": "This is the plot of the precision, which is the probability of retrieving relevant documents.",
                    "label": 0
                },
                {
                    "sent": "For instance, given among the relevant documents, and the recall is just the true positive rate.",
                    "label": 0
                },
                {
                    "sent": "So the probability of having relevant documents among the ones retrieved.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 0
                },
                {
                    "sent": "The the precision recall curve is just a parametric curve indexed by the threshold T here, which defines the level for retrieving the instances and so this is just the definition of the PR curve and using the previous notation, while 1 -- F plus is just the true positive rate and the precision here is the ratio of P 1 -- F plus.",
                    "label": 1
                },
                {
                    "sent": "Divided by 1 minus FT, where F is the CDF for Z's OK.",
                    "label": 0
                },
                {
                    "sent": "The unconditional CDF.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what are the type of properties that you can state for such objects?",
                    "label": 0
                },
                {
                    "sent": "Well, if the two populations are equal then there's no point in ranking them.",
                    "label": 0
                },
                {
                    "sent": "And of course this can be observed on the curve and if they are exactly equal, these two distributions then you just observe a constant equal to P on the graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so P is the proportion of plus ones and also you can derive the limits.",
                    "label": 0
                },
                {
                    "sent": "At the at zero and at one.",
                    "label": 0
                },
                {
                    "sent": "So for this for this plot here.",
                    "label": 0
                },
                {
                    "sent": "So when the threshold tends to minus Infinity then this corresponds to the X axis true positive rate equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Since you have all the guys and the precision, here is all the positive label which is equal to P. OK and when?",
                    "label": 0
                },
                {
                    "sent": "You take the limit at plus Infinity for the threshold, then the true positive rate tends to zero and the precision tends to this ratio.",
                    "label": 0
                },
                {
                    "sent": "Here, P, L, /, P, L plus 1 -- P, where L is the limit of the likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if this likelihood ratio is bounded, then the limit is 1.",
                    "label": 0
                },
                {
                    "sent": "And since we deal here with the true precision recalls, so we assume that we know the distribution.",
                    "label": 0
                },
                {
                    "sent": "And if we have some additional assumptions on the distribution, then we have some additional properties for the plot.",
                    "label": 0
                },
                {
                    "sent": "And for instance, we can say that the PR curve is decreasing, so this is deterministically decreasing if the likelihood ratio is monotone.",
                    "label": 1
                },
                {
                    "sent": "OK, so these are quite simple properties and it's it just gives us some ideas about the the form of the shape of these curves.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now to state the results I need to change a bit the representation of the curve and represent it as the as a function.",
                    "label": 0
                },
                {
                    "sent": "So just by changing parameters and so we can denote by X the true positive rate and inverting the previous definition we can.",
                    "label": 0
                },
                {
                    "sent": "See that the the the PR curve is just the PR curve is just the plot of this function here, so this is PX divided by P X + 1 -- P times Alpha.",
                    "label": 1
                },
                {
                    "sent": "XX is in 01, so this corresponds to the levels for the true positive rates an Alpha X is some re parameterization of the false positive rate.",
                    "label": 0
                },
                {
                    "sent": "OK at level X.",
                    "label": 0
                },
                {
                    "sent": "So I'm doing this backwards, but so here this function here is just the conditional quantile function.",
                    "label": 0
                },
                {
                    "sent": "So this is the generalized inverse for the positive distribution of the positive instances at level 1 -- X.",
                    "label": 0
                },
                {
                    "sent": "And this is just the Alpha.",
                    "label": 0
                },
                {
                    "sent": "X is just the true positive rate for the level, which is determined by the X.",
                    "label": 0
                },
                {
                    "sent": "Here for this quantile function.",
                    "label": 0
                },
                {
                    "sent": "OK so but this is just a re parameterization of the previous definition here, so set this XL two this equal to X and just replace T by.",
                    "label": 0
                },
                {
                    "sent": "You can invert this formula in T and then replacing this you get some function which depends on X. OK so this is just a real valued function on 01.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was the true precision recall curve, but now if we have some sample, so assume that we have an IID.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example with diyi data and then we can plot the empirical version of this.",
                    "label": 0
                },
                {
                    "sent": "Of this object and I need some extra annotations here for for dealing with this empirical version.",
                    "label": 0
                },
                {
                    "sent": "So we denote by N plus the number of positive instances in the sample and the empirical false positive rate at X is just the empirical version of Alpha X obtained by plugging in the empirical CDF's instead of the true CDF's.",
                    "label": 1
                },
                {
                    "sent": "OK, so the empirical precision recall function is just.",
                    "label": 0
                },
                {
                    "sent": "The same as before, where we replace the proportion P by N + / N and then Alpha of X by Alpha hat.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If X. OK, so remember the motivation which is controlling the deviations?",
                    "label": 0
                },
                {
                    "sent": "How the empirical PR curves that we obtain in practice deviate from the truth.",
                    "label": 1
                },
                {
                    "sent": "So we want to state some results about the fluctuation process.",
                    "label": 0
                },
                {
                    "sent": "So here I take the normalized fluctuation process for the precision recall, which is just the pointwise deviation of the empirical version from the truth.",
                    "label": 0
                },
                {
                    "sent": "With the scale factor of square root of N, which is the right normalization for this process here?",
                    "label": 0
                },
                {
                    "sent": "And we will state some results for in terms of functional approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, so we need some metric to say how to describe the proximity between two curves and we will consider the uniform metric.",
                    "label": 0
                },
                {
                    "sent": "So say the supremum of the deviation over the interval.",
                    "label": 0
                },
                {
                    "sent": "But we need to exclude the extremities in the results and this is well I will explain later why we have this restriction here on the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Domain.",
                    "label": 0
                },
                {
                    "sent": "So there are some technical assumptions about the distribution, so first we assume that the positive and negative labels have shared the same support and they are absolutely continuous with respect to LA Bag measure.",
                    "label": 0
                },
                {
                    "sent": "So they have some density.",
                    "label": 0
                },
                {
                    "sent": "So the CDF's are differentiable.",
                    "label": 0
                },
                {
                    "sent": "We assume that these densities are strictly positive at the points.",
                    "label": 0
                },
                {
                    "sent": "When we consider the inverses of of X by the quantile function.",
                    "label": 1
                },
                {
                    "sent": "And the technical assumption which is required in stating the result is that the slope of the tangent of the curves of the function Alpha is bounded.",
                    "label": 1
                },
                {
                    "sent": "OK, so this amounts to say something about the ratio of densities of conditional densities at the point F plus the inverse of F plus at X OK. And there is also a parameter here, gamma which controls this.",
                    "label": 0
                },
                {
                    "sent": "This boundedness here and this also plays some role in the result.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Here is the 1st result, so this is a strong approximation result which is valid almost surely.",
                    "label": 1
                },
                {
                    "sent": "And this provides an asymptotic approximation of the PR curve of these empirical PR curves.",
                    "label": 0
                },
                {
                    "sent": "OK, this random realizations on some data and the 1st result is just a consistency result.",
                    "label": 0
                },
                {
                    "sent": "Say that you have uniform convergence of the empirical function to the true precision recall function on this restricted domain, where we removed the zero and one.",
                    "label": 0
                },
                {
                    "sent": "And the the 2nd result is that, well, the second part of this result is that you can.",
                    "label": 0
                },
                {
                    "sent": "Either for the fluctuation process here an approximation with the process ZN of X plus some extra term here which is of the order of 1 / sqrt N up to some logarithmic factor, which is described here and depends on the gamma in the assumption.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the approximation here involves the underlying distribution, of course, and the densities and the marginal of this process are Gaussian, so we can state explicitly the form of.",
                    "label": 0
                },
                {
                    "sent": "Well, this is a bit ugly, but it's just to point out that we have an explicit expression for this random process here, and this is some kind of combination of.",
                    "label": 0
                },
                {
                    "sent": "A standard Gaussian here W and some Brownian bridges, so they have marginal distributions which look like Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you fix the X then the distribution is just a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is something which is complete.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Explicit, but maybe this is not enough for our purpose, since everything depends on the unknown distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so people who can.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sidered parametric approach.",
                    "label": 0
                },
                {
                    "sent": "They say that OK, we can consider.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The underlying distribution is a mixture of Gaussian and we just estimate the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parameters and plug them in this formula and we can get.",
                    "label": 0
                },
                {
                    "sent": "We can construct some confidence interval under this parametric assumption, but here I will very quickly state a nonparametric approach to this problem so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is just.",
                    "label": 0
                },
                {
                    "sent": "Another way to look at the problem, and this is to consider for building this confidence interval to use a bootstrap's team estimate.",
                    "label": 0
                },
                {
                    "sent": "So just resample the data available but the knife bootstrap.",
                    "label": 0
                },
                {
                    "sent": "Since we have some quantile involved and we need to estimate this quantile is very slow, so we need to make some adjustments in order to make it work in practice.",
                    "label": 0
                },
                {
                    "sent": "So PR star will be the empirical PR curve which is obtained on a bootstrap sample so.",
                    "label": 1
                },
                {
                    "sent": "Assume we sample from the data.",
                    "label": 0
                },
                {
                    "sent": "We built this empirical PR function on these different data sample an.",
                    "label": 0
                },
                {
                    "sent": "This will be denoted by PR star and I will state Now some results for the Bootstrap PR fluctuation process.",
                    "label": 0
                },
                {
                    "sent": "But I will explain first how we do the bootstrap.",
                    "label": 0
                },
                {
                    "sent": "So there are basically two ideas.",
                    "label": 0
                },
                {
                    "sent": "The first idea is that you should not re sample.",
                    "label": 0
                },
                {
                    "sent": "Directly.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the available data, first you should apply some smoothing on this data.",
                    "label": 0
                },
                {
                    "sent": "So this is just to make the quantile estimation part work, so you can do just some standard kernel smoothing on the histogram with some Gaussian kernel and the bandwidth here is denoted by H and the.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Procedure in fact, we don't really need to do this in practice, it is enough to just re sample from the initial data.",
                    "label": 0
                },
                {
                    "sent": "You get some Z prime eyes and just add some random Gaussian noise on on each of them and then this will give you the Z star White Star which will be the bootstrap sample.",
                    "label": 0
                },
                {
                    "sent": "Or",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and the other idea is to do some.",
                    "label": 0
                },
                {
                    "sent": "Apply some ideas from important sampling.",
                    "label": 0
                },
                {
                    "sent": "Since we are dealing with these PR curves very often with very skewed distributions, and if we do resampling there maybe we won't catch any positive instance.",
                    "label": 0
                },
                {
                    "sent": "So you need to make some correction in order to make this kind of estimate work, and this comes from important sampling, so you just.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean 2.",
                    "label": 0
                },
                {
                    "sent": "To do the re sampling here, here we only talked about the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Additional distribution, but you also modify the parameter.",
                    "label": 0
                },
                {
                    "sent": "The mixture parameter P and you can take it equal to 1/2 so that you take an equal quantity of positive and negative instances and then there is just some correction in the estimate.",
                    "label": 1
                },
                {
                    "sent": "Here through this important function.",
                    "label": 0
                },
                {
                    "sent": "So this is very common idea in Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "Most Monte Carlo methods for for very for estimate.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rare events.",
                    "label": 0
                },
                {
                    "sent": "So we also have a second result which guarantees the validity of this procedure, so combining smoothing, an important sampling, and here the rate is by doing the right calibration on the on the size of the bandwidth, you get some error for the quantity, which is here, which allows you to build the confidence bands which will be of the order of N to the power minus 2/5 instead of North to the power minus 1/4, which would be the case if we had.",
                    "label": 0
                },
                {
                    "sent": "Done a simple bootstrap.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now to conclude, just very simple ideas from statistics that provides some grounds for studying this.",
                    "label": 0
                },
                {
                    "sent": "These concepts coming from information retrieval applications.",
                    "label": 0
                },
                {
                    "sent": "So we believe that it is very interesting and important to provide these results and for precision recall curves.",
                    "label": 0
                },
                {
                    "sent": "This is just the very first result, but for.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Orosi curve learning.",
                    "label": 0
                },
                {
                    "sent": "We have developed.",
                    "label": 0
                },
                {
                    "sent": "Some theories about the statistical estimation and learning these are OC curve and focusing on the on the function like performance measure and not on only on summaries like the AUC or the partially UC or other measures that I used in this Community.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Next yes.",
                    "label": 0
                },
                {
                    "sent": "Questions, did this ring feminization?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Are there other parametrizations you could use?",
                    "label": 0
                },
                {
                    "sent": "This is something magical about that one.",
                    "label": 0
                },
                {
                    "sent": "The assumptions that you make.",
                    "label": 0
                },
                {
                    "sent": "I mean, I can imagine yeah.",
                    "label": 0
                },
                {
                    "sent": "Is there an intuition behind them?",
                    "label": 0
                },
                {
                    "sent": "I mean, do you feel that there's somehow intrinsic or is just a matter of the technicalities to get the proof?",
                    "label": 0
                },
                {
                    "sent": "I mean the well there is one assumption which was not stated in the list in this list but stated before is the fact that we look at uniform convergence on epsilon 1 minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure about the 1 minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "I believe that we should get uniform results on epsilon one.",
                    "label": 0
                },
                {
                    "sent": "Because also when you do the simulation you can see that the.",
                    "label": 0
                },
                {
                    "sent": "I mean, you get better result the rate of convergence improves as you get closer to the value of 1, so I think this might be removed with maybe some different parameterization, or maybe looking at things a bit differently, so here.",
                    "label": 0
                },
                {
                    "sent": "The other assumptions they are mainly due to this quantile estimation part and the fact that we want a very strong result because it's a uniform strong approximation almost sure.",
                    "label": 0
                },
                {
                    "sent": "In uniform norm.",
                    "label": 0
                },
                {
                    "sent": "So this is a very strong result and I think we need this type of assumptions so.",
                    "label": 0
                }
            ]
        }
    }
}