{
    "id": "rxpmipn3woee4qn3jobd3rvptucknqb5",
    "title": "Hierarchical Mixture Models: a Probabilistic Analysis",
    "info": {
        "author": [
            "Mark Sandler, Google, Inc."
        ],
        "published": "Aug. 15, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/kdd07_sandler_hmm/",
    "segmentation": [
        [
            "Alright, so the topic of my talk is Rockefeller Mixer balls are probabilistic analysis and let me begin with a short overview of why are we in this kind of prob."
        ],
        [
            "So.",
            "So it's a classical problem.",
            "We have a bunch of documents and they are on various topics and we would like to automatically classify them and mixture models provide us with a way to formally reason about the problem and.",
            "So.",
            "In order mixture models actually.",
            "Sorry.",
            "It's not supposed to go like this.",
            "Supposed to go 1 by 1.",
            "So innovation model each each topic different probability distribution of our entire whatever.",
            "So mods could have it published English like that and physics which looks like something else and each document is characterized by quantity from relevance to each one of those topics.",
            "And of course this is an overly simplistic representation, but the hope is that it will actually capturing all of the properties which would let us characterize document which topic it belongs to.",
            "And of course document.",
            "And a document is thought of as a repeated sample from one of those virtual distributions, and the goal is that we have these documents and we want to infer the underlying topics Anna computer document.",
            "World of regular mixed models and the question is why, what?",
            "Why do we actually want you in there?"
        ],
        [
            "And the problem is that.",
            "We actually.",
            "There are lots of topics in real data.",
            "There could be hundreds, hundreds of thousands, and regular remodels just want all of them, which might not be just visible for check.",
            "Maybe 1234123.",
            "Alright.",
            "I was running away.",
            "It was a lot alright, so there are lots of topics in real data and we want to and it might not be feasible to find all of them.",
            "And another thing is that topics are not independent, so topics.",
            "So something about Mom.",
            "Otherwise, we classified as a science and you wrote.",
            "It allows us to include this kind of dependencies.",
            "And another thing that you're OK.",
            "I'll just do lazy question.",
            "So I definitely are according to difference could be just initially classified into sports without actually wearing wearing in this party.",
            "So this is all great, but how do you find the right?",
            "So not only we now have to find topics, relevance is, but also mature and that sort of brings us to."
        ],
        [
            "Our results.",
            "So we propose a generative model which actually built, which describes how the irac is constructed, and it's a.",
            "Using some adversarial game where adverse addressing gets to tune some notes and then push the button that Europe is constructed and we show no matter how horses in case we can still write up.",
            "This will guarantee the accuracy of the classification.",
            "And the second stage is that we treat the whole European as entire as a giant picture models and just use regular results.",
            "And then we showed it in this.",
            "We can show that we might take for granted even if not only part of the ear.",
            "Again, we maintain the classification for spending time in Taiwan.",
            "So what does it mean?",
            "So suppose we know.",
            "On the base topic.",
            "So we don't know anything about that.",
            "And now we see a document which is about 20 pounds, which is actually about cycling, which is not in the in the Iraqi as we know.",
            "So we can sort it in the fabric of this little patient, reports.",
            "An contributions that we designed an album which allows you to feel that you are from from unlabeled data, so the second one, even apart we can prove that something would happen.",
            "We can show how you can actually feel the fear and finally we presented dependent result.",
            "So let me go into there first."
        ],
        [
            "The generative model.",
            "So as I said to you, recognition models have mixture models underneath of them, so each topic is still a probability distributions or overall possible terms, and but now there is a base topic we should kind of includes all governments, and utopic is generated for the parent by adversity.",
            "It's only summer, possibly all of difficulties, so we start with this topic and you can think of base topic as just ended distribution.",
            "So just as a channel frequency across all the documents that you could find an address, you choose how traffic is changes in this one topic.",
            "Then how changing another and then it continues down in Europe?",
            "And slightly more."
        ],
        [
            "Formal let's actually define.",
            "So first adversary chooses.",
            "And major solution and we don't just how he chooses.",
            "No matter no matter what choices he makes.",
            "I'll grant you still home.",
            "I'm at least part of it.",
            "I decided or the number of products offered by serving size to have $2 and then let each child he chose vector probability distribution which essentially defines how each term is going to be altered.",
            "They choose for each problem of how their frequencies that object and then there.",
            "Pictures of determine the child, He will be just frequency of the shop of disrupting the parent, plus some notes, and this noise is the distribution that is being chosen from is defined by dressing.",
            "So we do have to restrict that how it was.",
            "It can choose the distributions, but those are general conditions which we can actually show that they are all necessary."
        ],
        [
            "So.",
            "I suppose so.",
            "OK, so the child topic is in traffic plus there plus applications and each location that we require that the expectation of the changes 0 so that probability goes up or down.",
            "Button expectations missing?",
            "Second?",
            "Why the child topic should be different from the parent company?",
            "And that's again like something because if they are the same, there's no reasonable way how we can fix this emails.",
            "3rd one, weed.",
            "No matter how it works.",
            "So I guess we cannot choose.",
            "Connections noted the frequency become negative because we don't know what negative because it means so.",
            "Probability will change.",
            "Let it be 0 and finally, which is the most natural conditions.",
            "Here we require the spread of the distribution to work and what it is that we want the frequency changes to be concentrated across many channels, not just a few single ones.",
            "We can show that this is also necessary condition.",
            "So."
        ],
        [
            "So that's that's our model and.",
            "Let me briefly overview there later.",
            "Perhaps the most well known is there using Chinese Chinese restaurant process followed by lightning like he's laid off from his own for.",
            "So the based on the basis of that unregister soldiery clan here.",
            "We don't have have different approaches to get directly from the label data or using.",
            "Model trump.",
            "And then there is a lot of work.",
            "We just sort of not related, but it's also your here question.",
            "But it's a bottom up approach.",
            "We start building power plus info.",
            "Such a finding things together, then build things from small clusters.",
            "So."
        ],
        [
            "So that's that's even model.",
            "And now let's go back how we can show it only if you not quite like Europe that we maintain classification versus the Tier 1."
        ],
        [
            "So again, suppose we order.",
            "Unsportsman, sorry.",
            "Please sign up.",
            "It's also so we have.",
            "We know that, but now we have a document which is on physics of hockey puck.",
            "So it belongs to two topics.",
            "And physics.",
            "So we show that the crawfish contributes to healthier will in fact get just assigned to the."
        ],
        [
            "So.",
            "So how do we do this?",
            "Well, let's just treat a pie in the Sky rocket as a single instance of a mixture model and just solve it completely independently of the rest of the model.",
            "So it's so weird.",
            "So here it is, I know is a topic, so we create the instruction model and we don't solve it.",
            "It's not clear though.",
            "In particular, the problem is in reality or in all of our model.",
            "The documents are in generated from a different decision that that I, from those that we have in our mission.",
            "But however we are, we can show that that's actually.",
            "Because of our general assumption actually works.",
            "So before I go into details, apply, first let me actually show you how to do classification for just for regular mission work.",
            "So forget it for a few minutes that we actually have your ankle mixture model and let's come back from second to play."
        ],
        [
            "Schwantd, so suppose we have a major topics and each document is not just a sample from this picture.",
            "So this is based perspective on the document document and.",
            "What was this?",
            "As a sample from the Holder probability distribution, which is a linear combination of the topics so given.",
            "Correct that we need to compute underlying mixing coefficients.",
            "So I sort of classical approaches just let's just use naive Bayes.",
            "But the problem is that my base only works if you know for sure that document belongs to one topic, otherwise it gives someone unclear guarantees and you have to do a lot of doing to actually make it work.",
            "So she did the rest of the event.",
            "The better way is actually used to divorce, and they actually provide you can recover under license with small Aaron Hypernova.",
            "Not go into too much detail about this funding company self, so just one single flag."
        ],
        [
            "So the idea that you can find a matrix B such that if your computer if your computer product.",
            "So if you eat.",
            "Just like speed and.",
            "And a 22 packages actually recover the true true true true purpose of hyper growth.",
            "And you can show that this holds and the.",
            "How much is my Microsoft account?",
            "Paper for more details, so let me know.",
            "Or is no problem?"
        ],
        [
            "So the initial that because there is a pot pie for the record, whereas our document is generated from from another public PJ outside of this path.",
            "So an being generated based on the probability distribution.",
            "So what we can show is that.",
            "If we just treat her computer, consider reflectors for that work with the with the path.",
            "Then we can show the product.",
            "Of what you observe for there for the original document will be the same as observed difficult having generated from the closest node in the path and then decided so.",
            "It doesn't matter if we don't get that we don't know their distributions being generally found, but we, but we assume that it's just been generated from there.",
            "The topic is generated from the other daily processes generated, and that's.",
            "And so that's pretty much how we how we do.",
            "At the office.",
            "These are.",
            "Actual proof of life, right?",
            "So this is just.",
            "Some interest."
        ],
        [
            "No, let me go to how to be reconstructed Iraqi.",
            "Probably so their album is actually.",
            "Fairly simple, so they use that.",
            "We compute their ambient history.",
            "I'm going to frequency though that does it all.",
            "All the channels across all the differences we have and that forms are based based out of there for each child topic where we build occurrence matrix.",
            "That is how often every pair of transporting an across all columns of this occurrence matrix which we choose, one which is.",
            "Basic hustle and then classified documents that belongs to this new topic and then so now we.",
            "We have sort of binary instance of classification tasks and now we have documents which are still part of the original.",
            "Part of it.",
            "Envy you just tried on both an additional fees.",
            "Actually, when there is no document, we found the topic, but we found no documents.",
            "We decided that that actually indicator that the Europeans"
        ],
        [
            "So now looking at going to experimental is also the midnight reforms really well, so we."
        ],
        [
            "Did some experiments on archive or other sensitive, so we use 1/4 million abstracts, which mostly on different activities like have some computer science and math and M and goes to there.",
            "Professional agreement to produce individual clusters, so the result we produced 76.",
            "And overcompensated was 7070%."
        ],
        [
            "These are actually.",
            "Some numbers and they both things that actually performed really well despite there is a really huge difference in the size of the class.",
            "For example, computer science has only ever had very high precision recall, for instance.",
            "Astrophysics has 44,000 classes and has his own hierarchy.",
            "It also had very high across his record, and another thing is that that is not possible there.",
            "In the past these how many clusters get this.",
            "There is a majority of this form computing recall and precision over reported that sometimes we will find some field actually have found a single big cluster and then the algorithm will just explaining them because it felt there are more topics in there and we just resolution in the original data to tell whether.",
            "Reasonable speed alone and this.",
            "Recall effort is 70%."
        ],
        [
            "And the second experiment was on a useful data set.",
            "Where is not winning his drugs from there on several $1,000,000.",
            "Tronics, politics, religion.",
            "To help with small data set it has and.",
            "So because of that they only use in order to only build.",
            "Chocolate clusters, and so the good news that the client that they found.",
            "Well coincided with."
        ],
        [
            "Speak of the topic.",
            "So what happened was that the first half of the column's computer station footprint, like everything from the computer related topics.",
            "The second class refundable sports, which had some of the medicine, but it doesn't make sense.",
            "Start on the campaign.",
            "Middle Eastern medicine about politics and religion.",
            "Pendergast wasn't friendly.",
            "Michelle Mitchell Sleeve or fungals.",
            "Purely religious and again Publix near forgot to be diluted because Middle East area is going to be.",
            "Feast topic was great talking politics and motorcycles artists get diluted by medicine because of their taxes.",
            "All the topics so they don't necessarily point exactly with the boundaries, but the question.",
            "The problem is that it's not clear that any other would be able to or any human should be able to start it up.",
            "So I'm that spray."
        ],
        [
            "If so, we provide a three different work too.",
            "I've always talked about Europes.",
            "If it is a national general construct from scratch and we provided algorithm algorithm building erected from unlabeled data.",
            "And is there any questions?",
            "I'm happy to ask for so possible #15.",
            "Questions.",
            "Alright, let's start.",
            "Do you think do you know how you would take advantage of someone was willing to go through and label just a couple for you?",
            "Is is there an easy way to take?",
            "Yeah?",
            "Sure you can actually use that to build the topical distributions.",
            "So right now we build it from unlabeled data from the current metrics.",
            "But if you have some label data, you can just build a channel frequency and said this is my topic.",
            "Do something with it and that makes sense.",
            "We actually support that actually works very well.",
            "So you obviously went through for like a solution based on linear algebra.",
            "It's weather related work having like an Moe, and they use a Gibbs sampler right?",
            "So why did you decide to go for that particular solution as opposed to kind of these other and more statistically oriented?",
            "Any reason for needing switching back?",
            "So I guess you don't want so.",
            "I did get a clear clear so I was trying to.",
            "Show that you can find so most most of this property, say so.",
            "Here's the problem.",
            "Let's let's run some local optimization or find something.",
            "So what I was trying to do is to see if you can actually guarantee that that's what you found is closer to the real ones.",
            "Whatever the real one is, and that's sort of made to actually think about it.",
            "I mean, in the world of mixture models, I guess it's a question of how flows mixture models started reality, but.",
            "Interesting, yeah, what this algorithm exhausted the weight of.",
            "So the main thing is that we don't assume any specific shape on their probability distribution on the underlying probability distributions, so we don't say anything he said.",
            "How do I choose any decision he wants and then the process starts?",
            "I mean, I'm happy to talk like this.",
            "Thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so the topic of my talk is Rockefeller Mixer balls are probabilistic analysis and let me begin with a short overview of why are we in this kind of prob.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So it's a classical problem.",
                    "label": 1
                },
                {
                    "sent": "We have a bunch of documents and they are on various topics and we would like to automatically classify them and mixture models provide us with a way to formally reason about the problem and.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In order mixture models actually.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "It's not supposed to go like this.",
                    "label": 0
                },
                {
                    "sent": "Supposed to go 1 by 1.",
                    "label": 1
                },
                {
                    "sent": "So innovation model each each topic different probability distribution of our entire whatever.",
                    "label": 1
                },
                {
                    "sent": "So mods could have it published English like that and physics which looks like something else and each document is characterized by quantity from relevance to each one of those topics.",
                    "label": 0
                },
                {
                    "sent": "And of course this is an overly simplistic representation, but the hope is that it will actually capturing all of the properties which would let us characterize document which topic it belongs to.",
                    "label": 1
                },
                {
                    "sent": "And of course document.",
                    "label": 0
                },
                {
                    "sent": "And a document is thought of as a repeated sample from one of those virtual distributions, and the goal is that we have these documents and we want to infer the underlying topics Anna computer document.",
                    "label": 0
                },
                {
                    "sent": "World of regular mixed models and the question is why, what?",
                    "label": 0
                },
                {
                    "sent": "Why do we actually want you in there?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the problem is that.",
                    "label": 0
                },
                {
                    "sent": "We actually.",
                    "label": 0
                },
                {
                    "sent": "There are lots of topics in real data.",
                    "label": 1
                },
                {
                    "sent": "There could be hundreds, hundreds of thousands, and regular remodels just want all of them, which might not be just visible for check.",
                    "label": 0
                },
                {
                    "sent": "Maybe 1234123.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "I was running away.",
                    "label": 0
                },
                {
                    "sent": "It was a lot alright, so there are lots of topics in real data and we want to and it might not be feasible to find all of them.",
                    "label": 1
                },
                {
                    "sent": "And another thing is that topics are not independent, so topics.",
                    "label": 0
                },
                {
                    "sent": "So something about Mom.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, we classified as a science and you wrote.",
                    "label": 0
                },
                {
                    "sent": "It allows us to include this kind of dependencies.",
                    "label": 1
                },
                {
                    "sent": "And another thing that you're OK.",
                    "label": 0
                },
                {
                    "sent": "I'll just do lazy question.",
                    "label": 1
                },
                {
                    "sent": "So I definitely are according to difference could be just initially classified into sports without actually wearing wearing in this party.",
                    "label": 0
                },
                {
                    "sent": "So this is all great, but how do you find the right?",
                    "label": 0
                },
                {
                    "sent": "So not only we now have to find topics, relevance is, but also mature and that sort of brings us to.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our results.",
                    "label": 0
                },
                {
                    "sent": "So we propose a generative model which actually built, which describes how the irac is constructed, and it's a.",
                    "label": 1
                },
                {
                    "sent": "Using some adversarial game where adverse addressing gets to tune some notes and then push the button that Europe is constructed and we show no matter how horses in case we can still write up.",
                    "label": 0
                },
                {
                    "sent": "This will guarantee the accuracy of the classification.",
                    "label": 0
                },
                {
                    "sent": "And the second stage is that we treat the whole European as entire as a giant picture models and just use regular results.",
                    "label": 1
                },
                {
                    "sent": "And then we showed it in this.",
                    "label": 1
                },
                {
                    "sent": "We can show that we might take for granted even if not only part of the ear.",
                    "label": 0
                },
                {
                    "sent": "Again, we maintain the classification for spending time in Taiwan.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "So suppose we know.",
                    "label": 0
                },
                {
                    "sent": "On the base topic.",
                    "label": 0
                },
                {
                    "sent": "So we don't know anything about that.",
                    "label": 0
                },
                {
                    "sent": "And now we see a document which is about 20 pounds, which is actually about cycling, which is not in the in the Iraqi as we know.",
                    "label": 0
                },
                {
                    "sent": "So we can sort it in the fabric of this little patient, reports.",
                    "label": 1
                },
                {
                    "sent": "An contributions that we designed an album which allows you to feel that you are from from unlabeled data, so the second one, even apart we can prove that something would happen.",
                    "label": 0
                },
                {
                    "sent": "We can show how you can actually feel the fear and finally we presented dependent result.",
                    "label": 0
                },
                {
                    "sent": "So let me go into there first.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The generative model.",
                    "label": 0
                },
                {
                    "sent": "So as I said to you, recognition models have mixture models underneath of them, so each topic is still a probability distributions or overall possible terms, and but now there is a base topic we should kind of includes all governments, and utopic is generated for the parent by adversity.",
                    "label": 1
                },
                {
                    "sent": "It's only summer, possibly all of difficulties, so we start with this topic and you can think of base topic as just ended distribution.",
                    "label": 0
                },
                {
                    "sent": "So just as a channel frequency across all the documents that you could find an address, you choose how traffic is changes in this one topic.",
                    "label": 0
                },
                {
                    "sent": "Then how changing another and then it continues down in Europe?",
                    "label": 0
                },
                {
                    "sent": "And slightly more.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Formal let's actually define.",
                    "label": 0
                },
                {
                    "sent": "So first adversary chooses.",
                    "label": 0
                },
                {
                    "sent": "And major solution and we don't just how he chooses.",
                    "label": 0
                },
                {
                    "sent": "No matter no matter what choices he makes.",
                    "label": 0
                },
                {
                    "sent": "I'll grant you still home.",
                    "label": 0
                },
                {
                    "sent": "I'm at least part of it.",
                    "label": 1
                },
                {
                    "sent": "I decided or the number of products offered by serving size to have $2 and then let each child he chose vector probability distribution which essentially defines how each term is going to be altered.",
                    "label": 1
                },
                {
                    "sent": "They choose for each problem of how their frequencies that object and then there.",
                    "label": 1
                },
                {
                    "sent": "Pictures of determine the child, He will be just frequency of the shop of disrupting the parent, plus some notes, and this noise is the distribution that is being chosen from is defined by dressing.",
                    "label": 0
                },
                {
                    "sent": "So we do have to restrict that how it was.",
                    "label": 0
                },
                {
                    "sent": "It can choose the distributions, but those are general conditions which we can actually show that they are all necessary.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I suppose so.",
                    "label": 0
                },
                {
                    "sent": "OK, so the child topic is in traffic plus there plus applications and each location that we require that the expectation of the changes 0 so that probability goes up or down.",
                    "label": 0
                },
                {
                    "sent": "Button expectations missing?",
                    "label": 0
                },
                {
                    "sent": "Second?",
                    "label": 0
                },
                {
                    "sent": "Why the child topic should be different from the parent company?",
                    "label": 1
                },
                {
                    "sent": "And that's again like something because if they are the same, there's no reasonable way how we can fix this emails.",
                    "label": 0
                },
                {
                    "sent": "3rd one, weed.",
                    "label": 0
                },
                {
                    "sent": "No matter how it works.",
                    "label": 0
                },
                {
                    "sent": "So I guess we cannot choose.",
                    "label": 0
                },
                {
                    "sent": "Connections noted the frequency become negative because we don't know what negative because it means so.",
                    "label": 0
                },
                {
                    "sent": "Probability will change.",
                    "label": 0
                },
                {
                    "sent": "Let it be 0 and finally, which is the most natural conditions.",
                    "label": 1
                },
                {
                    "sent": "Here we require the spread of the distribution to work and what it is that we want the frequency changes to be concentrated across many channels, not just a few single ones.",
                    "label": 0
                },
                {
                    "sent": "We can show that this is also necessary condition.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's that's our model and.",
                    "label": 0
                },
                {
                    "sent": "Let me briefly overview there later.",
                    "label": 0
                },
                {
                    "sent": "Perhaps the most well known is there using Chinese Chinese restaurant process followed by lightning like he's laid off from his own for.",
                    "label": 1
                },
                {
                    "sent": "So the based on the basis of that unregister soldiery clan here.",
                    "label": 0
                },
                {
                    "sent": "We don't have have different approaches to get directly from the label data or using.",
                    "label": 0
                },
                {
                    "sent": "Model trump.",
                    "label": 0
                },
                {
                    "sent": "And then there is a lot of work.",
                    "label": 0
                },
                {
                    "sent": "We just sort of not related, but it's also your here question.",
                    "label": 0
                },
                {
                    "sent": "But it's a bottom up approach.",
                    "label": 0
                },
                {
                    "sent": "We start building power plus info.",
                    "label": 0
                },
                {
                    "sent": "Such a finding things together, then build things from small clusters.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's that's even model.",
                    "label": 0
                },
                {
                    "sent": "And now let's go back how we can show it only if you not quite like Europe that we maintain classification versus the Tier 1.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, suppose we order.",
                    "label": 0
                },
                {
                    "sent": "Unsportsman, sorry.",
                    "label": 0
                },
                {
                    "sent": "Please sign up.",
                    "label": 0
                },
                {
                    "sent": "It's also so we have.",
                    "label": 0
                },
                {
                    "sent": "We know that, but now we have a document which is on physics of hockey puck.",
                    "label": 1
                },
                {
                    "sent": "So it belongs to two topics.",
                    "label": 0
                },
                {
                    "sent": "And physics.",
                    "label": 0
                },
                {
                    "sent": "So we show that the crawfish contributes to healthier will in fact get just assigned to the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So how do we do this?",
                    "label": 0
                },
                {
                    "sent": "Well, let's just treat a pie in the Sky rocket as a single instance of a mixture model and just solve it completely independently of the rest of the model.",
                    "label": 1
                },
                {
                    "sent": "So it's so weird.",
                    "label": 0
                },
                {
                    "sent": "So here it is, I know is a topic, so we create the instruction model and we don't solve it.",
                    "label": 0
                },
                {
                    "sent": "It's not clear though.",
                    "label": 0
                },
                {
                    "sent": "In particular, the problem is in reality or in all of our model.",
                    "label": 1
                },
                {
                    "sent": "The documents are in generated from a different decision that that I, from those that we have in our mission.",
                    "label": 0
                },
                {
                    "sent": "But however we are, we can show that that's actually.",
                    "label": 0
                },
                {
                    "sent": "Because of our general assumption actually works.",
                    "label": 0
                },
                {
                    "sent": "So before I go into details, apply, first let me actually show you how to do classification for just for regular mission work.",
                    "label": 0
                },
                {
                    "sent": "So forget it for a few minutes that we actually have your ankle mixture model and let's come back from second to play.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Schwantd, so suppose we have a major topics and each document is not just a sample from this picture.",
                    "label": 1
                },
                {
                    "sent": "So this is based perspective on the document document and.",
                    "label": 0
                },
                {
                    "sent": "What was this?",
                    "label": 0
                },
                {
                    "sent": "As a sample from the Holder probability distribution, which is a linear combination of the topics so given.",
                    "label": 1
                },
                {
                    "sent": "Correct that we need to compute underlying mixing coefficients.",
                    "label": 1
                },
                {
                    "sent": "So I sort of classical approaches just let's just use naive Bayes.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that my base only works if you know for sure that document belongs to one topic, otherwise it gives someone unclear guarantees and you have to do a lot of doing to actually make it work.",
                    "label": 0
                },
                {
                    "sent": "So she did the rest of the event.",
                    "label": 0
                },
                {
                    "sent": "The better way is actually used to divorce, and they actually provide you can recover under license with small Aaron Hypernova.",
                    "label": 0
                },
                {
                    "sent": "Not go into too much detail about this funding company self, so just one single flag.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea that you can find a matrix B such that if your computer if your computer product.",
                    "label": 1
                },
                {
                    "sent": "So if you eat.",
                    "label": 0
                },
                {
                    "sent": "Just like speed and.",
                    "label": 0
                },
                {
                    "sent": "And a 22 packages actually recover the true true true true purpose of hyper growth.",
                    "label": 0
                },
                {
                    "sent": "And you can show that this holds and the.",
                    "label": 0
                },
                {
                    "sent": "How much is my Microsoft account?",
                    "label": 1
                },
                {
                    "sent": "Paper for more details, so let me know.",
                    "label": 0
                },
                {
                    "sent": "Or is no problem?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the initial that because there is a pot pie for the record, whereas our document is generated from from another public PJ outside of this path.",
                    "label": 1
                },
                {
                    "sent": "So an being generated based on the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So what we can show is that.",
                    "label": 0
                },
                {
                    "sent": "If we just treat her computer, consider reflectors for that work with the with the path.",
                    "label": 0
                },
                {
                    "sent": "Then we can show the product.",
                    "label": 0
                },
                {
                    "sent": "Of what you observe for there for the original document will be the same as observed difficult having generated from the closest node in the path and then decided so.",
                    "label": 1
                },
                {
                    "sent": "It doesn't matter if we don't get that we don't know their distributions being generally found, but we, but we assume that it's just been generated from there.",
                    "label": 0
                },
                {
                    "sent": "The topic is generated from the other daily processes generated, and that's.",
                    "label": 0
                },
                {
                    "sent": "And so that's pretty much how we how we do.",
                    "label": 0
                },
                {
                    "sent": "At the office.",
                    "label": 0
                },
                {
                    "sent": "These are.",
                    "label": 0
                },
                {
                    "sent": "Actual proof of life, right?",
                    "label": 0
                },
                {
                    "sent": "So this is just.",
                    "label": 0
                },
                {
                    "sent": "Some interest.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, let me go to how to be reconstructed Iraqi.",
                    "label": 0
                },
                {
                    "sent": "Probably so their album is actually.",
                    "label": 0
                },
                {
                    "sent": "Fairly simple, so they use that.",
                    "label": 0
                },
                {
                    "sent": "We compute their ambient history.",
                    "label": 0
                },
                {
                    "sent": "I'm going to frequency though that does it all.",
                    "label": 0
                },
                {
                    "sent": "All the channels across all the differences we have and that forms are based based out of there for each child topic where we build occurrence matrix.",
                    "label": 1
                },
                {
                    "sent": "That is how often every pair of transporting an across all columns of this occurrence matrix which we choose, one which is.",
                    "label": 1
                },
                {
                    "sent": "Basic hustle and then classified documents that belongs to this new topic and then so now we.",
                    "label": 0
                },
                {
                    "sent": "We have sort of binary instance of classification tasks and now we have documents which are still part of the original.",
                    "label": 0
                },
                {
                    "sent": "Part of it.",
                    "label": 0
                },
                {
                    "sent": "Envy you just tried on both an additional fees.",
                    "label": 1
                },
                {
                    "sent": "Actually, when there is no document, we found the topic, but we found no documents.",
                    "label": 0
                },
                {
                    "sent": "We decided that that actually indicator that the Europeans",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now looking at going to experimental is also the midnight reforms really well, so we.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Did some experiments on archive or other sensitive, so we use 1/4 million abstracts, which mostly on different activities like have some computer science and math and M and goes to there.",
                    "label": 1
                },
                {
                    "sent": "Professional agreement to produce individual clusters, so the result we produced 76.",
                    "label": 0
                },
                {
                    "sent": "And overcompensated was 7070%.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are actually.",
                    "label": 0
                },
                {
                    "sent": "Some numbers and they both things that actually performed really well despite there is a really huge difference in the size of the class.",
                    "label": 0
                },
                {
                    "sent": "For example, computer science has only ever had very high precision recall, for instance.",
                    "label": 0
                },
                {
                    "sent": "Astrophysics has 44,000 classes and has his own hierarchy.",
                    "label": 0
                },
                {
                    "sent": "It also had very high across his record, and another thing is that that is not possible there.",
                    "label": 0
                },
                {
                    "sent": "In the past these how many clusters get this.",
                    "label": 0
                },
                {
                    "sent": "There is a majority of this form computing recall and precision over reported that sometimes we will find some field actually have found a single big cluster and then the algorithm will just explaining them because it felt there are more topics in there and we just resolution in the original data to tell whether.",
                    "label": 0
                },
                {
                    "sent": "Reasonable speed alone and this.",
                    "label": 0
                },
                {
                    "sent": "Recall effort is 70%.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second experiment was on a useful data set.",
                    "label": 0
                },
                {
                    "sent": "Where is not winning his drugs from there on several $1,000,000.",
                    "label": 0
                },
                {
                    "sent": "Tronics, politics, religion.",
                    "label": 0
                },
                {
                    "sent": "To help with small data set it has and.",
                    "label": 0
                },
                {
                    "sent": "So because of that they only use in order to only build.",
                    "label": 0
                },
                {
                    "sent": "Chocolate clusters, and so the good news that the client that they found.",
                    "label": 0
                },
                {
                    "sent": "Well coincided with.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speak of the topic.",
                    "label": 0
                },
                {
                    "sent": "So what happened was that the first half of the column's computer station footprint, like everything from the computer related topics.",
                    "label": 0
                },
                {
                    "sent": "The second class refundable sports, which had some of the medicine, but it doesn't make sense.",
                    "label": 0
                },
                {
                    "sent": "Start on the campaign.",
                    "label": 0
                },
                {
                    "sent": "Middle Eastern medicine about politics and religion.",
                    "label": 0
                },
                {
                    "sent": "Pendergast wasn't friendly.",
                    "label": 0
                },
                {
                    "sent": "Michelle Mitchell Sleeve or fungals.",
                    "label": 0
                },
                {
                    "sent": "Purely religious and again Publix near forgot to be diluted because Middle East area is going to be.",
                    "label": 0
                },
                {
                    "sent": "Feast topic was great talking politics and motorcycles artists get diluted by medicine because of their taxes.",
                    "label": 0
                },
                {
                    "sent": "All the topics so they don't necessarily point exactly with the boundaries, but the question.",
                    "label": 0
                },
                {
                    "sent": "The problem is that it's not clear that any other would be able to or any human should be able to start it up.",
                    "label": 0
                },
                {
                    "sent": "So I'm that spray.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If so, we provide a three different work too.",
                    "label": 0
                },
                {
                    "sent": "I've always talked about Europes.",
                    "label": 0
                },
                {
                    "sent": "If it is a national general construct from scratch and we provided algorithm algorithm building erected from unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "And is there any questions?",
                    "label": 0
                },
                {
                    "sent": "I'm happy to ask for so possible #15.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Alright, let's start.",
                    "label": 0
                },
                {
                    "sent": "Do you think do you know how you would take advantage of someone was willing to go through and label just a couple for you?",
                    "label": 0
                },
                {
                    "sent": "Is is there an easy way to take?",
                    "label": 0
                },
                {
                    "sent": "Yeah?",
                    "label": 0
                },
                {
                    "sent": "Sure you can actually use that to build the topical distributions.",
                    "label": 0
                },
                {
                    "sent": "So right now we build it from unlabeled data from the current metrics.",
                    "label": 0
                },
                {
                    "sent": "But if you have some label data, you can just build a channel frequency and said this is my topic.",
                    "label": 0
                },
                {
                    "sent": "Do something with it and that makes sense.",
                    "label": 0
                },
                {
                    "sent": "We actually support that actually works very well.",
                    "label": 0
                },
                {
                    "sent": "So you obviously went through for like a solution based on linear algebra.",
                    "label": 0
                },
                {
                    "sent": "It's weather related work having like an Moe, and they use a Gibbs sampler right?",
                    "label": 0
                },
                {
                    "sent": "So why did you decide to go for that particular solution as opposed to kind of these other and more statistically oriented?",
                    "label": 0
                },
                {
                    "sent": "Any reason for needing switching back?",
                    "label": 0
                },
                {
                    "sent": "So I guess you don't want so.",
                    "label": 0
                },
                {
                    "sent": "I did get a clear clear so I was trying to.",
                    "label": 0
                },
                {
                    "sent": "Show that you can find so most most of this property, say so.",
                    "label": 0
                },
                {
                    "sent": "Here's the problem.",
                    "label": 0
                },
                {
                    "sent": "Let's let's run some local optimization or find something.",
                    "label": 0
                },
                {
                    "sent": "So what I was trying to do is to see if you can actually guarantee that that's what you found is closer to the real ones.",
                    "label": 0
                },
                {
                    "sent": "Whatever the real one is, and that's sort of made to actually think about it.",
                    "label": 0
                },
                {
                    "sent": "I mean, in the world of mixture models, I guess it's a question of how flows mixture models started reality, but.",
                    "label": 0
                },
                {
                    "sent": "Interesting, yeah, what this algorithm exhausted the weight of.",
                    "label": 0
                },
                {
                    "sent": "So the main thing is that we don't assume any specific shape on their probability distribution on the underlying probability distributions, so we don't say anything he said.",
                    "label": 0
                },
                {
                    "sent": "How do I choose any decision he wants and then the process starts?",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm happy to talk like this.",
                    "label": 0
                },
                {
                    "sent": "Thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}