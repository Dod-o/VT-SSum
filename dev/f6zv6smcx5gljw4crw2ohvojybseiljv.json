{
    "id": "f6zv6smcx5gljw4crw2ohvojybseiljv",
    "title": "Estimation of Location Uncertainty for Scale Invariant Features Points",
    "info": {
        "author": [
            "Bernhard Zeisl, Department of Computer Science, ETH Zurich"
        ],
        "published": "Dec. 1, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc09_zeisl_elus/",
    "segmentation": [
        [
            "My name is Bennett Cisel and I'm going to talk about estimation of location uncertainty for scaling."
        ],
        [
            "Again, feature points.",
            "Cindy Binning I want to give a motivation and make the problem statement clear, so I assume most of know most of you know what feature detection and the concept of local features are.",
            "They are state of the art in computer vision and used in a number of applications like object detection, localization in object nutrition and image retrieval or in weight baseline matching in 3D reconstruction.",
            "So the inception the discipline caitians make is.",
            "That feature points are I detected accurately on the other side, the deviation in error is constant for all of the feature points.",
            "So in what we claim is that this assumption doesn't hold true.",
            "Why wouldn't that be so?"
        ],
        [
            "So.",
            "Let's have a look at this feature point, which represents the eye of the dude in the picture.",
            "And if we want to try to re detect this point in the same image but now with image noise introduced.",
            "We will get a distribution.",
            "Around the feature point.",
            "And if we do that for similar feature points, we will get the distribution of the arrow, which doesn't look the same for all, so they have different shapes.",
            "So the goal of this work is to.",
            "Estimate an individual localization error for each feature point detected in an image, and we model this distribution is Gaussian, so the parameterized the location accuracy by a covariance matrix.",
            "So the next."
        ],
        [
            "Step I will just briefly explain what invariant local feature detection means and how it works.",
            "Then I will represent the estimation or uncertainty estimation framework redeveloped most of the time I will spend on explaining experiments and results we got and finally conclude the talk."
        ],
        [
            "So why is there actually an error in localising a point in an image?",
            "And there's two reasons?",
            "On the one hand side, we have got pixel intensity noise and then the other side.",
            "Does the algorithm itself.",
            "So I assume we have got.",
            "X, which is a ground truth point.",
            "But we actually don't know about this groundtruth location.",
            "An there isn't.",
            "It tends to be related to that point, so the capturing process will introduce some noise and the following detection algorithm will build on this intensity plus noise and the argument itself introduces some other noise becauses approximate calculations mainly for complexity reasons.",
            "So in the end we will come up with a point X hat which is not the real ground truth point.",
            "Anne."
        ],
        [
            "As we stated in our title, we want to evaluate the uncertainty for scale invariant feature points.",
            "So scale invariant feature point detection allows us to detect the feature different sizes in images and it's a two step approach.",
            "So on the 1st or like the first step is representation in scale space, so the image is represented.",
            "In an image pyramid of differently sized or consecutively more blurred images.",
            "And then the detection operator of the algorithm is applied to each of these layers and the local maximum in the layer response or relates to a feature point.",
            "And in the second step we try to find the particular size of that feature which is done by a critical touristic scale selection.",
            "They apply another function and the maximum gives you the scale.",
            "So in that example the scale for that feature would be 6.4 hits 3.2.",
            "So duration tells us this.",
            "Features got double size and if you normalize by this scale, we're able to compare features.",
            "But for detection and the location of a point, only the first step is important, which is the scale space representation and the application of detector to it.",
            "So let's stick with that."
        ],
        [
            "And Nessa said before.",
            "A feature point.",
            "Is the local maximum in the detector response?",
            "On the right hand side you can see this blue surface.",
            "That's the detector response for the particular layer.",
            "And the intuition or.",
            "What we say now is if this surface around the point is very flat.",
            "The probability that we make an error in locating this point will be higher than if the surface is pointy.",
            "So how can we map that in a mathematical formulation?",
            "First we define a residual and approximate that residual 2nd order, which is then clearly described by the Hessian and the Hessian is nothing else than describing the curvature.",
            "So if we want to now.",
            "Parameterized the accuracy with which we can take the point.",
            "We take the inverse of the Hessian and get the covariance matrix, and this is also shown here.",
            "We are this..."
        ],
        [
            "And we implemented this approach for the SIFT and surf feature detector.",
            "Just because both are widely used.",
            "They are very similar.",
            "They only differ in the way.",
            "How do you calculate the detector response?",
            "So safety is using a difference of Gaussians approach while surface using the determinant of the Hessian.",
            "But once you got get detector response.",
            "You can apply the same approach, So what we actually did is we calculate a weighted sum.",
            "Of Hessians aintain.",
            "Take the inverse to get the covariance matrix.",
            "What is important here?",
            "Because we do not increase the complexity of any detection algorithm because the detect responses already calculated.",
            "The only thing we need to do is calculate this derivatives and they are implemented by different filters.",
            "So for sift and surf.",
            "Or Sift and surf.",
            "Implement the scale space by grouping it into octave.",
            "So and each of the octave contains a particularly sized images.",
            "So if it detects or want to estimate the covariance for a particular feature point at a particular scale which is not related to the current image size, you have to pack project to covariance to the actual image size.",
            "So how?"
        ],
        [
            "Should then actually work and observe the behavior.",
            "We did this statistical error modeling.",
            "So we created an image Patch.",
            "Which one specific feature in it and the special thing about that features is that we know the ground truth, location of the feature point.",
            "So we created such patches for SIFT and SURF and we have another application where we show how to derive that, especially for surf and what you can do with it.",
            "But here it's only important we know the ground truth location of a feature point.",
            "Then we introduced noise to dispatches and also did a projective transformation of the Patch.",
            "And the result is that we get the distribution of the location which is shown in blue.",
            "And the red dashed line.",
            "Is illustrating the maximum like list estimate for the covariance which is describing the real underlying distribution of the error and you can see our black.",
            "Ellipse which results from our covariance estimate really follows that shape.",
            "And we did the same experiment for surf and we came up with same results.",
            "So we can state here that our covariance estimate really follows the underlying distribution of the error."
        ],
        [
            "So in the first step we were able to show that the shape of the covariance matrix fits to the underlying distribution.",
            "In the second step we wanted to see how does the scale in.",
            "Change the covariance matrix so in that two diagrams you can see on the Y axis we plot the Frobenius norm of the covariance, which is related to the size of the covariance or the size of the arrow.",
            "And on the X axis you can see the scale.",
            "So an interesting thing here to see is that for a particular scale.",
            "We get for a higher scale.",
            "We get a higher error, so there is an higher localization error.",
            "4 points detected at a higher scale.",
            "And if we have look in a real image.",
            "This green points feature points appoint should have a small covariance matrix and this yellow circles appoints which have high norm for their covariance matrix.",
            "So.",
            "And Additionally, you can see this green points relate to distinctive features in an image and the yellow circles relate to blobs, so blobs, avers, localized than distinctive image features.",
            "Right?",
            "Another thing to note here is that these norm of the covariance matrix.",
            "Is in quadratic dependence to this scale and.",
            "That implies."
        ],
        [
            "Is that the covariances have an automatic scale normalization behavior?",
            "So I want to give you an example.",
            "Take 2 images, one which has a high resolution, the other one with small resolution and you want to register it to each other.",
            "So if you just do it with another optimization approach here, the arrow in the high resolution image will be a lot higher just because of the image size.",
            "So in an optimization a lot more weight will be given on that image.",
            "So what you normally do is that you normalize the error.",
            "But if you apply our covariances.",
            "This is automatically done.",
            "So in these two images.",
            "Covariances for corresponding feature points are illustrated.",
            "And covariances relating to this image are projected via the underlying homography.",
            "And you can see that the covariances are almost identically, so the localization error is similar for both images in relation to their size, and you can use this.",
            "Coherence is now to normalize the error and it will Additionally also weight the error.",
            "In an optimization approach, and thus differently sized images can be used."
        ],
        [
            "And we actually did this for bundle adjustment, so bundle adjustment is trying to recover the 3D structure of his scene now that the pose of the cameras.",
            "In our example, the scene are four patches located a different deaths from the cameras, and we know the ground rules location of these corner points.",
            "So we took a couple of images and now try to recover.",
            "The projection.",
            "Of dispatches into the images.",
            "And if you normally apply bundle adjustment in.",
            "NET Framework, you will try to minimize the Acadian distance of you.",
            "Re projection of this 3D points.",
            "So normally you can do better because you don't have covariance matrices for your feature points.",
            "But we.",
            "Um?",
            "Deliver them so if you apply them you will minimize the melanosis distance.",
            "So points which are localized better will have a higher weight in the minimization.",
            "And as a result, we evaluate.",
            "We evaluate performance in terms of the reprojection error of the known corner points.",
            "So just some example."
        ],
        [
            "Images this magenta triangle is the ground truth point of a corner point in an image.",
            "And the Green Square is the corner point projected with the estimated projection, so we can see that the Green square is closer to the triangle, so we get a best better estimate.",
            "And we and we if we evaluate that mathematically.",
            "We have about had about 100 image pairs and calculated the mean of the reprojection error.",
            "So.",
            "We get an improvement in terms of reprojection error, four shift, and for Surfer bundle adjust."
        ],
        [
            "So Deanna would just shortly wrap up the main contributions of that work.",
            "At first we gave a general formulation for feature detection and scale space.",
            "Actually that was not presented in that presentation, but it will be given in the paper.",
            "Then we were able to compute stable covariances for scaling variant image features.",
            "We gave justification for the correctness of the covariance estimates.",
            "We showed that this covariances have an inherent scale normalization behavior.",
            "And finally we were able to show that there is a performance improvement for bundle adjustment.",
            "And actually there are a couple of other model fitting algorithms, so we would like really like to encourage you to test and use our results and the code of our.",
            "Approach is available at that webpage.",
            "So thank you for your attention and I'm looking forward to your questions.",
            "Yeah."
        ],
        [
            "No, that's a very good command, and we're thinking about that as well, but I think you're referring to that example, so the features the matching features we have are the same.",
            "So if you have a higher resolution image to find exactly the same feature, we have to go up in the pyramid a lot higher so we will detect the featured exactly the same size, so the accuracy is the same.",
            "So say maybe maybe I have to state also for that image.",
            "We detect a lot more features.",
            "And also features which cannot detect detected here.",
            "So they're more accurate, but if you want to detect the same feature in both images, you have to go very up high here in the pyramid, and that as you said, there is a lot of blurring and so you lose the accuracy.",
            "OK.",
            "In that case, we compared to performance by minimizing the kleidion distance and by minimizing the melanomas distance.",
            "So in the if we used the Milanovich distance, you incorporate the covariances.",
            "So in that case point which we find to be localized very accurately will have a higher weight.",
            "Compared to a point which is not that well localized and in their Canadian distance, both have the same weight.",
            "So like if wrong localized to badly localized pointers to same influences, better localized point.",
            "So if we concentrate on the points which are better localized, we will get a better estimate of the 3D scene.",
            "Right and the reprojection error is actually the.",
            "Known location in an image of the corner point.",
            "Subtracted by the projected 3D corner point and that's the estimate here.",
            "And that projection estimate is better if you use the covariances, right?",
            "Yeah.",
            "So as I said, like the detector response is already calculated in every detection algorithm and the only thing we do is calculate the Hessian at the neighbor of the feature point."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Bennett Cisel and I'm going to talk about estimation of location uncertainty for scaling.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, feature points.",
                    "label": 0
                },
                {
                    "sent": "Cindy Binning I want to give a motivation and make the problem statement clear, so I assume most of know most of you know what feature detection and the concept of local features are.",
                    "label": 1
                },
                {
                    "sent": "They are state of the art in computer vision and used in a number of applications like object detection, localization in object nutrition and image retrieval or in weight baseline matching in 3D reconstruction.",
                    "label": 1
                },
                {
                    "sent": "So the inception the discipline caitians make is.",
                    "label": 0
                },
                {
                    "sent": "That feature points are I detected accurately on the other side, the deviation in error is constant for all of the feature points.",
                    "label": 0
                },
                {
                    "sent": "So in what we claim is that this assumption doesn't hold true.",
                    "label": 0
                },
                {
                    "sent": "Why wouldn't that be so?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at this feature point, which represents the eye of the dude in the picture.",
                    "label": 0
                },
                {
                    "sent": "And if we want to try to re detect this point in the same image but now with image noise introduced.",
                    "label": 0
                },
                {
                    "sent": "We will get a distribution.",
                    "label": 0
                },
                {
                    "sent": "Around the feature point.",
                    "label": 0
                },
                {
                    "sent": "And if we do that for similar feature points, we will get the distribution of the arrow, which doesn't look the same for all, so they have different shapes.",
                    "label": 0
                },
                {
                    "sent": "So the goal of this work is to.",
                    "label": 0
                },
                {
                    "sent": "Estimate an individual localization error for each feature point detected in an image, and we model this distribution is Gaussian, so the parameterized the location accuracy by a covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "So the next.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Step I will just briefly explain what invariant local feature detection means and how it works.",
                    "label": 0
                },
                {
                    "sent": "Then I will represent the estimation or uncertainty estimation framework redeveloped most of the time I will spend on explaining experiments and results we got and finally conclude the talk.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why is there actually an error in localising a point in an image?",
                    "label": 0
                },
                {
                    "sent": "And there's two reasons?",
                    "label": 0
                },
                {
                    "sent": "On the one hand side, we have got pixel intensity noise and then the other side.",
                    "label": 1
                },
                {
                    "sent": "Does the algorithm itself.",
                    "label": 0
                },
                {
                    "sent": "So I assume we have got.",
                    "label": 0
                },
                {
                    "sent": "X, which is a ground truth point.",
                    "label": 1
                },
                {
                    "sent": "But we actually don't know about this groundtruth location.",
                    "label": 0
                },
                {
                    "sent": "An there isn't.",
                    "label": 0
                },
                {
                    "sent": "It tends to be related to that point, so the capturing process will introduce some noise and the following detection algorithm will build on this intensity plus noise and the argument itself introduces some other noise becauses approximate calculations mainly for complexity reasons.",
                    "label": 1
                },
                {
                    "sent": "So in the end we will come up with a point X hat which is not the real ground truth point.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As we stated in our title, we want to evaluate the uncertainty for scale invariant feature points.",
                    "label": 1
                },
                {
                    "sent": "So scale invariant feature point detection allows us to detect the feature different sizes in images and it's a two step approach.",
                    "label": 0
                },
                {
                    "sent": "So on the 1st or like the first step is representation in scale space, so the image is represented.",
                    "label": 0
                },
                {
                    "sent": "In an image pyramid of differently sized or consecutively more blurred images.",
                    "label": 0
                },
                {
                    "sent": "And then the detection operator of the algorithm is applied to each of these layers and the local maximum in the layer response or relates to a feature point.",
                    "label": 0
                },
                {
                    "sent": "And in the second step we try to find the particular size of that feature which is done by a critical touristic scale selection.",
                    "label": 0
                },
                {
                    "sent": "They apply another function and the maximum gives you the scale.",
                    "label": 0
                },
                {
                    "sent": "So in that example the scale for that feature would be 6.4 hits 3.2.",
                    "label": 0
                },
                {
                    "sent": "So duration tells us this.",
                    "label": 0
                },
                {
                    "sent": "Features got double size and if you normalize by this scale, we're able to compare features.",
                    "label": 1
                },
                {
                    "sent": "But for detection and the location of a point, only the first step is important, which is the scale space representation and the application of detector to it.",
                    "label": 0
                },
                {
                    "sent": "So let's stick with that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And Nessa said before.",
                    "label": 0
                },
                {
                    "sent": "A feature point.",
                    "label": 0
                },
                {
                    "sent": "Is the local maximum in the detector response?",
                    "label": 1
                },
                {
                    "sent": "On the right hand side you can see this blue surface.",
                    "label": 0
                },
                {
                    "sent": "That's the detector response for the particular layer.",
                    "label": 0
                },
                {
                    "sent": "And the intuition or.",
                    "label": 0
                },
                {
                    "sent": "What we say now is if this surface around the point is very flat.",
                    "label": 0
                },
                {
                    "sent": "The probability that we make an error in locating this point will be higher than if the surface is pointy.",
                    "label": 0
                },
                {
                    "sent": "So how can we map that in a mathematical formulation?",
                    "label": 0
                },
                {
                    "sent": "First we define a residual and approximate that residual 2nd order, which is then clearly described by the Hessian and the Hessian is nothing else than describing the curvature.",
                    "label": 0
                },
                {
                    "sent": "So if we want to now.",
                    "label": 0
                },
                {
                    "sent": "Parameterized the accuracy with which we can take the point.",
                    "label": 0
                },
                {
                    "sent": "We take the inverse of the Hessian and get the covariance matrix, and this is also shown here.",
                    "label": 0
                },
                {
                    "sent": "We are this...",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we implemented this approach for the SIFT and surf feature detector.",
                    "label": 0
                },
                {
                    "sent": "Just because both are widely used.",
                    "label": 0
                },
                {
                    "sent": "They are very similar.",
                    "label": 0
                },
                {
                    "sent": "They only differ in the way.",
                    "label": 0
                },
                {
                    "sent": "How do you calculate the detector response?",
                    "label": 0
                },
                {
                    "sent": "So safety is using a difference of Gaussians approach while surface using the determinant of the Hessian.",
                    "label": 0
                },
                {
                    "sent": "But once you got get detector response.",
                    "label": 0
                },
                {
                    "sent": "You can apply the same approach, So what we actually did is we calculate a weighted sum.",
                    "label": 0
                },
                {
                    "sent": "Of Hessians aintain.",
                    "label": 0
                },
                {
                    "sent": "Take the inverse to get the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "What is important here?",
                    "label": 0
                },
                {
                    "sent": "Because we do not increase the complexity of any detection algorithm because the detect responses already calculated.",
                    "label": 0
                },
                {
                    "sent": "The only thing we need to do is calculate this derivatives and they are implemented by different filters.",
                    "label": 0
                },
                {
                    "sent": "So for sift and surf.",
                    "label": 1
                },
                {
                    "sent": "Or Sift and surf.",
                    "label": 0
                },
                {
                    "sent": "Implement the scale space by grouping it into octave.",
                    "label": 0
                },
                {
                    "sent": "So and each of the octave contains a particularly sized images.",
                    "label": 0
                },
                {
                    "sent": "So if it detects or want to estimate the covariance for a particular feature point at a particular scale which is not related to the current image size, you have to pack project to covariance to the actual image size.",
                    "label": 0
                },
                {
                    "sent": "So how?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Should then actually work and observe the behavior.",
                    "label": 0
                },
                {
                    "sent": "We did this statistical error modeling.",
                    "label": 1
                },
                {
                    "sent": "So we created an image Patch.",
                    "label": 0
                },
                {
                    "sent": "Which one specific feature in it and the special thing about that features is that we know the ground truth, location of the feature point.",
                    "label": 1
                },
                {
                    "sent": "So we created such patches for SIFT and SURF and we have another application where we show how to derive that, especially for surf and what you can do with it.",
                    "label": 0
                },
                {
                    "sent": "But here it's only important we know the ground truth location of a feature point.",
                    "label": 0
                },
                {
                    "sent": "Then we introduced noise to dispatches and also did a projective transformation of the Patch.",
                    "label": 0
                },
                {
                    "sent": "And the result is that we get the distribution of the location which is shown in blue.",
                    "label": 0
                },
                {
                    "sent": "And the red dashed line.",
                    "label": 0
                },
                {
                    "sent": "Is illustrating the maximum like list estimate for the covariance which is describing the real underlying distribution of the error and you can see our black.",
                    "label": 0
                },
                {
                    "sent": "Ellipse which results from our covariance estimate really follows that shape.",
                    "label": 0
                },
                {
                    "sent": "And we did the same experiment for surf and we came up with same results.",
                    "label": 0
                },
                {
                    "sent": "So we can state here that our covariance estimate really follows the underlying distribution of the error.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the first step we were able to show that the shape of the covariance matrix fits to the underlying distribution.",
                    "label": 0
                },
                {
                    "sent": "In the second step we wanted to see how does the scale in.",
                    "label": 0
                },
                {
                    "sent": "Change the covariance matrix so in that two diagrams you can see on the Y axis we plot the Frobenius norm of the covariance, which is related to the size of the covariance or the size of the arrow.",
                    "label": 0
                },
                {
                    "sent": "And on the X axis you can see the scale.",
                    "label": 0
                },
                {
                    "sent": "So an interesting thing here to see is that for a particular scale.",
                    "label": 0
                },
                {
                    "sent": "We get for a higher scale.",
                    "label": 0
                },
                {
                    "sent": "We get a higher error, so there is an higher localization error.",
                    "label": 0
                },
                {
                    "sent": "4 points detected at a higher scale.",
                    "label": 1
                },
                {
                    "sent": "And if we have look in a real image.",
                    "label": 0
                },
                {
                    "sent": "This green points feature points appoint should have a small covariance matrix and this yellow circles appoints which have high norm for their covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And Additionally, you can see this green points relate to distinctive features in an image and the yellow circles relate to blobs, so blobs, avers, localized than distinctive image features.",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Another thing to note here is that these norm of the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Is in quadratic dependence to this scale and.",
                    "label": 0
                },
                {
                    "sent": "That implies.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that the covariances have an automatic scale normalization behavior?",
                    "label": 1
                },
                {
                    "sent": "So I want to give you an example.",
                    "label": 0
                },
                {
                    "sent": "Take 2 images, one which has a high resolution, the other one with small resolution and you want to register it to each other.",
                    "label": 0
                },
                {
                    "sent": "So if you just do it with another optimization approach here, the arrow in the high resolution image will be a lot higher just because of the image size.",
                    "label": 0
                },
                {
                    "sent": "So in an optimization a lot more weight will be given on that image.",
                    "label": 0
                },
                {
                    "sent": "So what you normally do is that you normalize the error.",
                    "label": 0
                },
                {
                    "sent": "But if you apply our covariances.",
                    "label": 0
                },
                {
                    "sent": "This is automatically done.",
                    "label": 1
                },
                {
                    "sent": "So in these two images.",
                    "label": 0
                },
                {
                    "sent": "Covariances for corresponding feature points are illustrated.",
                    "label": 1
                },
                {
                    "sent": "And covariances relating to this image are projected via the underlying homography.",
                    "label": 0
                },
                {
                    "sent": "And you can see that the covariances are almost identically, so the localization error is similar for both images in relation to their size, and you can use this.",
                    "label": 1
                },
                {
                    "sent": "Coherence is now to normalize the error and it will Additionally also weight the error.",
                    "label": 1
                },
                {
                    "sent": "In an optimization approach, and thus differently sized images can be used.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we actually did this for bundle adjustment, so bundle adjustment is trying to recover the 3D structure of his scene now that the pose of the cameras.",
                    "label": 1
                },
                {
                    "sent": "In our example, the scene are four patches located a different deaths from the cameras, and we know the ground rules location of these corner points.",
                    "label": 0
                },
                {
                    "sent": "So we took a couple of images and now try to recover.",
                    "label": 0
                },
                {
                    "sent": "The projection.",
                    "label": 0
                },
                {
                    "sent": "Of dispatches into the images.",
                    "label": 0
                },
                {
                    "sent": "And if you normally apply bundle adjustment in.",
                    "label": 0
                },
                {
                    "sent": "NET Framework, you will try to minimize the Acadian distance of you.",
                    "label": 0
                },
                {
                    "sent": "Re projection of this 3D points.",
                    "label": 0
                },
                {
                    "sent": "So normally you can do better because you don't have covariance matrices for your feature points.",
                    "label": 0
                },
                {
                    "sent": "But we.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Deliver them so if you apply them you will minimize the melanosis distance.",
                    "label": 0
                },
                {
                    "sent": "So points which are localized better will have a higher weight in the minimization.",
                    "label": 0
                },
                {
                    "sent": "And as a result, we evaluate.",
                    "label": 0
                },
                {
                    "sent": "We evaluate performance in terms of the reprojection error of the known corner points.",
                    "label": 0
                },
                {
                    "sent": "So just some example.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Images this magenta triangle is the ground truth point of a corner point in an image.",
                    "label": 0
                },
                {
                    "sent": "And the Green Square is the corner point projected with the estimated projection, so we can see that the Green square is closer to the triangle, so we get a best better estimate.",
                    "label": 0
                },
                {
                    "sent": "And we and we if we evaluate that mathematically.",
                    "label": 0
                },
                {
                    "sent": "We have about had about 100 image pairs and calculated the mean of the reprojection error.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "We get an improvement in terms of reprojection error, four shift, and for Surfer bundle adjust.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Deanna would just shortly wrap up the main contributions of that work.",
                    "label": 0
                },
                {
                    "sent": "At first we gave a general formulation for feature detection and scale space.",
                    "label": 1
                },
                {
                    "sent": "Actually that was not presented in that presentation, but it will be given in the paper.",
                    "label": 0
                },
                {
                    "sent": "Then we were able to compute stable covariances for scaling variant image features.",
                    "label": 0
                },
                {
                    "sent": "We gave justification for the correctness of the covariance estimates.",
                    "label": 1
                },
                {
                    "sent": "We showed that this covariances have an inherent scale normalization behavior.",
                    "label": 1
                },
                {
                    "sent": "And finally we were able to show that there is a performance improvement for bundle adjustment.",
                    "label": 0
                },
                {
                    "sent": "And actually there are a couple of other model fitting algorithms, so we would like really like to encourage you to test and use our results and the code of our.",
                    "label": 1
                },
                {
                    "sent": "Approach is available at that webpage.",
                    "label": 0
                },
                {
                    "sent": "So thank you for your attention and I'm looking forward to your questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, that's a very good command, and we're thinking about that as well, but I think you're referring to that example, so the features the matching features we have are the same.",
                    "label": 0
                },
                {
                    "sent": "So if you have a higher resolution image to find exactly the same feature, we have to go up in the pyramid a lot higher so we will detect the featured exactly the same size, so the accuracy is the same.",
                    "label": 0
                },
                {
                    "sent": "So say maybe maybe I have to state also for that image.",
                    "label": 0
                },
                {
                    "sent": "We detect a lot more features.",
                    "label": 0
                },
                {
                    "sent": "And also features which cannot detect detected here.",
                    "label": 0
                },
                {
                    "sent": "So they're more accurate, but if you want to detect the same feature in both images, you have to go very up high here in the pyramid, and that as you said, there is a lot of blurring and so you lose the accuracy.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In that case, we compared to performance by minimizing the kleidion distance and by minimizing the melanomas distance.",
                    "label": 0
                },
                {
                    "sent": "So in the if we used the Milanovich distance, you incorporate the covariances.",
                    "label": 0
                },
                {
                    "sent": "So in that case point which we find to be localized very accurately will have a higher weight.",
                    "label": 0
                },
                {
                    "sent": "Compared to a point which is not that well localized and in their Canadian distance, both have the same weight.",
                    "label": 0
                },
                {
                    "sent": "So like if wrong localized to badly localized pointers to same influences, better localized point.",
                    "label": 0
                },
                {
                    "sent": "So if we concentrate on the points which are better localized, we will get a better estimate of the 3D scene.",
                    "label": 0
                },
                {
                    "sent": "Right and the reprojection error is actually the.",
                    "label": 0
                },
                {
                    "sent": "Known location in an image of the corner point.",
                    "label": 0
                },
                {
                    "sent": "Subtracted by the projected 3D corner point and that's the estimate here.",
                    "label": 0
                },
                {
                    "sent": "And that projection estimate is better if you use the covariances, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So as I said, like the detector response is already calculated in every detection algorithm and the only thing we do is calculate the Hessian at the neighbor of the feature point.",
                    "label": 0
                }
            ]
        }
    }
}