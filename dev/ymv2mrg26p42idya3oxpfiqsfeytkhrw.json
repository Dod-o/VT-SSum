{
    "id": "ymv2mrg26p42idya3oxpfiqsfeytkhrw",
    "title": "Scalable Collaborative Filtering Algorithms for Mining Social Networks",
    "info": {
        "author": [
            "Edward Chang, Google, Inc."
        ],
        "published": "Dec. 20, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Network Analysis->Social Networks"
        ]
    },
    "url": "http://videolectures.net/bsciw08_chang_scfamsn/",
    "segmentation": [
        [
            "Good afternoon everyone in the presentation today I'm going to start with two applications to motivate why we want to do social network data mining and then the second half I'm going to talk about how to make some very popular algorithms scalable."
        ],
        [
            "You're multiple machines.",
            "And I'd like to acknowledge my collaborators first, so this will be published online so we can look at the details later."
        ],
        [
            "So we look at two systems.",
            "The first system was just built in China launch in China and Russia and this is a Q&A system and many people must have used the Yahoo answers right?",
            "And basically the user can post question and other users can answer the question.",
            "The idea is very simple.",
            "We launched the system about a year ago.",
            "You see, this is a code name.",
            "The product or Confucius, and in the first year or so you see the traffic was very low and the black number signify questions and the right number shows answers and before August this year both Q&A's the volumes are pretty low.",
            "And some magic happens around August.",
            "Machine learning we implement a few machine learning algorithms and then the system suddenly kicks off."
        ],
        [
            "And the second example application I will talk about is open social and how many have heard about open social.",
            "OK, that's great and Opensocial this far.",
            "Has reached about 675 users worldwide.",
            "Basically there are many major product social network products worldwide.",
            "Utilize open social as a standard and I will also going to talk about when social, slightly and motivating why we want to do scalable data mining."
        ],
        [
            "And let's begin with 1.0.",
            "One .0.",
            "Basically we have lots of document on the web.",
            "We send qualities to crawl documents, indexed documents and rank.",
            "The documents and user pretty much just submitting keyword queries."
        ],
        [
            "Getting their desired documents.",
            "For weapons to Web 2.0 this morning we heard about the talks.",
            "People also get involved in the picture.",
            "An so we have users can upload information in a QA system.",
            "The user can pose a question and other users can provide answers and between documents we have links and not only between documents.",
            "Also between users we may have explicit links, also implicit links."
        ],
        [
            "And let me go back to this Q&A system and basically we want to allow people to ask questions when they cannot find."
        ],
        [
            "Information from web search.",
            "And this is 1 example.",
            "Suppose I want to do a query.",
            "What are must see attractions in?"
        ],
        [
            "The storm.",
            "And for this query I can get desirable results from Google Search.",
            "If I click on the first one, I can see a three major attractions at Yellowstone.",
            "And let me do another query."
        ],
        [
            "What are the must see attraction at Yosemite and this query result is not as good if you see the result actually is coming from.",
            "Lodging site The lodging site is minor in and you can see massing attraction at the bottom.",
            "And if you go to Asia."
        ],
        [
            "Where websites are not very popular.",
            "And when I do a query about Marcia traction in Beijing, I get this page back and trust me on the left hand side you get a lot of advertisements.",
            "So for emerging markets, since we don't have a lot of sites and QA system become very important otherwise we don't have sufficient information to index and one example is the Korean market.",
            "And how could in the Korean market Google Market share is very very low?",
            "And market share is only 3%.",
            "The reason is because our major competitor called Never.",
            "They have a very good Q&A system and the system collects a lot of Q&A pairs.",
            "The little content and they block Google Crawler according the content and Google has nothing to index in Korea.",
            "So we lose the market to our competitor.",
            "So because of this reason, UGC."
        ],
        [
            "Becomes very important.",
            "And let's go back to the computer traffic and you look at the picture we consider.",
            "There are a number of key subroutines need to be implemented.",
            "So starting from a web search, we do a web search.",
            "If we don't see the results satisfactory and we can trigger a question answer session.",
            "So this is a first machine learning subroutine.",
            "Need to be implemented.",
            "The second one is given the question we like to be able to provide labels and this is like a very simple classification task.",
            "And the third one is given the question you want to find in the Q&A repository.",
            "Some similar questions people ask before and probably provides us right away.",
            "And the 4th one is we like to be able to evaluate user credentials and I will give you a reason why user credential is very important shortly.",
            "And the next one is given a question.",
            "We like to route the question to expert users, and otherwise every user comes into a system.",
            "They see a large number of questions is really hard for a user to sort through.",
            "All the question to find the question they can answer.",
            "And we like to be able to evaluate quality of the question is restreaming important if you want to evaluate user credential, the first thing we need to evaluate will be the answer quality.",
            "Otherwise you may evaluate a spammer to be a top performer.",
            "And finally, this is everybody's dream if we can provide subroutine which can do machine generated answers, I think you can start company today.",
            "And today I'm going to just talk about the first one.",
            "How do we evaluate user credential in a domain specific way?",
            "So."
        ],
        [
            "So naive user credential system is like this.",
            "Very simple 1 user register onto the system.",
            "We give the person a few points and each time the person login we give the person some points and so on so forth.",
            "And this system is problematic for a few reasons.",
            "I just give you a two simple reasons.",
            "One is, this system is very easy."
        ],
        [
            "It'll be damned if I sign on to 1000 different names and I post some questions myself, answer to myself, then I can get a lot of points.",
            "And also I can cut and paste other people's solutions as my answers.",
            "And some people can easily post advertisements onto the system and you get a lot of spams.",
            "And also freshness can be an issue.",
            "So suppose a user has been a top performer and if you don't consider the time factor, the freshness may not be properly considered."
        ],
        [
            "So this is a very simple system proposed by an intern working at Yahoo a few years ago, and this in turn just joined Google about a year ago.",
            "And this is a very simple formulation.",
            "Basically, if you're looking on the left, every user is is a node on this graph.",
            "And if a user answer question to another person, so we view a link, for instance user a answers question of user BC&E.",
            "To preventing spam, an Zoltan proposed between 2 users, you only can one link running multiple links, so on the right hand side, if we look at in links of ABCD, we get 04, and so on, so forth.",
            "And we don't care bout in links in links means I pose questions and many people ask answer my questions so that doesn't seem a persons question.",
            "Get a lot of people answered.",
            "The person is important.",
            "So in this situation we consider our links.",
            "And we consider unique our links and on the right hand side we can see 30221 and so on so forth and user a seems to be the most important.",
            "And this method is quite simple, and however it can also be easy spam.",
            "So suppose I answer all questions using the same answer.",
            "And this system cannot detect these particular spamming situation, so further things has to be done.",
            "So what we have done is we wait the edges."
        ],
        [
            "Currently based on answer quality and so on and so forth, which I don't plan to get into details.",
            "But the user credential is also important not only for identify most productive users, but also we can use user credential to do a page ranking.",
            "We all know about on Q&A system blocks and BBS we cannot harvest a lot of Intralinks.",
            "We don't Intralinks Pagerank that basically cannot work.",
            "And under this situation, we consider actually if you can do author rank very effectively, then utilizing author rank as an anchor point for the Pagerank, we can rate your content very effectively.",
            "So here I give you a very simple example.",
            "Suppose I have a query Q&A systems about Yosemite top attractions and I get about 10 questions about you 70 attractions.",
            "So here I illustrated by 4.",
            "So if I can measure the quality of which QA pair has the highest quality, suppose 0.4 means the lowest priority zero point 6 means the highest priority.",
            "Then when I do the web indexing, I can index a higher priority, higher quality kewene paired in on the web search result.",
            "An for each Q and a pair I may get multiple answers if we need to generate snippets, we cannot just randomly pick answers.",
            "We'd like to pick the answer with highest quality.",
            "If we know the author credential an IF we trust the high quality, authors can provide high quality documents, then author credential can give us a hint about the document quality and we consider this is one of the most effective methods for ranking Q&A blog and BBS and provide more effective searching experience."
        ],
        [
            "So I've mentioned about this Confucius, the next one is Opensocial."
        ],
        [
            "An open social.",
            "We talk about Web 2.0 ready and we can link documents together.",
            "We can link users together and open social.",
            "Take one step forward."
        ],
        [
            "Basically, we can put social platform on the home page.",
            "And let me give you an example.",
            "So we can substitute an HTML page as a container on the container.",
            "We can put application gadgets on it."
        ],
        [
            "So this is a very simple application we have built also in China and in the middle you see a Frank graph in the middle is my boss and my boss.",
            "We can display his friends.",
            "And also then we if we mouse over the particular person we can see the."
        ],
        [
            "Persons recent activities."
        ],
        [
            "So you can see there are three already properties on this platform.",
            "We can get a person's profile, we can get a person friends.",
            "Also, we can harvest a person's activities.",
            "In addition, we can also know the person, staff or the person have.",
            "For instance, this is a."
        ],
        [
            "Science blog.",
            "And we can now."
        ],
        [
            "Person has uploaded a lot of photos allowed UGC by a person."
        ],
        [
            "So if you look at the whole picture, open social APIs, we have four API's user profile, user, friends, activities and stuff.",
            "And based on the full API's, you can write applications."
        ],
        [
            "Do a lot of interesting things.",
            "So here I'm going to just give a very simple example on the right hand side and this application is I want to plot my friends on a map.",
            "So what I can do is first of all I call open social API, get my friends profile.",
            "And once I get the profile, I get the profile of the person's location."
        ],
        [
            "And then I can plot the person on this particular map.",
            "If I zoom."
        ],
        [
            "Into Beijing I can see my friends at Beijing if I further zoom in.",
            "I can see his recent activities."
        ],
        [
            "And the open social platform give us an interesting benefit.",
            "Once you write a gadget, you can put a gadget onto multiple platforms which comply to open social platform.",
            "So you write application once and application can be utilized in many places.",
            "And what's the benefit of having this platform?"
        ],
        [
            "Let me give you 2 examples.",
            "The first one is a personalized search example.",
            "Suppose I can know your profile.",
            "I understand your friends.",
            "I can harvest your activities and so on so forth.",
            "Maybe I can find harvest sufficient signals to try to do personalized search.",
            "And one example is supposed to have a Fuji search and Fuji can mean multiple things can be Fuji Mount and can be Fuji apples or Fuji cameras."
        ],
        [
            "If I look at my friends."
        ],
        [
            "Circle and I under."
        ],
        [
            "Then recently my friends are writing about digital camera blocks, so maybe the Fuji Fuji search means about Fuji cameras."
        ],
        [
            "And."
        ],
        [
            "Another example is a personal recommendation and we consider recommendation is a push model of search.",
            "And this one example is suppose a user has search for image of motorcycle.",
            "Then perhaps we can recommend another motorcycle photo to the person.",
            "A person has search for Niagara Falls pictures."
        ],
        [
            "We can recommend another one.",
            "And in general recommendation system, we can recommend photos, Friends, Community forums and also advertisements.",
            "The key requirement for a good recommendation system will be scalability, scalability, and."
        ],
        [
            "Ability.",
            "And this leads to the second half of the presentation, and we implemented a few key subroutines to provide scalable data mining.",
            "And you can look into details if you are interested in.",
            "The detail algorithm and I'm going to just focus on discussing two algorithms today, frequent itemset mining and this CCF algorithm.",
            "And less motivated a little bit why we need to have clustering algorithm."
        ],
        [
            "For analyzing social."
        ],
        [
            "Network.",
            "And suppose we want to do as targeting and this has been a very important problem for social network companies.",
            "We know most of social network companies haven't been able to make a profit.",
            "An we like to basically like to match match our ads to users.",
            "And one traditional paradigm is."
        ],
        [
            "We try to my profiles of users.",
            "Maybe we can get friends of user activity and so on and so forth.",
            "We try to match relevance between users and users activities and documents and this example shows my own profile.",
            "My friends, my stuff and also my activity.",
            "With open social API you can get more information to do relevance mining.",
            "However, this morning has been done for years, but like for example by Myspace by other social network companies and relevance itself may not be sufficient.",
            "Another important"
        ],
        [
            "There is influence.",
            "We not only want to know relevance, we also want to find influential users on the social network.",
            "And for instance, on this particular social network, we would like to do a centrality analysis.",
            "We like to analyze user quick credentials with user capabilities when we target ads.",
            "Maybe we should target users with highest influence.",
            "And the details we are not going to cover today in details because we have two patterns in."
        ],
        [
            "Nation.",
            "So let's get into frequent items."
        ],
        [
            "Mining.",
            "Collaborated filtering this particular data mining mechanism can be detected by this 2 dimensional matrix, so we have two dimensions here on the horizontal dimension will be the items we like to recommend to the vertical dimension users, and in this example I shows we like to recommend."
        ],
        [
            "Photos to users.",
            "If you see one in the cell means the particular user has access a particular photo.",
            "And what we like to accomplish is we like to guess the value on this question marks.",
            "So if suppose the value here will be either 010 means a user has never accessed this particular photo.",
            "1 means the user has accessed.",
            "We would like to be able to compute the probability of whether a user would like to access this particular photo with?",
            "If the probability value is very high, we will recommend the photo to the user."
        ],
        [
            "So basically, if I am frequent itemset mining can support this particular recommendation.",
            "So I gave you example already if I've already seen three photos and the question is, should I recommend you the fourth photo.",
            "And we look at associated mining rule.",
            "Basically, given AB&C, we like to find the conditional probability of given ABC.",
            "What is the conditional probability is desirable and this is equal to the support of ABC D divided by support of ABC.",
            "If we can compute support of ABC and ABC D We get this basic interpretation then we can do our recommendations.",
            "So."
        ],
        [
            "Let's look at FIM and basically we can make two observations.",
            "The first opposition is suppose an item A is not frequent.",
            "Then any pattern contents A won't be frequent.",
            "This is observation done by Rakesh.",
            "Suppose we have an item A&AB.",
            "If we know a is not frequent then AIB's super set cannot be frequent.",
            "The second observation is made by johannan pattern contents A or subsets of transactions contain a.",
            "So if we build conditional database of a containing all transactions content containing a.",
            "If we want to find the item set containing a, we have to go to this particular transaction database.",
            "So this is what it says here.",
            "And one example is, suppose we have a BAC and A3 transactions.",
            "We put those transaction into conditional transaction database a.",
            "Suppose we have a B&B C. We put them into translation database B, so this is quite straightforward, But you can right away see a problem.",
            "We may have duplicates, so observation three is suppose we want to divide the transaction into conditional databases an we may have duplicates between databases.",
            "An our mission to do this, divide and conquer so therefore we can paralyze the algorithm is to try to divide transition into independent databases without duplicates.",
            "So let's work through it."
        ],
        [
            "Example to show how we do it.",
            "Suppose I have five transactions on the left hand side.",
            "So first of all, I count the support of individual items.",
            "So we have F equal to four, and so on and so forth.",
            "And suppose we set the threshold support equal to three, so all the items with support less than three, we cut them off and we can rewrite all the transactions to be the middle column.",
            "So basically FCD and so on so forth.",
            "We get rid of load supper items, rewriting the transaction to be this one.",
            "An according to observe opposition Station one so already we get rid of low supply items and then we sort items on each transaction by the same order.",
            "Here we are sorting everything by the support value so you can see the support value.",
            "F is the highest, MP is the lowest.",
            "So every transaction will be sorted in this descending order.",
            "And once we have done this sorting, we can then avoid duplication.",
            "So."
        ],
        [
            "So let's see the next slide.",
            "How we divide the items into multiple conditional databases.",
            "So according to observation B, so we like to be able to divide transactions independently.",
            "And but how do we construct KDB?",
            "Suppose we have KDB containing a.",
            "And the example I gave you is PCA can be in three conditional databases.",
            "But if we sort them in alphabetical order, this is 1 order.",
            "We can solve the transactions then the following rule can avoid duplication, so we only put the prefix of a particular item into the conditional database.",
            "So if we sorbier see into ABC, then we if we look for items should be put into conditional database a the previous A.",
            "The prefix of A is empty set, so for conditional database a we put nothing in the database.",
            "4B We put a in a database.",
            "For C we put A&B.",
            "And by following the rule we can make sure we don't have duplicates in the conditional databases.",
            "So let's work through the same."
        ],
        [
            "Example to see how this can be done.",
            "So for conditional database P we go to all the transactions and we only harvest the prefix.",
            "So for the first one we get FCM.",
            "And for this one we get CB for the last one we get FCM.",
            "And do the same thing.",
            "We can compute conditional transaction database M conditi."
        ],
        [
            "Database B and so and so forth."
        ],
        [
            "Not going to get into the details."
        ],
        [
            "So once we have conditional database build, so this picture shows at every level level of the tree we can have independent conditional databases.",
            "But if the conditional database is very large, it's larger than the memory can hold the transactions.",
            "Then we recursively further divide the conditional database.",
            "So in this example, suppose we have a D as the conditional database and the contents AB&C.",
            "We can further divide conditional database D. In the database DADB&DC we do this recursion split until the.",
            "The final node can feed into the memory.",
            "So once the final conditional database can fit into memory, we can start to do our frequent itemset mining."
        ],
        [
            "So next picture shows we already distributed computation onto multiple machines on one machine.",
            "This machine containing conditional data with P and we see there are three transactions.",
            "And that's a magnified it to harvest item sets with support greater or equal than three, you can see P is one of them, and then we can see C occur three times.",
            "So P and PC will be our frequent itemsets in this situation.",
            "And we can do the same for every single conditional databases.",
            "At the end we aggregate the results together.",
            "We get the final frequent item sets.",
            "And the example I just showed you."
        ],
        [
            "Can be implemented on map reduce because a we can divide the datasets onto independent databases.",
            "And Secondly we don't have iterative situations.",
            "Once we do the computation on one particular node, we don't have to go back to the same node to do further computation.",
            "So map reduce is a perfect infrastructure for such parallelization."
        ],
        [
            "The next one I'm going to illustrate.",
            "MapReduce may not be the best choice, and we call the algorithm combination combination of collaborative filtering.",
            "Let me motivate why we need this particular algorithm.",
            "We already talked about frequent itemset mining and some of you may thought well it's very easy, very straightforward.",
            "We don't any other fancy algorithm, but there are a couple of shortcomings of frequent itemset mining.",
            "So here, let me use the example of four."
        ],
        [
            "Recommendation, suppose a user joins multiple number of forums.",
            "We like to be able to recommend a user other forms to join.",
            "So likewise we use the same metrics to decode a forum user has joined.",
            "But here if you look at the frequent itemset situation, we can only feel number 01 in the cells.",
            "An suppose a user participate in forum many times.",
            "We'd like to be able to also encode the strength or interest.",
            "So therefore this is probably a better formulation of the problem we want to solve.",
            "So we put numbers in there rather than just doing 1.",
            "And Furthermore, we like to be able to encode latent aspect or categories of forums."
        ],
        [
            "So before we get into details, let's define some notations and we use C to donate community.",
            "We use U to denote users.",
            "D is descripcion a set of keywords.",
            "And Z will be latent aspects.",
            "Descriptions are often use her off the community or descriptiones description of community here.",
            "Ann with going to discuss 2 baseline models.",
            "The first one is Community user model community.",
            "Descripcion model is the second model and then we talk about combined model.",
            "So this is a latent property this later."
        ],
        [
            "Semantic analysis proposed by Hoffman.",
            "And basically, suppose we want to.",
            "Did describe the joint probability of D&C so community and its description.",
            "So we can rewrite the joint distribution into PC and the conditional probability.",
            "An introducing Z in the middle.",
            "The latent aspect.",
            "We can rewrite it as the follows.",
            "And by having this formulation, we not only can do a recommendation, but also we can do analysis.",
            "We can do probability inferencing between C and between D and also DC joint probability.",
            "So you can compare this model with FIMFIN.",
            "We cannot do this kind of analysis, But with PSA.",
            "Further analysis can be performed.",
            "And."
        ],
        [
            "Once we have the model, then we can learn a Model V OEM or Gibbs sampling algorithm.",
            "So further motivate why we need to have latent aspect.",
            "Suppose we have two documents.",
            "One document says the Apple is the fruit of Apple tree and so on so forth.",
            "The other document talk about the Apple Computer Company and suppose we have a topic distribution latent layer and the topic topics are it food historian porn.",
            "For the first document we know the probability of the first document belonging to food is higher belonging to its, lower for the second document is just the other way.",
            "And suppose we have two queries, one queries about iPhone crack.",
            "We classify this iPhone correct also into this latent aspect.",
            "And on the right hand side, Apple Pie, the fool enjoys higher probability.",
            "Once we have a latent aspect, then we can do matching more effectively.",
            "Imagine if we don't have it written aspect.",
            "Suppose we have Apple pie query.",
            "We may be getting the documents from Apple Computer because Apple Computer enjoy much higher Pagerank.",
            "So without the latent aspect, semantics may not be a property considered.",
            "OK, so if you consider frequent itemset mining, we only have items set descriptions.",
            "We don't have this semantics of item set, so I can say money may not be able to do analysis like I depicted on this picture.",
            "And let's go back to look at the basic model about recommendation."
        ],
        [
            "For communities, so one way to model Community recommendation is we can consider each community as a bag of users.",
            "So a large number of users assigned to different communities.",
            "You can look at who join the party community and model a community based on its participants.",
            "And also we can model community as a bag of words.",
            "The description of the community or the posts in the community.",
            "So now I'm going to get in the details, but let's look at this joint."
        ],
        [
            "Model the community is depicted jointly by users and escription.",
            "At this model avoids a few shortcomings of the basic models.",
            "First of all, the community is viewed by both a bag of users and the bag of words.",
            "By adding this CU branch, if you look at the CZ D branch, this branch doesn't consider user into the picture, so even you can do let's say committee recommendation, but we cannot consider user idiosyncrasy by adding EU branch into a picture.",
            "Then we can do personalization.",
            "An if you consider the other way by adding CD by adding this branch to the seeds U branch, we make the information denser.",
            "If we only have CZ you branch the information may be quite sparse.",
            "So adding more branches can improve the density of information, so therefore the accuracy of recommendation.",
            "In addition, we can also do analysis between U&D, so in this particular case we can have conditional probability of given U what would be the words this particular would be interested and this can be very useful for advertisement targeting.",
            "So let me show."
        ],
        [
            "To some empirical study, we collected some market data, including about 300,000 users and 100,000 communities.",
            "And we utilize up to 200 machines and each machine is about 200 megahertz CPU power and four gigabytes memory.",
            "And we evaluate in two metrics."
        ],
        [
            "Why is the community recommendation accuracy and also the speed up of the algorithm?",
            "And we try to evaluate the more objective fashion an otherwise we have to put a lot of users into the room to ask for their feedback.",
            "So be more objectively, we do leave one out.",
            "Basically, suppose the user have four photos, they are he or she is interested.",
            "We want to take one away to see whether our system can recommend the 4th one.",
            "And this particular recommendation may not be enjoyed.",
            "A high precision recall because we do have other Niagara for pictures.",
            "Recommending another one can be as relevant.",
            "However, our interest is to show the relevance the relevant relative performance evaluation between our combined model an based models, so this is probably OK.",
            "So first of all, we see precision recall."
        ],
        [
            "Comparison compare with base model.",
            "CU is a community user model and CCF is a combination model and both precision and recall of the combination model outperforms the basic model and this is pretty reasonable.",
            "And the second picture shows on the essays we show number of communities user has joined and then the precision of recommendation an if you look at here, if a user has only joined about 20 communities, the precision is quite low.",
            "It's only about 10%.",
            "And this is only also understandable when the information is not sparse enough.",
            "Recommendation cannot be very accurate.",
            "So two things we can learn from the picture.",
            "One is we may want to devise other methods for doing recommendation if we don't have sufficient user information.",
            "And the second lesson I just mentioned was this is basically final result, right?",
            "So the precision recall tend to be lower and maybe we can dismiss this particular factor right here.",
            "So for the second evaluation we like to."
        ],
        [
            "Evaluate the parallelization performance.",
            "We use a time machine as our baseline.",
            "The reason we utilized time machine as a baseline for evaluation is when you sit utilized one machine, we cannot feed data into the memory.",
            "We have to use at least 10 machine to run the algorithm.",
            "So suppose 10 machines, the baseline.",
            "We assume we can speed are linearly an by using up to about 100 machine we can pretty much get linear speedup.",
            "And when we increasing the machine number to 200 then the improvement saturates and this is easy to understand because and out slowly ventually kicks in and synchronization overhead and the communication overhead eventually become a dominant factor.",
            "But the good thing we enjoy was suppose the data set get larger.",
            "We can always further increase the number of machines to do the mining.",
            "And to defer the point, and also can kick in.",
            "And what we have doing in the last few months was try to extend our model."
        ],
        [
            "The model I showed you was we use a PSA.",
            "We have already implemented a new model with LDA."
        ],
        [
            "And we also implemented a few extension of LDA, including considering time dimension and perform incremental learning and also construct topic hierarchy and so on and so forth.",
            "So."
        ],
        [
            "The 4th algorithm we made in parallel is super vector machine.",
            "We presented the paper last year at NIPS, so I don't want to get into this algorithm today.",
            "So you can look at the details on the web.",
            "So I'd like to say."
        ],
        [
            "And the final five minutes talking about this should be complete computing perspective, so we talk about scalability, Zaky and a lot of people may say scalability is pretty easy.",
            "Google has GFS.",
            "Google has MapReduce.",
            "Basically, you can make everything running on map reduce, then solving the problem.",
            "But the solution is not very easy.",
            "So let's look at.",
            "Basically, there are three things we need to watch out.",
            "First of all, the lot of machine learning algorithm is iterative, so we have multiple iterations.",
            "So the solution processing.",
            "And this incurs an interesting challenge.",
            "The data dependency iteration T + 1 depends on the data of T. And for each iteration we shouldn't have problem to do parallelization, but the challenges between iterations.",
            "How do we resolve the data dependency problem?",
            "And also the third challenge in Israel when you have multiple machines, let's say 1000 or even 10,000 machines, the probability one machine fails in the process of learning can be very high, so we don't want one machine fail.",
            "Then we have to rerun the whole computation.",
            "So therefore recovery is also critical.",
            "So let's look at the map."
        ],
        [
            "Reduce architecture.",
            "Basically we can store input data on a disk and this is a very simple depiction of GFS.",
            "Every single copy of the data we replicate into 3 copies.",
            "And then we schedule the task onto multiple mappers.",
            "So if you consider this frequent itemset mining algorithm, so every single conditional database can be scheduled on one task.",
            "An suppose one CPU reads the data condition database data and start to do a frequent artisan mining.",
            "At the end we try to do shuffle based on items that content and finally we do reduction, then output the data onto GFS.",
            "So for frequentists mining image reduce dimension is perfect.",
            "But however, if your algorithm is iterative, then we have two challenges.",
            "One is, once one iteration has been done.",
            "According to MapReduce picture, we have to write all the data back to the GFS to ensure recovery can be performed.",
            "The second challenge is in the second iteration.",
            "Suppose we read data out of the GFS, we have to reset reschedule.",
            "The task may be on too much auto different machines.",
            "So by not being able to utilize the same machine between iterations.",
            "Basically, we cannot take advantage of caching.",
            "So my reduce may not be the perfect solution for CCF or for other algorithms.",
            "So the next picture shows what we have been experimenting with in the."
        ],
        [
            "One year or two.",
            "So this column is map reduce an the right hand side MPI.",
            "I think most people must be very familiar with and we are experimenting with another distributed framework an which we cannot disclose the detail but the major criteria we value are the following.",
            "First of all we like to see whether we need to reschedule GFS IO between iterations.",
            "For my reduce we have to do so.",
            "And we like to be able to device a new method.",
            "We don't have to do that.",
            "We should be able to reuse the same thread over and over again between multiple reiterations.",
            "For MPI we do have the flexibility to do so.",
            "The second one is do we have a flexible computation model?",
            "An format reduces not very flexible.",
            "We only have this all reduced model.",
            "And sorry for my reduce, we only have this or reduced model for MPI.",
            "We can do pretty much virtually anything.",
            "We like an something in the middle, maybe a tradeoff between the two models.",
            "And you can go through the table to see at the end.",
            "Here recovery recovery map reduce the model itself, writes the data back to the GFS recoveries, ensure.",
            "On the on, the MPI infrastructure recovery is not guaranteed.",
            "Of course, you can write your own logic to do checkpointing, but it's not intrinsic in the model and suppose you can build a different distribute algorithm in the middle to try to take advantage of recovery situation.",
            "So maybe I can defer.",
            "The question is about about the end of presentation.",
            "So currently we can score different computational models, may reduce may not be the best computational model for machine learning algorithms which require iterative process.",
            "MPI also may not be the best, but you can implement your own checkpoint.",
            "The MPI may be applicable and we are exploring some more advanced algorithms right now.",
            "So let me move to the conclusion.",
            "So we started motivating."
        ],
        [
            "Machine learning problems by using 2 examples.",
            "One is this Confucius product we mentioned when the machine learning kicks in.",
            "Traffic goes up because we can really kick off equals the ecosystem in the product.",
            "The second example is the open social right now has been able to reach so many people.",
            "And how can we take advantage of the API and utilizing machine learning technologies to perhaps do recommendation or do."
        ],
        [
            "It's matching.",
            "So 7.",
            "Machine learning algorithms subroutines have been implemented for the Confucius project.",
            "Recommendation system as I mentioned, is a push model of search and can grow increasing popularity in the future.",
            "Recommendation system definitely demands scalability.",
            "With 650 million people, Opensocial can reach without scalable algorithm.",
            "We cannot do recommendation in the daily fashion.",
            "And machine learning algorithm demands better distributed computing infrastructure than MapReduce, which I think many different labs are developing right now.",
            "So finally"
        ],
        [
            "If you are interested in the details of the algorithms, they are all online.",
            "You can access through my website.",
            "We also made the support vector machine parallel algorithm online.",
            "You can download from the open source for the relevant documents and citations.",
            "You can refer to the reference of my presentation, so thank you very much.",
            "Time for a few questions.",
            "So this is basically our estimation or rating for this."
        ],
        [
            "Let's say my reduce right flexibility in computational model we consider is not very flexible.",
            "So we give you the."
        ],
        [
            "Fine, this is our rating.",
            "And for MPI we consider the model is extremely flexible.",
            "You can do whatever you want on every single computational task.",
            "So this is pretty much our own rating.",
            "You can say 4.6, but basically it's already rating between different.",
            "Distribute computing paradigms.",
            "Yes, is there any recommended system that you're working on where both documents or communities, for example, as you were showing them end users have features 'cause at the moment in your system it's only the communities that have a description of the users don't?",
            "I don't have any kind of further features right?",
            "We didn't talk about, we didn't write out the features of users, but when we put you there implies the profiles of users.",
            "So let me go back to this picture here."
        ],
        [
            "So the you here you can see the you here includes a profile of the user.",
            "And also activities of user and stuff of users everything.",
            "Does that mean that those are combined like simply concatenated inside equivalent, or is that a little bit different structure the structure?",
            "Features.",
            "On the on this particular branch, yes, you can consider additional information can be just concatenated onto the onto the vector, but when you join the two together, this is different probability model.",
            "I guess the question is how do you combine those probabilities.",
            "So suppose you have a probability of 1 particular feature.",
            "Basically, this model is when you expand it would be proud of multiple conditional probabilities.",
            "Then using Gibbs sampling to learn the weights.",
            "That's a challenging problem.",
            "Yes.",
            "We basically, if you have this particular framework at the end you have this analytical model with a new user, you can right away to a recommendation.",
            "However, if the new users information is very sparse, suppose you user hasn't filled in profile information, then we don't have foundation to do recommendation in the situation.",
            "The only way we can do it is probably based on the right hand side branch.",
            "So we don't have personalized information.",
            "And there are other methods we can deal with this kind of method, but you cannot use this particular model.",
            "It cannot be very effective.",
            "Tell us anything about your hierarchical.",
            "What you're doing with tirofiban this morning, I think details will be probably disclosing in the near paper."
        ],
        [
            "But basically the patching goal machine was a paper published by UC Irvine, I suppose.",
            "So basically we are following that direction.",
            "And also another paper published by David Blei supervised LDA.",
            "So the model here we depicted.",
            "We don't consider we have prior information about documents or users or whatever, but suppose you have some prior labels on a person or undocumented community.",
            "Then perhaps you can align your latent aspects to this hierarchy and also with a pre label hierarchy.",
            "Not only a hierarchical model, but maybe a pre label ontology or taxonomy.",
            "So we're still doing experiments right now, but the models were proposed already by the machine learning community.",
            "So perhaps a bit of a high level question, so imagine you managed to solve these sort of a planetary social network and you know you.",
            "So with the key players where you know who can be trusted, who cannot, can you tell us a little bit?",
            "You know in what, what direction would Google be using that to change the?",
            "You know the experience, beat search or interaction with the web.",
            "Right, I don't know what the search people would do.",
            "The only thing I can answer would be on Archon."
        ],
        [
            "Future system.",
            "Give example here already.",
            "Maybe it's easier for me to flip back.",
            "So in this example."
        ],
        [
            "Soso suppose we have multiple QA pairs.",
            "Or you can consider you have lots of forums about the same topic and which one you want to select to index on the web search and user credential can be important factor.",
            "Alright, so Q&A peers about Yosemite.",
            "We can get 10 pairs, but if one pair is written by a credible person, maybe not.",
            "There should be indexed.",
            "So this is very simple idea.",
            "Facebook.",
            "How much is cocaine?",
            "The number we don't have here, so.",
            "If you if you the prior, if you can model the power accurately, you can gain quite substantially, but the question is how do you tune the LDA parameter to start with and I guess yesterday there was a paper at NIPS and discussing about how do you tune the priors.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone in the presentation today I'm going to start with two applications to motivate why we want to do social network data mining and then the second half I'm going to talk about how to make some very popular algorithms scalable.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're multiple machines.",
                    "label": 0
                },
                {
                    "sent": "And I'd like to acknowledge my collaborators first, so this will be published online so we can look at the details later.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we look at two systems.",
                    "label": 0
                },
                {
                    "sent": "The first system was just built in China launch in China and Russia and this is a Q&A system and many people must have used the Yahoo answers right?",
                    "label": 1
                },
                {
                    "sent": "And basically the user can post question and other users can answer the question.",
                    "label": 0
                },
                {
                    "sent": "The idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "We launched the system about a year ago.",
                    "label": 0
                },
                {
                    "sent": "You see, this is a code name.",
                    "label": 0
                },
                {
                    "sent": "The product or Confucius, and in the first year or so you see the traffic was very low and the black number signify questions and the right number shows answers and before August this year both Q&A's the volumes are pretty low.",
                    "label": 0
                },
                {
                    "sent": "And some magic happens around August.",
                    "label": 0
                },
                {
                    "sent": "Machine learning we implement a few machine learning algorithms and then the system suddenly kicks off.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second example application I will talk about is open social and how many have heard about open social.",
                    "label": 0
                },
                {
                    "sent": "OK, that's great and Opensocial this far.",
                    "label": 0
                },
                {
                    "sent": "Has reached about 675 users worldwide.",
                    "label": 0
                },
                {
                    "sent": "Basically there are many major product social network products worldwide.",
                    "label": 0
                },
                {
                    "sent": "Utilize open social as a standard and I will also going to talk about when social, slightly and motivating why we want to do scalable data mining.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's begin with 1.0.",
                    "label": 0
                },
                {
                    "sent": "One .0.",
                    "label": 0
                },
                {
                    "sent": "Basically we have lots of document on the web.",
                    "label": 0
                },
                {
                    "sent": "We send qualities to crawl documents, indexed documents and rank.",
                    "label": 0
                },
                {
                    "sent": "The documents and user pretty much just submitting keyword queries.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Getting their desired documents.",
                    "label": 0
                },
                {
                    "sent": "For weapons to Web 2.0 this morning we heard about the talks.",
                    "label": 1
                },
                {
                    "sent": "People also get involved in the picture.",
                    "label": 0
                },
                {
                    "sent": "An so we have users can upload information in a QA system.",
                    "label": 0
                },
                {
                    "sent": "The user can pose a question and other users can provide answers and between documents we have links and not only between documents.",
                    "label": 0
                },
                {
                    "sent": "Also between users we may have explicit links, also implicit links.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let me go back to this Q&A system and basically we want to allow people to ask questions when they cannot find.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Information from web search.",
                    "label": 0
                },
                {
                    "sent": "And this is 1 example.",
                    "label": 0
                },
                {
                    "sent": "Suppose I want to do a query.",
                    "label": 0
                },
                {
                    "sent": "What are must see attractions in?",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The storm.",
                    "label": 0
                },
                {
                    "sent": "And for this query I can get desirable results from Google Search.",
                    "label": 0
                },
                {
                    "sent": "If I click on the first one, I can see a three major attractions at Yellowstone.",
                    "label": 1
                },
                {
                    "sent": "And let me do another query.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What are the must see attraction at Yosemite and this query result is not as good if you see the result actually is coming from.",
                    "label": 1
                },
                {
                    "sent": "Lodging site The lodging site is minor in and you can see massing attraction at the bottom.",
                    "label": 0
                },
                {
                    "sent": "And if you go to Asia.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where websites are not very popular.",
                    "label": 0
                },
                {
                    "sent": "And when I do a query about Marcia traction in Beijing, I get this page back and trust me on the left hand side you get a lot of advertisements.",
                    "label": 0
                },
                {
                    "sent": "So for emerging markets, since we don't have a lot of sites and QA system become very important otherwise we don't have sufficient information to index and one example is the Korean market.",
                    "label": 0
                },
                {
                    "sent": "And how could in the Korean market Google Market share is very very low?",
                    "label": 0
                },
                {
                    "sent": "And market share is only 3%.",
                    "label": 0
                },
                {
                    "sent": "The reason is because our major competitor called Never.",
                    "label": 0
                },
                {
                    "sent": "They have a very good Q&A system and the system collects a lot of Q&A pairs.",
                    "label": 0
                },
                {
                    "sent": "The little content and they block Google Crawler according the content and Google has nothing to index in Korea.",
                    "label": 0
                },
                {
                    "sent": "So we lose the market to our competitor.",
                    "label": 0
                },
                {
                    "sent": "So because of this reason, UGC.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Becomes very important.",
                    "label": 0
                },
                {
                    "sent": "And let's go back to the computer traffic and you look at the picture we consider.",
                    "label": 0
                },
                {
                    "sent": "There are a number of key subroutines need to be implemented.",
                    "label": 0
                },
                {
                    "sent": "So starting from a web search, we do a web search.",
                    "label": 0
                },
                {
                    "sent": "If we don't see the results satisfactory and we can trigger a question answer session.",
                    "label": 1
                },
                {
                    "sent": "So this is a first machine learning subroutine.",
                    "label": 0
                },
                {
                    "sent": "Need to be implemented.",
                    "label": 0
                },
                {
                    "sent": "The second one is given the question we like to be able to provide labels and this is like a very simple classification task.",
                    "label": 0
                },
                {
                    "sent": "And the third one is given the question you want to find in the Q&A repository.",
                    "label": 1
                },
                {
                    "sent": "Some similar questions people ask before and probably provides us right away.",
                    "label": 0
                },
                {
                    "sent": "And the 4th one is we like to be able to evaluate user credentials and I will give you a reason why user credential is very important shortly.",
                    "label": 0
                },
                {
                    "sent": "And the next one is given a question.",
                    "label": 1
                },
                {
                    "sent": "We like to route the question to expert users, and otherwise every user comes into a system.",
                    "label": 0
                },
                {
                    "sent": "They see a large number of questions is really hard for a user to sort through.",
                    "label": 0
                },
                {
                    "sent": "All the question to find the question they can answer.",
                    "label": 0
                },
                {
                    "sent": "And we like to be able to evaluate quality of the question is restreaming important if you want to evaluate user credential, the first thing we need to evaluate will be the answer quality.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you may evaluate a spammer to be a top performer.",
                    "label": 0
                },
                {
                    "sent": "And finally, this is everybody's dream if we can provide subroutine which can do machine generated answers, I think you can start company today.",
                    "label": 0
                },
                {
                    "sent": "And today I'm going to just talk about the first one.",
                    "label": 0
                },
                {
                    "sent": "How do we evaluate user credential in a domain specific way?",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So naive user credential system is like this.",
                    "label": 1
                },
                {
                    "sent": "Very simple 1 user register onto the system.",
                    "label": 1
                },
                {
                    "sent": "We give the person a few points and each time the person login we give the person some points and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "And this system is problematic for a few reasons.",
                    "label": 0
                },
                {
                    "sent": "I just give you a two simple reasons.",
                    "label": 0
                },
                {
                    "sent": "One is, this system is very easy.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It'll be damned if I sign on to 1000 different names and I post some questions myself, answer to myself, then I can get a lot of points.",
                    "label": 0
                },
                {
                    "sent": "And also I can cut and paste other people's solutions as my answers.",
                    "label": 0
                },
                {
                    "sent": "And some people can easily post advertisements onto the system and you get a lot of spams.",
                    "label": 0
                },
                {
                    "sent": "And also freshness can be an issue.",
                    "label": 0
                },
                {
                    "sent": "So suppose a user has been a top performer and if you don't consider the time factor, the freshness may not be properly considered.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a very simple system proposed by an intern working at Yahoo a few years ago, and this in turn just joined Google about a year ago.",
                    "label": 0
                },
                {
                    "sent": "And this is a very simple formulation.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you're looking on the left, every user is is a node on this graph.",
                    "label": 0
                },
                {
                    "sent": "And if a user answer question to another person, so we view a link, for instance user a answers question of user BC&E.",
                    "label": 0
                },
                {
                    "sent": "To preventing spam, an Zoltan proposed between 2 users, you only can one link running multiple links, so on the right hand side, if we look at in links of ABCD, we get 04, and so on, so forth.",
                    "label": 0
                },
                {
                    "sent": "And we don't care bout in links in links means I pose questions and many people ask answer my questions so that doesn't seem a persons question.",
                    "label": 1
                },
                {
                    "sent": "Get a lot of people answered.",
                    "label": 0
                },
                {
                    "sent": "The person is important.",
                    "label": 0
                },
                {
                    "sent": "So in this situation we consider our links.",
                    "label": 0
                },
                {
                    "sent": "And we consider unique our links and on the right hand side we can see 30221 and so on so forth and user a seems to be the most important.",
                    "label": 0
                },
                {
                    "sent": "And this method is quite simple, and however it can also be easy spam.",
                    "label": 0
                },
                {
                    "sent": "So suppose I answer all questions using the same answer.",
                    "label": 0
                },
                {
                    "sent": "And this system cannot detect these particular spamming situation, so further things has to be done.",
                    "label": 0
                },
                {
                    "sent": "So what we have done is we wait the edges.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Currently based on answer quality and so on and so forth, which I don't plan to get into details.",
                    "label": 0
                },
                {
                    "sent": "But the user credential is also important not only for identify most productive users, but also we can use user credential to do a page ranking.",
                    "label": 0
                },
                {
                    "sent": "We all know about on Q&A system blocks and BBS we cannot harvest a lot of Intralinks.",
                    "label": 0
                },
                {
                    "sent": "We don't Intralinks Pagerank that basically cannot work.",
                    "label": 0
                },
                {
                    "sent": "And under this situation, we consider actually if you can do author rank very effectively, then utilizing author rank as an anchor point for the Pagerank, we can rate your content very effectively.",
                    "label": 0
                },
                {
                    "sent": "So here I give you a very simple example.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have a query Q&A systems about Yosemite top attractions and I get about 10 questions about you 70 attractions.",
                    "label": 0
                },
                {
                    "sent": "So here I illustrated by 4.",
                    "label": 0
                },
                {
                    "sent": "So if I can measure the quality of which QA pair has the highest quality, suppose 0.4 means the lowest priority zero point 6 means the highest priority.",
                    "label": 0
                },
                {
                    "sent": "Then when I do the web indexing, I can index a higher priority, higher quality kewene paired in on the web search result.",
                    "label": 0
                },
                {
                    "sent": "An for each Q and a pair I may get multiple answers if we need to generate snippets, we cannot just randomly pick answers.",
                    "label": 0
                },
                {
                    "sent": "We'd like to pick the answer with highest quality.",
                    "label": 0
                },
                {
                    "sent": "If we know the author credential an IF we trust the high quality, authors can provide high quality documents, then author credential can give us a hint about the document quality and we consider this is one of the most effective methods for ranking Q&A blog and BBS and provide more effective searching experience.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I've mentioned about this Confucius, the next one is Opensocial.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An open social.",
                    "label": 0
                },
                {
                    "sent": "We talk about Web 2.0 ready and we can link documents together.",
                    "label": 1
                },
                {
                    "sent": "We can link users together and open social.",
                    "label": 0
                },
                {
                    "sent": "Take one step forward.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, we can put social platform on the home page.",
                    "label": 0
                },
                {
                    "sent": "And let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "So we can substitute an HTML page as a container on the container.",
                    "label": 0
                },
                {
                    "sent": "We can put application gadgets on it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a very simple application we have built also in China and in the middle you see a Frank graph in the middle is my boss and my boss.",
                    "label": 0
                },
                {
                    "sent": "We can display his friends.",
                    "label": 0
                },
                {
                    "sent": "And also then we if we mouse over the particular person we can see the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Persons recent activities.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can see there are three already properties on this platform.",
                    "label": 0
                },
                {
                    "sent": "We can get a person's profile, we can get a person friends.",
                    "label": 0
                },
                {
                    "sent": "Also, we can harvest a person's activities.",
                    "label": 0
                },
                {
                    "sent": "In addition, we can also know the person, staff or the person have.",
                    "label": 0
                },
                {
                    "sent": "For instance, this is a.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Science blog.",
                    "label": 0
                },
                {
                    "sent": "And we can now.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Person has uploaded a lot of photos allowed UGC by a person.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you look at the whole picture, open social APIs, we have four API's user profile, user, friends, activities and stuff.",
                    "label": 0
                },
                {
                    "sent": "And based on the full API's, you can write applications.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do a lot of interesting things.",
                    "label": 0
                },
                {
                    "sent": "So here I'm going to just give a very simple example on the right hand side and this application is I want to plot my friends on a map.",
                    "label": 0
                },
                {
                    "sent": "So what I can do is first of all I call open social API, get my friends profile.",
                    "label": 0
                },
                {
                    "sent": "And once I get the profile, I get the profile of the person's location.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I can plot the person on this particular map.",
                    "label": 0
                },
                {
                    "sent": "If I zoom.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into Beijing I can see my friends at Beijing if I further zoom in.",
                    "label": 0
                },
                {
                    "sent": "I can see his recent activities.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the open social platform give us an interesting benefit.",
                    "label": 0
                },
                {
                    "sent": "Once you write a gadget, you can put a gadget onto multiple platforms which comply to open social platform.",
                    "label": 0
                },
                {
                    "sent": "So you write application once and application can be utilized in many places.",
                    "label": 0
                },
                {
                    "sent": "And what's the benefit of having this platform?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me give you 2 examples.",
                    "label": 0
                },
                {
                    "sent": "The first one is a personalized search example.",
                    "label": 1
                },
                {
                    "sent": "Suppose I can know your profile.",
                    "label": 0
                },
                {
                    "sent": "I understand your friends.",
                    "label": 0
                },
                {
                    "sent": "I can harvest your activities and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "Maybe I can find harvest sufficient signals to try to do personalized search.",
                    "label": 1
                },
                {
                    "sent": "And one example is supposed to have a Fuji search and Fuji can mean multiple things can be Fuji Mount and can be Fuji apples or Fuji cameras.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I look at my friends.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Circle and I under.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then recently my friends are writing about digital camera blocks, so maybe the Fuji Fuji search means about Fuji cameras.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example is a personal recommendation and we consider recommendation is a push model of search.",
                    "label": 0
                },
                {
                    "sent": "And this one example is suppose a user has search for image of motorcycle.",
                    "label": 0
                },
                {
                    "sent": "Then perhaps we can recommend another motorcycle photo to the person.",
                    "label": 0
                },
                {
                    "sent": "A person has search for Niagara Falls pictures.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can recommend another one.",
                    "label": 0
                },
                {
                    "sent": "And in general recommendation system, we can recommend photos, Friends, Community forums and also advertisements.",
                    "label": 0
                },
                {
                    "sent": "The key requirement for a good recommendation system will be scalability, scalability, and.",
                    "label": 1
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ability.",
                    "label": 0
                },
                {
                    "sent": "And this leads to the second half of the presentation, and we implemented a few key subroutines to provide scalable data mining.",
                    "label": 1
                },
                {
                    "sent": "And you can look into details if you are interested in.",
                    "label": 0
                },
                {
                    "sent": "The detail algorithm and I'm going to just focus on discussing two algorithms today, frequent itemset mining and this CCF algorithm.",
                    "label": 1
                },
                {
                    "sent": "And less motivated a little bit why we need to have clustering algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For analyzing social.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Network.",
                    "label": 0
                },
                {
                    "sent": "And suppose we want to do as targeting and this has been a very important problem for social network companies.",
                    "label": 0
                },
                {
                    "sent": "We know most of social network companies haven't been able to make a profit.",
                    "label": 0
                },
                {
                    "sent": "An we like to basically like to match match our ads to users.",
                    "label": 0
                },
                {
                    "sent": "And one traditional paradigm is.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We try to my profiles of users.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can get friends of user activity and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "We try to match relevance between users and users activities and documents and this example shows my own profile.",
                    "label": 0
                },
                {
                    "sent": "My friends, my stuff and also my activity.",
                    "label": 0
                },
                {
                    "sent": "With open social API you can get more information to do relevance mining.",
                    "label": 0
                },
                {
                    "sent": "However, this morning has been done for years, but like for example by Myspace by other social network companies and relevance itself may not be sufficient.",
                    "label": 0
                },
                {
                    "sent": "Another important",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is influence.",
                    "label": 0
                },
                {
                    "sent": "We not only want to know relevance, we also want to find influential users on the social network.",
                    "label": 0
                },
                {
                    "sent": "And for instance, on this particular social network, we would like to do a centrality analysis.",
                    "label": 0
                },
                {
                    "sent": "We like to analyze user quick credentials with user capabilities when we target ads.",
                    "label": 0
                },
                {
                    "sent": "Maybe we should target users with highest influence.",
                    "label": 0
                },
                {
                    "sent": "And the details we are not going to cover today in details because we have two patterns in.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation.",
                    "label": 0
                },
                {
                    "sent": "So let's get into frequent items.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mining.",
                    "label": 0
                },
                {
                    "sent": "Collaborated filtering this particular data mining mechanism can be detected by this 2 dimensional matrix, so we have two dimensions here on the horizontal dimension will be the items we like to recommend to the vertical dimension users, and in this example I shows we like to recommend.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Photos to users.",
                    "label": 0
                },
                {
                    "sent": "If you see one in the cell means the particular user has access a particular photo.",
                    "label": 0
                },
                {
                    "sent": "And what we like to accomplish is we like to guess the value on this question marks.",
                    "label": 0
                },
                {
                    "sent": "So if suppose the value here will be either 010 means a user has never accessed this particular photo.",
                    "label": 0
                },
                {
                    "sent": "1 means the user has accessed.",
                    "label": 0
                },
                {
                    "sent": "We would like to be able to compute the probability of whether a user would like to access this particular photo with?",
                    "label": 0
                },
                {
                    "sent": "If the probability value is very high, we will recommend the photo to the user.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically, if I am frequent itemset mining can support this particular recommendation.",
                    "label": 0
                },
                {
                    "sent": "So I gave you example already if I've already seen three photos and the question is, should I recommend you the fourth photo.",
                    "label": 0
                },
                {
                    "sent": "And we look at associated mining rule.",
                    "label": 0
                },
                {
                    "sent": "Basically, given AB&C, we like to find the conditional probability of given ABC.",
                    "label": 0
                },
                {
                    "sent": "What is the conditional probability is desirable and this is equal to the support of ABC D divided by support of ABC.",
                    "label": 0
                },
                {
                    "sent": "If we can compute support of ABC and ABC D We get this basic interpretation then we can do our recommendations.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's look at FIM and basically we can make two observations.",
                    "label": 0
                },
                {
                    "sent": "The first opposition is suppose an item A is not frequent.",
                    "label": 1
                },
                {
                    "sent": "Then any pattern contents A won't be frequent.",
                    "label": 0
                },
                {
                    "sent": "This is observation done by Rakesh.",
                    "label": 1
                },
                {
                    "sent": "Suppose we have an item A&AB.",
                    "label": 0
                },
                {
                    "sent": "If we know a is not frequent then AIB's super set cannot be frequent.",
                    "label": 1
                },
                {
                    "sent": "The second observation is made by johannan pattern contents A or subsets of transactions contain a.",
                    "label": 0
                },
                {
                    "sent": "So if we build conditional database of a containing all transactions content containing a.",
                    "label": 0
                },
                {
                    "sent": "If we want to find the item set containing a, we have to go to this particular transaction database.",
                    "label": 1
                },
                {
                    "sent": "So this is what it says here.",
                    "label": 0
                },
                {
                    "sent": "And one example is, suppose we have a BAC and A3 transactions.",
                    "label": 0
                },
                {
                    "sent": "We put those transaction into conditional transaction database a.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a B&B C. We put them into translation database B, so this is quite straightforward, But you can right away see a problem.",
                    "label": 0
                },
                {
                    "sent": "We may have duplicates, so observation three is suppose we want to divide the transaction into conditional databases an we may have duplicates between databases.",
                    "label": 0
                },
                {
                    "sent": "An our mission to do this, divide and conquer so therefore we can paralyze the algorithm is to try to divide transition into independent databases without duplicates.",
                    "label": 0
                },
                {
                    "sent": "So let's work through it.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example to show how we do it.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have five transactions on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "So first of all, I count the support of individual items.",
                    "label": 1
                },
                {
                    "sent": "So we have F equal to four, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And suppose we set the threshold support equal to three, so all the items with support less than three, we cut them off and we can rewrite all the transactions to be the middle column.",
                    "label": 0
                },
                {
                    "sent": "So basically FCD and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "We get rid of load supper items, rewriting the transaction to be this one.",
                    "label": 1
                },
                {
                    "sent": "An according to observe opposition Station one so already we get rid of low supply items and then we sort items on each transaction by the same order.",
                    "label": 1
                },
                {
                    "sent": "Here we are sorting everything by the support value so you can see the support value.",
                    "label": 0
                },
                {
                    "sent": "F is the highest, MP is the lowest.",
                    "label": 0
                },
                {
                    "sent": "So every transaction will be sorted in this descending order.",
                    "label": 0
                },
                {
                    "sent": "And once we have done this sorting, we can then avoid duplication.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's see the next slide.",
                    "label": 0
                },
                {
                    "sent": "How we divide the items into multiple conditional databases.",
                    "label": 0
                },
                {
                    "sent": "So according to observation B, so we like to be able to divide transactions independently.",
                    "label": 1
                },
                {
                    "sent": "And but how do we construct KDB?",
                    "label": 0
                },
                {
                    "sent": "Suppose we have KDB containing a.",
                    "label": 0
                },
                {
                    "sent": "And the example I gave you is PCA can be in three conditional databases.",
                    "label": 0
                },
                {
                    "sent": "But if we sort them in alphabetical order, this is 1 order.",
                    "label": 1
                },
                {
                    "sent": "We can solve the transactions then the following rule can avoid duplication, so we only put the prefix of a particular item into the conditional database.",
                    "label": 1
                },
                {
                    "sent": "So if we sorbier see into ABC, then we if we look for items should be put into conditional database a the previous A.",
                    "label": 1
                },
                {
                    "sent": "The prefix of A is empty set, so for conditional database a we put nothing in the database.",
                    "label": 0
                },
                {
                    "sent": "4B We put a in a database.",
                    "label": 0
                },
                {
                    "sent": "For C we put A&B.",
                    "label": 0
                },
                {
                    "sent": "And by following the rule we can make sure we don't have duplicates in the conditional databases.",
                    "label": 0
                },
                {
                    "sent": "So let's work through the same.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example to see how this can be done.",
                    "label": 0
                },
                {
                    "sent": "So for conditional database P we go to all the transactions and we only harvest the prefix.",
                    "label": 0
                },
                {
                    "sent": "So for the first one we get FCM.",
                    "label": 0
                },
                {
                    "sent": "And for this one we get CB for the last one we get FCM.",
                    "label": 0
                },
                {
                    "sent": "And do the same thing.",
                    "label": 0
                },
                {
                    "sent": "We can compute conditional transaction database M conditi.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Database B and so and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not going to get into the details.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So once we have conditional database build, so this picture shows at every level level of the tree we can have independent conditional databases.",
                    "label": 1
                },
                {
                    "sent": "But if the conditional database is very large, it's larger than the memory can hold the transactions.",
                    "label": 0
                },
                {
                    "sent": "Then we recursively further divide the conditional database.",
                    "label": 0
                },
                {
                    "sent": "So in this example, suppose we have a D as the conditional database and the contents AB&C.",
                    "label": 0
                },
                {
                    "sent": "We can further divide conditional database D. In the database DADB&DC we do this recursion split until the.",
                    "label": 0
                },
                {
                    "sent": "The final node can feed into the memory.",
                    "label": 1
                },
                {
                    "sent": "So once the final conditional database can fit into memory, we can start to do our frequent itemset mining.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So next picture shows we already distributed computation onto multiple machines on one machine.",
                    "label": 0
                },
                {
                    "sent": "This machine containing conditional data with P and we see there are three transactions.",
                    "label": 0
                },
                {
                    "sent": "And that's a magnified it to harvest item sets with support greater or equal than three, you can see P is one of them, and then we can see C occur three times.",
                    "label": 0
                },
                {
                    "sent": "So P and PC will be our frequent itemsets in this situation.",
                    "label": 0
                },
                {
                    "sent": "And we can do the same for every single conditional databases.",
                    "label": 0
                },
                {
                    "sent": "At the end we aggregate the results together.",
                    "label": 0
                },
                {
                    "sent": "We get the final frequent item sets.",
                    "label": 0
                },
                {
                    "sent": "And the example I just showed you.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can be implemented on map reduce because a we can divide the datasets onto independent databases.",
                    "label": 0
                },
                {
                    "sent": "And Secondly we don't have iterative situations.",
                    "label": 0
                },
                {
                    "sent": "Once we do the computation on one particular node, we don't have to go back to the same node to do further computation.",
                    "label": 0
                },
                {
                    "sent": "So map reduce is a perfect infrastructure for such parallelization.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next one I'm going to illustrate.",
                    "label": 0
                },
                {
                    "sent": "MapReduce may not be the best choice, and we call the algorithm combination combination of collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "Let me motivate why we need this particular algorithm.",
                    "label": 0
                },
                {
                    "sent": "We already talked about frequent itemset mining and some of you may thought well it's very easy, very straightforward.",
                    "label": 0
                },
                {
                    "sent": "We don't any other fancy algorithm, but there are a couple of shortcomings of frequent itemset mining.",
                    "label": 0
                },
                {
                    "sent": "So here, let me use the example of four.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recommendation, suppose a user joins multiple number of forums.",
                    "label": 0
                },
                {
                    "sent": "We like to be able to recommend a user other forms to join.",
                    "label": 0
                },
                {
                    "sent": "So likewise we use the same metrics to decode a forum user has joined.",
                    "label": 0
                },
                {
                    "sent": "But here if you look at the frequent itemset situation, we can only feel number 01 in the cells.",
                    "label": 0
                },
                {
                    "sent": "An suppose a user participate in forum many times.",
                    "label": 0
                },
                {
                    "sent": "We'd like to be able to also encode the strength or interest.",
                    "label": 0
                },
                {
                    "sent": "So therefore this is probably a better formulation of the problem we want to solve.",
                    "label": 0
                },
                {
                    "sent": "So we put numbers in there rather than just doing 1.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, we like to be able to encode latent aspect or categories of forums.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before we get into details, let's define some notations and we use C to donate community.",
                    "label": 0
                },
                {
                    "sent": "We use U to denote users.",
                    "label": 0
                },
                {
                    "sent": "D is descripcion a set of keywords.",
                    "label": 0
                },
                {
                    "sent": "And Z will be latent aspects.",
                    "label": 0
                },
                {
                    "sent": "Descriptions are often use her off the community or descriptiones description of community here.",
                    "label": 0
                },
                {
                    "sent": "Ann with going to discuss 2 baseline models.",
                    "label": 0
                },
                {
                    "sent": "The first one is Community user model community.",
                    "label": 0
                },
                {
                    "sent": "Descripcion model is the second model and then we talk about combined model.",
                    "label": 0
                },
                {
                    "sent": "So this is a latent property this later.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Semantic analysis proposed by Hoffman.",
                    "label": 0
                },
                {
                    "sent": "And basically, suppose we want to.",
                    "label": 0
                },
                {
                    "sent": "Did describe the joint probability of D&C so community and its description.",
                    "label": 0
                },
                {
                    "sent": "So we can rewrite the joint distribution into PC and the conditional probability.",
                    "label": 0
                },
                {
                    "sent": "An introducing Z in the middle.",
                    "label": 0
                },
                {
                    "sent": "The latent aspect.",
                    "label": 0
                },
                {
                    "sent": "We can rewrite it as the follows.",
                    "label": 0
                },
                {
                    "sent": "And by having this formulation, we not only can do a recommendation, but also we can do analysis.",
                    "label": 0
                },
                {
                    "sent": "We can do probability inferencing between C and between D and also DC joint probability.",
                    "label": 0
                },
                {
                    "sent": "So you can compare this model with FIMFIN.",
                    "label": 0
                },
                {
                    "sent": "We cannot do this kind of analysis, But with PSA.",
                    "label": 0
                },
                {
                    "sent": "Further analysis can be performed.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once we have the model, then we can learn a Model V OEM or Gibbs sampling algorithm.",
                    "label": 0
                },
                {
                    "sent": "So further motivate why we need to have latent aspect.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have two documents.",
                    "label": 0
                },
                {
                    "sent": "One document says the Apple is the fruit of Apple tree and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "The other document talk about the Apple Computer Company and suppose we have a topic distribution latent layer and the topic topics are it food historian porn.",
                    "label": 0
                },
                {
                    "sent": "For the first document we know the probability of the first document belonging to food is higher belonging to its, lower for the second document is just the other way.",
                    "label": 0
                },
                {
                    "sent": "And suppose we have two queries, one queries about iPhone crack.",
                    "label": 0
                },
                {
                    "sent": "We classify this iPhone correct also into this latent aspect.",
                    "label": 0
                },
                {
                    "sent": "And on the right hand side, Apple Pie, the fool enjoys higher probability.",
                    "label": 0
                },
                {
                    "sent": "Once we have a latent aspect, then we can do matching more effectively.",
                    "label": 0
                },
                {
                    "sent": "Imagine if we don't have it written aspect.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have Apple pie query.",
                    "label": 0
                },
                {
                    "sent": "We may be getting the documents from Apple Computer because Apple Computer enjoy much higher Pagerank.",
                    "label": 0
                },
                {
                    "sent": "So without the latent aspect, semantics may not be a property considered.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you consider frequent itemset mining, we only have items set descriptions.",
                    "label": 0
                },
                {
                    "sent": "We don't have this semantics of item set, so I can say money may not be able to do analysis like I depicted on this picture.",
                    "label": 0
                },
                {
                    "sent": "And let's go back to look at the basic model about recommendation.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For communities, so one way to model Community recommendation is we can consider each community as a bag of users.",
                    "label": 1
                },
                {
                    "sent": "So a large number of users assigned to different communities.",
                    "label": 1
                },
                {
                    "sent": "You can look at who join the party community and model a community based on its participants.",
                    "label": 0
                },
                {
                    "sent": "And also we can model community as a bag of words.",
                    "label": 1
                },
                {
                    "sent": "The description of the community or the posts in the community.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to get in the details, but let's look at this joint.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model the community is depicted jointly by users and escription.",
                    "label": 0
                },
                {
                    "sent": "At this model avoids a few shortcomings of the basic models.",
                    "label": 0
                },
                {
                    "sent": "First of all, the community is viewed by both a bag of users and the bag of words.",
                    "label": 1
                },
                {
                    "sent": "By adding this CU branch, if you look at the CZ D branch, this branch doesn't consider user into the picture, so even you can do let's say committee recommendation, but we cannot consider user idiosyncrasy by adding EU branch into a picture.",
                    "label": 0
                },
                {
                    "sent": "Then we can do personalization.",
                    "label": 1
                },
                {
                    "sent": "An if you consider the other way by adding CD by adding this branch to the seeds U branch, we make the information denser.",
                    "label": 0
                },
                {
                    "sent": "If we only have CZ you branch the information may be quite sparse.",
                    "label": 0
                },
                {
                    "sent": "So adding more branches can improve the density of information, so therefore the accuracy of recommendation.",
                    "label": 0
                },
                {
                    "sent": "In addition, we can also do analysis between U&D, so in this particular case we can have conditional probability of given U what would be the words this particular would be interested and this can be very useful for advertisement targeting.",
                    "label": 0
                },
                {
                    "sent": "So let me show.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To some empirical study, we collected some market data, including about 300,000 users and 100,000 communities.",
                    "label": 0
                },
                {
                    "sent": "And we utilize up to 200 machines and each machine is about 200 megahertz CPU power and four gigabytes memory.",
                    "label": 1
                },
                {
                    "sent": "And we evaluate in two metrics.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is the community recommendation accuracy and also the speed up of the algorithm?",
                    "label": 1
                },
                {
                    "sent": "And we try to evaluate the more objective fashion an otherwise we have to put a lot of users into the room to ask for their feedback.",
                    "label": 0
                },
                {
                    "sent": "So be more objectively, we do leave one out.",
                    "label": 0
                },
                {
                    "sent": "Basically, suppose the user have four photos, they are he or she is interested.",
                    "label": 0
                },
                {
                    "sent": "We want to take one away to see whether our system can recommend the 4th one.",
                    "label": 0
                },
                {
                    "sent": "And this particular recommendation may not be enjoyed.",
                    "label": 0
                },
                {
                    "sent": "A high precision recall because we do have other Niagara for pictures.",
                    "label": 0
                },
                {
                    "sent": "Recommending another one can be as relevant.",
                    "label": 1
                },
                {
                    "sent": "However, our interest is to show the relevance the relevant relative performance evaluation between our combined model an based models, so this is probably OK.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we see precision recall.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comparison compare with base model.",
                    "label": 0
                },
                {
                    "sent": "CU is a community user model and CCF is a combination model and both precision and recall of the combination model outperforms the basic model and this is pretty reasonable.",
                    "label": 0
                },
                {
                    "sent": "And the second picture shows on the essays we show number of communities user has joined and then the precision of recommendation an if you look at here, if a user has only joined about 20 communities, the precision is quite low.",
                    "label": 0
                },
                {
                    "sent": "It's only about 10%.",
                    "label": 0
                },
                {
                    "sent": "And this is only also understandable when the information is not sparse enough.",
                    "label": 0
                },
                {
                    "sent": "Recommendation cannot be very accurate.",
                    "label": 0
                },
                {
                    "sent": "So two things we can learn from the picture.",
                    "label": 0
                },
                {
                    "sent": "One is we may want to devise other methods for doing recommendation if we don't have sufficient user information.",
                    "label": 0
                },
                {
                    "sent": "And the second lesson I just mentioned was this is basically final result, right?",
                    "label": 0
                },
                {
                    "sent": "So the precision recall tend to be lower and maybe we can dismiss this particular factor right here.",
                    "label": 0
                },
                {
                    "sent": "So for the second evaluation we like to.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evaluate the parallelization performance.",
                    "label": 0
                },
                {
                    "sent": "We use a time machine as our baseline.",
                    "label": 0
                },
                {
                    "sent": "The reason we utilized time machine as a baseline for evaluation is when you sit utilized one machine, we cannot feed data into the memory.",
                    "label": 0
                },
                {
                    "sent": "We have to use at least 10 machine to run the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So suppose 10 machines, the baseline.",
                    "label": 0
                },
                {
                    "sent": "We assume we can speed are linearly an by using up to about 100 machine we can pretty much get linear speedup.",
                    "label": 1
                },
                {
                    "sent": "And when we increasing the machine number to 200 then the improvement saturates and this is easy to understand because and out slowly ventually kicks in and synchronization overhead and the communication overhead eventually become a dominant factor.",
                    "label": 0
                },
                {
                    "sent": "But the good thing we enjoy was suppose the data set get larger.",
                    "label": 0
                },
                {
                    "sent": "We can always further increase the number of machines to do the mining.",
                    "label": 1
                },
                {
                    "sent": "And to defer the point, and also can kick in.",
                    "label": 0
                },
                {
                    "sent": "And what we have doing in the last few months was try to extend our model.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The model I showed you was we use a PSA.",
                    "label": 0
                },
                {
                    "sent": "We have already implemented a new model with LDA.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also implemented a few extension of LDA, including considering time dimension and perform incremental learning and also construct topic hierarchy and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The 4th algorithm we made in parallel is super vector machine.",
                    "label": 0
                },
                {
                    "sent": "We presented the paper last year at NIPS, so I don't want to get into this algorithm today.",
                    "label": 0
                },
                {
                    "sent": "So you can look at the details on the web.",
                    "label": 0
                },
                {
                    "sent": "So I'd like to say.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the final five minutes talking about this should be complete computing perspective, so we talk about scalability, Zaky and a lot of people may say scalability is pretty easy.",
                    "label": 0
                },
                {
                    "sent": "Google has GFS.",
                    "label": 0
                },
                {
                    "sent": "Google has MapReduce.",
                    "label": 0
                },
                {
                    "sent": "Basically, you can make everything running on map reduce, then solving the problem.",
                    "label": 0
                },
                {
                    "sent": "But the solution is not very easy.",
                    "label": 0
                },
                {
                    "sent": "So let's look at.",
                    "label": 0
                },
                {
                    "sent": "Basically, there are three things we need to watch out.",
                    "label": 0
                },
                {
                    "sent": "First of all, the lot of machine learning algorithm is iterative, so we have multiple iterations.",
                    "label": 0
                },
                {
                    "sent": "So the solution processing.",
                    "label": 0
                },
                {
                    "sent": "And this incurs an interesting challenge.",
                    "label": 0
                },
                {
                    "sent": "The data dependency iteration T + 1 depends on the data of T. And for each iteration we shouldn't have problem to do parallelization, but the challenges between iterations.",
                    "label": 1
                },
                {
                    "sent": "How do we resolve the data dependency problem?",
                    "label": 0
                },
                {
                    "sent": "And also the third challenge in Israel when you have multiple machines, let's say 1000 or even 10,000 machines, the probability one machine fails in the process of learning can be very high, so we don't want one machine fail.",
                    "label": 0
                },
                {
                    "sent": "Then we have to rerun the whole computation.",
                    "label": 0
                },
                {
                    "sent": "So therefore recovery is also critical.",
                    "label": 0
                },
                {
                    "sent": "So let's look at the map.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reduce architecture.",
                    "label": 0
                },
                {
                    "sent": "Basically we can store input data on a disk and this is a very simple depiction of GFS.",
                    "label": 0
                },
                {
                    "sent": "Every single copy of the data we replicate into 3 copies.",
                    "label": 0
                },
                {
                    "sent": "And then we schedule the task onto multiple mappers.",
                    "label": 0
                },
                {
                    "sent": "So if you consider this frequent itemset mining algorithm, so every single conditional database can be scheduled on one task.",
                    "label": 0
                },
                {
                    "sent": "An suppose one CPU reads the data condition database data and start to do a frequent artisan mining.",
                    "label": 0
                },
                {
                    "sent": "At the end we try to do shuffle based on items that content and finally we do reduction, then output the data onto GFS.",
                    "label": 0
                },
                {
                    "sent": "So for frequentists mining image reduce dimension is perfect.",
                    "label": 0
                },
                {
                    "sent": "But however, if your algorithm is iterative, then we have two challenges.",
                    "label": 0
                },
                {
                    "sent": "One is, once one iteration has been done.",
                    "label": 0
                },
                {
                    "sent": "According to MapReduce picture, we have to write all the data back to the GFS to ensure recovery can be performed.",
                    "label": 0
                },
                {
                    "sent": "The second challenge is in the second iteration.",
                    "label": 0
                },
                {
                    "sent": "Suppose we read data out of the GFS, we have to reset reschedule.",
                    "label": 0
                },
                {
                    "sent": "The task may be on too much auto different machines.",
                    "label": 0
                },
                {
                    "sent": "So by not being able to utilize the same machine between iterations.",
                    "label": 0
                },
                {
                    "sent": "Basically, we cannot take advantage of caching.",
                    "label": 0
                },
                {
                    "sent": "So my reduce may not be the perfect solution for CCF or for other algorithms.",
                    "label": 0
                },
                {
                    "sent": "So the next picture shows what we have been experimenting with in the.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One year or two.",
                    "label": 0
                },
                {
                    "sent": "So this column is map reduce an the right hand side MPI.",
                    "label": 0
                },
                {
                    "sent": "I think most people must be very familiar with and we are experimenting with another distributed framework an which we cannot disclose the detail but the major criteria we value are the following.",
                    "label": 0
                },
                {
                    "sent": "First of all we like to see whether we need to reschedule GFS IO between iterations.",
                    "label": 1
                },
                {
                    "sent": "For my reduce we have to do so.",
                    "label": 0
                },
                {
                    "sent": "And we like to be able to device a new method.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do that.",
                    "label": 0
                },
                {
                    "sent": "We should be able to reuse the same thread over and over again between multiple reiterations.",
                    "label": 0
                },
                {
                    "sent": "For MPI we do have the flexibility to do so.",
                    "label": 0
                },
                {
                    "sent": "The second one is do we have a flexible computation model?",
                    "label": 1
                },
                {
                    "sent": "An format reduces not very flexible.",
                    "label": 0
                },
                {
                    "sent": "We only have this all reduced model.",
                    "label": 0
                },
                {
                    "sent": "And sorry for my reduce, we only have this or reduced model for MPI.",
                    "label": 0
                },
                {
                    "sent": "We can do pretty much virtually anything.",
                    "label": 0
                },
                {
                    "sent": "We like an something in the middle, maybe a tradeoff between the two models.",
                    "label": 0
                },
                {
                    "sent": "And you can go through the table to see at the end.",
                    "label": 0
                },
                {
                    "sent": "Here recovery recovery map reduce the model itself, writes the data back to the GFS recoveries, ensure.",
                    "label": 0
                },
                {
                    "sent": "On the on, the MPI infrastructure recovery is not guaranteed.",
                    "label": 0
                },
                {
                    "sent": "Of course, you can write your own logic to do checkpointing, but it's not intrinsic in the model and suppose you can build a different distribute algorithm in the middle to try to take advantage of recovery situation.",
                    "label": 0
                },
                {
                    "sent": "So maybe I can defer.",
                    "label": 0
                },
                {
                    "sent": "The question is about about the end of presentation.",
                    "label": 1
                },
                {
                    "sent": "So currently we can score different computational models, may reduce may not be the best computational model for machine learning algorithms which require iterative process.",
                    "label": 0
                },
                {
                    "sent": "MPI also may not be the best, but you can implement your own checkpoint.",
                    "label": 0
                },
                {
                    "sent": "The MPI may be applicable and we are exploring some more advanced algorithms right now.",
                    "label": 0
                },
                {
                    "sent": "So let me move to the conclusion.",
                    "label": 0
                },
                {
                    "sent": "So we started motivating.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Machine learning problems by using 2 examples.",
                    "label": 0
                },
                {
                    "sent": "One is this Confucius product we mentioned when the machine learning kicks in.",
                    "label": 0
                },
                {
                    "sent": "Traffic goes up because we can really kick off equals the ecosystem in the product.",
                    "label": 0
                },
                {
                    "sent": "The second example is the open social right now has been able to reach so many people.",
                    "label": 0
                },
                {
                    "sent": "And how can we take advantage of the API and utilizing machine learning technologies to perhaps do recommendation or do.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's matching.",
                    "label": 0
                },
                {
                    "sent": "So 7.",
                    "label": 0
                },
                {
                    "sent": "Machine learning algorithms subroutines have been implemented for the Confucius project.",
                    "label": 0
                },
                {
                    "sent": "Recommendation system as I mentioned, is a push model of search and can grow increasing popularity in the future.",
                    "label": 1
                },
                {
                    "sent": "Recommendation system definitely demands scalability.",
                    "label": 0
                },
                {
                    "sent": "With 650 million people, Opensocial can reach without scalable algorithm.",
                    "label": 0
                },
                {
                    "sent": "We cannot do recommendation in the daily fashion.",
                    "label": 1
                },
                {
                    "sent": "And machine learning algorithm demands better distributed computing infrastructure than MapReduce, which I think many different labs are developing right now.",
                    "label": 0
                },
                {
                    "sent": "So finally",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you are interested in the details of the algorithms, they are all online.",
                    "label": 0
                },
                {
                    "sent": "You can access through my website.",
                    "label": 0
                },
                {
                    "sent": "We also made the support vector machine parallel algorithm online.",
                    "label": 1
                },
                {
                    "sent": "You can download from the open source for the relevant documents and citations.",
                    "label": 0
                },
                {
                    "sent": "You can refer to the reference of my presentation, so thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Time for a few questions.",
                    "label": 0
                },
                {
                    "sent": "So this is basically our estimation or rating for this.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say my reduce right flexibility in computational model we consider is not very flexible.",
                    "label": 0
                },
                {
                    "sent": "So we give you the.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fine, this is our rating.",
                    "label": 0
                },
                {
                    "sent": "And for MPI we consider the model is extremely flexible.",
                    "label": 0
                },
                {
                    "sent": "You can do whatever you want on every single computational task.",
                    "label": 0
                },
                {
                    "sent": "So this is pretty much our own rating.",
                    "label": 0
                },
                {
                    "sent": "You can say 4.6, but basically it's already rating between different.",
                    "label": 0
                },
                {
                    "sent": "Distribute computing paradigms.",
                    "label": 0
                },
                {
                    "sent": "Yes, is there any recommended system that you're working on where both documents or communities, for example, as you were showing them end users have features 'cause at the moment in your system it's only the communities that have a description of the users don't?",
                    "label": 0
                },
                {
                    "sent": "I don't have any kind of further features right?",
                    "label": 0
                },
                {
                    "sent": "We didn't talk about, we didn't write out the features of users, but when we put you there implies the profiles of users.",
                    "label": 0
                },
                {
                    "sent": "So let me go back to this picture here.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the you here you can see the you here includes a profile of the user.",
                    "label": 0
                },
                {
                    "sent": "And also activities of user and stuff of users everything.",
                    "label": 0
                },
                {
                    "sent": "Does that mean that those are combined like simply concatenated inside equivalent, or is that a little bit different structure the structure?",
                    "label": 0
                },
                {
                    "sent": "Features.",
                    "label": 0
                },
                {
                    "sent": "On the on this particular branch, yes, you can consider additional information can be just concatenated onto the onto the vector, but when you join the two together, this is different probability model.",
                    "label": 0
                },
                {
                    "sent": "I guess the question is how do you combine those probabilities.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have a probability of 1 particular feature.",
                    "label": 0
                },
                {
                    "sent": "Basically, this model is when you expand it would be proud of multiple conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "Then using Gibbs sampling to learn the weights.",
                    "label": 0
                },
                {
                    "sent": "That's a challenging problem.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "We basically, if you have this particular framework at the end you have this analytical model with a new user, you can right away to a recommendation.",
                    "label": 0
                },
                {
                    "sent": "However, if the new users information is very sparse, suppose you user hasn't filled in profile information, then we don't have foundation to do recommendation in the situation.",
                    "label": 0
                },
                {
                    "sent": "The only way we can do it is probably based on the right hand side branch.",
                    "label": 0
                },
                {
                    "sent": "So we don't have personalized information.",
                    "label": 0
                },
                {
                    "sent": "And there are other methods we can deal with this kind of method, but you cannot use this particular model.",
                    "label": 0
                },
                {
                    "sent": "It cannot be very effective.",
                    "label": 0
                },
                {
                    "sent": "Tell us anything about your hierarchical.",
                    "label": 0
                },
                {
                    "sent": "What you're doing with tirofiban this morning, I think details will be probably disclosing in the near paper.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But basically the patching goal machine was a paper published by UC Irvine, I suppose.",
                    "label": 0
                },
                {
                    "sent": "So basically we are following that direction.",
                    "label": 0
                },
                {
                    "sent": "And also another paper published by David Blei supervised LDA.",
                    "label": 0
                },
                {
                    "sent": "So the model here we depicted.",
                    "label": 0
                },
                {
                    "sent": "We don't consider we have prior information about documents or users or whatever, but suppose you have some prior labels on a person or undocumented community.",
                    "label": 0
                },
                {
                    "sent": "Then perhaps you can align your latent aspects to this hierarchy and also with a pre label hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Not only a hierarchical model, but maybe a pre label ontology or taxonomy.",
                    "label": 0
                },
                {
                    "sent": "So we're still doing experiments right now, but the models were proposed already by the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "So perhaps a bit of a high level question, so imagine you managed to solve these sort of a planetary social network and you know you.",
                    "label": 0
                },
                {
                    "sent": "So with the key players where you know who can be trusted, who cannot, can you tell us a little bit?",
                    "label": 0
                },
                {
                    "sent": "You know in what, what direction would Google be using that to change the?",
                    "label": 0
                },
                {
                    "sent": "You know the experience, beat search or interaction with the web.",
                    "label": 0
                },
                {
                    "sent": "Right, I don't know what the search people would do.",
                    "label": 0
                },
                {
                    "sent": "The only thing I can answer would be on Archon.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Future system.",
                    "label": 0
                },
                {
                    "sent": "Give example here already.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's easier for me to flip back.",
                    "label": 0
                },
                {
                    "sent": "So in this example.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Soso suppose we have multiple QA pairs.",
                    "label": 0
                },
                {
                    "sent": "Or you can consider you have lots of forums about the same topic and which one you want to select to index on the web search and user credential can be important factor.",
                    "label": 1
                },
                {
                    "sent": "Alright, so Q&A peers about Yosemite.",
                    "label": 0
                },
                {
                    "sent": "We can get 10 pairs, but if one pair is written by a credible person, maybe not.",
                    "label": 0
                },
                {
                    "sent": "There should be indexed.",
                    "label": 0
                },
                {
                    "sent": "So this is very simple idea.",
                    "label": 0
                },
                {
                    "sent": "Facebook.",
                    "label": 0
                },
                {
                    "sent": "How much is cocaine?",
                    "label": 0
                },
                {
                    "sent": "The number we don't have here, so.",
                    "label": 0
                },
                {
                    "sent": "If you if you the prior, if you can model the power accurately, you can gain quite substantially, but the question is how do you tune the LDA parameter to start with and I guess yesterday there was a paper at NIPS and discussing about how do you tune the priors.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}