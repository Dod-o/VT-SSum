{
    "id": "xcohh5krk2twokyapspvznuxi72d64pc",
    "title": "An efficient approach to stochastic optimal control",
    "info": {
        "author": [
            "Bert Kappen, Department of Medical Physics and Biophysics, Radboud University Nijmegen"
        ],
        "published": "Aug. 5, 2008",
        "recorded": "May 2008",
        "category": [
            "Top->Computer Science->Optimization Methods->Stochastic Optimization"
        ]
    },
    "url": "http://videolectures.net/aispds08_kappen_easop/",
    "segmentation": [
        [
            "OK, well good morning everybody and let me first thank the speaker.",
            "The speaker is not the the organizer.",
            "Put it wonderful meeting and for inviting me here I'm enjoying it very much.",
            "What are we talking about?",
            "This is about stochastic optimal control theory, which is really not my field, but I got into it because I've been working a lot on approximate inference.",
            "And graphical models.",
            "And I have the feeling that that's sort of saturating.",
            "We've seen the bulk of that and was good time to look at something something else, something new, and I was always.",
            "I was sort of control is one of these areas where I thought there's a lot of complexity.",
            "Very little approximate inference happening, so this may be an area out to that will be good to see what we can do there something, and I've been looking a lot at.",
            "At so, if you look at control, you look at the first thing you look at this these development equations and development equations in are also arise in physics and their quality Hamilton Jacobi equations.",
            "And of course these equations are the classical equations from classical mechanics, and you can write these equations.",
            "There are sort of related to the Schrodinger equation.",
            "I was very much intrigued by that link for a long time, particularly because the Schrodinger equation is a linear equation.",
            "A linear sounds easy, so if you can make something linear, then there's maybe a link, but the Schrodinger equation is a complex valued equation and I tried to explore that link and it goes.",
            "There's a lot of work in that area actually trying to explore that link under his work by Nelson from the 60s.",
            "Who made some some stochastic interpretation of some stochastic system which actually exactly mimics quantum mechanics.",
            "I was very intrigued by that, didn't get anywhere in the end.",
            "I did was able to explore that link and that's the story I will will tell you about today."
        ],
        [
            "So.",
            "Optimal control is delayed reward task, so you do something now and the reward comes in the future.",
            "So you make a arm movement.",
            "And the whole trajectory leads to a final goal, which is banging somebody on the hat, and that's the reward that you get in your future.",
            "And so we have to take this whole sequence of action and the whole sequence has to be correct in order to appreciate the year to collect the reward.",
            "And of course."
        ],
        [
            "This is complex and is particularly complex if the system and the environment that you have has a lot of noise, because then everything easily gets."
        ],
        [
            "It's intractable.",
            "So."
        ],
        [
            "So control is how to act now to optimize future rewards.",
            "And.",
            "In particular, and here you see an example of why this can be difficult, because the optimal control actually depends on the amount of noise in the environment.",
            "So if I look at this, Spider wants to go to that to the Bank of money on the other side of the Lake.",
            "You can either cross the bridge or go around the Lake, and if there's no noise in the problem.",
            "Of course, clearly the shortest way is to just cross the bridge, and there he goes, but if there is noise in the problem, there is a finite probability that he will fall off the bridge.",
            "And then that's the expected cost of.",
            "That path becomes very expensive.",
            "Basically shutting down that path and then the optimal track directory is actually to walk around the.",
            "Lake, so in other words, optimal control with noise is not just a noisy version of optimal control without noise, it can be actually very different.",
            "Kind of a solution OK?",
            "So this computation is intractable in general because you have to solve a number of you have to solve partial differential equation in a very high dimensional state space, and if descript eyes and everything gets, it gets very very slow.",
            "And if you want to have a tractable approach then you are stuck with a unimodal class of models either being the linear quadratic common type of models or you are in the distant deterministic setting and out of those cannot really treat this kind of complex.",
            "Problem."
        ],
        [
            "So what I want to talk about today is to give you a feeling of to just refresh you on control theory.",
            "Some of you may notice some you may not and then introduces a path to control theory that allows some efficient computation and discuss with you some symmetry breaking effects that you see there, which are, which are way of saying basically that you get as a function of the noise.",
            "You get different solutions and you will get.",
            "You will see how in this system these qualitatively different solutions for high and low noise arises symmetry breakings in such system and if time allows.",
            "I will go to agents, but we'll see how far we go.",
            "Um so."
        ],
        [
            "I'll start with this tree discrete time control in in a noiseless system, so I have a dynamics which is a pointer.",
            "That's OK, so X D + 1 is a function of XT, and maybe depends explicitly on time, and there is some control variable.",
            "Utah, which if I want to so, then I consider this system for a finite amount of time in the future an if I specify all the controls UTI this whole vector, then I know the starting position of XI know.",
            "Of course the whole trajectory of X.",
            "And then I can consider a cost which is a cost of incur at each time point, which is some function which depends on the state and making the control value.",
            "And I sum all these cost contribution gives me a final cost and this cost only depends on the initial position of X and on the control vector that I use and optimal control problem is to find the vector you that minimizes this cost."
        ],
        [
            "And the solution is is standard and it is you computed by dynamic programming and it goes by introducing the quantity is quality optimal cost ago.",
            "Suppose that you have solved this cost problem at some intermediate time.",
            "Small T for some arbitrary location X being so.",
            "Then you have the minimum of the remaining controls of this of this sum and then if you have this quantity.",
            "At T is capital T. Of course it's this sum becomes empty and this is so that gives a boundary value and AT is is zero.",
            "You have the original solution so you have to just get a recursive update for this in the following way that you say that JAT."
        ],
        [
            "This one is zero and JAT.",
            "Is this definition that you take one to him out and you push the minimization.",
            "You push it through.",
            "You recover the definition of J at A at the next time point at some arbitrary location and then.",
            "And you have to minimize this with respect to you've T Now XD plus one is."
        ],
        [
            "X D + 1 is also a function of beauty because you can fill in the dynamics here."
        ],
        [
            "So this whole right inside becomes a function of Utah only, and so you have to do a pointwise minimization with respect to Utah.",
            "You have to do that for all time steps, and this way you get get a solution at T0 and once you have this solution, sorry, then once you have this solution, you have the whole sequence of control actions and then you can make a step and get forward and get the get the whole optimal.",
            "Optimal dynamics for such a system, so this is dynamic programming and it's basically."
        ],
        [
            "If you go into the continuous, consider the continuous case so you have a.",
            "Now we have space, so we take instead of increments one.",
            "We take increments Delta T and we get this same recursive equation that we had on the previous sheet with this minimization.",
            "And now we now we do just the Taylor expansion to 1st order in Delta T. We expand J team does Delta TX plus Delta TXT plus Delta T in this way.",
            "At the time derivative.",
            "And there is a space derivative, and we insert a Delta.",
            "X is FFDT and so then we can just collect this whole thing.",
            "We get continuous time version of this of this dynamic programming.",
            "And here you see the partial differential equation nature.",
            "So J is a function of X&T.",
            "There's some time derivative, some space derivative and there is this funny pointwise minimization that you have to do at each intermediate time.",
            "Now it going from the discrete time solution discrete time formulation to the continuous time formulation.",
            "I have separated in the in the in this sum."
        ],
        [
            "Separated out the end cost as a separate term.",
            "In here we would get a density over costs over the over the winter."
        ],
        [
            "Pediat times and so the end cost.",
            "Now I did not hear Fi and it becomes a boundary value for this.",
            "For this J at the end time and so here you see a picture of how this looks like.",
            "So in the future I have a cost J which is equal to five which may be some double well potential.",
            "Something that I want to be here in the future or here was equal equal cost.",
            "And now the question is what to do at now at an earlier time?",
            "So this is.",
            "Time does earlier and this J is then computed by solving this partial differential equation with boundary condition and it may be giving you this kind of shape and basically to think of the optimal control is that when you are at any of these X locations then the optimal control is a gradient sort of gradients operation on this J.",
            "So it may be moving to the middle.",
            "So this term J optimal cost ago is also known as the anticipated potential, so it's a potential that is is what is applies to now instead of to the future."
        ],
        [
            "OK so here you see a simple example.",
            "1 dimensional system.",
            "2nd order where we have Newton's law FS M * A an we have masses one and we get to control where we can where we can use this with the spring force and we have an external control.",
            "So we get this kind of a second order system and now we want to control this thing in such a way that given an initial position and velocity at time zero find to control path which is between minus one and plus one such that at the end.",
            "Time, the position of the ball is maximum, right?",
            "This case is extended control that you can formulate."
        ],
        [
            "And you write a system as as two for a couple 1st order to 1st order systems.",
            "So then it's of this form that we just discussed.",
            "Here is the control variable.",
            "Here's the states variables and.",
            "Then we have some costs and then we can take this Hamilton Jacobi equation which is this equation we just filling.",
            "The thing we get something looks like this.",
            "We can do actually the minimization and since you is between minus one and one, he gets an absolute value here.",
            "So we get this equation which we have to solve."
        ],
        [
            "We don't have to do details, But anyway, this is the solution that you didn't get an if the end time is 2\u03c0 then it is called Bang Bang control that between T is 0 and \u03c0 you have to push a maximally down to get the maximum extension of the spring and then between \u03c0 is between time pie in 2\u03c0 you have to push the force up and here you see that the.",
            "Trajectory of the position as how it is eczema.",
            "This maximum value.",
            "So this is very simple example of such a control case."
        ],
        [
            "Now if we have noise we have, we have a winner.",
            "We can have a Wiener process so we have such a additive term here and basically the equations.",
            "What now changes.",
            "So this is, you know, we've seen the lot in the last few days, but this is how Gaussian noise looks.",
            "We get the cost now becomes an expectation.",
            "It's not a deterministic quantity, so we can only optimize the expected cost and the expected cost is so, given that you are.",
            "At position X and you specify the whole control path, then you don't really know where your particle is going to end up because of this noise, and therefore you can do at best an expectation.",
            "So you compute this expectation value if you can, and then you start changing.",
            "Conceptually changing these control paths in such a way that you minimize is expected value, so that's that's the task at hand that we now have."
        ],
        [
            "And we can start again at the same recursive equation that we had before this this continuous time.",
            "A dynamical programming update and now we have began to do this Taylor expansion.",
            "Here are the differences now that we have the expectation values here around here.",
            "So we now do the Taylor expansion here again, but now we have to expand to 2nd order in the X because of the Vilna noise, of course is the square displacement is of order DT, which is which is the nature of the of the of the Gaussian noise, and so we have to expand the 2nd order in X.",
            "And 1st order in DT and then DX is just the domain drift of the dynamics and the X squared is just.",
            "Nudity is a noise in the system.",
            "So we can just plug this in here and we get basically the same equation with one extra term which reduces to dismissing case if news are equal to 0.",
            "If there is no noise.",
            "So do we get this this called stochastic Hamilton Jacobi Bellman equation?",
            "And again we have to solve this with this boundary condition at the end at the end time.",
            "Alright.",
            "Any questions?",
            "Everybody happy so far.",
            "OK.",
            "Difficulty of solving.",
            "Dementia.",
            "So this is a partial differential equation, an IV access the state space, which is, you know high dimensional.",
            "You have to basically discretize.",
            "And that's the difficulty in solving this thing.",
            "Well, the minimum of you is there is you have the minimum of the path, but this is a pointwise minimum right at each at each time point.",
            "So it is indeed it may be.",
            "This is like, you know, if you have a 10 dimensional problem then you have a 10 dimensional.",
            "Can numbers to minimize.",
            "I mean, you can do some.",
            "Eliminate it then.",
            "Huawei.",
            "Well, this depends.",
            "I was in the in the in the special case I consider.",
            "I can eliminate it, but in general it may not be not be easy to actually eliminate it.",
            "Yeah.",
            "OK, so."
        ],
        [
            "General this is this.",
            "You get stuck with this and you cannot really do much practical things with it and therefore I will now look at a special case in which the F, the dynamics of the system is additive in the control variable.",
            "And where the costs of the is separates as a term which depends on is state dependent, arbitrary and is also additive, quadratically in the cost in the in the control.",
            "So these.",
            "So this this term, this dynamics becomes this.",
            "There's a.",
            "There's a linear terming you here, and here is a quadratic term U, and for the rest is arbitrary, so we have an arbitrary dynamical system which has can have an arbitrary state dependent cost.",
            "But the control that we have is sort of very simple.",
            "We can only act linearly on the on the dynamics, and we get a quadratic cost.",
            "So it's like a simple control over arbitrary complex system.",
            "So then this equation becomes here, the R becomes you squared plus B&F.",
            "Sorry, does F. Plus you should be FU here.",
            "This is a mistake.",
            "FU and so then we have linear quadratic.",
            "Here we can minimize explicitly and then we have a second we get U is minus the gradient of J and we can plug it back in and so we now have a quadratic term in here.",
            "So this is then a partial differential equation which is a nonlinear partial differential equation.",
            "Which we have to solve again, which is boundary values at the end time and once we have the solution JXT we have to take his gradient and it gives us our control signal at the point XT.",
            "Yeah."
        ],
        [
            "Now this equation can be solved and this is the link to the that I said before to the quantum mechanics because this."
        ],
        [
            "This this this.",
            "This is also known in physics as the Hamilton Jacobi equation, and it is very closely related to the Schrodinger equation."
        ],
        [
            "And the link is through a log transform, which was also Mumford was flashing that at some point in one of his sheets.",
            "So there is a link actually between this work and what month it was talking about.",
            "So if you do that, you get this.",
            "You make this change of variables.",
            "You get that this equation becomes linear.",
            "Inside as a partial differential equation with the end condition now becomes just simply this and so we can write this as an operator H acting on PSI, and so this is again a partial difference equation.",
            "Which of the soul was an end condition, etc, and so that's that's OK. Now we define a new process which is a stochastic which is a diffusion process which is.",
            "Sort of a joint to this process, so there is a - here to change and the age is replaced by HHH dagger, which is the mission conjugate of H. So if you do that, then it basically means that this term becomes a little bit different, and but the other two terms stay the same.",
            "And the trick is that if you define this process of this process, row is a density which runs in positive direction, positive time direction.",
            "So it starts at T is the small T and it runs forward in time where this process was starting.",
            "At the end time and running backward in time, and the construction is such that the the product of ro times sigh is independent of time.",
            "So in other words.",
            "So if I take PSI at some intermediate time, I've computed it backwards.",
            "From the capital T and I get some solution and I multiply it with row which starts at the initial time and I run it forward to this same intermediate time tour.",
            "Then this quantity of our integrated over overall space.",
            "Then this quantity becomes independent of the choice of the intermediate time.",
            "And the reason is very simple, because if you take the time derivative of this whole quantity, you get time derivative first plus times a second plus the time plus the first time through the 2nd, and you get his H&H bar and is minus and then basically it becomes time independent, so by construction is time independent."
        ],
        [
            "And that means that I can evaluate this quantity at the initial time or end at the final time and should give the same result at initial time.",
            "This row is a Delta.",
            "At some location, so Drose initialized at X.",
            "So we have a Delta.",
            "Here it just becomes shy XD.",
            "If I initialize that initial.",
            "If I computers initial time.",
            "So at initial time gets ixta at the end time I get row at the end time times this one at the end time, which is just the boundary condition.",
            "So I can equate these two things and I will get this surrogates ixta.",
            "Is this row evaluated at the end time Times E to the end condition?",
            "So in other words I have here the explicit solution of my optimal control problem.",
            "Because once have sigh, I can take the log transform again J once, if Ji take the derivative, I get my optimal control and it solved.",
            "Also have the optimal control solution for this problem.",
            "OK."
        ],
        [
            "So let's look at the example.",
            "Here we have a simple dynamics where F is zero.",
            "We just have to control and we have the noise.",
            "Ann is 1 dimensional.",
            "X&X is running in this direction.",
            "And time is running in this direction.",
            "And the aim is to have this stochastic process end up at the origin, so even end cost, which is 5 which is X squared at the end time.",
            "So that's this term and then we have a intermediate path cost which is given by this double slit where the cost everywhere is at time is 1 V. At times one is infinite everywhere except for these 30 two holes where there is no cost.",
            "So indeed so if you want to get a trajectory then the minimal cost.",
            "Trees are ready to move through this one or through the other one, and so how you compute it well in this case you can just compute this thing.",
            "You can do this diffusion process.",
            "What we have to do this to compute is the Fusion process, which I will talk."
        ],
        [
            "But in a minute, so we have to solve this forward process and get a solution and."
        ],
        [
            "Plug it in there and that's what I did and you can do it analytically.",
            "And for instance the J that comes out as a function of X for time 0 is this blue line.",
            "And it shows basically two things.",
            "One is that if you are in one of these valleys, it pushes you by the gradient to these minimal points, which are located at minus sort of minus five here and plus six which is related to the fact that these holes are the ones these holes centered around 7:00, and this whole centered around minus five, and the other thing is that you see is that the the height of this value is how?",
            "Is higher than that one because Rimmer, J is should be interpreted as the expected cost to go, so it is the expected cost that you have from any point to reach, reach the goal and the expected cost is higher here than there.",
            "'cause if you're in front of this whole then you have to make a larger path to the origin story in smaller path through the origin.",
            "And if you are here and so the expected steering cost that you have in this part is higher than the expected stealing cost in this part and that's why this one is higher than that one.",
            "So that's why you get these.",
            "These things so OK and so then if you have this solution you can do it for all intermediate times and you can then steer you taking the gradients of this J and those are these two trajectories are two examples of those kind of optimal trajectory that you get under this optimal controller policy."
        ],
        [
            "So I.",
            "To go to this to look at this a little bit further."
        ],
        [
            "If we just look at the at this part of the problem between zero and one.",
            "So basically you can make these slits arbitrary small.",
            "So basically two targets you I go this way or that way."
        ],
        [
            "And as I've drawn here.",
            "And if you go to that limit."
        ],
        [
            "Then you can actually solve these J analytically and it becomes.",
            "This function is just exclude formed expression.",
            "You take what capital T is now the time to reach.",
            "It's not the end time, but it's the time to reach it's time to go.",
            "So it's capital T minus multi in the earlier notation, and if you take this out you see that here between the brackets you have a function which depends only.",
            "It depends on X and on the product of New Times T News the noise so depends on the product of the noise and the time to go.",
            "And if you look at different values of this product as a function of X then you see that you get the symmetry breaking in this system where for high values.",
            "Of tee times new, you have a smooth unimodal shape and for low values of T times new you get this breaking where you have these two these two minima and it means that.",
            "That if you are far away in time from the targets from any other two targets, so."
        ],
        [
            "If you are sort of here and then you know the optimal control says that you have to steer towards the middle.",
            "And if you get a certain beyond a certain point, clearly stealing towards the middle is not good at all times, because then you will miss the target altogether.",
            "So at some point you will have to make a choice, and this choice is given by this symmetry breaking affect where the wedding."
        ],
        [
            "J. Ben starts to bend over, so at this point you're forced to make a choice.",
            "Actually, at this point it is 1 where your steering to idle their goals, because otherwise you're going to miss that many of the goals.",
            "And so while you can ask yourself why is steering to the middle is a good idea if you."
        ],
        [
            "Still far away, well, it's very easy in a sense, because if you're far away in time, if you do nothing, you could go straight ahead.",
            "Then just by noise itself.",
            "By diffusion itself, you will reach any of these goals.",
            "You don't have to do anything which is going to drift to either of these goals, so why waste energy steering where you can get it for free?",
            "But of course that policy fails as soon as you're here, because then drift by itself will not exterior to that.",
            "So then you have to actually steer, so that's why."
        ],
        [
            "What's happening?",
            "Yeah.",
            "I wasn't quite clear with the bro you you solve it once and for all you have to resolve it at every time.",
            "So here I am so.",
            "Here I am.",
            "Well, you have to solve row condition on the on location where you are and since the location where you are.",
            "At the new timestep is unpredictable, basically because of the noise you have to solve it every time.",
            "Again again, yeah, yeah, yeah, yeah."
        ],
        [
            "OK so here you see these trajectory under optimal control.",
            "So here in this case this is a stochastic optimal control, where here is the X trajectory as a function of time.",
            "And here's the control as a function of time.",
            "An here on the right we see the deterministic where we basically have say, well we take the noiseless optimal control pace and you see here for the noise is optimal control case if X is positive, then it says well go to target one so it will steer upwards.",
            "If X is negative, it goes to target minus one, etc.",
            "So doing all these kind of control actions which are basically not needed because you're still drifting along way and then after you reach time is 1.",
            "You're stealing to one of these.",
            "One of these targets, whereas here in the stochastic case you see that the optimal control is basically zero.",
            "Saying do nothing and then at some point it actually has to do this."
        ],
        [
            "OK, so does the Fusion process which was solved which is given by this for Planck equation.",
            "With it.",
            "Let's look at a little more in detail.",
            "We have a drift term which recognizes just F is the mean.",
            "It's mean drift and we have a diffusion term which is just a standard diffusion term and then we have this funny term which is involves VV.",
            "Is the cost in the path.",
            "So remind your V will see we had written here."
        ],
        [
            "The cost is written as a vetren plus, so this is the cost that you incur."
        ],
        [
            "At a certain location.",
            "And the.",
            "So this actually these two terms, they conserve probability, so they if you take the integral overall X of row and you look at the time variation of it, then this one gives a time.",
            "This one gives 0 and this will also give 0.",
            "But this one actually kills probability at a certain rate.",
            "So the way that we can simulate that is to say, OK, well, we just have an ordinary diffusion process which is given by these two terms and then in parallel we have a killing rate.",
            "So we do this with probability 1 minus VDT over new and with probability DT over new.",
            "We take the particle out of the simulation, it's gone.",
            "And that is apparently the way to simulate this forward process in order to get a diffusion right, which we need.",
            "So then we get this diffusion kernel.",
            "We have a stochastic simulation of diffusion kernel and that's what we need to compute the optimal."
        ],
        [
            "Alright to put it in in here?",
            "So this is the Fusion.",
            "You can write it as a path integral because you can basically say, well, this diffusion is a is a walk from X to Y and that war can be in a finite amount of time.",
            "Capital T minus multi and that that work can be subdivided in a number of small intervals and then basically taking the limit of the interval size to zero you get that.",
            "Well, you get this this this conditional probability becomes a product of terms integrated over all the intermediate values and that the product of terms can be great in the exponent as a sum over terms which then converts into an interval as being this path.",
            "And this path costs just penalizes the deviation of the derivative of X from the mean drift, and there's a there's a potential."
        ],
        [
            "Dental term so in other words, just to put all the formulas on sheets, we have an optimal control solution which is of this form where weekend our oh we can write it as a passive role and we can take this term also into the path integral where S is not the past contribution plus the end term.",
            "So we can write this whole thing as a free energy because Jay is mines local size, so we just get exactly free energy contribution where you normally in the free energy you have some over exponent of the energy.",
            "Here we get some of the exponent of an action so and also divided by new which is a place a role for temperature.",
            "And so if this is the partition sum then the corresponding probability distribution is this quantity, right?",
            "So this is the normalizer and the probability distribution is just the exponent of each of the path that you can think of, conditioned on the current position where you are.",
            "So you are here, you can consider very many paths, each of them has a certain cost South which takes into account the path contribution at the end cost and then you have to then this is the probability of all these paths.",
            "So."
        ],
        [
            "To just put together, give a little bit well, let me skip this I think."
        ],
        [
            "Yeah.",
            "Mobility is, I mean, you're not using that to make decisions or anything, but it's just.",
            "It's just an analogy, is it?",
            "That probability will arise here once I.",
            "Let me see.",
            "So this is an example here.",
            "You'll see you'll see the rise.",
            "So now we have such a.",
            "Last thing I want to talk about is how you can actually use this to solve efficiently some very intractable problem.",
            "And this is the case of coordination of a number of agents.",
            "So now we have not one of these processes, but we have any of them which are agents and they each have a independent dynamics which is given by F Alpha and they have independent controls, which are you Alpha and have independent noise which is Scialfa, but their actions should be coordinated in the sense that they have to jointly solve some task.",
            "Which is which is measured at a future time.",
            "So for instance they have to extinguish a number of fires and I have to run around to all run to the total tool.",
            "The same file that I exchanged only one of these fires, but I have to sort of coordinate attached at the end time there is an equal distribution of agents over over fires, so we have an end cost which depends on the end position of all the agents, and we assume that these agents positions are only restricted to these and any of these fire locations.",
            "So each of the agents end position is energies.",
            "Cajun an we have infinite costs for any of the other end configurations."
        ],
        [
            "Then we get exactly the same formula.",
            "We get that the disposition some is now with some of our integral of all the agent positions.",
            "The dynamics to go from X to Y factorizes.",
            "This is the forward diffusion of each of these agents to move from X A2.",
            "YL find these are completely independent, and so you just get a product of these of these independent agent dynamics, and then the whole thing is penalized by North cost, where all these ants costs are coupled through this FI.",
            "And so we can write this as a.",
            "Since the end costs are restricted to these low discrete locations, we can, which are the fires, we can restrict this.",
            "We can write some integral as a sum and we get here as sort of an energy expression where we put his role in the exponent and so we have we defined this P of Y as this probability distribution the same way we did before then.",
            "Then the optimal control which is the gradient of J, which is the gradient of the log of.",
            "Sigh, it becomes this kind of an expectation value that we have to now compute, so we have to take a gradient of row row work to compute the dynamics for each of the agents.",
            "Take the gradient with respect to the initial position of that agent and that gives us some formula and that is OK. We can do that, but then we have to take the expectation value with respect to this probability distribution, which is really a probability distribution over all the.",
            "Ends positions of all the agents at the end time, right?",
            "And so we now see that this coordination task has become a graphical model inference task because if we think of.",
            "Of this probability distribution as a graphical model, which basically is then.",
            "Then, taking computing this expectation value is just depends on the single variable.",
            "So it's like computing a marginal for Alpha in high dimensional states, state vector Y going from one to N. So which is a marginal kind of computation?"
        ],
        [
            "So the pseudocode to solve this is that you compute the cost and the logarithm for each agent to move to each target.",
            "So each agent is Agent, Alpha is the location X Alpha where he currently is.",
            "You compute for each of the target location what the cost is in the absence of the of the control.",
            "And of course this can be, but this factorizes basically the problem of all the agents.",
            "So we have to do it for each agent separately can still be difficult, but you can do a pass in.",
            "The goal can be estimated using Monte Carlo sampling or something, or maybe variational approximation, and then once we have these terms, we have to do we have to do a graphical model inference in the couples.",
            "All these other."
        ],
        [
            "To basically put it in here and then do this graphical model inference."
        ],
        [
            "And it's in that case, and you can do that, maybe exact if the graphical model is small and you can use BP or mean field."
        ],
        [
            "Proximation, so in a simple example where the state space is 1 dimensional and we have N agents and we have no dynamics, then this conditional distribution is just a Gaussian and if the end cost just says well I want all the all the fires that have the same number of agents then then we get this kind of a quadratic form and then we can compute this optimal control and the optimal control is now given by the expectation value of Y at the graphical model.",
            "Minus the current position, so this thing is the Now the intractable quantity that we have to compute.",
            "It is the expected value of of at a future for Agent Alpha in the context of what all the other people are doing.",
            "So it's a summary of all this uncertainty of all that with all the other edges are doing.",
            "You see it here."
        ],
        [
            "In simulation.",
            "So here's the beginning of time.",
            "Here is the end of time.",
            "Here is 5 fires, and here is a bunch of agents and they start at some locations and use what I've plotted.",
            "Here is the expected target location of each of these agents as a function of time.",
            "So this blue agent, for instance, thinks initially he should go to the target located at 0, and then at some point something happens because the other agents are doing something and he said, well, now it's better actually that I go to.",
            "Target at minus two and then once he.",
            "So once you have your your expected target location."
        ],
        [
            "In which is this one?",
            "Which is the hard part of the computation, because it takes all the other agents in two accounts, one actually moving there is very easy.",
            "Optimally because you just just do this very simple rule which is moving just in a linear way to that particular target."
        ],
        [
            "And so the actual trajectories of X are then given in this way."
        ],
        [
            "And of course, computing this such expectation value, you can do it either is somehow Ristic and what you can see.",
            "Here we compare some midfield control and we compute this expectation of women fields, or with belief propagation, and basically comparing it to the exact value.",
            "Get very very similar values.",
            "Is the cost difference and just to see that this problem is actually not trivial, we've compared it with the greedy control where each agent is the same.",
            "Well, I'm just going to the nearest nearest fire and.",
            "Forget about everybody else and you see that that indicates that there is hardly any noise that is not such a bad policy.",
            "But if the system becomes noisy, debt grading policy is actually very bad."
        ],
        [
            "You see some computation times as a function of the number of agents comparing to exactly this is the line exact on the exponent on the log scale, and you see these these nice lines or the computation time for this mean field, so you can do efficient inference.",
            "OK. With a graphical model I didn't quite follow what the components the graph model identifiers and yet lost connectivity.",
            "So OK so."
        ],
        [
            "The connectivity in this case is if this is MJ, is the desired number of a of agents at at fire J and so these are numbers that are given and and J.",
            "This is the basically the number of agents that end up at 5 J.",
            "If you have this vector, why write the number to go there?",
            "And so this term becomes quadratic.",
            "And why so?",
            "This gives us sort of pairwise interaction in the graphical model.",
            "And then the and then the this term, which is the is also coming into the graphical model, right?",
            "Because it is, this term is here, right?",
            "This is all integrated.",
            "This is a graphical model and this dream is also in there.",
            "So in this case this term is of course only linear in any position, so it doesn't affect the graphical model structure.",
            "Right, so and clearly, the success of such a BP or mean field approach depends very much on the density of such a connectivity graph.",
            "Unfit no, it's yeah this quadratic, but sorry it's pointwise so it's only it's there's no term Y Alpha Y beta, so it's a it's a single single node.",
            "Service, yeah single it's a single variable.",
            "There's no it doesn't compute to it doesn't.",
            "There's no link is just a single variable.",
            "Know this.",
            "These variables are here restricted to to a discrete set of endpoints, so in this case each why Alpha can have the values minus two to two?",
            "And in this average, why this is now a completely deterministic thing?",
            "I mean that the noise is completely gone from the left picture.",
            "No no no no no no no no this so the average.",
            "So we have here so we have here a probability distribution over Y, where Y is a vector for each each of the agents, and why Alpha has values.",
            "Minus two to two.",
            "In this case, the one dimensional locations of the of the fire, and so we have an in-depth graphical model which consists of two ingredients.",
            "One is the pointwise terms that come from the from the free dynamics of each of these agents, and the other term comes from the interaction that they should minimize something jointly at the end time these two ingredients are in this graphical model and then have to do a graphical model inference an in this particular simple example, for instance, is just as an example.",
            "You have to then compute for the optimal control the expected value of Y, Alpha and its expected value."
        ],
        [
            "You see that they, so here the expected value for this green one is here.",
            "And then maybe it's complete.",
            "This is computed in the context of all the.",
            "All the others do.",
            "And then this.",
            "So let me just."
        ],
        [
            "So here's another example here.",
            "See a little bit more complex example where we have a number of agents in 2 dimensional space and where the dynamics of each of the agents is a second order.",
            "This is the 2nd order system.",
            "Let me see.",
            "Yeah well there is some.",
            "Yeah, so we have the position.",
            "The change in the position is given by the velocity and the change in the political philosophy is given by the control variable and there's some noise there.",
            "So we have some initial positions for these for these cars that can.",
            "So you can think of this cars with certain mass and against ear and they have to start a 10 car.",
            "Start here and they have to end up at East End locations.",
            "But there is only one car end up at each of these crosses so they should not go additional.",
            "Go to different ones so it's a little bit of coordination problem there.",
            "So here you see the sample path that are computed.",
            "In this case we cannot.",
            "We have no closed.",
            "Form expression now for this conditional probability we have to do some.",
            "We have to this path integral which you have to estimate which we do some some some Monte Carlo sampling we get these these kind of these targets going to that target we get there.",
            "Value for that, for that, for that kernel, and so for all the other pairs.",
            "And that's what we need then to input in the."
        ],
        [
            "In here and then have the end cost and then do the same computation with coordination and then."
        ],
        [
            "These are the trajectories that.",
            "I'm out."
        ],
        [
            "And you see that there is this one actually wants to go somewhere and then kind of go in there because of the mass.",
            "It's completely booked off too.",
            "Alright, so that's what happened.",
            "I'm not sure whether this is optimal, OK."
        ],
        [
            "OK, so.",
            "Computation time in this case, so we can do this with a junction tree up to about 10:10 agents because it's very high state space and we have a number of agents equal to the number of targets, so the state space goes to send to the power N, so we can go up to N. And here we see the alternative we compute with the fields and we get nice polynomial behavior.",
            "So."
        ],
        [
            "What I did is tell you a little bit about a recruit.",
            "The stricter class of control problems that you can formulate in the language of statistical physics and the notion of the path integral is very dominant in that there is the notion of symmetry breaking, showing that for different values of the noise you get, which is always the case with symmetry breaking that you get it simply break, is usually different regimes like water and and ice, and the solutions are qualitatively different.",
            "And here we also get his qualitatively different solutions for different values of the noise very naturally coming out of this free energy kind of concept.",
            "And of course, since we are in the realm of sceptical physics, we can use all the efficient quote unquote methods that we did we know and love like Monte Carlo sampling, belief propagation, etc.",
            "And it's hopefully that these methods can in this way contributes to an efficient computation for these intractable stochastic optimal control.",
            "Problems with these desires I will.",
            "Stop, Michael.",
            "Quick questions.",
            "Do you have to do conditional path subsampling because you've got you have boundary conditions at each end of the menu.",
            "Was something?",
            "Yeah yeah, yeah yeah, yeah yeah, yeah.",
            "Well, you have to.",
            "You have to basically solve these Brownian bridges for four.",
            "If you have this this if you have fixed.",
            "If you start here and you have to go there and you have to compute the cost of debt so that you have to do you have to compute these bandages in that case.",
            "That's in this particular examples.",
            "In other cases, of course, you you may want to compute the whole distribution, so in this case we have fixed discrete targets, but if maybe it can also be that at the end time the cost is just a smooth function, and in that case you actually may want to compute the whole conditional probability for any end position and then integrated out numerically.",
            "1.",
            "Getting assumed to be quite first week because we have first aid, which is very special case and scale it this time.",
            "So how far can utilize this?",
            "Could you have possibly observe state with some noise and wake Thursday?",
            "I think in your example you had two dimensional state space."
        ],
        [
            "So the partial possibilitie.",
            "I haven't really addressed.",
            "I have no answer whether this can be done."
        ],
        [
            "I believe so because.",
            "It is just introducing another expectation value that you have to average over and if like in like in the linear quadratic case, if you have a common if you have an estimation of the value, you can do some common method.",
            "Maybe you can do it in that way regarding the high dimensionality is a good that you pointed out, because in fact.",
            "This can be generalized to an dimensions if in this."
        ],
        [
            "Yep.",
            "You get from this."
        ],
        [
            "This code you have to get rid of this quadratic term in order to get this linear."
        ],
        [
            "Equation and this this will vanish in one dimension.",
            "Always vanished in the high dimension it will vanish if the structure of the noise with the covariance matrix of the noise which is new.",
            "Which is a new.",
            "If this is equal to some scalar times.",
            "R -- 1 where R is the cost of the appearing in the control, so we have in general in Anna mentions we get something we get in the.",
            "We get in the control cost becomes an end dimensional.",
            "Such a quadratic term and the noise becomes a matrix and uij and these two matrices.",
            "Do you have to be related in this way where this is a scalar value?",
            "So clearly in one dimension this is always true, but in high dimension it says intuitively that in those directions where you have noise you should also have control and vice versa.",
            "So if you so that is phrases in this 2 dimensional example that I had here.",
            "You see that we of course constructed in such a clever way."
        ],
        [
            "Anne."
        ],
        [
            "Here you see that the noise is acting the same dimension as the control.",
            "Right, so here you have an area of a 2 dimensional system.",
            "If you want Agent you have X&VT and in this direction where there's no control, there's no noise in the direction where is controlled as nodes, and that is basically that is that condition.",
            "Yeah, yeah, so there is a restriction.",
            "OK, well I'd like to keep this Mr schedule, so let's think about once again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, well good morning everybody and let me first thank the speaker.",
                    "label": 0
                },
                {
                    "sent": "The speaker is not the the organizer.",
                    "label": 0
                },
                {
                    "sent": "Put it wonderful meeting and for inviting me here I'm enjoying it very much.",
                    "label": 0
                },
                {
                    "sent": "What are we talking about?",
                    "label": 0
                },
                {
                    "sent": "This is about stochastic optimal control theory, which is really not my field, but I got into it because I've been working a lot on approximate inference.",
                    "label": 1
                },
                {
                    "sent": "And graphical models.",
                    "label": 0
                },
                {
                    "sent": "And I have the feeling that that's sort of saturating.",
                    "label": 0
                },
                {
                    "sent": "We've seen the bulk of that and was good time to look at something something else, something new, and I was always.",
                    "label": 0
                },
                {
                    "sent": "I was sort of control is one of these areas where I thought there's a lot of complexity.",
                    "label": 0
                },
                {
                    "sent": "Very little approximate inference happening, so this may be an area out to that will be good to see what we can do there something, and I've been looking a lot at.",
                    "label": 0
                },
                {
                    "sent": "At so, if you look at control, you look at the first thing you look at this these development equations and development equations in are also arise in physics and their quality Hamilton Jacobi equations.",
                    "label": 0
                },
                {
                    "sent": "And of course these equations are the classical equations from classical mechanics, and you can write these equations.",
                    "label": 0
                },
                {
                    "sent": "There are sort of related to the Schrodinger equation.",
                    "label": 0
                },
                {
                    "sent": "I was very much intrigued by that link for a long time, particularly because the Schrodinger equation is a linear equation.",
                    "label": 0
                },
                {
                    "sent": "A linear sounds easy, so if you can make something linear, then there's maybe a link, but the Schrodinger equation is a complex valued equation and I tried to explore that link and it goes.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of work in that area actually trying to explore that link under his work by Nelson from the 60s.",
                    "label": 0
                },
                {
                    "sent": "Who made some some stochastic interpretation of some stochastic system which actually exactly mimics quantum mechanics.",
                    "label": 0
                },
                {
                    "sent": "I was very intrigued by that, didn't get anywhere in the end.",
                    "label": 0
                },
                {
                    "sent": "I did was able to explore that link and that's the story I will will tell you about today.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Optimal control is delayed reward task, so you do something now and the reward comes in the future.",
                    "label": 0
                },
                {
                    "sent": "So you make a arm movement.",
                    "label": 0
                },
                {
                    "sent": "And the whole trajectory leads to a final goal, which is banging somebody on the hat, and that's the reward that you get in your future.",
                    "label": 0
                },
                {
                    "sent": "And so we have to take this whole sequence of action and the whole sequence has to be correct in order to appreciate the year to collect the reward.",
                    "label": 0
                },
                {
                    "sent": "And of course.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is complex and is particularly complex if the system and the environment that you have has a lot of noise, because then everything easily gets.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's intractable.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So control is how to act now to optimize future rewards.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In particular, and here you see an example of why this can be difficult, because the optimal control actually depends on the amount of noise in the environment.",
                    "label": 0
                },
                {
                    "sent": "So if I look at this, Spider wants to go to that to the Bank of money on the other side of the Lake.",
                    "label": 0
                },
                {
                    "sent": "You can either cross the bridge or go around the Lake, and if there's no noise in the problem.",
                    "label": 0
                },
                {
                    "sent": "Of course, clearly the shortest way is to just cross the bridge, and there he goes, but if there is noise in the problem, there is a finite probability that he will fall off the bridge.",
                    "label": 0
                },
                {
                    "sent": "And then that's the expected cost of.",
                    "label": 0
                },
                {
                    "sent": "That path becomes very expensive.",
                    "label": 0
                },
                {
                    "sent": "Basically shutting down that path and then the optimal track directory is actually to walk around the.",
                    "label": 0
                },
                {
                    "sent": "Lake, so in other words, optimal control with noise is not just a noisy version of optimal control without noise, it can be actually very different.",
                    "label": 0
                },
                {
                    "sent": "Kind of a solution OK?",
                    "label": 0
                },
                {
                    "sent": "So this computation is intractable in general because you have to solve a number of you have to solve partial differential equation in a very high dimensional state space, and if descript eyes and everything gets, it gets very very slow.",
                    "label": 0
                },
                {
                    "sent": "And if you want to have a tractable approach then you are stuck with a unimodal class of models either being the linear quadratic common type of models or you are in the distant deterministic setting and out of those cannot really treat this kind of complex.",
                    "label": 0
                },
                {
                    "sent": "Problem.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I want to talk about today is to give you a feeling of to just refresh you on control theory.",
                    "label": 1
                },
                {
                    "sent": "Some of you may notice some you may not and then introduces a path to control theory that allows some efficient computation and discuss with you some symmetry breaking effects that you see there, which are, which are way of saying basically that you get as a function of the noise.",
                    "label": 1
                },
                {
                    "sent": "You get different solutions and you will get.",
                    "label": 0
                },
                {
                    "sent": "You will see how in this system these qualitatively different solutions for high and low noise arises symmetry breakings in such system and if time allows.",
                    "label": 0
                },
                {
                    "sent": "I will go to agents, but we'll see how far we go.",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll start with this tree discrete time control in in a noiseless system, so I have a dynamics which is a pointer.",
                    "label": 1
                },
                {
                    "sent": "That's OK, so X D + 1 is a function of XT, and maybe depends explicitly on time, and there is some control variable.",
                    "label": 0
                },
                {
                    "sent": "Utah, which if I want to so, then I consider this system for a finite amount of time in the future an if I specify all the controls UTI this whole vector, then I know the starting position of XI know.",
                    "label": 0
                },
                {
                    "sent": "Of course the whole trajectory of X.",
                    "label": 1
                },
                {
                    "sent": "And then I can consider a cost which is a cost of incur at each time point, which is some function which depends on the state and making the control value.",
                    "label": 1
                },
                {
                    "sent": "And I sum all these cost contribution gives me a final cost and this cost only depends on the initial position of X and on the control vector that I use and optimal control problem is to find the vector you that minimizes this cost.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the solution is is standard and it is you computed by dynamic programming and it goes by introducing the quantity is quality optimal cost ago.",
                    "label": 1
                },
                {
                    "sent": "Suppose that you have solved this cost problem at some intermediate time.",
                    "label": 1
                },
                {
                    "sent": "Small T for some arbitrary location X being so.",
                    "label": 1
                },
                {
                    "sent": "Then you have the minimum of the remaining controls of this of this sum and then if you have this quantity.",
                    "label": 1
                },
                {
                    "sent": "At T is capital T. Of course it's this sum becomes empty and this is so that gives a boundary value and AT is is zero.",
                    "label": 0
                },
                {
                    "sent": "You have the original solution so you have to just get a recursive update for this in the following way that you say that JAT.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one is zero and JAT.",
                    "label": 0
                },
                {
                    "sent": "Is this definition that you take one to him out and you push the minimization.",
                    "label": 0
                },
                {
                    "sent": "You push it through.",
                    "label": 0
                },
                {
                    "sent": "You recover the definition of J at A at the next time point at some arbitrary location and then.",
                    "label": 0
                },
                {
                    "sent": "And you have to minimize this with respect to you've T Now XD plus one is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "X D + 1 is also a function of beauty because you can fill in the dynamics here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this whole right inside becomes a function of Utah only, and so you have to do a pointwise minimization with respect to Utah.",
                    "label": 0
                },
                {
                    "sent": "You have to do that for all time steps, and this way you get get a solution at T0 and once you have this solution, sorry, then once you have this solution, you have the whole sequence of control actions and then you can make a step and get forward and get the get the whole optimal.",
                    "label": 0
                },
                {
                    "sent": "Optimal dynamics for such a system, so this is dynamic programming and it's basically.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you go into the continuous, consider the continuous case so you have a.",
                    "label": 0
                },
                {
                    "sent": "Now we have space, so we take instead of increments one.",
                    "label": 0
                },
                {
                    "sent": "We take increments Delta T and we get this same recursive equation that we had on the previous sheet with this minimization.",
                    "label": 0
                },
                {
                    "sent": "And now we now we do just the Taylor expansion to 1st order in Delta T. We expand J team does Delta TX plus Delta TXT plus Delta T in this way.",
                    "label": 0
                },
                {
                    "sent": "At the time derivative.",
                    "label": 0
                },
                {
                    "sent": "And there is a space derivative, and we insert a Delta.",
                    "label": 0
                },
                {
                    "sent": "X is FFDT and so then we can just collect this whole thing.",
                    "label": 0
                },
                {
                    "sent": "We get continuous time version of this of this dynamic programming.",
                    "label": 1
                },
                {
                    "sent": "And here you see the partial differential equation nature.",
                    "label": 0
                },
                {
                    "sent": "So J is a function of X&T.",
                    "label": 0
                },
                {
                    "sent": "There's some time derivative, some space derivative and there is this funny pointwise minimization that you have to do at each intermediate time.",
                    "label": 0
                },
                {
                    "sent": "Now it going from the discrete time solution discrete time formulation to the continuous time formulation.",
                    "label": 1
                },
                {
                    "sent": "I have separated in the in the in this sum.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Separated out the end cost as a separate term.",
                    "label": 0
                },
                {
                    "sent": "In here we would get a density over costs over the over the winter.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pediat times and so the end cost.",
                    "label": 0
                },
                {
                    "sent": "Now I did not hear Fi and it becomes a boundary value for this.",
                    "label": 0
                },
                {
                    "sent": "For this J at the end time and so here you see a picture of how this looks like.",
                    "label": 0
                },
                {
                    "sent": "So in the future I have a cost J which is equal to five which may be some double well potential.",
                    "label": 0
                },
                {
                    "sent": "Something that I want to be here in the future or here was equal equal cost.",
                    "label": 0
                },
                {
                    "sent": "And now the question is what to do at now at an earlier time?",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Time does earlier and this J is then computed by solving this partial differential equation with boundary condition and it may be giving you this kind of shape and basically to think of the optimal control is that when you are at any of these X locations then the optimal control is a gradient sort of gradients operation on this J.",
                    "label": 0
                },
                {
                    "sent": "So it may be moving to the middle.",
                    "label": 0
                },
                {
                    "sent": "So this term J optimal cost ago is also known as the anticipated potential, so it's a potential that is is what is applies to now instead of to the future.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here you see a simple example.",
                    "label": 0
                },
                {
                    "sent": "1 dimensional system.",
                    "label": 0
                },
                {
                    "sent": "2nd order where we have Newton's law FS M * A an we have masses one and we get to control where we can where we can use this with the spring force and we have an external control.",
                    "label": 1
                },
                {
                    "sent": "So we get this kind of a second order system and now we want to control this thing in such a way that given an initial position and velocity at time zero find to control path which is between minus one and plus one such that at the end.",
                    "label": 1
                },
                {
                    "sent": "Time, the position of the ball is maximum, right?",
                    "label": 0
                },
                {
                    "sent": "This case is extended control that you can formulate.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you write a system as as two for a couple 1st order to 1st order systems.",
                    "label": 0
                },
                {
                    "sent": "So then it's of this form that we just discussed.",
                    "label": 0
                },
                {
                    "sent": "Here is the control variable.",
                    "label": 0
                },
                {
                    "sent": "Here's the states variables and.",
                    "label": 0
                },
                {
                    "sent": "Then we have some costs and then we can take this Hamilton Jacobi equation which is this equation we just filling.",
                    "label": 0
                },
                {
                    "sent": "The thing we get something looks like this.",
                    "label": 0
                },
                {
                    "sent": "We can do actually the minimization and since you is between minus one and one, he gets an absolute value here.",
                    "label": 0
                },
                {
                    "sent": "So we get this equation which we have to solve.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't have to do details, But anyway, this is the solution that you didn't get an if the end time is 2\u03c0 then it is called Bang Bang control that between T is 0 and \u03c0 you have to push a maximally down to get the maximum extension of the spring and then between \u03c0 is between time pie in 2\u03c0 you have to push the force up and here you see that the.",
                    "label": 0
                },
                {
                    "sent": "Trajectory of the position as how it is eczema.",
                    "label": 0
                },
                {
                    "sent": "This maximum value.",
                    "label": 0
                },
                {
                    "sent": "So this is very simple example of such a control case.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now if we have noise we have, we have a winner.",
                    "label": 0
                },
                {
                    "sent": "We can have a Wiener process so we have such a additive term here and basically the equations.",
                    "label": 0
                },
                {
                    "sent": "What now changes.",
                    "label": 0
                },
                {
                    "sent": "So this is, you know, we've seen the lot in the last few days, but this is how Gaussian noise looks.",
                    "label": 0
                },
                {
                    "sent": "We get the cost now becomes an expectation.",
                    "label": 1
                },
                {
                    "sent": "It's not a deterministic quantity, so we can only optimize the expected cost and the expected cost is so, given that you are.",
                    "label": 0
                },
                {
                    "sent": "At position X and you specify the whole control path, then you don't really know where your particle is going to end up because of this noise, and therefore you can do at best an expectation.",
                    "label": 0
                },
                {
                    "sent": "So you compute this expectation value if you can, and then you start changing.",
                    "label": 0
                },
                {
                    "sent": "Conceptually changing these control paths in such a way that you minimize is expected value, so that's that's the task at hand that we now have.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we can start again at the same recursive equation that we had before this this continuous time.",
                    "label": 1
                },
                {
                    "sent": "A dynamical programming update and now we have began to do this Taylor expansion.",
                    "label": 0
                },
                {
                    "sent": "Here are the differences now that we have the expectation values here around here.",
                    "label": 0
                },
                {
                    "sent": "So we now do the Taylor expansion here again, but now we have to expand to 2nd order in the X because of the Vilna noise, of course is the square displacement is of order DT, which is which is the nature of the of the of the Gaussian noise, and so we have to expand the 2nd order in X.",
                    "label": 0
                },
                {
                    "sent": "And 1st order in DT and then DX is just the domain drift of the dynamics and the X squared is just.",
                    "label": 0
                },
                {
                    "sent": "Nudity is a noise in the system.",
                    "label": 1
                },
                {
                    "sent": "So we can just plug this in here and we get basically the same equation with one extra term which reduces to dismissing case if news are equal to 0.",
                    "label": 1
                },
                {
                    "sent": "If there is no noise.",
                    "label": 1
                },
                {
                    "sent": "So do we get this this called stochastic Hamilton Jacobi Bellman equation?",
                    "label": 0
                },
                {
                    "sent": "And again we have to solve this with this boundary condition at the end at the end time.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Everybody happy so far.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Difficulty of solving.",
                    "label": 0
                },
                {
                    "sent": "Dementia.",
                    "label": 0
                },
                {
                    "sent": "So this is a partial differential equation, an IV access the state space, which is, you know high dimensional.",
                    "label": 0
                },
                {
                    "sent": "You have to basically discretize.",
                    "label": 0
                },
                {
                    "sent": "And that's the difficulty in solving this thing.",
                    "label": 0
                },
                {
                    "sent": "Well, the minimum of you is there is you have the minimum of the path, but this is a pointwise minimum right at each at each time point.",
                    "label": 0
                },
                {
                    "sent": "So it is indeed it may be.",
                    "label": 0
                },
                {
                    "sent": "This is like, you know, if you have a 10 dimensional problem then you have a 10 dimensional.",
                    "label": 0
                },
                {
                    "sent": "Can numbers to minimize.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can do some.",
                    "label": 0
                },
                {
                    "sent": "Eliminate it then.",
                    "label": 0
                },
                {
                    "sent": "Huawei.",
                    "label": 0
                },
                {
                    "sent": "Well, this depends.",
                    "label": 0
                },
                {
                    "sent": "I was in the in the in the special case I consider.",
                    "label": 0
                },
                {
                    "sent": "I can eliminate it, but in general it may not be not be easy to actually eliminate it.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "General this is this.",
                    "label": 0
                },
                {
                    "sent": "You get stuck with this and you cannot really do much practical things with it and therefore I will now look at a special case in which the F, the dynamics of the system is additive in the control variable.",
                    "label": 0
                },
                {
                    "sent": "And where the costs of the is separates as a term which depends on is state dependent, arbitrary and is also additive, quadratically in the cost in the in the control.",
                    "label": 0
                },
                {
                    "sent": "So these.",
                    "label": 0
                },
                {
                    "sent": "So this this term, this dynamics becomes this.",
                    "label": 0
                },
                {
                    "sent": "There's a.",
                    "label": 0
                },
                {
                    "sent": "There's a linear terming you here, and here is a quadratic term U, and for the rest is arbitrary, so we have an arbitrary dynamical system which has can have an arbitrary state dependent cost.",
                    "label": 0
                },
                {
                    "sent": "But the control that we have is sort of very simple.",
                    "label": 0
                },
                {
                    "sent": "We can only act linearly on the on the dynamics, and we get a quadratic cost.",
                    "label": 0
                },
                {
                    "sent": "So it's like a simple control over arbitrary complex system.",
                    "label": 0
                },
                {
                    "sent": "So then this equation becomes here, the R becomes you squared plus B&F.",
                    "label": 0
                },
                {
                    "sent": "Sorry, does F. Plus you should be FU here.",
                    "label": 0
                },
                {
                    "sent": "This is a mistake.",
                    "label": 0
                },
                {
                    "sent": "FU and so then we have linear quadratic.",
                    "label": 0
                },
                {
                    "sent": "Here we can minimize explicitly and then we have a second we get U is minus the gradient of J and we can plug it back in and so we now have a quadratic term in here.",
                    "label": 0
                },
                {
                    "sent": "So this is then a partial differential equation which is a nonlinear partial differential equation.",
                    "label": 0
                },
                {
                    "sent": "Which we have to solve again, which is boundary values at the end time and once we have the solution JXT we have to take his gradient and it gives us our control signal at the point XT.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now this equation can be solved and this is the link to the that I said before to the quantum mechanics because this.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This this this.",
                    "label": 0
                },
                {
                    "sent": "This is also known in physics as the Hamilton Jacobi equation, and it is very closely related to the Schrodinger equation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the link is through a log transform, which was also Mumford was flashing that at some point in one of his sheets.",
                    "label": 0
                },
                {
                    "sent": "So there is a link actually between this work and what month it was talking about.",
                    "label": 0
                },
                {
                    "sent": "So if you do that, you get this.",
                    "label": 0
                },
                {
                    "sent": "You make this change of variables.",
                    "label": 0
                },
                {
                    "sent": "You get that this equation becomes linear.",
                    "label": 0
                },
                {
                    "sent": "Inside as a partial differential equation with the end condition now becomes just simply this and so we can write this as an operator H acting on PSI, and so this is again a partial difference equation.",
                    "label": 0
                },
                {
                    "sent": "Which of the soul was an end condition, etc, and so that's that's OK. Now we define a new process which is a stochastic which is a diffusion process which is.",
                    "label": 0
                },
                {
                    "sent": "Sort of a joint to this process, so there is a - here to change and the age is replaced by HHH dagger, which is the mission conjugate of H. So if you do that, then it basically means that this term becomes a little bit different, and but the other two terms stay the same.",
                    "label": 0
                },
                {
                    "sent": "And the trick is that if you define this process of this process, row is a density which runs in positive direction, positive time direction.",
                    "label": 0
                },
                {
                    "sent": "So it starts at T is the small T and it runs forward in time where this process was starting.",
                    "label": 0
                },
                {
                    "sent": "At the end time and running backward in time, and the construction is such that the the product of ro times sigh is independent of time.",
                    "label": 0
                },
                {
                    "sent": "So in other words.",
                    "label": 0
                },
                {
                    "sent": "So if I take PSI at some intermediate time, I've computed it backwards.",
                    "label": 0
                },
                {
                    "sent": "From the capital T and I get some solution and I multiply it with row which starts at the initial time and I run it forward to this same intermediate time tour.",
                    "label": 0
                },
                {
                    "sent": "Then this quantity of our integrated over overall space.",
                    "label": 0
                },
                {
                    "sent": "Then this quantity becomes independent of the choice of the intermediate time.",
                    "label": 0
                },
                {
                    "sent": "And the reason is very simple, because if you take the time derivative of this whole quantity, you get time derivative first plus times a second plus the time plus the first time through the 2nd, and you get his H&H bar and is minus and then basically it becomes time independent, so by construction is time independent.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that means that I can evaluate this quantity at the initial time or end at the final time and should give the same result at initial time.",
                    "label": 0
                },
                {
                    "sent": "This row is a Delta.",
                    "label": 0
                },
                {
                    "sent": "At some location, so Drose initialized at X.",
                    "label": 0
                },
                {
                    "sent": "So we have a Delta.",
                    "label": 0
                },
                {
                    "sent": "Here it just becomes shy XD.",
                    "label": 0
                },
                {
                    "sent": "If I initialize that initial.",
                    "label": 0
                },
                {
                    "sent": "If I computers initial time.",
                    "label": 0
                },
                {
                    "sent": "So at initial time gets ixta at the end time I get row at the end time times this one at the end time, which is just the boundary condition.",
                    "label": 0
                },
                {
                    "sent": "So I can equate these two things and I will get this surrogates ixta.",
                    "label": 0
                },
                {
                    "sent": "Is this row evaluated at the end time Times E to the end condition?",
                    "label": 0
                },
                {
                    "sent": "So in other words I have here the explicit solution of my optimal control problem.",
                    "label": 0
                },
                {
                    "sent": "Because once have sigh, I can take the log transform again J once, if Ji take the derivative, I get my optimal control and it solved.",
                    "label": 0
                },
                {
                    "sent": "Also have the optimal control solution for this problem.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at the example.",
                    "label": 0
                },
                {
                    "sent": "Here we have a simple dynamics where F is zero.",
                    "label": 0
                },
                {
                    "sent": "We just have to control and we have the noise.",
                    "label": 0
                },
                {
                    "sent": "Ann is 1 dimensional.",
                    "label": 0
                },
                {
                    "sent": "X&X is running in this direction.",
                    "label": 0
                },
                {
                    "sent": "And time is running in this direction.",
                    "label": 0
                },
                {
                    "sent": "And the aim is to have this stochastic process end up at the origin, so even end cost, which is 5 which is X squared at the end time.",
                    "label": 0
                },
                {
                    "sent": "So that's this term and then we have a intermediate path cost which is given by this double slit where the cost everywhere is at time is 1 V. At times one is infinite everywhere except for these 30 two holes where there is no cost.",
                    "label": 0
                },
                {
                    "sent": "So indeed so if you want to get a trajectory then the minimal cost.",
                    "label": 0
                },
                {
                    "sent": "Trees are ready to move through this one or through the other one, and so how you compute it well in this case you can just compute this thing.",
                    "label": 0
                },
                {
                    "sent": "You can do this diffusion process.",
                    "label": 0
                },
                {
                    "sent": "What we have to do this to compute is the Fusion process, which I will talk.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in a minute, so we have to solve this forward process and get a solution and.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plug it in there and that's what I did and you can do it analytically.",
                    "label": 0
                },
                {
                    "sent": "And for instance the J that comes out as a function of X for time 0 is this blue line.",
                    "label": 0
                },
                {
                    "sent": "And it shows basically two things.",
                    "label": 0
                },
                {
                    "sent": "One is that if you are in one of these valleys, it pushes you by the gradient to these minimal points, which are located at minus sort of minus five here and plus six which is related to the fact that these holes are the ones these holes centered around 7:00, and this whole centered around minus five, and the other thing is that you see is that the the height of this value is how?",
                    "label": 0
                },
                {
                    "sent": "Is higher than that one because Rimmer, J is should be interpreted as the expected cost to go, so it is the expected cost that you have from any point to reach, reach the goal and the expected cost is higher here than there.",
                    "label": 0
                },
                {
                    "sent": "'cause if you're in front of this whole then you have to make a larger path to the origin story in smaller path through the origin.",
                    "label": 0
                },
                {
                    "sent": "And if you are here and so the expected steering cost that you have in this part is higher than the expected stealing cost in this part and that's why this one is higher than that one.",
                    "label": 0
                },
                {
                    "sent": "So that's why you get these.",
                    "label": 0
                },
                {
                    "sent": "These things so OK and so then if you have this solution you can do it for all intermediate times and you can then steer you taking the gradients of this J and those are these two trajectories are two examples of those kind of optimal trajectory that you get under this optimal controller policy.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I.",
                    "label": 0
                },
                {
                    "sent": "To go to this to look at this a little bit further.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we just look at the at this part of the problem between zero and one.",
                    "label": 0
                },
                {
                    "sent": "So basically you can make these slits arbitrary small.",
                    "label": 0
                },
                {
                    "sent": "So basically two targets you I go this way or that way.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I've drawn here.",
                    "label": 0
                },
                {
                    "sent": "And if you go to that limit.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then you can actually solve these J analytically and it becomes.",
                    "label": 0
                },
                {
                    "sent": "This function is just exclude formed expression.",
                    "label": 0
                },
                {
                    "sent": "You take what capital T is now the time to reach.",
                    "label": 1
                },
                {
                    "sent": "It's not the end time, but it's the time to reach it's time to go.",
                    "label": 0
                },
                {
                    "sent": "So it's capital T minus multi in the earlier notation, and if you take this out you see that here between the brackets you have a function which depends only.",
                    "label": 0
                },
                {
                    "sent": "It depends on X and on the product of New Times T News the noise so depends on the product of the noise and the time to go.",
                    "label": 0
                },
                {
                    "sent": "And if you look at different values of this product as a function of X then you see that you get the symmetry breaking in this system where for high values.",
                    "label": 0
                },
                {
                    "sent": "Of tee times new, you have a smooth unimodal shape and for low values of T times new you get this breaking where you have these two these two minima and it means that.",
                    "label": 0
                },
                {
                    "sent": "That if you are far away in time from the targets from any other two targets, so.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you are sort of here and then you know the optimal control says that you have to steer towards the middle.",
                    "label": 0
                },
                {
                    "sent": "And if you get a certain beyond a certain point, clearly stealing towards the middle is not good at all times, because then you will miss the target altogether.",
                    "label": 0
                },
                {
                    "sent": "So at some point you will have to make a choice, and this choice is given by this symmetry breaking affect where the wedding.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "J. Ben starts to bend over, so at this point you're forced to make a choice.",
                    "label": 0
                },
                {
                    "sent": "Actually, at this point it is 1 where your steering to idle their goals, because otherwise you're going to miss that many of the goals.",
                    "label": 0
                },
                {
                    "sent": "And so while you can ask yourself why is steering to the middle is a good idea if you.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still far away, well, it's very easy in a sense, because if you're far away in time, if you do nothing, you could go straight ahead.",
                    "label": 0
                },
                {
                    "sent": "Then just by noise itself.",
                    "label": 0
                },
                {
                    "sent": "By diffusion itself, you will reach any of these goals.",
                    "label": 0
                },
                {
                    "sent": "You don't have to do anything which is going to drift to either of these goals, so why waste energy steering where you can get it for free?",
                    "label": 0
                },
                {
                    "sent": "But of course that policy fails as soon as you're here, because then drift by itself will not exterior to that.",
                    "label": 0
                },
                {
                    "sent": "So then you have to actually steer, so that's why.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What's happening?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I wasn't quite clear with the bro you you solve it once and for all you have to resolve it at every time.",
                    "label": 0
                },
                {
                    "sent": "So here I am so.",
                    "label": 0
                },
                {
                    "sent": "Here I am.",
                    "label": 0
                },
                {
                    "sent": "Well, you have to solve row condition on the on location where you are and since the location where you are.",
                    "label": 0
                },
                {
                    "sent": "At the new timestep is unpredictable, basically because of the noise you have to solve it every time.",
                    "label": 0
                },
                {
                    "sent": "Again again, yeah, yeah, yeah, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so here you see these trajectory under optimal control.",
                    "label": 0
                },
                {
                    "sent": "So here in this case this is a stochastic optimal control, where here is the X trajectory as a function of time.",
                    "label": 0
                },
                {
                    "sent": "And here's the control as a function of time.",
                    "label": 0
                },
                {
                    "sent": "An here on the right we see the deterministic where we basically have say, well we take the noiseless optimal control pace and you see here for the noise is optimal control case if X is positive, then it says well go to target one so it will steer upwards.",
                    "label": 0
                },
                {
                    "sent": "If X is negative, it goes to target minus one, etc.",
                    "label": 0
                },
                {
                    "sent": "So doing all these kind of control actions which are basically not needed because you're still drifting along way and then after you reach time is 1.",
                    "label": 0
                },
                {
                    "sent": "You're stealing to one of these.",
                    "label": 0
                },
                {
                    "sent": "One of these targets, whereas here in the stochastic case you see that the optimal control is basically zero.",
                    "label": 0
                },
                {
                    "sent": "Saying do nothing and then at some point it actually has to do this.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so does the Fusion process which was solved which is given by this for Planck equation.",
                    "label": 0
                },
                {
                    "sent": "With it.",
                    "label": 0
                },
                {
                    "sent": "Let's look at a little more in detail.",
                    "label": 0
                },
                {
                    "sent": "We have a drift term which recognizes just F is the mean.",
                    "label": 0
                },
                {
                    "sent": "It's mean drift and we have a diffusion term which is just a standard diffusion term and then we have this funny term which is involves VV.",
                    "label": 0
                },
                {
                    "sent": "Is the cost in the path.",
                    "label": 0
                },
                {
                    "sent": "So remind your V will see we had written here.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The cost is written as a vetren plus, so this is the cost that you incur.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At a certain location.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "So this actually these two terms, they conserve probability, so they if you take the integral overall X of row and you look at the time variation of it, then this one gives a time.",
                    "label": 0
                },
                {
                    "sent": "This one gives 0 and this will also give 0.",
                    "label": 0
                },
                {
                    "sent": "But this one actually kills probability at a certain rate.",
                    "label": 0
                },
                {
                    "sent": "So the way that we can simulate that is to say, OK, well, we just have an ordinary diffusion process which is given by these two terms and then in parallel we have a killing rate.",
                    "label": 0
                },
                {
                    "sent": "So we do this with probability 1 minus VDT over new and with probability DT over new.",
                    "label": 1
                },
                {
                    "sent": "We take the particle out of the simulation, it's gone.",
                    "label": 0
                },
                {
                    "sent": "And that is apparently the way to simulate this forward process in order to get a diffusion right, which we need.",
                    "label": 0
                },
                {
                    "sent": "So then we get this diffusion kernel.",
                    "label": 0
                },
                {
                    "sent": "We have a stochastic simulation of diffusion kernel and that's what we need to compute the optimal.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright to put it in in here?",
                    "label": 0
                },
                {
                    "sent": "So this is the Fusion.",
                    "label": 0
                },
                {
                    "sent": "You can write it as a path integral because you can basically say, well, this diffusion is a is a walk from X to Y and that war can be in a finite amount of time.",
                    "label": 1
                },
                {
                    "sent": "Capital T minus multi and that that work can be subdivided in a number of small intervals and then basically taking the limit of the interval size to zero you get that.",
                    "label": 0
                },
                {
                    "sent": "Well, you get this this this conditional probability becomes a product of terms integrated over all the intermediate values and that the product of terms can be great in the exponent as a sum over terms which then converts into an interval as being this path.",
                    "label": 0
                },
                {
                    "sent": "And this path costs just penalizes the deviation of the derivative of X from the mean drift, and there's a there's a potential.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dental term so in other words, just to put all the formulas on sheets, we have an optimal control solution which is of this form where weekend our oh we can write it as a passive role and we can take this term also into the path integral where S is not the past contribution plus the end term.",
                    "label": 0
                },
                {
                    "sent": "So we can write this whole thing as a free energy because Jay is mines local size, so we just get exactly free energy contribution where you normally in the free energy you have some over exponent of the energy.",
                    "label": 1
                },
                {
                    "sent": "Here we get some of the exponent of an action so and also divided by new which is a place a role for temperature.",
                    "label": 0
                },
                {
                    "sent": "And so if this is the partition sum then the corresponding probability distribution is this quantity, right?",
                    "label": 1
                },
                {
                    "sent": "So this is the normalizer and the probability distribution is just the exponent of each of the path that you can think of, conditioned on the current position where you are.",
                    "label": 0
                },
                {
                    "sent": "So you are here, you can consider very many paths, each of them has a certain cost South which takes into account the path contribution at the end cost and then you have to then this is the probability of all these paths.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To just put together, give a little bit well, let me skip this I think.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Mobility is, I mean, you're not using that to make decisions or anything, but it's just.",
                    "label": 0
                },
                {
                    "sent": "It's just an analogy, is it?",
                    "label": 0
                },
                {
                    "sent": "That probability will arise here once I.",
                    "label": 0
                },
                {
                    "sent": "Let me see.",
                    "label": 0
                },
                {
                    "sent": "So this is an example here.",
                    "label": 0
                },
                {
                    "sent": "You'll see you'll see the rise.",
                    "label": 0
                },
                {
                    "sent": "So now we have such a.",
                    "label": 0
                },
                {
                    "sent": "Last thing I want to talk about is how you can actually use this to solve efficiently some very intractable problem.",
                    "label": 0
                },
                {
                    "sent": "And this is the case of coordination of a number of agents.",
                    "label": 1
                },
                {
                    "sent": "So now we have not one of these processes, but we have any of them which are agents and they each have a independent dynamics which is given by F Alpha and they have independent controls, which are you Alpha and have independent noise which is Scialfa, but their actions should be coordinated in the sense that they have to jointly solve some task.",
                    "label": 0
                },
                {
                    "sent": "Which is which is measured at a future time.",
                    "label": 1
                },
                {
                    "sent": "So for instance they have to extinguish a number of fires and I have to run around to all run to the total tool.",
                    "label": 0
                },
                {
                    "sent": "The same file that I exchanged only one of these fires, but I have to sort of coordinate attached at the end time there is an equal distribution of agents over over fires, so we have an end cost which depends on the end position of all the agents, and we assume that these agents positions are only restricted to these and any of these fire locations.",
                    "label": 0
                },
                {
                    "sent": "So each of the agents end position is energies.",
                    "label": 0
                },
                {
                    "sent": "Cajun an we have infinite costs for any of the other end configurations.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we get exactly the same formula.",
                    "label": 0
                },
                {
                    "sent": "We get that the disposition some is now with some of our integral of all the agent positions.",
                    "label": 0
                },
                {
                    "sent": "The dynamics to go from X to Y factorizes.",
                    "label": 0
                },
                {
                    "sent": "This is the forward diffusion of each of these agents to move from X A2.",
                    "label": 0
                },
                {
                    "sent": "YL find these are completely independent, and so you just get a product of these of these independent agent dynamics, and then the whole thing is penalized by North cost, where all these ants costs are coupled through this FI.",
                    "label": 0
                },
                {
                    "sent": "And so we can write this as a.",
                    "label": 0
                },
                {
                    "sent": "Since the end costs are restricted to these low discrete locations, we can, which are the fires, we can restrict this.",
                    "label": 0
                },
                {
                    "sent": "We can write some integral as a sum and we get here as sort of an energy expression where we put his role in the exponent and so we have we defined this P of Y as this probability distribution the same way we did before then.",
                    "label": 0
                },
                {
                    "sent": "Then the optimal control which is the gradient of J, which is the gradient of the log of.",
                    "label": 0
                },
                {
                    "sent": "Sigh, it becomes this kind of an expectation value that we have to now compute, so we have to take a gradient of row row work to compute the dynamics for each of the agents.",
                    "label": 0
                },
                {
                    "sent": "Take the gradient with respect to the initial position of that agent and that gives us some formula and that is OK. We can do that, but then we have to take the expectation value with respect to this probability distribution, which is really a probability distribution over all the.",
                    "label": 0
                },
                {
                    "sent": "Ends positions of all the agents at the end time, right?",
                    "label": 0
                },
                {
                    "sent": "And so we now see that this coordination task has become a graphical model inference task because if we think of.",
                    "label": 0
                },
                {
                    "sent": "Of this probability distribution as a graphical model, which basically is then.",
                    "label": 1
                },
                {
                    "sent": "Then, taking computing this expectation value is just depends on the single variable.",
                    "label": 0
                },
                {
                    "sent": "So it's like computing a marginal for Alpha in high dimensional states, state vector Y going from one to N. So which is a marginal kind of computation?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the pseudocode to solve this is that you compute the cost and the logarithm for each agent to move to each target.",
                    "label": 1
                },
                {
                    "sent": "So each agent is Agent, Alpha is the location X Alpha where he currently is.",
                    "label": 0
                },
                {
                    "sent": "You compute for each of the target location what the cost is in the absence of the of the control.",
                    "label": 0
                },
                {
                    "sent": "And of course this can be, but this factorizes basically the problem of all the agents.",
                    "label": 0
                },
                {
                    "sent": "So we have to do it for each agent separately can still be difficult, but you can do a pass in.",
                    "label": 1
                },
                {
                    "sent": "The goal can be estimated using Monte Carlo sampling or something, or maybe variational approximation, and then once we have these terms, we have to do we have to do a graphical model inference in the couples.",
                    "label": 0
                },
                {
                    "sent": "All these other.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To basically put it in here and then do this graphical model inference.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's in that case, and you can do that, maybe exact if the graphical model is small and you can use BP or mean field.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proximation, so in a simple example where the state space is 1 dimensional and we have N agents and we have no dynamics, then this conditional distribution is just a Gaussian and if the end cost just says well I want all the all the fires that have the same number of agents then then we get this kind of a quadratic form and then we can compute this optimal control and the optimal control is now given by the expectation value of Y at the graphical model.",
                    "label": 1
                },
                {
                    "sent": "Minus the current position, so this thing is the Now the intractable quantity that we have to compute.",
                    "label": 1
                },
                {
                    "sent": "It is the expected value of of at a future for Agent Alpha in the context of what all the other people are doing.",
                    "label": 0
                },
                {
                    "sent": "So it's a summary of all this uncertainty of all that with all the other edges are doing.",
                    "label": 0
                },
                {
                    "sent": "You see it here.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In simulation.",
                    "label": 0
                },
                {
                    "sent": "So here's the beginning of time.",
                    "label": 0
                },
                {
                    "sent": "Here is the end of time.",
                    "label": 0
                },
                {
                    "sent": "Here is 5 fires, and here is a bunch of agents and they start at some locations and use what I've plotted.",
                    "label": 0
                },
                {
                    "sent": "Here is the expected target location of each of these agents as a function of time.",
                    "label": 0
                },
                {
                    "sent": "So this blue agent, for instance, thinks initially he should go to the target located at 0, and then at some point something happens because the other agents are doing something and he said, well, now it's better actually that I go to.",
                    "label": 0
                },
                {
                    "sent": "Target at minus two and then once he.",
                    "label": 0
                },
                {
                    "sent": "So once you have your your expected target location.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In which is this one?",
                    "label": 0
                },
                {
                    "sent": "Which is the hard part of the computation, because it takes all the other agents in two accounts, one actually moving there is very easy.",
                    "label": 0
                },
                {
                    "sent": "Optimally because you just just do this very simple rule which is moving just in a linear way to that particular target.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the actual trajectories of X are then given in this way.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course, computing this such expectation value, you can do it either is somehow Ristic and what you can see.",
                    "label": 0
                },
                {
                    "sent": "Here we compare some midfield control and we compute this expectation of women fields, or with belief propagation, and basically comparing it to the exact value.",
                    "label": 0
                },
                {
                    "sent": "Get very very similar values.",
                    "label": 0
                },
                {
                    "sent": "Is the cost difference and just to see that this problem is actually not trivial, we've compared it with the greedy control where each agent is the same.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm just going to the nearest nearest fire and.",
                    "label": 0
                },
                {
                    "sent": "Forget about everybody else and you see that that indicates that there is hardly any noise that is not such a bad policy.",
                    "label": 0
                },
                {
                    "sent": "But if the system becomes noisy, debt grading policy is actually very bad.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You see some computation times as a function of the number of agents comparing to exactly this is the line exact on the exponent on the log scale, and you see these these nice lines or the computation time for this mean field, so you can do efficient inference.",
                    "label": 1
                },
                {
                    "sent": "OK. With a graphical model I didn't quite follow what the components the graph model identifiers and yet lost connectivity.",
                    "label": 0
                },
                {
                    "sent": "So OK so.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The connectivity in this case is if this is MJ, is the desired number of a of agents at at fire J and so these are numbers that are given and and J.",
                    "label": 0
                },
                {
                    "sent": "This is the basically the number of agents that end up at 5 J.",
                    "label": 1
                },
                {
                    "sent": "If you have this vector, why write the number to go there?",
                    "label": 0
                },
                {
                    "sent": "And so this term becomes quadratic.",
                    "label": 0
                },
                {
                    "sent": "And why so?",
                    "label": 0
                },
                {
                    "sent": "This gives us sort of pairwise interaction in the graphical model.",
                    "label": 0
                },
                {
                    "sent": "And then the and then the this term, which is the is also coming into the graphical model, right?",
                    "label": 0
                },
                {
                    "sent": "Because it is, this term is here, right?",
                    "label": 0
                },
                {
                    "sent": "This is all integrated.",
                    "label": 0
                },
                {
                    "sent": "This is a graphical model and this dream is also in there.",
                    "label": 0
                },
                {
                    "sent": "So in this case this term is of course only linear in any position, so it doesn't affect the graphical model structure.",
                    "label": 0
                },
                {
                    "sent": "Right, so and clearly, the success of such a BP or mean field approach depends very much on the density of such a connectivity graph.",
                    "label": 0
                },
                {
                    "sent": "Unfit no, it's yeah this quadratic, but sorry it's pointwise so it's only it's there's no term Y Alpha Y beta, so it's a it's a single single node.",
                    "label": 0
                },
                {
                    "sent": "Service, yeah single it's a single variable.",
                    "label": 0
                },
                {
                    "sent": "There's no it doesn't compute to it doesn't.",
                    "label": 0
                },
                {
                    "sent": "There's no link is just a single variable.",
                    "label": 0
                },
                {
                    "sent": "Know this.",
                    "label": 0
                },
                {
                    "sent": "These variables are here restricted to to a discrete set of endpoints, so in this case each why Alpha can have the values minus two to two?",
                    "label": 0
                },
                {
                    "sent": "And in this average, why this is now a completely deterministic thing?",
                    "label": 0
                },
                {
                    "sent": "I mean that the noise is completely gone from the left picture.",
                    "label": 0
                },
                {
                    "sent": "No no no no no no no no this so the average.",
                    "label": 0
                },
                {
                    "sent": "So we have here so we have here a probability distribution over Y, where Y is a vector for each each of the agents, and why Alpha has values.",
                    "label": 0
                },
                {
                    "sent": "Minus two to two.",
                    "label": 1
                },
                {
                    "sent": "In this case, the one dimensional locations of the of the fire, and so we have an in-depth graphical model which consists of two ingredients.",
                    "label": 0
                },
                {
                    "sent": "One is the pointwise terms that come from the from the free dynamics of each of these agents, and the other term comes from the interaction that they should minimize something jointly at the end time these two ingredients are in this graphical model and then have to do a graphical model inference an in this particular simple example, for instance, is just as an example.",
                    "label": 1
                },
                {
                    "sent": "You have to then compute for the optimal control the expected value of Y, Alpha and its expected value.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see that they, so here the expected value for this green one is here.",
                    "label": 0
                },
                {
                    "sent": "And then maybe it's complete.",
                    "label": 0
                },
                {
                    "sent": "This is computed in the context of all the.",
                    "label": 0
                },
                {
                    "sent": "All the others do.",
                    "label": 0
                },
                {
                    "sent": "And then this.",
                    "label": 0
                },
                {
                    "sent": "So let me just.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's another example here.",
                    "label": 0
                },
                {
                    "sent": "See a little bit more complex example where we have a number of agents in 2 dimensional space and where the dynamics of each of the agents is a second order.",
                    "label": 0
                },
                {
                    "sent": "This is the 2nd order system.",
                    "label": 0
                },
                {
                    "sent": "Let me see.",
                    "label": 0
                },
                {
                    "sent": "Yeah well there is some.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we have the position.",
                    "label": 0
                },
                {
                    "sent": "The change in the position is given by the velocity and the change in the political philosophy is given by the control variable and there's some noise there.",
                    "label": 0
                },
                {
                    "sent": "So we have some initial positions for these for these cars that can.",
                    "label": 0
                },
                {
                    "sent": "So you can think of this cars with certain mass and against ear and they have to start a 10 car.",
                    "label": 0
                },
                {
                    "sent": "Start here and they have to end up at East End locations.",
                    "label": 0
                },
                {
                    "sent": "But there is only one car end up at each of these crosses so they should not go additional.",
                    "label": 0
                },
                {
                    "sent": "Go to different ones so it's a little bit of coordination problem there.",
                    "label": 0
                },
                {
                    "sent": "So here you see the sample path that are computed.",
                    "label": 0
                },
                {
                    "sent": "In this case we cannot.",
                    "label": 0
                },
                {
                    "sent": "We have no closed.",
                    "label": 0
                },
                {
                    "sent": "Form expression now for this conditional probability we have to do some.",
                    "label": 0
                },
                {
                    "sent": "We have to this path integral which you have to estimate which we do some some some Monte Carlo sampling we get these these kind of these targets going to that target we get there.",
                    "label": 0
                },
                {
                    "sent": "Value for that, for that, for that kernel, and so for all the other pairs.",
                    "label": 0
                },
                {
                    "sent": "And that's what we need then to input in the.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In here and then have the end cost and then do the same computation with coordination and then.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are the trajectories that.",
                    "label": 0
                },
                {
                    "sent": "I'm out.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you see that there is this one actually wants to go somewhere and then kind of go in there because of the mass.",
                    "label": 0
                },
                {
                    "sent": "It's completely booked off too.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's what happened.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether this is optimal, OK.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Computation time in this case, so we can do this with a junction tree up to about 10:10 agents because it's very high state space and we have a number of agents equal to the number of targets, so the state space goes to send to the power N, so we can go up to N. And here we see the alternative we compute with the fields and we get nice polynomial behavior.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What I did is tell you a little bit about a recruit.",
                    "label": 0
                },
                {
                    "sent": "The stricter class of control problems that you can formulate in the language of statistical physics and the notion of the path integral is very dominant in that there is the notion of symmetry breaking, showing that for different values of the noise you get, which is always the case with symmetry breaking that you get it simply break, is usually different regimes like water and and ice, and the solutions are qualitatively different.",
                    "label": 1
                },
                {
                    "sent": "And here we also get his qualitatively different solutions for different values of the noise very naturally coming out of this free energy kind of concept.",
                    "label": 0
                },
                {
                    "sent": "And of course, since we are in the realm of sceptical physics, we can use all the efficient quote unquote methods that we did we know and love like Monte Carlo sampling, belief propagation, etc.",
                    "label": 1
                },
                {
                    "sent": "And it's hopefully that these methods can in this way contributes to an efficient computation for these intractable stochastic optimal control.",
                    "label": 0
                },
                {
                    "sent": "Problems with these desires I will.",
                    "label": 0
                },
                {
                    "sent": "Stop, Michael.",
                    "label": 0
                },
                {
                    "sent": "Quick questions.",
                    "label": 0
                },
                {
                    "sent": "Do you have to do conditional path subsampling because you've got you have boundary conditions at each end of the menu.",
                    "label": 0
                },
                {
                    "sent": "Was something?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, yeah yeah, yeah yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, you have to.",
                    "label": 0
                },
                {
                    "sent": "You have to basically solve these Brownian bridges for four.",
                    "label": 0
                },
                {
                    "sent": "If you have this this if you have fixed.",
                    "label": 0
                },
                {
                    "sent": "If you start here and you have to go there and you have to compute the cost of debt so that you have to do you have to compute these bandages in that case.",
                    "label": 0
                },
                {
                    "sent": "That's in this particular examples.",
                    "label": 0
                },
                {
                    "sent": "In other cases, of course, you you may want to compute the whole distribution, so in this case we have fixed discrete targets, but if maybe it can also be that at the end time the cost is just a smooth function, and in that case you actually may want to compute the whole conditional probability for any end position and then integrated out numerically.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "Getting assumed to be quite first week because we have first aid, which is very special case and scale it this time.",
                    "label": 0
                },
                {
                    "sent": "So how far can utilize this?",
                    "label": 0
                },
                {
                    "sent": "Could you have possibly observe state with some noise and wake Thursday?",
                    "label": 0
                },
                {
                    "sent": "I think in your example you had two dimensional state space.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the partial possibilitie.",
                    "label": 0
                },
                {
                    "sent": "I haven't really addressed.",
                    "label": 0
                },
                {
                    "sent": "I have no answer whether this can be done.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I believe so because.",
                    "label": 0
                },
                {
                    "sent": "It is just introducing another expectation value that you have to average over and if like in like in the linear quadratic case, if you have a common if you have an estimation of the value, you can do some common method.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can do it in that way regarding the high dimensionality is a good that you pointed out, because in fact.",
                    "label": 0
                },
                {
                    "sent": "This can be generalized to an dimensions if in this.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "You get from this.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This code you have to get rid of this quadratic term in order to get this linear.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equation and this this will vanish in one dimension.",
                    "label": 0
                },
                {
                    "sent": "Always vanished in the high dimension it will vanish if the structure of the noise with the covariance matrix of the noise which is new.",
                    "label": 0
                },
                {
                    "sent": "Which is a new.",
                    "label": 0
                },
                {
                    "sent": "If this is equal to some scalar times.",
                    "label": 0
                },
                {
                    "sent": "R -- 1 where R is the cost of the appearing in the control, so we have in general in Anna mentions we get something we get in the.",
                    "label": 0
                },
                {
                    "sent": "We get in the control cost becomes an end dimensional.",
                    "label": 0
                },
                {
                    "sent": "Such a quadratic term and the noise becomes a matrix and uij and these two matrices.",
                    "label": 0
                },
                {
                    "sent": "Do you have to be related in this way where this is a scalar value?",
                    "label": 0
                },
                {
                    "sent": "So clearly in one dimension this is always true, but in high dimension it says intuitively that in those directions where you have noise you should also have control and vice versa.",
                    "label": 0
                },
                {
                    "sent": "So if you so that is phrases in this 2 dimensional example that I had here.",
                    "label": 0
                },
                {
                    "sent": "You see that we of course constructed in such a clever way.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you see that the noise is acting the same dimension as the control.",
                    "label": 0
                },
                {
                    "sent": "Right, so here you have an area of a 2 dimensional system.",
                    "label": 0
                },
                {
                    "sent": "If you want Agent you have X&VT and in this direction where there's no control, there's no noise in the direction where is controlled as nodes, and that is basically that is that condition.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, so there is a restriction.",
                    "label": 0
                },
                {
                    "sent": "OK, well I'd like to keep this Mr schedule, so let's think about once again.",
                    "label": 0
                }
            ]
        }
    }
}