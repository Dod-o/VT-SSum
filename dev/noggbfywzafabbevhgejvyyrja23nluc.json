{
    "id": "noggbfywzafabbevhgejvyyrja23nluc",
    "title": "Diagnosing Error in Object Detectors",
    "info": {
        "author": [
            "Derek Hoiem, University of Illinois at Urbana-Champaign"
        ],
        "chairman": [
            "Antonio Torralba, Center for Future Civic Media, Massachusetts Institute of Technology, MIT",
            "Stefan Carlsson, KTH - Royal Institute of Technology"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/eccv2012_hoiem_detectors/",
    "segmentation": [
        [
            "So."
        ],
        [
            "Object detection is actually best thought of as a whole collection of subproblems.",
            "For example, you need to learn a set of appearance models that are robust to different kinds of interclass variations, such as occlusion, differences in shape, viewpoint, and distance.",
            "At the same time, you need these models to differentiate between different possible confusing distractors."
        ],
        [
            "Such as random textures in the background.",
            "Semantically similar categories such as airplanes and birds which have wings and fly dissimilar categories like dog and airplane which don't have much function in common but might have similar boundaries and localization error, which are detections that are on the right kind of object, but that don't accurately enough circumscribe it or correspond to duplicate detections.",
            "So it's."
        ],
        [
            "Seems clear that with such a complicated task like recognition, we need a whole suite of tools to better understand the performance of our detectors.",
            "Currently, most research researchers rely exclusively on average precision, which is a summary of how well the object examples rank.",
            "For example, here the researchers compare two proposed improvements to a baseline method using a table in which they report the average precision for each of the categories.",
            "Now, this kind of evaluation is useful as a good summary.",
            "AP is useful.",
            "Here is a good summary statistic for a quick comparison, but it doesn't help us to understand.",
            "How these proposed methods have improved the results or how they could be improved further?",
            "And so we've created a set of tools that allows us to evaluate where the detectors fail and succeed, and what would be the potential impact for different kinds of improvement.",
            "And we found this useful within our own group, so we wanted to share it with the Community."
        ],
        [
            "As examples in the paper and in this talk, we show evaluation, we show how we can use these tools on two different detection methods on the VOC 2007 data set.",
            "The first is the day formal parts model by felon swab at all, which localizes objects with a sliding window and evaluates them based on a mixture of hug templates with sub templates that have latent positions.",
            "The second method is the multiple kernel learning detector by Vidal D at all, which localizes objects with a window.",
            "Keypoint based window prediction and evaluates them using various spatial pyramid bag of words.",
            "Features that are combined with multiple kernel learning.",
            "So first let's look at false positives."
        ],
        [
            "False positives are confident detections that don't correspond to the object category or they aren't localized well enough.",
            "One way that we can analyze those is by looking at the top looking at how many different kinds of looking at the fraction of different kinds of false positives that we see among the top edge detections.",
            "Where NJ is the number of objects in the category.",
            "So we do that for the DPM detector here for airplane.",
            "And that's shown in the pie chart here.",
            "So for example, 29% of the top false detections correspond to localization error, and there are some examples shown there in the upper right with the number in front of the image showing the overall rank of that false positive.",
            "33% correspond to confusion with similar objects, mainly birds, boats and cars.",
            "11% other objects which which are not semantically similar, and then 27% correspond to confusion with background.",
            "Another way that we can look at analyzing the false positives is to see what the impact would be if we were able to fix or remove different kinds of false positives.",
            "So for example, the long blue bar shows that if we were to fix the localization errors, for example with the category based segmentation method, we return some true positives into false positives and false positives and true positives, and we would improve the average precision by about .15.",
            "If we were only able to identify the localization errors.",
            "With some score that is able to say whether it bounding box is likely to be a good localization, then the average precision would improve by about .04.",
            "If we were able to remove all of the false detections that are due to background or due to dissimilar objects, which is the purple bar, then average precision would improve by about .04.",
            "Let's look at another category.",
            "So for dogs, again for the deep."
        ],
        [
            "Cam detector we see a different characterization of the false positives.",
            "In particular, there's much more confusion with similar objects.",
            "50% of the top false positives are due to confusion with other animals or people, particularly person, cat and horse.",
            "Still localization fixing localization errors would have the biggest impact because it's able to turn some false positives in a true positives according to the BOC metric.",
            "Now let's look at dogs, but on the other detector, the MK."
        ],
        [
            "Detector and we can see that for this detector there's an even more overwhelming correspondence between it's false positives and confusion with similar objects.",
            "74% of the false detections correspond to confusion with similar objects, particularly cow, person, sheep, and horse.",
            "And note that only 9% of the false positives correspond to confusion with background patches or with other dissimilar objects.",
            "And for this detector, if they were able to resolve the ambiguity between different kinds of similar objects, the AP would improve by about .2.",
            "So looking so this kind of analysis would lead you to pursue different different directions if you want to try to find the most fruitful direction to try to improve a particular director detector."
        ],
        [
            "We can also summarize these kinds of statistics by averaging over different subsets of categories, and I just want to point out a couple of things about this.",
            "This kind of summarization is useful if you want to show characteristics of your detector in a paper or do a quick comparison.",
            "So a couple things to point out is that most of the false detections actually correspond to localization error or confusion with similar objects, which for many applications are not as egregious errors as confusion with background or dissimilar objects.",
            "Another is that fixing localization error usually makes the biggest impact, and the third is if you compare the two detectors, particularly an animal, you can see that the MCL detector on the bottom has much less confusion with background and dissimilar objects, and so that this kind of analysis combined with the improved AP of the MCL detector and animals would lend further weight to it's being able to say that it's a better detector for these kinds of objects.",
            "So you can with this kind of analysis you can provide further evidence beyond AP that your detector is working better.",
            "Or worse, for different kinds of objects.",
            "We also want to be able to analyze."
        ],
        [
            "The characteristics of the objects influenced the detectors, so this is more of like a false negative analysis and analysis of which objects are easy or difficult to detect.",
            "For that, we create additional annotations on seven categories, level of occlusion, part visibility and side visibility."
        ],
        [
            "Now one tricky thing is that we want to compare performance for different subsets of objects.",
            "An average precision doesn't work because average precision is very sensitive to the number of objects you have in a category.",
            "If you have more objects in a category, you have more opportunities for true positives.",
            "So for the same detection rate, you would expect a category that has more objects to score a higher precision.",
            "And so we just fixed that with this simple normalization where when we're computing the number of true positives, we replace replace an J, the number of objects per category with a fixed N. So this allows us to perform a detailed analysis."
        ],
        [
            "As of how we detect a response, objects with different characteristics, and this is what the DPM airplane?"
        ],
        [
            "Hector for example.",
            "Here the dashed line shows the overall performance about .35.",
            "For unincluded objects, the detector averages point 37, so even if it did as well for all objects as it does for unincluded objects, the improvement would only be about .02.",
            "On the other hand, the detector isn't very robust to occlusion.",
            "It performs poorly for lightly occluded objects .23 and even worse for medium and heavy included objects.",
            "Looking."
        ],
        [
            "And another one we can see that the detector is a strong preference for medium to large objects, achieving a much higher performance than for the average object performs poorly on large objects, largely because of perspective effects and truncation and poorly on the smallest objects because they are low resolution."
        ],
        [
            "You can see that the detector is a strong preference for wide site for wide views of airplanes, which tend to correspond to side views."
        ],
        [
            "And if we were to look at this more detailed analysis, you could see that the detector has a preference for when it can see the side but not the bottom front, rear top.",
            "And it prefers to be able to see all of the parts.",
            "So so this detector prefers to see exact side views of airplanes.",
            "So this is a more detailed analysis that you could do to try."
        ],
        [
            "Understand where your detector is succeeding or failing, or to compare it to another approach or after an improvement.",
            "We also want to be able to summarize this concisely, so for this we we look at the average performance of the best case for a subset within a characteristic.",
            "For example, what's the performance for unoccluded objects, the average overall performance in the average performance for worst case?",
            "For example, heavily occluded objects.",
            "And we can use this to look at the sensitivity in the impact of different characteristic."
        ],
        [
            "Here we do a comparison of DPM in the MCL detectors in green and red and green, so the height of these bars tells you the sensitivity.",
            "The difference between the best and the worst case within a characteristic.",
            "The difference between the Dash line and the top tells you the amount of impact that you could get if you were able to improve your robustness to that characteristic.",
            "So one thing that you might notice is that these detectors have similar sensitivity to these different characteristics."
        ],
        [
            "And in fact, in the more detailed analysis those similarities continue even at the object level.",
            "A couple of things that you can see from this is that both detectors are have high sensitivity to occlusion, but that fixing occlusion would have a low impact in overall AP.",
            "So if you want to propose improvements to occlusion robustness, it's important to evaluate specifically on subsets of included objects."
        ],
        [
            "You can see that the MKL detector is more sensitive to size, likely because its interest point based appearance models are better able to take advantage of high resolution.",
            "While they might provide a sparse representation for low resolution objects."
        ],
        [
            "And the DPM model is more sensitive to aspect ratio, which is appearance model."
        ],
        [
            "So this is just an example of the kind of analysis that you can do in the paper, we have more analysis as well as a set of recommendations for areas of fruitful research.",
            "I just want to highlight a couple of conclusions.",
            "One is that most of the errors that current detectors make are reasonable, so when you see that a detector has an average precision of say .1, you might think that it's doing really horribly.",
            "But then when you look at the kinds of errors it's making, often it's making errors due to localization or due to confusion with similar objects that might not be as important for some applications.",
            "We've also found that large improvements in specific areas.",
            "For example, if you were able to remove all of the false positives that correspond to background patches and dissimilar objects often lead to very small gains in overall average precision because there are many different kinds of errors that contribute to that summary, and so it's really important that you perform specific analysis to better understand exactly how your improvements are made.",
            "Whether you're making large improvements in certain areas, and we found this this kind of analysis very useful in our own research group.",
            "And so we've put the code in annotations on line so that you can automatically very easily run this kind of analysis and produce similar reports for your own detectors.",
            "And so we hope that you."
        ],
        [
            "And it useful, thank you.",
            "I have a question because a lot of detectors has post processing procedures such as Max response, mean shift.",
            "Have you tried to dies the last election result before the post processing, or will the post processing have different kind of conclusion?",
            "A slightly different kind of conclusion in subsequent scenarios.",
            "OK, so the question is that there are various kinds of post processing operations that you can apply to detectors and the question was whether I've analyzed those different kinds of post processing to see whether it would influence the conclusions I'm able to draw.",
            "For example about localization error.",
            "I haven't analyzed all of these.",
            "These different variations of detectors.",
            "The main thing that I was interested in is trying to provide examples of how how researchers could evaluate their proposed improvements so that they can say, for example, that we're able to get an improvement of .03 AP that corresponds to a large drop in localization error, or that corresponds to a large drop in confusion with similar objects or robustness to occlusion.",
            "So I think the.",
            "Tools that we've provided would make it very easy for for these kinds of detailed comparisons, but since there are so many of them, we didn't try to do an exhaustive study that way.",
            "Testing it on Pascal.",
            "Every image in Pascal has at least one object, so one worry would be that you may be over counting the actual number of confused confusions with other objects.",
            "Have you have you tried doing it on just random images that are maybe a little bit different?",
            "Distribution Pascal?",
            "Well, So what?",
            "I tried doing as I shuffled the detections with the image IDs so that I would be able to see if I had like a random set of detections with the same distribution of positions.",
            "How the breakdown would occur for that and you get about.",
            "Typically you get about 70 or 80% of the detections corresponded background or dissimilar objects, and also you may have.",
            "You may still have around 20% that correspond to similar objects, but it will be broadly distributed among the objects that are considered to be similar.",
            "Well, if you look at the details of the confusion with similar objects, usually it's only like two or three categories that are you have a lot of confusion with a given category.",
            "So it's a quite different distribution than what you would get with a randomized detector.",
            "So 1 one last.",
            "So these are all these results are for the Pascal data set.",
            "But what happens with other data sets?",
            "Do you think the conclusions will be similar like Pascal has 20 object categories?",
            "What if you have many more object classes so that everything on the image is something?",
            "So there is no background anymore.",
            "I guess as you change the.",
            "If you change the distribution of the kinds of false positives are available.",
            "For example, if your images are even more dominated or less dominated by objects, then I would expect that you have.",
            "You would end up with a different distribution of errors, but I think that the important if there's one take home message I want to convey is that it's important to do this kind of more detailed analysis when you're proposing a new system or when you're making an improvement to your system so that you understand specifically how the changes that you've made.",
            "Have impacted the errors of the detector.",
            "Thanks, OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Object detection is actually best thought of as a whole collection of subproblems.",
                    "label": 1
                },
                {
                    "sent": "For example, you need to learn a set of appearance models that are robust to different kinds of interclass variations, such as occlusion, differences in shape, viewpoint, and distance.",
                    "label": 0
                },
                {
                    "sent": "At the same time, you need these models to differentiate between different possible confusing distractors.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Such as random textures in the background.",
                    "label": 0
                },
                {
                    "sent": "Semantically similar categories such as airplanes and birds which have wings and fly dissimilar categories like dog and airplane which don't have much function in common but might have similar boundaries and localization error, which are detections that are on the right kind of object, but that don't accurately enough circumscribe it or correspond to duplicate detections.",
                    "label": 1
                },
                {
                    "sent": "So it's.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seems clear that with such a complicated task like recognition, we need a whole suite of tools to better understand the performance of our detectors.",
                    "label": 0
                },
                {
                    "sent": "Currently, most research researchers rely exclusively on average precision, which is a summary of how well the object examples rank.",
                    "label": 0
                },
                {
                    "sent": "For example, here the researchers compare two proposed improvements to a baseline method using a table in which they report the average precision for each of the categories.",
                    "label": 0
                },
                {
                    "sent": "Now, this kind of evaluation is useful as a good summary.",
                    "label": 0
                },
                {
                    "sent": "AP is useful.",
                    "label": 0
                },
                {
                    "sent": "Here is a good summary statistic for a quick comparison, but it doesn't help us to understand.",
                    "label": 1
                },
                {
                    "sent": "How these proposed methods have improved the results or how they could be improved further?",
                    "label": 1
                },
                {
                    "sent": "And so we've created a set of tools that allows us to evaluate where the detectors fail and succeed, and what would be the potential impact for different kinds of improvement.",
                    "label": 0
                },
                {
                    "sent": "And we found this useful within our own group, so we wanted to share it with the Community.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As examples in the paper and in this talk, we show evaluation, we show how we can use these tools on two different detection methods on the VOC 2007 data set.",
                    "label": 0
                },
                {
                    "sent": "The first is the day formal parts model by felon swab at all, which localizes objects with a sliding window and evaluates them based on a mixture of hug templates with sub templates that have latent positions.",
                    "label": 0
                },
                {
                    "sent": "The second method is the multiple kernel learning detector by Vidal D at all, which localizes objects with a window.",
                    "label": 0
                },
                {
                    "sent": "Keypoint based window prediction and evaluates them using various spatial pyramid bag of words.",
                    "label": 1
                },
                {
                    "sent": "Features that are combined with multiple kernel learning.",
                    "label": 0
                },
                {
                    "sent": "So first let's look at false positives.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "False positives are confident detections that don't correspond to the object category or they aren't localized well enough.",
                    "label": 1
                },
                {
                    "sent": "One way that we can analyze those is by looking at the top looking at how many different kinds of looking at the fraction of different kinds of false positives that we see among the top edge detections.",
                    "label": 0
                },
                {
                    "sent": "Where NJ is the number of objects in the category.",
                    "label": 0
                },
                {
                    "sent": "So we do that for the DPM detector here for airplane.",
                    "label": 0
                },
                {
                    "sent": "And that's shown in the pie chart here.",
                    "label": 0
                },
                {
                    "sent": "So for example, 29% of the top false detections correspond to localization error, and there are some examples shown there in the upper right with the number in front of the image showing the overall rank of that false positive.",
                    "label": 0
                },
                {
                    "sent": "33% correspond to confusion with similar objects, mainly birds, boats and cars.",
                    "label": 1
                },
                {
                    "sent": "11% other objects which which are not semantically similar, and then 27% correspond to confusion with background.",
                    "label": 0
                },
                {
                    "sent": "Another way that we can look at analyzing the false positives is to see what the impact would be if we were able to fix or remove different kinds of false positives.",
                    "label": 0
                },
                {
                    "sent": "So for example, the long blue bar shows that if we were to fix the localization errors, for example with the category based segmentation method, we return some true positives into false positives and false positives and true positives, and we would improve the average precision by about .15.",
                    "label": 0
                },
                {
                    "sent": "If we were only able to identify the localization errors.",
                    "label": 0
                },
                {
                    "sent": "With some score that is able to say whether it bounding box is likely to be a good localization, then the average precision would improve by about .04.",
                    "label": 0
                },
                {
                    "sent": "If we were able to remove all of the false detections that are due to background or due to dissimilar objects, which is the purple bar, then average precision would improve by about .04.",
                    "label": 0
                },
                {
                    "sent": "Let's look at another category.",
                    "label": 0
                },
                {
                    "sent": "So for dogs, again for the deep.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cam detector we see a different characterization of the false positives.",
                    "label": 0
                },
                {
                    "sent": "In particular, there's much more confusion with similar objects.",
                    "label": 1
                },
                {
                    "sent": "50% of the top false positives are due to confusion with other animals or people, particularly person, cat and horse.",
                    "label": 1
                },
                {
                    "sent": "Still localization fixing localization errors would have the biggest impact because it's able to turn some false positives in a true positives according to the BOC metric.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at dogs, but on the other detector, the MK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detector and we can see that for this detector there's an even more overwhelming correspondence between it's false positives and confusion with similar objects.",
                    "label": 0
                },
                {
                    "sent": "74% of the false detections correspond to confusion with similar objects, particularly cow, person, sheep, and horse.",
                    "label": 1
                },
                {
                    "sent": "And note that only 9% of the false positives correspond to confusion with background patches or with other dissimilar objects.",
                    "label": 0
                },
                {
                    "sent": "And for this detector, if they were able to resolve the ambiguity between different kinds of similar objects, the AP would improve by about .2.",
                    "label": 0
                },
                {
                    "sent": "So looking so this kind of analysis would lead you to pursue different different directions if you want to try to find the most fruitful direction to try to improve a particular director detector.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also summarize these kinds of statistics by averaging over different subsets of categories, and I just want to point out a couple of things about this.",
                    "label": 0
                },
                {
                    "sent": "This kind of summarization is useful if you want to show characteristics of your detector in a paper or do a quick comparison.",
                    "label": 0
                },
                {
                    "sent": "So a couple things to point out is that most of the false detections actually correspond to localization error or confusion with similar objects, which for many applications are not as egregious errors as confusion with background or dissimilar objects.",
                    "label": 0
                },
                {
                    "sent": "Another is that fixing localization error usually makes the biggest impact, and the third is if you compare the two detectors, particularly an animal, you can see that the MCL detector on the bottom has much less confusion with background and dissimilar objects, and so that this kind of analysis combined with the improved AP of the MCL detector and animals would lend further weight to it's being able to say that it's a better detector for these kinds of objects.",
                    "label": 0
                },
                {
                    "sent": "So you can with this kind of analysis you can provide further evidence beyond AP that your detector is working better.",
                    "label": 0
                },
                {
                    "sent": "Or worse, for different kinds of objects.",
                    "label": 0
                },
                {
                    "sent": "We also want to be able to analyze.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The characteristics of the objects influenced the detectors, so this is more of like a false negative analysis and analysis of which objects are easy or difficult to detect.",
                    "label": 0
                },
                {
                    "sent": "For that, we create additional annotations on seven categories, level of occlusion, part visibility and side visibility.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now one tricky thing is that we want to compare performance for different subsets of objects.",
                    "label": 0
                },
                {
                    "sent": "An average precision doesn't work because average precision is very sensitive to the number of objects you have in a category.",
                    "label": 1
                },
                {
                    "sent": "If you have more objects in a category, you have more opportunities for true positives.",
                    "label": 0
                },
                {
                    "sent": "So for the same detection rate, you would expect a category that has more objects to score a higher precision.",
                    "label": 0
                },
                {
                    "sent": "And so we just fixed that with this simple normalization where when we're computing the number of true positives, we replace replace an J, the number of objects per category with a fixed N. So this allows us to perform a detailed analysis.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As of how we detect a response, objects with different characteristics, and this is what the DPM airplane?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hector for example.",
                    "label": 0
                },
                {
                    "sent": "Here the dashed line shows the overall performance about .35.",
                    "label": 1
                },
                {
                    "sent": "For unincluded objects, the detector averages point 37, so even if it did as well for all objects as it does for unincluded objects, the improvement would only be about .02.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, the detector isn't very robust to occlusion.",
                    "label": 0
                },
                {
                    "sent": "It performs poorly for lightly occluded objects .23 and even worse for medium and heavy included objects.",
                    "label": 0
                },
                {
                    "sent": "Looking.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another one we can see that the detector is a strong preference for medium to large objects, achieving a much higher performance than for the average object performs poorly on large objects, largely because of perspective effects and truncation and poorly on the smallest objects because they are low resolution.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see that the detector is a strong preference for wide site for wide views of airplanes, which tend to correspond to side views.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if we were to look at this more detailed analysis, you could see that the detector has a preference for when it can see the side but not the bottom front, rear top.",
                    "label": 0
                },
                {
                    "sent": "And it prefers to be able to see all of the parts.",
                    "label": 0
                },
                {
                    "sent": "So so this detector prefers to see exact side views of airplanes.",
                    "label": 0
                },
                {
                    "sent": "So this is a more detailed analysis that you could do to try.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Understand where your detector is succeeding or failing, or to compare it to another approach or after an improvement.",
                    "label": 0
                },
                {
                    "sent": "We also want to be able to summarize this concisely, so for this we we look at the average performance of the best case for a subset within a characteristic.",
                    "label": 1
                },
                {
                    "sent": "For example, what's the performance for unoccluded objects, the average overall performance in the average performance for worst case?",
                    "label": 1
                },
                {
                    "sent": "For example, heavily occluded objects.",
                    "label": 0
                },
                {
                    "sent": "And we can use this to look at the sensitivity in the impact of different characteristic.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we do a comparison of DPM in the MCL detectors in green and red and green, so the height of these bars tells you the sensitivity.",
                    "label": 0
                },
                {
                    "sent": "The difference between the best and the worst case within a characteristic.",
                    "label": 1
                },
                {
                    "sent": "The difference between the Dash line and the top tells you the amount of impact that you could get if you were able to improve your robustness to that characteristic.",
                    "label": 0
                },
                {
                    "sent": "So one thing that you might notice is that these detectors have similar sensitivity to these different characteristics.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in fact, in the more detailed analysis those similarities continue even at the object level.",
                    "label": 0
                },
                {
                    "sent": "A couple of things that you can see from this is that both detectors are have high sensitivity to occlusion, but that fixing occlusion would have a low impact in overall AP.",
                    "label": 0
                },
                {
                    "sent": "So if you want to propose improvements to occlusion robustness, it's important to evaluate specifically on subsets of included objects.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see that the MKL detector is more sensitive to size, likely because its interest point based appearance models are better able to take advantage of high resolution.",
                    "label": 0
                },
                {
                    "sent": "While they might provide a sparse representation for low resolution objects.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the DPM model is more sensitive to aspect ratio, which is appearance model.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is just an example of the kind of analysis that you can do in the paper, we have more analysis as well as a set of recommendations for areas of fruitful research.",
                    "label": 0
                },
                {
                    "sent": "I just want to highlight a couple of conclusions.",
                    "label": 0
                },
                {
                    "sent": "One is that most of the errors that current detectors make are reasonable, so when you see that a detector has an average precision of say .1, you might think that it's doing really horribly.",
                    "label": 1
                },
                {
                    "sent": "But then when you look at the kinds of errors it's making, often it's making errors due to localization or due to confusion with similar objects that might not be as important for some applications.",
                    "label": 0
                },
                {
                    "sent": "We've also found that large improvements in specific areas.",
                    "label": 1
                },
                {
                    "sent": "For example, if you were able to remove all of the false positives that correspond to background patches and dissimilar objects often lead to very small gains in overall average precision because there are many different kinds of errors that contribute to that summary, and so it's really important that you perform specific analysis to better understand exactly how your improvements are made.",
                    "label": 0
                },
                {
                    "sent": "Whether you're making large improvements in certain areas, and we found this this kind of analysis very useful in our own research group.",
                    "label": 0
                },
                {
                    "sent": "And so we've put the code in annotations on line so that you can automatically very easily run this kind of analysis and produce similar reports for your own detectors.",
                    "label": 0
                },
                {
                    "sent": "And so we hope that you.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it useful, thank you.",
                    "label": 1
                },
                {
                    "sent": "I have a question because a lot of detectors has post processing procedures such as Max response, mean shift.",
                    "label": 0
                },
                {
                    "sent": "Have you tried to dies the last election result before the post processing, or will the post processing have different kind of conclusion?",
                    "label": 0
                },
                {
                    "sent": "A slightly different kind of conclusion in subsequent scenarios.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is that there are various kinds of post processing operations that you can apply to detectors and the question was whether I've analyzed those different kinds of post processing to see whether it would influence the conclusions I'm able to draw.",
                    "label": 0
                },
                {
                    "sent": "For example about localization error.",
                    "label": 0
                },
                {
                    "sent": "I haven't analyzed all of these.",
                    "label": 0
                },
                {
                    "sent": "These different variations of detectors.",
                    "label": 0
                },
                {
                    "sent": "The main thing that I was interested in is trying to provide examples of how how researchers could evaluate their proposed improvements so that they can say, for example, that we're able to get an improvement of .03 AP that corresponds to a large drop in localization error, or that corresponds to a large drop in confusion with similar objects or robustness to occlusion.",
                    "label": 0
                },
                {
                    "sent": "So I think the.",
                    "label": 0
                },
                {
                    "sent": "Tools that we've provided would make it very easy for for these kinds of detailed comparisons, but since there are so many of them, we didn't try to do an exhaustive study that way.",
                    "label": 0
                },
                {
                    "sent": "Testing it on Pascal.",
                    "label": 0
                },
                {
                    "sent": "Every image in Pascal has at least one object, so one worry would be that you may be over counting the actual number of confused confusions with other objects.",
                    "label": 0
                },
                {
                    "sent": "Have you have you tried doing it on just random images that are maybe a little bit different?",
                    "label": 0
                },
                {
                    "sent": "Distribution Pascal?",
                    "label": 0
                },
                {
                    "sent": "Well, So what?",
                    "label": 0
                },
                {
                    "sent": "I tried doing as I shuffled the detections with the image IDs so that I would be able to see if I had like a random set of detections with the same distribution of positions.",
                    "label": 0
                },
                {
                    "sent": "How the breakdown would occur for that and you get about.",
                    "label": 0
                },
                {
                    "sent": "Typically you get about 70 or 80% of the detections corresponded background or dissimilar objects, and also you may have.",
                    "label": 0
                },
                {
                    "sent": "You may still have around 20% that correspond to similar objects, but it will be broadly distributed among the objects that are considered to be similar.",
                    "label": 0
                },
                {
                    "sent": "Well, if you look at the details of the confusion with similar objects, usually it's only like two or three categories that are you have a lot of confusion with a given category.",
                    "label": 0
                },
                {
                    "sent": "So it's a quite different distribution than what you would get with a randomized detector.",
                    "label": 0
                },
                {
                    "sent": "So 1 one last.",
                    "label": 0
                },
                {
                    "sent": "So these are all these results are for the Pascal data set.",
                    "label": 0
                },
                {
                    "sent": "But what happens with other data sets?",
                    "label": 0
                },
                {
                    "sent": "Do you think the conclusions will be similar like Pascal has 20 object categories?",
                    "label": 0
                },
                {
                    "sent": "What if you have many more object classes so that everything on the image is something?",
                    "label": 0
                },
                {
                    "sent": "So there is no background anymore.",
                    "label": 0
                },
                {
                    "sent": "I guess as you change the.",
                    "label": 1
                },
                {
                    "sent": "If you change the distribution of the kinds of false positives are available.",
                    "label": 0
                },
                {
                    "sent": "For example, if your images are even more dominated or less dominated by objects, then I would expect that you have.",
                    "label": 0
                },
                {
                    "sent": "You would end up with a different distribution of errors, but I think that the important if there's one take home message I want to convey is that it's important to do this kind of more detailed analysis when you're proposing a new system or when you're making an improvement to your system so that you understand specifically how the changes that you've made.",
                    "label": 0
                },
                {
                    "sent": "Have impacted the errors of the detector.",
                    "label": 0
                },
                {
                    "sent": "Thanks, OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}