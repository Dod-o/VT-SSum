{
    "id": "q65kdgoolzqb2xgfhgowlki5qtzzdlto",
    "title": "Prediction by random-walk perturbation",
    "info": {
        "author": [
            "Gergely Neu, SequeL, INRIA Lille - Nord Europe"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_neu_prediction/",
    "segmentation": [
        [
            "So this talk is about special case of online learning problems.",
            "So besides minimizing loss, you are also trying to focus on minimizing the number of switches between the predictions.",
            "So besides paying some laws, you also have to pay some price for switching between predictions and what we propose for this situation is a variant of the FPL algorithm that uses random walk predictions instead of IID predictions.",
            "So let me start with the."
        ],
        [
            "Simple motivating example.",
            "So this is this is the problem of sequential routing, where in each round of this decision problem.",
            "The learner has to transfer packet from node.",
            "You know W. So in each round you have to select a route.",
            "For this and then the packet suffers some delay and afterwards the delays are revealed to the learner over each edge and the goal of the learner is to minimize the total delay or to be precise, to minimize regret when the losses change arbitrarily overtime.",
            "But in practical settings this is not the only thing that you care about.",
            "You also want to minimize your bandwidth."
        ],
        [
            "As well, so in this situation you also have to pay an additional price for switching between routes, 'cause if you just approach this problem as a standard online learning problem."
        ],
        [
            "This is what this is, what every packet will look like.",
            "So in each round you have to transfer header that specifies the route.",
            "For the packet and then comes the data and so with each with each new new piece of data you have to."
        ],
        [
            "So the header."
        ],
        [
            "Repeat it over and over again, but you can save a lot of bandwidth by.",
            "By just transferring the head."
        ],
        [
            "It's only when you switch between the routes, so This is why we are interested in bounding the number of switches between between.",
            "Between the experts so.",
            "But of course this is.",
            "This is just an example and there are a lot of more practical problems, and this is also interesting from a theoretical point of view."
        ],
        [
            "So here, so here is a formal setting.",
            "This is standard online learning problem where you have a decision set where each each action can be represented by a vector of zeros and ones, and we assume that the maximum number of ones in each decision is upper bounded by M, so."
        ],
        [
            "About this as the length of the longest path in the shortest path problem an the prediction method goes like this.",
            "So in each round the learner has to choose one decision out of this decision set and then the adversary select selects a loss vector and then the losses given the loss of the learner learner is given by the inner product between these two and after suffering the loss the learner guests observe the whole loss factors here and so you are facing.",
            "Is full information situation.",
            "And."
        ],
        [
            "As always in this session we are interested in minimizing the regret which is, which is just the difference between the total loss that you that you got and the loss of the best fixed decision."
        ],
        [
            "But we're also interested in controlling the number of switches, so this is, this is just the number of times that you switch between predictions, so it's clear so far so.",
            "So."
        ],
        [
            "Here are some previous results.",
            "That we know of.",
            "So for the simple experts case where you have M = 1, so each each expert is independent of the other.",
            "The losses of each expert, and so for this variant you can use the simplified FF variant by Kalayaan Vampola and guarantee optimal regret an optimal number of switches.",
            "Or you could also use this shrinking dartboard variant, which is proposed in a code paper by Golden working and Winkler.",
            "Three years ago in the code and it also guarantees optimal performance, but these bounds only holding expectations, so we are also interested in bonds that hold with high probability, and there's no way that you can prove that this hold with high probability.",
            "I mean both at the same time.",
            "So in the combinatorial setting we know about this, follow the Leader algorithm, which is the usual regret guarantee of FPL.",
            "Algorithms in combinatorial problems.",
            "And it guarantees that the switch is scaled dis quantity, and so as you can see, this is scales with the square root of D, which can be suboptimal and number of dimensions is large.",
            "So it's a better idea probably to use the shrinking dartboard algorithm that has a better regret guarantee.",
            "And it also.",
            "Has better scaling.",
            "Yeah, in the number of.",
            "So in the size of the maximizer, yes.",
            "The D is the number of dimensions, so it's a dimension of the decision vectors.",
            "Number of edges in graph.",
            "Yeah, number of edges in the graph.",
            "Total number of edges in the graph.",
            "And so in practice."
        ],
        [
            "Situations the number of edges in the graph is much, much larger than the length of the longest path in the graph.",
            "So, so there's this problem with the follow the least lazily that it's suboptimal, and the problem with the shrinking dot board algorithm is that it can't always be efficiently implemented because it's just a variant of exponentially weighted average well for the for the path problem, this can be efficiently implemented, but not always, not for every every decision set of interest, so."
        ],
        [
            "So what we have in this paper is that for the experts case, we retrieve the usual guarantees and for the combinatorial case we get an upper bound and on a number of switches that scales only with them.",
            "So with the length of the longest path.",
            "An depends on logarithmically on the so.",
            "So this is much better.",
            "The regret bounds are slightly worse than the shrinking dartboard algorithm.",
            "But but this is an efficient algorithm, so this can always be efficiently implemented.",
            "So you understand the target on the 1st."
        ],
        [
            "To talk about the well known FPL algorithm that most of you might probably know.",
            "So this is how it works.",
            "In around you draw some.",
            "You draw some perturbations from scratch, IID perturbations, and then you perturb all the previous losses that you observed so far, and then pick the leader.",
            "The big, the big decision that minimizes these perturb losses.",
            "So so this is a really simple and nice algorithm, But the problem with that if you use IID perturbation, so if you draw a new perturbations in each round, you might end up switching all the time.",
            "So this says absolutely no guarantees about.",
            "Think about a number of switches between predictions.",
            "So we came up with the idea.",
            "Alfred."
        ],
        [
            "Facing these these perturbations by random walks.",
            "So what you what we ended up doing is that.",
            "We retain the perturbation from the previous round and then we add just a small additional perturbation to it, which is just a Rademacher random variable, so we end up with having random walk perturbation, symmetric random walks and this way we can hope that we can guarantee small number of switches between the experts.",
            "So for analyzing this algorithm.",
            "Simple expert setting.",
            "You first have to observe that the expected regret is explicitly upper bounded by two times the number of times.",
            "The predictions are switched, so this is very easy to show by some standard arguments and then by intuition it is enough to study the case where you have no losses at all.",
            "Because this is the case where the number of switches is maximized in expectation for symmetry reasons.",
            "So what we what we have to do is is bound the number of leader switches in the parallel random walks.",
            "So why we hope that this would work?",
            "That is well known for for two random walks the number of switches is bounded by square root of N with high probability.",
            "So we can have both high probability bounds on the number of switches and the regret at the same time so but.",
            "The question is what happens if we increase the number of random walks?",
            "So we first have to make this observation is that as we as we increase the number of random walks, what happens is that.",
            "The situation gets very dense around 0, so most of posted a random walks are going to concentrate around zero and there are just going to be a few guys fighting over the 1st place at any given time.",
            "So if you just increase the number of random walks even further you can see that there are just just a few guys fighting over there and and most of the random walks are just clustered around 0.",
            "So what we study?",
            "Is this so called lead back?",
            "Which is which is the set of guys that are fighting over fighting over the 1st place at any given time?",
            "So this is the set is the set of experts that have positive probability of taking over the lead at the next time step and.",
            "And this is this is the result that we have, so the probability of delete that consisting of more than one guy.",
            "So if there are any competitor, there is his upper bounded by this quantity.",
            "So this scales with the square root of logarithm of the of the number of random walks.",
            "So it just depends very very mildly on the number of random walks.",
            "And I have a short slide about how the proof works for.",
            "Fergusons case when when the increments of the random walks are Goshen, so.",
            "So it's a very, very simple argument that you can workout in a couple of lines so that the probability of delete bag being larger than one is upper bounded by some constant over T plus the expectation of the maximum.",
            "Of the largest random walk over T. So this is a very simple argument, and since we know that the bank system is the expectation of the maximum is is at most sqrt 2 times log D sqrt T. So this gives a nice result.",
            "And this is what makes it possible for us to prove the.",
            "Prove the regret bound is so well this analysis.",
            "So this is just a simplification.",
            "The same proof can be carried out for Rademacher distributions where you can get some tighter bounds as well.",
            "But essentially it's just the same and.",
            "So here's the main result.",
            "It's not surprising after all that I've told you so.",
            "So we regret this upper bounded by by the number of switches, and this is this is of the optimal order.",
            "So the question is.",
            "Well, how can you generalize this whole thing to the combinatorial action action set where where M is larger than one?",
            "For example, the shortest path problem where you have longer path faster than one.",
            "So in this case for convenience we by standard use Gaussian perturbations.",
            "Anne, it is also possible to define the lead back as the set of experts that have a positive probability of taking the lead.",
            "And the lemma here is exactly identical to what we had in the experts case.",
            "The only difference is that everything is multiplied by M which is.",
            "Which is the length of the longer path.",
            "An proof?",
            "Well, it has the exact same form.",
            "This expression has the exact same form as as in the experts case, but the difference is that, well, so the proof of that is just three lines, and the proof of this is 3 pages, so you need to pull up lots of tricks while in the process, and the main difficulty is that in this, in this case you don't have to.",
            "You don't have to control the number of switches in the parallel independent random walks, but now you have.",
            "Combinatorial number of dependent random walks, so this is the main difficulty here, but.",
            "But perhaps surprisingly, this is the same result, and this leads to our main results concerning this case.",
            "So the number of number of experts which is now M times whatever we had before and they regret is is another thing multiplied by another room.",
            "So it's M squared.",
            "It's slightly worse than the best bound for exponential weighting or shrinking dartboard.",
            "Sort of sort of main observation is that it depends very mildly on the number of dimensions.",
            "So so these are mainly our results, but we have a number of future directions so.",
            "So the most interesting thing about this algorithm that it has absolutely no parameters.",
            "So as you see in the random walks were just Rademacher random walks and they were not scaled by any step size or any learning rate.",
            "This just happens to be square root of log D. Whatever small perturbations you use.",
            "But well, it's it's a.",
            "It's an interesting thing to look at the case where the losses tend to be small and.",
            "So in this situation, you probably have to scale down the random walks to be compareable to the thoughts of losses.",
            "And, well, the question is how do you get high priority bands on both both the number of switches and the regret.",
            "So right now this is very, very easy to have for two random walks, but.",
            "Probably can be done for more than two random walks.",
            "It's an interesting thing, but it's also important to note that this is the first target on this property, so everything that we had before was either high probability on the regret and expectation on the number of switches, or high probability bound in a more switches an expectation on the regret.",
            "So it's very interesting to see that if this trade off is inherent or not.",
            "So whether this is necessary or you can do better, but for the equals two we already have this so.",
            "And the bounds can be further improved if you're not looking at the probability of switching between experts, but what about the expectation of the difference between between the consecutive predictions?",
            "Because this way you can.",
            "Probably get some more sensible results and improve your graph guarantees as well so.",
            "My my intuition is that you can chop up chop off a sqrt M, but not much more.",
            "And of course, an interesting question is where would this idea work when you have bandit feedback and so you don't get to observe the losses on each edge?",
            "But you have some sort of bandit feedback, but but right now it doesn't.",
            "Doesn't seem very promising, so Nicole has some initial negative results about this situation, and but we also we remain hopeful that this would work in that situation, so.",
            "So this is it.",
            "And thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this talk is about special case of online learning problems.",
                    "label": 0
                },
                {
                    "sent": "So besides minimizing loss, you are also trying to focus on minimizing the number of switches between the predictions.",
                    "label": 0
                },
                {
                    "sent": "So besides paying some laws, you also have to pay some price for switching between predictions and what we propose for this situation is a variant of the FPL algorithm that uses random walk predictions instead of IID predictions.",
                    "label": 0
                },
                {
                    "sent": "So let me start with the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple motivating example.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the problem of sequential routing, where in each round of this decision problem.",
                    "label": 0
                },
                {
                    "sent": "The learner has to transfer packet from node.",
                    "label": 0
                },
                {
                    "sent": "You know W. So in each round you have to select a route.",
                    "label": 0
                },
                {
                    "sent": "For this and then the packet suffers some delay and afterwards the delays are revealed to the learner over each edge and the goal of the learner is to minimize the total delay or to be precise, to minimize regret when the losses change arbitrarily overtime.",
                    "label": 0
                },
                {
                    "sent": "But in practical settings this is not the only thing that you care about.",
                    "label": 0
                },
                {
                    "sent": "You also want to minimize your bandwidth.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As well, so in this situation you also have to pay an additional price for switching between routes, 'cause if you just approach this problem as a standard online learning problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what this is, what every packet will look like.",
                    "label": 0
                },
                {
                    "sent": "So in each round you have to transfer header that specifies the route.",
                    "label": 0
                },
                {
                    "sent": "For the packet and then comes the data and so with each with each new new piece of data you have to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the header.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Repeat it over and over again, but you can save a lot of bandwidth by.",
                    "label": 0
                },
                {
                    "sent": "By just transferring the head.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's only when you switch between the routes, so This is why we are interested in bounding the number of switches between between.",
                    "label": 0
                },
                {
                    "sent": "Between the experts so.",
                    "label": 0
                },
                {
                    "sent": "But of course this is.",
                    "label": 0
                },
                {
                    "sent": "This is just an example and there are a lot of more practical problems, and this is also interesting from a theoretical point of view.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here, so here is a formal setting.",
                    "label": 0
                },
                {
                    "sent": "This is standard online learning problem where you have a decision set where each each action can be represented by a vector of zeros and ones, and we assume that the maximum number of ones in each decision is upper bounded by M, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About this as the length of the longest path in the shortest path problem an the prediction method goes like this.",
                    "label": 1
                },
                {
                    "sent": "So in each round the learner has to choose one decision out of this decision set and then the adversary select selects a loss vector and then the losses given the loss of the learner learner is given by the inner product between these two and after suffering the loss the learner guests observe the whole loss factors here and so you are facing.",
                    "label": 0
                },
                {
                    "sent": "Is full information situation.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As always in this session we are interested in minimizing the regret which is, which is just the difference between the total loss that you that you got and the loss of the best fixed decision.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we're also interested in controlling the number of switches, so this is, this is just the number of times that you switch between predictions, so it's clear so far so.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some previous results.",
                    "label": 1
                },
                {
                    "sent": "That we know of.",
                    "label": 1
                },
                {
                    "sent": "So for the simple experts case where you have M = 1, so each each expert is independent of the other.",
                    "label": 1
                },
                {
                    "sent": "The losses of each expert, and so for this variant you can use the simplified FF variant by Kalayaan Vampola and guarantee optimal regret an optimal number of switches.",
                    "label": 0
                },
                {
                    "sent": "Or you could also use this shrinking dartboard variant, which is proposed in a code paper by Golden working and Winkler.",
                    "label": 1
                },
                {
                    "sent": "Three years ago in the code and it also guarantees optimal performance, but these bounds only holding expectations, so we are also interested in bonds that hold with high probability, and there's no way that you can prove that this hold with high probability.",
                    "label": 0
                },
                {
                    "sent": "I mean both at the same time.",
                    "label": 0
                },
                {
                    "sent": "So in the combinatorial setting we know about this, follow the Leader algorithm, which is the usual regret guarantee of FPL.",
                    "label": 0
                },
                {
                    "sent": "Algorithms in combinatorial problems.",
                    "label": 0
                },
                {
                    "sent": "And it guarantees that the switch is scaled dis quantity, and so as you can see, this is scales with the square root of D, which can be suboptimal and number of dimensions is large.",
                    "label": 1
                },
                {
                    "sent": "So it's a better idea probably to use the shrinking dartboard algorithm that has a better regret guarantee.",
                    "label": 0
                },
                {
                    "sent": "And it also.",
                    "label": 0
                },
                {
                    "sent": "Has better scaling.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in the number of.",
                    "label": 0
                },
                {
                    "sent": "So in the size of the maximizer, yes.",
                    "label": 0
                },
                {
                    "sent": "The D is the number of dimensions, so it's a dimension of the decision vectors.",
                    "label": 0
                },
                {
                    "sent": "Number of edges in graph.",
                    "label": 0
                },
                {
                    "sent": "Yeah, number of edges in the graph.",
                    "label": 0
                },
                {
                    "sent": "Total number of edges in the graph.",
                    "label": 0
                },
                {
                    "sent": "And so in practice.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Situations the number of edges in the graph is much, much larger than the length of the longest path in the graph.",
                    "label": 0
                },
                {
                    "sent": "So, so there's this problem with the follow the least lazily that it's suboptimal, and the problem with the shrinking dot board algorithm is that it can't always be efficiently implemented because it's just a variant of exponentially weighted average well for the for the path problem, this can be efficiently implemented, but not always, not for every every decision set of interest, so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we have in this paper is that for the experts case, we retrieve the usual guarantees and for the combinatorial case we get an upper bound and on a number of switches that scales only with them.",
                    "label": 0
                },
                {
                    "sent": "So with the length of the longest path.",
                    "label": 0
                },
                {
                    "sent": "An depends on logarithmically on the so.",
                    "label": 0
                },
                {
                    "sent": "So this is much better.",
                    "label": 0
                },
                {
                    "sent": "The regret bounds are slightly worse than the shrinking dartboard algorithm.",
                    "label": 0
                },
                {
                    "sent": "But but this is an efficient algorithm, so this can always be efficiently implemented.",
                    "label": 0
                },
                {
                    "sent": "So you understand the target on the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To talk about the well known FPL algorithm that most of you might probably know.",
                    "label": 0
                },
                {
                    "sent": "So this is how it works.",
                    "label": 0
                },
                {
                    "sent": "In around you draw some.",
                    "label": 0
                },
                {
                    "sent": "You draw some perturbations from scratch, IID perturbations, and then you perturb all the previous losses that you observed so far, and then pick the leader.",
                    "label": 1
                },
                {
                    "sent": "The big, the big decision that minimizes these perturb losses.",
                    "label": 0
                },
                {
                    "sent": "So so this is a really simple and nice algorithm, But the problem with that if you use IID perturbation, so if you draw a new perturbations in each round, you might end up switching all the time.",
                    "label": 0
                },
                {
                    "sent": "So this says absolutely no guarantees about.",
                    "label": 0
                },
                {
                    "sent": "Think about a number of switches between predictions.",
                    "label": 0
                },
                {
                    "sent": "So we came up with the idea.",
                    "label": 0
                },
                {
                    "sent": "Alfred.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Facing these these perturbations by random walks.",
                    "label": 1
                },
                {
                    "sent": "So what you what we ended up doing is that.",
                    "label": 0
                },
                {
                    "sent": "We retain the perturbation from the previous round and then we add just a small additional perturbation to it, which is just a Rademacher random variable, so we end up with having random walk perturbation, symmetric random walks and this way we can hope that we can guarantee small number of switches between the experts.",
                    "label": 0
                },
                {
                    "sent": "So for analyzing this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Simple expert setting.",
                    "label": 0
                },
                {
                    "sent": "You first have to observe that the expected regret is explicitly upper bounded by two times the number of times.",
                    "label": 0
                },
                {
                    "sent": "The predictions are switched, so this is very easy to show by some standard arguments and then by intuition it is enough to study the case where you have no losses at all.",
                    "label": 0
                },
                {
                    "sent": "Because this is the case where the number of switches is maximized in expectation for symmetry reasons.",
                    "label": 0
                },
                {
                    "sent": "So what we what we have to do is is bound the number of leader switches in the parallel random walks.",
                    "label": 0
                },
                {
                    "sent": "So why we hope that this would work?",
                    "label": 0
                },
                {
                    "sent": "That is well known for for two random walks the number of switches is bounded by square root of N with high probability.",
                    "label": 0
                },
                {
                    "sent": "So we can have both high probability bounds on the number of switches and the regret at the same time so but.",
                    "label": 0
                },
                {
                    "sent": "The question is what happens if we increase the number of random walks?",
                    "label": 0
                },
                {
                    "sent": "So we first have to make this observation is that as we as we increase the number of random walks, what happens is that.",
                    "label": 0
                },
                {
                    "sent": "The situation gets very dense around 0, so most of posted a random walks are going to concentrate around zero and there are just going to be a few guys fighting over the 1st place at any given time.",
                    "label": 0
                },
                {
                    "sent": "So if you just increase the number of random walks even further you can see that there are just just a few guys fighting over there and and most of the random walks are just clustered around 0.",
                    "label": 0
                },
                {
                    "sent": "So what we study?",
                    "label": 0
                },
                {
                    "sent": "Is this so called lead back?",
                    "label": 0
                },
                {
                    "sent": "Which is which is the set of guys that are fighting over fighting over the 1st place at any given time?",
                    "label": 0
                },
                {
                    "sent": "So this is the set is the set of experts that have positive probability of taking over the lead at the next time step and.",
                    "label": 0
                },
                {
                    "sent": "And this is this is the result that we have, so the probability of delete that consisting of more than one guy.",
                    "label": 0
                },
                {
                    "sent": "So if there are any competitor, there is his upper bounded by this quantity.",
                    "label": 0
                },
                {
                    "sent": "So this scales with the square root of logarithm of the of the number of random walks.",
                    "label": 0
                },
                {
                    "sent": "So it just depends very very mildly on the number of random walks.",
                    "label": 0
                },
                {
                    "sent": "And I have a short slide about how the proof works for.",
                    "label": 0
                },
                {
                    "sent": "Fergusons case when when the increments of the random walks are Goshen, so.",
                    "label": 0
                },
                {
                    "sent": "So it's a very, very simple argument that you can workout in a couple of lines so that the probability of delete bag being larger than one is upper bounded by some constant over T plus the expectation of the maximum.",
                    "label": 0
                },
                {
                    "sent": "Of the largest random walk over T. So this is a very simple argument, and since we know that the bank system is the expectation of the maximum is is at most sqrt 2 times log D sqrt T. So this gives a nice result.",
                    "label": 0
                },
                {
                    "sent": "And this is what makes it possible for us to prove the.",
                    "label": 0
                },
                {
                    "sent": "Prove the regret bound is so well this analysis.",
                    "label": 0
                },
                {
                    "sent": "So this is just a simplification.",
                    "label": 0
                },
                {
                    "sent": "The same proof can be carried out for Rademacher distributions where you can get some tighter bounds as well.",
                    "label": 0
                },
                {
                    "sent": "But essentially it's just the same and.",
                    "label": 0
                },
                {
                    "sent": "So here's the main result.",
                    "label": 0
                },
                {
                    "sent": "It's not surprising after all that I've told you so.",
                    "label": 0
                },
                {
                    "sent": "So we regret this upper bounded by by the number of switches, and this is this is of the optimal order.",
                    "label": 0
                },
                {
                    "sent": "So the question is.",
                    "label": 0
                },
                {
                    "sent": "Well, how can you generalize this whole thing to the combinatorial action action set where where M is larger than one?",
                    "label": 0
                },
                {
                    "sent": "For example, the shortest path problem where you have longer path faster than one.",
                    "label": 0
                },
                {
                    "sent": "So in this case for convenience we by standard use Gaussian perturbations.",
                    "label": 0
                },
                {
                    "sent": "Anne, it is also possible to define the lead back as the set of experts that have a positive probability of taking the lead.",
                    "label": 0
                },
                {
                    "sent": "And the lemma here is exactly identical to what we had in the experts case.",
                    "label": 0
                },
                {
                    "sent": "The only difference is that everything is multiplied by M which is.",
                    "label": 0
                },
                {
                    "sent": "Which is the length of the longer path.",
                    "label": 0
                },
                {
                    "sent": "An proof?",
                    "label": 0
                },
                {
                    "sent": "Well, it has the exact same form.",
                    "label": 0
                },
                {
                    "sent": "This expression has the exact same form as as in the experts case, but the difference is that, well, so the proof of that is just three lines, and the proof of this is 3 pages, so you need to pull up lots of tricks while in the process, and the main difficulty is that in this, in this case you don't have to.",
                    "label": 0
                },
                {
                    "sent": "You don't have to control the number of switches in the parallel independent random walks, but now you have.",
                    "label": 0
                },
                {
                    "sent": "Combinatorial number of dependent random walks, so this is the main difficulty here, but.",
                    "label": 0
                },
                {
                    "sent": "But perhaps surprisingly, this is the same result, and this leads to our main results concerning this case.",
                    "label": 0
                },
                {
                    "sent": "So the number of number of experts which is now M times whatever we had before and they regret is is another thing multiplied by another room.",
                    "label": 0
                },
                {
                    "sent": "So it's M squared.",
                    "label": 0
                },
                {
                    "sent": "It's slightly worse than the best bound for exponential weighting or shrinking dartboard.",
                    "label": 0
                },
                {
                    "sent": "Sort of sort of main observation is that it depends very mildly on the number of dimensions.",
                    "label": 0
                },
                {
                    "sent": "So so these are mainly our results, but we have a number of future directions so.",
                    "label": 0
                },
                {
                    "sent": "So the most interesting thing about this algorithm that it has absolutely no parameters.",
                    "label": 0
                },
                {
                    "sent": "So as you see in the random walks were just Rademacher random walks and they were not scaled by any step size or any learning rate.",
                    "label": 0
                },
                {
                    "sent": "This just happens to be square root of log D. Whatever small perturbations you use.",
                    "label": 0
                },
                {
                    "sent": "But well, it's it's a.",
                    "label": 0
                },
                {
                    "sent": "It's an interesting thing to look at the case where the losses tend to be small and.",
                    "label": 0
                },
                {
                    "sent": "So in this situation, you probably have to scale down the random walks to be compareable to the thoughts of losses.",
                    "label": 0
                },
                {
                    "sent": "And, well, the question is how do you get high priority bands on both both the number of switches and the regret.",
                    "label": 0
                },
                {
                    "sent": "So right now this is very, very easy to have for two random walks, but.",
                    "label": 0
                },
                {
                    "sent": "Probably can be done for more than two random walks.",
                    "label": 0
                },
                {
                    "sent": "It's an interesting thing, but it's also important to note that this is the first target on this property, so everything that we had before was either high probability on the regret and expectation on the number of switches, or high probability bound in a more switches an expectation on the regret.",
                    "label": 0
                },
                {
                    "sent": "So it's very interesting to see that if this trade off is inherent or not.",
                    "label": 0
                },
                {
                    "sent": "So whether this is necessary or you can do better, but for the equals two we already have this so.",
                    "label": 0
                },
                {
                    "sent": "And the bounds can be further improved if you're not looking at the probability of switching between experts, but what about the expectation of the difference between between the consecutive predictions?",
                    "label": 0
                },
                {
                    "sent": "Because this way you can.",
                    "label": 0
                },
                {
                    "sent": "Probably get some more sensible results and improve your graph guarantees as well so.",
                    "label": 0
                },
                {
                    "sent": "My my intuition is that you can chop up chop off a sqrt M, but not much more.",
                    "label": 0
                },
                {
                    "sent": "And of course, an interesting question is where would this idea work when you have bandit feedback and so you don't get to observe the losses on each edge?",
                    "label": 0
                },
                {
                    "sent": "But you have some sort of bandit feedback, but but right now it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Doesn't seem very promising, so Nicole has some initial negative results about this situation, and but we also we remain hopeful that this would work in that situation, so.",
                    "label": 0
                },
                {
                    "sent": "So this is it.",
                    "label": 0
                },
                {
                    "sent": "And thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}