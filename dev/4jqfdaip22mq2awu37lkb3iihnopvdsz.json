{
    "id": "4jqfdaip22mq2awu37lkb3iihnopvdsz",
    "title": "Multi-Label Relational Neighbor Classification using Social Context Features",
    "info": {
        "author": [
            "Xi Wang, Department of Electrical Engineering and Computer Science, University of Central Florida"
        ],
        "published": "Sept. 27, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2013_wang_social_context/",
    "segmentation": [
        [
            "Hi everyone, my name is Sheila and today I'm going to present our paper multi label relational Neighbor classification using social context feature and this is joint work with my advisor Doctor Guyton 6 anchor from University of Central Florida so."
        ],
        [
            "The network data, such as data set crop from social network, bibliographic network, biological and other information network has attracted a lot of attention during the past decade and relational learning has received huge success in solving classification problem network data.",
            "However, those conventional relational classification models only focusing on single label classification.",
            "So which assumes all the instance in the network only have one single label.",
            "However, this is not actually true in most of real world datasets.",
            "So for example in the like graph work, the document have more than.",
            "Can have multiple topics and in scientific collaboration network authors can have multiple research interests.",
            "So and also the connections between instance in this multi label network, usually driven by various causal reasons, so authors are seeking to collaborate with other coauthors for different kind of projects, so the classification problem in this scenario is much more complex.",
            "So the."
        ],
        [
            "Problem we are solving in this paper can be regarded as a node classification problem.",
            "So the input is the natural structure, that is the connectivity in formation of the network and also the labels of some actors in the network and we want to predict the other labels of other actors in the network."
        ],
        [
            "So one of the most property for networks resulting from social process is harmfully.",
            "That is not with.",
            "Similar labels are more likely to be connected and relational learning models enhance the trackability of computing the joint probability of the data by making the 1st order Markov assumption.",
            "That is, the label of 1 node depending on that of its neighbors in the network so.",
            "Traditional relational models are built on the labels of the neighbors and by making use the correlation label correlation of the linked instance and the prediction made using collective inference.",
            "So the contribution of."
        ],
        [
            "Our paper is we introduce a new multi label iterative relational label classifier to solve the node classification problem.",
            "Multi relational network and our model is improved by introducing our class propagation probability, which use the social context feature extracted from network structure and we will demonstrate that by using the social context features.",
            "Our proposed model can improve the classification performance on several Real World Collaborative network."
        ],
        [
            "So here I first give a brief introduction about what is relational label classifier.",
            "It is very simple but very effective classifier.",
            "Which make predictions of the target nodes based only on the labels of its neighbors.",
            "So here I give a training graph.",
            "And we are predicts the labels of the target nodes based on the class of its neighbors who have the maximum maximum amount of votes.",
            "So the prediction continues its richly until by the end all the labels in the network is a stable stable."
        ],
        [
            "So the weighted world relational neighbor classifier extends the traditional relational label classifier by using the class problem class probability of its neighbors instead of using the hard labeling.",
            "So it estimates the prediction probability by the weighted mean of the class probability of the nodes neighbors."
        ],
        [
            "So the problem is when we directly apply the relational neighbor classified into this multi relational network.",
            "Because in multi relational network we have nodes who have more than one class labels.",
            "So by directly applied the relational label classifier will end up with a lot of nodes who have multiple levels, especially with the nodes who shall directly connection with the.",
            "Overlapping nodes, that is nodes with multiple labels, so actually functionally.",
            "Unfortunately this is not correct, so the idea of our paper is we during the during the label propagation procedure, instead of giving equal probability of each class, we want to maintain a higher class probability of the in this case of the red class.",
            "All the green class so we can offer more accurate results by the end and if we could use this class problem propagation probability, what is the best better way to calculate this class probability?"
        ],
        [
            "So even though we can use some of the intrinsic feature like the words in the net in the document to calculate this class propagation probability, we found the network structure itself is very informative.",
            "So the connection in human networks, mainly application driven and the links Internet internetwork, possess a strong connection between the nodes class.",
            "So for instance.",
            "If two authors have been collaborating on a KDD paper, there is higher chance that these two authors are all interested in data mining area.",
            "So the link information here can help us solving node classification problem so.",
            "But however, since the age class information is not always available in most of the data set unsupervised clustering methods can be adopted here.",
            "To partition the links into different groups."
        ],
        [
            "So in our paper we use the scalable Age Clustering method proposed by time and others in 2009 so.",
            "Firstly, we we each age is represented in a feature based format where the age where the features are represented by the node index.",
            "And then we use K means clustering on the ages, features and finally our social features are constructed based on the age cluster IDs.",
            "That's the node is involved with."
        ],
        [
            "So here I give an example of the result of each clustering, a subset of DLP data set with 95 instance.",
            "The ages are clustered into 10 different groups and each of which is showing in a different color.",
            "So intuitively the node with higher degree are more likely to be involved in two different groups and we can see from this figure that the links connected with this.",
            "Overlapping nodes are more likely to be participate in two different into different clusters."
        ],
        [
            "So our proposed method consists of the following steps.",
            "So firstly we initially the class reference vector which is defined based on the weighted sum of the node social features in that class.",
            "And then we calculate the nodes class propagation probability based on the node social features and the class reference features.",
            "So the same similarity can be calculated using any vector based.",
            "Similarity measure such as the cosine or inner product and so on.",
            "So the SCRN method estimates the class."
        ],
        [
            "IS membership of the target node based on three different parts?",
            "And the first one is class propagation probability.",
            "The second one is a similarity between the connecting nodes or the link weights.",
            "And the last one is class probability of its neighbors.",
            "So the actually the last two having already have been already adopted in the traditional relational neighbor classifier.",
            "Here we introduce the class propagation probability and we want to demonstrate that by introducing this class problem propagation probability, we can reduce the incorrectness during the label propagation procedure."
        ],
        [
            "So our post model is make predictions.",
            "It's ritually, and during each iteration we update the.",
            "Both the class reference vector as well as the notes as well as the nodes class propagation probability based on the labels of both both the training instance and the testing instance in and in the current iteration and the prediction stops when when all the labels in the network stable or the maximum amount of iterations is reached."
        ],
        [
            "So here I showing our result of our SCR method on synthetic multi label network with 1000 node and 30 two different classes.",
            "Sorry, is it actually the black nodes in the center?",
            "Other nodes with multiple labels and our method is richly predicted.",
            "Labels of the rest of nodes and we can see that after 15 iterations the labels in the networks are quite stable."
        ],
        [
            "So further evaluates the performance classification performance of our model.",
            "We select three different kinds of datasets.",
            "The first one is DLP date data set.",
            "We select 15 represented conference in six research area, ranging from database data mining to compute vision and machine learning."
        ],
        [
            "The second one is the IMDb data set extracted from 2000 two 2010 and we use 27 different candidates movie genres as the class label.",
            "And the last one is a subset."
        ],
        [
            "Out of YouTube data set with 15 hundred, $15,000 and 47 different interest groups as a class label."
        ],
        [
            "The comparative method used in this paper are the first one is a scalable age clustering method and the second one is the weighted worlds relational label classifier.",
            "The prior method make make estimation of the class based on the fraction of the nodes based on the fraction of the nodes in the training pool who which are in that class and the random methods.",
            "Make predictions by randomly select class in the class pool."
        ],
        [
            "So the size of social features base is set to be.",
            "1002 DBLP and YouTube data set, and 10,000 two IMDb data set.",
            "This gives the best performance of each clustering method and offers a fair comparison between our method and age clustering method.",
            "Our class propagation probability is calculated using generalized histogram intersection kernel and this gives us the best performance.",
            "The we also adopted the relaxation labeling.",
            "Into the collective inference framework for both SCRN and wbre.",
            "We assume since our problem is essentially multi label classification problem, we assume the number of labels for the taxi node is known and this scheme has already been adopted in some previous work."
        ],
        [
            "Instead of using the traditional cross validation methods, we use the network cross validation method to reduce the overlap between the test samples.",
            "An hour classification performance is evaluated based on micro F1 macro file from an harming loss.",
            "So the macro FF1 anmc off one F1 are the method based on the precision and recall the homologues directly.",
            "Cap compare the Hamming distance between their predicted labels and the ground truth."
        ],
        [
            "So here I'm showing the result Michael F1 result on DLP data set the size of the training samples range from 5% to 30%.",
            "We can see that the.",
            "The method based on considering the label correlation of the links modes such as SCR in age, clustering and depth varying perform perform better than the other two.",
            "By directly using the label correlation WVR and perform better than the each clustering method, an hour method by using considering the social feature similarity, we perform the best.",
            "And here is."
        ],
        [
            "The Mac of F1 result and we get the quite similar result.",
            "Our CRM method consistently perform the best.",
            "So far."
        ],
        [
            "Timing loss things.",
            "The lower the lower the value, the better, the more accurate we got, so we can see that our method also gives the best result of both.",
            "Both WBR in an age chemistry."
        ],
        [
            "So here I just showing the results of the Hamming loss result, IMDb data set and the training sample are from 1% to 20% and our model perform the best, especially when the training samples are small."
        ],
        [
            "So we have a very interesting finding that in YouTube data set all these three methods perform quite equally and in some cases the edge clustering method may be performed better than the other two.",
            "So we attributed this to the fact that the YouTube data set is not essentially collaborative network and the number of class is much higher than the other two, so an.",
            "So the low label correlation in the network can limit the performance of both WVI and our method."
        ],
        [
            "So to sum up, so in this in this paper we solving the node classification problem in multi relational network when the links are heterogeneous and the nodes can belong to multiple groups and we propose a method which tackle the problem went directly apply the relation label, classify in multi relational network by introducing a class propagation probability that considering the now social.",
            "Feature similarity and by several experiment on several real world datasets.",
            "We demonstrate that our proposed method can improve the classification problem performance over several benchmarks.",
            "So our open source implementation of SCR is available at Google Code Repository.",
            "And here are the reference of our."
        ],
        [
            "Paper.",
            "And thank you for listening."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, my name is Sheila and today I'm going to present our paper multi label relational Neighbor classification using social context feature and this is joint work with my advisor Doctor Guyton 6 anchor from University of Central Florida so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The network data, such as data set crop from social network, bibliographic network, biological and other information network has attracted a lot of attention during the past decade and relational learning has received huge success in solving classification problem network data.",
                    "label": 0
                },
                {
                    "sent": "However, those conventional relational classification models only focusing on single label classification.",
                    "label": 1
                },
                {
                    "sent": "So which assumes all the instance in the network only have one single label.",
                    "label": 0
                },
                {
                    "sent": "However, this is not actually true in most of real world datasets.",
                    "label": 0
                },
                {
                    "sent": "So for example in the like graph work, the document have more than.",
                    "label": 1
                },
                {
                    "sent": "Can have multiple topics and in scientific collaboration network authors can have multiple research interests.",
                    "label": 0
                },
                {
                    "sent": "So and also the connections between instance in this multi label network, usually driven by various causal reasons, so authors are seeking to collaborate with other coauthors for different kind of projects, so the classification problem in this scenario is much more complex.",
                    "label": 1
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem we are solving in this paper can be regarded as a node classification problem.",
                    "label": 0
                },
                {
                    "sent": "So the input is the natural structure, that is the connectivity in formation of the network and also the labels of some actors in the network and we want to predict the other labels of other actors in the network.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the most property for networks resulting from social process is harmfully.",
                    "label": 0
                },
                {
                    "sent": "That is not with.",
                    "label": 0
                },
                {
                    "sent": "Similar labels are more likely to be connected and relational learning models enhance the trackability of computing the joint probability of the data by making the 1st order Markov assumption.",
                    "label": 1
                },
                {
                    "sent": "That is, the label of 1 node depending on that of its neighbors in the network so.",
                    "label": 1
                },
                {
                    "sent": "Traditional relational models are built on the labels of the neighbors and by making use the correlation label correlation of the linked instance and the prediction made using collective inference.",
                    "label": 1
                },
                {
                    "sent": "So the contribution of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our paper is we introduce a new multi label iterative relational label classifier to solve the node classification problem.",
                    "label": 1
                },
                {
                    "sent": "Multi relational network and our model is improved by introducing our class propagation probability, which use the social context feature extracted from network structure and we will demonstrate that by using the social context features.",
                    "label": 0
                },
                {
                    "sent": "Our proposed model can improve the classification performance on several Real World Collaborative network.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here I first give a brief introduction about what is relational label classifier.",
                    "label": 0
                },
                {
                    "sent": "It is very simple but very effective classifier.",
                    "label": 0
                },
                {
                    "sent": "Which make predictions of the target nodes based only on the labels of its neighbors.",
                    "label": 0
                },
                {
                    "sent": "So here I give a training graph.",
                    "label": 1
                },
                {
                    "sent": "And we are predicts the labels of the target nodes based on the class of its neighbors who have the maximum maximum amount of votes.",
                    "label": 1
                },
                {
                    "sent": "So the prediction continues its richly until by the end all the labels in the network is a stable stable.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the weighted world relational neighbor classifier extends the traditional relational label classifier by using the class problem class probability of its neighbors instead of using the hard labeling.",
                    "label": 0
                },
                {
                    "sent": "So it estimates the prediction probability by the weighted mean of the class probability of the nodes neighbors.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem is when we directly apply the relational neighbor classified into this multi relational network.",
                    "label": 0
                },
                {
                    "sent": "Because in multi relational network we have nodes who have more than one class labels.",
                    "label": 0
                },
                {
                    "sent": "So by directly applied the relational label classifier will end up with a lot of nodes who have multiple levels, especially with the nodes who shall directly connection with the.",
                    "label": 0
                },
                {
                    "sent": "Overlapping nodes, that is nodes with multiple labels, so actually functionally.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately this is not correct, so the idea of our paper is we during the during the label propagation procedure, instead of giving equal probability of each class, we want to maintain a higher class probability of the in this case of the red class.",
                    "label": 0
                },
                {
                    "sent": "All the green class so we can offer more accurate results by the end and if we could use this class problem propagation probability, what is the best better way to calculate this class probability?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So even though we can use some of the intrinsic feature like the words in the net in the document to calculate this class propagation probability, we found the network structure itself is very informative.",
                    "label": 0
                },
                {
                    "sent": "So the connection in human networks, mainly application driven and the links Internet internetwork, possess a strong connection between the nodes class.",
                    "label": 1
                },
                {
                    "sent": "So for instance.",
                    "label": 0
                },
                {
                    "sent": "If two authors have been collaborating on a KDD paper, there is higher chance that these two authors are all interested in data mining area.",
                    "label": 0
                },
                {
                    "sent": "So the link information here can help us solving node classification problem so.",
                    "label": 1
                },
                {
                    "sent": "But however, since the age class information is not always available in most of the data set unsupervised clustering methods can be adopted here.",
                    "label": 1
                },
                {
                    "sent": "To partition the links into different groups.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in our paper we use the scalable Age Clustering method proposed by time and others in 2009 so.",
                    "label": 1
                },
                {
                    "sent": "Firstly, we we each age is represented in a feature based format where the age where the features are represented by the node index.",
                    "label": 1
                },
                {
                    "sent": "And then we use K means clustering on the ages, features and finally our social features are constructed based on the age cluster IDs.",
                    "label": 0
                },
                {
                    "sent": "That's the node is involved with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here I give an example of the result of each clustering, a subset of DLP data set with 95 instance.",
                    "label": 0
                },
                {
                    "sent": "The ages are clustered into 10 different groups and each of which is showing in a different color.",
                    "label": 1
                },
                {
                    "sent": "So intuitively the node with higher degree are more likely to be involved in two different groups and we can see from this figure that the links connected with this.",
                    "label": 0
                },
                {
                    "sent": "Overlapping nodes are more likely to be participate in two different into different clusters.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our proposed method consists of the following steps.",
                    "label": 1
                },
                {
                    "sent": "So firstly we initially the class reference vector which is defined based on the weighted sum of the node social features in that class.",
                    "label": 1
                },
                {
                    "sent": "And then we calculate the nodes class propagation probability based on the node social features and the class reference features.",
                    "label": 1
                },
                {
                    "sent": "So the same similarity can be calculated using any vector based.",
                    "label": 0
                },
                {
                    "sent": "Similarity measure such as the cosine or inner product and so on.",
                    "label": 0
                },
                {
                    "sent": "So the SCRN method estimates the class.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "IS membership of the target node based on three different parts?",
                    "label": 0
                },
                {
                    "sent": "And the first one is class propagation probability.",
                    "label": 1
                },
                {
                    "sent": "The second one is a similarity between the connecting nodes or the link weights.",
                    "label": 0
                },
                {
                    "sent": "And the last one is class probability of its neighbors.",
                    "label": 1
                },
                {
                    "sent": "So the actually the last two having already have been already adopted in the traditional relational neighbor classifier.",
                    "label": 0
                },
                {
                    "sent": "Here we introduce the class propagation probability and we want to demonstrate that by introducing this class problem propagation probability, we can reduce the incorrectness during the label propagation procedure.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our post model is make predictions.",
                    "label": 0
                },
                {
                    "sent": "It's ritually, and during each iteration we update the.",
                    "label": 1
                },
                {
                    "sent": "Both the class reference vector as well as the notes as well as the nodes class propagation probability based on the labels of both both the training instance and the testing instance in and in the current iteration and the prediction stops when when all the labels in the network stable or the maximum amount of iterations is reached.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here I showing our result of our SCR method on synthetic multi label network with 1000 node and 30 two different classes.",
                    "label": 1
                },
                {
                    "sent": "Sorry, is it actually the black nodes in the center?",
                    "label": 0
                },
                {
                    "sent": "Other nodes with multiple labels and our method is richly predicted.",
                    "label": 1
                },
                {
                    "sent": "Labels of the rest of nodes and we can see that after 15 iterations the labels in the networks are quite stable.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So further evaluates the performance classification performance of our model.",
                    "label": 0
                },
                {
                    "sent": "We select three different kinds of datasets.",
                    "label": 0
                },
                {
                    "sent": "The first one is DLP date data set.",
                    "label": 0
                },
                {
                    "sent": "We select 15 represented conference in six research area, ranging from database data mining to compute vision and machine learning.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second one is the IMDb data set extracted from 2000 two 2010 and we use 27 different candidates movie genres as the class label.",
                    "label": 0
                },
                {
                    "sent": "And the last one is a subset.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out of YouTube data set with 15 hundred, $15,000 and 47 different interest groups as a class label.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The comparative method used in this paper are the first one is a scalable age clustering method and the second one is the weighted worlds relational label classifier.",
                    "label": 0
                },
                {
                    "sent": "The prior method make make estimation of the class based on the fraction of the nodes based on the fraction of the nodes in the training pool who which are in that class and the random methods.",
                    "label": 0
                },
                {
                    "sent": "Make predictions by randomly select class in the class pool.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the size of social features base is set to be.",
                    "label": 1
                },
                {
                    "sent": "1002 DBLP and YouTube data set, and 10,000 two IMDb data set.",
                    "label": 0
                },
                {
                    "sent": "This gives the best performance of each clustering method and offers a fair comparison between our method and age clustering method.",
                    "label": 0
                },
                {
                    "sent": "Our class propagation probability is calculated using generalized histogram intersection kernel and this gives us the best performance.",
                    "label": 1
                },
                {
                    "sent": "The we also adopted the relaxation labeling.",
                    "label": 1
                },
                {
                    "sent": "Into the collective inference framework for both SCRN and wbre.",
                    "label": 0
                },
                {
                    "sent": "We assume since our problem is essentially multi label classification problem, we assume the number of labels for the taxi node is known and this scheme has already been adopted in some previous work.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instead of using the traditional cross validation methods, we use the network cross validation method to reduce the overlap between the test samples.",
                    "label": 1
                },
                {
                    "sent": "An hour classification performance is evaluated based on micro F1 macro file from an harming loss.",
                    "label": 0
                },
                {
                    "sent": "So the macro FF1 anmc off one F1 are the method based on the precision and recall the homologues directly.",
                    "label": 0
                },
                {
                    "sent": "Cap compare the Hamming distance between their predicted labels and the ground truth.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I'm showing the result Michael F1 result on DLP data set the size of the training samples range from 5% to 30%.",
                    "label": 0
                },
                {
                    "sent": "We can see that the.",
                    "label": 0
                },
                {
                    "sent": "The method based on considering the label correlation of the links modes such as SCR in age, clustering and depth varying perform perform better than the other two.",
                    "label": 0
                },
                {
                    "sent": "By directly using the label correlation WVR and perform better than the each clustering method, an hour method by using considering the social feature similarity, we perform the best.",
                    "label": 0
                },
                {
                    "sent": "And here is.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Mac of F1 result and we get the quite similar result.",
                    "label": 0
                },
                {
                    "sent": "Our CRM method consistently perform the best.",
                    "label": 0
                },
                {
                    "sent": "So far.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Timing loss things.",
                    "label": 0
                },
                {
                    "sent": "The lower the lower the value, the better, the more accurate we got, so we can see that our method also gives the best result of both.",
                    "label": 0
                },
                {
                    "sent": "Both WBR in an age chemistry.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I just showing the results of the Hamming loss result, IMDb data set and the training sample are from 1% to 20% and our model perform the best, especially when the training samples are small.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a very interesting finding that in YouTube data set all these three methods perform quite equally and in some cases the edge clustering method may be performed better than the other two.",
                    "label": 0
                },
                {
                    "sent": "So we attributed this to the fact that the YouTube data set is not essentially collaborative network and the number of class is much higher than the other two, so an.",
                    "label": 0
                },
                {
                    "sent": "So the low label correlation in the network can limit the performance of both WVI and our method.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to sum up, so in this in this paper we solving the node classification problem in multi relational network when the links are heterogeneous and the nodes can belong to multiple groups and we propose a method which tackle the problem went directly apply the relation label, classify in multi relational network by introducing a class propagation probability that considering the now social.",
                    "label": 0
                },
                {
                    "sent": "Feature similarity and by several experiment on several real world datasets.",
                    "label": 1
                },
                {
                    "sent": "We demonstrate that our proposed method can improve the classification problem performance over several benchmarks.",
                    "label": 0
                },
                {
                    "sent": "So our open source implementation of SCR is available at Google Code Repository.",
                    "label": 1
                },
                {
                    "sent": "And here are the reference of our.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper.",
                    "label": 0
                },
                {
                    "sent": "And thank you for listening.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}