{
    "id": "s6ewuagmpmxoe5zyjduaxqvadbntphh3",
    "title": "Inference for Networks",
    "info": {
        "author": [
            "Peter J. Bickel, Department of Statistics, UC Berkeley"
        ],
        "published": "July 30, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/mlss09us_bickel_in/",
    "segmentation": [
        [
            "And the speaker today is.",
            "Peter Bickel from UC Berkeley.",
            "Well, thank you very much Martha.",
            "It's a great pleasure to be here.",
            "I wish I could have been here for longer, but I sent some students will then tell me what all the exciting things that happened.",
            "So.",
            "What I'd like to talk to you about is a an area which has actually.",
            "Grown in interest in a number of communities.",
            "In particular, Interestingly enough, the physicists have are very active in this, so so they are busy constructing.",
            "Network models of various types and her modularity's and I'll talk about some of those, and then I'll try to show you."
        ],
        [
            "Now this can be put in to a.",
            "More probabilistic framework and perhaps help understanding what's going on with it.",
            "So the outline is that I'm going to talk about the problem that most people talk about, which is the sub community identification problem and what modularity czar?",
            "And then a nonparametric probability model for unlabeled graphs and its relation to things called block models which have appeared in the in the literature and then issues with maximum likelihood.",
            "And then the consistency of a particular type of modularity.",
            "The Newman Girvan, and then a bit of talk about algorithms, simulations and real data and some discussion.",
            "So."
        ],
        [
            "OK, so here's an example of.",
            "From a paper by Mark Newman of the University of Michigan there's a physicist.",
            "Of the kind of thing that is interesting we have you have in this case the circles and squares represent members of a karate club.",
            "And the links correspond to people knowing each other or having some other contact with each other.",
            "And the idea is that there are sub communities which you want to identify in this graph simply just from knowing the relationships between individuals.",
            "And it turns out that in fact.",
            "I don't know before the factor after the fact that this this club sort of had a split.",
            "And at some point right, there really were two distinct groups of people with different loyalties.",
            "If you want who formed and this is the result of using something called.",
            "Well, actually type of modularity introduced by Newman and a lot of people agree with this.",
            "With this kind of split, the dotted line corresponds to a principal component of a matrix.",
            "It's not spectral graph partitioning, but something something else."
        ],
        [
            "The second is.",
            "Again, more of a social science graph.",
            "But this is ethnicities of.",
            "Of students in high and high school.",
            "And again you the links correspond to whether the students know of each other.",
            "And this is the partition that the the.",
            "The black squares, the Hispanics, etc.",
            "The squares, the diamonds, the circles correspond to known ethnicities, and these were put on afterward, so to speak.",
            "So the two communities are actually sort of identified by the blobs, and as you can see there is pretty much agreement just on the basis of who knew whom?",
            "S2, which community one falls into.",
            "There's an interesting question about the people who are common to both.",
            "And in fact, I think that actually reflects.",
            "Reality, at least in my experience with my kids who were at school in Berkeley and the crossover, unfortunately, was largely a class crossover, right?",
            "So people with middle class parents would tend to affiliate.",
            "More with the with sort of the largely faculty Brat group of students."
        ],
        [
            "OK, so here's the mathematical formulation of this kind of problem.",
            "You're given an undirected graph VE.",
            "And the vertices are arbitrarily labeled right.",
            "You're not using information about who, who is who.",
            "You have an adjacency matrix for this graph, so AIJ is one of the edge between I&J.",
            "Is there is an edge between J and 0 otherwise and think of the edge between Andre as being some indication of relationship."
        ],
        [
            "And the problem is that there is an unknown number of what you can think of as subcommunities.",
            "Which composed this community V. Vertices V1 through VK and let's pretend that K is known.",
            "Of course, in practice it often isn't.",
            "And the problem is to determine the VJ using only a."
        ],
        [
            "So here's the approach that has been as I said, come mainly out of the physics community.",
            "Proposed by Newman and Girvin in physics Review E in 2004.",
            "And basically it's.",
            "It's a function which depends of course on the adjacency matrix and on a putative partition of the group.",
            "Right, so E corresponds to a labeling of the members of the group.",
            "So in this case the it's sort of complicated to read all this, but let me just tell you the OKK corresponds to, so you have a putative labeling of groups.",
            "OK, corresponds to relationships between members in the group.",
            "So OKK is between indicates Group D plus is simply the total number of edges which is twice sorry for the sum of the degrees and that's twice the number of edges between all nodes.",
            "Because he changes kind of twice.",
            "And so DK E / D plus squared, which is subtracting is a kind of expected.",
            "I mean, that's the motivation that Newman gives, and the expected is, roughly speaking, suppose that you simply made the assignment at random.",
            "And the assignment was made according to the degree of the individual proportional to the degree of the individual.",
            "So the OK K / D Plus is the observed.",
            "The DKE over D plus squared is the expected in some sense, although both are dependent upon what he is.",
            "OK."
        ],
        [
            "Now there's an entirely different line of approach which.",
            "Is older comes goes back to the early 80s and which came from the social science literature, where of course the types of graphs that I just showed at the beginning.",
            "Came from and that is that you think of communities as have big labels.",
            "Corresponding Community C1 CN you don't know what the labels are and you have a multinomial with unknown parameters.",
            "Pi one Pi K There K communities.",
            "And the the probability and so the story that you tell yourself is, first of all, that the labels are assigned.",
            "Community labels are assigned to the members Independantly according to this multinomial.",
            "And then given the labeling right, then the probability of an edge.",
            "Given the community membership of the two members.",
            "Is again unknown, but a fixed quantity pabs.",
            "So and so, and everything is in their condition independent.",
            "So the probability of having no edge at all is 1 minus that sum.",
            "The most.",
            "Primitive model of this type of course goes back goes way back.",
            "I don't know how far back but it is treated mathematically in great detail.",
            "Beier, dishon, Rennie.",
            "And that's the case.",
            "We have only one community.",
            "Right, so basically what you do is for any two individuals who put in an edge with probability P and don't put in an ad with probability 1 -- P. And then there's a whole theory about you know the structure of these communities, that there's a phase transition in PP goes above a certain point you get a giant connected component.",
            "For awhile people used the order any models to try to work with, but what they found is that in fact they didn't correspond to many of the properties mathematical properties of air trainee.",
            "As you let end go to Infinity, did not correspond to.",
            "Graphs that were observed."
        ],
        [
            "OK.",
            "There is a frequentist approach.",
            "Then, if you believe in this model.",
            "To this problem that you basically simply do maximum likelihood on these parameters.",
            "And you compute the likelihood by YM because what you don't know where the labels.",
            "If you knew the labels, then of course the the structure is very simple.",
            "But not knowing the labels you've got a problem.",
            "And then you compute P hat and Pi hat and then you can just simply assign labels according to Bayes rule for the conditional probabilities.",
            "And you maxify you, classified by maximizing the probability, CIPS a given API.",
            "In principle this looks terrible because there are two to the NTH possible assignments of labels.",
            "But in practice, so the problem is NP complete, sorry.",
            "Well, you don't hear me.",
            "I'm sorry I'm so sorry.",
            "Is it better?",
            "This is the one to turn this on if we can.",
            "Now it works alright.",
            "Well, you did what, that's it?",
            "OK, thank you very much and I apologize.",
            "So do you want me to go back at all to I shout loud enough so that most of you at least.",
            "So in practice, however.",
            "The places I've not done anything.",
            "Low battery, precisely that's what it's telling us.",
            "So can this be turned on and I'll use this, that's OK.",
            "Yes, yes yes, but is it is is the big Mike on.",
            "OK.",
            "There's always something that happens at any talk.",
            "You know.",
            "It's technology always.",
            "Gives you trouble.",
            "OK, so so.",
            "So that's the story.",
            "So in theory this is quite difficult to do.",
            "In practice."
        ],
        [
            "It's not so bad.",
            "You basically do a swapping algorithm.",
            "You have an initial and you have an initial assignment of.",
            "Identity's and then you swap from one community to the other and you see if it goes up and you keep on following that.",
            "And this actually seems to converge fairly quickly.",
            "It is not a unimodal surface but you know you try it with a bunch of random starts and and it behaves OK. Um?"
        ],
        [
            "OK, so that's more or less what the.",
            "The situation is coming on.",
            "The one hand from the physics literature, which I should say, the reason that there's been considerable interest.",
            "Recently has been of course not because of so much of the social science aspects, but becausw of the Internet, for example.",
            "So so you know you have, we now have situations where you have very large graphs where you're interested in Community structure.",
            "And I'll have an example like that.",
            "A bit later, but.",
            "Basically what I wanted to do or what are you and I, my collaborator, who was on the 1st slide.",
            "Have wanted to do and was too.",
            "To try to see if we couldn't get something which is like a nonparametric model.",
            "For graphs, which is analogous to the nonparametric model you're all familiar with in, say, classification and machine learning.",
            "Well, to do that you have to get some sort of notion of what's the analogue of IID.",
            "And what's the analogue of the population?",
            "Well, there's a very natural characterization.",
            "Which actually was studied in David oldest.",
            "His thesis in 1983, and there's a book which appeared recently by Kahlenberg, which I think amplifies on it.",
            "There was some problems, I think with all this is original argument, but basically you say, well, OK, I have an unlabeled graph.",
            "I can imagine this being infinite that corresponds to a population.",
            "And then the question is what do I mean by the thing being unlabeled?",
            "And that the information is coming entirely from the relations?",
            "And the answer I think is pretty clear that if you so now we have a joint probability distribution on this infinite matrix.",
            "Right call it P. And it seems clear that that's intuitively to satisfy this requirement that you know the labels shouldn't mean anything.",
            "It should be true that if you take a permutation.",
            "Of the indices.",
            "The distribution of the law of a pie.",
            "I Pi J the same permutation should be the same as the distribution of the law of AIJ.",
            "And when I say AIG or a pipe, I don't just mean that random variable, I mean that whole huge infinite array.",
            "And.",
            "What old is showed?",
            "Is a very beautiful result, which in retrospect seems intuitive.",
            "Which is that any such probability distribution?",
            "Can be represented as follows.",
            "You have a function G. Which goes from the unit interval to the 4th power.",
            "To 01.",
            "And AIJ which is the indicator of whether you have a link or not, is a function of Alpha, cick, CJ and AJ.",
            "Where Alpha, Xywrite, CJ and eight IJ are all a huge group of IID U01 variables.",
            "They don't have to be uniform number one.",
            "Clearly, since G is arbitrary right, there can be any transform of those, but that's the representation.",
            "And if you think about it, one of those variables plays a special role, namely the Alpha.",
            "The Alpha is really a choice of function.",
            "And it is very much.",
            "There's an analogous theorem which I think probably many of you know, called Definitely's theorem.",
            "Which tells you that if you have a sequence of exchangeable random variables.",
            "An infinite sequence of exchangeable random variables.",
            "Let's say taking the value 01 that was the original definite formulation.",
            "Any such sequence can be thought of as.",
            "A mixture.",
            "Of coin tossing sequences.",
            "Right, so you pick a P and then you just toss your coin with that PIID forever.",
            "That's how you get that.",
            "Well, it's pretty clear in that case, and in this case as well that.",
            "The if that you cannot identify the mixture.",
            "You cannot identify the mixing variable right because.",
            "A choice of Alpha is made and then all you can observe is the sequence of zeros and ones.",
            "So you can certainly find the P that has been picked.",
            "But you have no idea about how it's been picked.",
            "And that's true here too.",
            "And there's another characterization, by the way, that the IID sequences in definitely theorem are the extreme points of the set of all such distribution.",
            "That's a convex set of distributions, and this was in fact this line of research beyond definitely was initiated by my colleague, David Friedman.",
            "Unfortunately died recently, but anyway so.",
            "If you remove the Alpha.",
            "Oh, and I'm sorry I didn't mention, but of course it's obvious right, because the graph is unlabeled.",
            "This function G must be symmetric in psych CJ, right?",
            "'cause CJ Edge in the GI edge at the same?",
            "And Furthermore, the AIJ must be hji, but that's trivial.",
            "The critical point is the is the Alpha."
        ],
        [
            "And you can argue that you get a good icity just as you get with IID sequences.",
            "If and only if you drop the Alpha.",
            "And I now claim that it's not this quite plausible and reasonable to think.",
            "Of things like this, these GF CI CJ8I J as being ergotic.",
            "Probability distribution there what corresponds to IID variables in this context?",
            "Now.",
            "Alright, so we have IID variables, But we don't have to know what characterizes them, right?",
            "I mean, in the usual situation, there is a distribution function.",
            "This probability measure of one of them.",
            "Well in this case.",
            "It's clear that since the ADA I Jays are IID.",
            "Completely, So what really matters is what happens conditionally.",
            "If I give you the set of axes.",
            "So the function that at the very least, which determines the probability distribution is this function huv, which is a function of 201 variables.",
            "Variables on University one and which has to be symmetric again because of the requirement that the edges be be undirected."
        ],
        [
            "Now H as was noted, I think probably oldest noted recently in a paper of Diaconis and Janssen as well, which actually looked at some other things.",
            "H is not uniquely determined.",
            "And that's pretty clear, because if I take.",
            "A function, sigh.",
            "It's such a sigh of succeeding.",
            "U01 is itself U01, Another measure, a measure preserving transformation.",
            "Then H of science CYP SCIEX EJ.",
            "That whole big distribution is the same.",
            "You haven't changed it.",
            "Because the joint distribution of the SIAC sees is the same as it exceeds themselves.",
            "Well, that's a problem, but here is a proposal and I believe it's it's quite reasonable since I'm proposing it that there is a Canonical member.",
            "Of this family of functions.",
            "Basically consider the function G of you, which is the probability that your edge you have an edge between I&J given the vertex, the value of the latent variable at I.",
            "That's a function of 1 variable.",
            "Now you can think of GFC I I.",
            "That's a random variable.",
            "A single random variable.",
            "And there is a unique choice of G. We you know what Geoview is.",
            "It's the integral 0 to one HUVDV OK.",
            "There is a unique choice of G. Which is monotone, which is monotone increasing.",
            "And I claim that gives you a Canonical huv.",
            "And so the H Canonical of CEOC CJ is distributed L. Angie Canonical of H Canonical.",
            "Is increasing in you.",
            "And once you think about it, that's not too difficult to see."
        ],
        [
            "R. All you do is G of scii has a distribution capital F. Which obviously depends.",
            "Only on P on the probability distribution, right?",
            "So you know capital F that doesn't depend on H. It depends on the joint probability distribution variables.",
            "And assume that this continues.",
            "That's actually not necessary, but it's just convenient for writing this down.",
            "You define now a measure preserving PSI.",
            "Which is capital F of geoview.",
            "And you can check that that indeed send 01 variables into 01, because all you're doing is you're applying F inverse.",
            "Right?",
            "222 applying distribution F inverse to a variable which has distribution F. Capital F. And so, in fact, the Canonical G is nothing else but the inverse of you, and it's increasing.",
            "OK, so now what we have is really.",
            "A parametrization nonparametric parametrization if you want of the set of probability distributions."
        ],
        [
            "Now you can see the block models which were introduced earlier as approximations and rather reasonable approximations.",
            "That is, I simply partition up remember the pies in this case are the probabilities of the communities.",
            "So I generate the Pis by simply partitioning up the interval.",
            "Into in consecutive intervals of length Pi, One Pi 2 etc.",
            "And then I define.",
            "On the block.",
            "Define HUB to BHAB.",
            "If you're in the block defined by.",
            "You know the thing which gives you \u03c0 and \u03c0 J.",
            "And you can check that that's indeed a block model.",
            "And it's sort of intuitively clear that.",
            "You should be able to get the Canonical guy.",
            "You know, with enough data approximately by.",
            "By by taking blocks of equal probability.",
            "I make your life a little bit easier.",
            "1 / K. And then fit the block model, which takes values H maybe?",
            "On the block corresponding to to to EU UV square.",
            "A -- 1 / K. 2A or K B -- 1 / K to be over K. And then you choose KN to be growing slowly.",
            "And oh, and how do you do the Canonical bit?",
            "By the way, it's pretty clear, right?",
            "I mean all you do is I?",
            "I add up the summation Overby paisa BH baby.",
            "That's what my integral 0 to one.",
            "That's why the geoview is it is and I simply cannot order the A's in such a way that these numbers are increasing.",
            "Right as I choose the order in which I I create Pi, one Pi 2 etc.",
            "That's up to me.",
            "All I need is a partition into \u03c0 one Pi K. OK, so that's a proposal that we haven't developed much at this point, but we started to play around further with this idea of block models and so and that's."
        ],
        [
            "Mainly what I'll tell you about.",
            "Well.",
            "So so so.",
            "Somehow our our statistical point of view, if you want.",
            "Let us into studying another modularity, which one can think of as the likelihood modularity.",
            "And what that is is suppose that I knew what the partition was.",
            "He I can then write down the likelihood once I've written down the likelihood, I can estimate the parameters.",
            "And then I can write down with the log.",
            "Likelihood is at those parameters, and that's what this is.",
            "So what you're left is a function of the labeling.",
            "And I'll tell you a bit more about how that behaves, but I won't.",
            "This is simply plugging in as I said, estimated parameters into the log likelihood.",
            "The conditional log likelihood given me."
        ],
        [
            "OK, now I want to do a bit of asymptotics.",
            "And study the modularity's.",
            "And see how they behave.",
            "So let's consider a sequence of models.",
            "Now this could be a single model.",
            "Maybe you should think about Lambda sub N equal to N. Were Lambda sub in is defining the expected value, the expected total number of edges?",
            "Or two times the expected total number of edges.",
            "Now notice that if in fact Lambda N is equal to N. That's what you would expect if the pabs matrix were.",
            "Fixed.",
            "And that corresponds to the situation where basically you have on the order of N squared edges between.",
            "Each pair of communities.",
            "And that's actually important.",
            "Now you can sort of make this a little bit.",
            "It's actually interesting to think of the situation so that corresponds if you want for a very dense graph, right?",
            "I mean I have.",
            "In fact, the physicist called this the dense graph approximation.",
            "And basically your situation is much more like Internet kind of situations.",
            "That is, you have every vertex has connected with a substantial fraction.",
            "Of the remaining vertices.",
            "Or some non trivial fraction of the remaining vertices.",
            "My kids are in squared possible edges and choose two possible edges.",
            "So the other case, which is interesting but which I'm just going to say that I we have some.",
            "Results about is the case where Lambda sabanas of the order of 1.",
            "Which is the sparse graph model that is the model where each vertex has only a bounded number.",
            "Of its degree, is is bounded.",
            "Um?",
            "And so I'm going to study this as N goes to Infinity and as Lambda N parameter goes to Infinity.",
            "And here's a result which at least initially."
        ],
        [
            "I found surprising.",
            "Well sorry I have to define something first.",
            "OK, this is the maybe I should just even skip about this.",
            "You can define a general modularity which includes both the likelihood modularity that I gave an Newman Girvan modularity and my guess is probably most of the different modularity's of people have studied, but I won't vouch for that.",
            "And the question is.",
            "When can you say that these are consistent?",
            "Well, what does consistency mean?",
            "Consistency means that with probability tending to one.",
            "You will identify the communities correctly.",
            "Which at first sight seems really surprising, right?",
            "I mean that you could actually get the labels correct.",
            "But"
        ],
        [
            "Indeed, you can under rather mild conditions, so here's the conditions the matrix WL replace W by P and think of Lambda sub being equal to N, so that is the case with P stays fixed right?",
            "So the parameters are pie and P. OK, and this is a general form for limiting conditional modularity.",
            "Forget about that.",
            "That's more or less a condition that in fact in what corresponds to the population case.",
            "You actually make the assignments correctly.",
            "And then there's a third condition which tells you that in fact, at the maximum, which corresponds to making the assignment correctly, you have.",
            "You know it's not flat, it's a sharp maximum.",
            "And finally.",
            "What is actually very weak condition if you think about it, is that the Lambda Savannah over log N tends to Infinity.",
            "So remember Lambda sub N = N is the case that we naively think about the dense graph case, Lambda sub N equals one is the is the sparse graph case.",
            "Right completely sparse graph case and log in is really not that bad.",
            "Well, the theorem is."
        ],
        [
            "Only that.",
            "If these conditions hold.",
            "Then, not only do you actually not only do you actually do the classification correctly, with probability tending to one.",
            "But in fact, the probability of making a mistake any mistake at all right C had not equal to see.",
            "Goes to zero exponentially.",
            "So we think of lamps penalty and that's the that's the usual exponential bit.",
            "And a remark like that was also made for this model in the social science literature, but which seems to be sort of very special to doing what one sort of would naively do or not naively, but in normally do as a statistician that you have this model you do you do maximum likelihood.",
            "You compute the posterior probabilities.",
            "You do classification on the basis of those, and indeed it was shown that for that particular situation, which as I've argued, although in practice.",
            "It's not that bad in theory, it could be NP complete.",
            "That, in fact, at least at the probability, goes to of misclassification, goes to 0 as well.",
            "And it's basically the same reason."
        ],
        [
            "Oh sorry."
        ],
        [
            "Let me go and it's basically the same reason, and the reason is really very primitive.",
            "The reason is that.",
            "Although you have N vertices which we need to classify.",
            "You have N squared observations, not N, but N squared on the order and squared observations.",
            "And that's all you need.",
            "If you plug into the usual sort of bounds.",
            "And of course, once you've done that."
        ],
        [
            "By one of these modularity's which satisfies these conditions.",
            "You basically don't need to futz around with with maximum like anything like that.",
            "It's clear how you estimate the parameters, right?",
            "You simply count.",
            "How many of the guys are population one through population K?",
            "How many links there are between population one population and indeed under these circumstances?",
            "Not surprisingly, these things behave as best you can hope for in others, they behave as if you actually had known the labeling to begin with.",
            "Right?",
            "Because that's, that's that's all you can get, right?",
            "You still have Bernoulli trials, so you don't have.",
            "You still have to estimate the parameters of the model.",
            "And the speed for the peahats is in because that's how many observations and essentially you have to get at them.",
            "I mean you have in squared observations to get the P had a bees, you only have in observations.",
            "To get the the pies."
        ],
        [
            "Alright, so now let's look at how some of these modularity's fear.",
            "And it turns out, for Newman Girvin, you can write down this limiting condition, which is, as I said, sort of basically a population consistency condition.",
            "And.",
            "It turns out that.",
            "Oh, I think this is.",
            "It turns out that C2 fails actually for Newman Girvan, that is Newman Girvan in the population case, does not.",
            "Necessarily give you the correct labeling because it isn't actually getting you the right point.",
            "In the population and you can see that by an exam."
        ],
        [
            "Simple.",
            "Oh well, I see I I don't know I don't know what that first.",
            "Anyway?",
            "Angie, satisfy C2 and C3 only if the matrix of PAB has all diagonal entries positive.",
            "Not only, but has if and all that non diagonal entries negative.",
            "So there's simple conditions, but they may fail.",
            "And here's an example."
        ],
        [
            "Of a community 3 three subcommunities there's those of the pies.",
            "There's the P matrix.",
            "And you can show that the with that rule in labeling approaches one but.",
            ".10 unique name Newman Girvan modularity.",
            "But the true Max modular.",
            "In other words, the modularity which you which you.",
            "Which in fact maximizes this population quantity.",
            "Is sorry not.",
            "The value which gives you the correct communities in the limit.",
            "Is larger and in fact it's achieved by merging.",
            "Two of the three communities."
        ],
        [
            "Well, this is technical to show you just what what kind of things enter into the this argument.",
            "This theorem, which is not very difficult.",
            "Um?"
        ],
        [
            "We can make the same analysis for the profile likelihood and lo and behold, that one is consistent.",
            "Under minimal conditions so so.",
            "So basically what happens is that the.",
            "The maximum of the population.",
            "The maximum population maximum of the Newman Girvan modularity is not achieved at the true.",
            "Best partition, in this case it is achieved at the true best partition.",
            "Always."
        ],
        [
            "And here's a simulation and I, Oh dear, I had taken out the.",
            "My my my notes on what the simulation was.",
            "It's it's a simulation where you look at.",
            "Set I think we have three communities were the probabilities of each trial.",
            "The probabilities of the PBS are chosen from the uniform and then the diagonal has a bit added so that you.",
            "You would expect if enough is added for Newman Girvan to work.",
            "Nevertheless, if you look at the percent of perfect labeling as you increase the graph size numbers, then indeed the likelihood modularity.",
            "Outperforms it, but of course this is in the kind of model in the kind of model that.",
            "That's hypothesized."
        ],
        [
            "Now here's some real data, and of course one that we don't know what ground truth is.",
            "But it's it's data on a I guess.",
            "I think I've told me some.",
            "It's a business exchange.",
            "It's within a branch exchange.",
            "He works for Alcatel Lucent and so he can.",
            "He can get data like this.",
            "And so the the there are 1500 members of this branch exchange.",
            "And.",
            "And what you have shown are the.",
            "The Konnect well there's the connectivities.",
            "And what you are shown here are the communities formed by the Newman Girvan Ann profile Modularity's.",
            "Now it's a little bit misleading because in fact.",
            "These look as if they were sort of the same individuals, but they're not right.",
            "These correspond to different permutations.",
            "Nevertheless, one can argue that perhaps the one on the right.",
            "Which shows you sort of rather interesting structure where you have a small group of people which who don't talk to each other at all.",
            "Maybe because they're in the same office, is all telephone conversations, but talk to others so.",
            "But in fact we're going to try and get close to ground truth, but you can't actually get ground truth in this case.",
            "OK, I see that I have 5 more minutes.",
            "And I think I'll I'll manage that so."
        ],
        [
            "Let me close with.",
            "An approach we have not yet implemented.",
            "But which in principle?",
            "Should be quicker.",
            "Than any of the modularity's.",
            "Ann should give you hopefully.",
            "Sort of ask correct classification is possible.",
            "I mean, you know, for example, that if you knew the parameters right.",
            "If you knew the parameters.",
            "Then if you were able to compute explicitly the posterior probability, the conditional probability given the data that individual one has is labeled with Community A.",
            "Right?",
            "Then that thing would indeed be.",
            "Sort of.",
            "The best thing you could do from you, know the usual Bayes argument that you minimize the probability of misclassification since you now are in the situation where you know the parameters.",
            "So, so that's clearly the right rule.",
            "But the trouble is, it's not so easy to get at.",
            "So my proposal we have here is a Monte Carlo kind of proposal, or first of all, you can argue that you can estimate these parameters, P. Forget about the ends P hat and Pi hat.",
            "By the method of moments.",
            "That is, you can look.",
            "What you expect?",
            "The degree to be.",
            "You can look at how many vis you expect.",
            "You can look at how many ZS you expect, right IJJKK?",
            "Help for example.",
            "So.",
            "And so therefore.",
            "If you have enough of these.",
            "You should be able to estimate the parameters via estimating equations, right?",
            "You just simply set the observed fractions to the expected fractions and you solve.",
            "For the parameters.",
            "Then you see you can plug in.",
            "If you could compute.",
            "The conditional probability that CI the iPhone dividual is belongs to communicate.",
            "Given AP hat and Lambda hat.",
            "And take the maximum of that.",
            "That would be your estimated best.",
            "Best assignment of labels.",
            "Well, but I claim.",
            "Although you can't do that exactly very nicely, you can do it pretty easily by Montecarlo.",
            "See 'cause I know the parameters now.",
            "I know I know what the pies are.",
            "Pretend that I know them, their pie hats, but pretend that their pies.",
            "So what I do is I can simulate.",
            "I can simulate for each individual I toss a coin with probability \u03c0 to decide which community I'm going to put it in.",
            "That gives me a partition.",
            "Once I have that."
        ],
        [
            "I can compute this quantity, which is what the which was exactly the conditional probability.",
            "Of the individual belonging to Community K. Given the data.",
            "Right, the data being now not only the observed data, but the assignment that I've made.",
            "And now."
        ],
        [
            "Wow, OK. Tells you what these terms are.",
            "I don't think that's important.",
            "Um?",
            "But it's fairly clear that if you make.",
            "If you make the number of simulations large enough.",
            "Oh, I'm sorry.",
            "I sort of jumped the last thing I should not have jumped over.",
            "I take, of course, is my estimate of the posterior.",
            "Probability the average over all the simulations.",
            "And you can convince yourself fairly quickly that if you let the number of simulations go to Infinity, you are doing exactly the right thing.",
            "If those were.",
            "The population parameters."
        ],
        [
            "So OK, I guess have two minutes for discussion.",
            "It seems to be working out pretty well.",
            "What this says is that the problem of Lambda sub N = N is easy.",
            "Right, sort of any almost any reasonable modularity or likely functor, whatever.",
            "Will get you the correct.",
            "The correct labeling if this model holds.",
            "However, it doesn't tell you that the model is necessarily reasonable, and in fact the line that I would argue one should pursue is the sieve method that I indicated at the beginning.",
            "That is, you basically.",
            "And divide into K. Intervals you have a model with K modularity you know of K communities.",
            "Then you estimate actually.",
            "You estimate this function H which we started out with.",
            "Which is the Canonical which is the kernel function and then you look at it in the same way that one would look at a density estimate.",
            "And and the modes of that would sort of tell you.",
            "Where, how many communities, roughly?",
            "You know who should belong to what community?",
            "And so you're not committed to a particular structure.",
            "OK, next.",
            "This framework lends itself to generalization as an order of statistics.",
            "That is, as I said, this is the analogue of IID variables.",
            "Well, what do we do in order statistics when we form more complex models?",
            "We simply add covariates.",
            "Well, you can add covariance here too, right?",
            "Like the identity, you know some people are in the same geographical location.",
            "Some people are related.",
            "By family ties.",
            "Um?",
            "You can also generalize fairly straightforwardly to the directed case, I believe, by basically dropping down to the undirected case by dropping the directions, wiping out the directions.",
            "And then, um.",
            "And then going back and estimating the directions after you estimate the communities.",
            "And finally, I guess I should have started with this.",
            "This is, I think, the right in some sense the right way to proceed, which should appeal to.",
            "To an audience, at least the machine learning people.",
            "Well, maybe all of you in the audience, which is that you don't commit yourself.",
            "To a particular model.",
            "Particular parametric model you let the data somehow tell you.",
            "What the structure is and that is, you estimate this H Canonical and that's it, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the speaker today is.",
                    "label": 0
                },
                {
                    "sent": "Peter Bickel from UC Berkeley.",
                    "label": 1
                },
                {
                    "sent": "Well, thank you very much Martha.",
                    "label": 0
                },
                {
                    "sent": "It's a great pleasure to be here.",
                    "label": 0
                },
                {
                    "sent": "I wish I could have been here for longer, but I sent some students will then tell me what all the exciting things that happened.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What I'd like to talk to you about is a an area which has actually.",
                    "label": 0
                },
                {
                    "sent": "Grown in interest in a number of communities.",
                    "label": 0
                },
                {
                    "sent": "In particular, Interestingly enough, the physicists have are very active in this, so so they are busy constructing.",
                    "label": 0
                },
                {
                    "sent": "Network models of various types and her modularity's and I'll talk about some of those, and then I'll try to show you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this can be put in to a.",
                    "label": 0
                },
                {
                    "sent": "More probabilistic framework and perhaps help understanding what's going on with it.",
                    "label": 0
                },
                {
                    "sent": "So the outline is that I'm going to talk about the problem that most people talk about, which is the sub community identification problem and what modularity czar?",
                    "label": 0
                },
                {
                    "sent": "And then a nonparametric probability model for unlabeled graphs and its relation to things called block models which have appeared in the in the literature and then issues with maximum likelihood.",
                    "label": 1
                },
                {
                    "sent": "And then the consistency of a particular type of modularity.",
                    "label": 1
                },
                {
                    "sent": "The Newman Girvan, and then a bit of talk about algorithms, simulations and real data and some discussion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's an example of.",
                    "label": 0
                },
                {
                    "sent": "From a paper by Mark Newman of the University of Michigan there's a physicist.",
                    "label": 0
                },
                {
                    "sent": "Of the kind of thing that is interesting we have you have in this case the circles and squares represent members of a karate club.",
                    "label": 1
                },
                {
                    "sent": "And the links correspond to people knowing each other or having some other contact with each other.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that there are sub communities which you want to identify in this graph simply just from knowing the relationships between individuals.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that in fact.",
                    "label": 0
                },
                {
                    "sent": "I don't know before the factor after the fact that this this club sort of had a split.",
                    "label": 0
                },
                {
                    "sent": "And at some point right, there really were two distinct groups of people with different loyalties.",
                    "label": 0
                },
                {
                    "sent": "If you want who formed and this is the result of using something called.",
                    "label": 0
                },
                {
                    "sent": "Well, actually type of modularity introduced by Newman and a lot of people agree with this.",
                    "label": 0
                },
                {
                    "sent": "With this kind of split, the dotted line corresponds to a principal component of a matrix.",
                    "label": 0
                },
                {
                    "sent": "It's not spectral graph partitioning, but something something else.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second is.",
                    "label": 0
                },
                {
                    "sent": "Again, more of a social science graph.",
                    "label": 0
                },
                {
                    "sent": "But this is ethnicities of.",
                    "label": 0
                },
                {
                    "sent": "Of students in high and high school.",
                    "label": 1
                },
                {
                    "sent": "And again you the links correspond to whether the students know of each other.",
                    "label": 0
                },
                {
                    "sent": "And this is the partition that the the.",
                    "label": 0
                },
                {
                    "sent": "The black squares, the Hispanics, etc.",
                    "label": 0
                },
                {
                    "sent": "The squares, the diamonds, the circles correspond to known ethnicities, and these were put on afterward, so to speak.",
                    "label": 0
                },
                {
                    "sent": "So the two communities are actually sort of identified by the blobs, and as you can see there is pretty much agreement just on the basis of who knew whom?",
                    "label": 0
                },
                {
                    "sent": "S2, which community one falls into.",
                    "label": 0
                },
                {
                    "sent": "There's an interesting question about the people who are common to both.",
                    "label": 0
                },
                {
                    "sent": "And in fact, I think that actually reflects.",
                    "label": 0
                },
                {
                    "sent": "Reality, at least in my experience with my kids who were at school in Berkeley and the crossover, unfortunately, was largely a class crossover, right?",
                    "label": 0
                },
                {
                    "sent": "So people with middle class parents would tend to affiliate.",
                    "label": 0
                },
                {
                    "sent": "More with the with sort of the largely faculty Brat group of students.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the mathematical formulation of this kind of problem.",
                    "label": 1
                },
                {
                    "sent": "You're given an undirected graph VE.",
                    "label": 1
                },
                {
                    "sent": "And the vertices are arbitrarily labeled right.",
                    "label": 0
                },
                {
                    "sent": "You're not using information about who, who is who.",
                    "label": 0
                },
                {
                    "sent": "You have an adjacency matrix for this graph, so AIJ is one of the edge between I&J.",
                    "label": 1
                },
                {
                    "sent": "Is there is an edge between J and 0 otherwise and think of the edge between Andre as being some indication of relationship.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the problem is that there is an unknown number of what you can think of as subcommunities.",
                    "label": 0
                },
                {
                    "sent": "Which composed this community V. Vertices V1 through VK and let's pretend that K is known.",
                    "label": 0
                },
                {
                    "sent": "Of course, in practice it often isn't.",
                    "label": 0
                },
                {
                    "sent": "And the problem is to determine the VJ using only a.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the approach that has been as I said, come mainly out of the physics community.",
                    "label": 0
                },
                {
                    "sent": "Proposed by Newman and Girvin in physics Review E in 2004.",
                    "label": 0
                },
                {
                    "sent": "And basically it's.",
                    "label": 0
                },
                {
                    "sent": "It's a function which depends of course on the adjacency matrix and on a putative partition of the group.",
                    "label": 0
                },
                {
                    "sent": "Right, so E corresponds to a labeling of the members of the group.",
                    "label": 0
                },
                {
                    "sent": "So in this case the it's sort of complicated to read all this, but let me just tell you the OKK corresponds to, so you have a putative labeling of groups.",
                    "label": 0
                },
                {
                    "sent": "OK, corresponds to relationships between members in the group.",
                    "label": 1
                },
                {
                    "sent": "So OKK is between indicates Group D plus is simply the total number of edges which is twice sorry for the sum of the degrees and that's twice the number of edges between all nodes.",
                    "label": 1
                },
                {
                    "sent": "Because he changes kind of twice.",
                    "label": 0
                },
                {
                    "sent": "And so DK E / D plus squared, which is subtracting is a kind of expected.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's the motivation that Newman gives, and the expected is, roughly speaking, suppose that you simply made the assignment at random.",
                    "label": 1
                },
                {
                    "sent": "And the assignment was made according to the degree of the individual proportional to the degree of the individual.",
                    "label": 0
                },
                {
                    "sent": "So the OK K / D Plus is the observed.",
                    "label": 0
                },
                {
                    "sent": "The DKE over D plus squared is the expected in some sense, although both are dependent upon what he is.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's an entirely different line of approach which.",
                    "label": 0
                },
                {
                    "sent": "Is older comes goes back to the early 80s and which came from the social science literature, where of course the types of graphs that I just showed at the beginning.",
                    "label": 0
                },
                {
                    "sent": "Came from and that is that you think of communities as have big labels.",
                    "label": 0
                },
                {
                    "sent": "Corresponding Community C1 CN you don't know what the labels are and you have a multinomial with unknown parameters.",
                    "label": 0
                },
                {
                    "sent": "Pi one Pi K There K communities.",
                    "label": 0
                },
                {
                    "sent": "And the the probability and so the story that you tell yourself is, first of all, that the labels are assigned.",
                    "label": 0
                },
                {
                    "sent": "Community labels are assigned to the members Independantly according to this multinomial.",
                    "label": 0
                },
                {
                    "sent": "And then given the labeling right, then the probability of an edge.",
                    "label": 0
                },
                {
                    "sent": "Given the community membership of the two members.",
                    "label": 0
                },
                {
                    "sent": "Is again unknown, but a fixed quantity pabs.",
                    "label": 0
                },
                {
                    "sent": "So and so, and everything is in their condition independent.",
                    "label": 0
                },
                {
                    "sent": "So the probability of having no edge at all is 1 minus that sum.",
                    "label": 0
                },
                {
                    "sent": "The most.",
                    "label": 0
                },
                {
                    "sent": "Primitive model of this type of course goes back goes way back.",
                    "label": 0
                },
                {
                    "sent": "I don't know how far back but it is treated mathematically in great detail.",
                    "label": 0
                },
                {
                    "sent": "Beier, dishon, Rennie.",
                    "label": 0
                },
                {
                    "sent": "And that's the case.",
                    "label": 0
                },
                {
                    "sent": "We have only one community.",
                    "label": 0
                },
                {
                    "sent": "Right, so basically what you do is for any two individuals who put in an edge with probability P and don't put in an ad with probability 1 -- P. And then there's a whole theory about you know the structure of these communities, that there's a phase transition in PP goes above a certain point you get a giant connected component.",
                    "label": 0
                },
                {
                    "sent": "For awhile people used the order any models to try to work with, but what they found is that in fact they didn't correspond to many of the properties mathematical properties of air trainee.",
                    "label": 0
                },
                {
                    "sent": "As you let end go to Infinity, did not correspond to.",
                    "label": 0
                },
                {
                    "sent": "Graphs that were observed.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "There is a frequentist approach.",
                    "label": 0
                },
                {
                    "sent": "Then, if you believe in this model.",
                    "label": 0
                },
                {
                    "sent": "To this problem that you basically simply do maximum likelihood on these parameters.",
                    "label": 0
                },
                {
                    "sent": "And you compute the likelihood by YM because what you don't know where the labels.",
                    "label": 0
                },
                {
                    "sent": "If you knew the labels, then of course the the structure is very simple.",
                    "label": 0
                },
                {
                    "sent": "But not knowing the labels you've got a problem.",
                    "label": 0
                },
                {
                    "sent": "And then you compute P hat and Pi hat and then you can just simply assign labels according to Bayes rule for the conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "And you maxify you, classified by maximizing the probability, CIPS a given API.",
                    "label": 0
                },
                {
                    "sent": "In principle this looks terrible because there are two to the NTH possible assignments of labels.",
                    "label": 0
                },
                {
                    "sent": "But in practice, so the problem is NP complete, sorry.",
                    "label": 1
                },
                {
                    "sent": "Well, you don't hear me.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I'm so sorry.",
                    "label": 0
                },
                {
                    "sent": "Is it better?",
                    "label": 0
                },
                {
                    "sent": "This is the one to turn this on if we can.",
                    "label": 0
                },
                {
                    "sent": "Now it works alright.",
                    "label": 0
                },
                {
                    "sent": "Well, you did what, that's it?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much and I apologize.",
                    "label": 0
                },
                {
                    "sent": "So do you want me to go back at all to I shout loud enough so that most of you at least.",
                    "label": 0
                },
                {
                    "sent": "So in practice, however.",
                    "label": 0
                },
                {
                    "sent": "The places I've not done anything.",
                    "label": 0
                },
                {
                    "sent": "Low battery, precisely that's what it's telling us.",
                    "label": 0
                },
                {
                    "sent": "So can this be turned on and I'll use this, that's OK.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes yes, but is it is is the big Mike on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "There's always something that happens at any talk.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "It's technology always.",
                    "label": 0
                },
                {
                    "sent": "Gives you trouble.",
                    "label": 0
                },
                {
                    "sent": "OK, so so.",
                    "label": 0
                },
                {
                    "sent": "So that's the story.",
                    "label": 0
                },
                {
                    "sent": "So in theory this is quite difficult to do.",
                    "label": 0
                },
                {
                    "sent": "In practice.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not so bad.",
                    "label": 0
                },
                {
                    "sent": "You basically do a swapping algorithm.",
                    "label": 0
                },
                {
                    "sent": "You have an initial and you have an initial assignment of.",
                    "label": 0
                },
                {
                    "sent": "Identity's and then you swap from one community to the other and you see if it goes up and you keep on following that.",
                    "label": 0
                },
                {
                    "sent": "And this actually seems to converge fairly quickly.",
                    "label": 0
                },
                {
                    "sent": "It is not a unimodal surface but you know you try it with a bunch of random starts and and it behaves OK. Um?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's more or less what the.",
                    "label": 0
                },
                {
                    "sent": "The situation is coming on.",
                    "label": 0
                },
                {
                    "sent": "The one hand from the physics literature, which I should say, the reason that there's been considerable interest.",
                    "label": 0
                },
                {
                    "sent": "Recently has been of course not because of so much of the social science aspects, but becausw of the Internet, for example.",
                    "label": 0
                },
                {
                    "sent": "So so you know you have, we now have situations where you have very large graphs where you're interested in Community structure.",
                    "label": 0
                },
                {
                    "sent": "And I'll have an example like that.",
                    "label": 0
                },
                {
                    "sent": "A bit later, but.",
                    "label": 0
                },
                {
                    "sent": "Basically what I wanted to do or what are you and I, my collaborator, who was on the 1st slide.",
                    "label": 0
                },
                {
                    "sent": "Have wanted to do and was too.",
                    "label": 0
                },
                {
                    "sent": "To try to see if we couldn't get something which is like a nonparametric model.",
                    "label": 0
                },
                {
                    "sent": "For graphs, which is analogous to the nonparametric model you're all familiar with in, say, classification and machine learning.",
                    "label": 0
                },
                {
                    "sent": "Well, to do that you have to get some sort of notion of what's the analogue of IID.",
                    "label": 0
                },
                {
                    "sent": "And what's the analogue of the population?",
                    "label": 0
                },
                {
                    "sent": "Well, there's a very natural characterization.",
                    "label": 0
                },
                {
                    "sent": "Which actually was studied in David oldest.",
                    "label": 0
                },
                {
                    "sent": "His thesis in 1983, and there's a book which appeared recently by Kahlenberg, which I think amplifies on it.",
                    "label": 0
                },
                {
                    "sent": "There was some problems, I think with all this is original argument, but basically you say, well, OK, I have an unlabeled graph.",
                    "label": 0
                },
                {
                    "sent": "I can imagine this being infinite that corresponds to a population.",
                    "label": 0
                },
                {
                    "sent": "And then the question is what do I mean by the thing being unlabeled?",
                    "label": 0
                },
                {
                    "sent": "And that the information is coming entirely from the relations?",
                    "label": 0
                },
                {
                    "sent": "And the answer I think is pretty clear that if you so now we have a joint probability distribution on this infinite matrix.",
                    "label": 0
                },
                {
                    "sent": "Right call it P. And it seems clear that that's intuitively to satisfy this requirement that you know the labels shouldn't mean anything.",
                    "label": 0
                },
                {
                    "sent": "It should be true that if you take a permutation.",
                    "label": 0
                },
                {
                    "sent": "Of the indices.",
                    "label": 0
                },
                {
                    "sent": "The distribution of the law of a pie.",
                    "label": 0
                },
                {
                    "sent": "I Pi J the same permutation should be the same as the distribution of the law of AIJ.",
                    "label": 0
                },
                {
                    "sent": "And when I say AIG or a pipe, I don't just mean that random variable, I mean that whole huge infinite array.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What old is showed?",
                    "label": 0
                },
                {
                    "sent": "Is a very beautiful result, which in retrospect seems intuitive.",
                    "label": 0
                },
                {
                    "sent": "Which is that any such probability distribution?",
                    "label": 0
                },
                {
                    "sent": "Can be represented as follows.",
                    "label": 0
                },
                {
                    "sent": "You have a function G. Which goes from the unit interval to the 4th power.",
                    "label": 0
                },
                {
                    "sent": "To 01.",
                    "label": 0
                },
                {
                    "sent": "And AIJ which is the indicator of whether you have a link or not, is a function of Alpha, cick, CJ and AJ.",
                    "label": 0
                },
                {
                    "sent": "Where Alpha, Xywrite, CJ and eight IJ are all a huge group of IID U01 variables.",
                    "label": 0
                },
                {
                    "sent": "They don't have to be uniform number one.",
                    "label": 0
                },
                {
                    "sent": "Clearly, since G is arbitrary right, there can be any transform of those, but that's the representation.",
                    "label": 0
                },
                {
                    "sent": "And if you think about it, one of those variables plays a special role, namely the Alpha.",
                    "label": 0
                },
                {
                    "sent": "The Alpha is really a choice of function.",
                    "label": 0
                },
                {
                    "sent": "And it is very much.",
                    "label": 0
                },
                {
                    "sent": "There's an analogous theorem which I think probably many of you know, called Definitely's theorem.",
                    "label": 0
                },
                {
                    "sent": "Which tells you that if you have a sequence of exchangeable random variables.",
                    "label": 0
                },
                {
                    "sent": "An infinite sequence of exchangeable random variables.",
                    "label": 0
                },
                {
                    "sent": "Let's say taking the value 01 that was the original definite formulation.",
                    "label": 0
                },
                {
                    "sent": "Any such sequence can be thought of as.",
                    "label": 0
                },
                {
                    "sent": "A mixture.",
                    "label": 0
                },
                {
                    "sent": "Of coin tossing sequences.",
                    "label": 0
                },
                {
                    "sent": "Right, so you pick a P and then you just toss your coin with that PIID forever.",
                    "label": 0
                },
                {
                    "sent": "That's how you get that.",
                    "label": 0
                },
                {
                    "sent": "Well, it's pretty clear in that case, and in this case as well that.",
                    "label": 0
                },
                {
                    "sent": "The if that you cannot identify the mixture.",
                    "label": 0
                },
                {
                    "sent": "You cannot identify the mixing variable right because.",
                    "label": 0
                },
                {
                    "sent": "A choice of Alpha is made and then all you can observe is the sequence of zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "So you can certainly find the P that has been picked.",
                    "label": 0
                },
                {
                    "sent": "But you have no idea about how it's been picked.",
                    "label": 0
                },
                {
                    "sent": "And that's true here too.",
                    "label": 0
                },
                {
                    "sent": "And there's another characterization, by the way, that the IID sequences in definitely theorem are the extreme points of the set of all such distribution.",
                    "label": 0
                },
                {
                    "sent": "That's a convex set of distributions, and this was in fact this line of research beyond definitely was initiated by my colleague, David Friedman.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately died recently, but anyway so.",
                    "label": 0
                },
                {
                    "sent": "If you remove the Alpha.",
                    "label": 0
                },
                {
                    "sent": "Oh, and I'm sorry I didn't mention, but of course it's obvious right, because the graph is unlabeled.",
                    "label": 0
                },
                {
                    "sent": "This function G must be symmetric in psych CJ, right?",
                    "label": 0
                },
                {
                    "sent": "'cause CJ Edge in the GI edge at the same?",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, the AIJ must be hji, but that's trivial.",
                    "label": 0
                },
                {
                    "sent": "The critical point is the is the Alpha.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can argue that you get a good icity just as you get with IID sequences.",
                    "label": 0
                },
                {
                    "sent": "If and only if you drop the Alpha.",
                    "label": 0
                },
                {
                    "sent": "And I now claim that it's not this quite plausible and reasonable to think.",
                    "label": 0
                },
                {
                    "sent": "Of things like this, these GF CI CJ8I J as being ergotic.",
                    "label": 0
                },
                {
                    "sent": "Probability distribution there what corresponds to IID variables in this context?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we have IID variables, But we don't have to know what characterizes them, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, in the usual situation, there is a distribution function.",
                    "label": 0
                },
                {
                    "sent": "This probability measure of one of them.",
                    "label": 0
                },
                {
                    "sent": "Well in this case.",
                    "label": 0
                },
                {
                    "sent": "It's clear that since the ADA I Jays are IID.",
                    "label": 0
                },
                {
                    "sent": "Completely, So what really matters is what happens conditionally.",
                    "label": 0
                },
                {
                    "sent": "If I give you the set of axes.",
                    "label": 0
                },
                {
                    "sent": "So the function that at the very least, which determines the probability distribution is this function huv, which is a function of 201 variables.",
                    "label": 0
                },
                {
                    "sent": "Variables on University one and which has to be symmetric again because of the requirement that the edges be be undirected.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now H as was noted, I think probably oldest noted recently in a paper of Diaconis and Janssen as well, which actually looked at some other things.",
                    "label": 0
                },
                {
                    "sent": "H is not uniquely determined.",
                    "label": 1
                },
                {
                    "sent": "And that's pretty clear, because if I take.",
                    "label": 0
                },
                {
                    "sent": "A function, sigh.",
                    "label": 0
                },
                {
                    "sent": "It's such a sigh of succeeding.",
                    "label": 0
                },
                {
                    "sent": "U01 is itself U01, Another measure, a measure preserving transformation.",
                    "label": 0
                },
                {
                    "sent": "Then H of science CYP SCIEX EJ.",
                    "label": 0
                },
                {
                    "sent": "That whole big distribution is the same.",
                    "label": 0
                },
                {
                    "sent": "You haven't changed it.",
                    "label": 0
                },
                {
                    "sent": "Because the joint distribution of the SIAC sees is the same as it exceeds themselves.",
                    "label": 0
                },
                {
                    "sent": "Well, that's a problem, but here is a proposal and I believe it's it's quite reasonable since I'm proposing it that there is a Canonical member.",
                    "label": 0
                },
                {
                    "sent": "Of this family of functions.",
                    "label": 0
                },
                {
                    "sent": "Basically consider the function G of you, which is the probability that your edge you have an edge between I&J given the vertex, the value of the latent variable at I.",
                    "label": 0
                },
                {
                    "sent": "That's a function of 1 variable.",
                    "label": 0
                },
                {
                    "sent": "Now you can think of GFC I I.",
                    "label": 0
                },
                {
                    "sent": "That's a random variable.",
                    "label": 0
                },
                {
                    "sent": "A single random variable.",
                    "label": 0
                },
                {
                    "sent": "And there is a unique choice of G. We you know what Geoview is.",
                    "label": 0
                },
                {
                    "sent": "It's the integral 0 to one HUVDV OK.",
                    "label": 0
                },
                {
                    "sent": "There is a unique choice of G. Which is monotone, which is monotone increasing.",
                    "label": 0
                },
                {
                    "sent": "And I claim that gives you a Canonical huv.",
                    "label": 0
                },
                {
                    "sent": "And so the H Canonical of CEOC CJ is distributed L. Angie Canonical of H Canonical.",
                    "label": 0
                },
                {
                    "sent": "Is increasing in you.",
                    "label": 0
                },
                {
                    "sent": "And once you think about it, that's not too difficult to see.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "R. All you do is G of scii has a distribution capital F. Which obviously depends.",
                    "label": 0
                },
                {
                    "sent": "Only on P on the probability distribution, right?",
                    "label": 0
                },
                {
                    "sent": "So you know capital F that doesn't depend on H. It depends on the joint probability distribution variables.",
                    "label": 0
                },
                {
                    "sent": "And assume that this continues.",
                    "label": 1
                },
                {
                    "sent": "That's actually not necessary, but it's just convenient for writing this down.",
                    "label": 0
                },
                {
                    "sent": "You define now a measure preserving PSI.",
                    "label": 1
                },
                {
                    "sent": "Which is capital F of geoview.",
                    "label": 0
                },
                {
                    "sent": "And you can check that that indeed send 01 variables into 01, because all you're doing is you're applying F inverse.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "222 applying distribution F inverse to a variable which has distribution F. Capital F. And so, in fact, the Canonical G is nothing else but the inverse of you, and it's increasing.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what we have is really.",
                    "label": 0
                },
                {
                    "sent": "A parametrization nonparametric parametrization if you want of the set of probability distributions.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now you can see the block models which were introduced earlier as approximations and rather reasonable approximations.",
                    "label": 1
                },
                {
                    "sent": "That is, I simply partition up remember the pies in this case are the probabilities of the communities.",
                    "label": 0
                },
                {
                    "sent": "So I generate the Pis by simply partitioning up the interval.",
                    "label": 0
                },
                {
                    "sent": "Into in consecutive intervals of length Pi, One Pi 2 etc.",
                    "label": 0
                },
                {
                    "sent": "And then I define.",
                    "label": 0
                },
                {
                    "sent": "On the block.",
                    "label": 0
                },
                {
                    "sent": "Define HUB to BHAB.",
                    "label": 0
                },
                {
                    "sent": "If you're in the block defined by.",
                    "label": 0
                },
                {
                    "sent": "You know the thing which gives you \u03c0 and \u03c0 J.",
                    "label": 0
                },
                {
                    "sent": "And you can check that that's indeed a block model.",
                    "label": 0
                },
                {
                    "sent": "And it's sort of intuitively clear that.",
                    "label": 0
                },
                {
                    "sent": "You should be able to get the Canonical guy.",
                    "label": 0
                },
                {
                    "sent": "You know, with enough data approximately by.",
                    "label": 0
                },
                {
                    "sent": "By by taking blocks of equal probability.",
                    "label": 0
                },
                {
                    "sent": "I make your life a little bit easier.",
                    "label": 1
                },
                {
                    "sent": "1 / K. And then fit the block model, which takes values H maybe?",
                    "label": 0
                },
                {
                    "sent": "On the block corresponding to to to EU UV square.",
                    "label": 0
                },
                {
                    "sent": "A -- 1 / K. 2A or K B -- 1 / K to be over K. And then you choose KN to be growing slowly.",
                    "label": 0
                },
                {
                    "sent": "And oh, and how do you do the Canonical bit?",
                    "label": 0
                },
                {
                    "sent": "By the way, it's pretty clear, right?",
                    "label": 0
                },
                {
                    "sent": "I mean all you do is I?",
                    "label": 0
                },
                {
                    "sent": "I add up the summation Overby paisa BH baby.",
                    "label": 0
                },
                {
                    "sent": "That's what my integral 0 to one.",
                    "label": 0
                },
                {
                    "sent": "That's why the geoview is it is and I simply cannot order the A's in such a way that these numbers are increasing.",
                    "label": 0
                },
                {
                    "sent": "Right as I choose the order in which I I create Pi, one Pi 2 etc.",
                    "label": 0
                },
                {
                    "sent": "That's up to me.",
                    "label": 0
                },
                {
                    "sent": "All I need is a partition into \u03c0 one Pi K. OK, so that's a proposal that we haven't developed much at this point, but we started to play around further with this idea of block models and so and that's.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mainly what I'll tell you about.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So so so.",
                    "label": 0
                },
                {
                    "sent": "Somehow our our statistical point of view, if you want.",
                    "label": 0
                },
                {
                    "sent": "Let us into studying another modularity, which one can think of as the likelihood modularity.",
                    "label": 0
                },
                {
                    "sent": "And what that is is suppose that I knew what the partition was.",
                    "label": 0
                },
                {
                    "sent": "He I can then write down the likelihood once I've written down the likelihood, I can estimate the parameters.",
                    "label": 0
                },
                {
                    "sent": "And then I can write down with the log.",
                    "label": 0
                },
                {
                    "sent": "Likelihood is at those parameters, and that's what this is.",
                    "label": 0
                },
                {
                    "sent": "So what you're left is a function of the labeling.",
                    "label": 0
                },
                {
                    "sent": "And I'll tell you a bit more about how that behaves, but I won't.",
                    "label": 0
                },
                {
                    "sent": "This is simply plugging in as I said, estimated parameters into the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "The conditional log likelihood given me.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now I want to do a bit of asymptotics.",
                    "label": 0
                },
                {
                    "sent": "And study the modularity's.",
                    "label": 0
                },
                {
                    "sent": "And see how they behave.",
                    "label": 0
                },
                {
                    "sent": "So let's consider a sequence of models.",
                    "label": 1
                },
                {
                    "sent": "Now this could be a single model.",
                    "label": 0
                },
                {
                    "sent": "Maybe you should think about Lambda sub N equal to N. Were Lambda sub in is defining the expected value, the expected total number of edges?",
                    "label": 0
                },
                {
                    "sent": "Or two times the expected total number of edges.",
                    "label": 0
                },
                {
                    "sent": "Now notice that if in fact Lambda N is equal to N. That's what you would expect if the pabs matrix were.",
                    "label": 0
                },
                {
                    "sent": "Fixed.",
                    "label": 0
                },
                {
                    "sent": "And that corresponds to the situation where basically you have on the order of N squared edges between.",
                    "label": 0
                },
                {
                    "sent": "Each pair of communities.",
                    "label": 0
                },
                {
                    "sent": "And that's actually important.",
                    "label": 0
                },
                {
                    "sent": "Now you can sort of make this a little bit.",
                    "label": 0
                },
                {
                    "sent": "It's actually interesting to think of the situation so that corresponds if you want for a very dense graph, right?",
                    "label": 0
                },
                {
                    "sent": "I mean I have.",
                    "label": 0
                },
                {
                    "sent": "In fact, the physicist called this the dense graph approximation.",
                    "label": 0
                },
                {
                    "sent": "And basically your situation is much more like Internet kind of situations.",
                    "label": 0
                },
                {
                    "sent": "That is, you have every vertex has connected with a substantial fraction.",
                    "label": 0
                },
                {
                    "sent": "Of the remaining vertices.",
                    "label": 0
                },
                {
                    "sent": "Or some non trivial fraction of the remaining vertices.",
                    "label": 0
                },
                {
                    "sent": "My kids are in squared possible edges and choose two possible edges.",
                    "label": 0
                },
                {
                    "sent": "So the other case, which is interesting but which I'm just going to say that I we have some.",
                    "label": 0
                },
                {
                    "sent": "Results about is the case where Lambda sabanas of the order of 1.",
                    "label": 0
                },
                {
                    "sent": "Which is the sparse graph model that is the model where each vertex has only a bounded number.",
                    "label": 0
                },
                {
                    "sent": "Of its degree, is is bounded.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so I'm going to study this as N goes to Infinity and as Lambda N parameter goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "And here's a result which at least initially.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I found surprising.",
                    "label": 0
                },
                {
                    "sent": "Well sorry I have to define something first.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the maybe I should just even skip about this.",
                    "label": 0
                },
                {
                    "sent": "You can define a general modularity which includes both the likelihood modularity that I gave an Newman Girvan modularity and my guess is probably most of the different modularity's of people have studied, but I won't vouch for that.",
                    "label": 0
                },
                {
                    "sent": "And the question is.",
                    "label": 0
                },
                {
                    "sent": "When can you say that these are consistent?",
                    "label": 0
                },
                {
                    "sent": "Well, what does consistency mean?",
                    "label": 0
                },
                {
                    "sent": "Consistency means that with probability tending to one.",
                    "label": 0
                },
                {
                    "sent": "You will identify the communities correctly.",
                    "label": 0
                },
                {
                    "sent": "Which at first sight seems really surprising, right?",
                    "label": 0
                },
                {
                    "sent": "I mean that you could actually get the labels correct.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Indeed, you can under rather mild conditions, so here's the conditions the matrix WL replace W by P and think of Lambda sub being equal to N, so that is the case with P stays fixed right?",
                    "label": 0
                },
                {
                    "sent": "So the parameters are pie and P. OK, and this is a general form for limiting conditional modularity.",
                    "label": 0
                },
                {
                    "sent": "Forget about that.",
                    "label": 0
                },
                {
                    "sent": "That's more or less a condition that in fact in what corresponds to the population case.",
                    "label": 0
                },
                {
                    "sent": "You actually make the assignments correctly.",
                    "label": 0
                },
                {
                    "sent": "And then there's a third condition which tells you that in fact, at the maximum, which corresponds to making the assignment correctly, you have.",
                    "label": 0
                },
                {
                    "sent": "You know it's not flat, it's a sharp maximum.",
                    "label": 0
                },
                {
                    "sent": "And finally.",
                    "label": 0
                },
                {
                    "sent": "What is actually very weak condition if you think about it, is that the Lambda Savannah over log N tends to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So remember Lambda sub N = N is the case that we naively think about the dense graph case, Lambda sub N equals one is the is the sparse graph case.",
                    "label": 0
                },
                {
                    "sent": "Right completely sparse graph case and log in is really not that bad.",
                    "label": 0
                },
                {
                    "sent": "Well, the theorem is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only that.",
                    "label": 0
                },
                {
                    "sent": "If these conditions hold.",
                    "label": 0
                },
                {
                    "sent": "Then, not only do you actually not only do you actually do the classification correctly, with probability tending to one.",
                    "label": 0
                },
                {
                    "sent": "But in fact, the probability of making a mistake any mistake at all right C had not equal to see.",
                    "label": 0
                },
                {
                    "sent": "Goes to zero exponentially.",
                    "label": 0
                },
                {
                    "sent": "So we think of lamps penalty and that's the that's the usual exponential bit.",
                    "label": 0
                },
                {
                    "sent": "And a remark like that was also made for this model in the social science literature, but which seems to be sort of very special to doing what one sort of would naively do or not naively, but in normally do as a statistician that you have this model you do you do maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "You compute the posterior probabilities.",
                    "label": 0
                },
                {
                    "sent": "You do classification on the basis of those, and indeed it was shown that for that particular situation, which as I've argued, although in practice.",
                    "label": 0
                },
                {
                    "sent": "It's not that bad in theory, it could be NP complete.",
                    "label": 0
                },
                {
                    "sent": "That, in fact, at least at the probability, goes to of misclassification, goes to 0 as well.",
                    "label": 0
                },
                {
                    "sent": "And it's basically the same reason.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh sorry.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me go and it's basically the same reason, and the reason is really very primitive.",
                    "label": 0
                },
                {
                    "sent": "The reason is that.",
                    "label": 0
                },
                {
                    "sent": "Although you have N vertices which we need to classify.",
                    "label": 0
                },
                {
                    "sent": "You have N squared observations, not N, but N squared on the order and squared observations.",
                    "label": 0
                },
                {
                    "sent": "And that's all you need.",
                    "label": 0
                },
                {
                    "sent": "If you plug into the usual sort of bounds.",
                    "label": 0
                },
                {
                    "sent": "And of course, once you've done that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By one of these modularity's which satisfies these conditions.",
                    "label": 0
                },
                {
                    "sent": "You basically don't need to futz around with with maximum like anything like that.",
                    "label": 0
                },
                {
                    "sent": "It's clear how you estimate the parameters, right?",
                    "label": 0
                },
                {
                    "sent": "You simply count.",
                    "label": 0
                },
                {
                    "sent": "How many of the guys are population one through population K?",
                    "label": 0
                },
                {
                    "sent": "How many links there are between population one population and indeed under these circumstances?",
                    "label": 0
                },
                {
                    "sent": "Not surprisingly, these things behave as best you can hope for in others, they behave as if you actually had known the labeling to begin with.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Because that's, that's that's all you can get, right?",
                    "label": 0
                },
                {
                    "sent": "You still have Bernoulli trials, so you don't have.",
                    "label": 0
                },
                {
                    "sent": "You still have to estimate the parameters of the model.",
                    "label": 0
                },
                {
                    "sent": "And the speed for the peahats is in because that's how many observations and essentially you have to get at them.",
                    "label": 0
                },
                {
                    "sent": "I mean you have in squared observations to get the P had a bees, you only have in observations.",
                    "label": 0
                },
                {
                    "sent": "To get the the pies.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so now let's look at how some of these modularity's fear.",
                    "label": 0
                },
                {
                    "sent": "And it turns out, for Newman Girvin, you can write down this limiting condition, which is, as I said, sort of basically a population consistency condition.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It turns out that.",
                    "label": 0
                },
                {
                    "sent": "Oh, I think this is.",
                    "label": 0
                },
                {
                    "sent": "It turns out that C2 fails actually for Newman Girvan, that is Newman Girvan in the population case, does not.",
                    "label": 0
                },
                {
                    "sent": "Necessarily give you the correct labeling because it isn't actually getting you the right point.",
                    "label": 0
                },
                {
                    "sent": "In the population and you can see that by an exam.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simple.",
                    "label": 0
                },
                {
                    "sent": "Oh well, I see I I don't know I don't know what that first.",
                    "label": 0
                },
                {
                    "sent": "Anyway?",
                    "label": 0
                },
                {
                    "sent": "Angie, satisfy C2 and C3 only if the matrix of PAB has all diagonal entries positive.",
                    "label": 1
                },
                {
                    "sent": "Not only, but has if and all that non diagonal entries negative.",
                    "label": 0
                },
                {
                    "sent": "So there's simple conditions, but they may fail.",
                    "label": 0
                },
                {
                    "sent": "And here's an example.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of a community 3 three subcommunities there's those of the pies.",
                    "label": 0
                },
                {
                    "sent": "There's the P matrix.",
                    "label": 0
                },
                {
                    "sent": "And you can show that the with that rule in labeling approaches one but.",
                    "label": 0
                },
                {
                    "sent": ".10 unique name Newman Girvan modularity.",
                    "label": 0
                },
                {
                    "sent": "But the true Max modular.",
                    "label": 1
                },
                {
                    "sent": "In other words, the modularity which you which you.",
                    "label": 0
                },
                {
                    "sent": "Which in fact maximizes this population quantity.",
                    "label": 0
                },
                {
                    "sent": "Is sorry not.",
                    "label": 0
                },
                {
                    "sent": "The value which gives you the correct communities in the limit.",
                    "label": 0
                },
                {
                    "sent": "Is larger and in fact it's achieved by merging.",
                    "label": 1
                },
                {
                    "sent": "Two of the three communities.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, this is technical to show you just what what kind of things enter into the this argument.",
                    "label": 0
                },
                {
                    "sent": "This theorem, which is not very difficult.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can make the same analysis for the profile likelihood and lo and behold, that one is consistent.",
                    "label": 1
                },
                {
                    "sent": "Under minimal conditions so so.",
                    "label": 0
                },
                {
                    "sent": "So basically what happens is that the.",
                    "label": 0
                },
                {
                    "sent": "The maximum of the population.",
                    "label": 0
                },
                {
                    "sent": "The maximum population maximum of the Newman Girvan modularity is not achieved at the true.",
                    "label": 0
                },
                {
                    "sent": "Best partition, in this case it is achieved at the true best partition.",
                    "label": 0
                },
                {
                    "sent": "Always.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's a simulation and I, Oh dear, I had taken out the.",
                    "label": 0
                },
                {
                    "sent": "My my my notes on what the simulation was.",
                    "label": 0
                },
                {
                    "sent": "It's it's a simulation where you look at.",
                    "label": 0
                },
                {
                    "sent": "Set I think we have three communities were the probabilities of each trial.",
                    "label": 0
                },
                {
                    "sent": "The probabilities of the PBS are chosen from the uniform and then the diagonal has a bit added so that you.",
                    "label": 0
                },
                {
                    "sent": "You would expect if enough is added for Newman Girvan to work.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, if you look at the percent of perfect labeling as you increase the graph size numbers, then indeed the likelihood modularity.",
                    "label": 0
                },
                {
                    "sent": "Outperforms it, but of course this is in the kind of model in the kind of model that.",
                    "label": 0
                },
                {
                    "sent": "That's hypothesized.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now here's some real data, and of course one that we don't know what ground truth is.",
                    "label": 0
                },
                {
                    "sent": "But it's it's data on a I guess.",
                    "label": 0
                },
                {
                    "sent": "I think I've told me some.",
                    "label": 0
                },
                {
                    "sent": "It's a business exchange.",
                    "label": 0
                },
                {
                    "sent": "It's within a branch exchange.",
                    "label": 1
                },
                {
                    "sent": "He works for Alcatel Lucent and so he can.",
                    "label": 0
                },
                {
                    "sent": "He can get data like this.",
                    "label": 0
                },
                {
                    "sent": "And so the the there are 1500 members of this branch exchange.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And what you have shown are the.",
                    "label": 0
                },
                {
                    "sent": "The Konnect well there's the connectivities.",
                    "label": 0
                },
                {
                    "sent": "And what you are shown here are the communities formed by the Newman Girvan Ann profile Modularity's.",
                    "label": 1
                },
                {
                    "sent": "Now it's a little bit misleading because in fact.",
                    "label": 0
                },
                {
                    "sent": "These look as if they were sort of the same individuals, but they're not right.",
                    "label": 0
                },
                {
                    "sent": "These correspond to different permutations.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, one can argue that perhaps the one on the right.",
                    "label": 0
                },
                {
                    "sent": "Which shows you sort of rather interesting structure where you have a small group of people which who don't talk to each other at all.",
                    "label": 0
                },
                {
                    "sent": "Maybe because they're in the same office, is all telephone conversations, but talk to others so.",
                    "label": 0
                },
                {
                    "sent": "But in fact we're going to try and get close to ground truth, but you can't actually get ground truth in this case.",
                    "label": 0
                },
                {
                    "sent": "OK, I see that I have 5 more minutes.",
                    "label": 0
                },
                {
                    "sent": "And I think I'll I'll manage that so.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me close with.",
                    "label": 0
                },
                {
                    "sent": "An approach we have not yet implemented.",
                    "label": 0
                },
                {
                    "sent": "But which in principle?",
                    "label": 0
                },
                {
                    "sent": "Should be quicker.",
                    "label": 0
                },
                {
                    "sent": "Than any of the modularity's.",
                    "label": 0
                },
                {
                    "sent": "Ann should give you hopefully.",
                    "label": 0
                },
                {
                    "sent": "Sort of ask correct classification is possible.",
                    "label": 0
                },
                {
                    "sent": "I mean, you know, for example, that if you knew the parameters right.",
                    "label": 0
                },
                {
                    "sent": "If you knew the parameters.",
                    "label": 0
                },
                {
                    "sent": "Then if you were able to compute explicitly the posterior probability, the conditional probability given the data that individual one has is labeled with Community A.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Then that thing would indeed be.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "The best thing you could do from you, know the usual Bayes argument that you minimize the probability of misclassification since you now are in the situation where you know the parameters.",
                    "label": 0
                },
                {
                    "sent": "So, so that's clearly the right rule.",
                    "label": 0
                },
                {
                    "sent": "But the trouble is, it's not so easy to get at.",
                    "label": 0
                },
                {
                    "sent": "So my proposal we have here is a Monte Carlo kind of proposal, or first of all, you can argue that you can estimate these parameters, P. Forget about the ends P hat and Pi hat.",
                    "label": 0
                },
                {
                    "sent": "By the method of moments.",
                    "label": 0
                },
                {
                    "sent": "That is, you can look.",
                    "label": 0
                },
                {
                    "sent": "What you expect?",
                    "label": 0
                },
                {
                    "sent": "The degree to be.",
                    "label": 0
                },
                {
                    "sent": "You can look at how many vis you expect.",
                    "label": 0
                },
                {
                    "sent": "You can look at how many ZS you expect, right IJJKK?",
                    "label": 0
                },
                {
                    "sent": "Help for example.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And so therefore.",
                    "label": 0
                },
                {
                    "sent": "If you have enough of these.",
                    "label": 0
                },
                {
                    "sent": "You should be able to estimate the parameters via estimating equations, right?",
                    "label": 0
                },
                {
                    "sent": "You just simply set the observed fractions to the expected fractions and you solve.",
                    "label": 0
                },
                {
                    "sent": "For the parameters.",
                    "label": 0
                },
                {
                    "sent": "Then you see you can plug in.",
                    "label": 0
                },
                {
                    "sent": "If you could compute.",
                    "label": 0
                },
                {
                    "sent": "The conditional probability that CI the iPhone dividual is belongs to communicate.",
                    "label": 0
                },
                {
                    "sent": "Given AP hat and Lambda hat.",
                    "label": 0
                },
                {
                    "sent": "And take the maximum of that.",
                    "label": 0
                },
                {
                    "sent": "That would be your estimated best.",
                    "label": 0
                },
                {
                    "sent": "Best assignment of labels.",
                    "label": 0
                },
                {
                    "sent": "Well, but I claim.",
                    "label": 0
                },
                {
                    "sent": "Although you can't do that exactly very nicely, you can do it pretty easily by Montecarlo.",
                    "label": 0
                },
                {
                    "sent": "See 'cause I know the parameters now.",
                    "label": 0
                },
                {
                    "sent": "I know I know what the pies are.",
                    "label": 0
                },
                {
                    "sent": "Pretend that I know them, their pie hats, but pretend that their pies.",
                    "label": 0
                },
                {
                    "sent": "So what I do is I can simulate.",
                    "label": 0
                },
                {
                    "sent": "I can simulate for each individual I toss a coin with probability \u03c0 to decide which community I'm going to put it in.",
                    "label": 0
                },
                {
                    "sent": "That gives me a partition.",
                    "label": 0
                },
                {
                    "sent": "Once I have that.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can compute this quantity, which is what the which was exactly the conditional probability.",
                    "label": 0
                },
                {
                    "sent": "Of the individual belonging to Community K. Given the data.",
                    "label": 0
                },
                {
                    "sent": "Right, the data being now not only the observed data, but the assignment that I've made.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wow, OK. Tells you what these terms are.",
                    "label": 0
                },
                {
                    "sent": "I don't think that's important.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But it's fairly clear that if you make.",
                    "label": 0
                },
                {
                    "sent": "If you make the number of simulations large enough.",
                    "label": 0
                },
                {
                    "sent": "Oh, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "I sort of jumped the last thing I should not have jumped over.",
                    "label": 0
                },
                {
                    "sent": "I take, of course, is my estimate of the posterior.",
                    "label": 0
                },
                {
                    "sent": "Probability the average over all the simulations.",
                    "label": 0
                },
                {
                    "sent": "And you can convince yourself fairly quickly that if you let the number of simulations go to Infinity, you are doing exactly the right thing.",
                    "label": 0
                },
                {
                    "sent": "If those were.",
                    "label": 0
                },
                {
                    "sent": "The population parameters.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK, I guess have two minutes for discussion.",
                    "label": 0
                },
                {
                    "sent": "It seems to be working out pretty well.",
                    "label": 0
                },
                {
                    "sent": "What this says is that the problem of Lambda sub N = N is easy.",
                    "label": 1
                },
                {
                    "sent": "Right, sort of any almost any reasonable modularity or likely functor, whatever.",
                    "label": 0
                },
                {
                    "sent": "Will get you the correct.",
                    "label": 0
                },
                {
                    "sent": "The correct labeling if this model holds.",
                    "label": 0
                },
                {
                    "sent": "However, it doesn't tell you that the model is necessarily reasonable, and in fact the line that I would argue one should pursue is the sieve method that I indicated at the beginning.",
                    "label": 0
                },
                {
                    "sent": "That is, you basically.",
                    "label": 0
                },
                {
                    "sent": "And divide into K. Intervals you have a model with K modularity you know of K communities.",
                    "label": 0
                },
                {
                    "sent": "Then you estimate actually.",
                    "label": 0
                },
                {
                    "sent": "You estimate this function H which we started out with.",
                    "label": 0
                },
                {
                    "sent": "Which is the Canonical which is the kernel function and then you look at it in the same way that one would look at a density estimate.",
                    "label": 0
                },
                {
                    "sent": "And and the modes of that would sort of tell you.",
                    "label": 0
                },
                {
                    "sent": "Where, how many communities, roughly?",
                    "label": 0
                },
                {
                    "sent": "You know who should belong to what community?",
                    "label": 0
                },
                {
                    "sent": "And so you're not committed to a particular structure.",
                    "label": 0
                },
                {
                    "sent": "OK, next.",
                    "label": 0
                },
                {
                    "sent": "This framework lends itself to generalization as an order of statistics.",
                    "label": 1
                },
                {
                    "sent": "That is, as I said, this is the analogue of IID variables.",
                    "label": 0
                },
                {
                    "sent": "Well, what do we do in order statistics when we form more complex models?",
                    "label": 0
                },
                {
                    "sent": "We simply add covariates.",
                    "label": 0
                },
                {
                    "sent": "Well, you can add covariance here too, right?",
                    "label": 0
                },
                {
                    "sent": "Like the identity, you know some people are in the same geographical location.",
                    "label": 0
                },
                {
                    "sent": "Some people are related.",
                    "label": 0
                },
                {
                    "sent": "By family ties.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You can also generalize fairly straightforwardly to the directed case, I believe, by basically dropping down to the undirected case by dropping the directions, wiping out the directions.",
                    "label": 0
                },
                {
                    "sent": "And then, um.",
                    "label": 0
                },
                {
                    "sent": "And then going back and estimating the directions after you estimate the communities.",
                    "label": 0
                },
                {
                    "sent": "And finally, I guess I should have started with this.",
                    "label": 0
                },
                {
                    "sent": "This is, I think, the right in some sense the right way to proceed, which should appeal to.",
                    "label": 0
                },
                {
                    "sent": "To an audience, at least the machine learning people.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe all of you in the audience, which is that you don't commit yourself.",
                    "label": 0
                },
                {
                    "sent": "To a particular model.",
                    "label": 0
                },
                {
                    "sent": "Particular parametric model you let the data somehow tell you.",
                    "label": 0
                },
                {
                    "sent": "What the structure is and that is, you estimate this H Canonical and that's it, thank you.",
                    "label": 0
                }
            ]
        }
    }
}