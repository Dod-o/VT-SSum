{
    "id": "pc3cljknvf6k44ow3hvgzksfnpl45fpj",
    "title": "Empirical Analysis of Ranking Models for an Adaptable Dataset Search",
    "info": {
        "author": [
            "Andre Paes Leme, Federal University of Rio de Janeiro"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2018_leme_empirical_analysis/",
    "segmentation": [
        [
            "Hello hi everyone.",
            "I am from from this University Brazil.",
            "I'm going to talk about.",
            "An experiments, an input for empirical analysis of hunky models for an adult, and adaptable and adaptable search.",
            "I'll go."
        ],
        [
            "Go into the motivation Y and how we did an adaptable data set.",
            "Search and then we're going to show show you some hanging functions where we can use in the adaptable search, and then the experiments we did to check the idea and then the adaptable search itself, and then the conclusions."
        ],
        [
            "So in many works.",
            "Has been highlighted that the link and open data is growing.",
            "It's poorly linked and it is also mainly linked with popular datasets such as DPJ names and so on.",
            "So.",
            "We have we have a challenge that is to expand the linking between data sets less popular than the one way we could do this is providing users editors of datasets tools to find datasets.",
            "All the datasets in which they would find links to their datasets.",
            "So this presentation is about one such a tool.",
            "One tool that would help users to find other datasets."
        ],
        [
            "So.",
            "First of all, we could think about the linking process as being three step process, the first in the first step.",
            "The editor would select relevant order datasets in which.",
            "The data set of the editor would likely.",
            "Find links to the data set, then next step.",
            "The second step would be inspect the contents of the GNU datasets found to find confer links, and finally the editors would make the link says please charging new RDF triples in their data set.",
            "The first task we do would do with hanker list of datasets that Hank at least would favor.",
            "Did data sets that would.",
            "Most likely contain links to the target data set and the second task we would do mainly were using link discovery algorithms.",
            "Gram any tools that were proposed to do this."
        ],
        [
            "And we see in our vision we see two use cases too.",
            "Run this process in the first use case.",
            "Now users would select manually data sets from the anchor lists.",
            "And you would use Link discovery algorithm on the content of each data set to find links and add the links the RDF triples, meaning the links in their data sets the second use case is more automated.",
            "We see a program, we see a computer program progressing, slice top slice of the Hank at least looking fallings and the at the end of the traversal.",
            "Bro Sis, the program would offer to the users.",
            "Candidate links at least of content, links that the users would check and approve some of them than the others not.",
            "And at the end add new RDF triples in their data sets.",
            "The aim of the second use case is to automate the process to speed up the process, avoiding the users avoiding user interactions in the middle of the process.",
            "So."
        ],
        [
            "However, while in the first use case, hanqing models can be compared using traditional and DCG curves.",
            "We see that in the second use case, the better the better measure, the better performance measure to compare.",
            "Hankins would be recall at position because when a program is traversing hankered lists, it doesn't matter if a very important data set is in the beginning of the lease or it's in the end of the portion traversed by the problem then.",
            "It."
        ],
        [
            "Comes the questions.",
            "He's the best hunting function under NDC criterion.",
            "The best ranking function under recall at position.",
            "This is what we want to know how far in the hanging to go in the use case, number 2.",
            "And finally, how it would be an adaptable data set search if hanging functions were distinct in the first question?",
            "To answer these questions, at least two give to have a riff indication.",
            "On the answers of this question, because we didn't prove any of these questions, we did some experiments to test the idea.",
            "So."
        ],
        [
            "We extracted data from data hub and used that data to Hank.",
            "Datasets and measure and compare hunting functions.",
            "Hanky modules and the first hunting function we used was based on bias in classifiers, and intuition is as follows.",
            "If a target data set has a set of metadata that is very frequent among the datasets that have entity links with the data set DI.",
            "Then it's likely that the target data set.",
            "Will have links to the entities of the Y as well.",
            "And the funnel that follows these intuition is the formula used in the bias and classifiers, which is written down there.",
            "I will not go into details about this formula, but we use this.",
            "These function with two.",
            "Kinds of.",
            "Sets of metadata we used link sets as the metadata of the data sets and we will.",
            "We also use used set of topic categories.",
            "Containing indeed datasets, I will tell you how we get.",
            "We got the topic at errors later."
        ],
        [
            "The second ranking function we used.",
            "I forgot to mention that we tested order hanging functions which are not here, but they are in the paper I'm showing you.",
            "I'm showing you just the best ones.",
            "The winners of the comparisons to have the show you the idea of the of the paper.",
            "The second ranking function is based on rule based classifiers.",
            "And we used binary classifiers, one binary classifier for each data set.",
            "So each binary classifier classifier data set, target target data set as containing links.",
            "Or not.",
            "To another given data set the eye, for example, their likelihood.",
            "We stated that the likelihood of a target data set has links to the eye.",
            "Would be proportional to the class probability.",
            "Of the classification of the classifier.",
            "So.",
            "Proportional to the class probability or.",
            "1 minus the class probability depending on whether the classifier.",
            "Had classified as.",
            "Die or not die?",
            "This was the 2nd.",
            "Hanging function we also used link sets and topic categories as the set of metadata.",
            "For the data sets."
        ],
        [
            "And the data is I said we extracted from data heard.",
            "There we find list of data sets and also dealing sets.",
            "We extracted from that set dumps and from sparkling points.",
            "The literals contained in each data set.",
            "From the literals.",
            "We use DPD spotlight to find entities.",
            "And then we went to DB pedia to find that those entities and we queried about the categories topic categories of the entities.",
            "And for each topic categories we also got the superclasses of the topic categories.",
            "Then the set of all topic categories contained.",
            "In the end she's related to the entities of the data set we used as the set of topic categories of the datasets."
        ],
        [
            "So we.",
            "We did a tenfold cross validation.",
            "For each partition of the cross validation, we hankered the remaining data sets.",
            "We knew which hang with data set would be should be higher in the hankered list because we know which link sets belongs to it.",
            "Data set from data hub.",
            "Then we had ground truth to compare with.",
            "And then we computed the N, DCG and recall at position what we got."
        ],
        [
            "Is this graph here?",
            "Well, we can see that there are there are two models.",
            "Better than the others, and these two are based on.",
            "Dubai is an classifier by the classifier, no bias.",
            "And yes, by using classify and the other one.",
            "He is based on social network.",
            "I didn't mention it before, but we used an approach and our hunting function based in based on social network measures of professional attachment an.",
            "An resource allocation, but as as it we considered it.",
            "Poor than the others.",
            "I didn't mention it before.",
            "A poor because of what because because in this method social network we need to compute the similarity set of the Alpha target data, set the data set to which we are recommending we are to each we're hanging the other datasets and it's the other methods.",
            "By using the rule based classifier J rip.",
            "Didn't need to compute the similarity set then it's better using a method less expensive.",
            "This is why we disregarded the social network based approach.",
            "It's here just to compare to C to show you the differences.",
            "So.",
            "Did the model, the ranking model that best performance in this graph here is based on?",
            "By Asian classifiers and using a set of 12 topic category as a metadata of the data set and then we have the best and ECG.",
            "The other, the next model that we that performed better was based on J RIP.",
            "It's rude classifier rule based classifier.",
            "But instead of using sorry, sorry, sorry.",
            "I said by using classify using topic after we know the best model uses link sets 5 link sets.",
            "The second one would be J rip through basic classifier, but instead of using five link setters, metadata of the target data set, we used 12 topic categories.",
            "These performed worse.",
            "But we could we could understand we can see we could learn from this graph.",
            "That when we know.",
            "Link sets about the data set.",
            "We could use that link sets in conjunction with the bias and class bias and score function.",
            "To have a better result if we don't know any link set about the data set which is the case of a brand new data set which is not linked to anyone with anyone we would use.",
            "Topic categories as the metadata of the data set and the topic, attackers can also.",
            "Canal can always be gathered from any data set, which is not true with link sets.",
            "And continuing the experiment."
        ],
        [
            "We compared the methods with recall at position.",
            "Well, we see now that the best model is the rule based classifier.",
            "But this time using the 12 category twelve categories topic categories.",
            "Anne."
        ],
        [
            "Which is.",
            "Can be up to 7%.",
            "Better than the best model under the other criterion of N DCG.",
            "Which is not that much, but if we see from and."
        ],
        [
            "Other perspective.",
            "It can save at least 13% of the traversal.",
            "Instead of traversing almost half.",
            "Hunk Hunk Hunk in East Hunk at least we could traverse just 35%.",
            "Almost 1/3 of the Hank at least which is which is good so."
        ],
        [
            "Then then we have we have."
        ],
        [
            "Two functions at least, actually not two functions to ranking functions.",
            "Three ranking functions, one hanging functions.",
            "When we know when we have the link sets one ranking function.",
            "When we don't have link sets as metadata and one hunky function when.",
            "We would use that automated process for traversing the anchor lists.",
            "So.",
            "How can we distinguish how can we use?",
            "How can we know when to use each hanqing function?"
        ],
        [
            "In Semantic web we usually do content disambiguation.",
            "Content negotiation to the reference you arise.",
            "Then we could use that content negotiation to understand to to notice, to perceive if it is a user request.",
            "Off its machine requests if user is interacting with the third tool.",
            "Probably the interface could send the contents at content mimetype.",
            "Human readable if it's a machine interacting with the search tool, did that machine could send a request using machine readable RDF MIME type.",
            "Then we could."
        ],
        [
            "Use a simple rule.",
            "To decide which ranking function which hunky model we would use.",
            "Two Hank how existing datasets?",
            "So if it's a human interaction.",
            "We would know if it's human interaction based on content negotiation.",
            "We would see if the target data set contains none linkset how we would do that?",
            "You reading divide description of the data set.",
            "We would use them.",
            "Bias and hiking function.",
            "If the target data set didn't have.",
            "Link sets.",
            "Only topic categories returning divide file.",
            "You would use them.",
            "They rip rule based classifier and also if it's the case of a machine interaction, we would use the JRE.",
            "Plus if I this would be our adaptable what we call an adaptable data set search to deal with.",
            "Model selection of the hanqing or an automated.",
            "Traversal of the hanqing to find links."
        ],
        [
            "So conclusions are then we have a challenge.",
            "Expanding linking in the web of data.",
            "Manually and automatic use cases are possible for search tools, and experiments indicate that adaptable search is possible and useful.",
            "And that's all."
        ],
        [
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello hi everyone.",
                    "label": 0
                },
                {
                    "sent": "I am from from this University Brazil.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "An experiments, an input for empirical analysis of hunky models for an adult, and adaptable and adaptable search.",
                    "label": 1
                },
                {
                    "sent": "I'll go.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go into the motivation Y and how we did an adaptable data set.",
                    "label": 0
                },
                {
                    "sent": "Search and then we're going to show show you some hanging functions where we can use in the adaptable search, and then the experiments we did to check the idea and then the adaptable search itself, and then the conclusions.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in many works.",
                    "label": 0
                },
                {
                    "sent": "Has been highlighted that the link and open data is growing.",
                    "label": 1
                },
                {
                    "sent": "It's poorly linked and it is also mainly linked with popular datasets such as DPJ names and so on.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have we have a challenge that is to expand the linking between data sets less popular than the one way we could do this is providing users editors of datasets tools to find datasets.",
                    "label": 0
                },
                {
                    "sent": "All the datasets in which they would find links to their datasets.",
                    "label": 0
                },
                {
                    "sent": "So this presentation is about one such a tool.",
                    "label": 0
                },
                {
                    "sent": "One tool that would help users to find other datasets.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "First of all, we could think about the linking process as being three step process, the first in the first step.",
                    "label": 0
                },
                {
                    "sent": "The editor would select relevant order datasets in which.",
                    "label": 1
                },
                {
                    "sent": "The data set of the editor would likely.",
                    "label": 1
                },
                {
                    "sent": "Find links to the data set, then next step.",
                    "label": 0
                },
                {
                    "sent": "The second step would be inspect the contents of the GNU datasets found to find confer links, and finally the editors would make the link says please charging new RDF triples in their data set.",
                    "label": 0
                },
                {
                    "sent": "The first task we do would do with hanker list of datasets that Hank at least would favor.",
                    "label": 1
                },
                {
                    "sent": "Did data sets that would.",
                    "label": 1
                },
                {
                    "sent": "Most likely contain links to the target data set and the second task we would do mainly were using link discovery algorithms.",
                    "label": 1
                },
                {
                    "sent": "Gram any tools that were proposed to do this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we see in our vision we see two use cases too.",
                    "label": 0
                },
                {
                    "sent": "Run this process in the first use case.",
                    "label": 1
                },
                {
                    "sent": "Now users would select manually data sets from the anchor lists.",
                    "label": 0
                },
                {
                    "sent": "And you would use Link discovery algorithm on the content of each data set to find links and add the links the RDF triples, meaning the links in their data sets the second use case is more automated.",
                    "label": 0
                },
                {
                    "sent": "We see a program, we see a computer program progressing, slice top slice of the Hank at least looking fallings and the at the end of the traversal.",
                    "label": 0
                },
                {
                    "sent": "Bro Sis, the program would offer to the users.",
                    "label": 0
                },
                {
                    "sent": "Candidate links at least of content, links that the users would check and approve some of them than the others not.",
                    "label": 0
                },
                {
                    "sent": "And at the end add new RDF triples in their data sets.",
                    "label": 0
                },
                {
                    "sent": "The aim of the second use case is to automate the process to speed up the process, avoiding the users avoiding user interactions in the middle of the process.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, while in the first use case, hanqing models can be compared using traditional and DCG curves.",
                    "label": 1
                },
                {
                    "sent": "We see that in the second use case, the better the better measure, the better performance measure to compare.",
                    "label": 0
                },
                {
                    "sent": "Hankins would be recall at position because when a program is traversing hankered lists, it doesn't matter if a very important data set is in the beginning of the lease or it's in the end of the portion traversed by the problem then.",
                    "label": 1
                },
                {
                    "sent": "It.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Comes the questions.",
                    "label": 0
                },
                {
                    "sent": "He's the best hunting function under NDC criterion.",
                    "label": 0
                },
                {
                    "sent": "The best ranking function under recall at position.",
                    "label": 1
                },
                {
                    "sent": "This is what we want to know how far in the hanging to go in the use case, number 2.",
                    "label": 1
                },
                {
                    "sent": "And finally, how it would be an adaptable data set search if hanging functions were distinct in the first question?",
                    "label": 1
                },
                {
                    "sent": "To answer these questions, at least two give to have a riff indication.",
                    "label": 0
                },
                {
                    "sent": "On the answers of this question, because we didn't prove any of these questions, we did some experiments to test the idea.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We extracted data from data hub and used that data to Hank.",
                    "label": 0
                },
                {
                    "sent": "Datasets and measure and compare hunting functions.",
                    "label": 0
                },
                {
                    "sent": "Hanky modules and the first hunting function we used was based on bias in classifiers, and intuition is as follows.",
                    "label": 0
                },
                {
                    "sent": "If a target data set has a set of metadata that is very frequent among the datasets that have entity links with the data set DI.",
                    "label": 1
                },
                {
                    "sent": "Then it's likely that the target data set.",
                    "label": 1
                },
                {
                    "sent": "Will have links to the entities of the Y as well.",
                    "label": 0
                },
                {
                    "sent": "And the funnel that follows these intuition is the formula used in the bias and classifiers, which is written down there.",
                    "label": 0
                },
                {
                    "sent": "I will not go into details about this formula, but we use this.",
                    "label": 0
                },
                {
                    "sent": "These function with two.",
                    "label": 0
                },
                {
                    "sent": "Kinds of.",
                    "label": 1
                },
                {
                    "sent": "Sets of metadata we used link sets as the metadata of the data sets and we will.",
                    "label": 0
                },
                {
                    "sent": "We also use used set of topic categories.",
                    "label": 0
                },
                {
                    "sent": "Containing indeed datasets, I will tell you how we get.",
                    "label": 0
                },
                {
                    "sent": "We got the topic at errors later.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second ranking function we used.",
                    "label": 0
                },
                {
                    "sent": "I forgot to mention that we tested order hanging functions which are not here, but they are in the paper I'm showing you.",
                    "label": 0
                },
                {
                    "sent": "I'm showing you just the best ones.",
                    "label": 0
                },
                {
                    "sent": "The winners of the comparisons to have the show you the idea of the of the paper.",
                    "label": 0
                },
                {
                    "sent": "The second ranking function is based on rule based classifiers.",
                    "label": 0
                },
                {
                    "sent": "And we used binary classifiers, one binary classifier for each data set.",
                    "label": 0
                },
                {
                    "sent": "So each binary classifier classifier data set, target target data set as containing links.",
                    "label": 1
                },
                {
                    "sent": "Or not.",
                    "label": 0
                },
                {
                    "sent": "To another given data set the eye, for example, their likelihood.",
                    "label": 0
                },
                {
                    "sent": "We stated that the likelihood of a target data set has links to the eye.",
                    "label": 1
                },
                {
                    "sent": "Would be proportional to the class probability.",
                    "label": 1
                },
                {
                    "sent": "Of the classification of the classifier.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "Proportional to the class probability or.",
                    "label": 0
                },
                {
                    "sent": "1 minus the class probability depending on whether the classifier.",
                    "label": 0
                },
                {
                    "sent": "Had classified as.",
                    "label": 1
                },
                {
                    "sent": "Die or not die?",
                    "label": 0
                },
                {
                    "sent": "This was the 2nd.",
                    "label": 0
                },
                {
                    "sent": "Hanging function we also used link sets and topic categories as the set of metadata.",
                    "label": 0
                },
                {
                    "sent": "For the data sets.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the data is I said we extracted from data heard.",
                    "label": 0
                },
                {
                    "sent": "There we find list of data sets and also dealing sets.",
                    "label": 0
                },
                {
                    "sent": "We extracted from that set dumps and from sparkling points.",
                    "label": 0
                },
                {
                    "sent": "The literals contained in each data set.",
                    "label": 0
                },
                {
                    "sent": "From the literals.",
                    "label": 0
                },
                {
                    "sent": "We use DPD spotlight to find entities.",
                    "label": 0
                },
                {
                    "sent": "And then we went to DB pedia to find that those entities and we queried about the categories topic categories of the entities.",
                    "label": 0
                },
                {
                    "sent": "And for each topic categories we also got the superclasses of the topic categories.",
                    "label": 0
                },
                {
                    "sent": "Then the set of all topic categories contained.",
                    "label": 1
                },
                {
                    "sent": "In the end she's related to the entities of the data set we used as the set of topic categories of the datasets.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "We did a tenfold cross validation.",
                    "label": 0
                },
                {
                    "sent": "For each partition of the cross validation, we hankered the remaining data sets.",
                    "label": 1
                },
                {
                    "sent": "We knew which hang with data set would be should be higher in the hankered list because we know which link sets belongs to it.",
                    "label": 0
                },
                {
                    "sent": "Data set from data hub.",
                    "label": 0
                },
                {
                    "sent": "Then we had ground truth to compare with.",
                    "label": 0
                },
                {
                    "sent": "And then we computed the N, DCG and recall at position what we got.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is this graph here?",
                    "label": 0
                },
                {
                    "sent": "Well, we can see that there are there are two models.",
                    "label": 0
                },
                {
                    "sent": "Better than the others, and these two are based on.",
                    "label": 0
                },
                {
                    "sent": "Dubai is an classifier by the classifier, no bias.",
                    "label": 0
                },
                {
                    "sent": "And yes, by using classify and the other one.",
                    "label": 0
                },
                {
                    "sent": "He is based on social network.",
                    "label": 0
                },
                {
                    "sent": "I didn't mention it before, but we used an approach and our hunting function based in based on social network measures of professional attachment an.",
                    "label": 0
                },
                {
                    "sent": "An resource allocation, but as as it we considered it.",
                    "label": 0
                },
                {
                    "sent": "Poor than the others.",
                    "label": 0
                },
                {
                    "sent": "I didn't mention it before.",
                    "label": 0
                },
                {
                    "sent": "A poor because of what because because in this method social network we need to compute the similarity set of the Alpha target data, set the data set to which we are recommending we are to each we're hanging the other datasets and it's the other methods.",
                    "label": 0
                },
                {
                    "sent": "By using the rule based classifier J rip.",
                    "label": 0
                },
                {
                    "sent": "Didn't need to compute the similarity set then it's better using a method less expensive.",
                    "label": 0
                },
                {
                    "sent": "This is why we disregarded the social network based approach.",
                    "label": 0
                },
                {
                    "sent": "It's here just to compare to C to show you the differences.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Did the model, the ranking model that best performance in this graph here is based on?",
                    "label": 0
                },
                {
                    "sent": "By Asian classifiers and using a set of 12 topic category as a metadata of the data set and then we have the best and ECG.",
                    "label": 0
                },
                {
                    "sent": "The other, the next model that we that performed better was based on J RIP.",
                    "label": 0
                },
                {
                    "sent": "It's rude classifier rule based classifier.",
                    "label": 0
                },
                {
                    "sent": "But instead of using sorry, sorry, sorry.",
                    "label": 0
                },
                {
                    "sent": "I said by using classify using topic after we know the best model uses link sets 5 link sets.",
                    "label": 0
                },
                {
                    "sent": "The second one would be J rip through basic classifier, but instead of using five link setters, metadata of the target data set, we used 12 topic categories.",
                    "label": 0
                },
                {
                    "sent": "These performed worse.",
                    "label": 0
                },
                {
                    "sent": "But we could we could understand we can see we could learn from this graph.",
                    "label": 0
                },
                {
                    "sent": "That when we know.",
                    "label": 0
                },
                {
                    "sent": "Link sets about the data set.",
                    "label": 0
                },
                {
                    "sent": "We could use that link sets in conjunction with the bias and class bias and score function.",
                    "label": 0
                },
                {
                    "sent": "To have a better result if we don't know any link set about the data set which is the case of a brand new data set which is not linked to anyone with anyone we would use.",
                    "label": 0
                },
                {
                    "sent": "Topic categories as the metadata of the data set and the topic, attackers can also.",
                    "label": 0
                },
                {
                    "sent": "Canal can always be gathered from any data set, which is not true with link sets.",
                    "label": 0
                },
                {
                    "sent": "And continuing the experiment.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We compared the methods with recall at position.",
                    "label": 0
                },
                {
                    "sent": "Well, we see now that the best model is the rule based classifier.",
                    "label": 0
                },
                {
                    "sent": "But this time using the 12 category twelve categories topic categories.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Can be up to 7%.",
                    "label": 1
                },
                {
                    "sent": "Better than the best model under the other criterion of N DCG.",
                    "label": 0
                },
                {
                    "sent": "Which is not that much, but if we see from and.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other perspective.",
                    "label": 0
                },
                {
                    "sent": "It can save at least 13% of the traversal.",
                    "label": 0
                },
                {
                    "sent": "Instead of traversing almost half.",
                    "label": 0
                },
                {
                    "sent": "Hunk Hunk Hunk in East Hunk at least we could traverse just 35%.",
                    "label": 0
                },
                {
                    "sent": "Almost 1/3 of the Hank at least which is which is good so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then then we have we have.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two functions at least, actually not two functions to ranking functions.",
                    "label": 0
                },
                {
                    "sent": "Three ranking functions, one hanging functions.",
                    "label": 0
                },
                {
                    "sent": "When we know when we have the link sets one ranking function.",
                    "label": 0
                },
                {
                    "sent": "When we don't have link sets as metadata and one hunky function when.",
                    "label": 0
                },
                {
                    "sent": "We would use that automated process for traversing the anchor lists.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How can we distinguish how can we use?",
                    "label": 0
                },
                {
                    "sent": "How can we know when to use each hanqing function?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In Semantic web we usually do content disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Content negotiation to the reference you arise.",
                    "label": 0
                },
                {
                    "sent": "Then we could use that content negotiation to understand to to notice, to perceive if it is a user request.",
                    "label": 0
                },
                {
                    "sent": "Off its machine requests if user is interacting with the third tool.",
                    "label": 0
                },
                {
                    "sent": "Probably the interface could send the contents at content mimetype.",
                    "label": 0
                },
                {
                    "sent": "Human readable if it's a machine interacting with the search tool, did that machine could send a request using machine readable RDF MIME type.",
                    "label": 1
                },
                {
                    "sent": "Then we could.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use a simple rule.",
                    "label": 0
                },
                {
                    "sent": "To decide which ranking function which hunky model we would use.",
                    "label": 0
                },
                {
                    "sent": "Two Hank how existing datasets?",
                    "label": 0
                },
                {
                    "sent": "So if it's a human interaction.",
                    "label": 1
                },
                {
                    "sent": "We would know if it's human interaction based on content negotiation.",
                    "label": 0
                },
                {
                    "sent": "We would see if the target data set contains none linkset how we would do that?",
                    "label": 0
                },
                {
                    "sent": "You reading divide description of the data set.",
                    "label": 0
                },
                {
                    "sent": "We would use them.",
                    "label": 0
                },
                {
                    "sent": "Bias and hiking function.",
                    "label": 1
                },
                {
                    "sent": "If the target data set didn't have.",
                    "label": 0
                },
                {
                    "sent": "Link sets.",
                    "label": 0
                },
                {
                    "sent": "Only topic categories returning divide file.",
                    "label": 0
                },
                {
                    "sent": "You would use them.",
                    "label": 0
                },
                {
                    "sent": "They rip rule based classifier and also if it's the case of a machine interaction, we would use the JRE.",
                    "label": 1
                },
                {
                    "sent": "Plus if I this would be our adaptable what we call an adaptable data set search to deal with.",
                    "label": 0
                },
                {
                    "sent": "Model selection of the hanqing or an automated.",
                    "label": 0
                },
                {
                    "sent": "Traversal of the hanqing to find links.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So conclusions are then we have a challenge.",
                    "label": 0
                },
                {
                    "sent": "Expanding linking in the web of data.",
                    "label": 0
                },
                {
                    "sent": "Manually and automatic use cases are possible for search tools, and experiments indicate that adaptable search is possible and useful.",
                    "label": 1
                },
                {
                    "sent": "And that's all.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}