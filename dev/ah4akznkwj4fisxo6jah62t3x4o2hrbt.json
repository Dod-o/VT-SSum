{
    "id": "ah4akznkwj4fisxo6jah62t3x4o2hrbt",
    "title": "Steppest descent analysis for unregularized linear prediction with strictly convex penalties",
    "info": {
        "author": [
            "Matus Telgarsky, Department of Computer Science and Engineering, UC San Diego"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_telgarsky_penalties/",
    "segmentation": [
        [
            "OK, so briefly it only lists my name, but I'd like to think I had an anonymous reviewer that gave extremely good criticism.",
            "So if this ends up looking much cleaner than what you saw it, thanks to the reviewer.",
            "So this talk is going to be kind of in the nuts and bolts of classical gradient descent issues, and this came about from an analysis of a specific problem I studied, and it was kind of fascinating to me to see some gaps in classical analysis.",
            "So just let me just say one kind of philosophical point.",
            "This talk doesn't have anything to do about whether I.",
            "Suggest we should regularize or not.",
            "In fact, you'll notice that I leave out the issue of stopping conditions.",
            "I'm just analyzing a class of algorithms that are used widely in practice and have not been analyzed.",
            "So my goal was simply people use these algorithms.",
            "I'm not trying to argue whether good or not, I'm just trying to give a good convergence now so we can compare them to other variants."
        ],
        [
            "So let's get started.",
            "So here's our setup.",
            "I have a function F and I have a matrix A, so the objective function is F composed with a have some conditions on F. It's strictly convex, twice stretchable bounded below, so I haven't infima bounded below.",
            "I have any female finite everywhere, so I don't have any tricky constraint sets.",
            "And it has Lipschitz gradients.",
            "I haven't said anything about strong convexity, just strict convexity, and the algorithm is steepest descent.",
            "So I'm using the terminology of Boyd here.",
            "It's not truly standard, but when you choose the dissent direction, it's this inner product, and you do it with an enormous that looks familiar.",
            "It looks kind of like the dual norm definition, so there's nice dual norm property about this.",
            "But basically if you instantiate the norm with L2, you get great descent, L1, you get cornered, dissent, maybe you can use other norms if you want.",
            "And then I use an aggressive line search.",
            "You can ask me about the line search later.",
            "But it's basically an exact line search."
        ],
        [
            "OK, so there's the primal problem and I'm writing it in two ways because I'll it'll be useful to kick around different formulations of the primal problem.",
            "So there are two difficulties with this.",
            "One is it's not strictly convex.",
            "It has these flat regions, so if you open up a standard textbook on gradient descent for these, it needs this needs.",
            "Can't handle these flat regions, so for instance if A has duplicated columns, if A has linear dependencies in columns, we have these difficulties.",
            "Think about if I duplicate columns, why is it probably harder?",
            "So OK, so there is an analysis that can handle this.",
            "It's by Lou and sang.",
            "It gives a clue Q linear convergence, so if you delete a finite prefix of the iteration stream then you have a nice linear convergence after that.",
            "Then there is a more serious issue, which is what really kind of motivated me to submit to this workshop, which is the objective function might not have a minimizer and.",
            "It's actually.",
            "Shocking how difficult this case is.",
            "So one comment I've received is OK. Well, let's use the Nesterov method.",
            "So if you look actually saying has a nice analysis of Nesterov methods that don't depend on the existence of a minimizer, so let's just go and look at the House one over root epsilon.",
            "However, we've got a Bregman term in the OH this Bregman term.",
            "If we have minimized, we can plug it in, treated as a constant, but this Bregman term for using a strongly convex function of parameters, or bristly, do if we put in a minimizing sequence, this bound is going to grow.",
            "What I'm saying is that.",
            "This Bregman term is now a function of epsilon, so we can't just say one over root.",
            "We can't just say one over epsilon.",
            "I'm not saying the rate isn't that, but I'm saying that you have to be a little bit careful when formulating these convergence rates, so.",
            "So yeah, this this issue of not having a minimizer is quite difficult, so these are the two issues.",
            "Let me just say one more thing about using other methods, which is that typically you would regularize.",
            "So one way you would solve this problem with like an accelerated method of regularizer in you construct a Lipschitz coefficient on it, so that you're very close to the optimum of the original prob."
        ],
        [
            "OK, so I'm going to give you a call, a template theorem because two reasons I I don't have what I consider a total theory of what happens when you don't have a minimizer.",
            "Furthermore, all the conditions like started come up with look very complicated.",
            "I only know one instance of a widely used loss function that's very widely used in practice that does not minimize her, so I kept making generalizations with the only constraint being that they still contained one problem, so it sounded it was kind of contrived, so that's why they call it a template theorem.",
            "And then I'll talk about some of these special case."
        ],
        [
            "This is.",
            "OK, so actually this talk should seem quite simple because there's a very simple solution to all of our problems.",
            "If we look at the dual and notice I've rewritten the primal to make this duality kind of more obviously in the primal as the constraint optimization over this subspace, you take the dual when I write stars, I mean Fenchel conjugates.",
            "Now this is the fundamental duality of the Spanish.",
            "I am as always how I write span of this matrix spaniel left nullspace.",
            "So here's this duality.",
            "So let's take a look at this.",
            "Because I assume differentiability, my fundamental conjugates always strictly convex, so I have strict convexity because I was bounded below.",
            "The dual problem has a maximizer, so I have a unique maximizer by strict convexity.",
            "And Furthermore, this tricky matrix A has been moved into the constraints set, so actually this is a fairly accurate representation of one of the problems I'll talk about today.",
            "This black line represents the actual constraint problem.",
            "And so so you know the idea is look if the dual looks simple, let's do the analysis in the dual.",
            "That's exactly what we do I make."
        ],
        [
            "Potential function, which is the distance the dual feasible set.",
            "So by optimality conditions as you know, as you reach optimal in the primal, you're reaching feasibility in the tool, so that's what's going on here.",
            "When I fight either just my gradients and notice I leave the out so the gradient using matrix, the gradient of F composed of A is a transpose gradient FA, but I'm leaving out the A. I'll get to that there's this tricky set S that floats around for technical reasons.",
            "That's all I can really say that right now just to make this more parameterized bowl and easy to use.",
            "I have a triple norm is going just another norm, one of them still talk about tables held well, two for the two norms.",
            "One will have a 1L in Fig."
        ],
        [
            "We OK, so this looks a little bit hairy, but this is the fundamental quantity that will let us parse this object.",
            "So I'm going to fast.",
            "Let me actually do this a little bit more slowly so this quantity looks a little scary.",
            "What's really going on here is so this is this potential function.",
            "We had this the distance the dual feasible set the numerator, which just looks like a transpose FI.",
            "I can slip in there anybody in that left nullspace?",
            "So another way to write this subject?",
            "Another way to write this object is I can put if you consider this to be a projection element, it's non unique in the case of norms like L1, Infinity.",
            "But we can take this be a projection.",
            "I can plug it in there.",
            "So what this guy looks like is basically a transpose.",
            "This projection direction divided by projection direction.",
            "Now.",
            "Since I'm saying that Phi cannot be in this left null space, this in FEMA is always positive over its domain.",
            "The trickiness, of course, is showing that the infimum is zero, and this is.",
            "So if you want to see where things get hard, this is where it happens, but as long as S is polyhedral, this ends up working out.",
            "So I actually have a counterexample, RSS curvature and these vectors kind of these projection vectors kind of slowly get more and more close to the kernel, and you actually get a zero in here.",
            "Now.",
            "The reason why this does is good is because we have this potential function where we're going to handle the analysis.",
            "We're just going to upper lower bound it with useful quantities, and then we'll get a convergence rate.",
            "So this is fairly standard.",
            "One reason I liked writing it this way is because the mirror descent analysis.",
            "One way to write Meredith sent analysis, you have a potential function which is just the ultimate awaits you upper bound it and you lower bound.",
            "Interesting there you lower bound it with duality arguments.",
            "You upper bound it with divergences.",
            "That is a primal argument.",
            "I'm doing my nails in the dual I lower bound with dual Bregman divergences and upper bound.",
            "With this line search guarantee.",
            "So let me see what's going on here.",
            "This first step here.",
            "So this once again is just the denominator here.",
            "So I can instantiate this infima with one of my gradient elements.",
            "I can just instantiate the element I can instantiate with the current gradient element.",
            "And So what happens is this basically tells me to scaling if I go from this to that.",
            "So I just have to divide by that squared squared it.",
            "So this is basically just a death.",
            "This definition instantiated for that.",
            "And so this is kind of the magic step that lets us get around these duplicated columns.",
            "However, I'm going too fast so it's fine.",
            "Would it?",
            "Would it be just as doable to say there exist some pie in the kernel?",
            "That will make make the analysis work like 'cause S just be a Singleton no.",
            "OK, so first of all, sometimes when S is a sink, OK so.",
            "If S is a Singleton, then you can still have vectors that are inside the kernel, so this can.",
            "This can be set.",
            "This can become zero then so.",
            "The.",
            "So you have to be.",
            "Yeah, you have to be pretty careful about that.",
            "The other thing that might be a little bit strange, so that the choice of S will be depending on how I do the Bregman step and so.",
            "But it's completely up to you to choose us.",
            "Yeah, so for instance, one place, so I'm not going to talk about the construction of the S here, but.",
            "I had an analysis of boosting and I had to carefully choose these asses and actually I'm going too fast so I can tell you how I construct the S and in a proof that I missed that I kind of sketched out here.",
            "But basically it's not an algorithm components anality component, just need to control this set S. Yeah.",
            "And it actually has been fairly obvious all the times I've needed to do it.",
            "I just took things like cubes and stuff like that, 'cause it probably was never really difficult.",
            "OK, so this is just from some rearrangement here.",
            "The second part is a standard guarantee you get out of a line search update.",
            "Yeah, so this is just if you.",
            "If you look at up like a standard textbook about how it does the gradient descent analysis, you can see the second inequality.",
            "Oh, I should say one thing, Lt is the Lipschitz coefficient for the current sublevel set.",
            "So rather than having a Lipschitz coefficient for the entire domain, I keep refining the Lipschitz coefficient.",
            "This is kind of this might sound like a hack, but what's interesting is I have an example where I get a one over epsilon rate.",
            "I don't do this tightening and I get the log one of epsilon.",
            "If I do the careful analysis.",
            "So it's I'll try to demystify that."
        ],
        [
            "OK, so now that was the upper bound potential.",
            "This is why I call it a template theorem and I'm a little embarrassed about it is because the lower bound I just say if you can prove this lower bound in this form, then you have these rates.",
            "Now let me tell you what this lower bound is saying, so ignore these guys here.",
            "This is the this is the Bregman divergences, the Bregman distance.",
            "Don't worry bout the F star that just defensive conjugate.",
            "That's like our natural notion of distance point objective in the tool.",
            "So I've got this dual distance distance to dual feasible set refined by S, so I want that to be lower bounded by this norms distance.",
            "So one of the intuitions behind Mr. Kind of like norms and usually you can.",
            "If you've got like a strongly convex function you plug into your Bregman divergences, then you can get it lower bounded by normal.",
            "We need to be upper bounded by Norm, one case where you can prove something like this without any math or so, without any without getting too hairy and worrying about S, is if the primal is strongly convex.",
            "You get this in the dual.",
            "Use this a little bit later.",
            "That's actually a nice proof by Sheila Shorts.",
            "So and you are missing are so I just wanted to do this, but we're basically comparing these Bregman divergences to the distances that we're trying to approximate.",
            "OK, so and in particular we can prove this inequality if we can prove this inequality with K equal to 1, we get logarithm.",
            "We get these linear rates and then if we can prove with equals two we get the.",
            "Any arbitrary divergent you can upper bounded using.",
            "So you have to you have to be fair.",
            "This is where you have to design S very carefully.",
            "In fact.",
            "In fact, I made a mistake with this once.",
            "Squares of North look like they're more like squares of norms, yeah.",
            "In fact, Bregman divergences have a Pythagorean theorem, which means they can't be norms.",
            "So.",
            "I'm trying to leave about 3 minutes for questions, so I realize that I'm kind of papering over.",
            "OK, so."
        ],
        [
            "Less so terric, let me give some give 2 examples that I think."
        ],
        [
            "A little bit interesting, let me just say what happens when.",
            "This has minimizers, and we have strict convexity, and I'm defining in terms of a positive definite Hessian.",
            "Notice I haven't written.",
            "I haven't written something something positive times the identity matrix.",
            "I'm not saying is strongly convex, I'm saying so in particularly FEMA over the entire domain might have this to be just 00.",
            "Modulus of strong convexity.",
            "So now here's another trick.",
            "I'm going to use to rewrite the primal.",
            "I'm going to once again write it, as this is my indicator.",
            "No one uses notation.",
            "I should stop.",
            "This is the.",
            "This is the indicator of the of that subspace.",
            "So now I've kind of thrown out this problem of duplicated columns.",
            "This is just strict strictly convex function, but it has a constraint as a constraint set.",
            "So that means is strongly convex, can just take the infimum of this because I said twice continuously differentiable earlier.",
            "That's why I use it.",
            "I use it to get this.",
            "I use this trick from Schwartz to get that, I plug that in, I get the K = 1.",
            "And I've left out what the S is.",
            "You could just eigenvalue of this.",
            "Oh yeah, that's actually very interesting, so you're running with the C is here.",
            "OK, so the problem is that this has to be over there for the specter.",
            "That set S let me tell you, construct the set S. In this case, it's kind of a disaster.",
            "I take the sublevel set in the primal I project into the tool.",
            "I still have a compact set because I have continuous different derivatives compact set.",
            "Now I take a polyhedral approximation of it so I know for any epsilon there's like a Hausdorff close.",
            "Polyhedron and I have to be careful because I can't hit my constraint 'cause the dual, even though the Primals unconcerned though, might be constrained.",
            "I'd be careful about how we construct that, but you can do it just might have really I don't have it on the number of faces, so you get this polyhedron.",
            "Then you have to map that polyhedron back.",
            "You have to put it back into the primal and I have some weird set and you compute strong convexity computer for that.",
            "So it will be something like the inverse.",
            "The eigenvalue in the primal but with respect to that set.",
            "So based on what this mapping does, it's not really clear.",
            "But let me come back to that question in just a minute.",
            "So here are some examples.",
            "So once again, this is unregularized, so these, I admit are quite contrived, so I'm sorry we can ask.",
            "You can ask about how I change the objective function regular regularization later, so least squares strongly convex.",
            "That's kind of easy.",
            "So I get login website for both of these without needing to worry about.",
            "That A and then that one log cosh.",
            "That's a very nice.",
            "It's like a Huber's approximation Huber loss that strictly convex.",
            "Super losses, not really convex.",
            "So that's not strongly convex and we still get the login upsilon boosting.",
            "If boosting has a minimizer.",
            "Then it also gets that and this is a funny one, so quadratics with positive semidefinite hessian's I get log one over epsilon I get.",
            "So if you look into standard textbook you need you need positive definiteness, not positive semidefinite NIS.",
            "And actually for this case I worked out all the constants in the proof.",
            "It's easy for this one 'cause all my norms are two norms.",
            "The constant, so if you look in sorry I don't remember if it's in your book, but I know it's Stephen Boyd's book.",
            "Sorry, but you can get a bound that looks like the ratio of the min and Max eigen values.",
            "For this one you get a ratio of the min and Max positive singular values, so it's about as nice as you could expect.",
            "Yeah.",
            "Minimum maximum yeah non negative right?",
            "So it's basically exactly what you could hope for basically.",
            "Optimizing knowing where the current.",
            "Yeah, I mean so when I obviously when I first proved this and I saw that it had been proved, I got very scared that I had an error.",
            "So let me repeat once again that pulsing has this Culin here convergence where you delete the finite prefix for all of these.",
            "Actually his analysis much more powerful than mine can handle much more powerful objectives.",
            "Another so one intuition is like the thing I said about duplicating columns, and if you add columns in that are linearly dependent, you kind of give the algorithm or choice.",
            "So this is kind of my late my lazy intuition about what."
        ],
        [
            "Going on here.",
            "OK, so for the last let me just maybe I went a little slow.",
            "So here's why.",
            "So let me just say one really key thing.",
            "So boosting is an example where you do not have a minimizer 'cause things go off to Infinity.",
            "Now let me tell you, I'll skip most of this stuff.",
            "Let me just tell you the interesting thing about the analysis.",
            "When I had minimizers, I use strong convexity, strong convexity's, like for what I know from my grad school experiences doing optimization.",
            "It's like our workforce, so I needed a workhorse that worked in these situations without strong convexity when the when the minimizer goes out to Infinity.",
            "I needed something, and I reverse engineered the property that made the proof work, which is kind of embarrassing again, but I call it a flattening condition.",
            "Let me just explain what this means, because it's actually very.",
            "Simple and has a good intuition.",
            "Thanks.",
            "So the upper bound says their distance to the optimum is less single to your current gradient.",
            "What that means is if gradients are really so, that means the gradient can't become flat.",
            "IE you can't do very much with the great dissent method without being really close to the optimum.",
            "That's the upper bound means.",
            "If I only have the upper bound to get one over epsilon, the lower bound says near the optimum guy is super flat white.",
            "Does that sound like it helps?",
            "It's because I'm using line searches.",
            "That means if it's super flat, the line search basically just shoots at the optimum.",
            "So this is what I used to get the login or epsilon.",
            "So this is actually why boosting convergence rates was such a difficult orchestration say that that's why it was unresolved for awhile is because you needed something else."
        ],
        [
            "To analyze what happened, I feel like I. Bing.",
            "Yeah, so I do.",
            "I did analyze the closed form, kind of one over Lipschitz.",
            "It doesn't work as well in practice, it does get the same rate, but just like minimizing and upgrading quadratic.",
            "So the details of that are very interesting.",
            "Let me just."
        ],
        [
            "We just closed with just a summary, so this case with the linear prints for the minimizers.",
            "Then I have a very kind of loose strategy for some things, not minimizers."
        ],
        [
            "And was curious to me is I don't believe in this flattening condition I used actually Kartik.",
            "Should RN came by to my poster and had some very insightful in comments on what it actually means.",
            "So someone must figure out a better one.",
            "I'd love to hear about it, so thanks and that's the end of the talk."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so briefly it only lists my name, but I'd like to think I had an anonymous reviewer that gave extremely good criticism.",
                    "label": 0
                },
                {
                    "sent": "So if this ends up looking much cleaner than what you saw it, thanks to the reviewer.",
                    "label": 0
                },
                {
                    "sent": "So this talk is going to be kind of in the nuts and bolts of classical gradient descent issues, and this came about from an analysis of a specific problem I studied, and it was kind of fascinating to me to see some gaps in classical analysis.",
                    "label": 0
                },
                {
                    "sent": "So just let me just say one kind of philosophical point.",
                    "label": 0
                },
                {
                    "sent": "This talk doesn't have anything to do about whether I.",
                    "label": 0
                },
                {
                    "sent": "Suggest we should regularize or not.",
                    "label": 0
                },
                {
                    "sent": "In fact, you'll notice that I leave out the issue of stopping conditions.",
                    "label": 0
                },
                {
                    "sent": "I'm just analyzing a class of algorithms that are used widely in practice and have not been analyzed.",
                    "label": 0
                },
                {
                    "sent": "So my goal was simply people use these algorithms.",
                    "label": 0
                },
                {
                    "sent": "I'm not trying to argue whether good or not, I'm just trying to give a good convergence now so we can compare them to other variants.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's get started.",
                    "label": 0
                },
                {
                    "sent": "So here's our setup.",
                    "label": 0
                },
                {
                    "sent": "I have a function F and I have a matrix A, so the objective function is F composed with a have some conditions on F. It's strictly convex, twice stretchable bounded below, so I haven't infima bounded below.",
                    "label": 1
                },
                {
                    "sent": "I have any female finite everywhere, so I don't have any tricky constraint sets.",
                    "label": 0
                },
                {
                    "sent": "And it has Lipschitz gradients.",
                    "label": 0
                },
                {
                    "sent": "I haven't said anything about strong convexity, just strict convexity, and the algorithm is steepest descent.",
                    "label": 0
                },
                {
                    "sent": "So I'm using the terminology of Boyd here.",
                    "label": 0
                },
                {
                    "sent": "It's not truly standard, but when you choose the dissent direction, it's this inner product, and you do it with an enormous that looks familiar.",
                    "label": 0
                },
                {
                    "sent": "It looks kind of like the dual norm definition, so there's nice dual norm property about this.",
                    "label": 0
                },
                {
                    "sent": "But basically if you instantiate the norm with L2, you get great descent, L1, you get cornered, dissent, maybe you can use other norms if you want.",
                    "label": 0
                },
                {
                    "sent": "And then I use an aggressive line search.",
                    "label": 0
                },
                {
                    "sent": "You can ask me about the line search later.",
                    "label": 0
                },
                {
                    "sent": "But it's basically an exact line search.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there's the primal problem and I'm writing it in two ways because I'll it'll be useful to kick around different formulations of the primal problem.",
                    "label": 0
                },
                {
                    "sent": "So there are two difficulties with this.",
                    "label": 0
                },
                {
                    "sent": "One is it's not strictly convex.",
                    "label": 1
                },
                {
                    "sent": "It has these flat regions, so if you open up a standard textbook on gradient descent for these, it needs this needs.",
                    "label": 0
                },
                {
                    "sent": "Can't handle these flat regions, so for instance if A has duplicated columns, if A has linear dependencies in columns, we have these difficulties.",
                    "label": 0
                },
                {
                    "sent": "Think about if I duplicate columns, why is it probably harder?",
                    "label": 0
                },
                {
                    "sent": "So OK, so there is an analysis that can handle this.",
                    "label": 0
                },
                {
                    "sent": "It's by Lou and sang.",
                    "label": 0
                },
                {
                    "sent": "It gives a clue Q linear convergence, so if you delete a finite prefix of the iteration stream then you have a nice linear convergence after that.",
                    "label": 0
                },
                {
                    "sent": "Then there is a more serious issue, which is what really kind of motivated me to submit to this workshop, which is the objective function might not have a minimizer and.",
                    "label": 1
                },
                {
                    "sent": "It's actually.",
                    "label": 0
                },
                {
                    "sent": "Shocking how difficult this case is.",
                    "label": 0
                },
                {
                    "sent": "So one comment I've received is OK. Well, let's use the Nesterov method.",
                    "label": 0
                },
                {
                    "sent": "So if you look actually saying has a nice analysis of Nesterov methods that don't depend on the existence of a minimizer, so let's just go and look at the House one over root epsilon.",
                    "label": 0
                },
                {
                    "sent": "However, we've got a Bregman term in the OH this Bregman term.",
                    "label": 0
                },
                {
                    "sent": "If we have minimized, we can plug it in, treated as a constant, but this Bregman term for using a strongly convex function of parameters, or bristly, do if we put in a minimizing sequence, this bound is going to grow.",
                    "label": 0
                },
                {
                    "sent": "What I'm saying is that.",
                    "label": 0
                },
                {
                    "sent": "This Bregman term is now a function of epsilon, so we can't just say one over root.",
                    "label": 0
                },
                {
                    "sent": "We can't just say one over epsilon.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying the rate isn't that, but I'm saying that you have to be a little bit careful when formulating these convergence rates, so.",
                    "label": 1
                },
                {
                    "sent": "So yeah, this this issue of not having a minimizer is quite difficult, so these are the two issues.",
                    "label": 0
                },
                {
                    "sent": "Let me just say one more thing about using other methods, which is that typically you would regularize.",
                    "label": 0
                },
                {
                    "sent": "So one way you would solve this problem with like an accelerated method of regularizer in you construct a Lipschitz coefficient on it, so that you're very close to the optimum of the original prob.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to give you a call, a template theorem because two reasons I I don't have what I consider a total theory of what happens when you don't have a minimizer.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, all the conditions like started come up with look very complicated.",
                    "label": 0
                },
                {
                    "sent": "I only know one instance of a widely used loss function that's very widely used in practice that does not minimize her, so I kept making generalizations with the only constraint being that they still contained one problem, so it sounded it was kind of contrived, so that's why they call it a template theorem.",
                    "label": 0
                },
                {
                    "sent": "And then I'll talk about some of these special case.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "OK, so actually this talk should seem quite simple because there's a very simple solution to all of our problems.",
                    "label": 0
                },
                {
                    "sent": "If we look at the dual and notice I've rewritten the primal to make this duality kind of more obviously in the primal as the constraint optimization over this subspace, you take the dual when I write stars, I mean Fenchel conjugates.",
                    "label": 0
                },
                {
                    "sent": "Now this is the fundamental duality of the Spanish.",
                    "label": 1
                },
                {
                    "sent": "I am as always how I write span of this matrix spaniel left nullspace.",
                    "label": 0
                },
                {
                    "sent": "So here's this duality.",
                    "label": 0
                },
                {
                    "sent": "So let's take a look at this.",
                    "label": 0
                },
                {
                    "sent": "Because I assume differentiability, my fundamental conjugates always strictly convex, so I have strict convexity because I was bounded below.",
                    "label": 0
                },
                {
                    "sent": "The dual problem has a maximizer, so I have a unique maximizer by strict convexity.",
                    "label": 1
                },
                {
                    "sent": "And Furthermore, this tricky matrix A has been moved into the constraints set, so actually this is a fairly accurate representation of one of the problems I'll talk about today.",
                    "label": 0
                },
                {
                    "sent": "This black line represents the actual constraint problem.",
                    "label": 0
                },
                {
                    "sent": "And so so you know the idea is look if the dual looks simple, let's do the analysis in the dual.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what we do I make.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Potential function, which is the distance the dual feasible set.",
                    "label": 1
                },
                {
                    "sent": "So by optimality conditions as you know, as you reach optimal in the primal, you're reaching feasibility in the tool, so that's what's going on here.",
                    "label": 0
                },
                {
                    "sent": "When I fight either just my gradients and notice I leave the out so the gradient using matrix, the gradient of F composed of A is a transpose gradient FA, but I'm leaving out the A. I'll get to that there's this tricky set S that floats around for technical reasons.",
                    "label": 0
                },
                {
                    "sent": "That's all I can really say that right now just to make this more parameterized bowl and easy to use.",
                    "label": 0
                },
                {
                    "sent": "I have a triple norm is going just another norm, one of them still talk about tables held well, two for the two norms.",
                    "label": 0
                },
                {
                    "sent": "One will have a 1L in Fig.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We OK, so this looks a little bit hairy, but this is the fundamental quantity that will let us parse this object.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to fast.",
                    "label": 0
                },
                {
                    "sent": "Let me actually do this a little bit more slowly so this quantity looks a little scary.",
                    "label": 0
                },
                {
                    "sent": "What's really going on here is so this is this potential function.",
                    "label": 1
                },
                {
                    "sent": "We had this the distance the dual feasible set the numerator, which just looks like a transpose FI.",
                    "label": 0
                },
                {
                    "sent": "I can slip in there anybody in that left nullspace?",
                    "label": 0
                },
                {
                    "sent": "So another way to write this subject?",
                    "label": 0
                },
                {
                    "sent": "Another way to write this object is I can put if you consider this to be a projection element, it's non unique in the case of norms like L1, Infinity.",
                    "label": 0
                },
                {
                    "sent": "But we can take this be a projection.",
                    "label": 0
                },
                {
                    "sent": "I can plug it in there.",
                    "label": 0
                },
                {
                    "sent": "So what this guy looks like is basically a transpose.",
                    "label": 0
                },
                {
                    "sent": "This projection direction divided by projection direction.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Since I'm saying that Phi cannot be in this left null space, this in FEMA is always positive over its domain.",
                    "label": 0
                },
                {
                    "sent": "The trickiness, of course, is showing that the infimum is zero, and this is.",
                    "label": 0
                },
                {
                    "sent": "So if you want to see where things get hard, this is where it happens, but as long as S is polyhedral, this ends up working out.",
                    "label": 0
                },
                {
                    "sent": "So I actually have a counterexample, RSS curvature and these vectors kind of these projection vectors kind of slowly get more and more close to the kernel, and you actually get a zero in here.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The reason why this does is good is because we have this potential function where we're going to handle the analysis.",
                    "label": 0
                },
                {
                    "sent": "We're just going to upper lower bound it with useful quantities, and then we'll get a convergence rate.",
                    "label": 0
                },
                {
                    "sent": "So this is fairly standard.",
                    "label": 0
                },
                {
                    "sent": "One reason I liked writing it this way is because the mirror descent analysis.",
                    "label": 0
                },
                {
                    "sent": "One way to write Meredith sent analysis, you have a potential function which is just the ultimate awaits you upper bound it and you lower bound.",
                    "label": 0
                },
                {
                    "sent": "Interesting there you lower bound it with duality arguments.",
                    "label": 0
                },
                {
                    "sent": "You upper bound it with divergences.",
                    "label": 1
                },
                {
                    "sent": "That is a primal argument.",
                    "label": 0
                },
                {
                    "sent": "I'm doing my nails in the dual I lower bound with dual Bregman divergences and upper bound.",
                    "label": 0
                },
                {
                    "sent": "With this line search guarantee.",
                    "label": 1
                },
                {
                    "sent": "So let me see what's going on here.",
                    "label": 0
                },
                {
                    "sent": "This first step here.",
                    "label": 0
                },
                {
                    "sent": "So this once again is just the denominator here.",
                    "label": 0
                },
                {
                    "sent": "So I can instantiate this infima with one of my gradient elements.",
                    "label": 0
                },
                {
                    "sent": "I can just instantiate the element I can instantiate with the current gradient element.",
                    "label": 0
                },
                {
                    "sent": "And So what happens is this basically tells me to scaling if I go from this to that.",
                    "label": 0
                },
                {
                    "sent": "So I just have to divide by that squared squared it.",
                    "label": 0
                },
                {
                    "sent": "So this is basically just a death.",
                    "label": 0
                },
                {
                    "sent": "This definition instantiated for that.",
                    "label": 0
                },
                {
                    "sent": "And so this is kind of the magic step that lets us get around these duplicated columns.",
                    "label": 0
                },
                {
                    "sent": "However, I'm going too fast so it's fine.",
                    "label": 0
                },
                {
                    "sent": "Would it?",
                    "label": 0
                },
                {
                    "sent": "Would it be just as doable to say there exist some pie in the kernel?",
                    "label": 0
                },
                {
                    "sent": "That will make make the analysis work like 'cause S just be a Singleton no.",
                    "label": 0
                },
                {
                    "sent": "OK, so first of all, sometimes when S is a sink, OK so.",
                    "label": 0
                },
                {
                    "sent": "If S is a Singleton, then you can still have vectors that are inside the kernel, so this can.",
                    "label": 0
                },
                {
                    "sent": "This can be set.",
                    "label": 0
                },
                {
                    "sent": "This can become zero then so.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "So you have to be.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you have to be pretty careful about that.",
                    "label": 0
                },
                {
                    "sent": "The other thing that might be a little bit strange, so that the choice of S will be depending on how I do the Bregman step and so.",
                    "label": 0
                },
                {
                    "sent": "But it's completely up to you to choose us.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so for instance, one place, so I'm not going to talk about the construction of the S here, but.",
                    "label": 0
                },
                {
                    "sent": "I had an analysis of boosting and I had to carefully choose these asses and actually I'm going too fast so I can tell you how I construct the S and in a proof that I missed that I kind of sketched out here.",
                    "label": 0
                },
                {
                    "sent": "But basically it's not an algorithm components anality component, just need to control this set S. Yeah.",
                    "label": 0
                },
                {
                    "sent": "And it actually has been fairly obvious all the times I've needed to do it.",
                    "label": 0
                },
                {
                    "sent": "I just took things like cubes and stuff like that, 'cause it probably was never really difficult.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just from some rearrangement here.",
                    "label": 0
                },
                {
                    "sent": "The second part is a standard guarantee you get out of a line search update.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is just if you.",
                    "label": 0
                },
                {
                    "sent": "If you look at up like a standard textbook about how it does the gradient descent analysis, you can see the second inequality.",
                    "label": 1
                },
                {
                    "sent": "Oh, I should say one thing, Lt is the Lipschitz coefficient for the current sublevel set.",
                    "label": 0
                },
                {
                    "sent": "So rather than having a Lipschitz coefficient for the entire domain, I keep refining the Lipschitz coefficient.",
                    "label": 0
                },
                {
                    "sent": "This is kind of this might sound like a hack, but what's interesting is I have an example where I get a one over epsilon rate.",
                    "label": 0
                },
                {
                    "sent": "I don't do this tightening and I get the log one of epsilon.",
                    "label": 0
                },
                {
                    "sent": "If I do the careful analysis.",
                    "label": 0
                },
                {
                    "sent": "So it's I'll try to demystify that.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now that was the upper bound potential.",
                    "label": 0
                },
                {
                    "sent": "This is why I call it a template theorem and I'm a little embarrassed about it is because the lower bound I just say if you can prove this lower bound in this form, then you have these rates.",
                    "label": 1
                },
                {
                    "sent": "Now let me tell you what this lower bound is saying, so ignore these guys here.",
                    "label": 1
                },
                {
                    "sent": "This is the this is the Bregman divergences, the Bregman distance.",
                    "label": 0
                },
                {
                    "sent": "Don't worry bout the F star that just defensive conjugate.",
                    "label": 0
                },
                {
                    "sent": "That's like our natural notion of distance point objective in the tool.",
                    "label": 0
                },
                {
                    "sent": "So I've got this dual distance distance to dual feasible set refined by S, so I want that to be lower bounded by this norms distance.",
                    "label": 0
                },
                {
                    "sent": "So one of the intuitions behind Mr. Kind of like norms and usually you can.",
                    "label": 0
                },
                {
                    "sent": "If you've got like a strongly convex function you plug into your Bregman divergences, then you can get it lower bounded by normal.",
                    "label": 0
                },
                {
                    "sent": "We need to be upper bounded by Norm, one case where you can prove something like this without any math or so, without any without getting too hairy and worrying about S, is if the primal is strongly convex.",
                    "label": 0
                },
                {
                    "sent": "You get this in the dual.",
                    "label": 0
                },
                {
                    "sent": "Use this a little bit later.",
                    "label": 0
                },
                {
                    "sent": "That's actually a nice proof by Sheila Shorts.",
                    "label": 0
                },
                {
                    "sent": "So and you are missing are so I just wanted to do this, but we're basically comparing these Bregman divergences to the distances that we're trying to approximate.",
                    "label": 0
                },
                {
                    "sent": "OK, so and in particular we can prove this inequality if we can prove this inequality with K equal to 1, we get logarithm.",
                    "label": 0
                },
                {
                    "sent": "We get these linear rates and then if we can prove with equals two we get the.",
                    "label": 0
                },
                {
                    "sent": "Any arbitrary divergent you can upper bounded using.",
                    "label": 0
                },
                {
                    "sent": "So you have to you have to be fair.",
                    "label": 0
                },
                {
                    "sent": "This is where you have to design S very carefully.",
                    "label": 0
                },
                {
                    "sent": "In fact.",
                    "label": 0
                },
                {
                    "sent": "In fact, I made a mistake with this once.",
                    "label": 0
                },
                {
                    "sent": "Squares of North look like they're more like squares of norms, yeah.",
                    "label": 0
                },
                {
                    "sent": "In fact, Bregman divergences have a Pythagorean theorem, which means they can't be norms.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to leave about 3 minutes for questions, so I realize that I'm kind of papering over.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Less so terric, let me give some give 2 examples that I think.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit interesting, let me just say what happens when.",
                    "label": 0
                },
                {
                    "sent": "This has minimizers, and we have strict convexity, and I'm defining in terms of a positive definite Hessian.",
                    "label": 1
                },
                {
                    "sent": "Notice I haven't written.",
                    "label": 0
                },
                {
                    "sent": "I haven't written something something positive times the identity matrix.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying is strongly convex, I'm saying so in particularly FEMA over the entire domain might have this to be just 00.",
                    "label": 0
                },
                {
                    "sent": "Modulus of strong convexity.",
                    "label": 0
                },
                {
                    "sent": "So now here's another trick.",
                    "label": 0
                },
                {
                    "sent": "I'm going to use to rewrite the primal.",
                    "label": 0
                },
                {
                    "sent": "I'm going to once again write it, as this is my indicator.",
                    "label": 0
                },
                {
                    "sent": "No one uses notation.",
                    "label": 0
                },
                {
                    "sent": "I should stop.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "This is the indicator of the of that subspace.",
                    "label": 0
                },
                {
                    "sent": "So now I've kind of thrown out this problem of duplicated columns.",
                    "label": 0
                },
                {
                    "sent": "This is just strict strictly convex function, but it has a constraint as a constraint set.",
                    "label": 0
                },
                {
                    "sent": "So that means is strongly convex, can just take the infimum of this because I said twice continuously differentiable earlier.",
                    "label": 0
                },
                {
                    "sent": "That's why I use it.",
                    "label": 0
                },
                {
                    "sent": "I use it to get this.",
                    "label": 1
                },
                {
                    "sent": "I use this trick from Schwartz to get that, I plug that in, I get the K = 1.",
                    "label": 0
                },
                {
                    "sent": "And I've left out what the S is.",
                    "label": 0
                },
                {
                    "sent": "You could just eigenvalue of this.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, that's actually very interesting, so you're running with the C is here.",
                    "label": 0
                },
                {
                    "sent": "OK, so the problem is that this has to be over there for the specter.",
                    "label": 0
                },
                {
                    "sent": "That set S let me tell you, construct the set S. In this case, it's kind of a disaster.",
                    "label": 0
                },
                {
                    "sent": "I take the sublevel set in the primal I project into the tool.",
                    "label": 1
                },
                {
                    "sent": "I still have a compact set because I have continuous different derivatives compact set.",
                    "label": 0
                },
                {
                    "sent": "Now I take a polyhedral approximation of it so I know for any epsilon there's like a Hausdorff close.",
                    "label": 0
                },
                {
                    "sent": "Polyhedron and I have to be careful because I can't hit my constraint 'cause the dual, even though the Primals unconcerned though, might be constrained.",
                    "label": 0
                },
                {
                    "sent": "I'd be careful about how we construct that, but you can do it just might have really I don't have it on the number of faces, so you get this polyhedron.",
                    "label": 0
                },
                {
                    "sent": "Then you have to map that polyhedron back.",
                    "label": 0
                },
                {
                    "sent": "You have to put it back into the primal and I have some weird set and you compute strong convexity computer for that.",
                    "label": 0
                },
                {
                    "sent": "So it will be something like the inverse.",
                    "label": 0
                },
                {
                    "sent": "The eigenvalue in the primal but with respect to that set.",
                    "label": 0
                },
                {
                    "sent": "So based on what this mapping does, it's not really clear.",
                    "label": 0
                },
                {
                    "sent": "But let me come back to that question in just a minute.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "So once again, this is unregularized, so these, I admit are quite contrived, so I'm sorry we can ask.",
                    "label": 0
                },
                {
                    "sent": "You can ask about how I change the objective function regular regularization later, so least squares strongly convex.",
                    "label": 0
                },
                {
                    "sent": "That's kind of easy.",
                    "label": 0
                },
                {
                    "sent": "So I get login website for both of these without needing to worry about.",
                    "label": 0
                },
                {
                    "sent": "That A and then that one log cosh.",
                    "label": 0
                },
                {
                    "sent": "That's a very nice.",
                    "label": 0
                },
                {
                    "sent": "It's like a Huber's approximation Huber loss that strictly convex.",
                    "label": 0
                },
                {
                    "sent": "Super losses, not really convex.",
                    "label": 1
                },
                {
                    "sent": "So that's not strongly convex and we still get the login upsilon boosting.",
                    "label": 0
                },
                {
                    "sent": "If boosting has a minimizer.",
                    "label": 0
                },
                {
                    "sent": "Then it also gets that and this is a funny one, so quadratics with positive semidefinite hessian's I get log one over epsilon I get.",
                    "label": 1
                },
                {
                    "sent": "So if you look into standard textbook you need you need positive definiteness, not positive semidefinite NIS.",
                    "label": 0
                },
                {
                    "sent": "And actually for this case I worked out all the constants in the proof.",
                    "label": 0
                },
                {
                    "sent": "It's easy for this one 'cause all my norms are two norms.",
                    "label": 0
                },
                {
                    "sent": "The constant, so if you look in sorry I don't remember if it's in your book, but I know it's Stephen Boyd's book.",
                    "label": 0
                },
                {
                    "sent": "Sorry, but you can get a bound that looks like the ratio of the min and Max eigen values.",
                    "label": 0
                },
                {
                    "sent": "For this one you get a ratio of the min and Max positive singular values, so it's about as nice as you could expect.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Minimum maximum yeah non negative right?",
                    "label": 0
                },
                {
                    "sent": "So it's basically exactly what you could hope for basically.",
                    "label": 0
                },
                {
                    "sent": "Optimizing knowing where the current.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean so when I obviously when I first proved this and I saw that it had been proved, I got very scared that I had an error.",
                    "label": 0
                },
                {
                    "sent": "So let me repeat once again that pulsing has this Culin here convergence where you delete the finite prefix for all of these.",
                    "label": 0
                },
                {
                    "sent": "Actually his analysis much more powerful than mine can handle much more powerful objectives.",
                    "label": 0
                },
                {
                    "sent": "Another so one intuition is like the thing I said about duplicating columns, and if you add columns in that are linearly dependent, you kind of give the algorithm or choice.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of my late my lazy intuition about what.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going on here.",
                    "label": 0
                },
                {
                    "sent": "OK, so for the last let me just maybe I went a little slow.",
                    "label": 0
                },
                {
                    "sent": "So here's why.",
                    "label": 0
                },
                {
                    "sent": "So let me just say one really key thing.",
                    "label": 0
                },
                {
                    "sent": "So boosting is an example where you do not have a minimizer 'cause things go off to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Now let me tell you, I'll skip most of this stuff.",
                    "label": 0
                },
                {
                    "sent": "Let me just tell you the interesting thing about the analysis.",
                    "label": 0
                },
                {
                    "sent": "When I had minimizers, I use strong convexity, strong convexity's, like for what I know from my grad school experiences doing optimization.",
                    "label": 0
                },
                {
                    "sent": "It's like our workforce, so I needed a workhorse that worked in these situations without strong convexity when the when the minimizer goes out to Infinity.",
                    "label": 0
                },
                {
                    "sent": "I needed something, and I reverse engineered the property that made the proof work, which is kind of embarrassing again, but I call it a flattening condition.",
                    "label": 1
                },
                {
                    "sent": "Let me just explain what this means, because it's actually very.",
                    "label": 1
                },
                {
                    "sent": "Simple and has a good intuition.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 1
                },
                {
                    "sent": "So the upper bound says their distance to the optimum is less single to your current gradient.",
                    "label": 0
                },
                {
                    "sent": "What that means is if gradients are really so, that means the gradient can't become flat.",
                    "label": 0
                },
                {
                    "sent": "IE you can't do very much with the great dissent method without being really close to the optimum.",
                    "label": 0
                },
                {
                    "sent": "That's the upper bound means.",
                    "label": 0
                },
                {
                    "sent": "If I only have the upper bound to get one over epsilon, the lower bound says near the optimum guy is super flat white.",
                    "label": 0
                },
                {
                    "sent": "Does that sound like it helps?",
                    "label": 0
                },
                {
                    "sent": "It's because I'm using line searches.",
                    "label": 0
                },
                {
                    "sent": "That means if it's super flat, the line search basically just shoots at the optimum.",
                    "label": 0
                },
                {
                    "sent": "So this is what I used to get the login or epsilon.",
                    "label": 0
                },
                {
                    "sent": "So this is actually why boosting convergence rates was such a difficult orchestration say that that's why it was unresolved for awhile is because you needed something else.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To analyze what happened, I feel like I. Bing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I do.",
                    "label": 0
                },
                {
                    "sent": "I did analyze the closed form, kind of one over Lipschitz.",
                    "label": 0
                },
                {
                    "sent": "It doesn't work as well in practice, it does get the same rate, but just like minimizing and upgrading quadratic.",
                    "label": 0
                },
                {
                    "sent": "So the details of that are very interesting.",
                    "label": 0
                },
                {
                    "sent": "Let me just.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We just closed with just a summary, so this case with the linear prints for the minimizers.",
                    "label": 0
                },
                {
                    "sent": "Then I have a very kind of loose strategy for some things, not minimizers.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And was curious to me is I don't believe in this flattening condition I used actually Kartik.",
                    "label": 0
                },
                {
                    "sent": "Should RN came by to my poster and had some very insightful in comments on what it actually means.",
                    "label": 0
                },
                {
                    "sent": "So someone must figure out a better one.",
                    "label": 0
                },
                {
                    "sent": "I'd love to hear about it, so thanks and that's the end of the talk.",
                    "label": 0
                }
            ]
        }
    }
}