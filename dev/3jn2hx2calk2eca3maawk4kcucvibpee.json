{
    "id": "3jn2hx2calk2eca3maawk4kcucvibpee",
    "title": "Adaptive recovery of signals by convex optimization",
    "info": {
        "author": [
            "Dmitry Ostrovsky, Grenoble University"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_ostrovsky_convex_optimization/",
    "segmentation": [
        [
            "So this is a joint work with Natalie this key or cause neural scans later showing thank you."
        ],
        [
            "It works.",
            "So suppose that N samples of a signal X observed in the Goshen noise in the Gaussian noise.",
            "And the objective is to estimate the signal value.",
            "Yes, the objective is to estimate extent.",
            "The signal value in the last point.",
            "So start with the simplest one, with the simplest estimates, linear estimates and.",
            "No, that actually is linear.",
            "Estimator function is given as the convolution with some vector Phi which we call a filter related in some in appointment so.",
            "It's a classical result from the 80s and parametric statistics that if only the set of signals Capital X, which constitutes all the prior information about the problem for us, is convex and closed, the linear estimates I actually minimax for this problem.",
            "So if you want if suppose that we want to adapt to the best unknown linear estimate, minimax linear estimate actually, in the best estimated talk.",
            "It's it's services to adapt to.",
            "In short, to adapt to linear estimates.",
            "OK, so."
        ],
        [
            "Our main assumption is that there exists.",
            "Linear time invariant filtering which recovers.",
            "Let's say the last half of samples with the error bounded by 1 / sqrt N with high probability.",
            "It turns out that this assumption, stated informally, is fulfilled in.",
            "Several important problems, so to state more formally, we say that there is a bond.",
            "There is a constant row which bounds the.",
            "Yeah, there is a constant flow which bounds the equation norm of Oracle filter fi and this filter provides the recovery of the signal and the last let's say three M / 4 points with the error which is with high probability bounded by something proportional to again to roll over square root of N. And what's the the limit?",
            "Which we can achieve?",
            "What's the lower bound?",
            "It occurs that the lower bound stated in terms of this rule and N. Is that the price of adaptation?",
            "The best possible price of adaptation is raw Square root is proportional to rose Square root of log N, and our second rib."
        ],
        [
            "Vision is actually an estimator which.",
            "Knew late shifts.",
            "This lower bound if the chips, the abundant N but it fails to achieve it in in row.",
            "So the idea of the of estimation procedure, the recovery procedure.",
            "The court step in this procedure is this filter fitting problem basically to which fits a filter with a small L1 norm.",
            "But in the spectral domain using some kind of cross validation too.",
            "To reproduce the observations, so to reproduce observations with the error.",
            "Limited in terms of this?",
            "Term here.",
            "Then so after fixing the filter, we.",
            "Is this to meet with?",
            "Take the convolution of the signal of this filter.",
            "So what can we say about this estimators that first?",
            "It's a well structured problem to find it.",
            "To find this filter filtering problem.",
            "Basically it's a secondary control program.",
            "Second, with a with a nice structure, by the way, because of the free transforms involved inside.",
            "Second, this bond as I said, is nearly minimax and also the nice feature of this framework, that is, that is, it is generalized quite straightforwardly to the prediction case when the point estimate the signal is the point to estimate the signal is separated from the points in which the observation said given."
        ],
        [
            "So finally let me give some.",
            "Toy numerical example.",
            "So here are the noisy observations of basically signal composed of two just two sine waves.",
            "OK, so.",
            "In the right upper corner, is that true signal without noise?",
            "G is the signal in the target zone in which we we employed our pointwise recovery and sees the result of the recovery."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a joint work with Natalie this key or cause neural scans later showing thank you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It works.",
                    "label": 0
                },
                {
                    "sent": "So suppose that N samples of a signal X observed in the Goshen noise in the Gaussian noise.",
                    "label": 1
                },
                {
                    "sent": "And the objective is to estimate the signal value.",
                    "label": 0
                },
                {
                    "sent": "Yes, the objective is to estimate extent.",
                    "label": 0
                },
                {
                    "sent": "The signal value in the last point.",
                    "label": 0
                },
                {
                    "sent": "So start with the simplest one, with the simplest estimates, linear estimates and.",
                    "label": 0
                },
                {
                    "sent": "No, that actually is linear.",
                    "label": 0
                },
                {
                    "sent": "Estimator function is given as the convolution with some vector Phi which we call a filter related in some in appointment so.",
                    "label": 0
                },
                {
                    "sent": "It's a classical result from the 80s and parametric statistics that if only the set of signals Capital X, which constitutes all the prior information about the problem for us, is convex and closed, the linear estimates I actually minimax for this problem.",
                    "label": 1
                },
                {
                    "sent": "So if you want if suppose that we want to adapt to the best unknown linear estimate, minimax linear estimate actually, in the best estimated talk.",
                    "label": 1
                },
                {
                    "sent": "It's it's services to adapt to.",
                    "label": 0
                },
                {
                    "sent": "In short, to adapt to linear estimates.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our main assumption is that there exists.",
                    "label": 1
                },
                {
                    "sent": "Linear time invariant filtering which recovers.",
                    "label": 1
                },
                {
                    "sent": "Let's say the last half of samples with the error bounded by 1 / sqrt N with high probability.",
                    "label": 0
                },
                {
                    "sent": "It turns out that this assumption, stated informally, is fulfilled in.",
                    "label": 0
                },
                {
                    "sent": "Several important problems, so to state more formally, we say that there is a bond.",
                    "label": 0
                },
                {
                    "sent": "There is a constant row which bounds the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there is a constant flow which bounds the equation norm of Oracle filter fi and this filter provides the recovery of the signal and the last let's say three M / 4 points with the error which is with high probability bounded by something proportional to again to roll over square root of N. And what's the the limit?",
                    "label": 0
                },
                {
                    "sent": "Which we can achieve?",
                    "label": 0
                },
                {
                    "sent": "What's the lower bound?",
                    "label": 0
                },
                {
                    "sent": "It occurs that the lower bound stated in terms of this rule and N. Is that the price of adaptation?",
                    "label": 0
                },
                {
                    "sent": "The best possible price of adaptation is raw Square root is proportional to rose Square root of log N, and our second rib.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vision is actually an estimator which.",
                    "label": 0
                },
                {
                    "sent": "Knew late shifts.",
                    "label": 0
                },
                {
                    "sent": "This lower bound if the chips, the abundant N but it fails to achieve it in in row.",
                    "label": 1
                },
                {
                    "sent": "So the idea of the of estimation procedure, the recovery procedure.",
                    "label": 0
                },
                {
                    "sent": "The court step in this procedure is this filter fitting problem basically to which fits a filter with a small L1 norm.",
                    "label": 0
                },
                {
                    "sent": "But in the spectral domain using some kind of cross validation too.",
                    "label": 0
                },
                {
                    "sent": "To reproduce the observations, so to reproduce observations with the error.",
                    "label": 0
                },
                {
                    "sent": "Limited in terms of this?",
                    "label": 1
                },
                {
                    "sent": "Term here.",
                    "label": 0
                },
                {
                    "sent": "Then so after fixing the filter, we.",
                    "label": 0
                },
                {
                    "sent": "Is this to meet with?",
                    "label": 0
                },
                {
                    "sent": "Take the convolution of the signal of this filter.",
                    "label": 0
                },
                {
                    "sent": "So what can we say about this estimators that first?",
                    "label": 0
                },
                {
                    "sent": "It's a well structured problem to find it.",
                    "label": 0
                },
                {
                    "sent": "To find this filter filtering problem.",
                    "label": 0
                },
                {
                    "sent": "Basically it's a secondary control program.",
                    "label": 0
                },
                {
                    "sent": "Second, with a with a nice structure, by the way, because of the free transforms involved inside.",
                    "label": 0
                },
                {
                    "sent": "Second, this bond as I said, is nearly minimax and also the nice feature of this framework, that is, that is, it is generalized quite straightforwardly to the prediction case when the point estimate the signal is the point to estimate the signal is separated from the points in which the observation said given.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally let me give some.",
                    "label": 0
                },
                {
                    "sent": "Toy numerical example.",
                    "label": 0
                },
                {
                    "sent": "So here are the noisy observations of basically signal composed of two just two sine waves.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "In the right upper corner, is that true signal without noise?",
                    "label": 1
                },
                {
                    "sent": "G is the signal in the target zone in which we we employed our pointwise recovery and sees the result of the recovery.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}