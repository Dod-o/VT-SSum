{
    "id": "esv25z443sdlew3tvlyxubgnzwnva2y3",
    "title": "Using @Twitter Conventions to Improve #LOD-Based Named Entity Disambiguation",
    "info": {
        "author": [
            "Genevieve Gorrell, Department of Computer Science, University of Sheffield"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_gorrell_named_entities/",
    "segmentation": [
        [
            "So this is a work I'm presenting on behalf of myself and my Co author Johann Patrick and Clean a bunch ever."
        ],
        [
            "And the work takes place in the context of named entity recognition and disambiguation, which I think most people are familiar with here.",
            "But to quickly summarize in this example I've got here, I've found four named entities in this tweet, and I've disambiguated them against Wikipedia to their unique reference.",
            "To illustrate the concept.",
            "Ann, this is a popular task and enabler for other work.",
            "As we saw in two papers in the NLP session this morning, this often forms a component of more complex systems."
        ],
        [
            "When we apply this technology to tweets, we find we have a slightly harder problem.",
            "And performance is tended to lag behind more well formed text, such as newswire text, when the same technologies replied to tweets, and there's been quite a lot of effort recently in knowing that performance gap that this work forms part of.",
            "And the way we propose.",
            "Hoping to know that performance gap here is to make use of Twitter conventions that allow us to access additional content in order to enrich the context and compensate somewhat for the problem we have into each, which is that they are so short they don't provide very much information to help us decide which of possible multiple interpretations is the most appropriate.",
            "So in this example here you can see we've got #mufc.",
            "Hashtags are user generated semantic tags, which potentially allow us to access useful information about that, but that might be referring to we have a URL which obviously indicates a web page containing more content and then we have an @ which refers to another Twitter user and again provides a way for us to get information about who that's referring to.",
            "That would help us to disambiguate that mention."
        ],
        [
            "So in order to evaluate the possible contribution of these kinds of information, we need a named entity recognition and disintegration system.",
            "So I'm going to introduce our system yodi that we used to do this work.",
            "And we also need a corpus to evaluate the work on.",
            "When we did the work last year, the MSM corpus wasn't available, so we made our own and that corpus is now available and anyone who wants to welcome to use it available at this website indicated here.",
            "And those are tweets selected from news, financial and climate change domains.",
            "Have annotated for named entities unlinked against DPD."
        ],
        [
            "Few facts about corpus.",
            "There's some statistics here about the corpus, but most relevant to the work I'm presenting here is the number of URLs hashtags, and at mentions in the corpus.",
            "We've got 800 tweets.",
            "Containing 500 for URLs, of which 236 led to a successful web page retrieval URL's often go out of date quite quickly.",
            "359 hashtags that we were able to retrieve hashtag definitions for for a user populated site.",
            "I'll say more about that later.",
            "About mentions we have 334.",
            "Of which we were able to retrieve almost all biographies from Twitter.",
            "That query almost always succeeds unless someone changed their username.",
            "But the quality of those biographies is quite variable."
        ],
        [
            "The only system that we evaluated this working it's at any ID system developed over several EU projects in which we try to integrate current technologies and for achieving this task integrate with the long term plan of sharing those components.",
            "We aim to make it robust to different input types, hence our work on Twitter and we're currently working on making it portable to new domains.",
            "And it's suitable for this works.",
            "It's a typical approach comprising well researched and published techniques.",
            "And the performance that we achieve with this is compatible to state of the art systems."
        ],
        [
            "I'm so very quick overview so that you can understand.",
            "The way in which additional Twitter content helps, and also how likely this result is to transfer to other systems that may be slightly different from this one.",
            "And the approach we used to finding a named entities and putting candidate interpretations onto them is to construct a large gazetteer from.",
            "A list of labels, ways in which all DB pedia and entities can be referred to.",
            "Different aliases link text from Wikipedia.",
            "To compose a long list of ways in which these entities referred to we pruned that with a few heuristics, but essentially then look for mentions of that in the text to give us quite a high recall.",
            "First cut at finding candidates for the entities in the text.",
            "And this is relevant to to what comes next in terms of disambiguation, and that since it's high recall, we then relying on the disambiguation step to eliminate some of the spurious candidates likely to be generated at that stage.",
            "So having found these candidates, we then which themselves come with information such as Piper ability and so forth.",
            "We then score them for their success and fitting with the context.",
            "And this is the first place in which Twitter expansion makes a difference, in that it provides more context and hopefully allowing that to be done more successfully.",
            "We then choose the final choice of candidate using support vector machine disambiguation step.",
            "Based on the scores.",
            "So obviously if the scores are different then that has the potential to influence how well that final steps able to work."
        ],
        [
            "So quick overview of the scores that we've essentially I'm going to show you how Twitter expansion affect some scores.",
            "Then I'm going to show you how it affects the final result.",
            "Post disambiguation.",
            "So quick run through the scores.",
            "Firstly, we've got some structural scores.",
            "Basic idea with structural scores is to see how well candidates relate to other potential candidates on their by entities, so that you can try to pick candidates for different entities that are congruent with each other.",
            "So in the example I've got here, I've got three candidates for Kagawa and two Fer and Subotic.",
            "Three Kagawa candidates, once a footballer and of the two sebatik candidates.",
            "We also have a footballer so we should prefer the two candidates in the footballers because they've got a congruence between them in terms of domain.",
            "So that's the basic idea, but including this kind of information in the system can be achieved in different ways."
        ],
        [
            "A common way to do this is the pairwise approach of relatedness for million written.",
            "Which looks at Wikipedia pages linked to each of these candidates and how much overlap is there between those two that gives an indicator of how related they are.",
            "So we've included that one."
        ],
        [
            "And also in order to include a similar type of information but from the DB pedia graph.",
            "We've also counting relationships that appear in the DB pedia graph, connecting entities to each other.",
            "This tends to be a sparse symmetric, but a very high quality one."
        ],
        [
            "We also have some text based scores evaluating the success of a particular candidate in fitting with the textual content context.",
            "That it arises in.",
            "So we're comparing the entire text of the tweet.",
            "It's short enough already.",
            "Then we compare that with the abstract for the candidate DB pedia entry to see if we can find a congruence between them.",
            "And in order to improve that a little bit, we also map them through a semantic space that's being constructed over half a million DB pedia abstracts and then TF IDF transformed in order to expand those vectors a little bit with related terms and make that comparison more successful.",
            "We then cosine those vectors to obtain a score.",
            "Of how well that candidate seems to fit with the textual content context in which we found it."
        ],
        [
            "And finally, as I say, we use an SVM to rate each candidate.",
            "I'm having put these scores onto it for how likely that candidate is to be the right answer.",
            "And as I said earlier, we also rely on this stage to eliminate some spurious candidates.",
            "So if they're all considered unlikely, we drop the whole mention.",
            "When multiple candidates seem promising, we use probability allocated by the SVM to pick one."
        ],
        [
            "The expansions we studied it as I mentioned earlier, we use hashtag expansions from the website tagdef.com to get some user generated.",
            "Definitions of what hashtag refers to.",
            "We also use URLs to get the entire web page content, and we use that mentions to get the Twitter user via."
        ],
        [
            "And here's the example of familiar in the gate GUI.",
            "It's probably quite hard to read, but I don't think you need to to read it in great detail in yellow.",
            "At the top we've got the original tweet."
        ],
        [
            "And then underneath we've got the expansions.",
            "So friend Subotic, we've got the user bio.",
            "Importantly, in the user buyer we now have antibiotics full name written out in a way that very likely to be very informative.",
            "We then expanded on the mufc hashtag with these 5 user contributed definitions for what that refers to.",
            "These can be a variable quality, and this one in particular can see that all five are attempts at humor.",
            "But that said, it still contains some really useful information.",
            "We've got another footballer, the darker areas, by the way, are named entities that relocated using the same technology in the expansion.",
            "So we've got a further footballer found, which could possibly help us to disambiguate the domain, but also we've got the word soccer, and we've got the word football, so these are really likely to be helpful.",
            "And we've also expanded the URL.",
            "There's a lot more text scrolled off the bottom from that web page, but again, this contains a lot of useful information.",
            "We've got the full name of the football team from football team from the hashtag.",
            "Again, we've got the word football, so all this looks likely to be really helpful."
        ],
        [
            "So as I say for the.",
            "The two types of scores are adding more context essentially gives these scores more information to operate across.",
            "The structural scores have now got more entities to relate entities too, and the textual scores will get a lot more text.",
            "We also did another trick here, which I'll explain with reference to the previous slide."
        ],
        [
            "In the @ and Subotic that strings unlikely to retrieve very good quality candidate list because it's not a well formed representation of that person's name.",
            "Having expend expanded it to the biography.",
            "We have more chance of identifying that individual because his name is written out in full, but if we never had the right candidate on the @ then we can't select it.",
            "So the final trick we applied here is to find any candidate on any mention in the biography expansion and put them all as candidates on that mention.",
            "And I'm going to refer to that as backprojection from here.",
            "Back projection of candidates from the user bio onto the @"
        ],
        [
            "So the experimental condition is that we've run our first.",
            "We evaluated baseline system with no expansion.",
            "We then tried each of the three expansions separately.",
            "And then mentioned expansion with back projection of candidates from the use fire.",
            "We tried everything all together and we also tried one in which we exclude hashtag expansion since as you'll see on the final results, slide hashtag seemed like they may have limited utility is worth trying to see if they really contribute anything to the final result."
        ],
        [
            "Just a couple of baselines.",
            "I'm going to show you some results from some individual scores, and just to be able to position the results from those scores.",
            "Let's just look at these baselines.",
            "So at this stage in which we found entities and put candidate lists on all of them.",
            "If at that point you just pick one of those at random, you'll get an F1 result for the complete task named entity recognition and disambiguation.",
            "Your overall F1 score will be .229.",
            "If of those candidates you pick the one with the best prior probability, but which we've used in this case, the most you are I mentioned in Wikipedia, so this is the most probable candidate just in terms of background distribution, then that will give you an F1 of .521.",
            "And picking the most common candidate is a hard baseline to beat, and you'll see that the scores that we now look at don't beat that.",
            "What they do is contribute a different kind of information that the final disambiguation step can combine in order to get a result that's better than that overall."
        ],
        [
            "So initially the DB pedia based relatedness score between candidates.",
            "We can see that we've got a baseline F1 of .326 and essentially including Twitter expansion hasn't really succeeded in improving on that.",
            "We've got a very minor improvement for URL, but the deal is actually if anything, it maybe makes it worse.",
            "This is odd, I'm I expected to see a better result for this because the DPD graph is quite sparse.",
            "And doesn't you know, sometimes it doesn't include very sensible relations if there is a relation there.",
            "It's it's useful information, but lots of time relations that you would expect to see on there.",
            "So I thought adding more material might really help with this, but that's not what we've found so far."
        ],
        [
            "The relatedness score does a little bit better in that we do see some improvement.",
            "In particular, if we use user BIOS.",
            "So it's a little bit more of an improvement there."
        ],
        [
            "I'm getting looking at now looking at the text based comparison between the tweet text.",
            "The candidate abstract starting to look a little bit better.",
            "For baseline, we've got .27, and if we include user BIOS with back projection of candidates, we can get an F1 point .295, which is a bit better.",
            "In particular, we see a bit of a jumping recall, which is the kind of thing you'd expect to see because we're actually adding candidates onto that mentions which went there.",
            "So this is the kind of results I expected to see more in some of the other scores, but.",
            "We do start to see that here."
        ],
        [
            "And then finally, in addition to comparing.",
            "For the candidate with the DB Pedia abstract text.",
            "We also include all of the textual fields in DB pedia.",
            "So this is as much textual information so we can get out of DB pedia for that candidate.",
            "And here's where we start to see the most convincing result.",
            "With an F1 jumping from .279 at 2.32 C. Compelling.",
            "So in terms of some explanation for what what might be going on here?",
            "My feeling is if we if we just go back to our example."
        ],
        [
            "With the screenshot here we can see that we've added some knew mentions which are potentially quite useful, but given that some of the related metrics may be quite sparse, we've potentially not actually added any useful information at this stage.",
            "My feeling the contribution to the structural scores would be greater than using a less sparse relatedness metric, so I think that would be a potential to improve there, but essentially finding entities is somewhat.",
            "You know we we see repeated entities here, not necessarily added very great deal of information, but more text is much more.",
            "Deterministically going to improve performance and what we see is that if you have added more text to the context, then we get even more leverage.",
            "In the case where we've got more text for the candidate.",
            "So I think in order to maximize the result we get from from this, this kind of contribution, then what we need to see is as much text as possible for the."
        ],
        [
            "For example, using surrounding context from Wikipedia for the candidate is a way of getting even more."
        ],
        [
            "Information."
        ],
        [
            "So finally we include the disambiguation stage.",
            "The SVM in ranking rate doesn't rank it's cause them separately these candidates for their likelihood of being correct, has the potential to add more intelligence in that it can relate these different scores in different ways to other features that aren't necessarily just as simple as higher score is better.",
            "And so here's where we see greater improvements.",
            "We've got an accuracy jump from .55 up to .62 which is quite compelling.",
            "We've also done Mcnamer sign test to evaluate the significance of these improvements, and you can see that with the exception of user BIOS, all of the expansion types yield a significant improvement.",
            "In particular, back projection of candidates seems to help in that, as you would expect it improves.",
            "Recall a lot.",
            "With regards to the contribution of hashtag expansion, which I experimentally eliminate it because it doesn't seem to make that much difference, but nonetheless it does make a significant.",
            "Difference and the final result with regards to these last two lines where we have different.",
            "Search results in terms of whether accuracy F1 is better.",
            "You know this may just be a precision recall balancing issue, but I think in essence the best system is the one that includes all of the expansions."
        ],
        [
            "Just to contextualize the result, we run a few different systems on that corpus.",
            "And.",
            "You know, by adding that that extra advantage to yodi, we resulted in improvement.",
            "That sort of repositions is on this on this scoreboard here.",
            "Although note that this isn't a competition since those other systems don't use to eat expansion.",
            "But it does give an illustration of how this kind of difference you know is sort of substantial on the scale of the kind of performances that systems are achieving on that type of data."
        ],
        [
            "But in terms of how this is going to?",
            "Carry across to two other tasks and other systems.",
            "Well, I think corpus type is a big factor in how.",
            "How much of a improvement we're going to see in particular if you've got a tweet corpus, that's news focused.",
            "News tweets often consist of a title followed by a URL which you then follow up immediately may mean that you have a successful URL expansion for every tweet, in which case you might expect to see an accuracy gain of .06 in your corpus.",
            "In particular, that mentions if you have a successful @ expansion in every tweet, you can see if a very big accuracy gain due to that recall improvement.",
            "If and this was actually calculated in our corpus with no consideration of whether that mentioned first to someone who has a DB pedia page, so you may expect to see even more than that if your corpus focuses, perhaps some celebrities or politicians.",
            "I'm."
        ],
        [
            "That's all I have to say.",
            "Thank you.",
            "Among you structural features one you say is related to how you candidates are connected via deep area.",
            "Yes, I guess you're considering only path one so directly connected with just one predicate.",
            "Now we did include the direct relations.",
            "We also included indirect relations with one step removal.",
            "OK, but in this doing this you consider that all predicates are equal.",
            "No?",
            "We divided those by the inverse square of the number of steps in the relation.",
            "So we went up to a maximum of two steps, but then waited them by the inverse square of the number of steps.",
            "OK, but so you didn't throw out predicates like weaklings or that have very little semantics in how their connect to entities.",
            "Um, I would have to get back to you on that I.",
            "It's like a list of stopwords, but there will be a list of stuff.",
            "Pretty yes, it seems likely that my coauthor did this, but he just gave me the database.",
            "I'll have to get back to you.",
            "OK, yes, thank you for the talk, and I was wondering if you have been also looking at the bubble net.",
            "Framework I was testing some of the examples were giving and they were not that good as.",
            "As you seem to be but but I think it's interesting to look at this bubble net resource because they integrate all those wiki page at PPG and this kind of things and they also started to have a disambiguation engine running on this.",
            "Right now, I think it would be quite interesting to compare your approach.",
            "Yes, it would definitely definitely interested in comparing to that.",
            "Yeah, and a few other systems.",
            "So I have another questions came to my mind.",
            "When you use different so for the linguistic part.",
            "When you're analyzing tweets.",
            "So when you do posts and things like this, did you specific pose model like adapted for tweets?",
            "Or did you use a general purpose?",
            "Post now we used to tweet adapted one we used them gate to to prepare the tweet and then gate has a Twitter pipeline that does various things such As for example splitting hashtags into component based on casing which often allows us to find find things that we wouldn't.",
            "Those things like that yeah, OK. And the proportion of hashtags that you couldn't really expand using tag DEF.",
            "How is this?",
            "Proportion about half half about half yeah, but there are also possibilities for an for trying different databases of hashtag definitions to see if we can find one that works a bit better.",
            "Typedef tended to be quite jokey.",
            "So we have more questions.",
            "OK, so let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a work I'm presenting on behalf of myself and my Co author Johann Patrick and Clean a bunch ever.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the work takes place in the context of named entity recognition and disambiguation, which I think most people are familiar with here.",
                    "label": 1
                },
                {
                    "sent": "But to quickly summarize in this example I've got here, I've found four named entities in this tweet, and I've disambiguated them against Wikipedia to their unique reference.",
                    "label": 0
                },
                {
                    "sent": "To illustrate the concept.",
                    "label": 1
                },
                {
                    "sent": "Ann, this is a popular task and enabler for other work.",
                    "label": 0
                },
                {
                    "sent": "As we saw in two papers in the NLP session this morning, this often forms a component of more complex systems.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we apply this technology to tweets, we find we have a slightly harder problem.",
                    "label": 0
                },
                {
                    "sent": "And performance is tended to lag behind more well formed text, such as newswire text, when the same technologies replied to tweets, and there's been quite a lot of effort recently in knowing that performance gap that this work forms part of.",
                    "label": 0
                },
                {
                    "sent": "And the way we propose.",
                    "label": 0
                },
                {
                    "sent": "Hoping to know that performance gap here is to make use of Twitter conventions that allow us to access additional content in order to enrich the context and compensate somewhat for the problem we have into each, which is that they are so short they don't provide very much information to help us decide which of possible multiple interpretations is the most appropriate.",
                    "label": 0
                },
                {
                    "sent": "So in this example here you can see we've got #mufc.",
                    "label": 0
                },
                {
                    "sent": "Hashtags are user generated semantic tags, which potentially allow us to access useful information about that, but that might be referring to we have a URL which obviously indicates a web page containing more content and then we have an @ which refers to another Twitter user and again provides a way for us to get information about who that's referring to.",
                    "label": 0
                },
                {
                    "sent": "That would help us to disambiguate that mention.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to evaluate the possible contribution of these kinds of information, we need a named entity recognition and disintegration system.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to introduce our system yodi that we used to do this work.",
                    "label": 0
                },
                {
                    "sent": "And we also need a corpus to evaluate the work on.",
                    "label": 0
                },
                {
                    "sent": "When we did the work last year, the MSM corpus wasn't available, so we made our own and that corpus is now available and anyone who wants to welcome to use it available at this website indicated here.",
                    "label": 1
                },
                {
                    "sent": "And those are tweets selected from news, financial and climate change domains.",
                    "label": 0
                },
                {
                    "sent": "Have annotated for named entities unlinked against DPD.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Few facts about corpus.",
                    "label": 0
                },
                {
                    "sent": "There's some statistics here about the corpus, but most relevant to the work I'm presenting here is the number of URLs hashtags, and at mentions in the corpus.",
                    "label": 1
                },
                {
                    "sent": "We've got 800 tweets.",
                    "label": 0
                },
                {
                    "sent": "Containing 500 for URLs, of which 236 led to a successful web page retrieval URL's often go out of date quite quickly.",
                    "label": 0
                },
                {
                    "sent": "359 hashtags that we were able to retrieve hashtag definitions for for a user populated site.",
                    "label": 0
                },
                {
                    "sent": "I'll say more about that later.",
                    "label": 0
                },
                {
                    "sent": "About mentions we have 334.",
                    "label": 0
                },
                {
                    "sent": "Of which we were able to retrieve almost all biographies from Twitter.",
                    "label": 0
                },
                {
                    "sent": "That query almost always succeeds unless someone changed their username.",
                    "label": 0
                },
                {
                    "sent": "But the quality of those biographies is quite variable.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The only system that we evaluated this working it's at any ID system developed over several EU projects in which we try to integrate current technologies and for achieving this task integrate with the long term plan of sharing those components.",
                    "label": 1
                },
                {
                    "sent": "We aim to make it robust to different input types, hence our work on Twitter and we're currently working on making it portable to new domains.",
                    "label": 1
                },
                {
                    "sent": "And it's suitable for this works.",
                    "label": 0
                },
                {
                    "sent": "It's a typical approach comprising well researched and published techniques.",
                    "label": 0
                },
                {
                    "sent": "And the performance that we achieve with this is compatible to state of the art systems.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm so very quick overview so that you can understand.",
                    "label": 0
                },
                {
                    "sent": "The way in which additional Twitter content helps, and also how likely this result is to transfer to other systems that may be slightly different from this one.",
                    "label": 0
                },
                {
                    "sent": "And the approach we used to finding a named entities and putting candidate interpretations onto them is to construct a large gazetteer from.",
                    "label": 0
                },
                {
                    "sent": "A list of labels, ways in which all DB pedia and entities can be referred to.",
                    "label": 0
                },
                {
                    "sent": "Different aliases link text from Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "To compose a long list of ways in which these entities referred to we pruned that with a few heuristics, but essentially then look for mentions of that in the text to give us quite a high recall.",
                    "label": 1
                },
                {
                    "sent": "First cut at finding candidates for the entities in the text.",
                    "label": 0
                },
                {
                    "sent": "And this is relevant to to what comes next in terms of disambiguation, and that since it's high recall, we then relying on the disambiguation step to eliminate some of the spurious candidates likely to be generated at that stage.",
                    "label": 0
                },
                {
                    "sent": "So having found these candidates, we then which themselves come with information such as Piper ability and so forth.",
                    "label": 0
                },
                {
                    "sent": "We then score them for their success and fitting with the context.",
                    "label": 1
                },
                {
                    "sent": "And this is the first place in which Twitter expansion makes a difference, in that it provides more context and hopefully allowing that to be done more successfully.",
                    "label": 0
                },
                {
                    "sent": "We then choose the final choice of candidate using support vector machine disambiguation step.",
                    "label": 0
                },
                {
                    "sent": "Based on the scores.",
                    "label": 0
                },
                {
                    "sent": "So obviously if the scores are different then that has the potential to influence how well that final steps able to work.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So quick overview of the scores that we've essentially I'm going to show you how Twitter expansion affect some scores.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to show you how it affects the final result.",
                    "label": 0
                },
                {
                    "sent": "Post disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So quick run through the scores.",
                    "label": 0
                },
                {
                    "sent": "Firstly, we've got some structural scores.",
                    "label": 0
                },
                {
                    "sent": "Basic idea with structural scores is to see how well candidates relate to other potential candidates on their by entities, so that you can try to pick candidates for different entities that are congruent with each other.",
                    "label": 0
                },
                {
                    "sent": "So in the example I've got here, I've got three candidates for Kagawa and two Fer and Subotic.",
                    "label": 0
                },
                {
                    "sent": "Three Kagawa candidates, once a footballer and of the two sebatik candidates.",
                    "label": 0
                },
                {
                    "sent": "We also have a footballer so we should prefer the two candidates in the footballers because they've got a congruence between them in terms of domain.",
                    "label": 0
                },
                {
                    "sent": "So that's the basic idea, but including this kind of information in the system can be achieved in different ways.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A common way to do this is the pairwise approach of relatedness for million written.",
                    "label": 0
                },
                {
                    "sent": "Which looks at Wikipedia pages linked to each of these candidates and how much overlap is there between those two that gives an indicator of how related they are.",
                    "label": 0
                },
                {
                    "sent": "So we've included that one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also in order to include a similar type of information but from the DB pedia graph.",
                    "label": 0
                },
                {
                    "sent": "We've also counting relationships that appear in the DB pedia graph, connecting entities to each other.",
                    "label": 0
                },
                {
                    "sent": "This tends to be a sparse symmetric, but a very high quality one.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also have some text based scores evaluating the success of a particular candidate in fitting with the textual content context.",
                    "label": 0
                },
                {
                    "sent": "That it arises in.",
                    "label": 0
                },
                {
                    "sent": "So we're comparing the entire text of the tweet.",
                    "label": 0
                },
                {
                    "sent": "It's short enough already.",
                    "label": 0
                },
                {
                    "sent": "Then we compare that with the abstract for the candidate DB pedia entry to see if we can find a congruence between them.",
                    "label": 0
                },
                {
                    "sent": "And in order to improve that a little bit, we also map them through a semantic space that's being constructed over half a million DB pedia abstracts and then TF IDF transformed in order to expand those vectors a little bit with related terms and make that comparison more successful.",
                    "label": 1
                },
                {
                    "sent": "We then cosine those vectors to obtain a score.",
                    "label": 0
                },
                {
                    "sent": "Of how well that candidate seems to fit with the textual content context in which we found it.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, as I say, we use an SVM to rate each candidate.",
                    "label": 0
                },
                {
                    "sent": "I'm having put these scores onto it for how likely that candidate is to be the right answer.",
                    "label": 1
                },
                {
                    "sent": "And as I said earlier, we also rely on this stage to eliminate some spurious candidates.",
                    "label": 0
                },
                {
                    "sent": "So if they're all considered unlikely, we drop the whole mention.",
                    "label": 1
                },
                {
                    "sent": "When multiple candidates seem promising, we use probability allocated by the SVM to pick one.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The expansions we studied it as I mentioned earlier, we use hashtag expansions from the website tagdef.com to get some user generated.",
                    "label": 0
                },
                {
                    "sent": "Definitions of what hashtag refers to.",
                    "label": 0
                },
                {
                    "sent": "We also use URLs to get the entire web page content, and we use that mentions to get the Twitter user via.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here's the example of familiar in the gate GUI.",
                    "label": 1
                },
                {
                    "sent": "It's probably quite hard to read, but I don't think you need to to read it in great detail in yellow.",
                    "label": 0
                },
                {
                    "sent": "At the top we've got the original tweet.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then underneath we've got the expansions.",
                    "label": 0
                },
                {
                    "sent": "So friend Subotic, we've got the user bio.",
                    "label": 0
                },
                {
                    "sent": "Importantly, in the user buyer we now have antibiotics full name written out in a way that very likely to be very informative.",
                    "label": 0
                },
                {
                    "sent": "We then expanded on the mufc hashtag with these 5 user contributed definitions for what that refers to.",
                    "label": 0
                },
                {
                    "sent": "These can be a variable quality, and this one in particular can see that all five are attempts at humor.",
                    "label": 0
                },
                {
                    "sent": "But that said, it still contains some really useful information.",
                    "label": 0
                },
                {
                    "sent": "We've got another footballer, the darker areas, by the way, are named entities that relocated using the same technology in the expansion.",
                    "label": 0
                },
                {
                    "sent": "So we've got a further footballer found, which could possibly help us to disambiguate the domain, but also we've got the word soccer, and we've got the word football, so these are really likely to be helpful.",
                    "label": 0
                },
                {
                    "sent": "And we've also expanded the URL.",
                    "label": 0
                },
                {
                    "sent": "There's a lot more text scrolled off the bottom from that web page, but again, this contains a lot of useful information.",
                    "label": 0
                },
                {
                    "sent": "We've got the full name of the football team from football team from the hashtag.",
                    "label": 0
                },
                {
                    "sent": "Again, we've got the word football, so all this looks likely to be really helpful.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I say for the.",
                    "label": 0
                },
                {
                    "sent": "The two types of scores are adding more context essentially gives these scores more information to operate across.",
                    "label": 1
                },
                {
                    "sent": "The structural scores have now got more entities to relate entities too, and the textual scores will get a lot more text.",
                    "label": 1
                },
                {
                    "sent": "We also did another trick here, which I'll explain with reference to the previous slide.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the @ and Subotic that strings unlikely to retrieve very good quality candidate list because it's not a well formed representation of that person's name.",
                    "label": 0
                },
                {
                    "sent": "Having expend expanded it to the biography.",
                    "label": 0
                },
                {
                    "sent": "We have more chance of identifying that individual because his name is written out in full, but if we never had the right candidate on the @ then we can't select it.",
                    "label": 0
                },
                {
                    "sent": "So the final trick we applied here is to find any candidate on any mention in the biography expansion and put them all as candidates on that mention.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to refer to that as backprojection from here.",
                    "label": 0
                },
                {
                    "sent": "Back projection of candidates from the user bio onto the @",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the experimental condition is that we've run our first.",
                    "label": 0
                },
                {
                    "sent": "We evaluated baseline system with no expansion.",
                    "label": 1
                },
                {
                    "sent": "We then tried each of the three expansions separately.",
                    "label": 1
                },
                {
                    "sent": "And then mentioned expansion with back projection of candidates from the use fire.",
                    "label": 0
                },
                {
                    "sent": "We tried everything all together and we also tried one in which we exclude hashtag expansion since as you'll see on the final results, slide hashtag seemed like they may have limited utility is worth trying to see if they really contribute anything to the final result.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a couple of baselines.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you some results from some individual scores, and just to be able to position the results from those scores.",
                    "label": 0
                },
                {
                    "sent": "Let's just look at these baselines.",
                    "label": 0
                },
                {
                    "sent": "So at this stage in which we found entities and put candidate lists on all of them.",
                    "label": 0
                },
                {
                    "sent": "If at that point you just pick one of those at random, you'll get an F1 result for the complete task named entity recognition and disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Your overall F1 score will be .229.",
                    "label": 0
                },
                {
                    "sent": "If of those candidates you pick the one with the best prior probability, but which we've used in this case, the most you are I mentioned in Wikipedia, so this is the most probable candidate just in terms of background distribution, then that will give you an F1 of .521.",
                    "label": 1
                },
                {
                    "sent": "And picking the most common candidate is a hard baseline to beat, and you'll see that the scores that we now look at don't beat that.",
                    "label": 1
                },
                {
                    "sent": "What they do is contribute a different kind of information that the final disambiguation step can combine in order to get a result that's better than that overall.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So initially the DB pedia based relatedness score between candidates.",
                    "label": 0
                },
                {
                    "sent": "We can see that we've got a baseline F1 of .326 and essentially including Twitter expansion hasn't really succeeded in improving on that.",
                    "label": 0
                },
                {
                    "sent": "We've got a very minor improvement for URL, but the deal is actually if anything, it maybe makes it worse.",
                    "label": 0
                },
                {
                    "sent": "This is odd, I'm I expected to see a better result for this because the DPD graph is quite sparse.",
                    "label": 1
                },
                {
                    "sent": "And doesn't you know, sometimes it doesn't include very sensible relations if there is a relation there.",
                    "label": 0
                },
                {
                    "sent": "It's it's useful information, but lots of time relations that you would expect to see on there.",
                    "label": 0
                },
                {
                    "sent": "So I thought adding more material might really help with this, but that's not what we've found so far.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The relatedness score does a little bit better in that we do see some improvement.",
                    "label": 0
                },
                {
                    "sent": "In particular, if we use user BIOS.",
                    "label": 0
                },
                {
                    "sent": "So it's a little bit more of an improvement there.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm getting looking at now looking at the text based comparison between the tweet text.",
                    "label": 0
                },
                {
                    "sent": "The candidate abstract starting to look a little bit better.",
                    "label": 0
                },
                {
                    "sent": "For baseline, we've got .27, and if we include user BIOS with back projection of candidates, we can get an F1 point .295, which is a bit better.",
                    "label": 0
                },
                {
                    "sent": "In particular, we see a bit of a jumping recall, which is the kind of thing you'd expect to see because we're actually adding candidates onto that mentions which went there.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of results I expected to see more in some of the other scores, but.",
                    "label": 0
                },
                {
                    "sent": "We do start to see that here.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then finally, in addition to comparing.",
                    "label": 0
                },
                {
                    "sent": "For the candidate with the DB Pedia abstract text.",
                    "label": 0
                },
                {
                    "sent": "We also include all of the textual fields in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So this is as much textual information so we can get out of DB pedia for that candidate.",
                    "label": 0
                },
                {
                    "sent": "And here's where we start to see the most convincing result.",
                    "label": 0
                },
                {
                    "sent": "With an F1 jumping from .279 at 2.32 C. Compelling.",
                    "label": 0
                },
                {
                    "sent": "So in terms of some explanation for what what might be going on here?",
                    "label": 0
                },
                {
                    "sent": "My feeling is if we if we just go back to our example.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the screenshot here we can see that we've added some knew mentions which are potentially quite useful, but given that some of the related metrics may be quite sparse, we've potentially not actually added any useful information at this stage.",
                    "label": 0
                },
                {
                    "sent": "My feeling the contribution to the structural scores would be greater than using a less sparse relatedness metric, so I think that would be a potential to improve there, but essentially finding entities is somewhat.",
                    "label": 0
                },
                {
                    "sent": "You know we we see repeated entities here, not necessarily added very great deal of information, but more text is much more.",
                    "label": 0
                },
                {
                    "sent": "Deterministically going to improve performance and what we see is that if you have added more text to the context, then we get even more leverage.",
                    "label": 0
                },
                {
                    "sent": "In the case where we've got more text for the candidate.",
                    "label": 0
                },
                {
                    "sent": "So I think in order to maximize the result we get from from this, this kind of contribution, then what we need to see is as much text as possible for the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, using surrounding context from Wikipedia for the candidate is a way of getting even more.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Information.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So finally we include the disambiguation stage.",
                    "label": 0
                },
                {
                    "sent": "The SVM in ranking rate doesn't rank it's cause them separately these candidates for their likelihood of being correct, has the potential to add more intelligence in that it can relate these different scores in different ways to other features that aren't necessarily just as simple as higher score is better.",
                    "label": 0
                },
                {
                    "sent": "And so here's where we see greater improvements.",
                    "label": 0
                },
                {
                    "sent": "We've got an accuracy jump from .55 up to .62 which is quite compelling.",
                    "label": 0
                },
                {
                    "sent": "We've also done Mcnamer sign test to evaluate the significance of these improvements, and you can see that with the exception of user BIOS, all of the expansion types yield a significant improvement.",
                    "label": 0
                },
                {
                    "sent": "In particular, back projection of candidates seems to help in that, as you would expect it improves.",
                    "label": 0
                },
                {
                    "sent": "Recall a lot.",
                    "label": 0
                },
                {
                    "sent": "With regards to the contribution of hashtag expansion, which I experimentally eliminate it because it doesn't seem to make that much difference, but nonetheless it does make a significant.",
                    "label": 0
                },
                {
                    "sent": "Difference and the final result with regards to these last two lines where we have different.",
                    "label": 0
                },
                {
                    "sent": "Search results in terms of whether accuracy F1 is better.",
                    "label": 0
                },
                {
                    "sent": "You know this may just be a precision recall balancing issue, but I think in essence the best system is the one that includes all of the expansions.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to contextualize the result, we run a few different systems on that corpus.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "You know, by adding that that extra advantage to yodi, we resulted in improvement.",
                    "label": 0
                },
                {
                    "sent": "That sort of repositions is on this on this scoreboard here.",
                    "label": 0
                },
                {
                    "sent": "Although note that this isn't a competition since those other systems don't use to eat expansion.",
                    "label": 0
                },
                {
                    "sent": "But it does give an illustration of how this kind of difference you know is sort of substantial on the scale of the kind of performances that systems are achieving on that type of data.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in terms of how this is going to?",
                    "label": 0
                },
                {
                    "sent": "Carry across to two other tasks and other systems.",
                    "label": 0
                },
                {
                    "sent": "Well, I think corpus type is a big factor in how.",
                    "label": 0
                },
                {
                    "sent": "How much of a improvement we're going to see in particular if you've got a tweet corpus, that's news focused.",
                    "label": 0
                },
                {
                    "sent": "News tweets often consist of a title followed by a URL which you then follow up immediately may mean that you have a successful URL expansion for every tweet, in which case you might expect to see an accuracy gain of .06 in your corpus.",
                    "label": 0
                },
                {
                    "sent": "In particular, that mentions if you have a successful @ expansion in every tweet, you can see if a very big accuracy gain due to that recall improvement.",
                    "label": 0
                },
                {
                    "sent": "If and this was actually calculated in our corpus with no consideration of whether that mentioned first to someone who has a DB pedia page, so you may expect to see even more than that if your corpus focuses, perhaps some celebrities or politicians.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all I have to say.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Among you structural features one you say is related to how you candidates are connected via deep area.",
                    "label": 0
                },
                {
                    "sent": "Yes, I guess you're considering only path one so directly connected with just one predicate.",
                    "label": 0
                },
                {
                    "sent": "Now we did include the direct relations.",
                    "label": 0
                },
                {
                    "sent": "We also included indirect relations with one step removal.",
                    "label": 0
                },
                {
                    "sent": "OK, but in this doing this you consider that all predicates are equal.",
                    "label": 0
                },
                {
                    "sent": "No?",
                    "label": 0
                },
                {
                    "sent": "We divided those by the inverse square of the number of steps in the relation.",
                    "label": 0
                },
                {
                    "sent": "So we went up to a maximum of two steps, but then waited them by the inverse square of the number of steps.",
                    "label": 0
                },
                {
                    "sent": "OK, but so you didn't throw out predicates like weaklings or that have very little semantics in how their connect to entities.",
                    "label": 0
                },
                {
                    "sent": "Um, I would have to get back to you on that I.",
                    "label": 0
                },
                {
                    "sent": "It's like a list of stopwords, but there will be a list of stuff.",
                    "label": 0
                },
                {
                    "sent": "Pretty yes, it seems likely that my coauthor did this, but he just gave me the database.",
                    "label": 0
                },
                {
                    "sent": "I'll have to get back to you.",
                    "label": 0
                },
                {
                    "sent": "OK, yes, thank you for the talk, and I was wondering if you have been also looking at the bubble net.",
                    "label": 0
                },
                {
                    "sent": "Framework I was testing some of the examples were giving and they were not that good as.",
                    "label": 0
                },
                {
                    "sent": "As you seem to be but but I think it's interesting to look at this bubble net resource because they integrate all those wiki page at PPG and this kind of things and they also started to have a disambiguation engine running on this.",
                    "label": 0
                },
                {
                    "sent": "Right now, I think it would be quite interesting to compare your approach.",
                    "label": 0
                },
                {
                    "sent": "Yes, it would definitely definitely interested in comparing to that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and a few other systems.",
                    "label": 0
                },
                {
                    "sent": "So I have another questions came to my mind.",
                    "label": 0
                },
                {
                    "sent": "When you use different so for the linguistic part.",
                    "label": 0
                },
                {
                    "sent": "When you're analyzing tweets.",
                    "label": 0
                },
                {
                    "sent": "So when you do posts and things like this, did you specific pose model like adapted for tweets?",
                    "label": 0
                },
                {
                    "sent": "Or did you use a general purpose?",
                    "label": 0
                },
                {
                    "sent": "Post now we used to tweet adapted one we used them gate to to prepare the tweet and then gate has a Twitter pipeline that does various things such As for example splitting hashtags into component based on casing which often allows us to find find things that we wouldn't.",
                    "label": 0
                },
                {
                    "sent": "Those things like that yeah, OK. And the proportion of hashtags that you couldn't really expand using tag DEF.",
                    "label": 0
                },
                {
                    "sent": "How is this?",
                    "label": 0
                },
                {
                    "sent": "Proportion about half half about half yeah, but there are also possibilities for an for trying different databases of hashtag definitions to see if we can find one that works a bit better.",
                    "label": 0
                },
                {
                    "sent": "Typedef tended to be quite jokey.",
                    "label": 0
                },
                {
                    "sent": "So we have more questions.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}