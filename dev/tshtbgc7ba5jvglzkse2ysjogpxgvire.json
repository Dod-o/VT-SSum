{
    "id": "tshtbgc7ba5jvglzkse2ysjogpxgvire",
    "title": "Optimizing Horn-SHIQ Reasoning for OBDA",
    "info": {
        "author": [
            "Labinot Bajraktari, University of Prishtina"
        ],
        "published": "Dec. 10, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_bajraktari_horn_SHIQ/",
    "segmentation": [
        [
            "OK, so thank you for the introduction.",
            "So the work I'm presenting here today is in line of optimization or for Horn chic description logic with the aim of making it more suitable for ontology based data access."
        ],
        [
            "Our motivation for doing this is that state of the art of these systems are based on their light, and while this is for a very good reason because as query answering is a key service and or BDA the nice computational features that delight has with respect to this problem makes it a natural candidate.",
            "But in the other side there are there are many application domain in which the delight.",
            "Expressiveness is simply not enough, so we focus here in Hong Shik, which is a quite expressive description logic.",
            "That actually contains all the constructors that deal light and even yell and adds on top of it are transitive rolls and.",
            "Roll restrictions.",
            "Uh.",
            "And we aim to optimize this for over these."
        ],
        [
            "I think.",
            "So when it comes to query answering.",
            "The most well known and actually the the only algorithm two that is complete for all features of horn shake, is the one designed by known to us.",
            "At least is the one designed by either at all.",
            "This algorithm is also implemented in a system called Clipper.",
            "It relies on building the Canonical model or the universal model.",
            "In order to facilitate query answering and it does this in three steps.",
            "In the first step it employs a specially tailored calculus to infer new axioms that may be needed to build the universal model.",
            "In the second step, then it basically closes the Abebooks on the all the derived axioms, but the existentials once and in the end it employs.",
            "It basically runs chase procedure with existential axioms.",
            "Obtained in the step one, however, this."
        ],
        [
            "William has a problem.",
            "It's quite expensive and it's not just hypothetically worst case, exponential maybe, but it performs quite badly in a lot of for a lot of realistic ontologies.",
            "And this is mainly because it's data tables independent."
        ],
        [
            "We will illustrate this with a simple, simple example.",
            "Consider this snippet of an ontology of anti money laundry ontology which basically.",
            "Phil has the purpose of.",
            "Tracking suspicious activities in banking accounts where the first axiom are basically says that monitored account has has to be flagged.",
            "The second axiom says an individual.",
            "Account that is also monitored has to have the flag yellow flag and so on if we.",
            "If we saturate this with the existing calculus."
        ],
        [
            "A rule known As for example.",
            "In this case the for all rules becomes applicable, which basically states that for each existential axiom.",
            "So, so for each existential axiom that has a matching role with some axiom that has universals on on the right side.",
            "It derives an axiom which basically foresees that in some way box there might exist some individual that is a monitored account.",
            "An individual account.",
            "Therefore it has to have some flag that is a yellow flag.",
            "So far so good.",
            "But if we continue."
        ],
        [
            "Saturate"
        ],
        [
            "Bing this."
        ],
        [
            "No of D box with a."
        ],
        [
            "With."
        ],
        [
            "Given calculus, we see that we get an exponential blowup actually on the number of.",
            "Axioms basically, in the number of universal axioms on the right hand side.",
            "That, combined with the existential.",
            "Ask him on the top.",
            "Basically we have two to the power of 3 -- 1 and if we inspect."
        ],
        [
            "Them closely, we see that most of them are not needed because we will never have in a box that this together an individual account and small business account or etc.",
            "We expect this to be disjoint, however due to completeness and negativity of the calculus, these have to be considered an added there.",
            "So how do we go about?"
        ],
        [
            "Addressing this problem well, we try to use some information about the structure of the A boxes or relevante boxes, and this is very.",
            "Natural for the obvious setting where a boxes are actually generated.",
            "From your mappings and we can predict the structure we define.",
            "We use actually this.",
            "So we use the notion of a box types to capture the concept assertions that an individual might satisfy satisfying some relevant books for us and also its neighborhood.",
            "For example, incoming and outgoing rules, and we use this today."
        ],
        [
            "Drive activators, which are a key component in optimizing the calculus and what activators in our case have to cover.",
            "They have to cover all the concept assertions and.",
            "And Moreover, they we require them to cover all the potential concepts that might be propagated from the neighborhood of the.",
            "All the ebooks type we call these also over approximated ebooks type and.",
            "For.",
            "And a box.",
            "We say that any boxes covered by a set of activators, if for each of the individuals that occurs in the air box, we can find some activator that contains the over approximating over approximated able style so."
        ],
        [
            "Now, assuming that we have, we have a set of activators that cover all the relevant a boxes that can happen in practice.",
            "Let's assume that we have them.",
            "We can optimize the calculus by adding this site site conditions.",
            "Site conditions with basically check if the left hand side of the action that we want to derive is contained in one of the activators.",
            "If it is there then it's derived and Moreover we of course.",
            "Take care that the.",
            "The set of activators is actually closed.",
            "Under the terministic rules and we also have to add them on the way of the derivation process.",
            "The third, the last rule here, is just for housekeeping.",
            "Basically removing redundant activators.",
            "OK, but now."
        ],
        [
            "How do we get these activators that can cover any relevant tables?",
            "Well in all the day?",
            "Is simple, so we use the mapping layer.",
            "We focused on the mapping layer that is expressed in auto RML and basically mapping can be seen as.",
            "This is seen as a set of mapping assertions that take.",
            "An expression of the following form where the left hand side is basically just a separate set of database items.",
            "Right inside is an unary or binary predicate.",
            "The functional symbol of the functional symbol here basically is the error function that generates the name of the individual.",
            "When the mapping is evaluated over some concrete tables, we make the following assumptions about functional symbols that, for two different topless database tables and for the same functional symbol, we always get different values, and this is actually also embedded in the auto renewal standard and the 2nd is that for two different functional symbols we always get different values.",
            "We will never get.",
            "The same values.",
            "This is also an assumption that is made in obvious systems.",
            "For example on top."
        ],
        [
            "Now, how do we obtain the the activators?",
            "Now consider the this simple example of mapping assertions.",
            "One simple way would be to treat as an A box type.",
            "The set of all the head predicates.",
            "Of mappings that share that share the same functional symbol.",
            "However, this is."
        ],
        [
            "Can can be a problem because we can get a large box types and if we get a very large activators just think about a Singleton activator for example that contains all the vocabulary of the ontology.",
            "Then there is no optimization there.",
            "The idea is to have a small activators as possible, so can we do better and actually we can we."
        ],
        [
            "Can leverage functional dependencies to define which mappings or conflicting mappings.",
            "Basically that cannot fire for the same constants, constants, or."
        ],
        [
            "Consider for example the relation that occurs here, account details with its attribute ID, type and size.",
            "And the functional.",
            "The functional dependency that says the type and size depends functionally on the ID.",
            "Then it is clear, for example that the mapping M4 and then pipe conflict in the size attribute, so they will never be fired for the same constant in the database and in the end when we have all these conflicting mappings, we basically just take the maximal conflict.",
            "Reset off of.",
            "Mappings and use the health predicates in those two to generate head predicates that share the same functional symbols to generate the avox types from where we get the activators.",
            "So."
        ],
        [
            "So and lossed some results.",
            "We have implemented this, let's say simple maybe approach, but it yielded quite good results.",
            "We implemented it in the Clipper system and compared it with the base version.",
            "We use the Oxford Ontology repository to test it.",
            "After pre processing ontologies we saw that 221 where seen as relevant we got like.",
            "37% increase in the number of the.",
            "Ontologist that we could saturate basically with the optimized version versus the 108 with the original one.",
            "It goes without saying that in all cases where the unoptimized version succeeded, the optimized version also succeeded."
        ],
        [
            "If one picks a closer look in the cases where both of the version succeeded, one can see, for example, in the graph above.",
            "We have plotted the rate of the growth of the.",
            "Saturated the box with respect to the original steel box and the red bars are the ones that represent the original original calculus or or the original Clipper.",
            "And while the blue bars the optimized version, the blue bars are presented here are plotted on top of the red bars because we always get lower.",
            "And if one looks at the graph, sees that most of the actions that are derived with the.",
            "With the original calculus are actually redundant or not needed for for clearance and also in the run times.",
            "The optimized version was nearly always faster."
        ],
        [
            "For the against instances, basically ontologies in which only the optimized version succeeded while the.",
            "Oh the original 1 failed.",
            "We notice that the rate of growth was in the same range, basically like the other cases.",
            "Also, we got good times running times for these cases."
        ],
        [
            "In the end we also analyzed activators that we can get from obvious specifications because the instances that we tested on we had to get the activators directly from mailboxes because it's very hard to come across.",
            "Many of the benchmarks that have mappings and ontology that is expressed in homeshake.",
            "Actually that there are now.",
            "So we are analyzed, three of them with our approach that we described in detail in the paper and what we notice is that the number of activators and their size was in the moderately in the same range as the ones we got directly from the 8 boxes of.",
            "From testing them against Oxford Ontology repository."
        ],
        [
            "And in the end we.",
            "We can claim that this structure based approach for optimizing the reason is promising.",
            "We obtained encouraging results.",
            "Moreover, one can audit the activators that one gets and by auditing the ontology engineer can see that this activator can be broken up because these two concepts do not go together, in which case this can improve the performance even further.",
            "Moreover, the our approach is incremental.",
            "You can compute incrementally for future.",
            "We seek to develop more fine grained algorithms for obtaining the activators and also to try and validate this approach against more benchmarks."
        ],
        [
            "Thank you.",
            "Thank you.",
            "Questions.",
            "OK so I had one question that matter.",
            "One question, yeah, so some of the results in your optimization.",
            "This one that has a few sort of standouts.",
            "For example, about 85 if you have 85 instances, the Seahawks seems to be performing worse.",
            "Did you look into the cost for that one?",
            "I mean the the causes because sometimes we have to extract the activators and sometimes this doesn't pay off.",
            "But this doesn't mean that it performs way worse, because this is in a matter of runtime seconds and the.",
            "Procedure of extracting the activity is not very well engineered to be honest.",
            "So that's why it's just we we pay this cost and sometimes it doesn't pay off, but for a more larger ontologies this always and I didn't have the.",
            "I thought that I will be much slower, but we also looked at the distribution of the ontologies and we have like 25% of the cases where very large ontologies that had over 10,000 axioms and also very large array boxes and.",
            "It worked well, but this is the reason, OK, thank you.",
            "Thank you speaker again.",
            "Last speaker.",
            "Unless if OK, OK, thank you, OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so thank you for the introduction.",
                    "label": 0
                },
                {
                    "sent": "So the work I'm presenting here today is in line of optimization or for Horn chic description logic with the aim of making it more suitable for ontology based data access.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our motivation for doing this is that state of the art of these systems are based on their light, and while this is for a very good reason because as query answering is a key service and or BDA the nice computational features that delight has with respect to this problem makes it a natural candidate.",
                    "label": 1
                },
                {
                    "sent": "But in the other side there are there are many application domain in which the delight.",
                    "label": 0
                },
                {
                    "sent": "Expressiveness is simply not enough, so we focus here in Hong Shik, which is a quite expressive description logic.",
                    "label": 0
                },
                {
                    "sent": "That actually contains all the constructors that deal light and even yell and adds on top of it are transitive rolls and.",
                    "label": 0
                },
                {
                    "sent": "Roll restrictions.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "And we aim to optimize this for over these.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "So when it comes to query answering.",
                    "label": 0
                },
                {
                    "sent": "The most well known and actually the the only algorithm two that is complete for all features of horn shake, is the one designed by known to us.",
                    "label": 0
                },
                {
                    "sent": "At least is the one designed by either at all.",
                    "label": 0
                },
                {
                    "sent": "This algorithm is also implemented in a system called Clipper.",
                    "label": 0
                },
                {
                    "sent": "It relies on building the Canonical model or the universal model.",
                    "label": 1
                },
                {
                    "sent": "In order to facilitate query answering and it does this in three steps.",
                    "label": 0
                },
                {
                    "sent": "In the first step it employs a specially tailored calculus to infer new axioms that may be needed to build the universal model.",
                    "label": 0
                },
                {
                    "sent": "In the second step, then it basically closes the Abebooks on the all the derived axioms, but the existentials once and in the end it employs.",
                    "label": 0
                },
                {
                    "sent": "It basically runs chase procedure with existential axioms.",
                    "label": 0
                },
                {
                    "sent": "Obtained in the step one, however, this.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "William has a problem.",
                    "label": 0
                },
                {
                    "sent": "It's quite expensive and it's not just hypothetically worst case, exponential maybe, but it performs quite badly in a lot of for a lot of realistic ontologies.",
                    "label": 0
                },
                {
                    "sent": "And this is mainly because it's data tables independent.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will illustrate this with a simple, simple example.",
                    "label": 0
                },
                {
                    "sent": "Consider this snippet of an ontology of anti money laundry ontology which basically.",
                    "label": 0
                },
                {
                    "sent": "Phil has the purpose of.",
                    "label": 0
                },
                {
                    "sent": "Tracking suspicious activities in banking accounts where the first axiom are basically says that monitored account has has to be flagged.",
                    "label": 0
                },
                {
                    "sent": "The second axiom says an individual.",
                    "label": 0
                },
                {
                    "sent": "Account that is also monitored has to have the flag yellow flag and so on if we.",
                    "label": 0
                },
                {
                    "sent": "If we saturate this with the existing calculus.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A rule known As for example.",
                    "label": 0
                },
                {
                    "sent": "In this case the for all rules becomes applicable, which basically states that for each existential axiom.",
                    "label": 0
                },
                {
                    "sent": "So, so for each existential axiom that has a matching role with some axiom that has universals on on the right side.",
                    "label": 0
                },
                {
                    "sent": "It derives an axiom which basically foresees that in some way box there might exist some individual that is a monitored account.",
                    "label": 0
                },
                {
                    "sent": "An individual account.",
                    "label": 0
                },
                {
                    "sent": "Therefore it has to have some flag that is a yellow flag.",
                    "label": 0
                },
                {
                    "sent": "So far so good.",
                    "label": 0
                },
                {
                    "sent": "But if we continue.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Saturate",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bing this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No of D box with a.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given calculus, we see that we get an exponential blowup actually on the number of.",
                    "label": 0
                },
                {
                    "sent": "Axioms basically, in the number of universal axioms on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "That, combined with the existential.",
                    "label": 0
                },
                {
                    "sent": "Ask him on the top.",
                    "label": 0
                },
                {
                    "sent": "Basically we have two to the power of 3 -- 1 and if we inspect.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Them closely, we see that most of them are not needed because we will never have in a box that this together an individual account and small business account or etc.",
                    "label": 0
                },
                {
                    "sent": "We expect this to be disjoint, however due to completeness and negativity of the calculus, these have to be considered an added there.",
                    "label": 0
                },
                {
                    "sent": "So how do we go about?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Addressing this problem well, we try to use some information about the structure of the A boxes or relevante boxes, and this is very.",
                    "label": 0
                },
                {
                    "sent": "Natural for the obvious setting where a boxes are actually generated.",
                    "label": 0
                },
                {
                    "sent": "From your mappings and we can predict the structure we define.",
                    "label": 0
                },
                {
                    "sent": "We use actually this.",
                    "label": 0
                },
                {
                    "sent": "So we use the notion of a box types to capture the concept assertions that an individual might satisfy satisfying some relevant books for us and also its neighborhood.",
                    "label": 0
                },
                {
                    "sent": "For example, incoming and outgoing rules, and we use this today.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Drive activators, which are a key component in optimizing the calculus and what activators in our case have to cover.",
                    "label": 0
                },
                {
                    "sent": "They have to cover all the concept assertions and.",
                    "label": 0
                },
                {
                    "sent": "And Moreover, they we require them to cover all the potential concepts that might be propagated from the neighborhood of the.",
                    "label": 0
                },
                {
                    "sent": "All the ebooks type we call these also over approximated ebooks type and.",
                    "label": 0
                },
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "And a box.",
                    "label": 0
                },
                {
                    "sent": "We say that any boxes covered by a set of activators, if for each of the individuals that occurs in the air box, we can find some activator that contains the over approximating over approximated able style so.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, assuming that we have, we have a set of activators that cover all the relevant a boxes that can happen in practice.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that we have them.",
                    "label": 0
                },
                {
                    "sent": "We can optimize the calculus by adding this site site conditions.",
                    "label": 0
                },
                {
                    "sent": "Site conditions with basically check if the left hand side of the action that we want to derive is contained in one of the activators.",
                    "label": 0
                },
                {
                    "sent": "If it is there then it's derived and Moreover we of course.",
                    "label": 0
                },
                {
                    "sent": "Take care that the.",
                    "label": 0
                },
                {
                    "sent": "The set of activators is actually closed.",
                    "label": 0
                },
                {
                    "sent": "Under the terministic rules and we also have to add them on the way of the derivation process.",
                    "label": 0
                },
                {
                    "sent": "The third, the last rule here, is just for housekeeping.",
                    "label": 0
                },
                {
                    "sent": "Basically removing redundant activators.",
                    "label": 0
                },
                {
                    "sent": "OK, but now.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we get these activators that can cover any relevant tables?",
                    "label": 0
                },
                {
                    "sent": "Well in all the day?",
                    "label": 1
                },
                {
                    "sent": "Is simple, so we use the mapping layer.",
                    "label": 0
                },
                {
                    "sent": "We focused on the mapping layer that is expressed in auto RML and basically mapping can be seen as.",
                    "label": 1
                },
                {
                    "sent": "This is seen as a set of mapping assertions that take.",
                    "label": 0
                },
                {
                    "sent": "An expression of the following form where the left hand side is basically just a separate set of database items.",
                    "label": 0
                },
                {
                    "sent": "Right inside is an unary or binary predicate.",
                    "label": 0
                },
                {
                    "sent": "The functional symbol of the functional symbol here basically is the error function that generates the name of the individual.",
                    "label": 0
                },
                {
                    "sent": "When the mapping is evaluated over some concrete tables, we make the following assumptions about functional symbols that, for two different topless database tables and for the same functional symbol, we always get different values, and this is actually also embedded in the auto renewal standard and the 2nd is that for two different functional symbols we always get different values.",
                    "label": 1
                },
                {
                    "sent": "We will never get.",
                    "label": 0
                },
                {
                    "sent": "The same values.",
                    "label": 0
                },
                {
                    "sent": "This is also an assumption that is made in obvious systems.",
                    "label": 0
                },
                {
                    "sent": "For example on top.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, how do we obtain the the activators?",
                    "label": 0
                },
                {
                    "sent": "Now consider the this simple example of mapping assertions.",
                    "label": 0
                },
                {
                    "sent": "One simple way would be to treat as an A box type.",
                    "label": 0
                },
                {
                    "sent": "The set of all the head predicates.",
                    "label": 1
                },
                {
                    "sent": "Of mappings that share that share the same functional symbol.",
                    "label": 1
                },
                {
                    "sent": "However, this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can can be a problem because we can get a large box types and if we get a very large activators just think about a Singleton activator for example that contains all the vocabulary of the ontology.",
                    "label": 1
                },
                {
                    "sent": "Then there is no optimization there.",
                    "label": 0
                },
                {
                    "sent": "The idea is to have a small activators as possible, so can we do better and actually we can we.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can leverage functional dependencies to define which mappings or conflicting mappings.",
                    "label": 0
                },
                {
                    "sent": "Basically that cannot fire for the same constants, constants, or.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Consider for example the relation that occurs here, account details with its attribute ID, type and size.",
                    "label": 0
                },
                {
                    "sent": "And the functional.",
                    "label": 0
                },
                {
                    "sent": "The functional dependency that says the type and size depends functionally on the ID.",
                    "label": 0
                },
                {
                    "sent": "Then it is clear, for example that the mapping M4 and then pipe conflict in the size attribute, so they will never be fired for the same constant in the database and in the end when we have all these conflicting mappings, we basically just take the maximal conflict.",
                    "label": 0
                },
                {
                    "sent": "Reset off of.",
                    "label": 0
                },
                {
                    "sent": "Mappings and use the health predicates in those two to generate head predicates that share the same functional symbols to generate the avox types from where we get the activators.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and lossed some results.",
                    "label": 0
                },
                {
                    "sent": "We have implemented this, let's say simple maybe approach, but it yielded quite good results.",
                    "label": 0
                },
                {
                    "sent": "We implemented it in the Clipper system and compared it with the base version.",
                    "label": 0
                },
                {
                    "sent": "We use the Oxford Ontology repository to test it.",
                    "label": 0
                },
                {
                    "sent": "After pre processing ontologies we saw that 221 where seen as relevant we got like.",
                    "label": 0
                },
                {
                    "sent": "37% increase in the number of the.",
                    "label": 0
                },
                {
                    "sent": "Ontologist that we could saturate basically with the optimized version versus the 108 with the original one.",
                    "label": 0
                },
                {
                    "sent": "It goes without saying that in all cases where the unoptimized version succeeded, the optimized version also succeeded.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If one picks a closer look in the cases where both of the version succeeded, one can see, for example, in the graph above.",
                    "label": 0
                },
                {
                    "sent": "We have plotted the rate of the growth of the.",
                    "label": 0
                },
                {
                    "sent": "Saturated the box with respect to the original steel box and the red bars are the ones that represent the original original calculus or or the original Clipper.",
                    "label": 0
                },
                {
                    "sent": "And while the blue bars the optimized version, the blue bars are presented here are plotted on top of the red bars because we always get lower.",
                    "label": 0
                },
                {
                    "sent": "And if one looks at the graph, sees that most of the actions that are derived with the.",
                    "label": 0
                },
                {
                    "sent": "With the original calculus are actually redundant or not needed for for clearance and also in the run times.",
                    "label": 0
                },
                {
                    "sent": "The optimized version was nearly always faster.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the against instances, basically ontologies in which only the optimized version succeeded while the.",
                    "label": 0
                },
                {
                    "sent": "Oh the original 1 failed.",
                    "label": 0
                },
                {
                    "sent": "We notice that the rate of growth was in the same range, basically like the other cases.",
                    "label": 0
                },
                {
                    "sent": "Also, we got good times running times for these cases.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the end we also analyzed activators that we can get from obvious specifications because the instances that we tested on we had to get the activators directly from mailboxes because it's very hard to come across.",
                    "label": 0
                },
                {
                    "sent": "Many of the benchmarks that have mappings and ontology that is expressed in homeshake.",
                    "label": 0
                },
                {
                    "sent": "Actually that there are now.",
                    "label": 0
                },
                {
                    "sent": "So we are analyzed, three of them with our approach that we described in detail in the paper and what we notice is that the number of activators and their size was in the moderately in the same range as the ones we got directly from the 8 boxes of.",
                    "label": 1
                },
                {
                    "sent": "From testing them against Oxford Ontology repository.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in the end we.",
                    "label": 0
                },
                {
                    "sent": "We can claim that this structure based approach for optimizing the reason is promising.",
                    "label": 1
                },
                {
                    "sent": "We obtained encouraging results.",
                    "label": 0
                },
                {
                    "sent": "Moreover, one can audit the activators that one gets and by auditing the ontology engineer can see that this activator can be broken up because these two concepts do not go together, in which case this can improve the performance even further.",
                    "label": 0
                },
                {
                    "sent": "Moreover, the our approach is incremental.",
                    "label": 0
                },
                {
                    "sent": "You can compute incrementally for future.",
                    "label": 0
                },
                {
                    "sent": "We seek to develop more fine grained algorithms for obtaining the activators and also to try and validate this approach against more benchmarks.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "OK so I had one question that matter.",
                    "label": 0
                },
                {
                    "sent": "One question, yeah, so some of the results in your optimization.",
                    "label": 0
                },
                {
                    "sent": "This one that has a few sort of standouts.",
                    "label": 0
                },
                {
                    "sent": "For example, about 85 if you have 85 instances, the Seahawks seems to be performing worse.",
                    "label": 0
                },
                {
                    "sent": "Did you look into the cost for that one?",
                    "label": 0
                },
                {
                    "sent": "I mean the the causes because sometimes we have to extract the activators and sometimes this doesn't pay off.",
                    "label": 0
                },
                {
                    "sent": "But this doesn't mean that it performs way worse, because this is in a matter of runtime seconds and the.",
                    "label": 0
                },
                {
                    "sent": "Procedure of extracting the activity is not very well engineered to be honest.",
                    "label": 0
                },
                {
                    "sent": "So that's why it's just we we pay this cost and sometimes it doesn't pay off, but for a more larger ontologies this always and I didn't have the.",
                    "label": 0
                },
                {
                    "sent": "I thought that I will be much slower, but we also looked at the distribution of the ontologies and we have like 25% of the cases where very large ontologies that had over 10,000 axioms and also very large array boxes and.",
                    "label": 0
                },
                {
                    "sent": "It worked well, but this is the reason, OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you speaker again.",
                    "label": 0
                },
                {
                    "sent": "Last speaker.",
                    "label": 0
                },
                {
                    "sent": "Unless if OK, OK, thank you, OK.",
                    "label": 1
                }
            ]
        }
    }
}