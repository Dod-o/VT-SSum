{
    "id": "pe5fmqm7zldq7rtcmy4uj2jxbw35co2c",
    "title": "Multiclass Learnability and the ERM principle",
    "info": {
        "author": [
            "Amit Daniely, Einstein Institute of Mathematics, The Hebrew University of Jerusalem"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Multi-Task Learning"
        ]
    },
    "url": "http://videolectures.net/colt2011_daniely_principle/",
    "segmentation": [
        [
            "Fever joint work with Stefan Salvatore Simon to Vaiden Scholz.",
            "And the main purpose of this work was to study the sample complexity of multiclass learnability and that is the task of classification into few classes.",
            "And before we go to.",
            "What exactly ability?"
        ],
        [
            "Let us quickly recall the fundamental theorem of binary classification.",
            "Where did the fundamental theorem say that uniform convergence is equivalent to the fact that we are in walks which in turn equivalent to learnability?"
        ],
        [
            "And it is natural to ask whether we still have generalized to the multiclass setting and our maybe surprising answer that it is not, at least not in the quantity."
        ],
        [
            "And the question how to run properly in this setting remains open.",
            "A OK so to be."
        ],
        [
            "Even more concrete, let us quickly define their formal setting.",
            "X is the set of instances, while the set of labels H is the set of iPod."
        ],
        [
            "This.",
            "Given distribution D over 8th cross, why we define the error of the hypothesis edge to be the probability that age of X is not equal to?"
        ],
        [
            "Wife.",
            "Given a sample S, we defined the empirical error of the hypothesis H with respect to the sample S to be the average number of errors.",
            "A."
        ],
        [
            "Buy a pack algorithm.",
            "We mean an algorithm that receives Apple and return, and I parted this Saturday at upon seeing enough samples to tool and I got this with a small error."
        ],
        [
            "And by any armor item, we mean an algorithm that always tune, and I put this with minimal empirical error."
        ],
        [
            "And for simplicity we will soon to have the lecture.",
            "The realisable case that is there is an iPod.",
            "This HH star in edge with error zero."
        ],
        [
            "OK, so as we said before, the fundamental theorem says that uniform convergence equivalent to the fact that you are works, which in turn equivalent."
        ],
        [
            "To learn ability and the equivalence is not only qualitative, but also quantitative.",
            "That is the rate of convergence.",
            "I'll say the same up to Logan factors."
        ],
        [
            "Well by and you see a we mean the number of examples needed for uniform."
        ],
        [
            "Illness.",
            "Buy me RM is we mean the number of examples needed for the."
        ],
        [
            "Most of examples needed for the best.",
            "Barker with Mtoto an imported this with smaller."
        ],
        [
            "And as we said before, our main measures is that the fundamental theorem is no longer true in the multiclass entity."
        ],
        [
            "And a we will show that by showing that there might be a large gap between different air."
        ],
        [
            "Next so here's the outline."
        ],
        [
            "Of the talk."
        ],
        [
            "We will start with this counterexample, showing that there might be a large gap in the sample complexity between differently arms.",
            "From the example, we will conclude the principle how to design a good learning algorithm and we will see an application of this principle too.",
            "A characterized sample complexity of multiclassing ability, and, in the last part of the talk we will see how this theory is applicable in analyzing learning."
        ],
        [
            "So let's start with the counterexample X.",
            "The set of instances is an arbitrary set Huawei.",
            "The set of labels is defined to be all the subsets of X, and a special special element which we did not buy sell."
        ],
        [
            "And the third part of this is composed of the following functions for every subset T of X we define HD of X to be star.",
            "If X is not in T and to be the set, which is also a label T if X is in T. And the crucial property of.",
            "And if I put this class, is that if a learning algorithm sees a label, the label T, He knows that the hypothesis is trying to learn is H of T, so the hypothesis reveals itself.",
            "OK."
        ],
        [
            "So we will."
        ],
        [
            "Two, yeah, I'ma go within 4H.",
            "The first a good will have a good sample complexity of one over epsilon times long one over Delta and the 2nd a bug will have bad sample complexity of Omega of the cardinality of X over epsilon times land one over there."
        ],
        [
            "And we conclude the direction between the sample complexity of different theorems might be as large as the cardinality of it."
        ],
        [
            "Which equals two log of the number of labels and if X is an infinite set, then the problem is learnable by algorithm.",
            "A good but not by every RN, since for a bad the sample complexity is Infinity.",
            "So it's not able to buy some DRM, but not by every airline."
        ],
        [
            "OK, so let's start with the.",
            "Technical data and our first question we will handle is how does any RM4H looks like.",
            "So let a be."
        ],
        [
            "The 4H and let F be a sample."
        ],
        [
            "If HD of X = T, as we said before, a a no that they land opposes H of T and we will return the hypothesis H of T as every RAM."
        ],
        [
            "So A is completed data mined approved by part of this.",
            "IT returns on samples of the form as equals 6 one start to exit some."
        ],
        [
            "And let's start with going down for the good of written.",
            "We define a good of excellent style tweaks and start to build hypothesis corresponding to the empty set, which is the hypothesis that.",
            "Return style for every insta."
        ],
        [
            "And we claim that the sample complexity of a good is less than one over epsilon times line one over Delta.",
            "And let's see."
        ],
        [
            "Both let us be a sample.",
            "We assume that the distribution over X is arbitrary and the correct labeling is HT."
        ],
        [
            "If HX equals T, as we said before."
        ],
        [
            "Very good with that and I put this age of tea and Arrow will Brazil.",
            "Otherwise, hey, we returned.",
            "I positive H of the empty set.",
            "Its error is the probability of tea with respect to distribution from which the sample is generated.",
            "So a good will fail only if age of XI equals style.",
            "For every I and the probability of tea is great."
        ],
        [
            "Epsilon and the last event happens with probability less than Delta.",
            "For N greater than one of epsilon times long, one over Delta, and if.",
            "Concludes the proof of this plan."
        ],
        [
            "And we are not ready for the battle rhythm for the battle right now we define a bag of X1 style tweaks and style to be hypothesis corresponding to the complement of X1 to XN."
        ],
        [
            "And we claim that the sample complexity of a bad is Omega off the cardinality of X over epsilon times LAN one over Delta."
        ],
        [
            "And let's see if proof of this claim.",
            "So suppose that the Cork labeling is age of the empty set and distribution is uniform."
        ],
        [
            "Let let S be a sample and not that.",
            "Samples that generated if age of the empty set is the correct labeling will necessary looks like this.",
            "A."
        ],
        [
            "Hey Bud will not part of this age of the complement of X1 to XN by this definition, and this hypothesis is erroneous for every X that is not in the sample."
        ],
        [
            "So to donate and hypothesis with error less than epsilon, the sample must contain one epsilon fraction of X."
        ],
        [
            "Then by standard argument this happened with probability greater than one minus Delta.",
            "Only if an is Omega off the commonality of X over excellent I'm slang, one over Delta and this concludes the proof of the claim.",
            "An counter exam."
        ],
        [
            "Well.",
            "So we have proved that this equivalence no longer holds in the multiclass setting, at least in the quantitative test.",
            "And by the way, this equivalence we show in the paper that still holds."
        ],
        [
            "OK, so within two algorithm 4, the Class H, the first with good sample complexity and the second with but sample complexity.",
            "And it is natural to ask what makes a good good.",
            "So suppose that the correct labeling is age of T."
        ],
        [
            "For any sample.",
            "A good might return one of two hypothesis, namely age of tea or age of the empty set."
        ],
        [
            "However, a bad might own money, money, hypothesis for every sample X one start we can start, it will return a different IP."
        ],
        [
            "For this so to turn a good part of this, a bad master math must reject many, many more hypothesis than a good."
        ],
        [
            "And we conclude the following principle.",
            "For designing a goody alarm and the police, the principle says that a good ERM is an ERM that for every target hypothesis, consider a small number of hypothesis."
        ],
        [
            "And to be more concrete, suppose that the correct labeling is H star and define S of H dollar to be all the samples that are consistent with H."
        ],
        [
            "Wow.",
            "And not by a of F of reached out all the hypothesis that a might return upon a sample that is consistent with a A."
        ],
        [
            "Page down.",
            "And a good time is in your arm.",
            "This set is small."
        ],
        [
            "And in our example for a buddy set was of commonality two in the power of the commonality of X.",
            "And for a good it was of cardinality at most 2."
        ],
        [
            "OK, so in the next part of the talk we will."
        ],
        [
            "A cock try to characterize the sample complexity of multiclass learning.",
            "And we have seen that the rate of the uniform convergence is not the sample complexity, and so this question is remains open."
        ],
        [
            "And before we will say few words about it, we will recall a theorem about the sample complexity of an arbitrary LM.",
            "This theorem uses the notion of collagen dimension, which is a generalization of the known VC dimension to multiclass hypothesis classes.",
            "And we won."
        ],
        [
            "Define it now.",
            "And the theorem proved by in Attala Johnny in the 80s, later sharpened by Ben David and we also made slight sharpening.",
            "Claim that if Edge is an important class of intelligent dimension, D&A is an arbitrary.",
            "Here I'm algorithm.",
            "Then with sample complexity is bounded by these quantities."
        ],
        [
            "And we think that the land of the cardinality of why factor is necessary for an arbitrary LM."
        ],
        [
            "But what about specific yarn?",
            "So here we are."
        ],
        [
            "How a partial result fall semester classes where asymmetric class is the class that is invariant under changing the name of the labels?",
            "And here we should note that most of the popular classes are indeed asymmetric and Moreover.",
            "If we don't have prior knowledge about the classes, it is the most natural thing to use symmetric ladders."
        ],
        [
            "And using the principle we have shown before.",
            "We can prove that for every symmetric class of 1000 dimension D There is specific DRM a whose sample complexity bounded by these quantities."
        ],
        [
            "And we conjecture that the above theorem is true for every class is not necessary symmetric."
        ],
        [
            "OK, so in that part of the talk we will show how this story can be applied to analyze a learning algorithm."
        ],
        [
            "And specifically we will show calculation of the soccer complexity of the sample complexity of popular hypothesis classes, and in particular we will concentrate on multiclass to binary reductions."
        ],
        [
            "And disables compression between different landing."
        ],
        [
            "Methods and while privates analyzes calculated multiclass L in terms of the."
        ],
        [
            "Finally, all our method calculates the multiclass LD."
        ],
        [
            "Rectally.",
            "So in the paper we analyze few popular multiclass to binary reduction among them one versus rest linear multiclass construction."
        ],
        [
            "Liquid and we use linear predictors in our end has been over classifiers."
        ],
        [
            "And we prove that the Italian dimension of all of the above classes of all their D times the cardinality of Y."
        ],
        [
            "And we conclude that since the all this reduction has the same estimation, able to choose the right hypothesis class, one should analyze the approximation error."
        ],
        [
            "So we left it open question the first.",
            "Maybe the most important question is to prove the conjecture reset it before.",
            "What is the sample complexity of multiclass learning from symmetric?"
        ],
        [
            "Other.",
            "And the corresponding question, what is the corresponding general 11 principle?"
        ],
        [
            "And here we should note that in order to prove this conjecture, one has to develop new methods and it can't only.",
            "Rely on uniform convergence without.",
            "Since we have shown that it won't work.",
            "And in fact we we answer this question in the online learning model and even in the bandit setting.",
            "But these questions remain open in the backside in the park setting."
        ],
        [
            "We said yet in the budget setting, we still don't know the price of bandit information.",
            "That is, we have a combinatorial.",
            "A measure that measures the sample complexity in the full information setting, and another combinatorial measure that measure the sample capacity in a.",
            "In the band setting, but we don't know how loud the ratio might be.",
            "Anne and."
        ],
        [
            "That's it.",
            "Questions.",
            "So where can you extend your results to the agnostic setting as well when there is no single hypothesis which is always correct?",
            "Eh, we don't know.",
            "How to do that?",
            "We don't have an example there.",
            "Of darkness in diagnostic setting.",
            "So.",
            "Have a question.",
            "Seems like one important class of situations where you don't have symmetric classes, structured prediction or the labels labels.",
            "It is essentially a sequence of labels.",
            "Do you know if?",
            "But do you know if you can get a gap in that situation?",
            "In asymmetric classes.",
            "So the so the classes are not symmetric.",
            "You have a set of labels are sequences of labels essentially in a structured prediction setting.",
            "You ask if I have an example we can gap in symmetric.",
            "Let us know whether there can be a gap in structured prediction.",
            "Whether there can be a gap between the rim and learnability in structured prediction?",
            "Shut up.",
            "So when you said that there is a specific ERM that gets a good rate, is the proof constructive?",
            "Does it tell you what the specific error yes or yes?",
            "The proof is constructive.",
            "Is there any intuition about the idea of the proof is true and hypothesis with a small range that obtain a list possible labels as possible?",
            "Example that you gave that shows you know the fundamental theorem doesn't work in the multiclass case.",
            "If I understand it correctly, you're.",
            "Predict the output space is very large.",
            "You have a finite input space and then the cardinality of the output space is exponential in that is it necessary.",
            "So how small can you make the size of the prediction space?",
            "We can have an example when it is infinite and this phenomenon calls.",
            "Thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fever joint work with Stefan Salvatore Simon to Vaiden Scholz.",
                    "label": 0
                },
                {
                    "sent": "And the main purpose of this work was to study the sample complexity of multiclass learnability and that is the task of classification into few classes.",
                    "label": 1
                },
                {
                    "sent": "And before we go to.",
                    "label": 0
                },
                {
                    "sent": "What exactly ability?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let us quickly recall the fundamental theorem of binary classification.",
                    "label": 0
                },
                {
                    "sent": "Where did the fundamental theorem say that uniform convergence is equivalent to the fact that we are in walks which in turn equivalent to learnability?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it is natural to ask whether we still have generalized to the multiclass setting and our maybe surprising answer that it is not, at least not in the quantity.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the question how to run properly in this setting remains open.",
                    "label": 0
                },
                {
                    "sent": "A OK so to be.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even more concrete, let us quickly define their formal setting.",
                    "label": 0
                },
                {
                    "sent": "X is the set of instances, while the set of labels H is the set of iPod.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Given distribution D over 8th cross, why we define the error of the hypothesis edge to be the probability that age of X is not equal to?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wife.",
                    "label": 0
                },
                {
                    "sent": "Given a sample S, we defined the empirical error of the hypothesis H with respect to the sample S to be the average number of errors.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Buy a pack algorithm.",
                    "label": 0
                },
                {
                    "sent": "We mean an algorithm that receives Apple and return, and I parted this Saturday at upon seeing enough samples to tool and I got this with a small error.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And by any armor item, we mean an algorithm that always tune, and I put this with minimal empirical error.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for simplicity we will soon to have the lecture.",
                    "label": 0
                },
                {
                    "sent": "The realisable case that is there is an iPod.",
                    "label": 0
                },
                {
                    "sent": "This HH star in edge with error zero.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so as we said before, the fundamental theorem says that uniform convergence equivalent to the fact that you are works, which in turn equivalent.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To learn ability and the equivalence is not only qualitative, but also quantitative.",
                    "label": 0
                },
                {
                    "sent": "That is the rate of convergence.",
                    "label": 0
                },
                {
                    "sent": "I'll say the same up to Logan factors.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well by and you see a we mean the number of examples needed for uniform.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Illness.",
                    "label": 0
                },
                {
                    "sent": "Buy me RM is we mean the number of examples needed for the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most of examples needed for the best.",
                    "label": 0
                },
                {
                    "sent": "Barker with Mtoto an imported this with smaller.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as we said before, our main measures is that the fundamental theorem is no longer true in the multiclass entity.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a we will show that by showing that there might be a large gap between different air.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next so here's the outline.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the talk.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We will start with this counterexample, showing that there might be a large gap in the sample complexity between differently arms.",
                    "label": 0
                },
                {
                    "sent": "From the example, we will conclude the principle how to design a good learning algorithm and we will see an application of this principle too.",
                    "label": 0
                },
                {
                    "sent": "A characterized sample complexity of multiclassing ability, and, in the last part of the talk we will see how this theory is applicable in analyzing learning.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start with the counterexample X.",
                    "label": 0
                },
                {
                    "sent": "The set of instances is an arbitrary set Huawei.",
                    "label": 0
                },
                {
                    "sent": "The set of labels is defined to be all the subsets of X, and a special special element which we did not buy sell.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the third part of this is composed of the following functions for every subset T of X we define HD of X to be star.",
                    "label": 0
                },
                {
                    "sent": "If X is not in T and to be the set, which is also a label T if X is in T. And the crucial property of.",
                    "label": 0
                },
                {
                    "sent": "And if I put this class, is that if a learning algorithm sees a label, the label T, He knows that the hypothesis is trying to learn is H of T, so the hypothesis reveals itself.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we will.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two, yeah, I'ma go within 4H.",
                    "label": 0
                },
                {
                    "sent": "The first a good will have a good sample complexity of one over epsilon times long one over Delta and the 2nd a bug will have bad sample complexity of Omega of the cardinality of X over epsilon times land one over there.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we conclude the direction between the sample complexity of different theorems might be as large as the cardinality of it.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which equals two log of the number of labels and if X is an infinite set, then the problem is learnable by algorithm.",
                    "label": 1
                },
                {
                    "sent": "A good but not by every RN, since for a bad the sample complexity is Infinity.",
                    "label": 0
                },
                {
                    "sent": "So it's not able to buy some DRM, but not by every airline.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with the.",
                    "label": 0
                },
                {
                    "sent": "Technical data and our first question we will handle is how does any RM4H looks like.",
                    "label": 0
                },
                {
                    "sent": "So let a be.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The 4H and let F be a sample.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If HD of X = T, as we said before, a a no that they land opposes H of T and we will return the hypothesis H of T as every RAM.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So A is completed data mined approved by part of this.",
                    "label": 0
                },
                {
                    "sent": "IT returns on samples of the form as equals 6 one start to exit some.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let's start with going down for the good of written.",
                    "label": 1
                },
                {
                    "sent": "We define a good of excellent style tweaks and start to build hypothesis corresponding to the empty set, which is the hypothesis that.",
                    "label": 0
                },
                {
                    "sent": "Return style for every insta.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we claim that the sample complexity of a good is less than one over epsilon times line one over Delta.",
                    "label": 0
                },
                {
                    "sent": "And let's see.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Both let us be a sample.",
                    "label": 0
                },
                {
                    "sent": "We assume that the distribution over X is arbitrary and the correct labeling is HT.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If HX equals T, as we said before.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very good with that and I put this age of tea and Arrow will Brazil.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, hey, we returned.",
                    "label": 0
                },
                {
                    "sent": "I positive H of the empty set.",
                    "label": 0
                },
                {
                    "sent": "Its error is the probability of tea with respect to distribution from which the sample is generated.",
                    "label": 0
                },
                {
                    "sent": "So a good will fail only if age of XI equals style.",
                    "label": 1
                },
                {
                    "sent": "For every I and the probability of tea is great.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Epsilon and the last event happens with probability less than Delta.",
                    "label": 0
                },
                {
                    "sent": "For N greater than one of epsilon times long, one over Delta, and if.",
                    "label": 0
                },
                {
                    "sent": "Concludes the proof of this plan.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we are not ready for the battle rhythm for the battle right now we define a bag of X1 style tweaks and style to be hypothesis corresponding to the complement of X1 to XN.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we claim that the sample complexity of a bad is Omega off the cardinality of X over epsilon times LAN one over Delta.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let's see if proof of this claim.",
                    "label": 0
                },
                {
                    "sent": "So suppose that the Cork labeling is age of the empty set and distribution is uniform.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let let S be a sample and not that.",
                    "label": 0
                },
                {
                    "sent": "Samples that generated if age of the empty set is the correct labeling will necessary looks like this.",
                    "label": 1
                },
                {
                    "sent": "A.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey Bud will not part of this age of the complement of X1 to XN by this definition, and this hypothesis is erroneous for every X that is not in the sample.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to donate and hypothesis with error less than epsilon, the sample must contain one epsilon fraction of X.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then by standard argument this happened with probability greater than one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "Only if an is Omega off the commonality of X over excellent I'm slang, one over Delta and this concludes the proof of the claim.",
                    "label": 0
                },
                {
                    "sent": "An counter exam.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So we have proved that this equivalence no longer holds in the multiclass setting, at least in the quantitative test.",
                    "label": 0
                },
                {
                    "sent": "And by the way, this equivalence we show in the paper that still holds.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so within two algorithm 4, the Class H, the first with good sample complexity and the second with but sample complexity.",
                    "label": 1
                },
                {
                    "sent": "And it is natural to ask what makes a good good.",
                    "label": 0
                },
                {
                    "sent": "So suppose that the correct labeling is age of T.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For any sample.",
                    "label": 0
                },
                {
                    "sent": "A good might return one of two hypothesis, namely age of tea or age of the empty set.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, a bad might own money, money, hypothesis for every sample X one start we can start, it will return a different IP.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this so to turn a good part of this, a bad master math must reject many, many more hypothesis than a good.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we conclude the following principle.",
                    "label": 0
                },
                {
                    "sent": "For designing a goody alarm and the police, the principle says that a good ERM is an ERM that for every target hypothesis, consider a small number of hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to be more concrete, suppose that the correct labeling is H star and define S of H dollar to be all the samples that are consistent with H.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wow.",
                    "label": 0
                },
                {
                    "sent": "And not by a of F of reached out all the hypothesis that a might return upon a sample that is consistent with a A.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Page down.",
                    "label": 0
                },
                {
                    "sent": "And a good time is in your arm.",
                    "label": 0
                },
                {
                    "sent": "This set is small.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in our example for a buddy set was of commonality two in the power of the commonality of X.",
                    "label": 0
                },
                {
                    "sent": "And for a good it was of cardinality at most 2.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in the next part of the talk we will.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A cock try to characterize the sample complexity of multiclass learning.",
                    "label": 0
                },
                {
                    "sent": "And we have seen that the rate of the uniform convergence is not the sample complexity, and so this question is remains open.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And before we will say few words about it, we will recall a theorem about the sample complexity of an arbitrary LM.",
                    "label": 1
                },
                {
                    "sent": "This theorem uses the notion of collagen dimension, which is a generalization of the known VC dimension to multiclass hypothesis classes.",
                    "label": 1
                },
                {
                    "sent": "And we won.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Define it now.",
                    "label": 0
                },
                {
                    "sent": "And the theorem proved by in Attala Johnny in the 80s, later sharpened by Ben David and we also made slight sharpening.",
                    "label": 0
                },
                {
                    "sent": "Claim that if Edge is an important class of intelligent dimension, D&A is an arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Here I'm algorithm.",
                    "label": 0
                },
                {
                    "sent": "Then with sample complexity is bounded by these quantities.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we think that the land of the cardinality of why factor is necessary for an arbitrary LM.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what about specific yarn?",
                    "label": 0
                },
                {
                    "sent": "So here we are.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How a partial result fall semester classes where asymmetric class is the class that is invariant under changing the name of the labels?",
                    "label": 0
                },
                {
                    "sent": "And here we should note that most of the popular classes are indeed asymmetric and Moreover.",
                    "label": 0
                },
                {
                    "sent": "If we don't have prior knowledge about the classes, it is the most natural thing to use symmetric ladders.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And using the principle we have shown before.",
                    "label": 0
                },
                {
                    "sent": "We can prove that for every symmetric class of 1000 dimension D There is specific DRM a whose sample complexity bounded by these quantities.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we conjecture that the above theorem is true for every class is not necessary symmetric.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in that part of the talk we will show how this story can be applied to analyze a learning algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And specifically we will show calculation of the soccer complexity of the sample complexity of popular hypothesis classes, and in particular we will concentrate on multiclass to binary reductions.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And disables compression between different landing.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods and while privates analyzes calculated multiclass L in terms of the.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, all our method calculates the multiclass LD.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rectally.",
                    "label": 0
                },
                {
                    "sent": "So in the paper we analyze few popular multiclass to binary reduction among them one versus rest linear multiclass construction.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Liquid and we use linear predictors in our end has been over classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we prove that the Italian dimension of all of the above classes of all their D times the cardinality of Y.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we conclude that since the all this reduction has the same estimation, able to choose the right hypothesis class, one should analyze the approximation error.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we left it open question the first.",
                    "label": 0
                },
                {
                    "sent": "Maybe the most important question is to prove the conjecture reset it before.",
                    "label": 0
                },
                {
                    "sent": "What is the sample complexity of multiclass learning from symmetric?",
                    "label": 1
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other.",
                    "label": 0
                },
                {
                    "sent": "And the corresponding question, what is the corresponding general 11 principle?",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we should note that in order to prove this conjecture, one has to develop new methods and it can't only.",
                    "label": 0
                },
                {
                    "sent": "Rely on uniform convergence without.",
                    "label": 0
                },
                {
                    "sent": "Since we have shown that it won't work.",
                    "label": 0
                },
                {
                    "sent": "And in fact we we answer this question in the online learning model and even in the bandit setting.",
                    "label": 1
                },
                {
                    "sent": "But these questions remain open in the backside in the park setting.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We said yet in the budget setting, we still don't know the price of bandit information.",
                    "label": 1
                },
                {
                    "sent": "That is, we have a combinatorial.",
                    "label": 1
                },
                {
                    "sent": "A measure that measures the sample complexity in the full information setting, and another combinatorial measure that measure the sample capacity in a.",
                    "label": 0
                },
                {
                    "sent": "In the band setting, but we don't know how loud the ratio might be.",
                    "label": 0
                },
                {
                    "sent": "Anne and.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "So where can you extend your results to the agnostic setting as well when there is no single hypothesis which is always correct?",
                    "label": 0
                },
                {
                    "sent": "Eh, we don't know.",
                    "label": 0
                },
                {
                    "sent": "How to do that?",
                    "label": 0
                },
                {
                    "sent": "We don't have an example there.",
                    "label": 0
                },
                {
                    "sent": "Of darkness in diagnostic setting.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Have a question.",
                    "label": 0
                },
                {
                    "sent": "Seems like one important class of situations where you don't have symmetric classes, structured prediction or the labels labels.",
                    "label": 0
                },
                {
                    "sent": "It is essentially a sequence of labels.",
                    "label": 0
                },
                {
                    "sent": "Do you know if?",
                    "label": 0
                },
                {
                    "sent": "But do you know if you can get a gap in that situation?",
                    "label": 0
                },
                {
                    "sent": "In asymmetric classes.",
                    "label": 0
                },
                {
                    "sent": "So the so the classes are not symmetric.",
                    "label": 0
                },
                {
                    "sent": "You have a set of labels are sequences of labels essentially in a structured prediction setting.",
                    "label": 0
                },
                {
                    "sent": "You ask if I have an example we can gap in symmetric.",
                    "label": 0
                },
                {
                    "sent": "Let us know whether there can be a gap in structured prediction.",
                    "label": 0
                },
                {
                    "sent": "Whether there can be a gap between the rim and learnability in structured prediction?",
                    "label": 0
                },
                {
                    "sent": "Shut up.",
                    "label": 0
                },
                {
                    "sent": "So when you said that there is a specific ERM that gets a good rate, is the proof constructive?",
                    "label": 0
                },
                {
                    "sent": "Does it tell you what the specific error yes or yes?",
                    "label": 0
                },
                {
                    "sent": "The proof is constructive.",
                    "label": 0
                },
                {
                    "sent": "Is there any intuition about the idea of the proof is true and hypothesis with a small range that obtain a list possible labels as possible?",
                    "label": 0
                },
                {
                    "sent": "Example that you gave that shows you know the fundamental theorem doesn't work in the multiclass case.",
                    "label": 0
                },
                {
                    "sent": "If I understand it correctly, you're.",
                    "label": 0
                },
                {
                    "sent": "Predict the output space is very large.",
                    "label": 0
                },
                {
                    "sent": "You have a finite input space and then the cardinality of the output space is exponential in that is it necessary.",
                    "label": 0
                },
                {
                    "sent": "So how small can you make the size of the prediction space?",
                    "label": 0
                },
                {
                    "sent": "We can have an example when it is infinite and this phenomenon calls.",
                    "label": 0
                },
                {
                    "sent": "Thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}