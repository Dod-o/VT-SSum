{
    "id": "nq6p5j747n46vnxe2undiscpt2xxvar4",
    "title": "Play with Me \u2013 Measuring a Child\u2019s Engagement in a Social Interaction",
    "info": {
        "author": [
            "Shyam Sundar Rajagopalan, Faculty of Education, Science, Technology and Mathematics (ESTEM), University of Canberra"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_rajagopalan_social_interaction/",
    "segmentation": [
        [
            "Good morning everyone and thanks for joining me for this session.",
            "I'm Sham, Sunder, Rajagopal and your PhD student at the University of Canberra in Australia, so today I'll be talking about predicting the child's engagement level in social interaction and these are joint work with Ramana Roland and data from Georgia Tech."
        ],
        [
            "So we heard a lot about that.",
            "Lots of context and how it plays in understanding the behavior.",
            "The more in the keynote, and definitely well if we want to try to model the human behaviors.",
            "It's one of the important aspects that needs to be considered.",
            "One of the important challenges, especially when it comes to Parramatta Rising and modeling date and when it comes to the social interactions, then it is also important to understand from the various multimodal signals that dynamics that goes in the interaction.",
            "For example, a person when two people are the responses based on the air particular persons response.",
            "It has to be factored in and more so if the social interactions are more free flowing or more semi structured then extracting some of the high level features like IT process will be more challenging.",
            "These are all some of the challenges that we need to factor in while trying to develop a model and once we do."
        ],
        [
            "So that there are truth or of applications that are possible with the with the system ranging from who are human computer interaction to a learning to surveillance ports and the one that I will be focusing more on his mental health diagnosis and more specifically on autism spectrum disorders.",
            "So a quick brief on."
        ],
        [
            "Rasd, so it's all out.",
            "It is a complex neurodevelopmental disorder affecting children at their infancy, leading to deficits in social communication and cognitive abilities.",
            "Unfortunately, it's growing faster and it's one in 88.",
            "The current survey says that it's 188 children are affected with this or ASD and there is no known treatment per say available as we speak.",
            "However, the early intervention will help you mitigate some of the abnormalities.",
            "Going forward and their diagnosis is purely based on studying the behavior.",
            "Specialist will work with the child on multiple sessions over weeks, over weeks or over months.",
            "To understand the behavior and due to this process, typically it takes more than 20, four months or 18 to 24 months to do their diagnosis."
        ],
        [
            "Even though it takes time to do their diagnosis, the red signal start to appear as early as 14 months.",
            "Here are some other signals that is start to emerge by 14 months, and some of them are low social responsiveness and reciprocity, and the one that I will be focusing on today to talk about the computational modeling is on joint attention cues."
        ],
        [
            "So we."
        ],
        [
            "Looked into the development psychology literature to understand more about the joint attention and what I personally learned is that joint attention is not just about two people looking at a particular object or it's just not about two people alternating the gaze of a particular object.",
            "It's much more than that is what we learned from those studies, and it's actually used to encompass the behaviors the end children used to actively coordinate their attention and interest.",
            "In shared objects and events with the other person with the social partners, and broadly, we can categorize that as initiating joint joint attention and responding to the joint attention.",
            "The example that you see at the top is an example where in the child alternate their gaze at the same time it tries to draw the attention of the other social partner by initiating a gesture.",
            "So it's an example of initiating of joint attention and the one below is an example of responding to the joint attention."
        ],
        [
            "The field also distinguishes between joint attention and joint engagement, though they are very closely are related when joint attention happens over extended period of time, we can deduce that there is an engagement level in a scene or in a situation.",
            "So again coming back, my focus is on developing computational models of engagement, which will in turn result in trying to understand the joint attention behaviors which directly correlates to providing some quantifiable metrics for diagnosing.",
            "Rasd, so that's the focus of my work."
        ],
        [
            "So just a quick background on the work that has been done on engagement.",
            "There's been quite a lot of studies on about studying the engagement in the human robot interaction scenarios.",
            "When we looked at that, the primary goal there is for the Robo right to follow the direction of the humans action.",
            "Like the human turns and looks into the object you expect the robot to follow that.",
            "So lot of studies are done along these days.",
            "So how do we direct the robo to become more engaging with the user so that?",
            "Users have a better experience, so lot of studies around that happened and predominantly hidden hand forces have been used there and more recently studies start to emerge on adult child interactions and wherein again this kind of the setup would be like there are a chyanne examiner or caregiver will be interacting with a child or a particular play protocol exhibiting certain protocol, and in that particular situation and try to understand that so engagement levels.",
            "So the studies is beginning to happen actually.",
            "On this area and again some other feature perspectives, it's very interesting to note that even though the studies are beginning to emerge pretty much all the different modalities have started being applied to develop the interaction.",
            "The engagement model ranging from object trajectories to body gestures, and even the ADL signals and the other broad."
        ],
        [
            "Area where engagement level studies in season there were embodied conversational agents in that particular domain.",
            "Also, we wanted that virtual agent to be as engaging as possible with the human in order to have a better interactions.",
            "So there are lot of studies on that.",
            "So coming back to the our contribution in this paper is on two fold.",
            "One, we understand.",
            "We observe that there are complexities in extracting the high level features.",
            "So as a complementary in such situations.",
            "Can the low level features help in building a better computational model?",
            "That's the first English investigation, and then the.",
            "Secondly, we have employed our model using a hidden conditional random fields framework and then can we take advantage of some additional information provided from the learning of the hidden structures?",
            "Can we leverage that and then propose a two stage model so for better engagement prediction, so those are the two contributions of our work?",
            "So be."
        ],
        [
            "When I go into the details of the algorithms, I will quickly give you overview of a particular data set.",
            "Because this is predominantly we have used and this is a data set of an adult child interactions of around 160 sessions.",
            "This data set is released from Georgia Tech in 2012 and suffered as multimodal dyadic behavior datasets.",
            "So essentially in this data set there is a series of 160 sessions which are off duration three to five minutes, wherein yes specially trained person interacts with the child.",
            "To elicit their behaviors by exercising play protocol, which is a well defined protocol referred as a rapid ABC protocol.",
            "By using that they used to elicit their behaviors from the child.",
            "And there are different stages.",
            "For example, playing a ball, looking through the book and tickling games.",
            "Essentially, there are these five stages where they're trained.",
            "Specialist will exercise play activity with the child to elicit their behaviors, and at the end of it that specialist will help in annotating their overall engagement level offer.",
            "Child so we have used this particular data set to validate our approach."
        ],
        [
            "So obviously we started off with a higher level features.",
            "We wanted to use the head post features as that is one of the predominantly used or not very indicative feature for measuring the engagement and what we have found is that there are quite a bit of challenges especially in this semi structured interaction.",
            "We found that the child's behavior is completely uncontrolled, so there there's a different kind of situations wherein we are not able to detect the very reliable head process so that forces us to think about is there any other alternative of can we use the low level features which are?",
            "Fairly easy to obtain."
        ],
        [
            "So we made a certain we follow hypothesis wherein in such as in a situation where in, let's say in two partners are engaged in red dyadic interaction.",
            "Let's say if a child dominates in an interaction and if they will enter a dominant behavior in the video is predominantly due to the child, then can we leverage the motion information around the scene to build the model?",
            "So we wanted to validate that particular hypothesis.",
            "Another thing is, can we make use of the hidden finer substructures or final?",
            "Actions emanating from the behavior.",
            "Can we put that into that CRF model and will that help?",
            "So we wanted we carried out our model based on these two hypothesis."
        ],
        [
            "And when we tested it with when we did empirically, when we validated these two with the available ground truth, annotations from the MMD data set and manually guided a high level features.",
            "When I say manually guided, I refer to.",
            "In those situations where the head pose estimations was not detected, then we manually forced it to market and then we forced it to detect it.",
            "And when we compare this, we found that some of the even the low level features are equally contributing or equal close enough to the.",
            "Performance of engagement prediction.",
            "So this."
        ],
        [
            "So we built up build up on this and then we proposed two stage algorithm for determining the engagement level.",
            "So here is a very high level overview.",
            "Then I will get into the details in the first stage we learn the hidden substructures of the behavior and the input for this particular stage is a set of behavior words.",
            "I will talk about it next slide as to what these mean and the moment you pause in the behavior is what we get out of this stage.",
            "One are the hidden state probabilities of of the scene and these behavior.",
            "Words are used as a node.",
            "Observations in ahead CR of framework and in the second stage the hidden State probabilities that we obtained from the first stage are used as input, and then we use the VI SVM based classifier to predict the engagement.",
            "Now the two major aspects that we need to look into here on the first stage we need to understand how we compute the behavior words and in the second stage we need to understand how do we form the feature vector."
        ],
        [
            "So going back to computing behavior words the way we went about doing this is remember we have used the low level features, so we first detect the child's upper body region.",
            "We used a Calvin perverted detector and then we computed the histogram of optical flow around the upper body regions.",
            "Then we pick the for each and every frame we we picked the frame descriptor.",
            "We pick the frame descriptor based on the availability of hops in that particular frame.",
            "And we use them as the those and then once we have these frame descriptors for each and every frame, we obtain what are referred as the behavior words and that is a parametrizable variable and these each and every behavior word is used as an nodes in the HCR of linear chain."
        ],
        [
            "And on the second stage the at the end of the HCR of training what we get is the hidden straight probabilities of each, the every node and every hidden state belonging to every class.",
            "So we use that particular information and then we compute the marginal for each and every hidden straight across all the classes and then we fuse them together to form a feature vector.",
            "And this has indeed helped in improving the accuracy of the overall recognition engage."
        ],
        [
            "Prediction.",
            "So here is a quick summary of the results.",
            "There are.",
            "This is an example where in the engagement prediction accuracy based on the depending on the number of behavior words when leave and use, the HCR of model and when you augment that with a two stage approach and more.",
            "I can see that there is a improvement with the two stage model, except for those situations where we found that the number of hidden states that we can figure in the exterior of framework is optimal, because as we all know, one of the challenges with that CRF model is that how do we pick up the hidden states?",
            "What is the optimal number of hidden states, right?",
            "So in those situations where that is not optimal, two stage approach has indeed helped us to ensure."
        ],
        [
            "The generalization of this.",
            "We have also validated our approach on the JH MDB database, which is one of the action recognition datasets, and even we found the improvement with the 2nd two stage approach is so these two results are just an examples, but more results under different test configuration are reported in the paper.",
            "So in actual given that high level features are difficult to obtain, the low level features are a good substitute for an engagement prediction and two stage approach indeed.",
            "Results in providing additional complementary information."
        ],
        [
            "So we're all in summary, so if there is a dominant behavior from a child, then the motion cues can be leveraged to builder engagement model and the hidden's and the two stage approaches will be beneficial in those situations where the number of hidden states will not be optimal and what we want to do going forward is that we have features from different multimodal multi modalities.",
            "Can we instead of just doing a Fusion?",
            "Can we use them?",
            "Use the complementary information or even the.",
            "And and see information that is available in a multi view learning framework.",
            "And can we build a better model around it?",
            "So that's something that we want to investigate going forward.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning everyone and thanks for joining me for this session.",
                    "label": 0
                },
                {
                    "sent": "I'm Sham, Sunder, Rajagopal and your PhD student at the University of Canberra in Australia, so today I'll be talking about predicting the child's engagement level in social interaction and these are joint work with Ramana Roland and data from Georgia Tech.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we heard a lot about that.",
                    "label": 0
                },
                {
                    "sent": "Lots of context and how it plays in understanding the behavior.",
                    "label": 0
                },
                {
                    "sent": "The more in the keynote, and definitely well if we want to try to model the human behaviors.",
                    "label": 0
                },
                {
                    "sent": "It's one of the important aspects that needs to be considered.",
                    "label": 0
                },
                {
                    "sent": "One of the important challenges, especially when it comes to Parramatta Rising and modeling date and when it comes to the social interactions, then it is also important to understand from the various multimodal signals that dynamics that goes in the interaction.",
                    "label": 0
                },
                {
                    "sent": "For example, a person when two people are the responses based on the air particular persons response.",
                    "label": 0
                },
                {
                    "sent": "It has to be factored in and more so if the social interactions are more free flowing or more semi structured then extracting some of the high level features like IT process will be more challenging.",
                    "label": 0
                },
                {
                    "sent": "These are all some of the challenges that we need to factor in while trying to develop a model and once we do.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that there are truth or of applications that are possible with the with the system ranging from who are human computer interaction to a learning to surveillance ports and the one that I will be focusing more on his mental health diagnosis and more specifically on autism spectrum disorders.",
                    "label": 0
                },
                {
                    "sent": "So a quick brief on.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rasd, so it's all out.",
                    "label": 0
                },
                {
                    "sent": "It is a complex neurodevelopmental disorder affecting children at their infancy, leading to deficits in social communication and cognitive abilities.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately, it's growing faster and it's one in 88.",
                    "label": 1
                },
                {
                    "sent": "The current survey says that it's 188 children are affected with this or ASD and there is no known treatment per say available as we speak.",
                    "label": 0
                },
                {
                    "sent": "However, the early intervention will help you mitigate some of the abnormalities.",
                    "label": 0
                },
                {
                    "sent": "Going forward and their diagnosis is purely based on studying the behavior.",
                    "label": 0
                },
                {
                    "sent": "Specialist will work with the child on multiple sessions over weeks, over weeks or over months.",
                    "label": 0
                },
                {
                    "sent": "To understand the behavior and due to this process, typically it takes more than 20, four months or 18 to 24 months to do their diagnosis.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even though it takes time to do their diagnosis, the red signal start to appear as early as 14 months.",
                    "label": 0
                },
                {
                    "sent": "Here are some other signals that is start to emerge by 14 months, and some of them are low social responsiveness and reciprocity, and the one that I will be focusing on today to talk about the computational modeling is on joint attention cues.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Looked into the development psychology literature to understand more about the joint attention and what I personally learned is that joint attention is not just about two people looking at a particular object or it's just not about two people alternating the gaze of a particular object.",
                    "label": 0
                },
                {
                    "sent": "It's much more than that is what we learned from those studies, and it's actually used to encompass the behaviors the end children used to actively coordinate their attention and interest.",
                    "label": 1
                },
                {
                    "sent": "In shared objects and events with the other person with the social partners, and broadly, we can categorize that as initiating joint joint attention and responding to the joint attention.",
                    "label": 1
                },
                {
                    "sent": "The example that you see at the top is an example where in the child alternate their gaze at the same time it tries to draw the attention of the other social partner by initiating a gesture.",
                    "label": 0
                },
                {
                    "sent": "So it's an example of initiating of joint attention and the one below is an example of responding to the joint attention.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The field also distinguishes between joint attention and joint engagement, though they are very closely are related when joint attention happens over extended period of time, we can deduce that there is an engagement level in a scene or in a situation.",
                    "label": 1
                },
                {
                    "sent": "So again coming back, my focus is on developing computational models of engagement, which will in turn result in trying to understand the joint attention behaviors which directly correlates to providing some quantifiable metrics for diagnosing.",
                    "label": 1
                },
                {
                    "sent": "Rasd, so that's the focus of my work.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just a quick background on the work that has been done on engagement.",
                    "label": 0
                },
                {
                    "sent": "There's been quite a lot of studies on about studying the engagement in the human robot interaction scenarios.",
                    "label": 0
                },
                {
                    "sent": "When we looked at that, the primary goal there is for the Robo right to follow the direction of the humans action.",
                    "label": 0
                },
                {
                    "sent": "Like the human turns and looks into the object you expect the robot to follow that.",
                    "label": 0
                },
                {
                    "sent": "So lot of studies are done along these days.",
                    "label": 0
                },
                {
                    "sent": "So how do we direct the robo to become more engaging with the user so that?",
                    "label": 0
                },
                {
                    "sent": "Users have a better experience, so lot of studies around that happened and predominantly hidden hand forces have been used there and more recently studies start to emerge on adult child interactions and wherein again this kind of the setup would be like there are a chyanne examiner or caregiver will be interacting with a child or a particular play protocol exhibiting certain protocol, and in that particular situation and try to understand that so engagement levels.",
                    "label": 0
                },
                {
                    "sent": "So the studies is beginning to happen actually.",
                    "label": 0
                },
                {
                    "sent": "On this area and again some other feature perspectives, it's very interesting to note that even though the studies are beginning to emerge pretty much all the different modalities have started being applied to develop the interaction.",
                    "label": 0
                },
                {
                    "sent": "The engagement model ranging from object trajectories to body gestures, and even the ADL signals and the other broad.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Area where engagement level studies in season there were embodied conversational agents in that particular domain.",
                    "label": 0
                },
                {
                    "sent": "Also, we wanted that virtual agent to be as engaging as possible with the human in order to have a better interactions.",
                    "label": 0
                },
                {
                    "sent": "So there are lot of studies on that.",
                    "label": 0
                },
                {
                    "sent": "So coming back to the our contribution in this paper is on two fold.",
                    "label": 0
                },
                {
                    "sent": "One, we understand.",
                    "label": 0
                },
                {
                    "sent": "We observe that there are complexities in extracting the high level features.",
                    "label": 0
                },
                {
                    "sent": "So as a complementary in such situations.",
                    "label": 0
                },
                {
                    "sent": "Can the low level features help in building a better computational model?",
                    "label": 0
                },
                {
                    "sent": "That's the first English investigation, and then the.",
                    "label": 0
                },
                {
                    "sent": "Secondly, we have employed our model using a hidden conditional random fields framework and then can we take advantage of some additional information provided from the learning of the hidden structures?",
                    "label": 1
                },
                {
                    "sent": "Can we leverage that and then propose a two stage model so for better engagement prediction, so those are the two contributions of our work?",
                    "label": 0
                },
                {
                    "sent": "So be.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When I go into the details of the algorithms, I will quickly give you overview of a particular data set.",
                    "label": 0
                },
                {
                    "sent": "Because this is predominantly we have used and this is a data set of an adult child interactions of around 160 sessions.",
                    "label": 0
                },
                {
                    "sent": "This data set is released from Georgia Tech in 2012 and suffered as multimodal dyadic behavior datasets.",
                    "label": 0
                },
                {
                    "sent": "So essentially in this data set there is a series of 160 sessions which are off duration three to five minutes, wherein yes specially trained person interacts with the child.",
                    "label": 0
                },
                {
                    "sent": "To elicit their behaviors by exercising play protocol, which is a well defined protocol referred as a rapid ABC protocol.",
                    "label": 0
                },
                {
                    "sent": "By using that they used to elicit their behaviors from the child.",
                    "label": 0
                },
                {
                    "sent": "And there are different stages.",
                    "label": 0
                },
                {
                    "sent": "For example, playing a ball, looking through the book and tickling games.",
                    "label": 0
                },
                {
                    "sent": "Essentially, there are these five stages where they're trained.",
                    "label": 0
                },
                {
                    "sent": "Specialist will exercise play activity with the child to elicit their behaviors, and at the end of it that specialist will help in annotating their overall engagement level offer.",
                    "label": 0
                },
                {
                    "sent": "Child so we have used this particular data set to validate our approach.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So obviously we started off with a higher level features.",
                    "label": 0
                },
                {
                    "sent": "We wanted to use the head post features as that is one of the predominantly used or not very indicative feature for measuring the engagement and what we have found is that there are quite a bit of challenges especially in this semi structured interaction.",
                    "label": 0
                },
                {
                    "sent": "We found that the child's behavior is completely uncontrolled, so there there's a different kind of situations wherein we are not able to detect the very reliable head process so that forces us to think about is there any other alternative of can we use the low level features which are?",
                    "label": 0
                },
                {
                    "sent": "Fairly easy to obtain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we made a certain we follow hypothesis wherein in such as in a situation where in, let's say in two partners are engaged in red dyadic interaction.",
                    "label": 0
                },
                {
                    "sent": "Let's say if a child dominates in an interaction and if they will enter a dominant behavior in the video is predominantly due to the child, then can we leverage the motion information around the scene to build the model?",
                    "label": 1
                },
                {
                    "sent": "So we wanted to validate that particular hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Another thing is, can we make use of the hidden finer substructures or final?",
                    "label": 0
                },
                {
                    "sent": "Actions emanating from the behavior.",
                    "label": 0
                },
                {
                    "sent": "Can we put that into that CRF model and will that help?",
                    "label": 0
                },
                {
                    "sent": "So we wanted we carried out our model based on these two hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And when we tested it with when we did empirically, when we validated these two with the available ground truth, annotations from the MMD data set and manually guided a high level features.",
                    "label": 1
                },
                {
                    "sent": "When I say manually guided, I refer to.",
                    "label": 0
                },
                {
                    "sent": "In those situations where the head pose estimations was not detected, then we manually forced it to market and then we forced it to detect it.",
                    "label": 0
                },
                {
                    "sent": "And when we compare this, we found that some of the even the low level features are equally contributing or equal close enough to the.",
                    "label": 0
                },
                {
                    "sent": "Performance of engagement prediction.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we built up build up on this and then we proposed two stage algorithm for determining the engagement level.",
                    "label": 0
                },
                {
                    "sent": "So here is a very high level overview.",
                    "label": 0
                },
                {
                    "sent": "Then I will get into the details in the first stage we learn the hidden substructures of the behavior and the input for this particular stage is a set of behavior words.",
                    "label": 0
                },
                {
                    "sent": "I will talk about it next slide as to what these mean and the moment you pause in the behavior is what we get out of this stage.",
                    "label": 0
                },
                {
                    "sent": "One are the hidden state probabilities of of the scene and these behavior.",
                    "label": 0
                },
                {
                    "sent": "Words are used as a node.",
                    "label": 0
                },
                {
                    "sent": "Observations in ahead CR of framework and in the second stage the hidden State probabilities that we obtained from the first stage are used as input, and then we use the VI SVM based classifier to predict the engagement.",
                    "label": 1
                },
                {
                    "sent": "Now the two major aspects that we need to look into here on the first stage we need to understand how we compute the behavior words and in the second stage we need to understand how do we form the feature vector.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So going back to computing behavior words the way we went about doing this is remember we have used the low level features, so we first detect the child's upper body region.",
                    "label": 0
                },
                {
                    "sent": "We used a Calvin perverted detector and then we computed the histogram of optical flow around the upper body regions.",
                    "label": 1
                },
                {
                    "sent": "Then we pick the for each and every frame we we picked the frame descriptor.",
                    "label": 1
                },
                {
                    "sent": "We pick the frame descriptor based on the availability of hops in that particular frame.",
                    "label": 0
                },
                {
                    "sent": "And we use them as the those and then once we have these frame descriptors for each and every frame, we obtain what are referred as the behavior words and that is a parametrizable variable and these each and every behavior word is used as an nodes in the HCR of linear chain.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And on the second stage the at the end of the HCR of training what we get is the hidden straight probabilities of each, the every node and every hidden state belonging to every class.",
                    "label": 1
                },
                {
                    "sent": "So we use that particular information and then we compute the marginal for each and every hidden straight across all the classes and then we fuse them together to form a feature vector.",
                    "label": 1
                },
                {
                    "sent": "And this has indeed helped in improving the accuracy of the overall recognition engage.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prediction.",
                    "label": 0
                },
                {
                    "sent": "So here is a quick summary of the results.",
                    "label": 0
                },
                {
                    "sent": "There are.",
                    "label": 0
                },
                {
                    "sent": "This is an example where in the engagement prediction accuracy based on the depending on the number of behavior words when leave and use, the HCR of model and when you augment that with a two stage approach and more.",
                    "label": 0
                },
                {
                    "sent": "I can see that there is a improvement with the two stage model, except for those situations where we found that the number of hidden states that we can figure in the exterior of framework is optimal, because as we all know, one of the challenges with that CRF model is that how do we pick up the hidden states?",
                    "label": 0
                },
                {
                    "sent": "What is the optimal number of hidden states, right?",
                    "label": 1
                },
                {
                    "sent": "So in those situations where that is not optimal, two stage approach has indeed helped us to ensure.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The generalization of this.",
                    "label": 0
                },
                {
                    "sent": "We have also validated our approach on the JH MDB database, which is one of the action recognition datasets, and even we found the improvement with the 2nd two stage approach is so these two results are just an examples, but more results under different test configuration are reported in the paper.",
                    "label": 0
                },
                {
                    "sent": "So in actual given that high level features are difficult to obtain, the low level features are a good substitute for an engagement prediction and two stage approach indeed.",
                    "label": 1
                },
                {
                    "sent": "Results in providing additional complementary information.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we're all in summary, so if there is a dominant behavior from a child, then the motion cues can be leveraged to builder engagement model and the hidden's and the two stage approaches will be beneficial in those situations where the number of hidden states will not be optimal and what we want to do going forward is that we have features from different multimodal multi modalities.",
                    "label": 1
                },
                {
                    "sent": "Can we instead of just doing a Fusion?",
                    "label": 0
                },
                {
                    "sent": "Can we use them?",
                    "label": 0
                },
                {
                    "sent": "Use the complementary information or even the.",
                    "label": 1
                },
                {
                    "sent": "And and see information that is available in a multi view learning framework.",
                    "label": 0
                },
                {
                    "sent": "And can we build a better model around it?",
                    "label": 0
                },
                {
                    "sent": "So that's something that we want to investigate going forward.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}