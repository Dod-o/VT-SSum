{
    "id": "a5v5scfc2vzhngtb46kt7ysjorxakbbv",
    "title": "Disclosing Citation Meanings for Augmented Research Retrieval and Exploration",
    "info": {
        "author": [
            "Luigi Di Caro, University of Turin"
        ],
        "published": "July 19, 2019",
        "recorded": "June 2019",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2019_di_caro_disclosing_augmented/",
    "segmentation": [
        [
            "OK, thank you all for being here.",
            "So this work has been made in collaboration with Professor Clouds.",
            "Given Ella of the University of Turin, and we reject for out of the same University and in collaboration with Mario, Cataldi is working at the University of Paris 8.",
            "OK, so."
        ],
        [
            "Let's give some introduction.",
            "Some background on the on the topic.",
            "So we are talking about scientific publications, so we all know that.",
            "Day we we work on papers.",
            "We read them and we need to find relevant papers related to our topics, our research topics and this process requires time and effort and there exists a large literature, an working systems that basically.",
            "Aim at supporting this kind of search process and with this contribution we our main goal was to improve this kind of such project process by making use of classification, automatic classification of citations.",
            "So the reference is contained.",
            "In the papers and so, for instance, we all know that there are several references in a paper, but each reference has a specific meaning.",
            "So about the data used or you know method, or a technique or some examples or some background behind.",
            "The topic of the research and so forth so."
        ],
        [
            "We we proposed here a method for creating a semantic graph to explore and to retrieve significant or relevant papers, and we we started from from this data set.",
            "The ACL Ontology reference corpus.",
            "It is a data set containing 21 thousand articles.",
            "And around 300,000 references, some of them are internal to the corpus, around 32% so.",
            "I'm presenting here the results made on this corpus, but we are now working on a larger.",
            "Dataset integrating other resource is.",
            "OK so I will start from basic things like."
        ],
        [
            "Preprocessing and normalization of of the content.",
            "So if you download this corpus because it is public, you get an XML file like this.",
            "He's a part of the of the XML file and you need to extract the metadata.",
            "The content of the article and citations.",
            "But the problem is that there are some errors.",
            "And missing references and other kind of complex things or problems, let's say so we tried first to solve most of these problems and actually we got good results.",
            "So if you are interested in this data set, you can contact contact us to have the you know the same data set with the problem solved.",
            "So.",
            "So of course we made some normalization of the text, but these are just standard techniques.",
            "I will not go into the details of these things.",
            "Of course we integrated some domain specific processing like common abbreviation which are very common on this kind of data.",
            "An yeah, this is an example of problems we solved.",
            "For instance there is some non exact correspondence between the title of the papers and the content within the XML file so.",
            "There are a number of cases like this if you.",
            "If you look at the the red part OK compared to the part on the left.",
            "Which are pretty much the same.",
            "But when you get the data and you want to use them to make some semantic analysis, you basically go into some problems.",
            "And we solved all these problems by applying very efficient partial string matching techniques.",
            "And I we also made some manual evaluation of.",
            "Of these extracted links.",
            "Between non exact correspondences and we found that most of them and like 99% of the of these problems have been solved."
        ],
        [
            "OK, so.",
            "Now a few things about the proposed method.",
            "So basically OK from this part from the preprocessing.",
            "We extracted around 360,000 sentences which we called also snippets, so they are actually the context textual context of the references, OK?"
        ],
        [
            "And we basically applied some syntactic analysis of this of these snippets like this.",
            "So we made use of the Stanford NLP parser with the Universal Universal."
        ],
        [
            "Genesis an we basically started from the verbs.",
            "Of of this part re parse trees and then we traverse the path trees by using the dependencies on the left.",
            "So direct objects modifyers and so forth.",
            "And by applying very simple.",
            "Rules on the syntactic structures of the snippets.",
            "We basically.",
            "Achieved a good compromise to get the most significant terms contained in the snippet."
        ],
        [
            "So without making use of Stop word list and other you know background knowledge, we just use the parse trees and some rules over over it."
        ],
        [
            "OK, so of course we used some stemming procedures and we also use the bigrams and three grams to construct basically the bag of words representation of this textual data."
        ],
        [
            "Is commonly done in literature and again we applied very common techniques related to vector space models, so we used the well known TF IDF weighting strategy.",
            "To construct the vector space.",
            "And we made other normalization.",
            "You can find all the details in the paper, but they are not so interesting for this presentation and we are."
        ],
        [
            "Apply, we applied the singular value decomposition to this matrix to reduce the dimensions.",
            "The number of dimensions, but also to capture basically the Latin structure of the vector space.",
            "As this is also well known in literature and this is not the state of the art in terms of semantic extract, semantic extraction of the of the Latin content, but I. I must say that this works.",
            "We basically wanted to focus on the entire pipeline.",
            "Of all these things, without focusing on very on the most, let's say, advanced techniques for all these steps, because these are just modules that one can replace."
        ],
        [
            "And then again we used a simple clustering process based on K means, which is another very easy and known technique for clustering.",
            "And what we got basic."
        ],
        [
            "Lee was a set of clusters.",
            "We basically.",
            "Put some effort in doing this by varying all the parameters and the number of key, the number of clusters and we got some help from quantitative measures like silhouette coefficient.",
            "But we also spend some efforts.",
            "A manual effort in understanding the content of each cluster to get some parameters getting too, you know.",
            "Coherent clusters that can be associated with some useful labels.",
            "And after this process that took some time and it was manual."
        ],
        [
            "So this is a semi supervised technique.",
            "Overall we selected 12 clusters.",
            "OK, for instance on the right you can see an example of cluster and by with the help of top terms in the clusters and the top sentences in the clusters, we found a label to associate to each of the clusters which were automatically extracted and so for instance this cluster.",
            "We named it like this.",
            "See for details.",
            "And actually there were more than 12 significant clusters, but we only selected at the first stage, the ones having very specific meaning and well identified so very well coherent information inside."
        ],
        [
            "Then we got 11 because two of them were pretty much the same in terms of expressed semantics.",
            "And on the left you can see the meanings associated with the with labels and with the clusters.",
            "You can also find a type of.",
            "Meaning.",
            "The AB Citation and BC citation.",
            "These are two types of references.",
            "Um?",
            "So the AB citation is very simple, so you are in the paper A and then you find some reference direct reference to.",
            "To our paper B.",
            "So for instance, C for the tails.",
            "CB4 details for instance.",
            "But most of the most of the citations are of the other type, the BC type.",
            "Where you are in the paper A and then you find information about some semantics.",
            "See related to another paper.",
            "be OK.",
            "So I think that one of the main contribution of this work was also to extract information from all the papers but related to all the papers.",
            "Again, so for instance.",
            "All the semantic network related to paper A is is extracted from a of course, but mainly from the other papers talking about a. OK so um.",
            "OK, so on the right you can find distribution of these classes over the data set.",
            "And as you can see there is.",
            "That the major limitation of this work at this stage, so the limited coverage of this class is be cause.",
            "Most of the references are not labeled.",
            "We are working on this to extend this coverage.",
            "By making use of more advanced NLP techniques but also clustering techniques.",
            "But again.",
            "The part on the right, as you can see, as you will see later.",
            "Can be very useful to navigate the content in a in an info."
        ],
        [
            "From the way, so these are some information about the results.",
            "So we constructed a semantic graph.",
            "Of course, 21,000 notes, which are the articles and around 100,000 citations which are labeled.",
            "And we made a simple evaluation.",
            "So basically we.",
            "We extracted 100 random snippets per class and we manually evaluate them.",
            "And so we got very, very high accuracy levels and and basically we we only focused on 11 classes so far becausw this one.",
            "This was something we wanted.",
            "At the beginning, so having a high precision.",
            "Of the system.",
            "But we are extending the labels now and then.",
            "Of course we use the very simple modules about semantic analysis and processing, so the total computation time was very low, so the system is very cheap.",
            "I have enough with a normal laptop.",
            "This took around 4 hours from the extraction of the metadata to the processing to the semantic analysis and construction of the graph.",
            "So also the update of the semantic graph is very is very fast.",
            "OK, this is somehow the shape of the extracted graph we this is this is just a sample.",
            "Very little sample of the of the of the graph, but the shape is the same.",
            "This was just to give you an idea of the shape of the of the data."
        ],
        [
            "OK, so basically we are now again working on this on this.",
            "Paper presented here and you can find a web application so you can go there and try the application.",
            "You will find some other features which are not in the paper because we are working on it adding things every month.",
            "There is the source code so you can use it and you can ask also for the data set without those problems mentioned before.",
            "And about the future and current worker, we are of course working on on the integration, for instance of word embeddings.",
            "So neural network based approaches to semantic analysis with respect to the used singular value decomposition of the latter semantic analysis.",
            "And we are adding syntactic based rules to cover more classes, and we are now working on the clustering on the improvement of the clustering step.",
            "That's it, I think I finished.",
            "So please go and use the application and every feedback will be very much welcome.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thank you all for being here.",
                    "label": 0
                },
                {
                    "sent": "So this work has been made in collaboration with Professor Clouds.",
                    "label": 0
                },
                {
                    "sent": "Given Ella of the University of Turin, and we reject for out of the same University and in collaboration with Mario, Cataldi is working at the University of Paris 8.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's give some introduction.",
                    "label": 0
                },
                {
                    "sent": "Some background on the on the topic.",
                    "label": 0
                },
                {
                    "sent": "So we are talking about scientific publications, so we all know that.",
                    "label": 1
                },
                {
                    "sent": "Day we we work on papers.",
                    "label": 0
                },
                {
                    "sent": "We read them and we need to find relevant papers related to our topics, our research topics and this process requires time and effort and there exists a large literature, an working systems that basically.",
                    "label": 0
                },
                {
                    "sent": "Aim at supporting this kind of search process and with this contribution we our main goal was to improve this kind of such project process by making use of classification, automatic classification of citations.",
                    "label": 0
                },
                {
                    "sent": "So the reference is contained.",
                    "label": 0
                },
                {
                    "sent": "In the papers and so, for instance, we all know that there are several references in a paper, but each reference has a specific meaning.",
                    "label": 0
                },
                {
                    "sent": "So about the data used or you know method, or a technique or some examples or some background behind.",
                    "label": 0
                },
                {
                    "sent": "The topic of the research and so forth so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We we proposed here a method for creating a semantic graph to explore and to retrieve significant or relevant papers, and we we started from from this data set.",
                    "label": 0
                },
                {
                    "sent": "The ACL Ontology reference corpus.",
                    "label": 1
                },
                {
                    "sent": "It is a data set containing 21 thousand articles.",
                    "label": 1
                },
                {
                    "sent": "And around 300,000 references, some of them are internal to the corpus, around 32% so.",
                    "label": 0
                },
                {
                    "sent": "I'm presenting here the results made on this corpus, but we are now working on a larger.",
                    "label": 0
                },
                {
                    "sent": "Dataset integrating other resource is.",
                    "label": 0
                },
                {
                    "sent": "OK so I will start from basic things like.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Preprocessing and normalization of of the content.",
                    "label": 0
                },
                {
                    "sent": "So if you download this corpus because it is public, you get an XML file like this.",
                    "label": 0
                },
                {
                    "sent": "He's a part of the of the XML file and you need to extract the metadata.",
                    "label": 1
                },
                {
                    "sent": "The content of the article and citations.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that there are some errors.",
                    "label": 0
                },
                {
                    "sent": "And missing references and other kind of complex things or problems, let's say so we tried first to solve most of these problems and actually we got good results.",
                    "label": 0
                },
                {
                    "sent": "So if you are interested in this data set, you can contact contact us to have the you know the same data set with the problem solved.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So of course we made some normalization of the text, but these are just standard techniques.",
                    "label": 0
                },
                {
                    "sent": "I will not go into the details of these things.",
                    "label": 0
                },
                {
                    "sent": "Of course we integrated some domain specific processing like common abbreviation which are very common on this kind of data.",
                    "label": 0
                },
                {
                    "sent": "An yeah, this is an example of problems we solved.",
                    "label": 1
                },
                {
                    "sent": "For instance there is some non exact correspondence between the title of the papers and the content within the XML file so.",
                    "label": 0
                },
                {
                    "sent": "There are a number of cases like this if you.",
                    "label": 0
                },
                {
                    "sent": "If you look at the the red part OK compared to the part on the left.",
                    "label": 0
                },
                {
                    "sent": "Which are pretty much the same.",
                    "label": 0
                },
                {
                    "sent": "But when you get the data and you want to use them to make some semantic analysis, you basically go into some problems.",
                    "label": 0
                },
                {
                    "sent": "And we solved all these problems by applying very efficient partial string matching techniques.",
                    "label": 0
                },
                {
                    "sent": "And I we also made some manual evaluation of.",
                    "label": 0
                },
                {
                    "sent": "Of these extracted links.",
                    "label": 0
                },
                {
                    "sent": "Between non exact correspondences and we found that most of them and like 99% of the of these problems have been solved.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now a few things about the proposed method.",
                    "label": 0
                },
                {
                    "sent": "So basically OK from this part from the preprocessing.",
                    "label": 0
                },
                {
                    "sent": "We extracted around 360,000 sentences which we called also snippets, so they are actually the context textual context of the references, OK?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we basically applied some syntactic analysis of this of these snippets like this.",
                    "label": 0
                },
                {
                    "sent": "So we made use of the Stanford NLP parser with the Universal Universal.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Genesis an we basically started from the verbs.",
                    "label": 0
                },
                {
                    "sent": "Of of this part re parse trees and then we traverse the path trees by using the dependencies on the left.",
                    "label": 0
                },
                {
                    "sent": "So direct objects modifyers and so forth.",
                    "label": 0
                },
                {
                    "sent": "And by applying very simple.",
                    "label": 0
                },
                {
                    "sent": "Rules on the syntactic structures of the snippets.",
                    "label": 0
                },
                {
                    "sent": "We basically.",
                    "label": 0
                },
                {
                    "sent": "Achieved a good compromise to get the most significant terms contained in the snippet.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So without making use of Stop word list and other you know background knowledge, we just use the parse trees and some rules over over it.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so of course we used some stemming procedures and we also use the bigrams and three grams to construct basically the bag of words representation of this textual data.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is commonly done in literature and again we applied very common techniques related to vector space models, so we used the well known TF IDF weighting strategy.",
                    "label": 0
                },
                {
                    "sent": "To construct the vector space.",
                    "label": 0
                },
                {
                    "sent": "And we made other normalization.",
                    "label": 0
                },
                {
                    "sent": "You can find all the details in the paper, but they are not so interesting for this presentation and we are.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Apply, we applied the singular value decomposition to this matrix to reduce the dimensions.",
                    "label": 1
                },
                {
                    "sent": "The number of dimensions, but also to capture basically the Latin structure of the vector space.",
                    "label": 0
                },
                {
                    "sent": "As this is also well known in literature and this is not the state of the art in terms of semantic extract, semantic extraction of the of the Latin content, but I. I must say that this works.",
                    "label": 0
                },
                {
                    "sent": "We basically wanted to focus on the entire pipeline.",
                    "label": 0
                },
                {
                    "sent": "Of all these things, without focusing on very on the most, let's say, advanced techniques for all these steps, because these are just modules that one can replace.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then again we used a simple clustering process based on K means, which is another very easy and known technique for clustering.",
                    "label": 0
                },
                {
                    "sent": "And what we got basic.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lee was a set of clusters.",
                    "label": 0
                },
                {
                    "sent": "We basically.",
                    "label": 0
                },
                {
                    "sent": "Put some effort in doing this by varying all the parameters and the number of key, the number of clusters and we got some help from quantitative measures like silhouette coefficient.",
                    "label": 0
                },
                {
                    "sent": "But we also spend some efforts.",
                    "label": 0
                },
                {
                    "sent": "A manual effort in understanding the content of each cluster to get some parameters getting too, you know.",
                    "label": 0
                },
                {
                    "sent": "Coherent clusters that can be associated with some useful labels.",
                    "label": 0
                },
                {
                    "sent": "And after this process that took some time and it was manual.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a semi supervised technique.",
                    "label": 0
                },
                {
                    "sent": "Overall we selected 12 clusters.",
                    "label": 0
                },
                {
                    "sent": "OK, for instance on the right you can see an example of cluster and by with the help of top terms in the clusters and the top sentences in the clusters, we found a label to associate to each of the clusters which were automatically extracted and so for instance this cluster.",
                    "label": 1
                },
                {
                    "sent": "We named it like this.",
                    "label": 0
                },
                {
                    "sent": "See for details.",
                    "label": 0
                },
                {
                    "sent": "And actually there were more than 12 significant clusters, but we only selected at the first stage, the ones having very specific meaning and well identified so very well coherent information inside.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we got 11 because two of them were pretty much the same in terms of expressed semantics.",
                    "label": 0
                },
                {
                    "sent": "And on the left you can see the meanings associated with the with labels and with the clusters.",
                    "label": 0
                },
                {
                    "sent": "You can also find a type of.",
                    "label": 0
                },
                {
                    "sent": "Meaning.",
                    "label": 0
                },
                {
                    "sent": "The AB Citation and BC citation.",
                    "label": 0
                },
                {
                    "sent": "These are two types of references.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the AB citation is very simple, so you are in the paper A and then you find some reference direct reference to.",
                    "label": 0
                },
                {
                    "sent": "To our paper B.",
                    "label": 0
                },
                {
                    "sent": "So for instance, C for the tails.",
                    "label": 0
                },
                {
                    "sent": "CB4 details for instance.",
                    "label": 0
                },
                {
                    "sent": "But most of the most of the citations are of the other type, the BC type.",
                    "label": 0
                },
                {
                    "sent": "Where you are in the paper A and then you find information about some semantics.",
                    "label": 0
                },
                {
                    "sent": "See related to another paper.",
                    "label": 0
                },
                {
                    "sent": "be OK.",
                    "label": 0
                },
                {
                    "sent": "So I think that one of the main contribution of this work was also to extract information from all the papers but related to all the papers.",
                    "label": 0
                },
                {
                    "sent": "Again, so for instance.",
                    "label": 0
                },
                {
                    "sent": "All the semantic network related to paper A is is extracted from a of course, but mainly from the other papers talking about a. OK so um.",
                    "label": 0
                },
                {
                    "sent": "OK, so on the right you can find distribution of these classes over the data set.",
                    "label": 0
                },
                {
                    "sent": "And as you can see there is.",
                    "label": 0
                },
                {
                    "sent": "That the major limitation of this work at this stage, so the limited coverage of this class is be cause.",
                    "label": 0
                },
                {
                    "sent": "Most of the references are not labeled.",
                    "label": 0
                },
                {
                    "sent": "We are working on this to extend this coverage.",
                    "label": 0
                },
                {
                    "sent": "By making use of more advanced NLP techniques but also clustering techniques.",
                    "label": 0
                },
                {
                    "sent": "But again.",
                    "label": 0
                },
                {
                    "sent": "The part on the right, as you can see, as you will see later.",
                    "label": 0
                },
                {
                    "sent": "Can be very useful to navigate the content in a in an info.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the way, so these are some information about the results.",
                    "label": 0
                },
                {
                    "sent": "So we constructed a semantic graph.",
                    "label": 0
                },
                {
                    "sent": "Of course, 21,000 notes, which are the articles and around 100,000 citations which are labeled.",
                    "label": 0
                },
                {
                    "sent": "And we made a simple evaluation.",
                    "label": 0
                },
                {
                    "sent": "So basically we.",
                    "label": 0
                },
                {
                    "sent": "We extracted 100 random snippets per class and we manually evaluate them.",
                    "label": 1
                },
                {
                    "sent": "And so we got very, very high accuracy levels and and basically we we only focused on 11 classes so far becausw this one.",
                    "label": 0
                },
                {
                    "sent": "This was something we wanted.",
                    "label": 0
                },
                {
                    "sent": "At the beginning, so having a high precision.",
                    "label": 0
                },
                {
                    "sent": "Of the system.",
                    "label": 0
                },
                {
                    "sent": "But we are extending the labels now and then.",
                    "label": 1
                },
                {
                    "sent": "Of course we use the very simple modules about semantic analysis and processing, so the total computation time was very low, so the system is very cheap.",
                    "label": 0
                },
                {
                    "sent": "I have enough with a normal laptop.",
                    "label": 0
                },
                {
                    "sent": "This took around 4 hours from the extraction of the metadata to the processing to the semantic analysis and construction of the graph.",
                    "label": 0
                },
                {
                    "sent": "So also the update of the semantic graph is very is very fast.",
                    "label": 0
                },
                {
                    "sent": "OK, this is somehow the shape of the extracted graph we this is this is just a sample.",
                    "label": 0
                },
                {
                    "sent": "Very little sample of the of the of the graph, but the shape is the same.",
                    "label": 0
                },
                {
                    "sent": "This was just to give you an idea of the shape of the of the data.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so basically we are now again working on this on this.",
                    "label": 0
                },
                {
                    "sent": "Paper presented here and you can find a web application so you can go there and try the application.",
                    "label": 1
                },
                {
                    "sent": "You will find some other features which are not in the paper because we are working on it adding things every month.",
                    "label": 1
                },
                {
                    "sent": "There is the source code so you can use it and you can ask also for the data set without those problems mentioned before.",
                    "label": 0
                },
                {
                    "sent": "And about the future and current worker, we are of course working on on the integration, for instance of word embeddings.",
                    "label": 1
                },
                {
                    "sent": "So neural network based approaches to semantic analysis with respect to the used singular value decomposition of the latter semantic analysis.",
                    "label": 0
                },
                {
                    "sent": "And we are adding syntactic based rules to cover more classes, and we are now working on the clustering on the improvement of the clustering step.",
                    "label": 0
                },
                {
                    "sent": "That's it, I think I finished.",
                    "label": 0
                },
                {
                    "sent": "So please go and use the application and every feedback will be very much welcome.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}