{
    "id": "aeztfvc47o7fmwknnt4y43c6n2bnx65d",
    "title": "Probability and Mathematical Needs",
    "info": {
        "author": [
            "Nathan Amanquah, Department of Computer Science, Ashesi University College"
        ],
        "published": "March 31, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/aibootcamp2011_amanquah_pmn/",
    "segmentation": [
        [
            "Hey good morning Ann.",
            "Nathan is my name, I'm Electrotypes University and we're going to try and do some mathematics and probability that's related to machine learning and I'll try to put things."
        ],
        [
            "In context, so we're not really lost now.",
            "I love the slides out, use virtually prepared by an Electra, Sandrine, and one in for the previous boot camp.",
            "But let's keep things consistent so you see a lot of slides as we go along."
        ],
        [
            "OK, so let's get the big picture machine learning.",
            "I'm sure over the last couple of days you've seen some research has been done and we actually do some of this already, as in trying to collect data and plots graphs in two dimensions and trying to find some relations between values.",
            "But you realize that the researchers and presented usually deals with very very large datasets, so it's not something actually pretty easily in two dimensions.",
            "And usually the number of dimensions are many.",
            "It's NN is large.",
            "You can easily visualize it.",
            "And so it becomes necessary to use tools that help us compute with actually necessarily seeing right now.",
            "Machine learning has a number of applications, and one area is determining where we collect a lot of data.",
            "Is that to improve decisions that we make a great business?",
            "It could be anywhere, could be manufacturing.",
            "And then there are some areas we can actually program because the options are too many.",
            "So you let the system Lane and then decide what happens in the future.",
            "Then also some programs that.",
            "Look at your preferences overtime and then make suggestions too.",
            "So there are lots of applications where if you look at these three scenarios, we need to learn from some data and project, and that means that we have to do probability right?",
            "And some of it will be conditional means that you look at what has happened and then you use that to predict the future and therefore we need to discuss some probabilities as well."
        ],
        [
            "Am so learning really is about improving the experience at some task, overtime and sometimes prior knowledge can help.",
            "If you see what was happening before, we can predict probability right now.",
            "The next lecture which will be introduction to machine learning, will talk a lot more about so the methodology's that are used in the song of the algorithms used.",
            "So sometimes we just need to classify things.",
            "You see something.",
            "Have you seen something like that before?",
            "So it helps you classify things.",
            "Other things just want to find clusters which set of things are related to each other.",
            "Right and I just mentioned.",
            "What we do usually with.",
            "Regression, I just want to show how we need to look at.",
            "Energy bra so we have a set of points.",
            "Let's see.",
            "And we can draw a best, best a line of best fits right now.",
            "What we really do is actually the minimum squares.",
            "Isn't it?",
            "Least least quest of errors, so this would be an errors.",
            "This with the error.",
            "This would be an error displaying error error, not each of these points has an X&Y coordinate.",
            "I'm working 2 dimensions because you can see that I hope you can hear me and I hope I'm not speaking too fast.",
            "OK, alright so each one has an X&Y coordinates, right?",
            "OK, now in trying to find this we have own ways of doing a regression, but as you mean S slash the number dimensions you guys actually do this OK.",
            "But if you watch it carefully.",
            "Obtain this care.",
            "We were interested in obtaining some ways to MX plus C. Isn't it OK now?",
            "At this point, let's call it something like two and three could be written as 2 = a certain constant.",
            "Times 2 + 7 C right, but actually there are errors involved in getting this MSE.",
            "Now we're going to write a series of equations.",
            "Assuming this is, let's see.",
            "They see 3, seven for example.",
            "We can also write 7 = 2 M 3 + C will have a series of equations.",
            "OK, obviously we have equations.",
            "You can actually build it as a matrix, isn't it?",
            "Right, so when he is M&C they can put this out.",
            "OK, can build a mattress and when the dimension become large obviously then we need some matrices to help solve it.",
            "In fact we can rewrite this as a linear as an expression which is in quadratic form, right and then want to minimize the error and went right in quadratic form, but will get there as we go along.",
            "We'll talk about some of this as we go along, but so the two main things to talk about.",
            "Vector spaces, matrices and probabilities."
        ],
        [
            "In addition, as well, it's a little bit, so that's kind of where we're going, so this is our outline.",
            "AM.",
            "I'm sure from your little bit already, but some of us are not."
        ],
        [
            "Using this activity so we change your mind, your memory to get some feedback and then we proceed from there because you actually meet it as we go along.",
            "Now vector species.",
            "We look at usually in school, do 2 dimensions.",
            "In three dimensions.",
            "We actually want to expand too because the properties of data that we're looking at has dimensions.",
            "OK, so in dimensional space dimensional space you can have a vector from X1 components X one to XN.",
            "Of course the transpose of it, and it's also true that the sum of two vectors would be another vector in that scene vector space, and we can have a scalar mode scalar multiply a vector instead.",
            "Victor just a longer vector version of it.",
            "OK, and.",
            "Whatever skills you choose, you would end up with another vector.",
            "Whether companies choose individual vector.",
            "Now this is true also for if you want to solve from genius differential equations, yes, process as a vector as well.",
            "And of course this would be the second differential for differential equals 0.",
            "There's no team does dependent on T by itself.",
            "OK, now in that case also the negative of that function belongs to that scene vector space.",
            "If you had any two of them so.",
            "Belongs to that space and then again similar properties.",
            "OK, but here you can also have just two dimensions using the Corsair sign you just toss DSPS."
        ],
        [
            "Obviously, right now we can also apply this, not just this also, but just any function.",
            "OK, so if you just take.",
            "Any function at all you can apply similar rules OK and here also you find that as we are interested in a single function, the negative of it belongs.",
            "That's in space.",
            "If you have two functions you consume, them belongs in space and even multiplied by scalar velocity in space as well, right?"
        ],
        [
            "The DOT product remains the same.",
            "The dot products.",
            "OK, so let's just look at the regular.",
            "So we have him.",
            "If you have X one X2X3 and we got this too lazy way.",
            "One way to wait.",
            "Three should remember those products X one and times 1 + X two times Y 2 + X three.",
            "Thanks bye three scalar products.",
            "The same happens for functions is also true for functions.",
            "We just mostly functions and integrate over the area and if you want to find a norm the distance well this time or less between this and that is.",
            "This square root of this square of each it's called which and then square root of it.",
            "So in the same case we have F of X squared and then square root of it.",
            "I guess it's clear any questions is fine, right?",
            "I'm not going too fast.",
            "Away.",
            "We're just trying to play what we know already and extend it to end dimensional space to functions, differential equations, principles I see OK, I'm sure we remember the scalar product right and then the length is the square fish team.",
            "Some of them square."
        ],
        [
            "Write simple functions.",
            "OK, so more for more formal definition.",
            "We can see a set.",
            "S is the real vector space if addition still means you add it belongs in vector space, is commutative means X + y SM as well as X rite of society as well.",
            "And we have the non elements you had zero to any other thing and it still stays the same and the negative it is invertible the negative.",
            "It also belongs to same sets.",
            "Multiplication by scalar.",
            "I think I've talked about this before, but this is for real species, right?",
            "And then.",
            "We can also have."
        ],
        [
            "Space if you have a subspace is just a subset of what we have by the same rules apply.",
            "This seems apply in the subspace right?",
            "Then it's important because sometimes want to have subspecies that appendix at each other.",
            "It's very or belong to same species.",
            "Right now we can have two subspaces, FNG, right?",
            "And if the intersection is not zero, if they don't overlap then together forms the full set full space right now.",
            "If that is also true, then it is possible to express X in terms of 1 subspace in data service.",
            "So if you use 2 dimensions you can have maybe an X component components together defining points with three dimensions you need three of them question.",
            "So if you have two subspaces and they don't have any.",
            "Then when you add them, you get a third space or the full.",
            "Yes, there was the whole space.",
            "A subspace is subset of it.",
            "What if we have 1/3 space subspace?",
            "Let's say if you H then then to be linearly dependent were dependent on there that you can express one in terms of a combination of the other.",
            "Yeah yeah OK, but actually we spend a lot more time on orthonormal orthonormal orthogonal species causes yet represents things OK. OK alright so soft pieces.",
            "You can generate them with a set of vectors, so in 3D space.",
            "We can have this point as it has an X component.",
            "Y component and as it components for example, X + y + Z.",
            "So in that case you can have different constants multiplying the different components of the man gets a particular.",
            "Particularly rates, and if they are linearly independent, the kids are asking the defendant by the linear independence, then this combination will be unique.",
            "Right, it's kind of two versions of it.",
            "OK, OK, now the number of components you have would be the dimension, so we have XY, zed, then straight dimensions.",
            "Just weeks and why there's two dimensions now.",
            "I have a plane is one letter number of dimensions.",
            "So in 3D space we have a clean like that do this.",
            "So this could be a clean in the 3D speed.",
            "We can reflect one thing with that in that in that screen.",
            "OK, so that would be about clean so.",
            "OK, great."
        ],
        [
            "OK, now let's look at the basis usually right edge key because they are perpendicular to each other.",
            "For 3D space or the clearance piece.",
            "Basis tend to be.",
            "It means by which we can access a point or the means by which we can decompose a point, right?",
            "How do you get to a particular point in space is a combination of.",
            "Yeah, scalar multiples of different components of the basis, right?",
            "OK, now in space and here we are talking about the Hilbert space.",
            "You can have an infinite number of components, the incoming and large approaching Infinity, right?",
            "OK, and usually they can be decomposition of wine into components.",
            "Usually they can be.",
            "Unique decomposition, so this tries to express it that if you have different components like XY and Z, something together to make one vector you have XYZ or in this case IGN keeping the basis OK.",
            "Same is true for differential equations that CL two RBC species, right?",
            "You can express intensive."
        ],
        [
            "It's insane, for example.",
            "OK, the dot product.",
            "What we did here before you can express more formally like this that you have D dimensional space and you want to do this and that you take the sum of X&Y over the whole space.",
            "For the vector right, and it's very closely related to the inferior norm.",
            "OK, so if its Axon itself, then the square root of its norm is distance.",
            "OKOK so X 1 ^2 + X ^2 + 3 squared square root of it will give the distance.",
            "But of course we can also express this if it's just two dimensions as this the angle between them being costita cosita X&Y.",
            "It's now if it is if.",
            "The angle is 0.",
            "Then we know their angle is 90 linear, perpendicular, right?",
            "OK, in that case."
        ],
        [
            "You get 0.",
            "OK, right?",
            "So let's talk about the.",
            "Norm again.",
            "If Munoz is 0.",
            "Then X must be 0.",
            "That's the distance, right OK?",
            "Right then you must face killer by Victor.",
            "As it seems the scalar times the norm.",
            "The models of scalar times vector is seamless.",
            "The scalar times is known is OK right?",
            "And if you have this one is important.",
            "If you have some two vectors, it's normal would be less than.",
            "The sum of the independent norms.",
            "So is this actually means that the distance to any point is actually the shortest distance between two points.",
            "Straight line between them rather than going through another point.",
            "OK, OK, I think this.",
            "We've also gone over the DOT product.",
            "Right, if it does seem victo descriptor gives you the norm and if you get exit web easier then the perpendicular to normal auto go now OK.",
            "Right now, for every F has a unique orthogonal supplementary F perpendicular to its right.",
            "In any space, you can always have one that's between you, Click to it, and if that is true, then convex press X in terms of the 1st and Espanola.",
            "OK, I think this is just mathematical language.",
            "We're seeing what we know already.",
            "OK, OK, now Hilbert space really extends beyond 3 dimensions and beyond like 3 and beyond OK. As a Hilbert space there, if you have space where we usually use to 3 dimensions, but here is peace and dimensions."
        ],
        [
            "OK.",
            "Right?",
            "OK, so this emphasizing orthonormal Autonoma, again, we can also apply this to differential equations, also in the lyrics piece as well.",
            "The rules at the same author basis.",
            "Each of these particular, and then we can have a unique combination of sums.",
            "There is also the vector and if you want to find the norm we do this the norm.",
            "Some of the squares of individual components."
        ],
        [
            "OK, I think I've talked about hyperplanes asking this one.",
            "So that's vectors.",
            "Let's talk about matrices."
        ],
        [
            "Everybody happy with this idea.",
            "It wasn't too fast, so it was OK.",
            "It's OK, OK, I didn't see I just kept repeating myself really OK.",
            "So now let's talk about matrices.",
            "AM.",
            "This obviously is a system of equations like we did before, so they are constants times.",
            "Variables OK equals zero.",
            "In this case we can express it like this where you X = 0 system of equations.",
            "We are happy with that."
        ],
        [
            "OK right now OK."
        ],
        [
            "Now if.",
            "You can expect you having matrix that is M by M rules by D columns.",
            "OK, then the products that vector matrix vector products.",
            "That's a mutant X can be done in two ways.",
            "You can have use column vectors or can use reactors.",
            "OK, so the temperature.",
            "It could."
        ],
        [
            "Equal to something else.",
            "It would be hard to something else so it could be equal to.",
            "So in this case is not equal to 0 anymore.",
            "If we quoted a constant or something, typically some set of constants."
        ],
        [
            "This one had zeros, but this one doesn't have zeros, but they seem similar set of equations.",
            "There's no question.",
            "Yeah, So what I'm saying is that you can have a set of questions they quoted zero you can express like this equal to 0, or if it's not equal to zero, we can still do the same."
        ],
        [
            "To some constants this way, but it can be solved OK.",
            "There are different ways of solving it.",
            "You can use skimming through for example if it's simple enough.",
            "Criminal rates."
        ],
        [
            "OK. OK. Now if.",
            "So we can.",
            "We can look at the vector as do each one is a column, so this is a vector that's a vector that's a vector.",
            "But together for some metrics.",
            "OK, in that case you can express that original function as extend you right.",
            "On the other hand, you can use.",
            "You can treat everyone as a rule, so each rule in this one of the use OK and you can UX come written in this format.",
            "That's you transpose times X dot product OK, it's the same as the norm matrix multiplication we know.",
            "OK."
        ],
        [
            "OK, so the usual notation for matrix this size of any size would be AIG, which goes from one to M and now goes from one to M&G, goes from one to N that represents this one for an M by D. OK, now the operations of matrices addition.",
            "We just add ID to be ID for addition and if it's multiplication first of all if it's is in by P&B is P by D. Waltham, Columbia must be similar anymore Rules Day.",
            "They can dream motivation.",
            "P&P must be cool right?",
            "If that is true, then 8 * B for each ID component is actually the sum of AI.",
            "Key times be cagey, writes the kid 'cause we take each rule in each column at the time, but it is not.",
            "Competitive.",
            "Not as distributive.",
            "OK now the transpose of matrix.",
            "If you have a matrix E transpose, you simply replace the rules by the columns.",
            "OK, so AIG becomes EJ for each each element in there."
        ],
        [
            "I guess it's fine and we know this one.",
            "OK, now schema traces, rules and more columns.",
            "Equal and some come be invertible.",
            "Someone invisible, some of them.",
            "We can finally investigate.",
            "Determinant is not very confining ways.",
            "That mattress is the leading.",
            "Set of all the elements on the diagonal and not 0.",
            "Right and everything is zero.",
            "We can also decompose a matrix into an upper triangular matrix and a lower triangular matrix, and that's particularly useful if you want to solve equations OK, because then you can sort the first line just one variable and substitute and carry on.",
            "It's pretty quick.",
            "OK now if a matrix and its transpose are equal, then is symmetric.",
            "Bemidji stress was equally symmetric and if a matrix times its transpose or transpose of matches in itself and cause the unity matrix, which is which has one on alien agonal, then it's a unitary matrix OK and usually is the basis for forming.",
            "So it's that much so final to normal basis, right?",
            "Means that you can actually express other vectors in terms of it.",
            "The vectors in terms of it."
        ],
        [
            "OK, so investing metrics first of all.",
            "Anne.",
            "If it's a diagonal matrix matrix, then none of the elements on the diagonal must be 0, otherwise they determined there because for a diagonal matrix the determinant really just a product of the elements of the diagonal given element zero.",
            "We cannot be invited for Apartment Wrangler matches are so as well see if any element on the diagonal is zero.",
            "We can't find anyways.",
            "Right, OK?",
            "Now suppose you have a system of equations like this, where there's a lower triangular matrix and every other thing is zero.",
            "Want to solve this equation right?",
            "As long as there's no zero in this line means there's an inverse.",
            "Which music can be solved now?",
            "This can be written like this, right?",
            "This times that equals that as this one and this time is that this times that equals this, which is this one.",
            "We can solve the first equation, get the X and substitutes in here X one and we can get text and keep going."
        ],
        [
            "OK.",
            "So this gives us X1.",
            "There."
        ],
        [
            "Replace X1 and we can obtain X2."
        ],
        [
            "Carry on that.",
            "We installed the holding the case.",
            "Actively OK determinants of the two by two matrix and determinant is 8 * D -- B * C. Everyone there are coming better in that case then versus this sub.",
            "These two and indicates those two right?",
            "That's the determinant an.",
            "Now, in generally generally.",
            "If there's a determinant, well, of course if there's a determinant is invertible and usually for square matrices, and they can be visible in the same conditions if there are no tools that are dependent on each other, that's one scalar multiple of the other.",
            "Then you can do an invasion.",
            "That's the determinant.",
            "If one is a multiple of, that means that you can subtract and one rule from there.",
            "Then you have a zero in a row and that means you can't base it.",
            "There's no determinant.",
            "OK, right now you can find recursively find the determinant is going to be OK according to this is going to be a certain element times is there?",
            "That's cool fact, this right?",
            "So if you take this one, find the determinant of this as in all elements screen destroy.",
            "Times this value, right?",
            "Thanks so possibly negative number.",
            "If you take this one is going to be an order means excluding this column and this rule.",
            "So this rule in this column they're going to use this number C and their numbers.",
            "They define it.",
            "So that's what this one is right now.",
            "Either determinant is not zero, then there's one over determinant times transpose or the cofactors.",
            "OK.",
            "I hope that's OK."
        ],
        [
            "Right now this is the more interesting part.",
            "The eigenvalues and eigenvectors.",
            "OK, now.",
            "If you have a vector in D dimensional space, OK.",
            "In the picture is not zero.",
            "Then we can have an equation like vector matrix times vector equals X killer times in vector and if the determinant of that is 0 then you can find a Lambda.",
            "Then the Lambda is adding value and the V is aging vector or the settling vectors OK. For diagonal matrices, Asian values are also the diagonal elements OK, and if it is zero if there is an edge in value then of course.",
            "It's impossible.",
            "Right, and this is a form that we are actually interested in.",
            "If you can diagonalize a matrix, then you can express it like this, where D said I'm going to matrix and this is a matrix.",
            "This times that is.",
            "OK, let's talk."
        ],
        [
            "A little more.",
            "OK. PTSD transpose gives you a OK, so we're interested in this form.",
            "This diagonal and this times that gives you the identity matrix.",
            "OK, right now, that's also true for symmetric symmetric matrices, symmetric matrices and matrix and its transpose, equal times metrics and transposed identity matrix.",
            "Now, if you do this, it gives you a scalar really.",
            "If you do this same as unit productive now if it gives you a number that's zero or positive, we can describe the semi definite positive.",
            "But if it gives you.",
            "A positive number which is not zero then it's definitely."
        ],
        [
            "OK this."
        ],
        [
            "Positive.",
            "OK."
        ],
        [
            "OK, is there any questions unknown?",
            "OK, we're going to do.",
            "We're going to look at some decompositions in different forms, in which I spent some time in the lab today doing.",
            "Where is the compositions?",
            "OK, because that's how we can use it to solve some equations.",
            "This.",
            "Governor then the eigenvalues are the elements of yeah, but The thing is, the agent values are not unique.",
            "There's a whole range of them, yeah?",
            "Define data and metrics Windows another.",
            "Emetrics being diagonal, there's just elements are leading on the leading diagonal.",
            "That's all zero.",
            "Thank you.",
            "OK, now if you have images that's not square like, imagine that is M * N. It's possible to express this intensive two or three other matrices.",
            "We can find a matrix."
        ],
        [
            "Transpose times B, which is D dimensional.",
            "Right, well that's deep ID OK. And we can't find something another matrix DN B transpose which also.",
            "M by M is cut up into different elements.",
            "Now if we have that then we can have forget this one.",
            "Look at this you can have.",
            "V * A diagonal diagonal matrix times this was transpose, which is D by D. They can have you.",
            "Thank you very much.",
            "Thanks transpose which is in by.",
            "OK, it's possible to evaluate that, and that is.",
            "So if you have these ones right and the elements and I'm gonna run on zero then on zero, then we can express the original matrix B in terms of.",
            "This one's made this is M by D. Then this would be M by M and this would be by D * A second diagonal matrix that's the same as original becomes original.",
            "OK so if this DD the dynamics you have this.",
            "OK. OK now so this will be arriving at B transpose is v * D times you transpose where these data metrics.",
            "Take a few minutes to three seconds.",
            "Look at it again.",
            "We're seeing that you can decompose an original matrix, which is M by N into three matrices.",
            "One is a diagonal, the other is one that is square by them by M and another one which is North by.",
            "Or divide in this case OK."
        ],
        [
            "It gives you the same as.",
            "The original.",
            "OK. OK, and that is called a singular value decomposition with the Lambda.",
            "The elements are diagonal, being the singular values.",
            "OK. Yeah, OK.",
            "It's OK, OK?",
            "Right now, that kind of decompositions which one to look at.",
            "OK then.",
            "Right, so we can.",
            "We can also do Lu factorization where we have this like 2 matrices, right?",
            "One is the El is their lower triangular matrix and they use an upper triangular matrix and the product will still give you the original matrix."
        ],
        [
            "That's possible to do.",
            "In that case you can solve.",
            "This expression as you have any questions so we can solve in two steps.",
            "Because you write that equal eight X = B, but we are now seeing E is seamless Lu right times X = B. Alright, so now we can actually do.",
            "We can solve.",
            "Complete this way so we can write L, y = B, but that means that UX cause why.",
            "Right, so you can solve this one first.",
            "OK, so they're using you can solve this one first.",
            "You can solve this office and it's all done right so.",
            "OL U * X = B.",
            "We don't know what taxes that were interested in, so we can replace the 8:00.",
            "So by lnu, and in that case we can solve L * 8 = B and they can solve you times X because they solve in two steps.",
            "There's always one unknown is often used to sort that out OK.",
            "Right, so let's keep depending on where you come from.",
            "Transfer this with the way OK for symmetric semidefinite positive matrices.",
            "OK, we can also write 2 triangular matrices where it ranked matches any transpose equals Princess.",
            "You transpose times, you will use an upper triangle matrix and again same principle you please.",
            "This ESU transpose you and it's always in two steps.",
            "The good thing is that there are tools to help us do the composition.",
            "So cannot wait about.",
            "The company so we should be using Octave which like Matlab identical to what life is here.",
            "Right then there's also cure decomposition for any matrix that is M by R. You can express it.",
            "As in terms of Q&R, where Q is a unity matrix and R is an upper triangular matrix.",
            "OK, I think that's what we do for matrices for now.",
            "Zaki OK, so now we're going to.",
            "Some probability.",
            "You might not necessary member everything because you might not be working with everybody, but it brings back memories, so it's kind of the same with probability as well, and hopefully something will come back.",
            "And then we can proceed.",
            "Hope that's OK, so you can do it.",
            "Determinant of four by four matrix.",
            "Should be easy.",
            "Thing is that we're going to use tools to do it, so it's not that difficult.",
            "We just need to remember the concept.",
            "Of course I want to research then really need to learn some more in this area.",
            "OK so.",
            "Some definitions first an here looking at random variables."
        ],
        [
            "Random speech Sam Omega is the set of all possibilities.",
            "More less.",
            "So if it was a coin, we are."
        ],
        [
            "Better have hits orthus.",
            "That's a set of data.",
            "Who sits then?",
            "We define it as a set of measurable.",
            "And collection of events right?",
            "So it costs once you get ahead or it gets a deal, right?",
            "So if you're tossing twice, you get hit at your head and so on.",
            "Or you get nothing, right?",
            "So there's a possibility.",
            "OK, now probabilities always lie between 01.",
            "And I think I don't need to emphasize that now.",
            "If you're looking for hits, the probability of heads is P and the opposite is getting into is 1 -- P, right?",
            "And if you want to get heads and tails, then the total of it is 1 probability of one.",
            "OK, now this I think the essential things probably between zero and one.",
            "They went North Korea.",
            "Zero events.",
            "Everything they said OK is 1 if you have two event out OK for this that the OK Together is this plus that OK and if the independent way they're dependent will look at that eventually, right?",
            "But the whole set is this plus that either independent one of them is 0.",
            "P. Intercession will be 0 in that case, just Adam."
        ],
        [
            "OK, now when we talk about measurability then there's there's more lesson invest investment function that preimage function that takes us back to the original OK.",
            "Right now we can have variables that are discrete, so continuous, discrete or continuous OK, and what different distributions for it so discrete or continuous random variables?",
            "Yeah.",
            "I think I don't need to see too much on this one."
        ],
        [
            "OK, now you have been really variable, like a coin toss and I have a hit or two."
        ],
        [
            "This is how we want expressive probability.",
            "OK, notation is X.",
            "Am manually or the variable right?",
            "And if it is binomial we use binomial OK.",
            "When is binomial women having more trails OK?",
            "Entrails, which would probably certain probability and for binomials before this as well, we're going to add if they each independent just adds the probabilities that your care together OK. And for binomials the probabilities.",
            "Am North Trails, North Texas is probably the success probability of failure and minus key.",
            "I'm sure you're familiar this one in combination key."
        ],
        [
            "OK, now the expected values.",
            "The mean is expected value.",
            "OK, this is general form before.",
            "In this particular case, expected value being X times probability of X or caring OK, and if it's discrete it's just a summation.",
            "If it's continuous is an integral.",
            "This is Constance gorgeous.",
            "OK, fewer views.",
            "Now the variance is.",
            "The division of variables from the mean more less.",
            "OK, so as expected.",
            "Value of X minus the mean squared expected value of it, and this can be written like this.",
            "An or can be written written like this.",
            "X squared times probability and then extend probability or script."
        ],
        [
            "OK alright."
        ],
        [
            "OK."
        ],
        [
            "OK, I think this repeats it and emphasizes the fact that measure some things are measurable.",
            "OK, so there's a couple Bernoulli variables, more specifically any variables."
        ],
        [
            "And in this case, disposition is is that OK?",
            "So there's no OK.",
            "So is submission of other possibilities right across it, so it's 0 * 1 -- P + 1 plus that you sleepy OK, and then for the variance will have summation of XI squared times P minus summation of.",
            "An essay where P or squid OK works out to be P 1 -- P OK when you workout that variance and expectation.",
            "Is this OK?",
            "Generally F of X, right F of X times P, AF0 and F1 times P."
        ],
        [
            "I'm sure we can all work it out if you take out three displays.",
            "OK, Ann.",
            "We can not move this onto victus.",
            "OK, we have victus right then.",
            "We now talk about.",
            "Expectation being expectation of.",
            "The different rules, of course is the vector is the transpose of this OK, and then we can talk about covariance matrix is the matrix and each element on the leading diagonal is the variance of of I.",
            "But when it's not the leading diagonal, then is a covariance which is expressed like this.",
            "Can I repeat that?",
            "OK?",
            "Right so we have a matrix or we have vectors then expectation.",
            "Of X."
        ],
        [
            "For example, for example an.",
            "X1 card this distribution annex two can have this distribution right?",
            "Just cause 1X1 and X2AD correlated.",
            "Then the covariance itself is 0 now expected value of this is expected value of that end that we know for manually expected values P. Or is your success.",
            "So if you're an MP, two covariance matrix on the leading diagonal with a variance of X, one X2 and the ones that are not on the leading diagonal.",
            "Recurrence of X2X1X1X2.",
            "This is the coordinates.",
            "In this position, right?",
            "OK, so that results we already know what the variance is and what the covariance is in this case.",
            "It's OK."
        ],
        [
            "OK. OK, now we look at discrete.",
            "Now let's look at.",
            "Am continuous right continuous?",
            "In that case, where about this summation replace with an integral?",
            "OK, and then we have probability distribution functions also.",
            "So the purpose is density function.",
            "If everywhere you find deep differential of P of X right there becomes the probability density function so that we intend to integrate and expected value is integral over this piece of X DX, just as we did before and the variances.",
            "Expected value of X minus expected value of X ^2.",
            "Seem right, just whereby summation now becomes an integral."
        ],
        [
            "Can I go for it?",
            "Thank you.",
            "OK, now let's look at the uniform distribution is continuous, uniform right?",
            "So the expected value of the distribution as X and the form is uniform between A&B, right?",
            "So that would mean that it would look like that.",
            "So between A&B in between tables out of SYMLIN have equal probability right?",
            "And so for that one expected values fix.",
            "PDX, which is which values to this one?",
            "Because actually the function is always 1 / B -- C, right?",
            "So this is published density function.",
            "Then for the Gaussian distribution.",
            "Like there no more.",
            "The Belk if an we have the same thing.",
            "I said value is FX DX right and so we can.",
            "Evaluate this, which usually rates for anybody.",
            "Whether the definition for it, and there's a probability density function for it, OK?"
        ],
        [
            "OK. AM.",
            "OK, so now we talk about vector spaces also for vector spaces the same thing, But this time.",
            "We are placing X with a set of vectors.",
            "OK, not a single variable anymore, so it's a set of vectors and this is what the probability density function is.",
            "We're going to do.",
            "Determinant of the matrix, right?",
            "And then we shall also have the expected value is an integral over the vector.",
            "Right, OK?",
            "I don't think we're going to do this, but it's just translates whatever it is in for continuous functions.",
            "Now, is it better?",
            "Vector of."
        ],
        [
            "Right, OK?",
            "OK, now let's look at joint probabilities was quite more related to learning.",
            "Something happens.",
            "You want to see what we can learn from it for the future.",
            "OK, so let's look at the case where we cost 2 coins for BitTorrent.",
            "Fair coiners half OK. Now suppose that you're going to toss twice.",
            "But the point of getting two hits it's half times half right because head is having itself.",
            "So for ease of getting any two of them will be worth 1/4.",
            "Just multiply them, right?",
            "As because they're independent.",
            "When one happens there.",
            "So mean that's the next thing will happen.",
            "Also, it's just independent.",
            "There's no intersection.",
            "OK, so probability of a anvil Karen is a probability of Ethan's policy of B. OK, right?",
            "That's the same, and then their independence.",
            "OK, but that's not necessary."
        ],
        [
            "Basically this look at the.",
            "From this chat will be the probability.",
            "Let's assume the test done there, some sick people, and then there's some healthy people and but there are some secret positive tests and there's some.",
            "And healthy people who also had a positive test.",
            "OK. And then there's also those who are sick by the test, retain negative, and then those who are alright.",
            "My test returned positive.",
            "OK, now what's the problem?"
        ],
        [
            "See that person is positive.",
            "Probably a person is positive would be 90 + 100.",
            "Also, the population isn't it, so it's 190 / 1 zero.",
            "OK, so that's this.",
            "The testing is positive now.",
            "Probably the person is sick would be 90 plus this with hundred out of the total.",
            "OK so that's 101 thing right now.",
            "What's the probability that person is positive and sick?",
            "You'd be inclined to modify these two, but to give you the wrong answer.",
            "OK, for this person is positive and seek positive.",
            "Is this 90 and sick is worth?",
            "AM.",
            "Ticket.",
            "And positive person is positive, sorry is sick, sick is this hundred OK and the probability that person is?",
            "OK, let me just check it again.",
            "OK so if only to the person is positive positive, is this rule OK?",
            "And then for each of the person is sick this column right?",
            "So it should be this way that sometimes this over that's OK. Actually it's not be correct.",
            "Isn't it?",
            "You can just play them OK?",
            "AM.",
            "So this was the perfect person.",
            "Actually positive messages.",
            "Just this number, isn't it?",
            "It's just he's seeking positive out of the total population is not the same as multiplying two together one like this must find this in that it's not correct."
        ],
        [
            "So that leads to dependence.",
            "Write an.",
            "If two probabilities are independent, or if two variables are independent, then the probabilities can just be multiplied because they don't.",
            "There's no dependence on between them, I just multiply them by their notes.",
            "Then we have to work with it differently.",
            "You have to subtract the intersection.",
            "OK, so for all A&B, publisher of the two of them were carrying is just that.",
            "If the independent right inverse continuous, there's the.",
            "Let's say sorry then expected value expected value is.",
            "The product expected the predictor expected values.",
            "Expected value is expected by these right now if they are independent then the covariance between them is also zero through the independent.",
            "And for question variables only.",
            "Equivalence is there.",
            "We also means that.",
            "Their orthogonal, they are independent.",
            "Right now, the independence, knowing about one or does not give any information about the other 'cause they're completely dependent.",
            "OK, but now let's talk about the cases where.",
            "There's some dependence like that."
        ],
        [
            "Example that we saw when there's no difference there cancel one gives information about another possibility.",
            "Right, so what's the probability of someone being?"
        ],
        [
            "Sick."
        ],
        [
            "But this one is being sick is 100 out of out of that now the probability that person is well, it's thousand over.",
            "That's OK. Now if you have a positive test.",
            "What's the probability they also seek?",
            "Now there's some dependence, right?",
            "So what's the police?",
            "They are given that you had a positive test for safe tests, which we had a positive test.",
            "It is either this or that's right, but what they seek in positive is 90 out of 190.",
            "Is there OK?",
            "OK now what's the problem that will fit given that her positive test is going to be this divide by 190.",
            "OK, now how about those who are negative things?",
            "Just just the numbers right?",
            "Negative test with this 10 out of 19 and the fits behind native tests 90.",
            "OK, so now we're going to use that to do."
        ],
        [
            "Do other things.",
            "And this just repeat of what you saw.",
            "What's the probability that we were sick given that way negative?",
            "And it's actually negative.",
            "There's a probability that there are sick and negative.",
            "Purpose of sick and negative right now give us a conditional probability with your product.",
            "OK, so sick and negative would be probably the way sick give their negative.",
            "Give tons of quality that we actually negative.",
            "OK. OK.",
            "So sick and native probability of sick or negative transferability of sick and negative.",
            "OK."
        ],
        [
            "Right, so in a more general expression.",
            "Am is probably off way.",
            "Times probability of X given Y.",
            "That gives us probability of X in working order of X&Y OK. OK. OK, that's the same thing, but we'll figure ways probably why given X, that will be suffix.",
            "OK. M and we extend it to the case where you have quality density functions."
        ],
        [
            "OK, so now let's look at the issue.",
            "AM.",
            "So we define Y as a random variable that we actually observed, event or caring, and it is the is the random variable that interesting, and the goal is to.",
            "Observe way given and find the best guess for for data.",
            "So that's something we're trying to.",
            "We're trying to drive some inference from some other event occurring like this is positive by the potentially sick.",
            "So do some tests and other people are positive.",
            "But what's the probability that they actually sick, right?",
            "So we know we can probably test whether if sick or not.",
            "I can do a test to see whether positive or negative, so that kind of thing we're going to do.",
            "So we're going to have a prior and posterior prior is we can actually measure the procedure is.",
            "Variance we can grow.",
            "OK right now.",
            "Please.",
            "OK, followed just did before probability of.",
            "And we can have probably 4 bit of extra positive way and they can have probability of X giving way same probability of X given way.",
            "Is actually probability of.",
            "Anne.",
            "XNY driveway publisher way.",
            "OK, so we can write the probability of X indecision.",
            "Why cause probability of X given Y?",
            "Thanks probability of way.",
            "OK, so that's that's the basic and we extend in the case of the issue.",
            "OK, now if we had.",
            "If you have, this is just two possibilities.",
            "Either X or case.",
            "Oreg does not care.",
            "OK, well OK, so why does not OK?",
            "Alright then probability of X or caring actually is probability of Y given that X or Kate.",
            "AM and then probability of Y given X is not K. This gives us the probability of why 'cause?",
            "I thought we were case.",
            "Lucky right now we try to extend here, right?",
            "So if you're interested in probability of.",
            "Him.",
            "I'm just trying to put my thoughts together to write this will.",
            "No Jesse.",
            "OK great, so basically I want you to please this one.",
            "I want to put this one here.",
            "Lucky because this part is away, so it means I'm actually going to some probability of.",
            "Why?",
            "Given all the possibilities of X moreles.",
            "Very places this one makes sense.",
            "Search repeated.",
            "Repeat it OK. OK, so probably 2 E giving that via case is seen as probability of A&B vary by probability of B. OK, right, and we can also probability of.",
            "An given B times probability of BOSP of a decision B.",
            "And this seemed P of a given B can also be written as P of B given a nice probability of a this equivalence.",
            "OK and just trying to explain that.",
            "Probably let's be orchis.",
            "Given that your kid or Aiden or K. The combination gives us the fact that be OK. Alright, so probably that your case is similar with the B orchid.",
            "In the ER, soak it right or probability of your caring, given that he did not OK, OK, sorry that's OK.",
            "But whenever we build case, so that's some gives this right.",
            "I'm trying to replace this one with this one so I can write an probability of a intersection.",
            "B is seamless probability of some of the probability of B, given that.",
            "E. OK senior, any component of your case.",
            "So we just sum the whole which about your case.",
            "But given that that's possible at your kid, but we can't replace this one with an expression like this, right P of a given B is seamless.",
            "An appeal of Intercession B.",
            "Is coming written as this one?",
            "During the session become richness so I can replace this with Pio Pio V as this one given a 10 speed of A equals OK, it seems this divided by summation of P of B given a.",
            "In this case, this just to ease, but as you open up for all possibilities, then in particular G. Then this will be from 8 to 10.",
            "Where this is particularly out of the Lords and then this is.",
            "For all of it, so that we have written here, right in the same way, so you have P of Y given the type of data and P of Y given data.",
            "Again times period data.",
            "But this one has.",
            "All the possibilities and this particular one of it's just as we have here.",
            "Is it OK?",
            "This one is OK. OK so this will be continuous.",
            "Nobody happy.",
            "Oh it's repeated.",
            "OK, OK, right?",
            "OK, so that really be true.",
            "If you know certain things, even though that B has a kid given that.",
            "In fact, all you're trying to do here is trading value, it's.",
            "And P of.",
            "P of E giving up your case where expressing tense of B given that your kid very expressing the opposite of it OK.",
            "Copy that EG or case giving up your case.",
            "We do this becauses the beacon measure we can measure the.",
            "Right, OK, so that's the idea.",
            "So we know some.",
            "Some condition we know it prior condition and use that to estimate the posterior right 'cause there's something major in order to make inferences about about other things OK.",
            "Right?",
            "OK then, let's talk a bit about entropy.",
            "Entropy really is the amount of disorder.",
            "It's got applications in Mo dynamics.",
            "But here in this case we talk about in terms of information theory."
        ],
        [
            "OK so entropies this state of disorder an.",
            "And is expressed in terms of a log.",
            "So entropy itself is the probability times probability.",
            "The log of the probability.",
            "OK, now the reason the user logs as big 'cause once we do add if two events or case theorems OK is probably one times that.",
            "By and large we just Adam.",
            "So that's behind.",
            "They look OK for discrete random variables.",
            "I remember this one.",
            "I need to just check in February.",
            "This one actually stands for a country right now.",
            "OK, now they are there, they know of.",
            "Theorems that help us know how to bits of information related.",
            "OK, OK, now if you've got two variables.",
            "OK, this expression here tells you how related the how related two piece of information as if evaluate this and it gives you a zero.",
            "It means that actually you have not learned anything, right?",
            "It's two things that they seem OK. Now we entropy is interesting.",
            "'cause if you're tossing, let's see dice tossing coins.",
            "And it is a double headed coin.",
            "OK, now the entropy there is zero because you're not learning anything anything it tells you definitely hit.",
            "So the interpreter is there, but if you have a fair coin we have ahead and until everything it 'cause you don't know what will happen next.",
            "Right, so the expectation is this kind of the highest entropy itself lies between.",
            "Anne.",
            "In this case there in.",
            "And one.",
            "OK, so the information that you also sort of information is.",
            "Is the cubic labor divergance for XY and then?",
            "X&Y.",
            "OK. And then the perplexity is too, is the power.",
            "The entropy as well?",
            "Send it.",
            "Yeah, OK at questions on this one.",
            "I wish you could prove it.",
            "OK, I can go by this again.",
            "Let me just make it difference.",
            "OK, right, so this is entropy.",
            "I think the entropy one is clear with a lot of the probability times of probabilities of the entropy that this is an.",
            "The amount of disorder in there.",
            "Now the reason we do this is to is also OK. Actually what happens is that the X is what we're measuring and why is a model that we have right?",
            "So we have a model that we used to predict X is the models to predict where the model is to predict X. OK, so we have.",
            "Where is available that we can model we built and this is what we're actually trying to estimate.",
            "OK, this is the event OK, and for do this even integral integral of probability of this times log of this minus this about that logo for dinner or the difference?",
            "OK, it gives us a value such that this is not actually quoted that, but when it is equal to 0 it means that our model closely matches the other one, right?",
            "Actually identical.",
            "Addictive, OK, but typically it is positive.",
            "Typically, this positive right and then the mutual information is shared information between the two of them, right as in.",
            "I have had it model.",
            "OK, so the this time you've already seen function, but this is P X * P of X * 5 Y and.",
            "No, I think I'll skip this one and I'll come back to it because I'm mixing up two other things, so I see if not for me to comment on it just now, then I'll come back to it.",
            "And.",
            "Arrange which one there.",
            "Call back inhabitants yeah.",
            "Is better than zero.",
            "I think there are two one.",
            "Yeah, that's one, that's one.",
            "Skip this one off.",
            "Please come back to it so they don't screw their information."
        ],
        [
            "OK."
        ],
        [
            "OK, and."
        ],
        [
            "OK, so now let's look at the confidence intervals.",
            "For example in approximations.",
            "OK, Ann.",
            "We want to be sure that when we build, we have a model the mean of.",
            "Distribution lists within a certain range.",
            "OK, the mean of a sample lies within a certain range of the population mean.",
            "For example, let's make sense.",
            "So there's a population we can't actually check the whole population, but so we take a sample, right?",
            "Want to have a certain assurance that our average we calculate actually less units in range of the population average?",
            "That's where these things come in.",
            "Now, Markov inequality says that.",
            "Let me just check what he says.",
            "The Markov inequality gives an upper bound for the probability that the sweater value is above some constant, right?",
            "So expected value actually is kind of the limit, and it's above.",
            "This will always be less than this one.",
            "OK, so expected value always be less than some particular range.",
            "It gives up a bunch of it.",
            "Now should be chef one, the chef inequality.",
            "We can be sure that nearly all values are close to the mean and no more than one of us epsilon squared for the distribution.",
            "It's more than a standard division.",
            "Are we right?",
            "So this is 1 version over this difference inequality that should be shared one and that says that.",
            "Am nearly all values.",
            "That will work with we closely mean and no more than.",
            "This distance away epsilon squared distance are we.",
            "Find for side-by-side vision OK.",
            "Right?",
            "And this one has to do with bounds on till distributions until distributions.",
            "I can't really explain this one's a lot more than this so I can come back to it.",
            "Additional information, but."
        ],
        [
            "I'm not an expert on this particular.",
            "AM.",
            "Alright, see about this is these are bounds on estimates.",
            "OK, that's why else for now, but it's also been a lecture, so that's.",
            "OK, so there's a cut in my edition minimization little.",
            "OK, so now we have a cave.",
            "And it's quite easy to find the minimum point within the first differential, and if it's zero, suggests that it might be a minimum, maximum.",
            "Or it could be a saddle point.",
            "It could be like that.",
            "Alright, so at this point it's not anymore so much it just say point of inflection right?",
            "So that alone.",
            "So we take the second differential also and when the second differential is positive then we know it's a minimum point.",
            "OK, but the other things other considerations.",
            "Sometimes my heart function that is just.",
            "That is like this.",
            "Alright then it's fine between this and that.",
            "OK, so it doesn't actually get to attending points, but this actually is a minimum for it.",
            "OK, so that's something to pay attention to, and so we can always have 000.",
            "Not always.",
            "Right?",
            "And just because the gradient is there does not mean it's a minimum requirement or inflection.",
            "OK."
        ],
        [
            "Right and then we also sometimes interesting global minimum."
        ],
        [
            "Right, so we might be that."
        ],
        [
            "The Cave might itself be like this, so my working around."
        ],
        [
            "I think it is a minimum bachelors.",
            "Under the minimum somewhere.",
            "OK."
        ],
        [
            "Right so then the other algorithms that can help us determine.",
            "When they agreed in the sense we can use it cause Newton method or the clinic within decent.",
            "They're iterative methods for calculating.",
            "Calculating the minimum.",
            "If you like."
        ],
        [
            "Right?",
            "OK. Write every talk about convex functions, convex functions.",
            "Functions like that.",
            "They are pretty concave, but these are convex function and we can determine points if you by taking a look at this.",
            "OK, so we know the middle point somewhere between, let's say X1.",
            "And X2 we can find.",
            "If there is really a mini point now, the condition is we have to look for another point here.",
            "So let's say this is F of this is F. Of this F of X1, this is F of X2.",
            "That OK we take a point that is in between.",
            "Here on an interval between 01 and if F of X + a constant.",
            "Anne.",
            "Let's see let me just write this, but yeah, OK, that's it.",
            "So we're going to find we're going to use a constant between zero and one OK, and so F of X + a constant plus one minus the constant Times X2, right?",
            "Is somewhere here, right?",
            "If we evaluated and the function is service less than what we value is, then they say that functions actually there's a minimum point in between the two.",
            "More less so we're going to actually be looking at this of this.",
            "Move that and then same thing.",
            "This should be.",
            "This should be less than, which now it's OK. Let me just ask.",
            "Into it.",
            "OK, so F of Lambda plus times X + 1 minus Lambda times way right should be less.",
            "We value.",
            "This gives us a point like here.",
            "Sorry that's on.",
            "The actual function, should give us a point that is less than what's play Lambda by this plus one minus Lambda times that that actually correspond to a higher point.",
            "That doesn't make sense, right?",
            "So when it happens, then we know that this minimum in between the two.",
            "OK, then we know we have a convex function.",
            "Right?"
        ],
        [
            "OK, so we'll stop here."
        ],
        [
            "Only stats love Ellie.",
            "What I've missed?",
            "The two slides I couldn't talk about will be in another class, so we're going to start doing stuff with vectors probability.",
            "Victors face any probability, so we're going to start up silly today and we're going to use Octave.",
            "So if you have math lab, we can use MATLAB, but we don't have much love.",
            "This active on the machines and we have programmers we can store is open source, is free so you can use the commands for Matlab and Octave identical.",
            "For the most part, right?",
            "So we're going to use for some of these to try some of these things will go next door to your lab and we can get started."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey good morning Ann.",
                    "label": 0
                },
                {
                    "sent": "Nathan is my name, I'm Electrotypes University and we're going to try and do some mathematics and probability that's related to machine learning and I'll try to put things.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In context, so we're not really lost now.",
                    "label": 0
                },
                {
                    "sent": "I love the slides out, use virtually prepared by an Electra, Sandrine, and one in for the previous boot camp.",
                    "label": 0
                },
                {
                    "sent": "But let's keep things consistent so you see a lot of slides as we go along.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's get the big picture machine learning.",
                    "label": 1
                },
                {
                    "sent": "I'm sure over the last couple of days you've seen some research has been done and we actually do some of this already, as in trying to collect data and plots graphs in two dimensions and trying to find some relations between values.",
                    "label": 0
                },
                {
                    "sent": "But you realize that the researchers and presented usually deals with very very large datasets, so it's not something actually pretty easily in two dimensions.",
                    "label": 0
                },
                {
                    "sent": "And usually the number of dimensions are many.",
                    "label": 0
                },
                {
                    "sent": "It's NN is large.",
                    "label": 0
                },
                {
                    "sent": "You can easily visualize it.",
                    "label": 0
                },
                {
                    "sent": "And so it becomes necessary to use tools that help us compute with actually necessarily seeing right now.",
                    "label": 0
                },
                {
                    "sent": "Machine learning has a number of applications, and one area is determining where we collect a lot of data.",
                    "label": 1
                },
                {
                    "sent": "Is that to improve decisions that we make a great business?",
                    "label": 0
                },
                {
                    "sent": "It could be anywhere, could be manufacturing.",
                    "label": 0
                },
                {
                    "sent": "And then there are some areas we can actually program because the options are too many.",
                    "label": 0
                },
                {
                    "sent": "So you let the system Lane and then decide what happens in the future.",
                    "label": 0
                },
                {
                    "sent": "Then also some programs that.",
                    "label": 0
                },
                {
                    "sent": "Look at your preferences overtime and then make suggestions too.",
                    "label": 0
                },
                {
                    "sent": "So there are lots of applications where if you look at these three scenarios, we need to learn from some data and project, and that means that we have to do probability right?",
                    "label": 0
                },
                {
                    "sent": "And some of it will be conditional means that you look at what has happened and then you use that to predict the future and therefore we need to discuss some probabilities as well.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Am so learning really is about improving the experience at some task, overtime and sometimes prior knowledge can help.",
                    "label": 1
                },
                {
                    "sent": "If you see what was happening before, we can predict probability right now.",
                    "label": 0
                },
                {
                    "sent": "The next lecture which will be introduction to machine learning, will talk a lot more about so the methodology's that are used in the song of the algorithms used.",
                    "label": 0
                },
                {
                    "sent": "So sometimes we just need to classify things.",
                    "label": 0
                },
                {
                    "sent": "You see something.",
                    "label": 0
                },
                {
                    "sent": "Have you seen something like that before?",
                    "label": 0
                },
                {
                    "sent": "So it helps you classify things.",
                    "label": 0
                },
                {
                    "sent": "Other things just want to find clusters which set of things are related to each other.",
                    "label": 0
                },
                {
                    "sent": "Right and I just mentioned.",
                    "label": 0
                },
                {
                    "sent": "What we do usually with.",
                    "label": 0
                },
                {
                    "sent": "Regression, I just want to show how we need to look at.",
                    "label": 0
                },
                {
                    "sent": "Energy bra so we have a set of points.",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "And we can draw a best, best a line of best fits right now.",
                    "label": 0
                },
                {
                    "sent": "What we really do is actually the minimum squares.",
                    "label": 0
                },
                {
                    "sent": "Isn't it?",
                    "label": 0
                },
                {
                    "sent": "Least least quest of errors, so this would be an errors.",
                    "label": 0
                },
                {
                    "sent": "This with the error.",
                    "label": 0
                },
                {
                    "sent": "This would be an error displaying error error, not each of these points has an X&Y coordinate.",
                    "label": 0
                },
                {
                    "sent": "I'm working 2 dimensions because you can see that I hope you can hear me and I hope I'm not speaking too fast.",
                    "label": 0
                },
                {
                    "sent": "OK, alright so each one has an X&Y coordinates, right?",
                    "label": 0
                },
                {
                    "sent": "OK, now in trying to find this we have own ways of doing a regression, but as you mean S slash the number dimensions you guys actually do this OK.",
                    "label": 0
                },
                {
                    "sent": "But if you watch it carefully.",
                    "label": 0
                },
                {
                    "sent": "Obtain this care.",
                    "label": 0
                },
                {
                    "sent": "We were interested in obtaining some ways to MX plus C. Isn't it OK now?",
                    "label": 0
                },
                {
                    "sent": "At this point, let's call it something like two and three could be written as 2 = a certain constant.",
                    "label": 0
                },
                {
                    "sent": "Times 2 + 7 C right, but actually there are errors involved in getting this MSE.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to write a series of equations.",
                    "label": 0
                },
                {
                    "sent": "Assuming this is, let's see.",
                    "label": 0
                },
                {
                    "sent": "They see 3, seven for example.",
                    "label": 0
                },
                {
                    "sent": "We can also write 7 = 2 M 3 + C will have a series of equations.",
                    "label": 0
                },
                {
                    "sent": "OK, obviously we have equations.",
                    "label": 0
                },
                {
                    "sent": "You can actually build it as a matrix, isn't it?",
                    "label": 0
                },
                {
                    "sent": "Right, so when he is M&C they can put this out.",
                    "label": 0
                },
                {
                    "sent": "OK, can build a mattress and when the dimension become large obviously then we need some matrices to help solve it.",
                    "label": 0
                },
                {
                    "sent": "In fact we can rewrite this as a linear as an expression which is in quadratic form, right and then want to minimize the error and went right in quadratic form, but will get there as we go along.",
                    "label": 0
                },
                {
                    "sent": "We'll talk about some of this as we go along, but so the two main things to talk about.",
                    "label": 0
                },
                {
                    "sent": "Vector spaces, matrices and probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In addition, as well, it's a little bit, so that's kind of where we're going, so this is our outline.",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "I'm sure from your little bit already, but some of us are not.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using this activity so we change your mind, your memory to get some feedback and then we proceed from there because you actually meet it as we go along.",
                    "label": 0
                },
                {
                    "sent": "Now vector species.",
                    "label": 0
                },
                {
                    "sent": "We look at usually in school, do 2 dimensions.",
                    "label": 0
                },
                {
                    "sent": "In three dimensions.",
                    "label": 0
                },
                {
                    "sent": "We actually want to expand too because the properties of data that we're looking at has dimensions.",
                    "label": 0
                },
                {
                    "sent": "OK, so in dimensional space dimensional space you can have a vector from X1 components X one to XN.",
                    "label": 0
                },
                {
                    "sent": "Of course the transpose of it, and it's also true that the sum of two vectors would be another vector in that scene vector space, and we can have a scalar mode scalar multiply a vector instead.",
                    "label": 0
                },
                {
                    "sent": "Victor just a longer vector version of it.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "Whatever skills you choose, you would end up with another vector.",
                    "label": 0
                },
                {
                    "sent": "Whether companies choose individual vector.",
                    "label": 0
                },
                {
                    "sent": "Now this is true also for if you want to solve from genius differential equations, yes, process as a vector as well.",
                    "label": 0
                },
                {
                    "sent": "And of course this would be the second differential for differential equals 0.",
                    "label": 0
                },
                {
                    "sent": "There's no team does dependent on T by itself.",
                    "label": 0
                },
                {
                    "sent": "OK, now in that case also the negative of that function belongs to that scene vector space.",
                    "label": 0
                },
                {
                    "sent": "If you had any two of them so.",
                    "label": 0
                },
                {
                    "sent": "Belongs to that space and then again similar properties.",
                    "label": 0
                },
                {
                    "sent": "OK, but here you can also have just two dimensions using the Corsair sign you just toss DSPS.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obviously, right now we can also apply this, not just this also, but just any function.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you just take.",
                    "label": 0
                },
                {
                    "sent": "Any function at all you can apply similar rules OK and here also you find that as we are interested in a single function, the negative of it belongs.",
                    "label": 0
                },
                {
                    "sent": "That's in space.",
                    "label": 0
                },
                {
                    "sent": "If you have two functions you consume, them belongs in space and even multiplied by scalar velocity in space as well, right?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The DOT product remains the same.",
                    "label": 0
                },
                {
                    "sent": "The dot products.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's just look at the regular.",
                    "label": 0
                },
                {
                    "sent": "So we have him.",
                    "label": 0
                },
                {
                    "sent": "If you have X one X2X3 and we got this too lazy way.",
                    "label": 0
                },
                {
                    "sent": "One way to wait.",
                    "label": 0
                },
                {
                    "sent": "Three should remember those products X one and times 1 + X two times Y 2 + X three.",
                    "label": 0
                },
                {
                    "sent": "Thanks bye three scalar products.",
                    "label": 0
                },
                {
                    "sent": "The same happens for functions is also true for functions.",
                    "label": 0
                },
                {
                    "sent": "We just mostly functions and integrate over the area and if you want to find a norm the distance well this time or less between this and that is.",
                    "label": 0
                },
                {
                    "sent": "This square root of this square of each it's called which and then square root of it.",
                    "label": 0
                },
                {
                    "sent": "So in the same case we have F of X squared and then square root of it.",
                    "label": 0
                },
                {
                    "sent": "I guess it's clear any questions is fine, right?",
                    "label": 0
                },
                {
                    "sent": "I'm not going too fast.",
                    "label": 0
                },
                {
                    "sent": "Away.",
                    "label": 0
                },
                {
                    "sent": "We're just trying to play what we know already and extend it to end dimensional space to functions, differential equations, principles I see OK, I'm sure we remember the scalar product right and then the length is the square fish team.",
                    "label": 0
                },
                {
                    "sent": "Some of them square.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Write simple functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so more for more formal definition.",
                    "label": 0
                },
                {
                    "sent": "We can see a set.",
                    "label": 0
                },
                {
                    "sent": "S is the real vector space if addition still means you add it belongs in vector space, is commutative means X + y SM as well as X rite of society as well.",
                    "label": 1
                },
                {
                    "sent": "And we have the non elements you had zero to any other thing and it still stays the same and the negative it is invertible the negative.",
                    "label": 0
                },
                {
                    "sent": "It also belongs to same sets.",
                    "label": 0
                },
                {
                    "sent": "Multiplication by scalar.",
                    "label": 0
                },
                {
                    "sent": "I think I've talked about this before, but this is for real species, right?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We can also have.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space if you have a subspace is just a subset of what we have by the same rules apply.",
                    "label": 0
                },
                {
                    "sent": "This seems apply in the subspace right?",
                    "label": 0
                },
                {
                    "sent": "Then it's important because sometimes want to have subspecies that appendix at each other.",
                    "label": 0
                },
                {
                    "sent": "It's very or belong to same species.",
                    "label": 0
                },
                {
                    "sent": "Right now we can have two subspaces, FNG, right?",
                    "label": 0
                },
                {
                    "sent": "And if the intersection is not zero, if they don't overlap then together forms the full set full space right now.",
                    "label": 0
                },
                {
                    "sent": "If that is also true, then it is possible to express X in terms of 1 subspace in data service.",
                    "label": 0
                },
                {
                    "sent": "So if you use 2 dimensions you can have maybe an X component components together defining points with three dimensions you need three of them question.",
                    "label": 0
                },
                {
                    "sent": "So if you have two subspaces and they don't have any.",
                    "label": 0
                },
                {
                    "sent": "Then when you add them, you get a third space or the full.",
                    "label": 0
                },
                {
                    "sent": "Yes, there was the whole space.",
                    "label": 0
                },
                {
                    "sent": "A subspace is subset of it.",
                    "label": 0
                },
                {
                    "sent": "What if we have 1/3 space subspace?",
                    "label": 0
                },
                {
                    "sent": "Let's say if you H then then to be linearly dependent were dependent on there that you can express one in terms of a combination of the other.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah OK, but actually we spend a lot more time on orthonormal orthonormal orthogonal species causes yet represents things OK. OK alright so soft pieces.",
                    "label": 0
                },
                {
                    "sent": "You can generate them with a set of vectors, so in 3D space.",
                    "label": 0
                },
                {
                    "sent": "We can have this point as it has an X component.",
                    "label": 0
                },
                {
                    "sent": "Y component and as it components for example, X + y + Z.",
                    "label": 0
                },
                {
                    "sent": "So in that case you can have different constants multiplying the different components of the man gets a particular.",
                    "label": 0
                },
                {
                    "sent": "Particularly rates, and if they are linearly independent, the kids are asking the defendant by the linear independence, then this combination will be unique.",
                    "label": 0
                },
                {
                    "sent": "Right, it's kind of two versions of it.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, now the number of components you have would be the dimension, so we have XY, zed, then straight dimensions.",
                    "label": 0
                },
                {
                    "sent": "Just weeks and why there's two dimensions now.",
                    "label": 0
                },
                {
                    "sent": "I have a plane is one letter number of dimensions.",
                    "label": 0
                },
                {
                    "sent": "So in 3D space we have a clean like that do this.",
                    "label": 0
                },
                {
                    "sent": "So this could be a clean in the 3D speed.",
                    "label": 0
                },
                {
                    "sent": "We can reflect one thing with that in that in that screen.",
                    "label": 0
                },
                {
                    "sent": "OK, so that would be about clean so.",
                    "label": 0
                },
                {
                    "sent": "OK, great.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now let's look at the basis usually right edge key because they are perpendicular to each other.",
                    "label": 0
                },
                {
                    "sent": "For 3D space or the clearance piece.",
                    "label": 0
                },
                {
                    "sent": "Basis tend to be.",
                    "label": 0
                },
                {
                    "sent": "It means by which we can access a point or the means by which we can decompose a point, right?",
                    "label": 0
                },
                {
                    "sent": "How do you get to a particular point in space is a combination of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, scalar multiples of different components of the basis, right?",
                    "label": 0
                },
                {
                    "sent": "OK, now in space and here we are talking about the Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "You can have an infinite number of components, the incoming and large approaching Infinity, right?",
                    "label": 0
                },
                {
                    "sent": "OK, and usually they can be decomposition of wine into components.",
                    "label": 0
                },
                {
                    "sent": "Usually they can be.",
                    "label": 0
                },
                {
                    "sent": "Unique decomposition, so this tries to express it that if you have different components like XY and Z, something together to make one vector you have XYZ or in this case IGN keeping the basis OK.",
                    "label": 0
                },
                {
                    "sent": "Same is true for differential equations that CL two RBC species, right?",
                    "label": 0
                },
                {
                    "sent": "You can express intensive.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's insane, for example.",
                    "label": 0
                },
                {
                    "sent": "OK, the dot product.",
                    "label": 0
                },
                {
                    "sent": "What we did here before you can express more formally like this that you have D dimensional space and you want to do this and that you take the sum of X&Y over the whole space.",
                    "label": 0
                },
                {
                    "sent": "For the vector right, and it's very closely related to the inferior norm.",
                    "label": 0
                },
                {
                    "sent": "OK, so if its Axon itself, then the square root of its norm is distance.",
                    "label": 0
                },
                {
                    "sent": "OKOK so X 1 ^2 + X ^2 + 3 squared square root of it will give the distance.",
                    "label": 0
                },
                {
                    "sent": "But of course we can also express this if it's just two dimensions as this the angle between them being costita cosita X&Y.",
                    "label": 0
                },
                {
                    "sent": "It's now if it is if.",
                    "label": 0
                },
                {
                    "sent": "The angle is 0.",
                    "label": 0
                },
                {
                    "sent": "Then we know their angle is 90 linear, perpendicular, right?",
                    "label": 0
                },
                {
                    "sent": "OK, in that case.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You get 0.",
                    "label": 0
                },
                {
                    "sent": "OK, right?",
                    "label": 0
                },
                {
                    "sent": "So let's talk about the.",
                    "label": 0
                },
                {
                    "sent": "Norm again.",
                    "label": 0
                },
                {
                    "sent": "If Munoz is 0.",
                    "label": 0
                },
                {
                    "sent": "Then X must be 0.",
                    "label": 0
                },
                {
                    "sent": "That's the distance, right OK?",
                    "label": 0
                },
                {
                    "sent": "Right then you must face killer by Victor.",
                    "label": 0
                },
                {
                    "sent": "As it seems the scalar times the norm.",
                    "label": 0
                },
                {
                    "sent": "The models of scalar times vector is seamless.",
                    "label": 0
                },
                {
                    "sent": "The scalar times is known is OK right?",
                    "label": 0
                },
                {
                    "sent": "And if you have this one is important.",
                    "label": 0
                },
                {
                    "sent": "If you have some two vectors, it's normal would be less than.",
                    "label": 0
                },
                {
                    "sent": "The sum of the independent norms.",
                    "label": 0
                },
                {
                    "sent": "So is this actually means that the distance to any point is actually the shortest distance between two points.",
                    "label": 0
                },
                {
                    "sent": "Straight line between them rather than going through another point.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, I think this.",
                    "label": 0
                },
                {
                    "sent": "We've also gone over the DOT product.",
                    "label": 0
                },
                {
                    "sent": "Right, if it does seem victo descriptor gives you the norm and if you get exit web easier then the perpendicular to normal auto go now OK.",
                    "label": 0
                },
                {
                    "sent": "Right now, for every F has a unique orthogonal supplementary F perpendicular to its right.",
                    "label": 1
                },
                {
                    "sent": "In any space, you can always have one that's between you, Click to it, and if that is true, then convex press X in terms of the 1st and Espanola.",
                    "label": 0
                },
                {
                    "sent": "OK, I think this is just mathematical language.",
                    "label": 0
                },
                {
                    "sent": "We're seeing what we know already.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, now Hilbert space really extends beyond 3 dimensions and beyond like 3 and beyond OK. As a Hilbert space there, if you have space where we usually use to 3 dimensions, but here is peace and dimensions.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK, so this emphasizing orthonormal Autonoma, again, we can also apply this to differential equations, also in the lyrics piece as well.",
                    "label": 0
                },
                {
                    "sent": "The rules at the same author basis.",
                    "label": 0
                },
                {
                    "sent": "Each of these particular, and then we can have a unique combination of sums.",
                    "label": 0
                },
                {
                    "sent": "There is also the vector and if you want to find the norm we do this the norm.",
                    "label": 0
                },
                {
                    "sent": "Some of the squares of individual components.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I think I've talked about hyperplanes asking this one.",
                    "label": 0
                },
                {
                    "sent": "So that's vectors.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about matrices.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Everybody happy with this idea.",
                    "label": 0
                },
                {
                    "sent": "It wasn't too fast, so it was OK.",
                    "label": 0
                },
                {
                    "sent": "It's OK, OK, I didn't see I just kept repeating myself really OK.",
                    "label": 0
                },
                {
                    "sent": "So now let's talk about matrices.",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "This obviously is a system of equations like we did before, so they are constants times.",
                    "label": 1
                },
                {
                    "sent": "Variables OK equals zero.",
                    "label": 0
                },
                {
                    "sent": "In this case we can express it like this where you X = 0 system of equations.",
                    "label": 0
                },
                {
                    "sent": "We are happy with that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK right now OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now if.",
                    "label": 0
                },
                {
                    "sent": "You can expect you having matrix that is M by M rules by D columns.",
                    "label": 0
                },
                {
                    "sent": "OK, then the products that vector matrix vector products.",
                    "label": 0
                },
                {
                    "sent": "That's a mutant X can be done in two ways.",
                    "label": 0
                },
                {
                    "sent": "You can have use column vectors or can use reactors.",
                    "label": 0
                },
                {
                    "sent": "OK, so the temperature.",
                    "label": 0
                },
                {
                    "sent": "It could.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equal to something else.",
                    "label": 0
                },
                {
                    "sent": "It would be hard to something else so it could be equal to.",
                    "label": 0
                },
                {
                    "sent": "So in this case is not equal to 0 anymore.",
                    "label": 0
                },
                {
                    "sent": "If we quoted a constant or something, typically some set of constants.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one had zeros, but this one doesn't have zeros, but they seem similar set of equations.",
                    "label": 0
                },
                {
                    "sent": "There's no question.",
                    "label": 0
                },
                {
                    "sent": "Yeah, So what I'm saying is that you can have a set of questions they quoted zero you can express like this equal to 0, or if it's not equal to zero, we can still do the same.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To some constants this way, but it can be solved OK.",
                    "label": 0
                },
                {
                    "sent": "There are different ways of solving it.",
                    "label": 0
                },
                {
                    "sent": "You can use skimming through for example if it's simple enough.",
                    "label": 0
                },
                {
                    "sent": "Criminal rates.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. OK. Now if.",
                    "label": 0
                },
                {
                    "sent": "So we can.",
                    "label": 0
                },
                {
                    "sent": "We can look at the vector as do each one is a column, so this is a vector that's a vector that's a vector.",
                    "label": 0
                },
                {
                    "sent": "But together for some metrics.",
                    "label": 0
                },
                {
                    "sent": "OK, in that case you can express that original function as extend you right.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you can use.",
                    "label": 0
                },
                {
                    "sent": "You can treat everyone as a rule, so each rule in this one of the use OK and you can UX come written in this format.",
                    "label": 0
                },
                {
                    "sent": "That's you transpose times X dot product OK, it's the same as the norm matrix multiplication we know.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the usual notation for matrix this size of any size would be AIG, which goes from one to M and now goes from one to M&G, goes from one to N that represents this one for an M by D. OK, now the operations of matrices addition.",
                    "label": 0
                },
                {
                    "sent": "We just add ID to be ID for addition and if it's multiplication first of all if it's is in by P&B is P by D. Waltham, Columbia must be similar anymore Rules Day.",
                    "label": 0
                },
                {
                    "sent": "They can dream motivation.",
                    "label": 0
                },
                {
                    "sent": "P&P must be cool right?",
                    "label": 0
                },
                {
                    "sent": "If that is true, then 8 * B for each ID component is actually the sum of AI.",
                    "label": 0
                },
                {
                    "sent": "Key times be cagey, writes the kid 'cause we take each rule in each column at the time, but it is not.",
                    "label": 0
                },
                {
                    "sent": "Competitive.",
                    "label": 0
                },
                {
                    "sent": "Not as distributive.",
                    "label": 0
                },
                {
                    "sent": "OK now the transpose of matrix.",
                    "label": 0
                },
                {
                    "sent": "If you have a matrix E transpose, you simply replace the rules by the columns.",
                    "label": 0
                },
                {
                    "sent": "OK, so AIG becomes EJ for each each element in there.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I guess it's fine and we know this one.",
                    "label": 0
                },
                {
                    "sent": "OK, now schema traces, rules and more columns.",
                    "label": 0
                },
                {
                    "sent": "Equal and some come be invertible.",
                    "label": 0
                },
                {
                    "sent": "Someone invisible, some of them.",
                    "label": 0
                },
                {
                    "sent": "We can finally investigate.",
                    "label": 0
                },
                {
                    "sent": "Determinant is not very confining ways.",
                    "label": 0
                },
                {
                    "sent": "That mattress is the leading.",
                    "label": 0
                },
                {
                    "sent": "Set of all the elements on the diagonal and not 0.",
                    "label": 0
                },
                {
                    "sent": "Right and everything is zero.",
                    "label": 0
                },
                {
                    "sent": "We can also decompose a matrix into an upper triangular matrix and a lower triangular matrix, and that's particularly useful if you want to solve equations OK, because then you can sort the first line just one variable and substitute and carry on.",
                    "label": 0
                },
                {
                    "sent": "It's pretty quick.",
                    "label": 0
                },
                {
                    "sent": "OK now if a matrix and its transpose are equal, then is symmetric.",
                    "label": 0
                },
                {
                    "sent": "Bemidji stress was equally symmetric and if a matrix times its transpose or transpose of matches in itself and cause the unity matrix, which is which has one on alien agonal, then it's a unitary matrix OK and usually is the basis for forming.",
                    "label": 0
                },
                {
                    "sent": "So it's that much so final to normal basis, right?",
                    "label": 0
                },
                {
                    "sent": "Means that you can actually express other vectors in terms of it.",
                    "label": 0
                },
                {
                    "sent": "The vectors in terms of it.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so investing metrics first of all.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "If it's a diagonal matrix matrix, then none of the elements on the diagonal must be 0, otherwise they determined there because for a diagonal matrix the determinant really just a product of the elements of the diagonal given element zero.",
                    "label": 0
                },
                {
                    "sent": "We cannot be invited for Apartment Wrangler matches are so as well see if any element on the diagonal is zero.",
                    "label": 0
                },
                {
                    "sent": "We can't find anyways.",
                    "label": 0
                },
                {
                    "sent": "Right, OK?",
                    "label": 0
                },
                {
                    "sent": "Now suppose you have a system of equations like this, where there's a lower triangular matrix and every other thing is zero.",
                    "label": 0
                },
                {
                    "sent": "Want to solve this equation right?",
                    "label": 0
                },
                {
                    "sent": "As long as there's no zero in this line means there's an inverse.",
                    "label": 0
                },
                {
                    "sent": "Which music can be solved now?",
                    "label": 0
                },
                {
                    "sent": "This can be written like this, right?",
                    "label": 0
                },
                {
                    "sent": "This times that equals that as this one and this time is that this times that equals this, which is this one.",
                    "label": 0
                },
                {
                    "sent": "We can solve the first equation, get the X and substitutes in here X one and we can get text and keep going.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this gives us X1.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replace X1 and we can obtain X2.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Carry on that.",
                    "label": 0
                },
                {
                    "sent": "We installed the holding the case.",
                    "label": 0
                },
                {
                    "sent": "Actively OK determinants of the two by two matrix and determinant is 8 * D -- B * C. Everyone there are coming better in that case then versus this sub.",
                    "label": 1
                },
                {
                    "sent": "These two and indicates those two right?",
                    "label": 0
                },
                {
                    "sent": "That's the determinant an.",
                    "label": 0
                },
                {
                    "sent": "Now, in generally generally.",
                    "label": 0
                },
                {
                    "sent": "If there's a determinant, well, of course if there's a determinant is invertible and usually for square matrices, and they can be visible in the same conditions if there are no tools that are dependent on each other, that's one scalar multiple of the other.",
                    "label": 0
                },
                {
                    "sent": "Then you can do an invasion.",
                    "label": 0
                },
                {
                    "sent": "That's the determinant.",
                    "label": 0
                },
                {
                    "sent": "If one is a multiple of, that means that you can subtract and one rule from there.",
                    "label": 0
                },
                {
                    "sent": "Then you have a zero in a row and that means you can't base it.",
                    "label": 0
                },
                {
                    "sent": "There's no determinant.",
                    "label": 0
                },
                {
                    "sent": "OK, right now you can find recursively find the determinant is going to be OK according to this is going to be a certain element times is there?",
                    "label": 0
                },
                {
                    "sent": "That's cool fact, this right?",
                    "label": 0
                },
                {
                    "sent": "So if you take this one, find the determinant of this as in all elements screen destroy.",
                    "label": 0
                },
                {
                    "sent": "Times this value, right?",
                    "label": 0
                },
                {
                    "sent": "Thanks so possibly negative number.",
                    "label": 0
                },
                {
                    "sent": "If you take this one is going to be an order means excluding this column and this rule.",
                    "label": 0
                },
                {
                    "sent": "So this rule in this column they're going to use this number C and their numbers.",
                    "label": 0
                },
                {
                    "sent": "They define it.",
                    "label": 0
                },
                {
                    "sent": "So that's what this one is right now.",
                    "label": 0
                },
                {
                    "sent": "Either determinant is not zero, then there's one over determinant times transpose or the cofactors.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I hope that's OK.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right now this is the more interesting part.",
                    "label": 0
                },
                {
                    "sent": "The eigenvalues and eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "If you have a vector in D dimensional space, OK.",
                    "label": 0
                },
                {
                    "sent": "In the picture is not zero.",
                    "label": 0
                },
                {
                    "sent": "Then we can have an equation like vector matrix times vector equals X killer times in vector and if the determinant of that is 0 then you can find a Lambda.",
                    "label": 0
                },
                {
                    "sent": "Then the Lambda is adding value and the V is aging vector or the settling vectors OK. For diagonal matrices, Asian values are also the diagonal elements OK, and if it is zero if there is an edge in value then of course.",
                    "label": 1
                },
                {
                    "sent": "It's impossible.",
                    "label": 0
                },
                {
                    "sent": "Right, and this is a form that we are actually interested in.",
                    "label": 0
                },
                {
                    "sent": "If you can diagonalize a matrix, then you can express it like this, where D said I'm going to matrix and this is a matrix.",
                    "label": 0
                },
                {
                    "sent": "This times that is.",
                    "label": 0
                },
                {
                    "sent": "OK, let's talk.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little more.",
                    "label": 0
                },
                {
                    "sent": "OK. PTSD transpose gives you a OK, so we're interested in this form.",
                    "label": 0
                },
                {
                    "sent": "This diagonal and this times that gives you the identity matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, right now, that's also true for symmetric symmetric matrices, symmetric matrices and matrix and its transpose, equal times metrics and transposed identity matrix.",
                    "label": 0
                },
                {
                    "sent": "Now, if you do this, it gives you a scalar really.",
                    "label": 0
                },
                {
                    "sent": "If you do this same as unit productive now if it gives you a number that's zero or positive, we can describe the semi definite positive.",
                    "label": 0
                },
                {
                    "sent": "But if it gives you.",
                    "label": 0
                },
                {
                    "sent": "A positive number which is not zero then it's definitely.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Positive.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, is there any questions unknown?",
                    "label": 0
                },
                {
                    "sent": "OK, we're going to do.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at some decompositions in different forms, in which I spent some time in the lab today doing.",
                    "label": 0
                },
                {
                    "sent": "Where is the compositions?",
                    "label": 0
                },
                {
                    "sent": "OK, because that's how we can use it to solve some equations.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Governor then the eigenvalues are the elements of yeah, but The thing is, the agent values are not unique.",
                    "label": 0
                },
                {
                    "sent": "There's a whole range of them, yeah?",
                    "label": 0
                },
                {
                    "sent": "Define data and metrics Windows another.",
                    "label": 0
                },
                {
                    "sent": "Emetrics being diagonal, there's just elements are leading on the leading diagonal.",
                    "label": 0
                },
                {
                    "sent": "That's all zero.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, now if you have images that's not square like, imagine that is M * N. It's possible to express this intensive two or three other matrices.",
                    "label": 0
                },
                {
                    "sent": "We can find a matrix.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transpose times B, which is D dimensional.",
                    "label": 0
                },
                {
                    "sent": "Right, well that's deep ID OK. And we can't find something another matrix DN B transpose which also.",
                    "label": 0
                },
                {
                    "sent": "M by M is cut up into different elements.",
                    "label": 0
                },
                {
                    "sent": "Now if we have that then we can have forget this one.",
                    "label": 0
                },
                {
                    "sent": "Look at this you can have.",
                    "label": 0
                },
                {
                    "sent": "V * A diagonal diagonal matrix times this was transpose, which is D by D. They can have you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thanks transpose which is in by.",
                    "label": 0
                },
                {
                    "sent": "OK, it's possible to evaluate that, and that is.",
                    "label": 0
                },
                {
                    "sent": "So if you have these ones right and the elements and I'm gonna run on zero then on zero, then we can express the original matrix B in terms of.",
                    "label": 0
                },
                {
                    "sent": "This one's made this is M by D. Then this would be M by M and this would be by D * A second diagonal matrix that's the same as original becomes original.",
                    "label": 0
                },
                {
                    "sent": "OK so if this DD the dynamics you have this.",
                    "label": 0
                },
                {
                    "sent": "OK. OK now so this will be arriving at B transpose is v * D times you transpose where these data metrics.",
                    "label": 0
                },
                {
                    "sent": "Take a few minutes to three seconds.",
                    "label": 0
                },
                {
                    "sent": "Look at it again.",
                    "label": 0
                },
                {
                    "sent": "We're seeing that you can decompose an original matrix, which is M by N into three matrices.",
                    "label": 0
                },
                {
                    "sent": "One is a diagonal, the other is one that is square by them by M and another one which is North by.",
                    "label": 0
                },
                {
                    "sent": "Or divide in this case OK.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It gives you the same as.",
                    "label": 1
                },
                {
                    "sent": "The original.",
                    "label": 1
                },
                {
                    "sent": "OK. OK, and that is called a singular value decomposition with the Lambda.",
                    "label": 1
                },
                {
                    "sent": "The elements are diagonal, being the singular values.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "It's OK, OK?",
                    "label": 0
                },
                {
                    "sent": "Right now, that kind of decompositions which one to look at.",
                    "label": 0
                },
                {
                    "sent": "OK then.",
                    "label": 0
                },
                {
                    "sent": "Right, so we can.",
                    "label": 0
                },
                {
                    "sent": "We can also do Lu factorization where we have this like 2 matrices, right?",
                    "label": 0
                },
                {
                    "sent": "One is the El is their lower triangular matrix and they use an upper triangular matrix and the product will still give you the original matrix.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's possible to do.",
                    "label": 0
                },
                {
                    "sent": "In that case you can solve.",
                    "label": 0
                },
                {
                    "sent": "This expression as you have any questions so we can solve in two steps.",
                    "label": 1
                },
                {
                    "sent": "Because you write that equal eight X = B, but we are now seeing E is seamless Lu right times X = B. Alright, so now we can actually do.",
                    "label": 0
                },
                {
                    "sent": "We can solve.",
                    "label": 0
                },
                {
                    "sent": "Complete this way so we can write L, y = B, but that means that UX cause why.",
                    "label": 0
                },
                {
                    "sent": "Right, so you can solve this one first.",
                    "label": 0
                },
                {
                    "sent": "OK, so they're using you can solve this one first.",
                    "label": 0
                },
                {
                    "sent": "You can solve this office and it's all done right so.",
                    "label": 0
                },
                {
                    "sent": "OL U * X = B.",
                    "label": 0
                },
                {
                    "sent": "We don't know what taxes that were interested in, so we can replace the 8:00.",
                    "label": 0
                },
                {
                    "sent": "So by lnu, and in that case we can solve L * 8 = B and they can solve you times X because they solve in two steps.",
                    "label": 0
                },
                {
                    "sent": "There's always one unknown is often used to sort that out OK.",
                    "label": 0
                },
                {
                    "sent": "Right, so let's keep depending on where you come from.",
                    "label": 0
                },
                {
                    "sent": "Transfer this with the way OK for symmetric semidefinite positive matrices.",
                    "label": 1
                },
                {
                    "sent": "OK, we can also write 2 triangular matrices where it ranked matches any transpose equals Princess.",
                    "label": 0
                },
                {
                    "sent": "You transpose times, you will use an upper triangle matrix and again same principle you please.",
                    "label": 1
                },
                {
                    "sent": "This ESU transpose you and it's always in two steps.",
                    "label": 0
                },
                {
                    "sent": "The good thing is that there are tools to help us do the composition.",
                    "label": 1
                },
                {
                    "sent": "So cannot wait about.",
                    "label": 0
                },
                {
                    "sent": "The company so we should be using Octave which like Matlab identical to what life is here.",
                    "label": 1
                },
                {
                    "sent": "Right then there's also cure decomposition for any matrix that is M by R. You can express it.",
                    "label": 0
                },
                {
                    "sent": "As in terms of Q&R, where Q is a unity matrix and R is an upper triangular matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, I think that's what we do for matrices for now.",
                    "label": 0
                },
                {
                    "sent": "Zaki OK, so now we're going to.",
                    "label": 0
                },
                {
                    "sent": "Some probability.",
                    "label": 0
                },
                {
                    "sent": "You might not necessary member everything because you might not be working with everybody, but it brings back memories, so it's kind of the same with probability as well, and hopefully something will come back.",
                    "label": 0
                },
                {
                    "sent": "And then we can proceed.",
                    "label": 0
                },
                {
                    "sent": "Hope that's OK, so you can do it.",
                    "label": 0
                },
                {
                    "sent": "Determinant of four by four matrix.",
                    "label": 0
                },
                {
                    "sent": "Should be easy.",
                    "label": 0
                },
                {
                    "sent": "Thing is that we're going to use tools to do it, so it's not that difficult.",
                    "label": 0
                },
                {
                    "sent": "We just need to remember the concept.",
                    "label": 0
                },
                {
                    "sent": "Of course I want to research then really need to learn some more in this area.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Some definitions first an here looking at random variables.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Random speech Sam Omega is the set of all possibilities.",
                    "label": 1
                },
                {
                    "sent": "More less.",
                    "label": 0
                },
                {
                    "sent": "So if it was a coin, we are.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Better have hits orthus.",
                    "label": 0
                },
                {
                    "sent": "That's a set of data.",
                    "label": 0
                },
                {
                    "sent": "Who sits then?",
                    "label": 0
                },
                {
                    "sent": "We define it as a set of measurable.",
                    "label": 1
                },
                {
                    "sent": "And collection of events right?",
                    "label": 0
                },
                {
                    "sent": "So it costs once you get ahead or it gets a deal, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're tossing twice, you get hit at your head and so on.",
                    "label": 0
                },
                {
                    "sent": "Or you get nothing, right?",
                    "label": 0
                },
                {
                    "sent": "So there's a possibility.",
                    "label": 0
                },
                {
                    "sent": "OK, now probabilities always lie between 01.",
                    "label": 0
                },
                {
                    "sent": "And I think I don't need to emphasize that now.",
                    "label": 1
                },
                {
                    "sent": "If you're looking for hits, the probability of heads is P and the opposite is getting into is 1 -- P, right?",
                    "label": 0
                },
                {
                    "sent": "And if you want to get heads and tails, then the total of it is 1 probability of one.",
                    "label": 0
                },
                {
                    "sent": "OK, now this I think the essential things probably between zero and one.",
                    "label": 0
                },
                {
                    "sent": "They went North Korea.",
                    "label": 0
                },
                {
                    "sent": "Zero events.",
                    "label": 0
                },
                {
                    "sent": "Everything they said OK is 1 if you have two event out OK for this that the OK Together is this plus that OK and if the independent way they're dependent will look at that eventually, right?",
                    "label": 0
                },
                {
                    "sent": "But the whole set is this plus that either independent one of them is 0.",
                    "label": 0
                },
                {
                    "sent": "P. Intercession will be 0 in that case, just Adam.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now when we talk about measurability then there's there's more lesson invest investment function that preimage function that takes us back to the original OK.",
                    "label": 0
                },
                {
                    "sent": "Right now we can have variables that are discrete, so continuous, discrete or continuous OK, and what different distributions for it so discrete or continuous random variables?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I think I don't need to see too much on this one.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now you have been really variable, like a coin toss and I have a hit or two.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is how we want expressive probability.",
                    "label": 0
                },
                {
                    "sent": "OK, notation is X.",
                    "label": 0
                },
                {
                    "sent": "Am manually or the variable right?",
                    "label": 0
                },
                {
                    "sent": "And if it is binomial we use binomial OK.",
                    "label": 0
                },
                {
                    "sent": "When is binomial women having more trails OK?",
                    "label": 0
                },
                {
                    "sent": "Entrails, which would probably certain probability and for binomials before this as well, we're going to add if they each independent just adds the probabilities that your care together OK. And for binomials the probabilities.",
                    "label": 0
                },
                {
                    "sent": "Am North Trails, North Texas is probably the success probability of failure and minus key.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you're familiar this one in combination key.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now the expected values.",
                    "label": 0
                },
                {
                    "sent": "The mean is expected value.",
                    "label": 0
                },
                {
                    "sent": "OK, this is general form before.",
                    "label": 0
                },
                {
                    "sent": "In this particular case, expected value being X times probability of X or caring OK, and if it's discrete it's just a summation.",
                    "label": 0
                },
                {
                    "sent": "If it's continuous is an integral.",
                    "label": 0
                },
                {
                    "sent": "This is Constance gorgeous.",
                    "label": 0
                },
                {
                    "sent": "OK, fewer views.",
                    "label": 0
                },
                {
                    "sent": "Now the variance is.",
                    "label": 0
                },
                {
                    "sent": "The division of variables from the mean more less.",
                    "label": 0
                },
                {
                    "sent": "OK, so as expected.",
                    "label": 0
                },
                {
                    "sent": "Value of X minus the mean squared expected value of it, and this can be written like this.",
                    "label": 0
                },
                {
                    "sent": "An or can be written written like this.",
                    "label": 0
                },
                {
                    "sent": "X squared times probability and then extend probability or script.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK alright.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I think this repeats it and emphasizes the fact that measure some things are measurable.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a couple Bernoulli variables, more specifically any variables.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this case, disposition is is that OK?",
                    "label": 0
                },
                {
                    "sent": "So there's no OK.",
                    "label": 0
                },
                {
                    "sent": "So is submission of other possibilities right across it, so it's 0 * 1 -- P + 1 plus that you sleepy OK, and then for the variance will have summation of XI squared times P minus summation of.",
                    "label": 1
                },
                {
                    "sent": "An essay where P or squid OK works out to be P 1 -- P OK when you workout that variance and expectation.",
                    "label": 0
                },
                {
                    "sent": "Is this OK?",
                    "label": 0
                },
                {
                    "sent": "Generally F of X, right F of X times P, AF0 and F1 times P.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm sure we can all work it out if you take out three displays.",
                    "label": 0
                },
                {
                    "sent": "OK, Ann.",
                    "label": 0
                },
                {
                    "sent": "We can not move this onto victus.",
                    "label": 0
                },
                {
                    "sent": "OK, we have victus right then.",
                    "label": 0
                },
                {
                    "sent": "We now talk about.",
                    "label": 0
                },
                {
                    "sent": "Expectation being expectation of.",
                    "label": 0
                },
                {
                    "sent": "The different rules, of course is the vector is the transpose of this OK, and then we can talk about covariance matrix is the matrix and each element on the leading diagonal is the variance of of I.",
                    "label": 1
                },
                {
                    "sent": "But when it's not the leading diagonal, then is a covariance which is expressed like this.",
                    "label": 0
                },
                {
                    "sent": "Can I repeat that?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Right so we have a matrix or we have vectors then expectation.",
                    "label": 0
                },
                {
                    "sent": "Of X.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, for example an.",
                    "label": 0
                },
                {
                    "sent": "X1 card this distribution annex two can have this distribution right?",
                    "label": 0
                },
                {
                    "sent": "Just cause 1X1 and X2AD correlated.",
                    "label": 0
                },
                {
                    "sent": "Then the covariance itself is 0 now expected value of this is expected value of that end that we know for manually expected values P. Or is your success.",
                    "label": 0
                },
                {
                    "sent": "So if you're an MP, two covariance matrix on the leading diagonal with a variance of X, one X2 and the ones that are not on the leading diagonal.",
                    "label": 0
                },
                {
                    "sent": "Recurrence of X2X1X1X2.",
                    "label": 0
                },
                {
                    "sent": "This is the coordinates.",
                    "label": 0
                },
                {
                    "sent": "In this position, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that results we already know what the variance is and what the covariance is in this case.",
                    "label": 0
                },
                {
                    "sent": "It's OK.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, now we look at discrete.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at.",
                    "label": 0
                },
                {
                    "sent": "Am continuous right continuous?",
                    "label": 0
                },
                {
                    "sent": "In that case, where about this summation replace with an integral?",
                    "label": 0
                },
                {
                    "sent": "OK, and then we have probability distribution functions also.",
                    "label": 0
                },
                {
                    "sent": "So the purpose is density function.",
                    "label": 0
                },
                {
                    "sent": "If everywhere you find deep differential of P of X right there becomes the probability density function so that we intend to integrate and expected value is integral over this piece of X DX, just as we did before and the variances.",
                    "label": 1
                },
                {
                    "sent": "Expected value of X minus expected value of X ^2.",
                    "label": 0
                },
                {
                    "sent": "Seem right, just whereby summation now becomes an integral.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can I go for it?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, now let's look at the uniform distribution is continuous, uniform right?",
                    "label": 0
                },
                {
                    "sent": "So the expected value of the distribution as X and the form is uniform between A&B, right?",
                    "label": 0
                },
                {
                    "sent": "So that would mean that it would look like that.",
                    "label": 0
                },
                {
                    "sent": "So between A&B in between tables out of SYMLIN have equal probability right?",
                    "label": 0
                },
                {
                    "sent": "And so for that one expected values fix.",
                    "label": 0
                },
                {
                    "sent": "PDX, which is which values to this one?",
                    "label": 0
                },
                {
                    "sent": "Because actually the function is always 1 / B -- C, right?",
                    "label": 0
                },
                {
                    "sent": "So this is published density function.",
                    "label": 0
                },
                {
                    "sent": "Then for the Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "Like there no more.",
                    "label": 0
                },
                {
                    "sent": "The Belk if an we have the same thing.",
                    "label": 0
                },
                {
                    "sent": "I said value is FX DX right and so we can.",
                    "label": 0
                },
                {
                    "sent": "Evaluate this, which usually rates for anybody.",
                    "label": 0
                },
                {
                    "sent": "Whether the definition for it, and there's a probability density function for it, OK?",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. AM.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we talk about vector spaces also for vector spaces the same thing, But this time.",
                    "label": 0
                },
                {
                    "sent": "We are placing X with a set of vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, not a single variable anymore, so it's a set of vectors and this is what the probability density function is.",
                    "label": 0
                },
                {
                    "sent": "We're going to do.",
                    "label": 0
                },
                {
                    "sent": "Determinant of the matrix, right?",
                    "label": 0
                },
                {
                    "sent": "And then we shall also have the expected value is an integral over the vector.",
                    "label": 0
                },
                {
                    "sent": "Right, OK?",
                    "label": 0
                },
                {
                    "sent": "I don't think we're going to do this, but it's just translates whatever it is in for continuous functions.",
                    "label": 0
                },
                {
                    "sent": "Now, is it better?",
                    "label": 0
                },
                {
                    "sent": "Vector of.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, now let's look at joint probabilities was quite more related to learning.",
                    "label": 0
                },
                {
                    "sent": "Something happens.",
                    "label": 0
                },
                {
                    "sent": "You want to see what we can learn from it for the future.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at the case where we cost 2 coins for BitTorrent.",
                    "label": 0
                },
                {
                    "sent": "Fair coiners half OK. Now suppose that you're going to toss twice.",
                    "label": 0
                },
                {
                    "sent": "But the point of getting two hits it's half times half right because head is having itself.",
                    "label": 0
                },
                {
                    "sent": "So for ease of getting any two of them will be worth 1/4.",
                    "label": 0
                },
                {
                    "sent": "Just multiply them, right?",
                    "label": 0
                },
                {
                    "sent": "As because they're independent.",
                    "label": 0
                },
                {
                    "sent": "When one happens there.",
                    "label": 0
                },
                {
                    "sent": "So mean that's the next thing will happen.",
                    "label": 0
                },
                {
                    "sent": "Also, it's just independent.",
                    "label": 0
                },
                {
                    "sent": "There's no intersection.",
                    "label": 0
                },
                {
                    "sent": "OK, so probability of a anvil Karen is a probability of Ethan's policy of B. OK, right?",
                    "label": 0
                },
                {
                    "sent": "That's the same, and then their independence.",
                    "label": 0
                },
                {
                    "sent": "OK, but that's not necessary.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically this look at the.",
                    "label": 0
                },
                {
                    "sent": "From this chat will be the probability.",
                    "label": 0
                },
                {
                    "sent": "Let's assume the test done there, some sick people, and then there's some healthy people and but there are some secret positive tests and there's some.",
                    "label": 0
                },
                {
                    "sent": "And healthy people who also had a positive test.",
                    "label": 0
                },
                {
                    "sent": "OK. And then there's also those who are sick by the test, retain negative, and then those who are alright.",
                    "label": 0
                },
                {
                    "sent": "My test returned positive.",
                    "label": 0
                },
                {
                    "sent": "OK, now what's the problem?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See that person is positive.",
                    "label": 0
                },
                {
                    "sent": "Probably a person is positive would be 90 + 100.",
                    "label": 0
                },
                {
                    "sent": "Also, the population isn't it, so it's 190 / 1 zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's this.",
                    "label": 0
                },
                {
                    "sent": "The testing is positive now.",
                    "label": 0
                },
                {
                    "sent": "Probably the person is sick would be 90 plus this with hundred out of the total.",
                    "label": 0
                },
                {
                    "sent": "OK so that's 101 thing right now.",
                    "label": 0
                },
                {
                    "sent": "What's the probability that person is positive and sick?",
                    "label": 0
                },
                {
                    "sent": "You'd be inclined to modify these two, but to give you the wrong answer.",
                    "label": 0
                },
                {
                    "sent": "OK, for this person is positive and seek positive.",
                    "label": 0
                },
                {
                    "sent": "Is this 90 and sick is worth?",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "Ticket.",
                    "label": 0
                },
                {
                    "sent": "And positive person is positive, sorry is sick, sick is this hundred OK and the probability that person is?",
                    "label": 0
                },
                {
                    "sent": "OK, let me just check it again.",
                    "label": 0
                },
                {
                    "sent": "OK so if only to the person is positive positive, is this rule OK?",
                    "label": 0
                },
                {
                    "sent": "And then for each of the person is sick this column right?",
                    "label": 0
                },
                {
                    "sent": "So it should be this way that sometimes this over that's OK. Actually it's not be correct.",
                    "label": 0
                },
                {
                    "sent": "Isn't it?",
                    "label": 0
                },
                {
                    "sent": "You can just play them OK?",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "So this was the perfect person.",
                    "label": 0
                },
                {
                    "sent": "Actually positive messages.",
                    "label": 0
                },
                {
                    "sent": "Just this number, isn't it?",
                    "label": 0
                },
                {
                    "sent": "It's just he's seeking positive out of the total population is not the same as multiplying two together one like this must find this in that it's not correct.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that leads to dependence.",
                    "label": 0
                },
                {
                    "sent": "Write an.",
                    "label": 0
                },
                {
                    "sent": "If two probabilities are independent, or if two variables are independent, then the probabilities can just be multiplied because they don't.",
                    "label": 1
                },
                {
                    "sent": "There's no dependence on between them, I just multiply them by their notes.",
                    "label": 0
                },
                {
                    "sent": "Then we have to work with it differently.",
                    "label": 0
                },
                {
                    "sent": "You have to subtract the intersection.",
                    "label": 0
                },
                {
                    "sent": "OK, so for all A&B, publisher of the two of them were carrying is just that.",
                    "label": 0
                },
                {
                    "sent": "If the independent right inverse continuous, there's the.",
                    "label": 0
                },
                {
                    "sent": "Let's say sorry then expected value expected value is.",
                    "label": 0
                },
                {
                    "sent": "The product expected the predictor expected values.",
                    "label": 0
                },
                {
                    "sent": "Expected value is expected by these right now if they are independent then the covariance between them is also zero through the independent.",
                    "label": 1
                },
                {
                    "sent": "And for question variables only.",
                    "label": 0
                },
                {
                    "sent": "Equivalence is there.",
                    "label": 0
                },
                {
                    "sent": "We also means that.",
                    "label": 0
                },
                {
                    "sent": "Their orthogonal, they are independent.",
                    "label": 0
                },
                {
                    "sent": "Right now, the independence, knowing about one or does not give any information about the other 'cause they're completely dependent.",
                    "label": 1
                },
                {
                    "sent": "OK, but now let's talk about the cases where.",
                    "label": 0
                },
                {
                    "sent": "There's some dependence like that.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example that we saw when there's no difference there cancel one gives information about another possibility.",
                    "label": 0
                },
                {
                    "sent": "Right, so what's the probability of someone being?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sick.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But this one is being sick is 100 out of out of that now the probability that person is well, it's thousand over.",
                    "label": 0
                },
                {
                    "sent": "That's OK. Now if you have a positive test.",
                    "label": 0
                },
                {
                    "sent": "What's the probability they also seek?",
                    "label": 0
                },
                {
                    "sent": "Now there's some dependence, right?",
                    "label": 0
                },
                {
                    "sent": "So what's the police?",
                    "label": 0
                },
                {
                    "sent": "They are given that you had a positive test for safe tests, which we had a positive test.",
                    "label": 1
                },
                {
                    "sent": "It is either this or that's right, but what they seek in positive is 90 out of 190.",
                    "label": 0
                },
                {
                    "sent": "Is there OK?",
                    "label": 0
                },
                {
                    "sent": "OK now what's the problem that will fit given that her positive test is going to be this divide by 190.",
                    "label": 0
                },
                {
                    "sent": "OK, now how about those who are negative things?",
                    "label": 0
                },
                {
                    "sent": "Just just the numbers right?",
                    "label": 1
                },
                {
                    "sent": "Negative test with this 10 out of 19 and the fits behind native tests 90.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're going to use that to do.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do other things.",
                    "label": 0
                },
                {
                    "sent": "And this just repeat of what you saw.",
                    "label": 0
                },
                {
                    "sent": "What's the probability that we were sick given that way negative?",
                    "label": 0
                },
                {
                    "sent": "And it's actually negative.",
                    "label": 0
                },
                {
                    "sent": "There's a probability that there are sick and negative.",
                    "label": 0
                },
                {
                    "sent": "Purpose of sick and negative right now give us a conditional probability with your product.",
                    "label": 0
                },
                {
                    "sent": "OK, so sick and negative would be probably the way sick give their negative.",
                    "label": 0
                },
                {
                    "sent": "Give tons of quality that we actually negative.",
                    "label": 0
                },
                {
                    "sent": "OK. OK.",
                    "label": 0
                },
                {
                    "sent": "So sick and native probability of sick or negative transferability of sick and negative.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so in a more general expression.",
                    "label": 0
                },
                {
                    "sent": "Am is probably off way.",
                    "label": 0
                },
                {
                    "sent": "Times probability of X given Y.",
                    "label": 1
                },
                {
                    "sent": "That gives us probability of X in working order of X&Y OK. OK. OK, that's the same thing, but we'll figure ways probably why given X, that will be suffix.",
                    "label": 0
                },
                {
                    "sent": "OK. M and we extend it to the case where you have quality density functions.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now let's look at the issue.",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "So we define Y as a random variable that we actually observed, event or caring, and it is the is the random variable that interesting, and the goal is to.",
                    "label": 1
                },
                {
                    "sent": "Observe way given and find the best guess for for data.",
                    "label": 1
                },
                {
                    "sent": "So that's something we're trying to.",
                    "label": 0
                },
                {
                    "sent": "We're trying to drive some inference from some other event occurring like this is positive by the potentially sick.",
                    "label": 0
                },
                {
                    "sent": "So do some tests and other people are positive.",
                    "label": 0
                },
                {
                    "sent": "But what's the probability that they actually sick, right?",
                    "label": 0
                },
                {
                    "sent": "So we know we can probably test whether if sick or not.",
                    "label": 0
                },
                {
                    "sent": "I can do a test to see whether positive or negative, so that kind of thing we're going to do.",
                    "label": 0
                },
                {
                    "sent": "So we're going to have a prior and posterior prior is we can actually measure the procedure is.",
                    "label": 0
                },
                {
                    "sent": "Variance we can grow.",
                    "label": 0
                },
                {
                    "sent": "OK right now.",
                    "label": 0
                },
                {
                    "sent": "Please.",
                    "label": 0
                },
                {
                    "sent": "OK, followed just did before probability of.",
                    "label": 0
                },
                {
                    "sent": "And we can have probably 4 bit of extra positive way and they can have probability of X giving way same probability of X given way.",
                    "label": 0
                },
                {
                    "sent": "Is actually probability of.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "XNY driveway publisher way.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can write the probability of X indecision.",
                    "label": 0
                },
                {
                    "sent": "Why cause probability of X given Y?",
                    "label": 0
                },
                {
                    "sent": "Thanks probability of way.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's the basic and we extend in the case of the issue.",
                    "label": 0
                },
                {
                    "sent": "OK, now if we had.",
                    "label": 0
                },
                {
                    "sent": "If you have, this is just two possibilities.",
                    "label": 0
                },
                {
                    "sent": "Either X or case.",
                    "label": 0
                },
                {
                    "sent": "Oreg does not care.",
                    "label": 0
                },
                {
                    "sent": "OK, well OK, so why does not OK?",
                    "label": 0
                },
                {
                    "sent": "Alright then probability of X or caring actually is probability of Y given that X or Kate.",
                    "label": 0
                },
                {
                    "sent": "AM and then probability of Y given X is not K. This gives us the probability of why 'cause?",
                    "label": 0
                },
                {
                    "sent": "I thought we were case.",
                    "label": 0
                },
                {
                    "sent": "Lucky right now we try to extend here, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in probability of.",
                    "label": 0
                },
                {
                    "sent": "Him.",
                    "label": 0
                },
                {
                    "sent": "I'm just trying to put my thoughts together to write this will.",
                    "label": 0
                },
                {
                    "sent": "No Jesse.",
                    "label": 0
                },
                {
                    "sent": "OK great, so basically I want you to please this one.",
                    "label": 0
                },
                {
                    "sent": "I want to put this one here.",
                    "label": 0
                },
                {
                    "sent": "Lucky because this part is away, so it means I'm actually going to some probability of.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Given all the possibilities of X moreles.",
                    "label": 0
                },
                {
                    "sent": "Very places this one makes sense.",
                    "label": 0
                },
                {
                    "sent": "Search repeated.",
                    "label": 0
                },
                {
                    "sent": "Repeat it OK. OK, so probably 2 E giving that via case is seen as probability of A&B vary by probability of B. OK, right, and we can also probability of.",
                    "label": 0
                },
                {
                    "sent": "An given B times probability of BOSP of a decision B.",
                    "label": 0
                },
                {
                    "sent": "And this seemed P of a given B can also be written as P of B given a nice probability of a this equivalence.",
                    "label": 0
                },
                {
                    "sent": "OK and just trying to explain that.",
                    "label": 0
                },
                {
                    "sent": "Probably let's be orchis.",
                    "label": 0
                },
                {
                    "sent": "Given that your kid or Aiden or K. The combination gives us the fact that be OK. Alright, so probably that your case is similar with the B orchid.",
                    "label": 0
                },
                {
                    "sent": "In the ER, soak it right or probability of your caring, given that he did not OK, OK, sorry that's OK.",
                    "label": 0
                },
                {
                    "sent": "But whenever we build case, so that's some gives this right.",
                    "label": 1
                },
                {
                    "sent": "I'm trying to replace this one with this one so I can write an probability of a intersection.",
                    "label": 0
                },
                {
                    "sent": "B is seamless probability of some of the probability of B, given that.",
                    "label": 0
                },
                {
                    "sent": "E. OK senior, any component of your case.",
                    "label": 0
                },
                {
                    "sent": "So we just sum the whole which about your case.",
                    "label": 0
                },
                {
                    "sent": "But given that that's possible at your kid, but we can't replace this one with an expression like this, right P of a given B is seamless.",
                    "label": 0
                },
                {
                    "sent": "An appeal of Intercession B.",
                    "label": 0
                },
                {
                    "sent": "Is coming written as this one?",
                    "label": 0
                },
                {
                    "sent": "During the session become richness so I can replace this with Pio Pio V as this one given a 10 speed of A equals OK, it seems this divided by summation of P of B given a.",
                    "label": 0
                },
                {
                    "sent": "In this case, this just to ease, but as you open up for all possibilities, then in particular G. Then this will be from 8 to 10.",
                    "label": 0
                },
                {
                    "sent": "Where this is particularly out of the Lords and then this is.",
                    "label": 0
                },
                {
                    "sent": "For all of it, so that we have written here, right in the same way, so you have P of Y given the type of data and P of Y given data.",
                    "label": 0
                },
                {
                    "sent": "Again times period data.",
                    "label": 0
                },
                {
                    "sent": "But this one has.",
                    "label": 0
                },
                {
                    "sent": "All the possibilities and this particular one of it's just as we have here.",
                    "label": 0
                },
                {
                    "sent": "Is it OK?",
                    "label": 0
                },
                {
                    "sent": "This one is OK. OK so this will be continuous.",
                    "label": 0
                },
                {
                    "sent": "Nobody happy.",
                    "label": 0
                },
                {
                    "sent": "Oh it's repeated.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that really be true.",
                    "label": 0
                },
                {
                    "sent": "If you know certain things, even though that B has a kid given that.",
                    "label": 0
                },
                {
                    "sent": "In fact, all you're trying to do here is trading value, it's.",
                    "label": 0
                },
                {
                    "sent": "And P of.",
                    "label": 0
                },
                {
                    "sent": "P of E giving up your case where expressing tense of B given that your kid very expressing the opposite of it OK.",
                    "label": 0
                },
                {
                    "sent": "Copy that EG or case giving up your case.",
                    "label": 0
                },
                {
                    "sent": "We do this becauses the beacon measure we can measure the.",
                    "label": 0
                },
                {
                    "sent": "Right, OK, so that's the idea.",
                    "label": 0
                },
                {
                    "sent": "So we know some.",
                    "label": 0
                },
                {
                    "sent": "Some condition we know it prior condition and use that to estimate the posterior right 'cause there's something major in order to make inferences about about other things OK.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK then, let's talk a bit about entropy.",
                    "label": 0
                },
                {
                    "sent": "Entropy really is the amount of disorder.",
                    "label": 0
                },
                {
                    "sent": "It's got applications in Mo dynamics.",
                    "label": 0
                },
                {
                    "sent": "But here in this case we talk about in terms of information theory.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so entropies this state of disorder an.",
                    "label": 0
                },
                {
                    "sent": "And is expressed in terms of a log.",
                    "label": 1
                },
                {
                    "sent": "So entropy itself is the probability times probability.",
                    "label": 0
                },
                {
                    "sent": "The log of the probability.",
                    "label": 0
                },
                {
                    "sent": "OK, now the reason the user logs as big 'cause once we do add if two events or case theorems OK is probably one times that.",
                    "label": 0
                },
                {
                    "sent": "By and large we just Adam.",
                    "label": 0
                },
                {
                    "sent": "So that's behind.",
                    "label": 0
                },
                {
                    "sent": "They look OK for discrete random variables.",
                    "label": 1
                },
                {
                    "sent": "I remember this one.",
                    "label": 0
                },
                {
                    "sent": "I need to just check in February.",
                    "label": 0
                },
                {
                    "sent": "This one actually stands for a country right now.",
                    "label": 0
                },
                {
                    "sent": "OK, now they are there, they know of.",
                    "label": 0
                },
                {
                    "sent": "Theorems that help us know how to bits of information related.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, now if you've got two variables.",
                    "label": 0
                },
                {
                    "sent": "OK, this expression here tells you how related the how related two piece of information as if evaluate this and it gives you a zero.",
                    "label": 0
                },
                {
                    "sent": "It means that actually you have not learned anything, right?",
                    "label": 0
                },
                {
                    "sent": "It's two things that they seem OK. Now we entropy is interesting.",
                    "label": 0
                },
                {
                    "sent": "'cause if you're tossing, let's see dice tossing coins.",
                    "label": 1
                },
                {
                    "sent": "And it is a double headed coin.",
                    "label": 0
                },
                {
                    "sent": "OK, now the entropy there is zero because you're not learning anything anything it tells you definitely hit.",
                    "label": 0
                },
                {
                    "sent": "So the interpreter is there, but if you have a fair coin we have ahead and until everything it 'cause you don't know what will happen next.",
                    "label": 0
                },
                {
                    "sent": "Right, so the expectation is this kind of the highest entropy itself lies between.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "In this case there in.",
                    "label": 0
                },
                {
                    "sent": "And one.",
                    "label": 0
                },
                {
                    "sent": "OK, so the information that you also sort of information is.",
                    "label": 0
                },
                {
                    "sent": "Is the cubic labor divergance for XY and then?",
                    "label": 0
                },
                {
                    "sent": "X&Y.",
                    "label": 1
                },
                {
                    "sent": "OK. And then the perplexity is too, is the power.",
                    "label": 0
                },
                {
                    "sent": "The entropy as well?",
                    "label": 0
                },
                {
                    "sent": "Send it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK at questions on this one.",
                    "label": 0
                },
                {
                    "sent": "I wish you could prove it.",
                    "label": 0
                },
                {
                    "sent": "OK, I can go by this again.",
                    "label": 0
                },
                {
                    "sent": "Let me just make it difference.",
                    "label": 0
                },
                {
                    "sent": "OK, right, so this is entropy.",
                    "label": 1
                },
                {
                    "sent": "I think the entropy one is clear with a lot of the probability times of probabilities of the entropy that this is an.",
                    "label": 0
                },
                {
                    "sent": "The amount of disorder in there.",
                    "label": 1
                },
                {
                    "sent": "Now the reason we do this is to is also OK. Actually what happens is that the X is what we're measuring and why is a model that we have right?",
                    "label": 0
                },
                {
                    "sent": "So we have a model that we used to predict X is the models to predict where the model is to predict X. OK, so we have.",
                    "label": 0
                },
                {
                    "sent": "Where is available that we can model we built and this is what we're actually trying to estimate.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the event OK, and for do this even integral integral of probability of this times log of this minus this about that logo for dinner or the difference?",
                    "label": 0
                },
                {
                    "sent": "OK, it gives us a value such that this is not actually quoted that, but when it is equal to 0 it means that our model closely matches the other one, right?",
                    "label": 0
                },
                {
                    "sent": "Actually identical.",
                    "label": 0
                },
                {
                    "sent": "Addictive, OK, but typically it is positive.",
                    "label": 0
                },
                {
                    "sent": "Typically, this positive right and then the mutual information is shared information between the two of them, right as in.",
                    "label": 1
                },
                {
                    "sent": "I have had it model.",
                    "label": 0
                },
                {
                    "sent": "OK, so the this time you've already seen function, but this is P X * P of X * 5 Y and.",
                    "label": 0
                },
                {
                    "sent": "No, I think I'll skip this one and I'll come back to it because I'm mixing up two other things, so I see if not for me to comment on it just now, then I'll come back to it.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Arrange which one there.",
                    "label": 0
                },
                {
                    "sent": "Call back inhabitants yeah.",
                    "label": 0
                },
                {
                    "sent": "Is better than zero.",
                    "label": 0
                },
                {
                    "sent": "I think there are two one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's one, that's one.",
                    "label": 0
                },
                {
                    "sent": "Skip this one off.",
                    "label": 0
                },
                {
                    "sent": "Please come back to it so they don't screw their information.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now let's look at the confidence intervals.",
                    "label": 0
                },
                {
                    "sent": "For example in approximations.",
                    "label": 0
                },
                {
                    "sent": "OK, Ann.",
                    "label": 0
                },
                {
                    "sent": "We want to be sure that when we build, we have a model the mean of.",
                    "label": 0
                },
                {
                    "sent": "Distribution lists within a certain range.",
                    "label": 0
                },
                {
                    "sent": "OK, the mean of a sample lies within a certain range of the population mean.",
                    "label": 0
                },
                {
                    "sent": "For example, let's make sense.",
                    "label": 0
                },
                {
                    "sent": "So there's a population we can't actually check the whole population, but so we take a sample, right?",
                    "label": 0
                },
                {
                    "sent": "Want to have a certain assurance that our average we calculate actually less units in range of the population average?",
                    "label": 0
                },
                {
                    "sent": "That's where these things come in.",
                    "label": 0
                },
                {
                    "sent": "Now, Markov inequality says that.",
                    "label": 0
                },
                {
                    "sent": "Let me just check what he says.",
                    "label": 0
                },
                {
                    "sent": "The Markov inequality gives an upper bound for the probability that the sweater value is above some constant, right?",
                    "label": 0
                },
                {
                    "sent": "So expected value actually is kind of the limit, and it's above.",
                    "label": 0
                },
                {
                    "sent": "This will always be less than this one.",
                    "label": 0
                },
                {
                    "sent": "OK, so expected value always be less than some particular range.",
                    "label": 0
                },
                {
                    "sent": "It gives up a bunch of it.",
                    "label": 0
                },
                {
                    "sent": "Now should be chef one, the chef inequality.",
                    "label": 0
                },
                {
                    "sent": "We can be sure that nearly all values are close to the mean and no more than one of us epsilon squared for the distribution.",
                    "label": 0
                },
                {
                    "sent": "It's more than a standard division.",
                    "label": 0
                },
                {
                    "sent": "Are we right?",
                    "label": 0
                },
                {
                    "sent": "So this is 1 version over this difference inequality that should be shared one and that says that.",
                    "label": 0
                },
                {
                    "sent": "Am nearly all values.",
                    "label": 0
                },
                {
                    "sent": "That will work with we closely mean and no more than.",
                    "label": 0
                },
                {
                    "sent": "This distance away epsilon squared distance are we.",
                    "label": 0
                },
                {
                    "sent": "Find for side-by-side vision OK.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And this one has to do with bounds on till distributions until distributions.",
                    "label": 0
                },
                {
                    "sent": "I can't really explain this one's a lot more than this so I can come back to it.",
                    "label": 0
                },
                {
                    "sent": "Additional information, but.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm not an expert on this particular.",
                    "label": 0
                },
                {
                    "sent": "AM.",
                    "label": 0
                },
                {
                    "sent": "Alright, see about this is these are bounds on estimates.",
                    "label": 0
                },
                {
                    "sent": "OK, that's why else for now, but it's also been a lecture, so that's.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a cut in my edition minimization little.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have a cave.",
                    "label": 0
                },
                {
                    "sent": "And it's quite easy to find the minimum point within the first differential, and if it's zero, suggests that it might be a minimum, maximum.",
                    "label": 0
                },
                {
                    "sent": "Or it could be a saddle point.",
                    "label": 0
                },
                {
                    "sent": "It could be like that.",
                    "label": 0
                },
                {
                    "sent": "Alright, so at this point it's not anymore so much it just say point of inflection right?",
                    "label": 0
                },
                {
                    "sent": "So that alone.",
                    "label": 0
                },
                {
                    "sent": "So we take the second differential also and when the second differential is positive then we know it's a minimum point.",
                    "label": 0
                },
                {
                    "sent": "OK, but the other things other considerations.",
                    "label": 0
                },
                {
                    "sent": "Sometimes my heart function that is just.",
                    "label": 0
                },
                {
                    "sent": "That is like this.",
                    "label": 0
                },
                {
                    "sent": "Alright then it's fine between this and that.",
                    "label": 0
                },
                {
                    "sent": "OK, so it doesn't actually get to attending points, but this actually is a minimum for it.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's something to pay attention to, and so we can always have 000.",
                    "label": 0
                },
                {
                    "sent": "Not always.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And just because the gradient is there does not mean it's a minimum requirement or inflection.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right and then we also sometimes interesting global minimum.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so we might be that.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Cave might itself be like this, so my working around.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think it is a minimum bachelors.",
                    "label": 0
                },
                {
                    "sent": "Under the minimum somewhere.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right so then the other algorithms that can help us determine.",
                    "label": 0
                },
                {
                    "sent": "When they agreed in the sense we can use it cause Newton method or the clinic within decent.",
                    "label": 0
                },
                {
                    "sent": "They're iterative methods for calculating.",
                    "label": 0
                },
                {
                    "sent": "Calculating the minimum.",
                    "label": 0
                },
                {
                    "sent": "If you like.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "OK. Write every talk about convex functions, convex functions.",
                    "label": 0
                },
                {
                    "sent": "Functions like that.",
                    "label": 0
                },
                {
                    "sent": "They are pretty concave, but these are convex function and we can determine points if you by taking a look at this.",
                    "label": 0
                },
                {
                    "sent": "OK, so we know the middle point somewhere between, let's say X1.",
                    "label": 0
                },
                {
                    "sent": "And X2 we can find.",
                    "label": 0
                },
                {
                    "sent": "If there is really a mini point now, the condition is we have to look for another point here.",
                    "label": 0
                },
                {
                    "sent": "So let's say this is F of this is F. Of this F of X1, this is F of X2.",
                    "label": 0
                },
                {
                    "sent": "That OK we take a point that is in between.",
                    "label": 0
                },
                {
                    "sent": "Here on an interval between 01 and if F of X + a constant.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Let's see let me just write this, but yeah, OK, that's it.",
                    "label": 0
                },
                {
                    "sent": "So we're going to find we're going to use a constant between zero and one OK, and so F of X + a constant plus one minus the constant Times X2, right?",
                    "label": 0
                },
                {
                    "sent": "Is somewhere here, right?",
                    "label": 0
                },
                {
                    "sent": "If we evaluated and the function is service less than what we value is, then they say that functions actually there's a minimum point in between the two.",
                    "label": 0
                },
                {
                    "sent": "More less so we're going to actually be looking at this of this.",
                    "label": 0
                },
                {
                    "sent": "Move that and then same thing.",
                    "label": 0
                },
                {
                    "sent": "This should be.",
                    "label": 0
                },
                {
                    "sent": "This should be less than, which now it's OK. Let me just ask.",
                    "label": 0
                },
                {
                    "sent": "Into it.",
                    "label": 0
                },
                {
                    "sent": "OK, so F of Lambda plus times X + 1 minus Lambda times way right should be less.",
                    "label": 0
                },
                {
                    "sent": "We value.",
                    "label": 0
                },
                {
                    "sent": "This gives us a point like here.",
                    "label": 0
                },
                {
                    "sent": "Sorry that's on.",
                    "label": 0
                },
                {
                    "sent": "The actual function, should give us a point that is less than what's play Lambda by this plus one minus Lambda times that that actually correspond to a higher point.",
                    "label": 0
                },
                {
                    "sent": "That doesn't make sense, right?",
                    "label": 0
                },
                {
                    "sent": "So when it happens, then we know that this minimum in between the two.",
                    "label": 0
                },
                {
                    "sent": "OK, then we know we have a convex function.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we'll stop here.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only stats love Ellie.",
                    "label": 0
                },
                {
                    "sent": "What I've missed?",
                    "label": 0
                },
                {
                    "sent": "The two slides I couldn't talk about will be in another class, so we're going to start doing stuff with vectors probability.",
                    "label": 0
                },
                {
                    "sent": "Victors face any probability, so we're going to start up silly today and we're going to use Octave.",
                    "label": 0
                },
                {
                    "sent": "So if you have math lab, we can use MATLAB, but we don't have much love.",
                    "label": 0
                },
                {
                    "sent": "This active on the machines and we have programmers we can store is open source, is free so you can use the commands for Matlab and Octave identical.",
                    "label": 0
                },
                {
                    "sent": "For the most part, right?",
                    "label": 0
                },
                {
                    "sent": "So we're going to use for some of these to try some of these things will go next door to your lab and we can get started.",
                    "label": 0
                }
            ]
        }
    }
}