{
    "id": "h266e7tge7eswcp3epbc3avz4os3pe62",
    "title": "Towards Combining Web Classification and Web Information Extraction: A Case Study",
    "info": {
        "author": [
            "Ping Luo, Institute of Computing Technology, Chinese Academy of Sciences"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "July 2009",
        "category": [
            "Top->Computer Science->Text Mining"
        ]
    },
    "url": "http://videolectures.net/kdd09_luo_tcwcwiecs/",
    "segmentation": [
        [
            "So that the title of this talk is towards compiling web classification and web information extraction, a case study, and the first quarter.",
            "And this is joint work with funding and zones.",
            "This from Institute of Computing Technology Chat is Academy of Sciences and my other two colleagues.",
            "You home shown and young job from HP."
        ],
        [
            "China.",
            "And it is popular that to build a web content analysis for vertical search engines are usually contains 2 steps.",
            "The first step is Web classification is to identify the target web pages and the second step is web information extraction to extract the metadata in the target pages.",
            "For example, if you want to to build a vertical search engine for product after you download the web pages from focused coding.",
            "Haha you will or you will use the web classification to identify the product pages and then use web information extraction to extract the metadata such as product name, model number and price.",
            "And in the other example if you want to build vertical search engine 4 cores for online courses, first you must identify the course home pages and then extract the course title, cost ID and time."
        ],
        [
            "Insurance along.",
            "And our work is based on our project, one HP Net China.",
            "While building an online search engine for for for for.",
            "For online courses the name is of course in this search engine you can use some query about the course cost description and then will return some costs related to your query and in this search engine this line is the title is the cost title extracted.",
            "And there's some other metadata, such as the cost ID and the University and the course time and and this time our search engine includes more than three starting serving 30,000 courses from the top 15 University in USA.",
            "So I talk about some techniques used in."
        ],
        [
            "This project and as I mentioned, that there are two sequential phases, two to web content analysis.",
            "These are two sequential and separate phases and it is very ineffective that these two.",
            "Steps are separated.",
            "Specifically, the these are the error from the first step of web classification will be propagated to the next step and eventually accumulate to a very high level and therefore the overall performance will be upper bounded by the performance of Web classification."
        ],
        [
            "So, so after some careful investigation, we found that these two steps of web classification and web information extraction are two very closely related tasks, and in that the information from one step will be grateful.",
            "Great, greatly helpful.",
            "Help help the other step.",
            "Specifically, if in one hand, if a webpage is is is a course homepage, there must be some metadata such as cost, title and cause, cause ID, and on the other hand the existence of some cost meta data will in turn.",
            "Indicate that this page is a course home page.",
            "So it means that there is forward dependency from web classification to web information extraction and more importantly there is also a backward independency from web information extraction to web classification.",
            "That's the way.",
            "In this paper we we.",
            "Proposed a method to combine these two steps, and.",
            "And aim to achieve achieve them you children's achieve the mutual enhancement and rather than conducting these two steps separately we are model can simultaneously detect the target pages and.",
            "Extract the metadata from from them.",
            "In this way, we aim to both.",
            "Improve the precision and recall of both web classification and."
        ],
        [
            "Web information extraction.",
            "And this this picture gives some some motivation examples to make you intuitively understand the room of this improvement.",
            "And, for example, this is a page.",
            "This is the page to tell how to enroll class and there are a lot of cost related terms on this page.",
            "If you use some bag of words features in web classification, it is more possible that this page is classified classified to be a cost home page.",
            "However, it is not if you have a, uh, Oracle of a web information extraction, it can tell that there is no course title on this page that it is not a cost home page.",
            "So in this example we tell that web information restruction can help to improve the priest."
        ],
        [
            "Meaning of web classification.",
            "In the next example, this is the course homepage.",
            "However, there are few cost related terms on this page.",
            "There is only one terms recommended books and thus it is more possible that this is not.",
            "This is not a custom page if you use the bag of words as a feature and then if you have a web information extraction Oracle and tell that there is a course title, this is the course title.",
            "And this is a course home page that we showed example web information extraction that can help improve the equals web classifica."
        ],
        [
            "Asian.",
            "So there is some definition of problem formulation and X is giving web page and why is the class label of this page indicating the type of the web page for web classification and XI is text dominate node in the in the web page XYI is the class label of XI indicating the type of the text node for text.",
            "For web information extraction and case number of text K. Text Don Live nails in this page.",
            "So this problem is too.",
            "Unable assignment problem for both X the page and all the Dom Dom."
        ],
        [
            "20 minutes.",
            "And then we just want to model the this conditional probability and we use the principle maximum posterior for the label assignment problem just to get the the labels assignment which maximizes this."
        ],
        [
            "Conditional probability.",
            "And this is the graphic model we used to combine used in this combination model and.",
            "This is the undirected graph graph."
        ],
        [
            "Model.",
            "And in this model there is.",
            "This is the first kind of maximal clique between X&Y.",
            "Ex says that the homepage and why is the type of the page so you can use some background words feature in this maximum."
        ],
        [
            "Eczema Creek.",
            "And this is the second kind of maximal clique in this, in each click.",
            "XI is the doctrine if node.",
            "And why is the class label on this storm traditional indicating the type of the meta data?",
            "And in this Max maximum click you can use some some features on the Dom tree, leaf node and such as the position and the format of this domain definite."
        ],
        [
            "In this maximal clique, and also we use.",
            "A third kind of maximal clique.",
            "This maximum clique is an on label variables including Y.",
            "The type of the web page and why I am like the type of meta data this nails are fully."
        ],
        [
            "Collected.",
            "So.",
            "So we adopt in the form of conditional random field to model in the context of this this conditional."
        ],
        [
            "Ability and four parimeter learning.",
            "We just use the maximum of poster posterior role to learn the.",
            "Are the para meters and and W 12 W 3 or the tradeoff para meters?",
            "And to consider the complexity?"
        ],
        [
            "The model.",
            "An however, there is a big challenge and the big challenge is the true come calculate the normalization factor in the conditional probability.",
            "This is the normalization factor and if the structure of the elements in the vector vector Y is very simple.",
            "Such as a linear chain, we can achieve exact computation.",
            "However, after if the structure in Y is very complex, such as they are fully collected in the proposed graphic model, we we cannot achieve exact computation.",
            "We have to approximate the compute."
        ],
        [
            "So in this example in this paper we just use some demand knowledge to constrain the output label space and we just use 2 rules.",
            "The first is the cost page contains one and only one course title and the second one is the non course homepage.",
            "Do not contain a coast title, so use these two rules.",
            "There are just K plus one cans of labels so we can achieve exact computation of."
        ],
        [
            "Normalization factor?",
            "So this is."
        ],
        [
            "Escape some some details of the baseline method and the experimental results show that.",
            "To extract the cost title way.",
            "Are our results significantly outperformed the two baseline methods?",
            "This is number."
        ],
        [
            "And to concluding, we show that the tasks that Hillary inherently joint should be addressed using one model.",
            "For example in web classification and web information extraction.",
            "In other some other applications such as the in NLP, you must first use the some syntactic analysis and then some thematic analysis.",
            "You can also use this.",
            "Method to combine these two type tasks.",
            "However, this definitely increase the complexity of the statistical model, and in this work we show the possibility of this joint model with tractable complexity, which is achieved by adopting some demand knowledge."
        ],
        [
            "OK, if you want to use this of course search engine to advertise you 'cause you can just.",
            "Click this bottle and and submit the URL of your costs and then you can add the.",
            "Listening to this search engine, thank you, that's all.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that the title of this talk is towards compiling web classification and web information extraction, a case study, and the first quarter.",
                    "label": 1
                },
                {
                    "sent": "And this is joint work with funding and zones.",
                    "label": 1
                },
                {
                    "sent": "This from Institute of Computing Technology Chat is Academy of Sciences and my other two colleagues.",
                    "label": 0
                },
                {
                    "sent": "You home shown and young job from HP.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "China.",
                    "label": 0
                },
                {
                    "sent": "And it is popular that to build a web content analysis for vertical search engines are usually contains 2 steps.",
                    "label": 1
                },
                {
                    "sent": "The first step is Web classification is to identify the target web pages and the second step is web information extraction to extract the metadata in the target pages.",
                    "label": 1
                },
                {
                    "sent": "For example, if you want to to build a vertical search engine for product after you download the web pages from focused coding.",
                    "label": 0
                },
                {
                    "sent": "Haha you will or you will use the web classification to identify the product pages and then use web information extraction to extract the metadata such as product name, model number and price.",
                    "label": 0
                },
                {
                    "sent": "And in the other example if you want to build vertical search engine 4 cores for online courses, first you must identify the course home pages and then extract the course title, cost ID and time.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Insurance along.",
                    "label": 0
                },
                {
                    "sent": "And our work is based on our project, one HP Net China.",
                    "label": 0
                },
                {
                    "sent": "While building an online search engine for for for for.",
                    "label": 1
                },
                {
                    "sent": "For online courses the name is of course in this search engine you can use some query about the course cost description and then will return some costs related to your query and in this search engine this line is the title is the cost title extracted.",
                    "label": 0
                },
                {
                    "sent": "And there's some other metadata, such as the cost ID and the University and the course time and and this time our search engine includes more than three starting serving 30,000 courses from the top 15 University in USA.",
                    "label": 0
                },
                {
                    "sent": "So I talk about some techniques used in.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This project and as I mentioned, that there are two sequential phases, two to web content analysis.",
                    "label": 1
                },
                {
                    "sent": "These are two sequential and separate phases and it is very ineffective that these two.",
                    "label": 1
                },
                {
                    "sent": "Steps are separated.",
                    "label": 0
                },
                {
                    "sent": "Specifically, the these are the error from the first step of web classification will be propagated to the next step and eventually accumulate to a very high level and therefore the overall performance will be upper bounded by the performance of Web classification.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so after some careful investigation, we found that these two steps of web classification and web information extraction are two very closely related tasks, and in that the information from one step will be grateful.",
                    "label": 0
                },
                {
                    "sent": "Great, greatly helpful.",
                    "label": 0
                },
                {
                    "sent": "Help help the other step.",
                    "label": 0
                },
                {
                    "sent": "Specifically, if in one hand, if a webpage is is is a course homepage, there must be some metadata such as cost, title and cause, cause ID, and on the other hand the existence of some cost meta data will in turn.",
                    "label": 0
                },
                {
                    "sent": "Indicate that this page is a course home page.",
                    "label": 0
                },
                {
                    "sent": "So it means that there is forward dependency from web classification to web information extraction and more importantly there is also a backward independency from web information extraction to web classification.",
                    "label": 1
                },
                {
                    "sent": "That's the way.",
                    "label": 0
                },
                {
                    "sent": "In this paper we we.",
                    "label": 0
                },
                {
                    "sent": "Proposed a method to combine these two steps, and.",
                    "label": 1
                },
                {
                    "sent": "And aim to achieve achieve them you children's achieve the mutual enhancement and rather than conducting these two steps separately we are model can simultaneously detect the target pages and.",
                    "label": 0
                },
                {
                    "sent": "Extract the metadata from from them.",
                    "label": 0
                },
                {
                    "sent": "In this way, we aim to both.",
                    "label": 0
                },
                {
                    "sent": "Improve the precision and recall of both web classification and.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Web information extraction.",
                    "label": 0
                },
                {
                    "sent": "And this this picture gives some some motivation examples to make you intuitively understand the room of this improvement.",
                    "label": 0
                },
                {
                    "sent": "And, for example, this is a page.",
                    "label": 0
                },
                {
                    "sent": "This is the page to tell how to enroll class and there are a lot of cost related terms on this page.",
                    "label": 1
                },
                {
                    "sent": "If you use some bag of words features in web classification, it is more possible that this page is classified classified to be a cost home page.",
                    "label": 0
                },
                {
                    "sent": "However, it is not if you have a, uh, Oracle of a web information extraction, it can tell that there is no course title on this page that it is not a cost home page.",
                    "label": 1
                },
                {
                    "sent": "So in this example we tell that web information restruction can help to improve the priest.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Meaning of web classification.",
                    "label": 0
                },
                {
                    "sent": "In the next example, this is the course homepage.",
                    "label": 0
                },
                {
                    "sent": "However, there are few cost related terms on this page.",
                    "label": 1
                },
                {
                    "sent": "There is only one terms recommended books and thus it is more possible that this is not.",
                    "label": 0
                },
                {
                    "sent": "This is not a custom page if you use the bag of words as a feature and then if you have a web information extraction Oracle and tell that there is a course title, this is the course title.",
                    "label": 0
                },
                {
                    "sent": "And this is a course home page that we showed example web information extraction that can help improve the equals web classifica.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asian.",
                    "label": 0
                },
                {
                    "sent": "So there is some definition of problem formulation and X is giving web page and why is the class label of this page indicating the type of the web page for web classification and XI is text dominate node in the in the web page XYI is the class label of XI indicating the type of the text node for text.",
                    "label": 1
                },
                {
                    "sent": "For web information extraction and case number of text K. Text Don Live nails in this page.",
                    "label": 0
                },
                {
                    "sent": "So this problem is too.",
                    "label": 1
                },
                {
                    "sent": "Unable assignment problem for both X the page and all the Dom Dom.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "20 minutes.",
                    "label": 0
                },
                {
                    "sent": "And then we just want to model the this conditional probability and we use the principle maximum posterior for the label assignment problem just to get the the labels assignment which maximizes this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Conditional probability.",
                    "label": 0
                },
                {
                    "sent": "And this is the graphic model we used to combine used in this combination model and.",
                    "label": 0
                },
                {
                    "sent": "This is the undirected graph graph.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "And in this model there is.",
                    "label": 0
                },
                {
                    "sent": "This is the first kind of maximal clique between X&Y.",
                    "label": 1
                },
                {
                    "sent": "Ex says that the homepage and why is the type of the page so you can use some background words feature in this maximum.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Eczema Creek.",
                    "label": 0
                },
                {
                    "sent": "And this is the second kind of maximal clique in this, in each click.",
                    "label": 1
                },
                {
                    "sent": "XI is the doctrine if node.",
                    "label": 0
                },
                {
                    "sent": "And why is the class label on this storm traditional indicating the type of the meta data?",
                    "label": 0
                },
                {
                    "sent": "And in this Max maximum click you can use some some features on the Dom tree, leaf node and such as the position and the format of this domain definite.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this maximal clique, and also we use.",
                    "label": 0
                },
                {
                    "sent": "A third kind of maximal clique.",
                    "label": 1
                },
                {
                    "sent": "This maximum clique is an on label variables including Y.",
                    "label": 0
                },
                {
                    "sent": "The type of the web page and why I am like the type of meta data this nails are fully.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Collected.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we adopt in the form of conditional random field to model in the context of this this conditional.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ability and four parimeter learning.",
                    "label": 0
                },
                {
                    "sent": "We just use the maximum of poster posterior role to learn the.",
                    "label": 0
                },
                {
                    "sent": "Are the para meters and and W 12 W 3 or the tradeoff para meters?",
                    "label": 0
                },
                {
                    "sent": "And to consider the complexity?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The model.",
                    "label": 0
                },
                {
                    "sent": "An however, there is a big challenge and the big challenge is the true come calculate the normalization factor in the conditional probability.",
                    "label": 0
                },
                {
                    "sent": "This is the normalization factor and if the structure of the elements in the vector vector Y is very simple.",
                    "label": 1
                },
                {
                    "sent": "Such as a linear chain, we can achieve exact computation.",
                    "label": 0
                },
                {
                    "sent": "However, after if the structure in Y is very complex, such as they are fully collected in the proposed graphic model, we we cannot achieve exact computation.",
                    "label": 0
                },
                {
                    "sent": "We have to approximate the compute.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this example in this paper we just use some demand knowledge to constrain the output label space and we just use 2 rules.",
                    "label": 0
                },
                {
                    "sent": "The first is the cost page contains one and only one course title and the second one is the non course homepage.",
                    "label": 1
                },
                {
                    "sent": "Do not contain a coast title, so use these two rules.",
                    "label": 0
                },
                {
                    "sent": "There are just K plus one cans of labels so we can achieve exact computation of.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Normalization factor?",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Escape some some details of the baseline method and the experimental results show that.",
                    "label": 0
                },
                {
                    "sent": "To extract the cost title way.",
                    "label": 0
                },
                {
                    "sent": "Are our results significantly outperformed the two baseline methods?",
                    "label": 0
                },
                {
                    "sent": "This is number.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to concluding, we show that the tasks that Hillary inherently joint should be addressed using one model.",
                    "label": 1
                },
                {
                    "sent": "For example in web classification and web information extraction.",
                    "label": 0
                },
                {
                    "sent": "In other some other applications such as the in NLP, you must first use the some syntactic analysis and then some thematic analysis.",
                    "label": 0
                },
                {
                    "sent": "You can also use this.",
                    "label": 0
                },
                {
                    "sent": "Method to combine these two type tasks.",
                    "label": 0
                },
                {
                    "sent": "However, this definitely increase the complexity of the statistical model, and in this work we show the possibility of this joint model with tractable complexity, which is achieved by adopting some demand knowledge.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, if you want to use this of course search engine to advertise you 'cause you can just.",
                    "label": 0
                },
                {
                    "sent": "Click this bottle and and submit the URL of your costs and then you can add the.",
                    "label": 0
                },
                {
                    "sent": "Listening to this search engine, thank you, that's all.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}