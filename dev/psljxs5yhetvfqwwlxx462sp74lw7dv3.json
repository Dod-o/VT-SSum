{
    "id": "psljxs5yhetvfqwwlxx462sp74lw7dv3",
    "title": "Named Entity Recognition using Cross-lingual Resources: Arabic as an Example",
    "info": {
        "author": [
            "Kareem Darwish, Qatar Computing Research Institute"
        ],
        "published": "Oct. 2, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Computational Linguistics"
        ]
    },
    "url": "http://videolectures.net/acl2013_darwish_arabic/",
    "segmentation": [
        [
            "So I'm going to talk about using cross lingual features to improve limb dental recognition, and I'm going to use Arabic as an example to show how these features can be used so."
        ],
        [
            "This flippin anyway, yes, OK good.",
            "So if you know to do named entity recognition, you know you need to do so.",
            "You look at some of the features of the text, for example like orthographic features like whether word is capitalized.",
            "If using English, some of the trigger words like for example, you know the word is preceded by president, then usually it comes afterwards and Eva person some of the letters.",
            "Sometimes in the beginning of the word or the end of the word will kind of tell you like Pakistan or Bloomberg.",
            "And using gazetteers also help two to do named entity recognition and what you."
        ],
        [
            "Find out that some of the languages are generally more friendly to named entity recognition.",
            "For example, English has, you know, has capitalization feature, which is actually quite strong.",
            "And also if you look at English as an example again, you will find that you know DB Pedia and Freebase and knowledge bases are actually quite large and this can be used quite effectively to improve named entity recognition and also language processing tools are also good now.",
            "If you switch to another language that is not so friendly to named entity recognition.",
            "Example Arabic here.",
            "You'll find, for example, it doesn't have any capitalization features, so there are no strong orthographic features.",
            "That kind of tell you that this is actually a named entity or not, and the knowledge base is actually quite small compared to English.",
            "So the example here that I have that English Wikipedia for example, has more than 4 million articles, while Arabic Wikipedia only has 250,000 articles, so the difference is actually quite substantial, so their main idea here is how can we use features, let's say in English to help out doing named entity recognition.",
            "In Arabic, and does not have to be Arabic in English, you can probably pick two other pairs where one has lots of resources and the other one has fewer resource."
        ],
        [
            "So the three features that I'm going to be presenting to today are as follows.",
            "One is cross language capitalization, meaning can we utilized, let's say, the capitalization feature in English to figure out whether a word is actually named entity or not.",
            "The other one is transliteration.",
            "Mining were basically if 2 words are transliterations of each other and their translations at the same time, then they likely be named entities, and the third one is using a large knowledge base, let's say from English.",
            "Into Arabic OK."
        ],
        [
            "So switching out a bit to Arabic so you can get you get you in the mood of you know what the problems are and what people talk about and what can people kind of do.",
            "Now let me tell you some of the properties that was kind of affect named entity recognition.",
            "As I told you, there's no capitalization features, so that's out.",
            "Also character level features are surprisingly good for Arabic, and they're actually good for excluding things that are not named entities.",
            "So for example, you know the 1st letter, the first 2 letters, the first 3 letters in a word.",
            "And and and the trailing letters in the word also.",
            "And they can actually kind of get you off the hook as far as doing any morphological analysis for Arabic or doing any substantial stemming and the last one is that people use public gazetteers and there's only one public one that you can actually use, you know that is readily available and that's actually quite small.",
            "It has about 5000 entries in total, that's organisations, locations and and persons, so they actually quite small.",
            "So."
        ],
        [
            "The baseline system that we that we were using for our work.",
            "Uses the following features.",
            "Basically the previous the previous word, the current word and the next word, so this would kind of capture context and we're using the first leading and trailing characters, meaning the first one, 2, three and four characters and the same thing at the end of the word.",
            "And we did some really, really simple.",
            "You know, bring that stemming where we just use the rule based EMR.",
            "That kind of chops and and when the less the feature that we used was.",
            "The publicly available gazetteer that we had access to an for decoding.",
            "We use just CRF plus plus."
        ],
        [
            "OK.",
            "So for training and testing so we had one training set that we that we that we use throughout.",
            "And basically there's a publicly available corpus for Arabic.",
            "Named entity recognition is called the Enercorp and the total has about 150,000 tokens.",
            "So we use one 22,000 tokens for training and we use this training throughout and for testing we had three different, so you know, as a test sets, the first one was 20% of enercorp of course does not overlap with the other part for training.",
            "An we created 2 new test sets.",
            "There is a reason why we created this.",
            "These two new data test sets for one.",
            "If you look at the enercorp test data set and it's actually created from a single source.",
            "And meaning I forgot which news source it was.",
            "But from a single source is done during a preset type time window.",
            "An if you basically do a really really dumb named entity recognizer that says you know what.",
            "If I've seen this token as a named entity during training, I'm just going to crank it, you know blindly at during testing you get about 65%, which is actually quite high, so the overlap between the training and testing is actually quite high.",
            "So we wanted to see.",
            "How are the our training would actually generalize to new test sets that we haven't seen before, and so with the first one we that we used was the news data set that was shifted in time by about 10 years and it has multiple sources.",
            "It did not include whole articles that just included headlines in the first couple of sentences of every article and the last one, which turned out to be actually quite painful to deal with, was a tweet data set.",
            "OK."
        ],
        [
            "So here are the results for the three test sets that we had.",
            "Do you have a pointer?",
            "He is a good good.",
            "We have a pointer.",
            "OK so this is the results that we get for the enercorp data set which is actually about 80%.",
            "And you can see that even when we go to then to another news test set, you know the results drop like a rock, right?",
            "I mean, the difference is almost.",
            "25 points OK, and when you go to tweet this at everything goes to help.",
            "Which is actually not good.",
            "So what we want to do is to see how we can generalize to two.",
            "These two need to test sets and whether we can get them to at least close to what Ascender data set does and whether we can improve on the standard data set.",
            "OK."
        ],
        [
            "So so I told you initially that we're going to use cross lingual features, so let me tell you some of the crossing resources that we had available to us so you can and then we will show you afterwards how we use these features, how we use them to apply to our features.",
            "So we had a large true case through case, meaning that we retain case we did not kiss fold during training and when we aligned parallel English.",
            "Arabic, English sentences and this was actually quite substantial in size, so it's about 3.7 million sentences, and so this was the first thing that we had.",
            "Also, we had the transliteration minor, and what that minor does is that basically given two sequences of words in both languages, it will be able to detect whether one of these two words is actually a translation of the other across languages.",
            "And then you know, in the simplest case you can say are these two words transliterations of each other or not?",
            "And this was trained using about 3500 parallel words, meaning the words and their tender transliterations between Arabic and English.",
            "And we also used English, Wikipedia and in particular we used the cross lingual links between Arabic and English Wikipedia and the last one is we use DPD OK, so the pedia is actually would be.",
            "I'll show you afterwards how important it was.",
            "Basically you get the named entity that is actually linked to an entry into Wikipedia.",
            "And then it tells you that, for example, NASA will give it multiple tags like it's an agent, an organization, and a government agency.",
            "So we're able to.",
            "So we will use this piece of information as we proceed forward with our features, OK?",
            "So let me tell you about the 1st."
        ],
        [
            "For the cross language is the cross lingual capitalization feature, so the feature works like this.",
            "Basically, given our true case phrase table and given a sequence of words on the Arabic side, we would go in and then translate using the phrase table and then look at the results in the phrase table and say are the words the corresponding words in English capitalized or not.",
            "And when I say capitalize this is after capitalization after dropping all the stop words, because this upwards would not be capitalized on the English side.",
            "So all the content words, will they be capitalized or not?",
            "And and basically this is in doing so we're trying to capture the strong English feature in this.",
            "This is this work has not.",
            "We're not the first people have done this.",
            "There are people who have done this in the past, but they've done it using a very small data set and we have done this using a very, very large resource.",
            "And basically we used the ratio that what is the probability that a sequence of words would be capitalized on the English side.",
            "Divided by the sum of the probabilities of all the other translations OK, and and we always always favored longer sequence of words.",
            "So if we're able to capture maybe like 4 words, we prefer that over capturing 3 words in the phrase table, and then we proceeded forward.",
            "So let me kind of show you."
        ],
        [
            "How there is also got affected?",
            "So I'm sorry the table is a little busy, but you know, I'm sure you'll bear with me.",
            "I know I'm competing here with with coffee that you're probably waiting for.",
            "It's been a long day, So what you see here is the value of the absolute value.",
            "Here is the difference above the baseline that I showed you in earlier table, and this is the relative.",
            "This is the percentage percent difference between the results from the baseline.",
            "OK, So what you can see right away from the table is that generally precision drops by just a little.",
            "Recall improves dramatically.",
            "And this translates into greater improvement in an improvement in overall F measure, and you can see that this is actually consistent across all three datasets.",
            "One of the things that is kind of surprising and you know we would, we guessed, I mean, my initial guess starting this that cross language capitalization would actually benefit persons and locations a lot.",
            "It turns out that the most benefit happened to persons and less so two locations.",
            "And this is actually consistent across all datasets.",
            "So as you can see, we're getting some improvement here.",
            "We're getting some improvement here and some improvement there OK?"
        ],
        [
            "As far as the second feature that we looked at was trends across language transliteration, and we've done this not at word sequence level, but actually at word level where basically we come in and say OK, here we have an Arabic token.",
            "If we go and translate this Arabic token to English using our phrase table, is the translation also a transliteration or not?",
            "And if it's a transliteration, then it would make sense that generally named entities get transliterated.",
            "Specially persons and locations and less so to organisations.",
            "And we again we used very similar ratio to the one that we had that I had showed you for for cross language capitalization and here as an example.",
            "Basically I have this token has an in Arabic and then you know this is 1 possible translation and this is another possible translation and good there's a third possible translation and as you can see has and you can probably figure out these two.",
            "First two are actually transliterations.",
            "And the last one is not.",
            "So basically the value of the feature becomes this.",
            "You know, the probability of these two translations divided by the probability of the sum of the other translations.",
            "One thing that is worth noting here is that most CRF implementation CRF implementations actually take nominal features rather than continuous value features, so all these values were been to one significant figure."
        ],
        [
            "So again, we saw very, very similar results to the results that we saw for crossing which capitalization where again we saw a drop in recall and precision and improvement in recall and recall improvement was much greater for persons compared to any other named entity type, and we still have to investigate why this actually happened as opposed to just having persons and locations as we initially suspected an and hopefully if he.",
            "Trans Cross lingual transliteration would kind of be a shoo in for crap cross language capitalization, specially if your helper language or your friendly language that you're that you're trying to refer to doesn't have a feature like capitalization for example.",
            "OK, and.",
            "And this seems I mean like the street data set.",
            "No matter what we do is just.",
            "You know, kind of likes being low and and and you know not so you know."
        ],
        [
            "Not so friendly, OK?",
            "The less feature that we looked at was.",
            "Basically, if we can go from an Arabic word sequence into an English word sequence that we can identify an entry inside Wikipedia or an action entry inside DB pedia, and then once we go and find an entry into DB pedia, we will take the category name in the English side an we then we use that back as a feature on the Arabic side.",
            "OK, so basically we had.",
            "At.",
            "As far as DPS is concerned, I showed you the example of Nessa that we had before that NASA was an agent and an organization and a government agency and basically agent is just way too, you know, ambiguous doesn't mean very much, so some of these categories we actually manually just thrown away and we kept the ones that were more sensible.",
            "And the ones that.",
            "The and also if we had the choice of multiple, you know annotations.",
            "We picked the one that was most likely and then for translation we used two transition resources.",
            "One was the translation table that I talked to you about before and we also used Wikipedia so we went to we matched against Arabic Wikipedia entry into English Wikipedia entry into DB pedia to get the tag and the reason why using DB pedia.",
            "I'm sorry.",
            "Arabic Wikipedia is a translation resource aside from free stable actually use both transition methods and they will use as two separate features in our training and testing is that?",
            "It seems that there's a rock band.",
            "Name anything that you can come up with.",
            "So you know I can come up with, you know, black ice and something has you know there's a broadband so and you actually find it in DB pedia.",
            "So actually doing the restriction you know on the Arabic site to say you know this is the specific English Wikipedia entry would actually make sense that you would get the correct one in DPD.",
            "So here's an example.",
            "For example, I have Hezbollah.",
            "This would be translated to Hezbollah and then I will go into DB Pedia and EP.",
            "They would recognize that this is an organization and this is how the feature would be realized at the end, OK?",
            "Let"
        ],
        [
            "Show the results.",
            "And the nice thing about using DB pedia, which is I mean the feature is actually structurally different from the previous other two, is that you know we get improvement in both precision and recall an you'll see that even the dreaded organisations get a substantial boost and the improvement is also across the board.",
            "Except for this really really really weird, strange thing called tweet data Set and I'll talk to you, but more about that later on.",
            "So an improvement you know instead of we were starting around 55.",
            "Now we're about 63 here and this improvement.",
            "This is actually the largest you know.",
            "Recorded results that for this data set and again we've improved here.",
            "Unfortunately, just by just a little bit."
        ],
        [
            "And then we could just put everything together.",
            "And then you can see that we got improvement.",
            "Overall, this is 84 compared to something like, you know, is a 79.9 and this is in.",
            "There is a more reasonable range right before we started at 55.",
            "Now we're about 64 and the tweet data set.",
            "That improvement is actually quite substantial, but still the results are actually still quite low.",
            "And it seems that the further away that you know the test set is from the training set, the more these features actually kind of help you.",
            "Right, the help for the Enercorp data set is relatively small, because as I told you a lot of there's a lot of overlap between the training and testing sets, right?",
            "While in this case you know the features that I showed you actually generalize quite well.",
            "OK."
        ],
        [
            "So as I showed you before, the DB Pedia feature was the best crossing with capitalization was slightly better that rather than cross lingual transliteration.",
            "And the greater the difference between the training and test sets you know, the more that these features actually kind of helped you now."
        ],
        [
            "Turned to tweets and tweets.",
            "Are very strange for a variety of reasons.",
            "I've tried to, you know.",
            "Just summarize some of the main things that kind of hurt you when you're doing named ignition for tweets.",
            "So for one people just kind of abbreviate named entities so they would not say that they would not say Real Madrid.",
            "They would say the real and that Madrid will just be you know or.",
            "The name full name entity would be kind of implied.",
            "Also it would start things like the Fed: and then announces blah blah blah blah blah.",
            "So named entities kind of appear at the beginning or the end of tweets rather than in the middle of tweets.",
            "Also there are not many non standard text things like you know.",
            "Emoticons, hashtags and URL's and so forth and all this kind of screws up the.",
            "The training, I'm sorry they named entity recognition, so there is.",
            "I'm sorry there's so there is some hint that we actually need in domain data to actually carry this through to make sure that we get reasonable named entity recognition for for for tweets and perhaps do something specifically for the tweets."
        ],
        [
            "OK. OK, so this is my last slide so it just comes right in time.",
            "Thank you.",
            "So as I told you that cross single features actually kind of help you quite substantially there are, you know, the things that I think we need to do significant amount work work for work for handling tweets and how to actually make them.",
            "You know to do reasonable name integration for them.",
            "Also, DB pedia when we use that.",
            "We used the most likely A tag.",
            "While you know multiple tags actually may actually end up helping you more.",
            "And this is about it.",
            "And the last thing that I want to tell you, if you're interested in the test sets that we have, there are publicly available, so you can just contact me and I'll just happily send them to you.",
            "Thank you.",
            "Thank you for presentation.",
            "Previously done some work on translating, summarize in Arabic into English in order to be evaluated using English Gold Standard, and I'm a bit sick about using any Arabic natural sorry named entity recognition where you have most of the Arabic names with the meaning and I was wondering in order to be capitalized at the end.",
            "What if it was translated, for example your name and Kareem and you have like at least 6 words.",
            "That means cream like or just like curious are those unfriendly, named it the language is always under resourced and that's why you looking at them.",
            "And if the translation of names will always come up with the meaning or would it be capitalized?",
            "Sure, this so this is a very good question.",
            "So basically this is not a binary decision on whether you know the transition is actually capitalized, for example or not.",
            "Basically, you kind of give your issue so you say you know, given all the transitions that I know for this word, which hopefully would cover most of the sensors in Arabic.",
            "You know the probability that it actually comes becomes capitalized on the English side, there's this much.",
            "Just say you know you know 10% or 20% to 50%, so this gives you kind of a clue and then all the other things around it.",
            "For example, you know the word before it they were after it and other things.",
            "We kind of help you along, so none of these features are kind of, you know, be all and end all kinds of features, but they just all push you along and hopefully in the right direction.",
            "I was wondering, for the tweets you presumably got the gold standard by some human coding.",
            "Yes OK so then I was curious if you did some sort of cross validation.",
            "Basically meaning if you train your system based on a part of the tweets and then test it on the rest, how good or how bad is it still so so let me tell you you know, we have actually some results that we have that we've obtained and this is a bit outside the scope of the paper.",
            "That actually using a part of the tweets for for training.",
            "Helps a lot.",
            "Which actually kind of makes sense because you know that the transitions between words.",
            "The transition probabilities are different the way that they're kind of, you know, the trigger words are different position in the sentence are different than many.",
            "Many things are different, so we actually used in domain training data that helped a lot.",
            "OK.",
            "Thank you for the nice talk.",
            "Actually I have a question that was might have been answered but it was not really clear so you gave us three different approaches.",
            "Yes, in order to improve your performance.",
            "Yes.",
            "OK the question is, have you tried combining them so the last result?",
            "Because I'm thinking of possible overlap between the methods.",
            "OK so so how about this?"
        ],
        [
            "The combined feature 3 features together OK, so it's is it because I can and cannot do the math right now, so it is the effect additive.",
            "So I mean or so is there significant?",
            "Does it make sense for me to use all three?",
            "So the answer.",
            "So the answer is yes, so let me show you like from the previous results which is the pedia was actually the strongest of the three features, right?",
            "And you know here is 83 and 62.",
            "And then when you go here you get you know 84 and 64.",
            "So there is actually room for improvement by adding them together.",
            "Thank you, can I ask a final question so for, for obvious reasons, you've looked at how you can improve the Arabic problem which has few resource is using the huge response resources for English.",
            "Would it be useful the other way round?",
            "So could the Arabic resource is be useful for English named entity recognition in some circumstances do you think?",
            "That's a good question.",
            "So potentially yes, and let me tell you where this would actually help.",
            "If I had things that were probably more culturally, you know, or you know named entities that that would more likely appear and more Arabic text for some reason, or I have some gazetteers that we kind of have better coverage for things that are, you know, more culturally or sensitive to Arabic, then then I think that would kind of make sense to do.",
            "But whether we do generalize for everything, I don't know.",
            "So thank you very much.",
            "Thank you and just coffee now."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk about using cross lingual features to improve limb dental recognition, and I'm going to use Arabic as an example to show how these features can be used so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This flippin anyway, yes, OK good.",
                    "label": 0
                },
                {
                    "sent": "So if you know to do named entity recognition, you know you need to do so.",
                    "label": 0
                },
                {
                    "sent": "You look at some of the features of the text, for example like orthographic features like whether word is capitalized.",
                    "label": 1
                },
                {
                    "sent": "If using English, some of the trigger words like for example, you know the word is preceded by president, then usually it comes afterwards and Eva person some of the letters.",
                    "label": 0
                },
                {
                    "sent": "Sometimes in the beginning of the word or the end of the word will kind of tell you like Pakistan or Bloomberg.",
                    "label": 0
                },
                {
                    "sent": "And using gazetteers also help two to do named entity recognition and what you.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Find out that some of the languages are generally more friendly to named entity recognition.",
                    "label": 0
                },
                {
                    "sent": "For example, English has, you know, has capitalization feature, which is actually quite strong.",
                    "label": 0
                },
                {
                    "sent": "And also if you look at English as an example again, you will find that you know DB Pedia and Freebase and knowledge bases are actually quite large and this can be used quite effectively to improve named entity recognition and also language processing tools are also good now.",
                    "label": 0
                },
                {
                    "sent": "If you switch to another language that is not so friendly to named entity recognition.",
                    "label": 1
                },
                {
                    "sent": "Example Arabic here.",
                    "label": 0
                },
                {
                    "sent": "You'll find, for example, it doesn't have any capitalization features, so there are no strong orthographic features.",
                    "label": 1
                },
                {
                    "sent": "That kind of tell you that this is actually a named entity or not, and the knowledge base is actually quite small compared to English.",
                    "label": 0
                },
                {
                    "sent": "So the example here that I have that English Wikipedia for example, has more than 4 million articles, while Arabic Wikipedia only has 250,000 articles, so the difference is actually quite substantial, so their main idea here is how can we use features, let's say in English to help out doing named entity recognition.",
                    "label": 0
                },
                {
                    "sent": "In Arabic, and does not have to be Arabic in English, you can probably pick two other pairs where one has lots of resources and the other one has fewer resource.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the three features that I'm going to be presenting to today are as follows.",
                    "label": 0
                },
                {
                    "sent": "One is cross language capitalization, meaning can we utilized, let's say, the capitalization feature in English to figure out whether a word is actually named entity or not.",
                    "label": 1
                },
                {
                    "sent": "The other one is transliteration.",
                    "label": 0
                },
                {
                    "sent": "Mining were basically if 2 words are transliterations of each other and their translations at the same time, then they likely be named entities, and the third one is using a large knowledge base, let's say from English.",
                    "label": 0
                },
                {
                    "sent": "Into Arabic OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So switching out a bit to Arabic so you can get you get you in the mood of you know what the problems are and what people talk about and what can people kind of do.",
                    "label": 0
                },
                {
                    "sent": "Now let me tell you some of the properties that was kind of affect named entity recognition.",
                    "label": 1
                },
                {
                    "sent": "As I told you, there's no capitalization features, so that's out.",
                    "label": 1
                },
                {
                    "sent": "Also character level features are surprisingly good for Arabic, and they're actually good for excluding things that are not named entities.",
                    "label": 0
                },
                {
                    "sent": "So for example, you know the 1st letter, the first 2 letters, the first 3 letters in a word.",
                    "label": 0
                },
                {
                    "sent": "And and and the trailing letters in the word also.",
                    "label": 0
                },
                {
                    "sent": "And they can actually kind of get you off the hook as far as doing any morphological analysis for Arabic or doing any substantial stemming and the last one is that people use public gazetteers and there's only one public one that you can actually use, you know that is readily available and that's actually quite small.",
                    "label": 0
                },
                {
                    "sent": "It has about 5000 entries in total, that's organisations, locations and and persons, so they actually quite small.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The baseline system that we that we were using for our work.",
                    "label": 0
                },
                {
                    "sent": "Uses the following features.",
                    "label": 0
                },
                {
                    "sent": "Basically the previous the previous word, the current word and the next word, so this would kind of capture context and we're using the first leading and trailing characters, meaning the first one, 2, three and four characters and the same thing at the end of the word.",
                    "label": 1
                },
                {
                    "sent": "And we did some really, really simple.",
                    "label": 0
                },
                {
                    "sent": "You know, bring that stemming where we just use the rule based EMR.",
                    "label": 0
                },
                {
                    "sent": "That kind of chops and and when the less the feature that we used was.",
                    "label": 1
                },
                {
                    "sent": "The publicly available gazetteer that we had access to an for decoding.",
                    "label": 0
                },
                {
                    "sent": "We use just CRF plus plus.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So for training and testing so we had one training set that we that we that we use throughout.",
                    "label": 0
                },
                {
                    "sent": "And basically there's a publicly available corpus for Arabic.",
                    "label": 0
                },
                {
                    "sent": "Named entity recognition is called the Enercorp and the total has about 150,000 tokens.",
                    "label": 1
                },
                {
                    "sent": "So we use one 22,000 tokens for training and we use this training throughout and for testing we had three different, so you know, as a test sets, the first one was 20% of enercorp of course does not overlap with the other part for training.",
                    "label": 1
                },
                {
                    "sent": "An we created 2 new test sets.",
                    "label": 0
                },
                {
                    "sent": "There is a reason why we created this.",
                    "label": 0
                },
                {
                    "sent": "These two new data test sets for one.",
                    "label": 0
                },
                {
                    "sent": "If you look at the enercorp test data set and it's actually created from a single source.",
                    "label": 0
                },
                {
                    "sent": "And meaning I forgot which news source it was.",
                    "label": 0
                },
                {
                    "sent": "But from a single source is done during a preset type time window.",
                    "label": 0
                },
                {
                    "sent": "An if you basically do a really really dumb named entity recognizer that says you know what.",
                    "label": 0
                },
                {
                    "sent": "If I've seen this token as a named entity during training, I'm just going to crank it, you know blindly at during testing you get about 65%, which is actually quite high, so the overlap between the training and testing is actually quite high.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to see.",
                    "label": 0
                },
                {
                    "sent": "How are the our training would actually generalize to new test sets that we haven't seen before, and so with the first one we that we used was the news data set that was shifted in time by about 10 years and it has multiple sources.",
                    "label": 0
                },
                {
                    "sent": "It did not include whole articles that just included headlines in the first couple of sentences of every article and the last one, which turned out to be actually quite painful to deal with, was a tweet data set.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results for the three test sets that we had.",
                    "label": 0
                },
                {
                    "sent": "Do you have a pointer?",
                    "label": 0
                },
                {
                    "sent": "He is a good good.",
                    "label": 0
                },
                {
                    "sent": "We have a pointer.",
                    "label": 0
                },
                {
                    "sent": "OK so this is the results that we get for the enercorp data set which is actually about 80%.",
                    "label": 1
                },
                {
                    "sent": "And you can see that even when we go to then to another news test set, you know the results drop like a rock, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, the difference is almost.",
                    "label": 0
                },
                {
                    "sent": "25 points OK, and when you go to tweet this at everything goes to help.",
                    "label": 1
                },
                {
                    "sent": "Which is actually not good.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is to see how we can generalize to two.",
                    "label": 1
                },
                {
                    "sent": "These two need to test sets and whether we can get them to at least close to what Ascender data set does and whether we can improve on the standard data set.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So so I told you initially that we're going to use cross lingual features, so let me tell you some of the crossing resources that we had available to us so you can and then we will show you afterwards how we use these features, how we use them to apply to our features.",
                    "label": 0
                },
                {
                    "sent": "So we had a large true case through case, meaning that we retain case we did not kiss fold during training and when we aligned parallel English.",
                    "label": 0
                },
                {
                    "sent": "Arabic, English sentences and this was actually quite substantial in size, so it's about 3.7 million sentences, and so this was the first thing that we had.",
                    "label": 0
                },
                {
                    "sent": "Also, we had the transliteration minor, and what that minor does is that basically given two sequences of words in both languages, it will be able to detect whether one of these two words is actually a translation of the other across languages.",
                    "label": 0
                },
                {
                    "sent": "And then you know, in the simplest case you can say are these two words transliterations of each other or not?",
                    "label": 0
                },
                {
                    "sent": "And this was trained using about 3500 parallel words, meaning the words and their tender transliterations between Arabic and English.",
                    "label": 0
                },
                {
                    "sent": "And we also used English, Wikipedia and in particular we used the cross lingual links between Arabic and English Wikipedia and the last one is we use DPD OK, so the pedia is actually would be.",
                    "label": 0
                },
                {
                    "sent": "I'll show you afterwards how important it was.",
                    "label": 0
                },
                {
                    "sent": "Basically you get the named entity that is actually linked to an entry into Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "And then it tells you that, for example, NASA will give it multiple tags like it's an agent, an organization, and a government agency.",
                    "label": 0
                },
                {
                    "sent": "So we're able to.",
                    "label": 0
                },
                {
                    "sent": "So we will use this piece of information as we proceed forward with our features, OK?",
                    "label": 0
                },
                {
                    "sent": "So let me tell you about the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the cross language is the cross lingual capitalization feature, so the feature works like this.",
                    "label": 1
                },
                {
                    "sent": "Basically, given our true case phrase table and given a sequence of words on the Arabic side, we would go in and then translate using the phrase table and then look at the results in the phrase table and say are the words the corresponding words in English capitalized or not.",
                    "label": 1
                },
                {
                    "sent": "And when I say capitalize this is after capitalization after dropping all the stop words, because this upwards would not be capitalized on the English side.",
                    "label": 0
                },
                {
                    "sent": "So all the content words, will they be capitalized or not?",
                    "label": 0
                },
                {
                    "sent": "And and basically this is in doing so we're trying to capture the strong English feature in this.",
                    "label": 0
                },
                {
                    "sent": "This is this work has not.",
                    "label": 0
                },
                {
                    "sent": "We're not the first people have done this.",
                    "label": 0
                },
                {
                    "sent": "There are people who have done this in the past, but they've done it using a very small data set and we have done this using a very, very large resource.",
                    "label": 0
                },
                {
                    "sent": "And basically we used the ratio that what is the probability that a sequence of words would be capitalized on the English side.",
                    "label": 1
                },
                {
                    "sent": "Divided by the sum of the probabilities of all the other translations OK, and and we always always favored longer sequence of words.",
                    "label": 0
                },
                {
                    "sent": "So if we're able to capture maybe like 4 words, we prefer that over capturing 3 words in the phrase table, and then we proceeded forward.",
                    "label": 0
                },
                {
                    "sent": "So let me kind of show you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How there is also got affected?",
                    "label": 0
                },
                {
                    "sent": "So I'm sorry the table is a little busy, but you know, I'm sure you'll bear with me.",
                    "label": 0
                },
                {
                    "sent": "I know I'm competing here with with coffee that you're probably waiting for.",
                    "label": 0
                },
                {
                    "sent": "It's been a long day, So what you see here is the value of the absolute value.",
                    "label": 0
                },
                {
                    "sent": "Here is the difference above the baseline that I showed you in earlier table, and this is the relative.",
                    "label": 0
                },
                {
                    "sent": "This is the percentage percent difference between the results from the baseline.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you can see right away from the table is that generally precision drops by just a little.",
                    "label": 0
                },
                {
                    "sent": "Recall improves dramatically.",
                    "label": 0
                },
                {
                    "sent": "And this translates into greater improvement in an improvement in overall F measure, and you can see that this is actually consistent across all three datasets.",
                    "label": 0
                },
                {
                    "sent": "One of the things that is kind of surprising and you know we would, we guessed, I mean, my initial guess starting this that cross language capitalization would actually benefit persons and locations a lot.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the most benefit happened to persons and less so two locations.",
                    "label": 0
                },
                {
                    "sent": "And this is actually consistent across all datasets.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, we're getting some improvement here.",
                    "label": 0
                },
                {
                    "sent": "We're getting some improvement here and some improvement there OK?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As far as the second feature that we looked at was trends across language transliteration, and we've done this not at word sequence level, but actually at word level where basically we come in and say OK, here we have an Arabic token.",
                    "label": 0
                },
                {
                    "sent": "If we go and translate this Arabic token to English using our phrase table, is the translation also a transliteration or not?",
                    "label": 1
                },
                {
                    "sent": "And if it's a transliteration, then it would make sense that generally named entities get transliterated.",
                    "label": 1
                },
                {
                    "sent": "Specially persons and locations and less so to organisations.",
                    "label": 0
                },
                {
                    "sent": "And we again we used very similar ratio to the one that we had that I had showed you for for cross language capitalization and here as an example.",
                    "label": 0
                },
                {
                    "sent": "Basically I have this token has an in Arabic and then you know this is 1 possible translation and this is another possible translation and good there's a third possible translation and as you can see has and you can probably figure out these two.",
                    "label": 0
                },
                {
                    "sent": "First two are actually transliterations.",
                    "label": 0
                },
                {
                    "sent": "And the last one is not.",
                    "label": 0
                },
                {
                    "sent": "So basically the value of the feature becomes this.",
                    "label": 0
                },
                {
                    "sent": "You know, the probability of these two translations divided by the probability of the sum of the other translations.",
                    "label": 0
                },
                {
                    "sent": "One thing that is worth noting here is that most CRF implementation CRF implementations actually take nominal features rather than continuous value features, so all these values were been to one significant figure.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, we saw very, very similar results to the results that we saw for crossing which capitalization where again we saw a drop in recall and precision and improvement in recall and recall improvement was much greater for persons compared to any other named entity type, and we still have to investigate why this actually happened as opposed to just having persons and locations as we initially suspected an and hopefully if he.",
                    "label": 0
                },
                {
                    "sent": "Trans Cross lingual transliteration would kind of be a shoo in for crap cross language capitalization, specially if your helper language or your friendly language that you're that you're trying to refer to doesn't have a feature like capitalization for example.",
                    "label": 1
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "And this seems I mean like the street data set.",
                    "label": 0
                },
                {
                    "sent": "No matter what we do is just.",
                    "label": 0
                },
                {
                    "sent": "You know, kind of likes being low and and and you know not so you know.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not so friendly, OK?",
                    "label": 0
                },
                {
                    "sent": "The less feature that we looked at was.",
                    "label": 0
                },
                {
                    "sent": "Basically, if we can go from an Arabic word sequence into an English word sequence that we can identify an entry inside Wikipedia or an action entry inside DB pedia, and then once we go and find an entry into DB pedia, we will take the category name in the English side an we then we use that back as a feature on the Arabic side.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically we had.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "As far as DPS is concerned, I showed you the example of Nessa that we had before that NASA was an agent and an organization and a government agency and basically agent is just way too, you know, ambiguous doesn't mean very much, so some of these categories we actually manually just thrown away and we kept the ones that were more sensible.",
                    "label": 0
                },
                {
                    "sent": "And the ones that.",
                    "label": 0
                },
                {
                    "sent": "The and also if we had the choice of multiple, you know annotations.",
                    "label": 0
                },
                {
                    "sent": "We picked the one that was most likely and then for translation we used two transition resources.",
                    "label": 0
                },
                {
                    "sent": "One was the translation table that I talked to you about before and we also used Wikipedia so we went to we matched against Arabic Wikipedia entry into English Wikipedia entry into DB pedia to get the tag and the reason why using DB pedia.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Arabic Wikipedia is a translation resource aside from free stable actually use both transition methods and they will use as two separate features in our training and testing is that?",
                    "label": 0
                },
                {
                    "sent": "It seems that there's a rock band.",
                    "label": 0
                },
                {
                    "sent": "Name anything that you can come up with.",
                    "label": 0
                },
                {
                    "sent": "So you know I can come up with, you know, black ice and something has you know there's a broadband so and you actually find it in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So actually doing the restriction you know on the Arabic site to say you know this is the specific English Wikipedia entry would actually make sense that you would get the correct one in DPD.",
                    "label": 0
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "For example, I have Hezbollah.",
                    "label": 0
                },
                {
                    "sent": "This would be translated to Hezbollah and then I will go into DB Pedia and EP.",
                    "label": 0
                },
                {
                    "sent": "They would recognize that this is an organization and this is how the feature would be realized at the end, OK?",
                    "label": 0
                },
                {
                    "sent": "Let",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show the results.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about using DB pedia, which is I mean the feature is actually structurally different from the previous other two, is that you know we get improvement in both precision and recall an you'll see that even the dreaded organisations get a substantial boost and the improvement is also across the board.",
                    "label": 0
                },
                {
                    "sent": "Except for this really really really weird, strange thing called tweet data Set and I'll talk to you, but more about that later on.",
                    "label": 0
                },
                {
                    "sent": "So an improvement you know instead of we were starting around 55.",
                    "label": 0
                },
                {
                    "sent": "Now we're about 63 here and this improvement.",
                    "label": 0
                },
                {
                    "sent": "This is actually the largest you know.",
                    "label": 0
                },
                {
                    "sent": "Recorded results that for this data set and again we've improved here.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, just by just a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we could just put everything together.",
                    "label": 0
                },
                {
                    "sent": "And then you can see that we got improvement.",
                    "label": 0
                },
                {
                    "sent": "Overall, this is 84 compared to something like, you know, is a 79.9 and this is in.",
                    "label": 0
                },
                {
                    "sent": "There is a more reasonable range right before we started at 55.",
                    "label": 0
                },
                {
                    "sent": "Now we're about 64 and the tweet data set.",
                    "label": 0
                },
                {
                    "sent": "That improvement is actually quite substantial, but still the results are actually still quite low.",
                    "label": 0
                },
                {
                    "sent": "And it seems that the further away that you know the test set is from the training set, the more these features actually kind of help you.",
                    "label": 0
                },
                {
                    "sent": "Right, the help for the Enercorp data set is relatively small, because as I told you a lot of there's a lot of overlap between the training and testing sets, right?",
                    "label": 0
                },
                {
                    "sent": "While in this case you know the features that I showed you actually generalize quite well.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I showed you before, the DB Pedia feature was the best crossing with capitalization was slightly better that rather than cross lingual transliteration.",
                    "label": 0
                },
                {
                    "sent": "And the greater the difference between the training and test sets you know, the more that these features actually kind of helped you now.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turned to tweets and tweets.",
                    "label": 1
                },
                {
                    "sent": "Are very strange for a variety of reasons.",
                    "label": 0
                },
                {
                    "sent": "I've tried to, you know.",
                    "label": 0
                },
                {
                    "sent": "Just summarize some of the main things that kind of hurt you when you're doing named ignition for tweets.",
                    "label": 0
                },
                {
                    "sent": "So for one people just kind of abbreviate named entities so they would not say that they would not say Real Madrid.",
                    "label": 1
                },
                {
                    "sent": "They would say the real and that Madrid will just be you know or.",
                    "label": 0
                },
                {
                    "sent": "The name full name entity would be kind of implied.",
                    "label": 1
                },
                {
                    "sent": "Also it would start things like the Fed: and then announces blah blah blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "So named entities kind of appear at the beginning or the end of tweets rather than in the middle of tweets.",
                    "label": 1
                },
                {
                    "sent": "Also there are not many non standard text things like you know.",
                    "label": 1
                },
                {
                    "sent": "Emoticons, hashtags and URL's and so forth and all this kind of screws up the.",
                    "label": 0
                },
                {
                    "sent": "The training, I'm sorry they named entity recognition, so there is.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry there's so there is some hint that we actually need in domain data to actually carry this through to make sure that we get reasonable named entity recognition for for for tweets and perhaps do something specifically for the tweets.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. OK, so this is my last slide so it just comes right in time.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So as I told you that cross single features actually kind of help you quite substantially there are, you know, the things that I think we need to do significant amount work work for work for handling tweets and how to actually make them.",
                    "label": 0
                },
                {
                    "sent": "You know to do reasonable name integration for them.",
                    "label": 0
                },
                {
                    "sent": "Also, DB pedia when we use that.",
                    "label": 0
                },
                {
                    "sent": "We used the most likely A tag.",
                    "label": 0
                },
                {
                    "sent": "While you know multiple tags actually may actually end up helping you more.",
                    "label": 0
                },
                {
                    "sent": "And this is about it.",
                    "label": 0
                },
                {
                    "sent": "And the last thing that I want to tell you, if you're interested in the test sets that we have, there are publicly available, so you can just contact me and I'll just happily send them to you.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you for presentation.",
                    "label": 0
                },
                {
                    "sent": "Previously done some work on translating, summarize in Arabic into English in order to be evaluated using English Gold Standard, and I'm a bit sick about using any Arabic natural sorry named entity recognition where you have most of the Arabic names with the meaning and I was wondering in order to be capitalized at the end.",
                    "label": 0
                },
                {
                    "sent": "What if it was translated, for example your name and Kareem and you have like at least 6 words.",
                    "label": 0
                },
                {
                    "sent": "That means cream like or just like curious are those unfriendly, named it the language is always under resourced and that's why you looking at them.",
                    "label": 0
                },
                {
                    "sent": "And if the translation of names will always come up with the meaning or would it be capitalized?",
                    "label": 0
                },
                {
                    "sent": "Sure, this so this is a very good question.",
                    "label": 0
                },
                {
                    "sent": "So basically this is not a binary decision on whether you know the transition is actually capitalized, for example or not.",
                    "label": 0
                },
                {
                    "sent": "Basically, you kind of give your issue so you say you know, given all the transitions that I know for this word, which hopefully would cover most of the sensors in Arabic.",
                    "label": 0
                },
                {
                    "sent": "You know the probability that it actually comes becomes capitalized on the English side, there's this much.",
                    "label": 0
                },
                {
                    "sent": "Just say you know you know 10% or 20% to 50%, so this gives you kind of a clue and then all the other things around it.",
                    "label": 0
                },
                {
                    "sent": "For example, you know the word before it they were after it and other things.",
                    "label": 0
                },
                {
                    "sent": "We kind of help you along, so none of these features are kind of, you know, be all and end all kinds of features, but they just all push you along and hopefully in the right direction.",
                    "label": 0
                },
                {
                    "sent": "I was wondering, for the tweets you presumably got the gold standard by some human coding.",
                    "label": 0
                },
                {
                    "sent": "Yes OK so then I was curious if you did some sort of cross validation.",
                    "label": 0
                },
                {
                    "sent": "Basically meaning if you train your system based on a part of the tweets and then test it on the rest, how good or how bad is it still so so let me tell you you know, we have actually some results that we have that we've obtained and this is a bit outside the scope of the paper.",
                    "label": 0
                },
                {
                    "sent": "That actually using a part of the tweets for for training.",
                    "label": 0
                },
                {
                    "sent": "Helps a lot.",
                    "label": 0
                },
                {
                    "sent": "Which actually kind of makes sense because you know that the transitions between words.",
                    "label": 0
                },
                {
                    "sent": "The transition probabilities are different the way that they're kind of, you know, the trigger words are different position in the sentence are different than many.",
                    "label": 0
                },
                {
                    "sent": "Many things are different, so we actually used in domain training data that helped a lot.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the nice talk.",
                    "label": 0
                },
                {
                    "sent": "Actually I have a question that was might have been answered but it was not really clear so you gave us three different approaches.",
                    "label": 0
                },
                {
                    "sent": "Yes, in order to improve your performance.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK the question is, have you tried combining them so the last result?",
                    "label": 0
                },
                {
                    "sent": "Because I'm thinking of possible overlap between the methods.",
                    "label": 0
                },
                {
                    "sent": "OK so so how about this?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The combined feature 3 features together OK, so it's is it because I can and cannot do the math right now, so it is the effect additive.",
                    "label": 0
                },
                {
                    "sent": "So I mean or so is there significant?",
                    "label": 0
                },
                {
                    "sent": "Does it make sense for me to use all three?",
                    "label": 0
                },
                {
                    "sent": "So the answer.",
                    "label": 0
                },
                {
                    "sent": "So the answer is yes, so let me show you like from the previous results which is the pedia was actually the strongest of the three features, right?",
                    "label": 0
                },
                {
                    "sent": "And you know here is 83 and 62.",
                    "label": 0
                },
                {
                    "sent": "And then when you go here you get you know 84 and 64.",
                    "label": 0
                },
                {
                    "sent": "So there is actually room for improvement by adding them together.",
                    "label": 0
                },
                {
                    "sent": "Thank you, can I ask a final question so for, for obvious reasons, you've looked at how you can improve the Arabic problem which has few resource is using the huge response resources for English.",
                    "label": 0
                },
                {
                    "sent": "Would it be useful the other way round?",
                    "label": 0
                },
                {
                    "sent": "So could the Arabic resource is be useful for English named entity recognition in some circumstances do you think?",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "So potentially yes, and let me tell you where this would actually help.",
                    "label": 0
                },
                {
                    "sent": "If I had things that were probably more culturally, you know, or you know named entities that that would more likely appear and more Arabic text for some reason, or I have some gazetteers that we kind of have better coverage for things that are, you know, more culturally or sensitive to Arabic, then then I think that would kind of make sense to do.",
                    "label": 0
                },
                {
                    "sent": "But whether we do generalize for everything, I don't know.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you and just coffee now.",
                    "label": 0
                }
            ]
        }
    }
}