{
    "id": "yn27n2jittnzvz3iuzt7c64c42sp2nvy",
    "title": "High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity",
    "info": {
        "author": [
            "Po-Ling Loh, Department of Statistics, UC Berkeley"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Regression"
        ]
    },
    "url": "http://videolectures.net/nips2011_loh_nonconvexity/",
    "segmentation": [
        [
            "Hi everyone, thanks for coming to my talk so today I'll be talking about high dimensional sparse regression when we have corruption in the variables.",
            "This is joint work with my advisor, Martin Wainwright, also from UC Berkeley."
        ],
        [
            "So this is just one slide of motivation, as you know who we're talking about.",
            "High dimensional problems where the number of parameters which we'll denote by P is much larger than the number of observations which we'll denote by N, and in many of the real world applications like the ones mentioned on this slide, P is often on the order of 10s of thousands, whereas an is on the order of hundreds."
        ],
        [
            "In particular, we'll be talking about linear regression, and so I'll remind you that a linear model is, while in which the variables XI and why I have a linear relationship.",
            "In this case, beta star is the parameter vector we're trying to infer, and since P is the number of parameters, then beta star is a vector of dimension P, and since P is larger than N, you can see from this diagram that X is going to be a shortened."
        ],
        [
            "Matrix.",
            "Now since P is larger than N, we have some intrinsic non identifiability and in order to recover beta star we need to impose some structural conditions.",
            "So we'll assume that the vector beta star is sparse.",
            "It has at most K non zero entries, but we don't know where those K."
        ],
        [
            "Entries are.",
            "Now this is a problem that has been widely studied in the last 10 or 15 years, and we're going to add an extra level of complication which comes from observing variables under subject to some corruption, so we'll assume that instead of observing the matrix X, we observe a corrupted version, which will call Z."
        ],
        [
            "One example, so we'll have two examples that we look at in detail.",
            "The first example is additive noise, so Z is equal to X plus some additive noise which is independent of X.",
            "And we need to know something about the pattern of corruption.",
            "In this case, we'll assume that we know Sigma W, which is the covariance of the noisy of the noise that we're adding examples of.",
            "When this occurs, in practice, our medical or experimental data where we observe a noisy version of the measurements or portfolio optimization when we're trying to solve some kind of regression problem.",
            "But all we have is like a sample covariance matrix.",
            "Anne."
        ],
        [
            "The second example will be looking at is missing data and in this example the entries of X are missing independently with probability Alpha.",
            "In the statistical literature, it's also known as data missing completely at random.",
            "And here Alpha is the probability that the entries are missing and it's a parameter that we can know beforehand or that we can estimate based on our observations.",
            "Examples of this when it comes up in practice are given on the bottom, and we're also going to point out that our theory allows for the setting when each column which corresponds to the P features has a different probability that the entry."
        ],
        [
            "These are missing, for instance in the context of survey data.",
            "Each question could have a different probability that it was skipped by the person filling out the survey."
        ],
        [
            "Now I'll remind you that the model again is the same, so we have a linear relationship between Y&X, but in general, for instance in the missing data case, there wouldn't be a linear relationship between Y&Z yet based on the the corrupted observations, we're trying to still infer this unknown beta star."
        ],
        [
            "I'll also point out that some methods that have been used previously, REM based methods for trying to fill in the missing values or the the noise that we're adding.",
            "However, the one drawback, the main drawback of EM is that since the objective that we're trying to minimize is nonconvex, oftentimes it will get stuck in local Optima and depending on the starting point of the algorithm, you have wildly different solutions.",
            "And it turns out that the objective that we will try to minimize is also nonconvex.",
            "However, we will show methods that can be used to optimize it efficiently."
        ],
        [
            "So how do we formulate our objective?",
            "Well, what I have here is a simple algebraic identity, and I'm going to compare this to the lasso and show you how we could unpack the lasso and use the lasso objective to motivate a new objective for corrupted data."
        ],
        [
            "And so if we look at the lasso, this is the constrained version where we're optimizing over an L1 ball to promote."
        ],
        [
            "Sparsity if we expand it out, you can see that there's a relationship between the expanded version and the algebraic identity of above, namely, if the observations X have zero mean, the X transpose X / N matrix is an unbiased estimator of the red Sigma X, which is up top.",
            "And similarly, the blue estimator Y, transpose X / N is an unbiased estimator of the covariance of Y&X, which for the linear model is the blue thing up top.",
            "Beta star transpose Sigma X.",
            "So that's the idea we'll use if we can somehow find unbiased estimators of the red and blue quantities based on corrupted variables, then maybe we can optimize a similar objective and get good theoret."
        ],
        [
            "Equal results.",
            "So the idea is given on this slide based on noisy observations, Y&Z form unbiased estimators, capital gamma hat and lower case, gamma hat and plug them in.",
            "And again we're optimizing over an L1 ball to promote sparsity in high dimensions.",
            "So that's the main idea."
        ],
        [
            "And to illustrate this idea, let's look at examples in the two frameworks that I mentioned earlier.",
            "So in the additive noise framework, since we're adding independent noise, it turns out that Sigma Z decomposes as a sum of Sigma X and Sigma W and also the covariance of Y&X is equal to the covariance of Y&Z.",
            "So the S."
        ],
        [
            "The meters will use are very natural since we observe Z form the sample covariance of Z and subtract the covariance of Sigma W which we assume we know and then use the unbiased estimator of Y&Z as a surrogate for the covariance."
        ],
        [
            "Hawaiian X.",
            "And this is the estimator that we get.",
            "Now, in the case of missing data."
        ],
        [
            "The math is a little bit more."
        ],
        [
            "Complicated, but I'll put it on this slide.",
            "Essentially what happens is you take your matrix Z with missing data and then you re scale it by 1 minus the probability Alpha that the entries are missing and this will effectively correct for the bias.",
            "And then we need to subtract the diagonal term and that corresponds to the fact that the diagonal entries are the variances of the features, whereas the off diagonals are the covariances of different features and then the objective that we get is down here on the bottom.",
            "So that's all good.",
            "But then the question is, how good is our estimator?",
            "Is it true that Beta hat will converge to the true beta star that we're trying to infer?",
            "And if so, at what rate?"
        ],
        [
            "And this is what we would call statistical can."
        ],
        [
            "Agency.",
            "So what I've plotted here is an empirical simulation.",
            "Basically we took this lasso that we proposed and ran it on the additive noise model of corruption for three different problem instances where P is 100, two, 100 and 500, and the sparsity is on the order of square root of P. And what you'll find is that if you plot L2 norm error versus number of observations N for each curve, it seems to be decreasing down to 0.",
            "And so that implies that our estimator seems to be consistent.",
            "Furthermore, as P increases, the curves are shifting upward because the problem is getting harder and harder.",
            "So this matches our intuition."
        ],
        [
            "But what can we say theoretically?",
            "Well, I will compare this to the standard results for the LASSO in the fully observed data case.",
            "And it's known that under restricted eigenvalue conditions which hold with high probability, say when X has rows sampled from a Gaussian distribution will get L1L2 error bounds on the distance between beta hat and beta star on the order given on this slide.",
            "Now for our corrupted case, it turns out that we get very similar."
        ],
        [
            "Bounds.",
            "So this slide gives our theorem on statistical error and essentially under similar restricted eigenvalue conditions and these deviation conditions down below, which I'll discuss in a moment.",
            "We get similar scaling that the L1 error is on the order of K, RT, log, P, / N and the L2 error is on the order of K log, P, /, N and the deviation conditions essentially tell us how good the red and blue estimators are for the population version, because right now all we've said is that they are unbiased.",
            "But they need to be close in some sense and then this extra."
        ],
        [
            "Term fee this is essentially a function of the pattern of corruption, be it additive noise or missing data and the variance.",
            "The noise variance of epsilon and in particular as you would expect as the noise in the additive noise setting increases, the problem gets harder.",
            "Sophie will increase and similarly as Alpha, the amount of corrupted data increases.",
            "Fee will get larger."
        ],
        [
            "So here I'm showing again this slide which shows empirical consistency.",
            "And what we see on the next slide?"
        ],
        [
            "Is that if we re scale the horizontal axis so it's N / K log P, then the three curves stack up and this agrees with our theory because our theory tells us that L2 error is on the order of root quelaag P / N. So if K log P / N is constant then for different problem instances the L2 error should be approximately the same.",
            "So that's the issue of statistical consistency that we just did."
        ],
        [
            "Now the other issue which is interesting is optimization.",
            "And as I hinted at the beginning of my talk and in the title, there are some issues of non convexity.",
            "And So what I've copied here is the objective for the additive noise case.",
            "And it turns out that it's not only nonconvex, but it's quite badly nonconvex, and what you would like to say maybe is that with high probability it's convex, but that's not even true because Z transpose Y / N is a rank deficient matrix, so it will have a whole bunch of zero eigenvalues, and then we subtract a positive definite matrix, so this has the interim is actually very very non positive, semi definite.",
            "But if it were a convex problem, one method you could use is projected gradient descent, which I'll discuss on the next slide."
        ],
        [
            "And it turns out that if we can pretend that this objective is convex and use projected gradient descent, we still get good behavior to optimize the nonconvex objective.",
            "So let me remind you what."
        ],
        [
            "Rejected gradient descent is basically what we tried to do is solve an optimization problem where we minimize a loss function L subject to some kind of convex constraint, and here I've put down the sum of the squares of the errors, but it could be any convex function."
        ],
        [
            "And the method basically goes from iterates Beta, Tita beta, T + 1 by going in the direction of the negative gradient.",
            "And since we want to constrain ourselves to this feasible set if we go outside the feasible set, we simply project back down on to the set and so we walk around."
        ],
        [
            "Now the theory tells us that if L is convex, in fact, strongly convex and smooth we get linear convergence rates, which basically says that the distance between the iterative beta T and the true optomizer beta hat will have this geometric contraction."
        ],
        [
            "However, when L is not convex like in our problem, there is no reason to think that projected gradient descent should converge or should converge to the global optimum.",
            "Or even like, even if it converges to converge."
        ],
        [
            "Quickly.",
            "But it turns out that for our problem, what we see is that we do get this linear convergence even though we have a nonconvex objective.",
            "And empirically, what we've done is plotted projected gradient descent run on and on our non convex problem with 10 different starting points and we see that if we plot log of the error, we're getting geometric convergence."
        ],
        [
            "So the theorem is given here.",
            "Basically we have linear convergence.",
            "Sorry, I just said geometric up to a certain point, and in particular if you remember our statistical error, beta hat minus beta star was on the order of root Kellogg, P, / N and so here we basically are getting linear convergence up to a point that was within the statistical precision."
        ],
        [
            "And I'll just mention that we use results from Agarwal at all from last year's NIPS applied to our nonconvex objective, and the sufficient conditions in their case are called restricted strong convexity and restricted smoothness, and so we need to verify that these hold with high probability in our settings of interest."
        ],
        [
            "And here we have a recapitulation with a picture.",
            "So the idea is that we were looking for the true beta star an we've proven that for any global optimizer beta hat, it lies within all of route quelaag P / N of beta star.",
            "There might be several optimizers, but they all lie within this region.",
            "And then when we run projected gradient descent, walking down from beta 0 beta T and so on, But then will converge to within little O of root K, log P, / N abeyta hat.",
            "So if we're in a regime where K log P /, N is going to 0, then projected gradient descent is converging quite efficiently to the true beta."
        ],
        [
            "They are.",
            "So in the last minute or two I am just going to talk a bit about an interesting application of our work.",
            "We'll be looking at Gaussian graphical models.",
            "And as you may know from standard theory on graphical models, if we have a bunch of nodes that represent the different variables that we're looking at, then the distribution of Xu on one node conditioned on all the other nodes is the same as the distribution of X you conditioned on its immediate neighbors."
        ],
        [
            "And when X is distributed as a multivariate Gaussian, then it turns out that the entries of the inverse covariance matrix the the non zero entries correspond to edges in this graph and there's a relationship between the entries and linear regression of one note against the rest.",
            "This idea was used by Meinshausen Billman for support recovery for the inverse covariance matrix of a Gaussian.",
            "It also used by again, but with the dancing selector to actually estimate Theta.",
            "And here we have to assume in high dimensions that that's true, Theta is sparse, and the sparsity or the number of non zeros in each row will correspond to the maximum degree of the of the Gaussian graphical model.",
            "So the idea is that since we can reduce estimation.",
            "Of Theta to a bunch of linear."
        ],
        [
            "Regressions we can also use these ideas in our case with corrupted variables.",
            "So essentially applying our ideas on corrupted linear regression, we can still recover the inverse covariance matrix of a Gaussian graphical model based on corrupted observations which might be corrupted due to additive noise or missing data."
        ],
        [
            "And so the theory basically will give us a statement about the spectral norm of the difference between the estimated Theta hat and the true Theta.",
            "And the result is that we have consistency on the order of K root log P / N which actually agrees up to some scaling constants with the result for estimating Theta in the fully observed case."
        ],
        [
            "So in summary, we have proposed a variant of the Lasso which works for corrupted observations, which exhibits good consistency in L2 and also in L1.",
            "And Furthermore, we have used this theory to find an estimator for the inverse covariance matrix of a Gaussian graphical model that also has scaling, which is roughly the same as in the fully observed case.",
            "And finally, we've shown that even though the objective we create is not convex, we can still use projected gradient descent to find a good optimizer."
        ],
        [
            "So this slide gives some open questions and that's it, thanks.",
            "OK, so the question was how we thought about using other objective measures, for which say M might be a better solution or comparable solution.",
            "Are you talking about like different types of loss functions for instance?",
            "Yeah, so so we could apply it to different loss functions.",
            "There are also cases when we could apply it to different assumptions on the pattern of corruption.",
            "For instance, like we had to assume here that we have data which is missing completely at random but EM for instance might be used in cases where that assumption is relaxed.",
            "So it might allow for more general corruption patterns, and so it would be a good a good direction.",
            "Future direction to try to compare them on some models that might not be specifically what?",
            "Our theory is referring to."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, thanks for coming to my talk so today I'll be talking about high dimensional sparse regression when we have corruption in the variables.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my advisor, Martin Wainwright, also from UC Berkeley.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is just one slide of motivation, as you know who we're talking about.",
                    "label": 0
                },
                {
                    "sent": "High dimensional problems where the number of parameters which we'll denote by P is much larger than the number of observations which we'll denote by N, and in many of the real world applications like the ones mentioned on this slide, P is often on the order of 10s of thousands, whereas an is on the order of hundreds.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In particular, we'll be talking about linear regression, and so I'll remind you that a linear model is, while in which the variables XI and why I have a linear relationship.",
                    "label": 0
                },
                {
                    "sent": "In this case, beta star is the parameter vector we're trying to infer, and since P is the number of parameters, then beta star is a vector of dimension P, and since P is larger than N, you can see from this diagram that X is going to be a shortened.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matrix.",
                    "label": 0
                },
                {
                    "sent": "Now since P is larger than N, we have some intrinsic non identifiability and in order to recover beta star we need to impose some structural conditions.",
                    "label": 0
                },
                {
                    "sent": "So we'll assume that the vector beta star is sparse.",
                    "label": 0
                },
                {
                    "sent": "It has at most K non zero entries, but we don't know where those K.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Entries are.",
                    "label": 0
                },
                {
                    "sent": "Now this is a problem that has been widely studied in the last 10 or 15 years, and we're going to add an extra level of complication which comes from observing variables under subject to some corruption, so we'll assume that instead of observing the matrix X, we observe a corrupted version, which will call Z.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One example, so we'll have two examples that we look at in detail.",
                    "label": 0
                },
                {
                    "sent": "The first example is additive noise, so Z is equal to X plus some additive noise which is independent of X.",
                    "label": 1
                },
                {
                    "sent": "And we need to know something about the pattern of corruption.",
                    "label": 0
                },
                {
                    "sent": "In this case, we'll assume that we know Sigma W, which is the covariance of the noisy of the noise that we're adding examples of.",
                    "label": 0
                },
                {
                    "sent": "When this occurs, in practice, our medical or experimental data where we observe a noisy version of the measurements or portfolio optimization when we're trying to solve some kind of regression problem.",
                    "label": 1
                },
                {
                    "sent": "But all we have is like a sample covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second example will be looking at is missing data and in this example the entries of X are missing independently with probability Alpha.",
                    "label": 1
                },
                {
                    "sent": "In the statistical literature, it's also known as data missing completely at random.",
                    "label": 0
                },
                {
                    "sent": "And here Alpha is the probability that the entries are missing and it's a parameter that we can know beforehand or that we can estimate based on our observations.",
                    "label": 0
                },
                {
                    "sent": "Examples of this when it comes up in practice are given on the bottom, and we're also going to point out that our theory allows for the setting when each column which corresponds to the P features has a different probability that the entry.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are missing, for instance in the context of survey data.",
                    "label": 0
                },
                {
                    "sent": "Each question could have a different probability that it was skipped by the person filling out the survey.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'll remind you that the model again is the same, so we have a linear relationship between Y&X, but in general, for instance in the missing data case, there wouldn't be a linear relationship between Y&Z yet based on the the corrupted observations, we're trying to still infer this unknown beta star.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll also point out that some methods that have been used previously, REM based methods for trying to fill in the missing values or the the noise that we're adding.",
                    "label": 0
                },
                {
                    "sent": "However, the one drawback, the main drawback of EM is that since the objective that we're trying to minimize is nonconvex, oftentimes it will get stuck in local Optima and depending on the starting point of the algorithm, you have wildly different solutions.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the objective that we will try to minimize is also nonconvex.",
                    "label": 0
                },
                {
                    "sent": "However, we will show methods that can be used to optimize it efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we formulate our objective?",
                    "label": 0
                },
                {
                    "sent": "Well, what I have here is a simple algebraic identity, and I'm going to compare this to the lasso and show you how we could unpack the lasso and use the lasso objective to motivate a new objective for corrupted data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so if we look at the lasso, this is the constrained version where we're optimizing over an L1 ball to promote.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sparsity if we expand it out, you can see that there's a relationship between the expanded version and the algebraic identity of above, namely, if the observations X have zero mean, the X transpose X / N matrix is an unbiased estimator of the red Sigma X, which is up top.",
                    "label": 0
                },
                {
                    "sent": "And similarly, the blue estimator Y, transpose X / N is an unbiased estimator of the covariance of Y&X, which for the linear model is the blue thing up top.",
                    "label": 0
                },
                {
                    "sent": "Beta star transpose Sigma X.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea we'll use if we can somehow find unbiased estimators of the red and blue quantities based on corrupted variables, then maybe we can optimize a similar objective and get good theoret.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Equal results.",
                    "label": 0
                },
                {
                    "sent": "So the idea is given on this slide based on noisy observations, Y&Z form unbiased estimators, capital gamma hat and lower case, gamma hat and plug them in.",
                    "label": 1
                },
                {
                    "sent": "And again we're optimizing over an L1 ball to promote sparsity in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "So that's the main idea.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to illustrate this idea, let's look at examples in the two frameworks that I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "So in the additive noise framework, since we're adding independent noise, it turns out that Sigma Z decomposes as a sum of Sigma X and Sigma W and also the covariance of Y&X is equal to the covariance of Y&Z.",
                    "label": 1
                },
                {
                    "sent": "So the S.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The meters will use are very natural since we observe Z form the sample covariance of Z and subtract the covariance of Sigma W which we assume we know and then use the unbiased estimator of Y&Z as a surrogate for the covariance.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hawaiian X.",
                    "label": 0
                },
                {
                    "sent": "And this is the estimator that we get.",
                    "label": 0
                },
                {
                    "sent": "Now, in the case of missing data.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The math is a little bit more.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complicated, but I'll put it on this slide.",
                    "label": 0
                },
                {
                    "sent": "Essentially what happens is you take your matrix Z with missing data and then you re scale it by 1 minus the probability Alpha that the entries are missing and this will effectively correct for the bias.",
                    "label": 0
                },
                {
                    "sent": "And then we need to subtract the diagonal term and that corresponds to the fact that the diagonal entries are the variances of the features, whereas the off diagonals are the covariances of different features and then the objective that we get is down here on the bottom.",
                    "label": 0
                },
                {
                    "sent": "So that's all good.",
                    "label": 0
                },
                {
                    "sent": "But then the question is, how good is our estimator?",
                    "label": 0
                },
                {
                    "sent": "Is it true that Beta hat will converge to the true beta star that we're trying to infer?",
                    "label": 0
                },
                {
                    "sent": "And if so, at what rate?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what we would call statistical can.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Agency.",
                    "label": 0
                },
                {
                    "sent": "So what I've plotted here is an empirical simulation.",
                    "label": 0
                },
                {
                    "sent": "Basically we took this lasso that we proposed and ran it on the additive noise model of corruption for three different problem instances where P is 100, two, 100 and 500, and the sparsity is on the order of square root of P. And what you'll find is that if you plot L2 norm error versus number of observations N for each curve, it seems to be decreasing down to 0.",
                    "label": 0
                },
                {
                    "sent": "And so that implies that our estimator seems to be consistent.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, as P increases, the curves are shifting upward because the problem is getting harder and harder.",
                    "label": 0
                },
                {
                    "sent": "So this matches our intuition.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But what can we say theoretically?",
                    "label": 0
                },
                {
                    "sent": "Well, I will compare this to the standard results for the LASSO in the fully observed data case.",
                    "label": 0
                },
                {
                    "sent": "And it's known that under restricted eigenvalue conditions which hold with high probability, say when X has rows sampled from a Gaussian distribution will get L1L2 error bounds on the distance between beta hat and beta star on the order given on this slide.",
                    "label": 1
                },
                {
                    "sent": "Now for our corrupted case, it turns out that we get very similar.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bounds.",
                    "label": 0
                },
                {
                    "sent": "So this slide gives our theorem on statistical error and essentially under similar restricted eigenvalue conditions and these deviation conditions down below, which I'll discuss in a moment.",
                    "label": 0
                },
                {
                    "sent": "We get similar scaling that the L1 error is on the order of K, RT, log, P, / N and the L2 error is on the order of K log, P, /, N and the deviation conditions essentially tell us how good the red and blue estimators are for the population version, because right now all we've said is that they are unbiased.",
                    "label": 1
                },
                {
                    "sent": "But they need to be close in some sense and then this extra.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Term fee this is essentially a function of the pattern of corruption, be it additive noise or missing data and the variance.",
                    "label": 0
                },
                {
                    "sent": "The noise variance of epsilon and in particular as you would expect as the noise in the additive noise setting increases, the problem gets harder.",
                    "label": 0
                },
                {
                    "sent": "Sophie will increase and similarly as Alpha, the amount of corrupted data increases.",
                    "label": 0
                },
                {
                    "sent": "Fee will get larger.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I'm showing again this slide which shows empirical consistency.",
                    "label": 0
                },
                {
                    "sent": "And what we see on the next slide?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that if we re scale the horizontal axis so it's N / K log P, then the three curves stack up and this agrees with our theory because our theory tells us that L2 error is on the order of root quelaag P / N. So if K log P / N is constant then for different problem instances the L2 error should be approximately the same.",
                    "label": 0
                },
                {
                    "sent": "So that's the issue of statistical consistency that we just did.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the other issue which is interesting is optimization.",
                    "label": 0
                },
                {
                    "sent": "And as I hinted at the beginning of my talk and in the title, there are some issues of non convexity.",
                    "label": 0
                },
                {
                    "sent": "And So what I've copied here is the objective for the additive noise case.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that it's not only nonconvex, but it's quite badly nonconvex, and what you would like to say maybe is that with high probability it's convex, but that's not even true because Z transpose Y / N is a rank deficient matrix, so it will have a whole bunch of zero eigenvalues, and then we subtract a positive definite matrix, so this has the interim is actually very very non positive, semi definite.",
                    "label": 0
                },
                {
                    "sent": "But if it were a convex problem, one method you could use is projected gradient descent, which I'll discuss on the next slide.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that if we can pretend that this objective is convex and use projected gradient descent, we still get good behavior to optimize the nonconvex objective.",
                    "label": 0
                },
                {
                    "sent": "So let me remind you what.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rejected gradient descent is basically what we tried to do is solve an optimization problem where we minimize a loss function L subject to some kind of convex constraint, and here I've put down the sum of the squares of the errors, but it could be any convex function.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the method basically goes from iterates Beta, Tita beta, T + 1 by going in the direction of the negative gradient.",
                    "label": 0
                },
                {
                    "sent": "And since we want to constrain ourselves to this feasible set if we go outside the feasible set, we simply project back down on to the set and so we walk around.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the theory tells us that if L is convex, in fact, strongly convex and smooth we get linear convergence rates, which basically says that the distance between the iterative beta T and the true optomizer beta hat will have this geometric contraction.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, when L is not convex like in our problem, there is no reason to think that projected gradient descent should converge or should converge to the global optimum.",
                    "label": 0
                },
                {
                    "sent": "Or even like, even if it converges to converge.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quickly.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that for our problem, what we see is that we do get this linear convergence even though we have a nonconvex objective.",
                    "label": 0
                },
                {
                    "sent": "And empirically, what we've done is plotted projected gradient descent run on and on our non convex problem with 10 different starting points and we see that if we plot log of the error, we're getting geometric convergence.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the theorem is given here.",
                    "label": 0
                },
                {
                    "sent": "Basically we have linear convergence.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I just said geometric up to a certain point, and in particular if you remember our statistical error, beta hat minus beta star was on the order of root Kellogg, P, / N and so here we basically are getting linear convergence up to a point that was within the statistical precision.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll just mention that we use results from Agarwal at all from last year's NIPS applied to our nonconvex objective, and the sufficient conditions in their case are called restricted strong convexity and restricted smoothness, and so we need to verify that these hold with high probability in our settings of interest.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we have a recapitulation with a picture.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we were looking for the true beta star an we've proven that for any global optimizer beta hat, it lies within all of route quelaag P / N of beta star.",
                    "label": 0
                },
                {
                    "sent": "There might be several optimizers, but they all lie within this region.",
                    "label": 0
                },
                {
                    "sent": "And then when we run projected gradient descent, walking down from beta 0 beta T and so on, But then will converge to within little O of root K, log P, / N abeyta hat.",
                    "label": 0
                },
                {
                    "sent": "So if we're in a regime where K log P /, N is going to 0, then projected gradient descent is converging quite efficiently to the true beta.",
                    "label": 1
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They are.",
                    "label": 0
                },
                {
                    "sent": "So in the last minute or two I am just going to talk a bit about an interesting application of our work.",
                    "label": 0
                },
                {
                    "sent": "We'll be looking at Gaussian graphical models.",
                    "label": 1
                },
                {
                    "sent": "And as you may know from standard theory on graphical models, if we have a bunch of nodes that represent the different variables that we're looking at, then the distribution of Xu on one node conditioned on all the other nodes is the same as the distribution of X you conditioned on its immediate neighbors.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And when X is distributed as a multivariate Gaussian, then it turns out that the entries of the inverse covariance matrix the the non zero entries correspond to edges in this graph and there's a relationship between the entries and linear regression of one note against the rest.",
                    "label": 1
                },
                {
                    "sent": "This idea was used by Meinshausen Billman for support recovery for the inverse covariance matrix of a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "It also used by again, but with the dancing selector to actually estimate Theta.",
                    "label": 0
                },
                {
                    "sent": "And here we have to assume in high dimensions that that's true, Theta is sparse, and the sparsity or the number of non zeros in each row will correspond to the maximum degree of the of the Gaussian graphical model.",
                    "label": 1
                },
                {
                    "sent": "So the idea is that since we can reduce estimation.",
                    "label": 0
                },
                {
                    "sent": "Of Theta to a bunch of linear.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regressions we can also use these ideas in our case with corrupted variables.",
                    "label": 0
                },
                {
                    "sent": "So essentially applying our ideas on corrupted linear regression, we can still recover the inverse covariance matrix of a Gaussian graphical model based on corrupted observations which might be corrupted due to additive noise or missing data.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the theory basically will give us a statement about the spectral norm of the difference between the estimated Theta hat and the true Theta.",
                    "label": 0
                },
                {
                    "sent": "And the result is that we have consistency on the order of K root log P / N which actually agrees up to some scaling constants with the result for estimating Theta in the fully observed case.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, we have proposed a variant of the Lasso which works for corrupted observations, which exhibits good consistency in L2 and also in L1.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, we have used this theory to find an estimator for the inverse covariance matrix of a Gaussian graphical model that also has scaling, which is roughly the same as in the fully observed case.",
                    "label": 1
                },
                {
                    "sent": "And finally, we've shown that even though the objective we create is not convex, we can still use projected gradient descent to find a good optimizer.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this slide gives some open questions and that's it, thanks.",
                    "label": 1
                },
                {
                    "sent": "OK, so the question was how we thought about using other objective measures, for which say M might be a better solution or comparable solution.",
                    "label": 0
                },
                {
                    "sent": "Are you talking about like different types of loss functions for instance?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so we could apply it to different loss functions.",
                    "label": 0
                },
                {
                    "sent": "There are also cases when we could apply it to different assumptions on the pattern of corruption.",
                    "label": 0
                },
                {
                    "sent": "For instance, like we had to assume here that we have data which is missing completely at random but EM for instance might be used in cases where that assumption is relaxed.",
                    "label": 1
                },
                {
                    "sent": "So it might allow for more general corruption patterns, and so it would be a good a good direction.",
                    "label": 0
                },
                {
                    "sent": "Future direction to try to compare them on some models that might not be specifically what?",
                    "label": 0
                },
                {
                    "sent": "Our theory is referring to.",
                    "label": 0
                }
            ]
        }
    }
}