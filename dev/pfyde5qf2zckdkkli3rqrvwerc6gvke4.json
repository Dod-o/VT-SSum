{
    "id": "pfyde5qf2zckdkkli3rqrvwerc6gvke4",
    "title": "Human Language Technology for the Semantic Web",
    "info": {
        "author": [
            "Hamish Cunningham, Department of Molecular Biology and Biotechnology, University of Sheffield"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "January 2004",
        "category": [
            "Top->Computer Science->Machine Learning->Human Language Technology",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/training06_cunningham_hltsw1/",
    "segmentation": [
        [
            "So welcome to the second tutorial session.",
            "the European Semantic web symposium.",
            "My name is finished Cunningham, my colleagues Valentin Tablan coming a bunch of her entire made out of doing the tutorial with me, will start off with some bold platitudes and simple concepts, which I'll do this stuff where I wave my hands around and make kind of bland comments.",
            "And as we go through the tutorial will get more complicated and interesting, and I'll kind of lose my depth and then the rest of the table will come and do it instead.",
            "Human language technology for the semantic web.",
            "Brought to you courtesy of whole bunch of projects including act and sect."
        ],
        [
            "Program manager sitting in the back.",
            "I have to say sick.",
            "First thing I want to say is, are you wasting your time?",
            "My brother used to be a school teacher and he showed me this thing called the learning pyramid and the width of the pyramid is proportional to the amount of stuff that you remember in various different learning activities, right?",
            "So down at the bottom here you're remembering 90% of what you do, and this is when you teach others or you use the knowledge that you're learning and immediate context.",
            "So probably if my brain wasn't so short, I remember 90% of what I'm going to do today up here at the top.",
            "Just sitting, listening passively to lecture you remember 5%.",
            "5% of the next realis is going to be left in your brain after this session.",
            "Can you make a home?",
            "I've loved outdoor, there's no.",
            "There's no way out.",
            "There's no way out of here until coffee break in an hour and a half.",
            "So the point is that if you ask a question if you try and use that knowledge, if you have a discussion over coffee break, then you can remember more stuff, right?",
            "And there's no specific."
        ],
        [
            "Discussion session in the tutorial.",
            "So whenever you want to ask a question, just throw it behind diving OK. Want to talk about it?",
            "I'm going to start with some motivation, background, information extraction.",
            "We're going to spend quite a lot of time on because that's currently the leading one of the leading technologies from language processing that's being deployed for semantic web.",
            "Valuation different approaches to information extraction.",
            "To begin with, we basically looking at language technologies.",
            "It kind of exists and has done for some time, and there's a tutorial moves out, will look more at stuff that's been done specifically in the semantic Web context.",
            "So we get around to various sorts of semantic tagging in the second half, and will finish up with language generation.",
            "The slides slightly outdated version that will be updated when we check in later on, and this URL that keep popping up throughout the session.",
            "If you want to grab it.",
            "Melville motivation Gartner reported a couple of years ago that on the one hand, through the next decade it was reported was kind of predicting the next decade of information systems.",
            "They said on the one hand, taxonomic and hierarchical knowledge mapping and indexing will become prevalent in all sorts of."
        ],
        [
            "In almost all information, rich applications, on the other hand, more than 95% of human to computer information, but will involve textual language.",
            "So there's kind of a contradiction here.",
            "On the one hand, semantics based systems systems with a kind of richer set of knowledge structures for processing information are becoming more and more common.",
            "On the other hand, most of the information out there and most of our interactions with computers in of a lot of cases is in the very ambiguous and informal.",
            "Mode of natural language.",
            "So the challenge really that we're talking about today is to try and reconcile these two these two situations.",
            "The various ways in which human language technology can do that, that various people are working on lots of people are working on.",
            "You've got on the right hand side.",
            "Here's this kind of for this.",
            "This diagram kind of summarizes those different ways, and we'll go through all of these at various stages during the tutorial on the right hand side.",
            "Here we've got the kind of formal knowledge on Teologi's knowledge base is instant spaces, and so on that underlie these new knowledge based technologies, semantic web."
        ],
        [
            "Semantic grid semantic web services and so on.",
            "The other hand, I'm here inside my left hand side about human language and these various arrows are the ways that human language technology can tie these things together.",
            "So you've got information extraction going from language to formal knowledge.",
            "You've got generation coming back in the opposite direction.",
            "You've got some kinds of controlled language information extraction that.",
            "Slightly reduced kind of human language, which is easier for machines to process.",
            "OK, so this is the kind of big picture of what we're talking about today.",
            "I just got some background out of the way before we move on to the meat.",
            "By saying that.",
            "Like other areas of computer science, language technology typically has, you know, has some typical data structures and infrastructure requirements.",
            "Just move this a bit.",
            "Might have been smarter to move the projector moment.",
            "Practice listening so various.",
            "There's some kind of typical data structures that language technology used in typical kind of infrastructural systems, so let's just get these out the way that the start before we concentrate on the on the meat of the science.",
            "One of the most important is annotation.",
            "Annotation is about associating arbitrary data with areas of text or speech, and there's a kind of de facto standard in the in the community.",
            "These days didn't always used to be like that, but these days is pretty much a defacto standard.",
            "She is based around Standoff Markup Standoff Markup is just a way of saying you don't change the language that you're analyzing, you just point to the bits that you're interested in.",
            "So instead of sticking on your XML markup inline into a document that you're analyzing, for example you have in a separate file and you have offsets, character offsets that point into the into the sources, and all all sorts of people doing doing this kind of thing.",
            "Now TR is a text encoding initiative night and important.",
            "Dialogue annotation tool Atlas Gate will cover these later.",
            "And there are all sorts of other things that are kind of coordinate technology, but not really very interesting from a scientific point of view visualization and editing, persistence and search metrics component models, so and so forth, to Caroline story, short human language technology has a lot of technological stuff underneath, behind the scenes and in this tutorial will use in many of our examples, will use a system that tries to cope with all those infrastructural needs.",
            "In one place, so that people developing these kinds of systems don't have to bother about this kind of stuff, and it's called gate general architecture, text engineering.",
            "Gates three things.",
            "It said architecture.",
            "It's A kind of high level organizational picture for the way that language processing systems fit together.",
            "Then it's a framework and object oriented class library that implements the architecture and then on top of it is built in IDE and integrated development environment.",
            "For producing these kinds of systems, why are we talking about this?",
            "Why we're using it for examples where we happen to know a little bit about it developed in Sheffield?",
            "It's free software.",
            "It's pretty comprehensive.",
            "It has growing and fairly extensive support.",
            "For semantic web stuff, but it means we can kind of ignore these infrastructure issues and just concentrate on the important stuff.",
            "This is not a claim that gate is the only system that gate is the best system in all cases or anything like that.",
            "It's just convenience.",
            "OK. Information extraction.",
            "Information extraction research has been running for maybe 15 years now.",
            "The point about it is to pull facts and structured information out of the content of text collections.",
            "And they said, instructive to get a handle on what this stuff is to compare it with information retrieval information retrieval, you type in some keywords, you get some documents back.",
            "You search for the information that you need within those documents, information extraction.",
            "You get the documents you specify an information need some particular set of facts that you're interested in that can be found in these documents, and the system automatically pulls that stuff out of the documents for you.",
            "That's the difference with retrieval.",
            "Are a bit of a history.",
            "This is a hideous caricature.",
            "Whereas we used to work on natural language understanding.",
            "We used to work on getting computers to really have a deep knowledge of what was going on in their text."
        ],
        [
            "So that it could, you know, so that you could you know the goal was to have that Star Trek computer where you talk to it and say, you know I need breakfast in 20 minutes and say the Klingons are attacking you got breakfast that got that kind of thing.",
            "OK, people used to work on this sort of stuff, at least some of them in the roundabout.",
            "The early 90s decided that the performance of these kinds of systems were so low that we want to move the goal posts, right?",
            "We couldn't score, so we made the gold digger by choosing a much simpler task.",
            "And that task was information extraction.",
            "So instead of."
        ],
        [
            "The point of my instruction is to do something to choose a task which is feasible from the point of view of end user applications to do something that you can really get end user applications out of the technology.",
            "Um?",
            "The site is about progress in information extraction and what's been driving it.",
            "This is a quote from a guy called Calvin.",
            "He gave his name to.",
            "The various things, including absolute zero, was government degrees Kelvin.",
            "Temperatures.",
            "Come inside when you can measure what you were speaking about and express it in numbers you know something about it, but when you cannot measure it when you cannot express it in numbers, your knowledge is of a meager and unsatisfactory kind.",
            "It may be the beginning of knowledge, but you have scarcely in your thoughts advanced to the stage of science.",
            "This famous man said, you gotta measure everything right behind Einstein, he said.",
            "Not everything that counts can be counted and not everything that can be counted counts.",
            "So trying Times Square those two.",
            "In any case, in information extraction community, it's been pretty much the case.",
            "But Calvin's kind of viewpoint.",
            "This viewpoint that you need to do measurement, you need to have metrics in order to have science quantitative evaluation.",
            "In other words, that's what's driven.",
            "The progress of information extraction.",
            "And I look now in some detail at two of those quantitative evaluation programs that have been responsible for a lot of the progress in the field over the past 15 years or so.",
            "And the first one is mock your message, understanding conferences, and Secondly AIS automatic content extraction.",
            "I always thought it stood for advanced content expression.",
            "They go.",
            "Mark 7.",
            "Held in 1997.",
            "Kind of came up with a sort of Canonical breakdown of the information extraction task in."
        ],
        [
            "Five subtasks what happened in these competitions was that people would get to get together with government sponsors and they define a task.",
            "They define what the extraction system was going to do, and then they'd mark up a whole load of data, and then they measure the degree that the markup and they produce training data, and then they produce our systems.",
            "And then everybody would get a separate set of test data for a week.",
            "When you run your system on it.",
            "Not do any corrections apart from stopping at crashing and only send the data back and then measure the performance and Mark 7.",
            "There was broken down at 5 things named entity recognition.",
            "Coreference resolution template elements.",
            "Template relations in scenario templates and we should have a nice posh slide from valenton.",
            "Giving an example of this stuff.",
            "The shiny red rocket was fired on Tuesday is the brainchild of Doctor Big Head.",
            "Dr Head is a staff scientist that we build rockets incorporated.",
            "So I started off by saying that we've moved on from simple toy examples to the real world and now I'm giving you a simple example just to see if you're on your toes.",
            "What are the various different things that come out from extraction here in the book 7 kind of style?",
            "Named entity recognition is to find these things appear in the text, so things like Rocket, the Rocket Tuesday Doctor Head we build Rocket will be rockets.",
            "Secondly, we try and figure out which of those things refer to the same entity in the world and also which kind of enough folic references refer to those things.",
            "So we're saying here that it in the second sentence refers to rocket in the first sentence, Doctor Big Head and Doctor had the same thing, and so on.",
            "Having done that, when we know where all the mentions of a particular entity are in the text, we can then pull out some of descriptive information that scatter and scattered around in the text and associated with those entities, and we call those template elements.",
            "So we can say, for example, that the rocket is shiny red and they stop their heads.",
            "Brainchild.",
            "Yeah, why is rapid?",
            "I'm just not sure.",
            "No good reason.",
            "No good reason at all.",
            "I'll kind of will cover a little bit about what is and what isn't an entity in various different contexts later on.",
            "But really, it's a pragmatic decision that you make in different ways in different applications, so, but you're right, it's inconsistent.",
            "These two shouldn't be.",
            "That one of them is the one who made money.",
            "Hi somebody, awake at the back.",
            "Template relations you've got all these entities, while the relations between them Doctor Head Works for we have been rockets.",
            "Finally scenario template, this kind of event concept.",
            "Here we were considering in this case in Mark Seven rocket launch events.",
            "So there was a rocket launching event.",
            "The various entities of the participants in this sense.",
            "And there you go.",
            "There's quite a lot more to say about that stuff, but we're kind of some of it as we go on, but we're also relatively short time so.",
            "I want to love it.",
            "Am I doing for time?",
            "What are good things about information extraction going back to that thing about measurement and counting?",
            "And so there's been a lot of measurement done.",
            "A lot of counting, so it's quite often possible for us to say in view of any particular task that's going to use extraction.",
            "Roughly how the persistence going to perform.",
            "3rd, the figures that came out from the mug program and other experiments.",
            "We got up to something like 97% accuracy and the best mobility recognition systems, and that's pretty much as good as human beings can do.",
            "'cause human beings make lots of mistakes, especially when they're doing boring and repetitive tasks like taking text.",
            "Current revelation is much more difficult, especially anaphoric resolution.",
            "We're looking at something like 6070% accuracy.",
            "I'll define accuracy later on in some detail.",
            "Um template elements in template relations around the 70 + 80% mark scenario templates there really hard again.",
            "So then we're thinking about maybe 60.",
            "This depends on the genre and the domain and the task in summer, but it's pretty low, but you should also note that human performance is pretty low for that kind of task.",
            "Under the thing about it is the thing about these figures.",
            "What they tend to suggest is that the more complicated that asks, the more complicated the extraction you're doing really, the bigger the task, the bigger they might have.",
            "Text has to be, because if you couldn't get a fairly low accuracy, then the only real point in doing it is there's so much text it just wouldn't be possible to do it by hand, or I'm not going to do by hand.",
            "So whereas you can do the simple stuff.",
            "To quite a high level of accuracy, once you start getting more complex than that reduces the kind of application space that you that you're looking at.",
            "Alright, now notice we've given some examples."
        ],
        [
            "Person names, organisations, companies, government organizations and so on.",
            "Location, cities, countries, rivers, date and time expressions in.",
            "In other types of applications we've had all sorts of things like measures, email addresses, web addresses, and some domain domain specific applications have looked for things like names of drugs, medical Commission, medical conditions, even bibliographic references.",
            "Tarnish their names, but I'll probably contradict me.",
            "Are in various cases like Mark and all these other programs you have these great long lists.",
            "This URL is great.",
            "Long definitions of what the things are that you're trying to extract an exclude certain types, for example, in book 7, excluded artifacts, common nouns, names of groups of people, adjectives to rifle names, and some other things.",
            "The point is not that this is a kind of final, wonderful, perfect definition of what this type of thing is.",
            "The point is, this is the kind of thing that you can target with an extraction system, and generally in each different application of the technology you'll make different choices about these."
        ],
        [
            "About what falls into your set of extraction targets and what doesn't.",
            "So what are the basic problems in doing entity recognition?",
            "We have"
        ],
        [
            "Creation of names so names can be stated in lots of different ways.",
            "John Smith, Mr Smith.",
            "John Solomon.",
            "We have ambiguity of types.",
            "John Smith is the makers Bear in England also person.",
            "It's also the company that makes the beer.",
            "Um May is a person can be a person or a month.",
            "Washington personal place.",
            "1945 can be caught too late or the year.",
            "So there's a lot of ambiguity with common words and all sorts of other ambiguities.",
            "This kind of typical language scenario.",
            "While language processing is so hard.",
            "On top of these basic problems you then have issues of style and structure and domain and genre, punctuation and spelling.",
            "If you've got the address at the bottom of the email, for example, perhaps how do you know that the Department of Computing mass stops here?",
            "And how do you know?"
        ],
        [
            "It doesn't.",
            "Just go over for leading an ordinary paragraph and a\nDoesn't really mean anything, but if you're in a dress or a table or something like that, there may be a\nOther kind of special impact on the processing.",
            "OK, so we're going to go on from looking at the kind of general picture about information extraction.",
            "So how how these tasks have measured the performance?",
            "How we've measured the performance in these these tests?",
            "Copper is just a name for for a collection of taxes, by the way, collection of documents.",
            "The typical way that you develop a system like this is you sit down and you define what's called the gold standard.",
            "You define what sort of annotation you would like to come out of your system.",
            "Then you get some poor oppressed people to manually annotate.",
            "A lot of texts with this gold standard and you divide this annotated corpus into a training portion of the testing portion.",
            "You do you have real development?",
            "Are you learning on that on the training portion and then you test on the on the other bit?",
            "What you're doing is you're adjusting in certain."
        ],
        [
            "In the in the case where using Rose, you're playing with real priorities, will effectiveness and so on.",
            "If you're using a learning algorithm, then yeah, you're playing with the parameters in the features used by typical routine with the learning algorithm is to do a thing called 10 fold cross validation.",
            "Why you divide up yet?",
            "You're trading full portion into 10 sections.",
            "You train on 90, test on 10, then you shift onto another 10 train 90.",
            "Test on that time and someone go go through.",
            "Go through this.",
            "An included the.",
            "No further tuning should be."
        ],
        [
            "And once the evaluation set is used.",
            "This kind of practice has been going on for a long time.",
            "There's a whole bunch of outdated corporate in the world that we can experiment with.",
            "Mark Saxon Box 7 Co. NLL Conference on natural language learning.",
            "The tides surprised language exercise, which run last year.",
            "That was a fun program to be in.",
            "They give you a new language when you had to produce a system within a month, they gave us they started off by giving us a language called Kibwana, which none of us actually heard about her anymore.",
            "I usually get a prize at this point.",
            "If anybody knows where Cubano is from Johns disqualified 'cause you got it last time?",
            "Anyone know where cables from?",
            "From the Philippines.",
            "We also had Hindi.",
            "And people take surprisingly, well, actually.",
            "I mean, we did.",
            "We did.",
            "We did systems for both.",
            "These language was known with no native speaker involvement.",
            "Actually we got some native speaker involvement for India.",
            "Certainly didn't.",
            "Play along.",
            "On the ice, which I'm going to talk about a little bit more.",
            "Is also available, but more details on the book 7 corpus.",
            "One of the things I haven't mentioned up until now is Inter annotator agreement.",
            "You need to know how well the human beings are doing the task and you do that by getting people to annotate the same stuff twice.",
            "You get two people to annotate the same stuff and then you measure their agreement."
        ],
        [
            "And this gives you a kind of measure of how well people can understand the task definition and how much they are agreeing about it.",
            "And so on.",
            "And the muck, at least among identity Corpus, had a very high Inter annotator agreement as 97%.",
            "There's some figures there about what is contained in these in this corpus.",
            "You can see one of the interesting things is that you actually haven't got that much data.",
            "There's only 100 documents that we use for training, and in this particular case, and that's fairly typical, it's really quite expensive to produce this stuff, and that has implications for the kind of approach that you use to do in the extraction, because you've only got this rather limited set of examples, typically.",
            "We'll talk about it later.",
            "It was marked up in."
        ],
        [
            "And some funny type of SGML.",
            "This is not inline markup.",
            "This is well, this is inline markup, not stand off, but I talked about everyone.",
            "Let's say you've got an entity name expression here of type location, Cape Canaveral, Cape Canaveral, and so on, so forth.",
            "OK, that was muck.",
            "I's more recently automating content extraction.",
            "Evaluation exercise.",
            "This moved on in a number of respects from from work, so whereas in muck.",
            "You are just essentially tagging names in the individual prices where they occur in the text in a.",
            "In a, each name was viewed as a mention of the underlying entities and the main task was to detect the mentions in the text of the entities themselves.",
            "So in AC kind of rolled together, the named entity task in the coreference task.",
            "I know some experimentation with different domains and different genres, and there's also stuff to do with trying trying to do the task on noisy input.",
            "So we had ASR output.",
            "Let's ASR stands for automated speech recognition, where you transcribe the voice of somebody who's speaking text OCR, optical character recognition.",
            "The entities in ice."
        ],
        [
            "With things like proper names, pronouns, nominal mentions, and as I said earlier, that the task was to identify which mentioned in the text, refer to rich entities.",
            "So you've got a text talking about the British Prime Minister, for example, and you've got a thank figure out that Tony Blair, Mr Blair, he the Prime Minister the Devil or refer to the same kind of thing.",
            "Are the ACE output format was like this?",
            "The whole section here is an entity.",
            "It's got an identifier.",
            "And then we've got a set of mentions, so these are the different places.",
            "These are different places in the text where we found some information about something that we think refers to the same thing.",
            "In this case, the National Air Traffic services.",
            "Which was sold off by Tony Blair recently.",
            "So think about that next time you're flying over Britain, and the fact that you fly through privatized airspace.",
            "I make a profit by doing it for as low cost as possible.",
            "OK.",
            "So the smaller side.",
            "Totals for doing this kind of details for the value for annotating corpora here.",
            "This is great in action."
        ],
        [
            "We look at a system called out and back in a minute."
        ],
        [
            "How do I stop it going?"
        ],
        [
            "You got a text in the middle here.",
            "It's not very clear, but you've got a text in the middle on the right hand side you got all the different annotations in the text underneath.",
            "You've got a kind of database view of the annotation, which tells you where these things came from.",
            "The pointers I mentioned earlier, standoff market pointing back into the text.",
            "And there's all sorts of facility for navigating around this kind of information space so you can click on the click on the database view and you see where in the text something happens.",
            "Click in the text and it will see show you the other views, and so on.",
            "And you can turn on and off.",
            "All the different sorts of annotation on the outside to the point is whizzing around and do some and at hand annotate."
        ],
        [
            "Another popular total for doing this kind of thing is a thing called lambeck ambiguous from mitre in the US.",
            "The interesting thing about my arm because it combines the basic facility for doing manual annotation with a kind of bootstrapping approach that learns some of the examples as you go on."
        ],
        [
            "So you can tell are big here.",
            "All these examples of names and then you can run it's learning.",
            "Strategy and then it will make some propositions or propose more names in subsequent documents.",
            "So how do you know them assist?",
            "How do they have assistance performing?",
            "You have an evaluation metric which mathematically defines the performance in relation to that gold standard that you've created with these annotation tools.",
            "And then you have a scoring program that implements the metrics and provides various measures.",
            "These run out both over documents, another corpus level for each different type of thing that you're trying to extract.",
            "The most common evaluation metrics.",
            "In this field, are things called precision and recall.",
            "Precision is a measure of how well you've recognized things.",
            "Recall is a measure of how many of the things out there that you manage to find.",
            "So the formula is that precision is the correct answers divided by the number of answers that you found.",
            "The recall is the correct answers divided by the total possible correct answers.",
            "You can typically set up systems to have a tradeoff between precision and recall.",
            "You can say OK, I'm only interested in the cases where you're really, really sure that this is correct.",
            "In other words, you want very high precision system.",
            "File for the recall down because you won't.",
            "You won't be able to include the ones that you're not sure of, right, so you won't get very many bug.",
            "Alternatively, you can say I want all the data that you can possibly find, whether they are right or not.",
            "Allow this diatribe the precision down because you'll include stuff that you're not really sure about.",
            "Typically people don't report precision and recall independently they were caught.",
            "They report a thing called the F measure, which is the weighted harmonic mean of the two of them.",
            "There are people in the world understand what that means.",
            "I'm not one."
        ],
        [
            "And and those are the figures I was giving earlier on things like 90% of what have you?",
            "That will be the F measure, the combined precision and recall on the task.",
            "It's not always.",
            "This is very, very prevalent kind of measurement.",
            "Metric is not always exactly the right thing to do.",
            "It tends to be sensitive, for example to the amount of data you have, the amount of entities that you have in a particular document.",
            "So if you're if you're concerned about that, you might use instead something called false positives.",
            "It's also you want in certain cases too.",
            "You want to be able to have an idea given different application parameters given different conditions are operating in your application.",
            "Whether the thing when the performance go up or down or not.",
            "An ace, for example, user cost based models.",
            "So you could tweak the parameters and see if the thing would go up and down.",
            "In different application scenarios.",
            "The other twist in the story is that sometimes things are partially correct.",
            "If you've got Blair, if you got string saying Tony Blair and we've only recognized Blair, then that's kind of half right.",
            "So people quite often modify the formula to take that into account.",
            "And you really want a tool to generate all these figures for you.",
            "This is the one that comes in gate.",
            "This is a document level view of both the differences between the gold standard in the machine and the metrics that those difference the measures that those differences result in the figures that they resulted.",
            "So essentially it's like one of these visual diff programs.",
            "If you've ever used some."
        ],
        [
            "Like TK death for lots of programming development environments that allow you to look at the difference between your current version of a file on the one that is stored in some repository somewhere.",
            "So you've got the key document here.",
            "That's the human annotated one, and the response document, the machine, the machine.",
            "I rotated one, and what you've got is a list of all the annotations are in these these two documents.",
            "But it tells you down the bottom here."
        ],
        [
            "While your precision and recall your ass measure further over the screen that you can't see it false positives and so on.",
            "So typically what you're doing when you're producing extraction system."
        ],
        [
            "Just iterating over this kind of this kind of picture of how the performance is improving, hopefully improving.",
            "You also need to track the system performance overtime so when a change is made we want to know what the implications are over the whole corpus number of a development methods for these types of systems can result in a change in one place.",
            "Drives down performance in another place, so you need to be able to.",
            "You need to be able to measure this.",
            "So you need a tool or do regression testing over the whole corpus.",
            "Similar kind of thing, but corpus corpus level.",
            "OK.",
            "Evaluation in the context specifically of the semantic Web, strung up a whole set of new challenges.",
            "Most of which haven't really been solved yet.",
            "Most of them are currently the subject of research.",
            "The Semantic Web task takes this ultra.",
            "This basic extraction problem because you're now trying to detect entities and events and so on in the context of a target ontology of the domain.",
            "You're trying to disambiguate the entities and events from the document, so your extraction pulls out with respect to the given ontology.",
            "So for example."
        ],
        [
            "Um, if you found Cambridge in a text and you correctly figured out that Cambridge is a location, maybe you want to try and actually define it.",
            "This is Cambridge, UK versus Cambridge, MA.",
            "And you also need to decide when you've got an instance that isn't actually present in your in your knowledge base yet.",
            "You know, maybe you haven't seen this thing before and it should be added to the knowledge base.",
            "It's not a mention of a pre existing entity.",
            "For example.",
            "Unless throws up a number of challenges, and in fact we need to adjust the metrics because of these challenges when your evaluating in this kind of hierarchical ontology based kind of picture, we need to take account distance in the hierarchy because we can.",
            "That we have a we have a different kind of partial correctness problem.",
            "If you find a company and.",
            "It was actually a charity or the other way around.",
            "Then that's probably less right than finding a company and saying it's a weapon of mass destruction or something like this.",
            "So you need something you need to make your metrics and metrics sensitive to that to the hierarchy.",
            "OK. About halfway through my bit.",
            "And.",
            "How do how do people typically do this extraction task?",
            "That's what we're going to talk about in the next section.",
            "So approaches to information extraction.",
            "There are two kinds of approaches to building this course with building this sort of system.",
            "There's a kind of knowledge engineering approach in this sort of learning approach machine learning approach, so the knowledge engineering approach is a kind of rule based typically rule based.",
            "It's developed by experienced language engineers, people who know about language processing.",
            "People have some linguistic program background.",
            "And it makes use of their human intuition.",
            "And trying to understand what's going on in the text and how you can process it using various kinds of tools that inquires only a small amount of training data because human beings are very good at generalizing.",
            "Obviously from the examples that they see.",
            "Development can be very time consuming and costly, and when you make changes to if the information needs changes and it can also be quite costly to to change the system.",
            "To the new information need.",
            "On the other hand, learning systems, the idea here is to get rid of the expertise, get rid of the expert people and replace them with somewhat less expert people who can just markup text.",
            "Give you lots of examples and then get the machine to learn from it using some kind of statistical model from the developers quite often then don't need so much linguistic knowledge.",
            "The downside is it requires a large amount of annotated training data.",
            "If you make changes in the information need, you may have to go back and re annotate all your training data.",
            "And although people doing the allocation of cheap, you get what you pay for.",
            "In other words, when you ask somebody to do a boring job, you don't pay them very much money.",
            "They don't typically do it very well.",
            "So there's a kind of tradeoff between these two different approaches.",
            "A lot of the.",
            "Quite a number of leading systems these days actually trying to combine these two approaches in various various sorts of ways now will go and the rest of this section will go through some examples of how these these approaches tend to workout in practice.",
            "So the very simplest sort of approach to my identity that you can think about using a baseline is just to have a long list of named entities and store them in things that, for historical reasons, tend to be called gazetteers.",
            "And this is simple, it's fast.",
            "It's language independent is that you don't need to have any specific knowledge about particular languages, and it's easy to retarget.",
            "You just recreate the lists lists.",
            "But names are very productive things.",
            "It's impossible to pre enumerate all the names that you're going to encounter in any kind of realistic test collections, so this approach goes a certain distance, but it basically breaks in almost all cases.",
            "So moving getting a little bit more complicated.",
            "People use a sort of shallow parsing approach which takes into account some of the internal structure of the neighbors.",
            "So there are some kinds of typical components of names which give you a clue that they are names and give you a clue what kind of what kind of name they are.",
            "So you've got for example in locations.",
            "Town might often be called something City, something forest blah blah blah.",
            "So if you have a capitalized word followed by one of these trigger expressions and you can figure out that it's a name.",
            "What this doesn't get you is that it doesn't deal with these various different sorts of ambiguity, so you get.",
            "Ambiguously capitalized words so that the study switches state police preceded by all.",
            "It doesn't get you the kind.",
            "It doesn't help you with the semantic ambiguity that you get between for in this case, for example, between the location and a person John John F Kennedy is at the airport, or the person Philip Morris is a person or organization, and it doesn't deal with the kinds of structural ambiguity that you get in cases like this.",
            "So cable and wireless, that's one thing.",
            "Microsoft and Dell are two things.",
            "How do you tell the difference between those those cases?",
            "So the next step is to try try and use shallow parsing shallow analysis with some of the context around the names you've done.",
            "Then you've got the internal structure.",
            "Now you're looking at the context of the names appearing.",
            "So here's another example where we can't."
        ],
        [
            "A priority figure out.",
            "The difference between these two things.",
            "Let's say that in this case Goldman Sachs.",
            "We're talking about company in this case.",
            "David Wilson is a person we can't really figure out just from those things themselves.",
            "What those types are.",
            "But if you go."
        ],
        [
            "The phrase David Walton of Goldman Sachs and you know that David Walton, the person, then we can use a pattern that if you have person of organization than the second entity, there is going to be an organization.",
            "Under hope long lists of these kinds of patterns that you can use.",
            "A person and money and organization as a headquarters in a location.",
            "Organization is worth money and so.",
            "Sarah, look at an example of a roadway system called Annie.",
            "Honey.",
            "Stands for nearly new information extraction systems.",
            "When it was born at Balsam, Strange resemblance to certain other previous ones.",
            "Let's open source is giving away free gate.",
            "Does some of the infrastructural stuff underneath dealing with document formats, saving results, evaluation, visualization and editing and so on.",
            "It's based on a finite State Park national language.",
            "Annie is based largely on this on this rule language.",
            "What are things that people want to approach is that people started started doing started using a lot for this kind of shallow extraction task was pattern based with pattern matching based on regular expressions and what they found was that you use a language like Perl and it's good for the first stage.",
            "You know you've got powerful regular expression capabilities, but then you've got these.",
            "You have pulled some information out of the text you want to store that information somehow.",
            "And then feed it into the next level of your pattern analyzer.",
            "And where do you store that?",
            "Do stuff it back into the text.",
            "If so, your patterns get.",
            "They tend to mushroom and get more and more complicated, so one of the things that was done was to.",
            "Abstract away from the text itself and due to finite state pattern matching over the over the annotation data and that's what this kind of rule based system is, is often.",
            "Based on.",
            "So the various components that this example system has.",
            "The red and the black boxes.",
            "The boxes are components and the overall kind of things are the resources.",
            "The data that they used to do their job.",
            "So we've got kind of processing and data boxes in this little sausage machine, so you got a document coming in here.",
            "It's going through all these things.",
            "Only your extraction is coming out the end in a variety of different formats.",
            "So we begin just by chopping up the text until it all units into tokens and this system uses the Unicode character classes to figure out what those chunks should be.",
            "So Unicode defines what is punctuation, what's capitalized word, etc, etc.",
            "With space for lots of different languages.",
            "We do the simple baseline thing that we mentioned at the start of gazeteer look up so we have a bunch of lists of things.",
            "In this case, they're mainly trigger trigger words like incorporated or limited or GmbH or whatever for recognizing companies.",
            "And we try and identify the sentence boundaries.",
            "And here we start using that kind of pattern language stuff.",
            "I talked about a minute ago.",
            "We don't do part of speech tagging.",
            "Figure out the syntactic constituents in the text, whether it's a noun or a verb or whatever, and then the main the main chunk of The thing is to do this semantic tagging using the patterns.",
            "The kinds of patterns that we looked at under the structural.",
            "Ambiguity slide earlier.",
            "Couple of other things that happen later on.",
            "You can solve some of the ambiguity problems by.",
            "Looking at where else in attacks occur, similar kinds web when names with similar properties occur in the text.",
            "So for example, if you got IBM in the text and you don't know what sort of name is but somewhere else, you've got international business machines limited when you figured out that that's a company.",
            "This component then goes through the text and sees that IBM is probably acronym for.",
            "A Big Blue.",
            "And fixes that one.",
            "And finally we do some nominal coreference and again this is a pattern based step.",
            "South side most of this already.",
            "The catalyst is storing these location into indicators.",
            "So that kind of these are this is just a from about the internal structure of the names.",
            "The little more detail about the about the semantic tagging computer components.",
            "This is again a fairly standard approach to the problem.",
            "You've got a set of phases of pattern matching rules that compiled and compiled into state machines, finite state transducers.",
            "Honey run these in the cascade over the.",
            "Input text this kind of cascaded transducer approach.",
            "For some reason, turns out to be a lot easier to write than than most of the other ways of doing this kind of pattern matching stuff.",
            "We got a bunch of annotations for from the format Alesis of Tokenizer.",
            "The sentence part of the part of speech, and so on, and then we apply the contextual information and it does.",
            "The semantic tagging.",
            "Does the entity recognition.",
            "Here's a very simple example.",
            "Um, this kind of light regular expression based approach was become fairly common in the extraction community.",
            "Jape is a language that implements this over annotations.",
            "To solve that problem with being able to store information between different phases.",
            "And you have things like you have rules that on the left hand side of a pattern and on the right hand side have some action to take when you match that pattern and the action is typically to add some more annotation to the pie that you can then either use to output as a result of your extraction, or you can use it in a subsequent matching phase.",
            "Further, the basic smallest elements are things like things in curly brackets like this basic pattern elements.",
            "This is saying that you've got a token annotation.",
            "It's got a feature of typography.",
            "The value of the feature is upper initial, so it's a word with an uppercase first letter.",
            "Regular expression operator.",
            "One or more of these things followed by look up annotation that something out of your list with an attribute kind value company designator.",
            "So you've got something like in Core GmbH or limited.",
            "I need find company and on the right side of the rule you create a new annotation with the same span of what you saw on the left hand side and you called it named entity and so it's a company.",
            "Come from this room so very simple stuff.",
            "I have seen this one earlier on.",
            "This is just a view of text with.",
            "With named entities highlighted like I showed you in the annotation, but.",
            "OK, when you've done some of this matching and you've got a bunch of ambiguous names, so you figure out their names, but you don't know quite what type they are, then you can use coreference resolution to figure out what those types are.",
            "Again, I gave you example this earlier on.",
            "Maybe I will.",
            "Myself.",
            "Here's a different view of the nine deadly space.",
            "This is highlighted all the ones are the same thing, so 18 T is highlighted in the same color.",
            "Mike Armstrong and Armstrong.",
            "Here they figured out, and this is the same guy.",
            "These are.",
            "These are basically chains in the text.",
            "When you've coauthored these things, you ended up with chains going through the text and you can turn them off on the right hand side here.",
            "OK, so.",
            "Pretty much done.",
            "My bit fountain is going to take over and look at learning based approaches to instruction.",
            "So we currently running on about 5% attention.",
            "Honey, honey questions.",
            "Yep.",
            "Semantics is to have entities of different types and their relations, yeah.",
            "She is mainly focusing on entity identification.",
            "Well, there's two answers why it will come to that in the second half of the talk talk.",
            "And the other is that a lot of the work up until now has been relatively simple, so it's been a lot of stuff about entities, but we will deal with this in the second half on semantic tagging and ontology based extraction and stuff like that.",
            "Coat.",
            "What are they talking about?",
            "Using machine learning for information extraction?",
            "So I want to 1st information extraction system are being developed.",
            "People first thought of using load engineering, which is what the Hammers talked about.",
            "So getting the you gather training corpus from the papers and you start building your own system you.",
            "Engineer it yourself.",
            "You create rules, work with the priorities and you get the information extraction system.",
            "Then they thought, well, we're getting this annotated corpus of the data and actually creating the system is pretty much the hard work.",
            "So why not let the computer the hard work so the idea is to use the annotated corpus to train automatically assistant.",
            "That will learn how to recognize things that were annotated in the training corpus, and that's the first approach there, which is to train machine learning models.",
            "On the manually annotated text.",
            "Then the next step was people realize that actually creating the annotated corpus was pretty much hard work as well, so why not get the computer to help with that one?",
            "So for instance, in arnocorps we can have same kind of MPs mentioned many many, many times, and once the user out is a few of them, smart machine learning algorithm can actually recognize most of the other ones.",
            "So why waste the users time which is expensive?",
            "By asking him to annotate the all dimensions in a document when you can have a computer that.",
            "So that's one.",
            "The idea of mixed initiative learning appeared where they're going to use all the information along every kernel information available from the mentation.",
            "At each Step 2 is the work of the annotator and the first reason for doing this is to help and to speed up the production of training data.",
            "Then people realize that as the system evolves and as the user aren't, it's more and more animal.",
            "Data model more text.",
            "The machine learning algorithm that runs in the background actually can get quite good and can in the end.",
            "In an ideal case, act as the final product as the actual information extraction system that you're trying to build.",
            "So that's the second reason for using mixed initiative learning.",
            "Now there's a variety of machine learning methods that have been used and the first ones that will try their doing symbolic learning, symbolic learning, and that's mostly.",
            "List of rose.",
            "That's because the knowledge engineered systems were based on list of rows.",
            "So humans are getting those rules.",
            "So the first logical step was OK. Let's get the machines to create those rows.",
            "The main advantage of that is that we end up with the same style of things like you did in the engineering system.",
            "You end up with a list of rules which are human readable, so they can be inspected.",
            "Then they can even be corrected or improved by a good engineer, but the performer brace you can.",
            "Is there other classical symbolic machine learning methods like decision trees which are required the quite successful?",
            "Another style of machine learning is statistical models.",
            "Now this is not as nice because pretty much a black box I mean a model for us at this grandmother is a huge table of probabilities in it.",
            "No human can possibly understand anything out of that, so they're harder to is.",
            "They cannot be inspector improved by the humans, but they tend to perform quite well, specially hmm, so hidden Markov models and maximum entropy have been used successfully, so you can't actually not use them just because you can't understand what they're doing is there.",
            "Weathering is good then why not use them?",
            "So that's the statistical models.",
            "Now we're going to talk about machine learning.",
            "Let's get our terms right.",
            "First, machine learning is very wide field and the very same issue.",
            "Learning.",
            "I mean one of many things in the context of information extraction, we usually talk about classification, which is one of the main problems of machine learning.",
            "And if we think about classification, have this concepts have instances which are examples of a particular phenomenon that happens, and that the.",
            "Machine learning algorithm tries to model so it looks at those instances.",
            "None instance and saying it's an example of a phenomenon that's a very abstract concept.",
            "Computers don't work very well with abstract concept, so the way we define instances by a set of attributes which have values.",
            "So we have all the attributes.",
            "If you have the values for all the attributes of an instance then you know everything there is to know about that instance, at least as far as the machine learning system is concerned.",
            "And then below what that actually tries to do is to split the.",
            "We would set of instances in two sets of businesses that are similar from some point of view and those are classes.",
            "So all this is that share something they belong in the same class and the way it works.",
            "You normally start with a set of instances which are pre classified given to the algorithm, which learns from that pre classification and then after it's trained you start giving it instances without the class value and it returns to be the class value for each instance that you.",
            "Providers input.",
            "Now how you solve this thing?",
            "For information extraction, the testing information extraction is the story is quite complex and it from different application can be quite different from from others.",
            "So there have been several things that have been used, one being for instance to find the boundaries of entities.",
            "So I'm not looking for a person in the text.",
            "We are looking for the place between 2 words were a person name begins and then you look for the place between towards or.",
            "Personally.",
            "Ends and that's sometimes, well, it's.",
            "It's mostly a technical reason for doing this kind of thing, so I mean, if you're another option, would be to look at each word and decide if it is or not part of an entity.",
            "So other classified the words or classify the spaces between the words.",
            "So if classified words, then you you're classifying tokens, otherwise you're fine.",
            "You're doing boundary detection.",
            "Now you could train the system to only find entities, not also tell you what the entity types are.",
            "And then it can be something else.",
            "Another classifier which will do the the actual classification of the all the entities that are found in two different named entity types.",
            "And that's also basically why you would want to do this is because it allows you to use different algorithms for different problems, and some algorithms are better than others that particular tasks.",
            "So everything we want to do the entire to solve entire problem, you spread the problem to solve problems in your address, each of them with the most appropriate algorithm.",
            "Oh my God, that has been tried this to you several models in the in the same time and do something that's called the president can do call training but it train to models in the same time and the output of one.",
            "It feels to train the output trained other model and the other way around.",
            "And you do this several times, that's kind of bootstrapping until they start agreeing with each other and when they go on the two models give the same result.",
            "Then it means they converge to something.",
            "So it's like that you've got good results.",
            "We also agreed about training or.",
            "Call testing what you could do.",
            "You use this to models, train them together and only ask the user to notate the examples of the two models disagree, so that's a problem.",
            "There you go to algorithm cannot figure it out, so that's why you have this.",
            "Only.",
            "Only use the humans time when you really can't do it automatically.",
            "Also, you may want to leave if you don't do court training.",
            "If you can afford it from a hardware point of, you may want to run several algorithms because there are some that train very quickly, so from a few examples they already start giving you results, but they level up quite quickly as well.",
            "So as you increase the level, the amount of input data performance doesn't crease that well, so you can use that to start up the process and in the meantime in the background the trainer better algorithm that will reach higher levels of performance in the end, but that requires more training data initially.",
            "So in order not to let the user completely unaided at the initial phase, user less good algorithm.",
            "But that has the in the 1st place and then you switch to the better run and there's lots of things that can be tried.",
            "Now somewhere ideas that have been used if you're doing a boundary detection occur, you're basically looking for things like start and end.",
            "If you're only looking for entities that that's all you look at, and then if you want, for instance can look straight for start of organization and organization.",
            "So if you look at this text for instance, this would be marked up with boundary detection, including the actual named entity classification.",
            "Another idea that has been used as they'll be notation which stands for inside, outside and beginning of.",
            "Then you have the same text there and you mark the inside an organization outside and inside person inside location.",
            "You only need to use beginning of when you have 20 years of the same Type, 1 after the other, and use beginning of to mark the place or the first one, and then the second one begins.",
            "And it's obviously the two models can be converted from one to the other.",
            "Pretty straightforward, they represent the same data really.",
            "Well, I said that the.",
            "An instance is defined by a set of features, and if we're talking about information extraction, that means similar language technology, and these are the kind of features that have been used first.",
            "First thing you can use this document structure and if you're starting from something like HTML pages, then you can use the original markup, and that's what so-called wrapper induction methods methods do.",
            "So those are very good for HTML pages that are generated from CGI scripts like from databases.",
            "List of prices.",
            "For instance, in on a website you use report induction and they're very successful for those kind of input.",
            "You can also look at stuff like paragraph and sentence structure.",
            "For instance, many times the entities tend to be.",
            "Mentioned towards the beginning of a sentence.",
            "Of course, the beginning of the paragraph, and that would be 1 feature that will help in the burning the the model.",
            "The ML model.",
            "Then you can move into higher level features like token length, capitalization, the stuff that he showed you that it's used in rules created by humans.",
            "Machine learning methods usually use the same kind of features.",
            "Talk on type.",
            "It's a word punctuation symbol for it's quite unlikely to have a symbol instead of person name so.",
            "That kind of information can be important.",
            "Then if you've got the MLP machinery behind the camera actually drive linguistic features like part of speech, morphology, syntax, we can do look up some lexicons like word, net or others and as we're moving towards our days you can start using.",
            "Look up in ontologies.",
            "For instance, you have an ontology that models domain.",
            "Sometimes you have some terms linked into the technology and the fact that particular term is linked to a particular class is quite an important indication over.",
            "What does meant anything else?",
            "I mean, there are lots of experiments that have been done at all kinds of features, and that is because the selection of features so called feature engineering is the most difficult part in using machine learning for permission extraction and the right set of features can give a success.",
            "The run set of features will give you complete failure regardless of the fact that you're using the best state of the art algorithm.",
            "If you don't get the right features, then you'll probably get nothing out of it.",
            "If you have a large set of features and you want to find out which are the best ones, there are some automatic methods that can be used to score the features.",
            "Things like information gain or entropy measures that can tell you that this feature is very important for us.",
            "This other one is actually not doing much becauses for instance depends on the other one.",
            "If you have the features that depend on each other and one of them is useless normally.",
            "But more about the next initiative learning.",
            "So it's crucial idea behind this is to have the human and the computer cooperate in order to achieve the common goal.",
            "So don't have the human start by annotating text, which is a boring task and it's time consuming, and then give the data to the computer instead of the computer in the human work together to achieve the goal.",
            "The first reason to do this is to speed up the creation of training data which other allows you.",
            "Cheaper training corpora were bigger ones for the same amount of money.",
            "Which is always a good thing.",
            "As I mentioned before, like you can end up with a working system in the end, so that's a bonus.",
            "Or sometimes it's actually what you're after now, probably the first implementation of a mixed initiative learning or active learning system is the Olympic Workbench in 97, which was presented by thinking part of the MC 7 conference and probably the most recent one is Mercury in Melita but you furniture event, which was presented last year.",
            "So how this thing works?",
            "Usually start with a blank document.",
            "So Unannotated data the user annotates, and that's where it used to stop the corpus creation procedure is stop there, but now in the background we have machine learning system being trained, which learns from the annotation as far as the user is concerned, nothing exchanges like before he's annotating data, and that's all he does at some point.",
            "OK, during all this process the system learns and.",
            "Test itself so tries to re annotate the same document and compares the results.",
            "So you can have a figure for the level of performance that's being attained by the system when a particular threshold is reached, which means that the suggestions made by the user out by the system are actually useful, and they're more overhead than a hindrance to the annotation process.",
            "Then the system enters the loop and it actually starts pre annotating the Pine annotated data and when the user first is, the document is not blank as before.",
            "It already has some data Internet and then, well, these are listed there is only correct that pre annotation which means other remove some of the wrong ones or add some of the mist ones and the system continues to learn in the background from the mistakes it made which were corrected by the human.",
            "And this is the loop that just continues and you get to your other documents.",
            "Now if your target is to actually get a fully trained system you set another threshold which means the level of performance unhappy enough that's good enough for my problem.",
            "So if I reach that I'm happy.",
            "And you have the user annotate until the system reaches this level of performance, after which you have the system by itself doing all the job and the user goes by the pool somewhere.",
            "First example is 1 made by Bay at others in the Mitre Corporation.",
            "They already have a lambic alembic.",
            "It was not true for manual annotation of of corporate.",
            "I think it was used in a lot in the creation of corpora for the mood competitions and at some point I decided well this work of creating corpies soon too hard.",
            "So let's try and help the user with some machine learning.",
            "They also had a lot of tools because they took part in the competitions.",
            "They had a lot of NLP tools like part of speech, taggers and all these kind of things that help you induce.",
            "Feature values so their drink of bootstrapping procedure where the user starts with some documents.",
            "They take some documents and then the system.",
            "Piano ties is not very interactive because at that time it was next serving.",
            "The hardware wasn't that good, so they couldn't afford train to retrain the system very often, so it was based on a document by document basis.",
            "These are fully annotate one document and then the system will train and there was much interaction between the two.",
            "Really, but the main point is that the process of manalan tation gets transformed.",
            "The process of review of existing annotation and sometimes you end up with a working system.",
            "Because it does the first system this style, it was generating the kind of roles that are being used in their knowledge engineered systems.",
            "So the user was able to actually look at the roles and edit them if they are skilled enough to do this kind of things and the learning itself is birth style, it generates rules.",
            "You apply them and measure for each role.",
            "The kind of results that it generates and you give you only keep the best rose from a pool of roles.",
            "No, this may sound like an ideal thing, so you have the machine will do you do your work, so everything is fine.",
            "Well, not truly.",
            "There are some problems with the mixed initiative idea.",
            "If the system has very high recall and I'll remind you that means that it finds most of the entities in a document, then the manual annotator may get used to this and may become over reliant on general assistance.",
            "OK, fine, so I think I'm not going to check the rest of the text because I know it finds everything.",
            "And what you're trying to create is a gold standard.",
            "It's really important that data is annotated properly.",
            "So if you start missing entities in the manual annotated corpus now, all the systems that will be created based on that will not actually find entities there.",
            "Emulate whatever the learning system did, which is not the task definition.",
            "Conversely, if you have too much precision, which means most of the interface it finds are correct, then the user will start looking at those.",
            "So OK, I'm not going to check what it does because I know it works well.",
            "So again, you may get mistakes in the output, so that's a problem and there isn't really an answer to that so far.",
            "This is also called the theory creepware loser.",
            "Once the user becomes over Latin overreliant from the system and they stab not correct in the system, you end up with the corpus that's annotated the way the system wants, not the way the annotation manual says, and that's not not what you're after.",
            "Another example, probably the most recent one, or at least the most recent I've heard of is the milita system.",
            "That's the mixed initiative system, which is based on the Amilcar a learning algorithm.",
            "America is also symbolic.",
            "Learning algorithm is a rule learning algorithm.",
            "It started from the idea of the wrapper induction and then it got changed a bit.",
            "It has a tagging rules which insert back into the text, then it have correction rules which can move the inserted packs around or can delete some of them.",
            "One interesting thing about it is that it learns begin and end tags independently, so as far as it's concerned there is no relation between start organization and organization.",
            "Now I'm not saying that necessarily a good thing is just it's original.",
            "It's something different from other systems so that some alcohol there's the learning algorithm.",
            "And then there's a system called Melitta which is based on amilkar and which does adaptive, adaptive information extraction is a different name for machine learning for information extraction.",
            "Amber OK Manitowoc picture does it the active learning because the user in the system cooperate to annotate the text.",
            "Recently it's being extended because they got more funding, so it's being expanded as part of the semantic web effort, and we're excited to see what they do with those money.",
            "All the basic idea behind Alembic Workbench and Melita is really the same, and they're both rule induction systems, so they are quite similar.",
            "The main difference between them is that Alembic is oriented towards language engineers, so people who would be able to look at the rules and change them and who understand very well what the problem is and what they're actually trying to achieve, whereas Melitta is.",
            "Oriented towards end users.",
            "So as they say, naive users, so people who aren't necessarily very experienced in this kind of problems because of that, lambeck exposes more of the internals of the system, whereas America is just a nice interface you don't really know what's happening underneath and just get some sliders, move them around and use it.",
            "Now, because of it was developed last year, military is able to talk about families and intrusiveness, so there are some options we can tell the system how often to intervene and so that you get the most satisfying experience for the user so they don't get bothered too often with the wrong intervention from the system and.",
            "This kind of gradually take into account Olympic does not do that, but that's probably because at that time you couldn't really afford to decide when to run the algorithm.",
            "You run it when you have the time, because the hardware wasn't that powerful, both of them acknowledged the problem of theory Crippen, the over reliance, but they don't have a solution for it.",
            "The machine learning behind the both of them is pretty much the same.",
            "It's very similar.",
            "Right, so as crucial saying will be given a lot of examples from gate as Alembic, Gate is a system that allows manual annotation, has a lot of NLP machinery behind it, so it's a good place to start implementing machine learning as well.",
            "Also, defining machine learning's classification, you have a set of attributes and then you have to infer the class from them.",
            "The objects that are instances in this case are the annotations over the text.",
            "Another simple interesting promises document classification which we're not addressing directly, but it can be addressed if you have annotation type that it's a one translation of documents.",
            "Each document has only one of that annotation type, and then you're classifying those annotations.",
            "You're actually classifying the document, so you can do document classification, although it's not really obvious from the first step how you would do that.",
            "Oh operations considered as expenses have to be the same type, so you define a particular type of my instances and then you work with them.",
            "The features are extracted from the instance annotation or from the context because as you saw in Hamish is part when you try to find entities.",
            "You have to look inside the text, but many times the context gives you useful clues as well.",
            "So you need to be able to get to the information from the context.",
            "There is a generic implementation which.",
            "Processes gave documents to collect the attributes and then that can be linked to any machine learning engine which is external.",
            "We figure that, well, we're not specialist in machine learning, so it makes more sense for us to implement yet another machine learning algorithm will be using some of the state of the art.",
            "Once we just make them work with textual data, the kind of data that we're using in human language technology.",
            "Currently we have integrated wake up, which is a very good library with lots of implementation for the classic.",
            "Algorithms and we have an HMM implementation from auto text and we're working in including maximum entropy and support vector machines, which are algorithms that work well with text.",
            "So you have a personal resource in gate which does the machine learning capabilities, does both training and application of the models.",
            "The configuration is in an XML file you have a data set definition which tell us what the instances are in what, how to collect the values for attributes or features.",
            "Then you have another element which defines which engine to use, which external engine to use.",
            "Now, if you think of this as annotation, so we have the text somewhere in this annotations covering various parts of the text, and you decide the tokens are instances.",
            "So here we have a sequence of tokens, and this is the current instance.",
            "The values for attributes are collected either from the annotation type and those are Boolean attribute telling for instance that over the current instance there is a look up annotation.",
            "That's what that means.",
            "Or we can collect values from the value of the features.",
            "And in order to get to the context, you have this positional value here.",
            "So for example have minus one.",
            "The value for this instance will be taken from the annotations overlapping the previous one.",
            "That's how you get to the context.",
            "Or you can have context towards the right side as well.",
            "How the way it works?",
            "The main later flow is started, documents you use all the MLP machinery you have at your disposal to enrich the documents as much data as possible in order to create features.",
            "Then the feature collection implementation creates the kind of structures that are usually used by machine learning algorithms, which makes them easy to use interface towards the machine learning engine itself.",
            "So once you want to integrate and machine learning you just need to.",
            "Rewrite this interface.",
            "Everything is already implemented.",
            "Round ocean.",
            "Learn and get the results and then this is also part of the core gate and you get generated documents.",
            "So that was the idea was pluggability.",
            "In order to allow to play with as many machine learning engines as possible.",
            "And I think that's my part.",
            "Any questions?",
            "Should we break now?",
            "It early, but rather than start something else.",
            "OK. My colleague anime North is going to talk about I want aladji based information extraction which are systems which explicitly use ontologies to perform the information extraction task, and then I'll give you some examples from large scale processing systems in the area as well.",
            "So just a brief reminder from what he's saying earlier on.",
            "If you think about the book named Entity Recognition Task, the tags in text were just parts of the segment, a part of the text, and these parts of the text were referring to a particular entity, like a location or an organization.",
            "But there is no specific effort to relay.",
            "Those two are two owned Aladji.",
            "So for example have a representation of the domain.",
            "In question like we have organizations that are sub classified in companies and nongovernmental organizations, and for example universities, etc, etc.",
            "So there is no ontology of the domain in mark, you just sort of identifying strings in the text and saying, OK, here is a location.",
            "Here is another organization, but there's no kind of relationship between those.",
            "On the other hand, walked we want to do when we haven't until GS to perform semantic tagging, and in this case the idea is to identify mentions in the text and say OK here.",
            "This piece of text Tony Blair for example, is talking about a particular instance Indian teologi, and that instance has an identifier 123 or whatever.",
            "And here are all the mentions in that text of this particular instance.",
            "So these all all these things are referring to one in same instance in our ontology.",
            "And then we have another instance, another person, and these are all the mentions in the text from regarding that instance in deontology.",
            "So if we think about all the tasks could be there 3 three aspects of these.",
            "So first of all we need to again look at the text and find all the mentions of particular entities, pretty much like you so up till now for traditional information extraction, then we need to disintegrate those references with respect to the ontology.",
            "So we need to decide.",
            "OK here this instance this.",
            "Piece of string Tony Blair or the Prime Minister is refering to instance 123 in the ontology and it's a type instance of concept person and sometimes maybe we just don't have that instance in our ontology at all.",
            "Maybe just something new that just come up in the text.",
            "So for example, if you are analyzing use texts, that could be a completely new company that's just being formed and this is the first text that you've come across about that company.",
            "So for example, when Halifax Bank joined with the Royal Bank of Scotland in.",
            "In England some time ago there were all these new texts mentioning this new company called H Boss and up to now in your ontology you wouldn't have an instance about age boss, so you have to identify that.",
            "OK, we have a new instance.",
            "It's above class company and we need to add it to entology because this is a brand new instance that we've not seen before.",
            "And then the third aspect of the task is the third type of task is to identify in the text attributes and relations with regards to these instances.",
            "So where they mentioned and we can do that, for example, using information from the ontology about what kind of domains and ranges can have properties can have certain properties.",
            "So here I want to give you an example of that.",
            "It's from Kim System, which we'll talk about later on.",
            "But the example is just trying to show the different aspects of these tasks, so we start off with that text on top and the different highlighted parts are the entities.",
            "So XY, Zed's 3rd of November, Bulgaria, London, etc.",
            "These are the entities, and here is our ontology and.",
            "So it has different instances like Bulgaria, UK, London etc.",
            "So we first identify them in a text.",
            "Then we identified the correct distances in our ontology which they are and once we have done that, the last step is to identify also the relations between them.",
            "So we have the company that is established on that date and it has certain headquarters.",
            "So these are this is kind of an example of these tasks that need to be carried out.",
            "In another, if you look at that from the ontology perspective just to make it slightly more clear what's happening is if we have that piece of text.",
            "Gordon Brown make my George Bush during his two day visit.",
            "Here is entology.",
            "On the left.",
            "We have this simple ontology of entities and persons and we have an instance for George Bush.",
            "So we identify the entities and then we identify that we need to add a new instance for Gordon Brown because he's not being in the ontology before.",
            "And then we call referred to things and then finally what we have in the text is this kind of metadata which says this is where differences from traditional information extraction.",
            "It gives you directly references to the class of the ontology and the instance identifier in that ontology, so we're not anymore just saying OK in this text, we have Gordon Brown, and that's a person in George Bush.",
            "And that's a person.",
            "But what we're doing?",
            "I mean, they're no longer tags.",
            "Like you so before you know it just had to talk person what we have in here is in the ontology based information extraction or semantic tagging.",
            "What you're trying to do is to assign automatically these information of classes given the ontology and instances to these occurrences in the text.",
            "So you have in dramatic dated descriptions about text you have which parts of the text are concerned there.",
            "So from from where this is starting, this is the end.",
            "And what is the string?",
            "So we have Gordon round there and we have world class and instance it belongs to.",
            "And this is the game for the next one.",
            "So these are the.",
            "This is the difference is quite a different task in comparison to before.",
            "So what happens if you have some more text cloud entology changes?",
            "Again the same thing but we have to add another instance for Tony Blair because it's not been there before and again we have the same kind of metadata.",
            "Here we have the same.",
            "Instance and class is before, but it's just a different mention because it's part of a different document and we have another mention of this new entity that we have there with businesses that we have just created and it's a gain of a class person according to our ontology.",
            "So if we look at the problem of metadata creation with information extraction.",
            "What we can say is there are two ways in which we can do it.",
            "One is too.",
            "If you remember in previous life I had the meta data here on the right and it was referring back to the original text in a standard fashion.",
            "Or you can insert all this information with the UI's for the instances in classes back into the document.",
            "Like is inline XML or whatever.",
            "So these are the two ways of doing putting the metadata.",
            "Into the text or separately and then also two other ways in which you can do at the metadata creation when you're using information extraction.",
            "When is semi automatic, so you have the information extraction system carry out the task.",
            "So identify concepts in instances as good as it can, and then you have a user which who is post editing that and creating the markup.",
            "Finally, validated human human validated markup and.",
            "This is good because you know it gives you very correct markup, but the downside of it is that we have only one view, which is to say that the user is using one particular ontology and they're creating metadata with respect to that particular ontology.",
            "And once we have that metadata it's already created.",
            "It said it's not very easy to change it if there are some changes in geology because we need to ask the user to look at this again.",
            "So in some sense you can think of it as.",
            "Human authored HTML where once you have the links in, that's it, you can't change them.",
            "And then we have the automatic metadata creation aspect where we have many different information extraction systems that can each run.",
            "We using different ontologies on the same text.",
            "They can create you separate different metadata sets for depending on which ontologies used.",
            "So if the ontology in some cases if one ontology has only persons, then Tony Blair, George Bush etc will be all persons.",
            "But if we have a more complex ontology in a different application that distinguishes between politicians and.",
            "I don't know researchers and other types of persons.",
            "Then you will have, according to that new entology, you will have a different information extraction application that will automatically classify politicians on their politicians and actors and directors etc.",
            "So you have different types of metadata according to the ontology.",
            "So this is the advantage of using different information extraction systems automatically on the same pages.",
            "The other advantage is that if the ontology is changed, then the meta data can be changed automatically because you just rerun it.",
            "There's no human who needs to go and validate each of the decisions, but the problem is that it's less reliable, so it makes mistakes.",
            "And in this tutorial will show both aspects and different systems.",
            "Now the first thing that people tried was OK.",
            "They'll take a traditional information extraction system in this type in the same style is like say, system created to identify Monk named entities or something like that and supply to the semantic web to create some metadata and that work has been done as part of this cream which stands for semi automatic creation of metadata and it's a joint work between.",
            "Where and people in Sheffield and there are main problem there is that there are semantic tags from information extraction.",
            "In this case it was all about hotels and rooms and prices and things like that.",
            "So I'll show you what kind of tags the information extraction system was trained to produce and also show you what was the target output of that system in terms of concepts and instances and attributes.",
            "So you see that there is quite a quite a big gap.",
            "Between those and the other problem with applying the the traditional information extraction approaches was that the majority of machine learning systems for information extraction, they don't deal very well with relations.",
            "Going back to a question that we had very earlier on.",
            "They've been mainly trained to identify entities or roles of entities in a text.",
            "So for example, to identify speakers, seminars, or to identify.",
            "Certain job descriptions or things like that, but nevertheless, although they're not named entities as much, defines them, so they're not necessarily people and locations and organizations.",
            "There are still kind of entities.",
            "Their concept in ontology.",
            "So if you're trying to identify automatically attributes or relations, so what's the with what had two concepts are connected?",
            "Or two instances are connected in the text?",
            "This is quite difficult.",
            "It's still an open issue.",
            "And the other problem that was found was a particular system that they used amilkar, which we introduced earlier on.",
            "It doesn't handle anaphora resolution.",
            "ORCA reference according to the class definitions earlier on so engaged we have such a component, but it wasn't used as part of the email correct system and they did have a struggle quite a lot with the lack of anaphora resolution, and this is because if you don't know all the mentions in the text which refer to the same entity, it's really hard to identify.",
            "The relations between the different instances in the text because you have to know, is this the same room that has been talked about earlier, or is this the same hotel?",
            "So to get around this, what they did was they implemented a discourse model which is based on logical rules, and that discourse model was fixing up the results from the information extraction system and deciding it knew about the ontology.",
            "So it's only at that point in the discourse model where it was taking the output of the information extraction system and saying OK, according to my ontology, this is probably an instance of my hotel concept.",
            "And this is probably an instance of a room, and this is its price.",
            "And show examples about how this was done, but the main point is that there is a problem with using this kind of approach for information to obtain metadata with respect to ontology.",
            "The problem is that this kind of discourse models they are very specific to a domain and you risztics that you see are later on in a minute very specific to the particular domain as well.",
            "So they're not very robust.",
            "And if you want to port them to a new domain.",
            "Well, we have to start from scratch basically, so it's not.",
            "It's a bit difficult to reuse them and write a generic system for that.",
            "So here is the example on the left hand side are the.",
            "Is the output that was created by manual annotators with respect to the ontology that I mentioned of hotels, cities, rooms, etc.",
            "So you can see that the manual annotators or created quite a lot of information like a particular instance filing then was a hotel and is located at a particular place dobbertin and it's an instance of a city, etc etc.",
            "Whereas the information extraction system will be produces art is kind of.",
            "Entities.",
            "And they are mainly, you know.",
            "It says OK, we have a hotel.",
            "We have a city.",
            "We have a single room and we have a price, currency etc.",
            "But what is missing here?",
            "Is all this information that this here is an instance of a particular concept and that there is a located that relation between the two and that you know we have room which has a price etc.",
            "So a lot of the information was missing there and this is a problem when you just take an information extraction system that doesn't know about the ontology.",
            "And you try to use its output to create the kind of meta data that you had there on the left.",
            "So coming back to the discourse rules.",
            "They had several basic types of rules.",
            "The first type was that you allowed to attach instances to entology only when the when you have the correct class.",
            "So for example, you cannot attach prices to cities because the ontology says that only only rooms have prices.",
            "So if the ontology says only rooms have prices and you have a price and you're trying to attach it to something, you automatically have to disqualify all all the concepts that don't match.",
            "According to the ontology.",
            "Then the next step is OK. We have this qualified.",
            "Some of the things from the some of the instances in the text because they don't match.",
            "What do Entology tells us, but still we have left with several.",
            "So which one are we going to choose?",
            "And according to various models of this course?",
            "Times it makes most sense to choose the nearest preceding compatible entity, so you're treating the discourse like a stack and you're thinking OK from this from the beginning of the text, we've talked about a hotel, then about a city, and then we've just spoken about a room, and now we found a price, and the question is, where do I put that price?",
            "First of all, OK, I checked my the entity on top of my stack is a is a room.",
            "Can it have a price?",
            "Yes it can OK, and then we think OK. Because this is the nearest preceding entity, most probably that price is about this entity, because this is how typically tell text work.",
            "So this is another heuristic.",
            "We attach it the price to the lightest room mentioned in the text.",
            "And there are also these kind of complex objects which which defy which combines several types of.",
            "Of outputs of the information extraction system.",
            "So, for example, the information extraction system can recognize currencies and numbers, and in the anthology we have this complex concept which is a rate and is defined.",
            "So there are some discourse rules which say that OK if we have a number followed by currency then we have this rate.",
            "So again, it's a bit like these.",
            "These rules that you saw earlier on about how you recognize entities.",
            "This is not that different.",
            "In that respect, and finally you can have experienced users.",
            "Users write such kind of discourse rules, but generally it's quite difficult.",
            "So I mean basically, this is the pros and the cons are of this approach are that it works quite well if you have a limited domain you can have these rules and you can get it off the ground quite quickly so you can use a traditional information extraction system that knows nothing about the ontology.",
            "But the downside of that is that you have a very specific system which is hard to Portland, ME.",
            "So if we think about what the challenges are for information extraction for the semantic web, we have these problems.",
            "We need to address portability because there are different ontologies even for the same domain according to different applications, they change overtime.",
            "There are different text types structured free texts, any structures, etc.",
            "We really need to be able to use the ontology information as much as possible and directly have outputs.",
            "From the information extraction system with respect to concepts and relations in the ontology not having to post process them like they did in scream and they need to train from small amounts of data.",
            "But preferably if we're going to use a machine learning approach because many want station is very expensive.",
            "As I said to output the results with respect to the given ontology and also there is a problem of how at what level.",
            "If you're doing machine learning at what level you have to direct to train the system, because ontologies hierarchical so you can choose to identify certain concepts.",
            "For example only identified persons and then not the train.",
            "The system on the subtypes of persons like politicians, artists etc.",
            "Or you can decide.",
            "OK, I'm going to train it separately for politicians and artists and all that.",
            "The problem is that the more concepts you're trying to learn, the more data you're going to need to do to have.",
            "And it's quite expensive to get that data and also the the finer grained distinctions you need.",
            "The more data you need to train that algorithm in order to be able to make those distinctions, so there is.",
            "There are a lot of challenges in that area and.",
            "These challenges have started to be addressed in.com project and they are going to be addressed in the site project as well.",
            "At this point I'm going to hand over to Diana to tell you about system that uses or the ontology as part of the information extraction task.",
            "OK, so I'm going to.",
            "Tell me about Toronto G based I and.",
            "Some of the stuff we've been doing with gate.",
            "Sungate, you've had a mission?",
            "Valentin, I'm talking about both learning and rule based methods of doing information extraction.",
            "Gate also enables us to combine the two in application.",
            "It also enables us to combine not just information extraction but also information retrieval and this can help us.",
            "With with respect to doing meta data extraction from the semantic web as I'll explain.",
            "Also, because gates and architecture where you can plug in various components as you want.",
            "So it means that you can stick into it.",
            "Large scale linguistic resource is for IE.",
            "For example word, net or any other.",
            "Any kinds of ontologies you want and various other applications.",
            "An other said it supports a montage is as part of the eye applications, so we can do ontology based, IE.",
            "So, for example, here's a screenshot of um.",
            "An ontology in gate using protege.",
            "So we plugged in Potamia protege.",
            "Into it and you can see here in the main window.",
            "Sorry, you can see as more section of an ontology and you've got the various features and attributes and so within the gate architecture you can.",
            "You can view your ontologies.",
            "You can create new ontologies, you can manage them, you can edit them whatever.",
            "So that just enables you to do this as part of part of the application.",
            "Information retrieval, and when you're doing traditional information extraction, you typically have a corpus of documents about a certain topic.",
            "So for example, in the competitions each year there was a specific very specific topic and you got a bunch of news texts about, for example, company takeovers in the eight evaluation, similar kind of thing.",
            "There were a predefined corpus of news text when you're doing them.",
            "Until you based information extraction well, when you're creating data for the semantic web, for example, typically you're using the whole of the web or a subsection of it, so you may not already have a predefined corpus, so you can combine information extraction information retrieval by first of all using an information retrieval system to find the documents about the particular topic you want, and then performing your information extraction on them.",
            "So again, in gate we can we can plug in an IR engine such as Lucene.",
            "And which is useful for combining as a semantic and keyword based search?",
            "So here we've just got a screenshot of leucine and gate, and we've searched for something like company takeovers, an here we've got a list of documents which are sorry Mr Documents which are relevant to our to our search, sorted by frequent by relevance.",
            "Um, funny as I said, we've got.",
            "We can also plug in things like word net into gate an we can use this to help us with with our application.",
            "So here we've got section of Word Net.",
            "And again, you can do.",
            "You can perform various searches for different.",
            "Different types, such as nouns and verbs.",
            "You can also look for relations like hypernyms and antonyms and all kinds of things, so again, you can.",
            "You can play around with that.",
            "So probably ontologies with IE as cleaner mentioned, this is just a different viewpoint of student of the same thing that cleaner showed before I think.",
            "So in the left hand side, we've got a text which has been annotated in gate, similar to things we've seen before, so we got examples of people in blue and various things, and then we can output the result of the annotations into an ontology.",
            "So I'ma right we've got the DML ontology.",
            "Square with attached instances.",
            "So for example Pakistan has been attached to location and plasma Putin's been attached to person and so on.",
            "So that's what it all looks like in gate.",
            "I will give an example of an ontology based information extraction application which we've been developing.",
            "It's easier to see what we're talking about by showing a real application.",
            "I think HX Light is a is a project which we've been involved in.",
            "Which aims to essentially track technological change overtime using terminological analysis.",
            "So in the project we've been using ontology based information extraction for the semantic tagging, tagging of things like job advertisements, news company reports in the domain of chemical engineering.",
            "So fundamental to the application is a domain specific ontology, so this is where it differs from traditional IE, because the whole basis is to start from from the set of texts and an ontology.",
            "We use instead of using a flat gazetteer structure as is using.",
            "Traditionally we have a set of terminological gazetteer lists which are linked to classes in the ontology.",
            "So we start from the ontology and build the lists and say from the ontology.",
            "So the lists contain typical instances of classes in the ontology, and then we use a rule based system to classify mentions in the text with respect to the domain ontology.",
            "So what we're using is.",
            "An adaptation of the default I sister money which Hamish talked about earlier.",
            "We don't use any machine learning in in this application, mainly becausw in order to use machine learning application we'd need a lot of pre annotated text which we didn't have an appetite quite time consuming to create these and you need a domain expert, so we've used a rule based system.",
            "And because the domains in which we're working and the applications at the moment kind of sample applications, so the ontologies are quite small and they're very specific as well to the particular application.",
            "So one of the important things is that we use, for example, a different ontology for each kind of domain in each application.",
            "So we use one ontology for tagging job advertisements, because the kind of things we're looking for in job advertisements are different from the kind of things we're looking for.",
            "In general news, text or.",
            "Technical reports.",
            "So the the system goes off and annotates the all the mentions in the text and say with respect to the ontology.",
            "Then outputs these annotations.",
            "It can output them as an ontology, as that you've seen in the example just now.",
            "We also output the annotations into a database, and this is used for further processing.",
            "So the point of the application is says to track change overtime.",
            "So we output the annotations in database format as well, where they're totally independent of the texts.",
            "At this point we don't care about the texts anymore, that's kind of irrelevant, and we then look at how the the.",
            "Frequency of thing instances appearing in the text and how those change overtime so we can manipulate the instances and the results and say use that for statistical analysis.",
            "So the few screenshots now, this is, here's an ontology.",
            "Keep doing that.",
            "His mental energy of which is used for tagging job advertisements.",
            "So in the center we've got, I don't seem to have a point or anywhere in the center.",
            "There's the ontology with the concepts and then to the right we've got various lists, lists of lists.",
            "And on the right stop touching it on the right.",
            "We've got.",
            "We've got an example of a list, so we've got programming types of programming packages.",
            "And then in the bottom center we've got some definite definition file which Maps instances to the ontology.",
            "So that's the.",
            "That's the gazetteers structure linked to the ontology an that's users say for finding the instances.",
            "His screenshot of the tagging gate, again very similar to what you've seen earlier, so we've got examples here.",
            "We've got things like we got typical things like locations and organizations, and we've got other things, like application which is methods of application for applying for jobs.",
            "Things like resumes is a Word document is the method of application for this particular job advertisement, and there are other things annotated, such as kinds of qualifications needed, references, what kind of sector, this kind of thing, and again at the bottom we've got list of the annotations an I don't know if it's big enough to see, but you've got the.",
            "Again, the information about the class information about where in the ontology these are linked.",
            "An another said we can export the results of this into a database and then we can say we can examine things like frequency, how often they occur overtime in different documents and this kind of thing.",
            "An answer to the question earlier again about relations.",
            "This is something else we've been able to do.",
            "I haven't got any examples of this in this lines because it's something we've just done very, very recently, but we can also use more than one ontology.",
            "There's nothing to say we have to only use one ontology for this sort of application, so we can stick in as many ontologies as we like an, and we've been able to to add to the application some relational extraction.",
            "Whereby, for example, we can find instances from different ontologies Ann and we can map.",
            "We can find relations between two instances from different ontologies Ann and say an extract that information and export it again into database or into a new ontology.",
            "So that's essentially the rich text like product, which is to say is is an example of ontology based information extraction.",
            "I'm going to hand you back to Kalina, who's sorry.",
            "Oh yes, I will take questions if there are any, otherwise I'll hand you back to to clean and we'll talk about some large scale processing platforms.",
            "Yes.",
            "The donkeys.",
            "Side note about knowledge about knowledge or information.",
            "Play versus united.",
            "Sorry I didn't hear the last part of us, please.",
            "That's not something we've we've done any work on at the moment, and but yeah.",
            "Find reviews of president.",
            "Yeah, but those are kind of stage further into into understanding when you start looking at things like intentions, which I mean that there is quite difficult to deal with with the sort of shallow I that we're doing here, you really need to say more deeper kind of models, But for doing this so at the moment that's that's not something we've really looked into, but I mean, you're right that it's it.",
            "It could be very useful.",
            "OK, I'm in the past year or so, there's been a couple of works on applying information extraction technology on a very large scale, which means that in thousands or hundreds of thousands or even millions of documents, and I'm going to show you some examples here.",
            "There are some commonalities across all those approaches and platforms.",
            "The advantage of when you have really large scale so many documents.",
            "The advantage of having doubts is that you can run corpus white statistics to improve the quality of your information extraction results.",
            "So for example, you can have these ambiguation.",
            "And the more data you have, so the more examples you have, and it allows you to train your algorithms better.",
            "And also for example, if you have only a certain types of rules that are very limited but you have a lot of data, then it's very likely that they will apply quite a lot of time.",
            "So you're going to collect a lot of examples.",
            "So for example, if we have some very simple rules that identify persons only by using.",
            "One rule in fact title like Mr or Mrs or Doctor followed by one or more tokens in upper case.",
            "So that's the only rule we have.",
            "We run it on a really big corpus over the web and the chances are adults it will pick up a lot of examples of names like Mr. Blair and Mr.",
            "I don't know John Smith and others, so you can use those then match those strings against that large corpus and use that to derive new examples for your learning algorithm.",
            "Where the these same strings are going, different concept of context.",
            "So then you're just you get more examples because you have a very big corpus.",
            "You can also use the same statistics to disintegrate.",
            "So for example are we talking about Paris in Paris in France or are we talking about Paris in America?",
            "Based on how frequently they occur in the corpus for example.",
            "Also, you can automatically discover aliases.",
            "So in your ontology.",
            "Each instance can have one or more aliases, which are the textual strings used to refer to those instances.",
            "So for people you can have John Smith, Mr Smith, he, etc.",
            "So if you have a big corpus, you can derive many aliases automatically using information extraction for one in the same instance.",
            "They all tend to generate semantic web output like RDF or OWL.",
            "They tend to use standoff annotation like XML or RDF and to index the metadata that has been discovered in the text and allow some kind of query and retrieval over it.",
            "They have very large instance basis to the zombie greater so they deal with thousands and thousands of instances in their ontology.",
            "It's not just an ontology that has 100 or 200 instances in it, it really has very large.",
            "A number of instances, and so they tend to use things like ontology servers for reasoning and access so that data and.",
            "To have many things in common, like components like crawlers which go over the web to find those documents to store the ontology and do reasoning with it, then do some document indexing of that big corpus, something to carry out queries and annotators.",
            "These are the information extraction systems that automatically produce that data, but the main point here is that all of these automatically produced by today.",
            "There's no human involved.",
            "You have one system, it works up to a certain standard, but because you have this big corpus which you couldn't annotate otherwise.",
            "That's the only thing you can do, but because you have that much data, there's a lot to find.",
            "There is a lot of redundancy that you can explore, so that's the good side of it, and they are used for many applications like semantic browsing, some authoring, etc.",
            "First example is the same tax system, it's from IBM, and it was presented last last years.",
            "Well, why web conference?",
            "Chooses the top ontology and that's Intellige has 65,000 instances.",
            "The ontology is mainly about entities.",
            "Again, things like people and their subclassified into politicians and other types of people like that location subclassified in cities and others.",
            "And the idea there are two types of disintegration that can occur when you have an instance in the when you have mentioned in the text.",
            "There are two types.",
            "You either have one of these instances in the taxonomy so you have John Smith as person in your taxonomy, and you need to identify that this is particular instance from from your ontology or taxonomy, or it's not present in that in your ontology.",
            "So you have John Smith, but in your according to your ontology there is no instance.",
            "Potentially can be called John Smith and they they.",
            "Distinction approach here.",
            "The distinctive approach here is that they think that the ontology has all the instances that are relevant to this task.",
            "We're not going to add new instances at all.",
            "Or are we going to do is say OK in this text?",
            "Here is John Smith.",
            "Is this an instance in our ontology?",
            "And then if it is which one, or otherwise we just think OK, it's not relevant to our application, so that's what we're trying to do here in the same tax system.",
            "I'm going to the other thing that's characteristic is that according to the top ontology, there isn't very high ambiguity between instances with the same label.",
            "So if we say for example, Paris, according to according to tap, maybe there will be just one one instance that will have the label Paris, which will be the Paris in France.",
            "They want that there isn't.",
            "There aren't very many.",
            "There aren't very many instances which have the same alias, an it means that they have focused mostly on the.",
            "On the second problem, which is not so much disambiguating between the possible instances according to the ontology, but deciding is this an instance in our ontology or is it not?",
            "And so for disintegration, I don't think I'll have time to go into that.",
            "So, but basically what they use for it to do that.",
            "Disintegration is like a bag of words approach where they building the context where in the text of this particular instance occurs.",
            "So for example, if it's talking about the person they're taking all the words on the left and right of that and saying, OK, we have John Smith and it's talking about presidency and it's talking about no attending meetings and things like that.",
            "So if you're matching that to an instance and then in each instance in the ontology they have similar contexts of where those instances have occurred previously in texts and then they match the two using information retrieval methods like cosine similarity, and if there is sufficient similarity between the two contexts, they say up the between the context in the text and the content.",
            "That instance entology.",
            "Then they say, OK, we have a match, so this is the same instance.",
            "And if there isn't then they say OK according to our ontology we don't have such an instance and we're just not going to into annotate.",
            "It's not relevant.",
            "They use some people to manually annotate what are the instances in urology for a given 200 labels and their context in texts.",
            "And it was quite interesting.",
            "I mean, I really encourage you to read the paper because the Inter Annotator agreement on some of these concepts was not very high.",
            "It was close to 70% and the reason for that is because entology there could be materna misuse.",
            "Of the same instances.",
            "So if we're talking about France, for example, if we have in our ontology, France is a country.",
            "But we can also have.",
            "France is a location over France is.",
            "As a governing body in the sense of the governing body of the of the country, right?",
            "So you can have the same instance potentially relevant to different concepts like the country.",
            "Or is it the governing body of that country?",
            "Or is it something else and this has been dealt with in Ace as well?",
            "What Hamish mentioned earlier on and the problem is that this kind of detecting the metonymic use of the same the same words or the same label in text is very very hard.",
            "So I mean, it's even hard for humans to make that distinction according to these texts.",
            "Are we talking about France?",
            "Is the location as in the part of the country located this geographical position?",
            "Are we talking to France?",
            "Is the country is in the sort of abstract sense of country?",
            "Are we talking in France in terms of the government of France?",
            "So this is very difficult to make even for human to agree on.",
            "And this is the problem.",
            "When you ask humans to classify instances from text according to an ontology.",
            "That's entology should speak sort of well engineered so that humans can make reliably this sort of distinctions, because if they can't make them, then there is very little hope that you can actually train a machine to do them reliably as well.",
            "The goal very quickly over this, but the high performance of that system is based on the Seeker architecture.",
            "It's a distributed architecture and it runs on.",
            "128 dual processor machines and separate storage and IT processes quite large number of documents is based on soap and there are different parts of that architecture.",
            "Kinda sees crawlers storage join us which are for cooling the indices that the analysis, which are the information extraction modules and the corresponding applications that browse that data.",
            "The second example that I wanted to cover is the Kim system, and it stands for Knowledge and information management management platform.",
            "It has an ontology called Chemo and it has different number of instances depending on which instance based you load.",
            "There is a smaller one which is about 90,000 document instances.",
            "There is a larger one which is 200 thousands and I think that they now have got even larger one, but I'm not sure about that.",
            "There's going to be a demo of that on Wednesday, so if you're interested in further information you can go and see it.",
            "The difference from the top ontology is that there is high ambiguity of instances with the same label, so there is a need to disambiguate again.",
            "Are we talking about Paris in France?",
            "Are we talking about Paris in the US because they have large number of geographic instances and it's a full geographical gazetteer, so these have a lot of ambiguity, unlike type.",
            "And so during the initial phase, they directly use the ontology to help the information extraction system in a similar way to which Diana was presenting.",
            "But the difference is that they don't use gazetteer lists.",
            "Instead, the information extraction system directly hooks into the knowledge server and extracts automatically from there via queries.",
            "All the instances of each which concept and just uses them to annotate the text.",
            "So there are no gazetteers at all, you're just directly looking at looking into the ontology to identify all the instances that you have and then annotate dousing the text and then combine that with rule based information extraction system to recognize other aliases of the same instances or new instances that have not been mentioned before and are those to do entology.",
            "So this is the next step, is the knowledge base enrichment where you have these new instances which have been identified for the first time by the system to be added to the ontology for future use.",
            "And in order to disambiguate how.",
            "What instance is used in the text from the several possible ones with the same label?",
            "They have the so called entity ranking algorithm and it implements basically priority ordering advantages based on some corpus statistics.",
            "And if you want some further details aside, ask them at the demo, but it's a very good example of how you can use a large corpus of thousands of documents to derive such kind of disambiguation.",
            "Statistics.",
            "So in terms of technology, the information extraction pipeline uses quite is quite similar to what you saw where you're on shown by Hamish Indiani system, but there's the so-called Semantic Gazetteer, which directly uses to ontology and to obtain the instances instead of having lists.",
            "And then you have the information extraction algorithms, the rules, but there are they use directly.",
            "Ontology and subsumption from the ontology to carry out some of the tasks.",
            "And they also have these these integration algorithms that I mentioned, and they also have some relation extraction, which is quite small.",
            "Set of relations according to the ontology.",
            "They're basically things like located at, so identifying what is the location of a particular person at the given time, or things like that.",
            "Some things related to time as well, I think, and also rolls like.",
            "What is the profession of a person and some other examples like that?",
            "They come from the ontology.",
            "So if you like some further information, have a look at their ontology and you can also update demo online for that system.",
            "So to compare briefly, these two systems, there is a big difference between them in terms of their aims.",
            "So in the same tag approach.",
            "But they're mainly aiming for accuracy.",
            "In other words, precision, so that's what they want to do is OK every time we find something in the text, we want to be sure that this is the instance in deontology that we say is we want to have very precise algorithm was what they try to do in Kim.",
            "Is to also in full coverage, which is the recall aspect.",
            "So what we're trying to do is to identify absolutely all mentions in the text, because they're trying to identify relations.",
            "So if you are trying to identify like located at relation and you have person on one side and location on the other, if you have missed the location then you cannot find the located at relation because you only have person right?",
            "And this is the difference because they're trying to identify relations and because of that they have to identify all mentions.",
            "In the text, so for them, recall is very important ways in.",
            "Sometimes they're just trying to find OK. Have we got this instance in the text or have we not got it?",
            "So it's mainly for like information retrieval, sort of purposes, and it's not important to identify always occurrences, so we try.",
            "There is a tradeoff here, as he said between precision and recall, and each application has to decide whether it's better to go like the same tag approach or the other approach.",
            "It really is a decision to.",
            "Be made by the application.",
            "The other difference is that sometimes does not attempt to discover and expand the instance base with new instances.",
            "So for example, new companies.",
            "And some.",
            "In other words, it depends what we're trying to do.",
            "Again, if it's important for us to discover new instances as part of the information extraction process, then perhaps we shouldn't.",
            "We should consider approach like that in Kim, where it can be handled.",
            "The differences to demonstrate this slightly more clearly is OK in the same tag approach we have this, it's fine, some instances and some in some tack.",
            "It doesn't find relations, but in Kimi does find some relations.",
            "And maybe that's enough we don't care so much about the mentions in the text, because what we're more interested in is in actually finding the syntactic in other semantic information, creating this and populating this with information extraction.",
            "So in this case, this is what we're interested in.",
            "Have we found those part of relations?",
            "Have we found the airport?",
            "So if this is enough, then this is considerably less problematic.",
            "It's easier to attain that goal then it is to try and identify.",
            "All of the relations in all dimensions in the texts, so to give it more clear example, if we go back to our previous case again, we find those.",
            "And we're comparing in this case, what we're trying to do is to just find these from teologi in all its instances.",
            "So in this case, if that's all we're trying to do, OK, we have 100% success because we have identified both instances here and our ontology looks like we want it to look, and we're not so interested about all these in the text.",
            "The fact that we missed President Bush up there is not relevant to us because we have still identified it, at least in one place.",
            "But the second growth scenario is where we really want to identify all the mentions in the text right at the curse, and the reason for it is because if we want to have sentence based or paragraphs based exploration of the top of the text, then we need to really have all them.",
            "All the semantic information, but it's really hard to achieve.",
            "So what we're talking about here is this.",
            "So we are comparing the fact that we have missed their President Bush and now we have a success rate of 66% because we have only found these two, whereas what we've set out to find originally was also this.",
            "And this is missing.",
            "So you can see that given same text and the same results from the information extraction depending on what your application is trying to do, you can have quite different results.",
            "So it's really important to have that in mind.",
            "And the third example is this one.",
            "It's a semantic web annotator.",
            "It's an ongoing collaboration between Dairy and Sheffield University.",
            "It's being hosted the dairy, and it comprises of the gate system that we shall do so earlier on.",
            "The Kim.",
            "Form that I just discussed and Psycho.",
            "It's an RDF color and the basic goals of these work are two.",
            "Similarly.",
            "Again, a large scale annotation effort aiming to annotate thousands of pages at the moment is performing custom indexing of news and in the future other types of web protects.",
            "Further uses ended quantitative media reporting.",
            "Annotated Web Workbench service and custom knowledge services, but for further information there will be a demo and poster on Wednesday.",
            "So before you do that, because I think we don't have time.",
            "For in depth discussion here, basically the logical architecture is very similar to what you saw in Sam tagging Seeker.",
            "You have the web and you have a focused crawling there and then you have many processors, different machines that carry out the information extraction task you collect the annotations in a database and there is no knowledge base with instances and ontology.",
            "And then you have a lot of web services.",
            "That's allowing access to all the data.",
            "For example, to have conceptual search and their different users here via web services or via user interface for human users.",
            "So one interesting thing here is that it has a console for controlling the cluster, so you can enable and disable machines which run the different information extraction tasks and so forth.",
            "So I'll go very briefly into this because we don't have very much time.",
            "The next step is to carry out the reference disambiguation cell to identify when we have many instances in the text which are the.",
            "Referring to the same to, say, Mr. Synology and which are referring to different ones, there are several possible approaches that have been explored.",
            "Young girl very much detail, but I'll point you at some of them so we can read them or yourself further, there's the vector space models as I mentioned in the systems like some tag where they compare basically context similarity, building vectors of the context and they run over corpora.",
            "There's also cross document Coreference work from the computational linguistics field, which is quite similar, but the difference here is that the cross document Coreference work is not concerned with ontologies per say, it's.",
            "Just a question.",
            "There was weather.",
            "Weather 2 documents that talk about, for example, John Smith are talking about the same John Smith, which is quite similar, but you don't have a specific explicit ontology of the domain and all the instances in that domain.",
            "There's also approached from knowledge management and its communities of practice.",
            "These are automatically identified on the basis of the ontology itself, so no reference to text whatsoever or the occurrences in the text.",
            "It just identification of weather 2 instances are actually the same instance on the basis of the ontology and the links that exist in the ontology by the different relations.",
            "There is a paper on that here at the SWS.",
            "It's about the CS active space.",
            "And you can have further details from that paper and then the final one is you can use some kind of reasoning to identify some to have some identity criteria from the ontology.",
            "So for example if we say OK, all people who have the same date of birth and name and place of birth are identical.",
            "Presumably if we have that kind of axiom in our ontology and we have identified using information extraction system that we have a person called.",
            "John Smith and he was born on 1st of January in London.",
            "Then you can say you can ask the ontology reason.",
            "There you have an instance that has the same name, the same date of birth and same location and because of the because the reason will say OK, this is these are the same person so you can disambiguate at that point saying OK that John Smith that I have in my text is the same as the instance of John Smith from Genealogy because there.",
            "That's what my reason are tells me they are identical.",
            "So one thing I'll skip that, but can somebody tell me 10 minutes?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So welcome to the second tutorial session.",
                    "label": 0
                },
                {
                    "sent": "the European Semantic web symposium.",
                    "label": 0
                },
                {
                    "sent": "My name is finished Cunningham, my colleagues Valentin Tablan coming a bunch of her entire made out of doing the tutorial with me, will start off with some bold platitudes and simple concepts, which I'll do this stuff where I wave my hands around and make kind of bland comments.",
                    "label": 0
                },
                {
                    "sent": "And as we go through the tutorial will get more complicated and interesting, and I'll kind of lose my depth and then the rest of the table will come and do it instead.",
                    "label": 0
                },
                {
                    "sent": "Human language technology for the semantic web.",
                    "label": 1
                },
                {
                    "sent": "Brought to you courtesy of whole bunch of projects including act and sect.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Program manager sitting in the back.",
                    "label": 0
                },
                {
                    "sent": "I have to say sick.",
                    "label": 0
                },
                {
                    "sent": "First thing I want to say is, are you wasting your time?",
                    "label": 0
                },
                {
                    "sent": "My brother used to be a school teacher and he showed me this thing called the learning pyramid and the width of the pyramid is proportional to the amount of stuff that you remember in various different learning activities, right?",
                    "label": 0
                },
                {
                    "sent": "So down at the bottom here you're remembering 90% of what you do, and this is when you teach others or you use the knowledge that you're learning and immediate context.",
                    "label": 0
                },
                {
                    "sent": "So probably if my brain wasn't so short, I remember 90% of what I'm going to do today up here at the top.",
                    "label": 0
                },
                {
                    "sent": "Just sitting, listening passively to lecture you remember 5%.",
                    "label": 0
                },
                {
                    "sent": "5% of the next realis is going to be left in your brain after this session.",
                    "label": 0
                },
                {
                    "sent": "Can you make a home?",
                    "label": 0
                },
                {
                    "sent": "I've loved outdoor, there's no.",
                    "label": 0
                },
                {
                    "sent": "There's no way out.",
                    "label": 0
                },
                {
                    "sent": "There's no way out of here until coffee break in an hour and a half.",
                    "label": 0
                },
                {
                    "sent": "So the point is that if you ask a question if you try and use that knowledge, if you have a discussion over coffee break, then you can remember more stuff, right?",
                    "label": 0
                },
                {
                    "sent": "And there's no specific.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Discussion session in the tutorial.",
                    "label": 0
                },
                {
                    "sent": "So whenever you want to ask a question, just throw it behind diving OK. Want to talk about it?",
                    "label": 0
                },
                {
                    "sent": "I'm going to start with some motivation, background, information extraction.",
                    "label": 0
                },
                {
                    "sent": "We're going to spend quite a lot of time on because that's currently the leading one of the leading technologies from language processing that's being deployed for semantic web.",
                    "label": 1
                },
                {
                    "sent": "Valuation different approaches to information extraction.",
                    "label": 1
                },
                {
                    "sent": "To begin with, we basically looking at language technologies.",
                    "label": 0
                },
                {
                    "sent": "It kind of exists and has done for some time, and there's a tutorial moves out, will look more at stuff that's been done specifically in the semantic Web context.",
                    "label": 1
                },
                {
                    "sent": "So we get around to various sorts of semantic tagging in the second half, and will finish up with language generation.",
                    "label": 0
                },
                {
                    "sent": "The slides slightly outdated version that will be updated when we check in later on, and this URL that keep popping up throughout the session.",
                    "label": 0
                },
                {
                    "sent": "If you want to grab it.",
                    "label": 0
                },
                {
                    "sent": "Melville motivation Gartner reported a couple of years ago that on the one hand, through the next decade it was reported was kind of predicting the next decade of information systems.",
                    "label": 0
                },
                {
                    "sent": "They said on the one hand, taxonomic and hierarchical knowledge mapping and indexing will become prevalent in all sorts of.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In almost all information, rich applications, on the other hand, more than 95% of human to computer information, but will involve textual language.",
                    "label": 0
                },
                {
                    "sent": "So there's kind of a contradiction here.",
                    "label": 0
                },
                {
                    "sent": "On the one hand, semantics based systems systems with a kind of richer set of knowledge structures for processing information are becoming more and more common.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, most of the information out there and most of our interactions with computers in of a lot of cases is in the very ambiguous and informal.",
                    "label": 0
                },
                {
                    "sent": "Mode of natural language.",
                    "label": 0
                },
                {
                    "sent": "So the challenge really that we're talking about today is to try and reconcile these two these two situations.",
                    "label": 0
                },
                {
                    "sent": "The various ways in which human language technology can do that, that various people are working on lots of people are working on.",
                    "label": 0
                },
                {
                    "sent": "You've got on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Here's this kind of for this.",
                    "label": 0
                },
                {
                    "sent": "This diagram kind of summarizes those different ways, and we'll go through all of these at various stages during the tutorial on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Here we've got the kind of formal knowledge on Teologi's knowledge base is instant spaces, and so on that underlie these new knowledge based technologies, semantic web.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Semantic grid semantic web services and so on.",
                    "label": 0
                },
                {
                    "sent": "The other hand, I'm here inside my left hand side about human language and these various arrows are the ways that human language technology can tie these things together.",
                    "label": 0
                },
                {
                    "sent": "So you've got information extraction going from language to formal knowledge.",
                    "label": 0
                },
                {
                    "sent": "You've got generation coming back in the opposite direction.",
                    "label": 0
                },
                {
                    "sent": "You've got some kinds of controlled language information extraction that.",
                    "label": 0
                },
                {
                    "sent": "Slightly reduced kind of human language, which is easier for machines to process.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the kind of big picture of what we're talking about today.",
                    "label": 0
                },
                {
                    "sent": "I just got some background out of the way before we move on to the meat.",
                    "label": 0
                },
                {
                    "sent": "By saying that.",
                    "label": 0
                },
                {
                    "sent": "Like other areas of computer science, language technology typically has, you know, has some typical data structures and infrastructure requirements.",
                    "label": 0
                },
                {
                    "sent": "Just move this a bit.",
                    "label": 0
                },
                {
                    "sent": "Might have been smarter to move the projector moment.",
                    "label": 1
                },
                {
                    "sent": "Practice listening so various.",
                    "label": 0
                },
                {
                    "sent": "There's some kind of typical data structures that language technology used in typical kind of infrastructural systems, so let's just get these out the way that the start before we concentrate on the on the meat of the science.",
                    "label": 0
                },
                {
                    "sent": "One of the most important is annotation.",
                    "label": 0
                },
                {
                    "sent": "Annotation is about associating arbitrary data with areas of text or speech, and there's a kind of de facto standard in the in the community.",
                    "label": 0
                },
                {
                    "sent": "These days didn't always used to be like that, but these days is pretty much a defacto standard.",
                    "label": 0
                },
                {
                    "sent": "She is based around Standoff Markup Standoff Markup is just a way of saying you don't change the language that you're analyzing, you just point to the bits that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So instead of sticking on your XML markup inline into a document that you're analyzing, for example you have in a separate file and you have offsets, character offsets that point into the into the sources, and all all sorts of people doing doing this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Now TR is a text encoding initiative night and important.",
                    "label": 0
                },
                {
                    "sent": "Dialogue annotation tool Atlas Gate will cover these later.",
                    "label": 0
                },
                {
                    "sent": "And there are all sorts of other things that are kind of coordinate technology, but not really very interesting from a scientific point of view visualization and editing, persistence and search metrics component models, so and so forth, to Caroline story, short human language technology has a lot of technological stuff underneath, behind the scenes and in this tutorial will use in many of our examples, will use a system that tries to cope with all those infrastructural needs.",
                    "label": 0
                },
                {
                    "sent": "In one place, so that people developing these kinds of systems don't have to bother about this kind of stuff, and it's called gate general architecture, text engineering.",
                    "label": 0
                },
                {
                    "sent": "Gates three things.",
                    "label": 0
                },
                {
                    "sent": "It said architecture.",
                    "label": 0
                },
                {
                    "sent": "It's A kind of high level organizational picture for the way that language processing systems fit together.",
                    "label": 0
                },
                {
                    "sent": "Then it's a framework and object oriented class library that implements the architecture and then on top of it is built in IDE and integrated development environment.",
                    "label": 0
                },
                {
                    "sent": "For producing these kinds of systems, why are we talking about this?",
                    "label": 0
                },
                {
                    "sent": "Why we're using it for examples where we happen to know a little bit about it developed in Sheffield?",
                    "label": 0
                },
                {
                    "sent": "It's free software.",
                    "label": 0
                },
                {
                    "sent": "It's pretty comprehensive.",
                    "label": 0
                },
                {
                    "sent": "It has growing and fairly extensive support.",
                    "label": 0
                },
                {
                    "sent": "For semantic web stuff, but it means we can kind of ignore these infrastructure issues and just concentrate on the important stuff.",
                    "label": 0
                },
                {
                    "sent": "This is not a claim that gate is the only system that gate is the best system in all cases or anything like that.",
                    "label": 0
                },
                {
                    "sent": "It's just convenience.",
                    "label": 0
                },
                {
                    "sent": "OK. Information extraction.",
                    "label": 0
                },
                {
                    "sent": "Information extraction research has been running for maybe 15 years now.",
                    "label": 0
                },
                {
                    "sent": "The point about it is to pull facts and structured information out of the content of text collections.",
                    "label": 1
                },
                {
                    "sent": "And they said, instructive to get a handle on what this stuff is to compare it with information retrieval information retrieval, you type in some keywords, you get some documents back.",
                    "label": 0
                },
                {
                    "sent": "You search for the information that you need within those documents, information extraction.",
                    "label": 0
                },
                {
                    "sent": "You get the documents you specify an information need some particular set of facts that you're interested in that can be found in these documents, and the system automatically pulls that stuff out of the documents for you.",
                    "label": 0
                },
                {
                    "sent": "That's the difference with retrieval.",
                    "label": 0
                },
                {
                    "sent": "Are a bit of a history.",
                    "label": 0
                },
                {
                    "sent": "This is a hideous caricature.",
                    "label": 0
                },
                {
                    "sent": "Whereas we used to work on natural language understanding.",
                    "label": 0
                },
                {
                    "sent": "We used to work on getting computers to really have a deep knowledge of what was going on in their text.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that it could, you know, so that you could you know the goal was to have that Star Trek computer where you talk to it and say, you know I need breakfast in 20 minutes and say the Klingons are attacking you got breakfast that got that kind of thing.",
                    "label": 0
                },
                {
                    "sent": "OK, people used to work on this sort of stuff, at least some of them in the roundabout.",
                    "label": 0
                },
                {
                    "sent": "The early 90s decided that the performance of these kinds of systems were so low that we want to move the goal posts, right?",
                    "label": 0
                },
                {
                    "sent": "We couldn't score, so we made the gold digger by choosing a much simpler task.",
                    "label": 0
                },
                {
                    "sent": "And that task was information extraction.",
                    "label": 0
                },
                {
                    "sent": "So instead of.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The point of my instruction is to do something to choose a task which is feasible from the point of view of end user applications to do something that you can really get end user applications out of the technology.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The site is about progress in information extraction and what's been driving it.",
                    "label": 0
                },
                {
                    "sent": "This is a quote from a guy called Calvin.",
                    "label": 0
                },
                {
                    "sent": "He gave his name to.",
                    "label": 0
                },
                {
                    "sent": "The various things, including absolute zero, was government degrees Kelvin.",
                    "label": 0
                },
                {
                    "sent": "Temperatures.",
                    "label": 0
                },
                {
                    "sent": "Come inside when you can measure what you were speaking about and express it in numbers you know something about it, but when you cannot measure it when you cannot express it in numbers, your knowledge is of a meager and unsatisfactory kind.",
                    "label": 0
                },
                {
                    "sent": "It may be the beginning of knowledge, but you have scarcely in your thoughts advanced to the stage of science.",
                    "label": 0
                },
                {
                    "sent": "This famous man said, you gotta measure everything right behind Einstein, he said.",
                    "label": 0
                },
                {
                    "sent": "Not everything that counts can be counted and not everything that can be counted counts.",
                    "label": 0
                },
                {
                    "sent": "So trying Times Square those two.",
                    "label": 0
                },
                {
                    "sent": "In any case, in information extraction community, it's been pretty much the case.",
                    "label": 0
                },
                {
                    "sent": "But Calvin's kind of viewpoint.",
                    "label": 0
                },
                {
                    "sent": "This viewpoint that you need to do measurement, you need to have metrics in order to have science quantitative evaluation.",
                    "label": 0
                },
                {
                    "sent": "In other words, that's what's driven.",
                    "label": 0
                },
                {
                    "sent": "The progress of information extraction.",
                    "label": 0
                },
                {
                    "sent": "And I look now in some detail at two of those quantitative evaluation programs that have been responsible for a lot of the progress in the field over the past 15 years or so.",
                    "label": 0
                },
                {
                    "sent": "And the first one is mock your message, understanding conferences, and Secondly AIS automatic content extraction.",
                    "label": 0
                },
                {
                    "sent": "I always thought it stood for advanced content expression.",
                    "label": 0
                },
                {
                    "sent": "They go.",
                    "label": 0
                },
                {
                    "sent": "Mark 7.",
                    "label": 0
                },
                {
                    "sent": "Held in 1997.",
                    "label": 0
                },
                {
                    "sent": "Kind of came up with a sort of Canonical breakdown of the information extraction task in.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Five subtasks what happened in these competitions was that people would get to get together with government sponsors and they define a task.",
                    "label": 0
                },
                {
                    "sent": "They define what the extraction system was going to do, and then they'd mark up a whole load of data, and then they measure the degree that the markup and they produce training data, and then they produce our systems.",
                    "label": 0
                },
                {
                    "sent": "And then everybody would get a separate set of test data for a week.",
                    "label": 0
                },
                {
                    "sent": "When you run your system on it.",
                    "label": 0
                },
                {
                    "sent": "Not do any corrections apart from stopping at crashing and only send the data back and then measure the performance and Mark 7.",
                    "label": 0
                },
                {
                    "sent": "There was broken down at 5 things named entity recognition.",
                    "label": 0
                },
                {
                    "sent": "Coreference resolution template elements.",
                    "label": 0
                },
                {
                    "sent": "Template relations in scenario templates and we should have a nice posh slide from valenton.",
                    "label": 0
                },
                {
                    "sent": "Giving an example of this stuff.",
                    "label": 0
                },
                {
                    "sent": "The shiny red rocket was fired on Tuesday is the brainchild of Doctor Big Head.",
                    "label": 0
                },
                {
                    "sent": "Dr Head is a staff scientist that we build rockets incorporated.",
                    "label": 0
                },
                {
                    "sent": "So I started off by saying that we've moved on from simple toy examples to the real world and now I'm giving you a simple example just to see if you're on your toes.",
                    "label": 0
                },
                {
                    "sent": "What are the various different things that come out from extraction here in the book 7 kind of style?",
                    "label": 0
                },
                {
                    "sent": "Named entity recognition is to find these things appear in the text, so things like Rocket, the Rocket Tuesday Doctor Head we build Rocket will be rockets.",
                    "label": 0
                },
                {
                    "sent": "Secondly, we try and figure out which of those things refer to the same entity in the world and also which kind of enough folic references refer to those things.",
                    "label": 0
                },
                {
                    "sent": "So we're saying here that it in the second sentence refers to rocket in the first sentence, Doctor Big Head and Doctor had the same thing, and so on.",
                    "label": 0
                },
                {
                    "sent": "Having done that, when we know where all the mentions of a particular entity are in the text, we can then pull out some of descriptive information that scatter and scattered around in the text and associated with those entities, and we call those template elements.",
                    "label": 0
                },
                {
                    "sent": "So we can say, for example, that the rocket is shiny red and they stop their heads.",
                    "label": 0
                },
                {
                    "sent": "Brainchild.",
                    "label": 0
                },
                {
                    "sent": "Yeah, why is rapid?",
                    "label": 0
                },
                {
                    "sent": "I'm just not sure.",
                    "label": 0
                },
                {
                    "sent": "No good reason.",
                    "label": 0
                },
                {
                    "sent": "No good reason at all.",
                    "label": 0
                },
                {
                    "sent": "I'll kind of will cover a little bit about what is and what isn't an entity in various different contexts later on.",
                    "label": 0
                },
                {
                    "sent": "But really, it's a pragmatic decision that you make in different ways in different applications, so, but you're right, it's inconsistent.",
                    "label": 0
                },
                {
                    "sent": "These two shouldn't be.",
                    "label": 0
                },
                {
                    "sent": "That one of them is the one who made money.",
                    "label": 0
                },
                {
                    "sent": "Hi somebody, awake at the back.",
                    "label": 0
                },
                {
                    "sent": "Template relations you've got all these entities, while the relations between them Doctor Head Works for we have been rockets.",
                    "label": 0
                },
                {
                    "sent": "Finally scenario template, this kind of event concept.",
                    "label": 0
                },
                {
                    "sent": "Here we were considering in this case in Mark Seven rocket launch events.",
                    "label": 0
                },
                {
                    "sent": "So there was a rocket launching event.",
                    "label": 0
                },
                {
                    "sent": "The various entities of the participants in this sense.",
                    "label": 0
                },
                {
                    "sent": "And there you go.",
                    "label": 0
                },
                {
                    "sent": "There's quite a lot more to say about that stuff, but we're kind of some of it as we go on, but we're also relatively short time so.",
                    "label": 0
                },
                {
                    "sent": "I want to love it.",
                    "label": 0
                },
                {
                    "sent": "Am I doing for time?",
                    "label": 0
                },
                {
                    "sent": "What are good things about information extraction going back to that thing about measurement and counting?",
                    "label": 0
                },
                {
                    "sent": "And so there's been a lot of measurement done.",
                    "label": 0
                },
                {
                    "sent": "A lot of counting, so it's quite often possible for us to say in view of any particular task that's going to use extraction.",
                    "label": 0
                },
                {
                    "sent": "Roughly how the persistence going to perform.",
                    "label": 0
                },
                {
                    "sent": "3rd, the figures that came out from the mug program and other experiments.",
                    "label": 0
                },
                {
                    "sent": "We got up to something like 97% accuracy and the best mobility recognition systems, and that's pretty much as good as human beings can do.",
                    "label": 0
                },
                {
                    "sent": "'cause human beings make lots of mistakes, especially when they're doing boring and repetitive tasks like taking text.",
                    "label": 0
                },
                {
                    "sent": "Current revelation is much more difficult, especially anaphoric resolution.",
                    "label": 0
                },
                {
                    "sent": "We're looking at something like 6070% accuracy.",
                    "label": 0
                },
                {
                    "sent": "I'll define accuracy later on in some detail.",
                    "label": 0
                },
                {
                    "sent": "Um template elements in template relations around the 70 + 80% mark scenario templates there really hard again.",
                    "label": 0
                },
                {
                    "sent": "So then we're thinking about maybe 60.",
                    "label": 0
                },
                {
                    "sent": "This depends on the genre and the domain and the task in summer, but it's pretty low, but you should also note that human performance is pretty low for that kind of task.",
                    "label": 0
                },
                {
                    "sent": "Under the thing about it is the thing about these figures.",
                    "label": 0
                },
                {
                    "sent": "What they tend to suggest is that the more complicated that asks, the more complicated the extraction you're doing really, the bigger the task, the bigger they might have.",
                    "label": 0
                },
                {
                    "sent": "Text has to be, because if you couldn't get a fairly low accuracy, then the only real point in doing it is there's so much text it just wouldn't be possible to do it by hand, or I'm not going to do by hand.",
                    "label": 0
                },
                {
                    "sent": "So whereas you can do the simple stuff.",
                    "label": 0
                },
                {
                    "sent": "To quite a high level of accuracy, once you start getting more complex than that reduces the kind of application space that you that you're looking at.",
                    "label": 0
                },
                {
                    "sent": "Alright, now notice we've given some examples.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Person names, organisations, companies, government organizations and so on.",
                    "label": 1
                },
                {
                    "sent": "Location, cities, countries, rivers, date and time expressions in.",
                    "label": 1
                },
                {
                    "sent": "In other types of applications we've had all sorts of things like measures, email addresses, web addresses, and some domain domain specific applications have looked for things like names of drugs, medical Commission, medical conditions, even bibliographic references.",
                    "label": 0
                },
                {
                    "sent": "Tarnish their names, but I'll probably contradict me.",
                    "label": 0
                },
                {
                    "sent": "Are in various cases like Mark and all these other programs you have these great long lists.",
                    "label": 0
                },
                {
                    "sent": "This URL is great.",
                    "label": 0
                },
                {
                    "sent": "Long definitions of what the things are that you're trying to extract an exclude certain types, for example, in book 7, excluded artifacts, common nouns, names of groups of people, adjectives to rifle names, and some other things.",
                    "label": 0
                },
                {
                    "sent": "The point is not that this is a kind of final, wonderful, perfect definition of what this type of thing is.",
                    "label": 0
                },
                {
                    "sent": "The point is, this is the kind of thing that you can target with an extraction system, and generally in each different application of the technology you'll make different choices about these.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About what falls into your set of extraction targets and what doesn't.",
                    "label": 0
                },
                {
                    "sent": "So what are the basic problems in doing entity recognition?",
                    "label": 0
                },
                {
                    "sent": "We have",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Creation of names so names can be stated in lots of different ways.",
                    "label": 0
                },
                {
                    "sent": "John Smith, Mr Smith.",
                    "label": 0
                },
                {
                    "sent": "John Solomon.",
                    "label": 0
                },
                {
                    "sent": "We have ambiguity of types.",
                    "label": 1
                },
                {
                    "sent": "John Smith is the makers Bear in England also person.",
                    "label": 0
                },
                {
                    "sent": "It's also the company that makes the beer.",
                    "label": 0
                },
                {
                    "sent": "Um May is a person can be a person or a month.",
                    "label": 0
                },
                {
                    "sent": "Washington personal place.",
                    "label": 0
                },
                {
                    "sent": "1945 can be caught too late or the year.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of ambiguity with common words and all sorts of other ambiguities.",
                    "label": 1
                },
                {
                    "sent": "This kind of typical language scenario.",
                    "label": 0
                },
                {
                    "sent": "While language processing is so hard.",
                    "label": 0
                },
                {
                    "sent": "On top of these basic problems you then have issues of style and structure and domain and genre, punctuation and spelling.",
                    "label": 0
                },
                {
                    "sent": "If you've got the address at the bottom of the email, for example, perhaps how do you know that the Department of Computing mass stops here?",
                    "label": 0
                },
                {
                    "sent": "And how do you know?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It doesn't.",
                    "label": 0
                },
                {
                    "sent": "Just go over for leading an ordinary paragraph and a\nDoesn't really mean anything, but if you're in a dress or a table or something like that, there may be a\nOther kind of special impact on the processing.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to go on from looking at the kind of general picture about information extraction.",
                    "label": 0
                },
                {
                    "sent": "So how how these tasks have measured the performance?",
                    "label": 0
                },
                {
                    "sent": "How we've measured the performance in these these tests?",
                    "label": 0
                },
                {
                    "sent": "Copper is just a name for for a collection of taxes, by the way, collection of documents.",
                    "label": 0
                },
                {
                    "sent": "The typical way that you develop a system like this is you sit down and you define what's called the gold standard.",
                    "label": 0
                },
                {
                    "sent": "You define what sort of annotation you would like to come out of your system.",
                    "label": 0
                },
                {
                    "sent": "Then you get some poor oppressed people to manually annotate.",
                    "label": 0
                },
                {
                    "sent": "A lot of texts with this gold standard and you divide this annotated corpus into a training portion of the testing portion.",
                    "label": 0
                },
                {
                    "sent": "You do you have real development?",
                    "label": 0
                },
                {
                    "sent": "Are you learning on that on the training portion and then you test on the on the other bit?",
                    "label": 0
                },
                {
                    "sent": "What you're doing is you're adjusting in certain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the in the case where using Rose, you're playing with real priorities, will effectiveness and so on.",
                    "label": 0
                },
                {
                    "sent": "If you're using a learning algorithm, then yeah, you're playing with the parameters in the features used by typical routine with the learning algorithm is to do a thing called 10 fold cross validation.",
                    "label": 1
                },
                {
                    "sent": "Why you divide up yet?",
                    "label": 0
                },
                {
                    "sent": "You're trading full portion into 10 sections.",
                    "label": 0
                },
                {
                    "sent": "You train on 90, test on 10, then you shift onto another 10 train 90.",
                    "label": 0
                },
                {
                    "sent": "Test on that time and someone go go through.",
                    "label": 0
                },
                {
                    "sent": "Go through this.",
                    "label": 0
                },
                {
                    "sent": "An included the.",
                    "label": 1
                },
                {
                    "sent": "No further tuning should be.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once the evaluation set is used.",
                    "label": 0
                },
                {
                    "sent": "This kind of practice has been going on for a long time.",
                    "label": 0
                },
                {
                    "sent": "There's a whole bunch of outdated corporate in the world that we can experiment with.",
                    "label": 0
                },
                {
                    "sent": "Mark Saxon Box 7 Co. NLL Conference on natural language learning.",
                    "label": 0
                },
                {
                    "sent": "The tides surprised language exercise, which run last year.",
                    "label": 0
                },
                {
                    "sent": "That was a fun program to be in.",
                    "label": 0
                },
                {
                    "sent": "They give you a new language when you had to produce a system within a month, they gave us they started off by giving us a language called Kibwana, which none of us actually heard about her anymore.",
                    "label": 0
                },
                {
                    "sent": "I usually get a prize at this point.",
                    "label": 0
                },
                {
                    "sent": "If anybody knows where Cubano is from Johns disqualified 'cause you got it last time?",
                    "label": 0
                },
                {
                    "sent": "Anyone know where cables from?",
                    "label": 0
                },
                {
                    "sent": "From the Philippines.",
                    "label": 0
                },
                {
                    "sent": "We also had Hindi.",
                    "label": 0
                },
                {
                    "sent": "And people take surprisingly, well, actually.",
                    "label": 0
                },
                {
                    "sent": "I mean, we did.",
                    "label": 0
                },
                {
                    "sent": "We did.",
                    "label": 0
                },
                {
                    "sent": "We did systems for both.",
                    "label": 0
                },
                {
                    "sent": "These language was known with no native speaker involvement.",
                    "label": 0
                },
                {
                    "sent": "Actually we got some native speaker involvement for India.",
                    "label": 0
                },
                {
                    "sent": "Certainly didn't.",
                    "label": 0
                },
                {
                    "sent": "Play along.",
                    "label": 0
                },
                {
                    "sent": "On the ice, which I'm going to talk about a little bit more.",
                    "label": 0
                },
                {
                    "sent": "Is also available, but more details on the book 7 corpus.",
                    "label": 0
                },
                {
                    "sent": "One of the things I haven't mentioned up until now is Inter annotator agreement.",
                    "label": 0
                },
                {
                    "sent": "You need to know how well the human beings are doing the task and you do that by getting people to annotate the same stuff twice.",
                    "label": 0
                },
                {
                    "sent": "You get two people to annotate the same stuff and then you measure their agreement.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this gives you a kind of measure of how well people can understand the task definition and how much they are agreeing about it.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And the muck, at least among identity Corpus, had a very high Inter annotator agreement as 97%.",
                    "label": 0
                },
                {
                    "sent": "There's some figures there about what is contained in these in this corpus.",
                    "label": 0
                },
                {
                    "sent": "You can see one of the interesting things is that you actually haven't got that much data.",
                    "label": 0
                },
                {
                    "sent": "There's only 100 documents that we use for training, and in this particular case, and that's fairly typical, it's really quite expensive to produce this stuff, and that has implications for the kind of approach that you use to do in the extraction, because you've only got this rather limited set of examples, typically.",
                    "label": 0
                },
                {
                    "sent": "We'll talk about it later.",
                    "label": 0
                },
                {
                    "sent": "It was marked up in.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And some funny type of SGML.",
                    "label": 0
                },
                {
                    "sent": "This is not inline markup.",
                    "label": 0
                },
                {
                    "sent": "This is well, this is inline markup, not stand off, but I talked about everyone.",
                    "label": 0
                },
                {
                    "sent": "Let's say you've got an entity name expression here of type location, Cape Canaveral, Cape Canaveral, and so on, so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, that was muck.",
                    "label": 0
                },
                {
                    "sent": "I's more recently automating content extraction.",
                    "label": 0
                },
                {
                    "sent": "Evaluation exercise.",
                    "label": 0
                },
                {
                    "sent": "This moved on in a number of respects from from work, so whereas in muck.",
                    "label": 0
                },
                {
                    "sent": "You are just essentially tagging names in the individual prices where they occur in the text in a.",
                    "label": 0
                },
                {
                    "sent": "In a, each name was viewed as a mention of the underlying entities and the main task was to detect the mentions in the text of the entities themselves.",
                    "label": 0
                },
                {
                    "sent": "So in AC kind of rolled together, the named entity task in the coreference task.",
                    "label": 0
                },
                {
                    "sent": "I know some experimentation with different domains and different genres, and there's also stuff to do with trying trying to do the task on noisy input.",
                    "label": 0
                },
                {
                    "sent": "So we had ASR output.",
                    "label": 0
                },
                {
                    "sent": "Let's ASR stands for automated speech recognition, where you transcribe the voice of somebody who's speaking text OCR, optical character recognition.",
                    "label": 0
                },
                {
                    "sent": "The entities in ice.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With things like proper names, pronouns, nominal mentions, and as I said earlier, that the task was to identify which mentioned in the text, refer to rich entities.",
                    "label": 0
                },
                {
                    "sent": "So you've got a text talking about the British Prime Minister, for example, and you've got a thank figure out that Tony Blair, Mr Blair, he the Prime Minister the Devil or refer to the same kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Are the ACE output format was like this?",
                    "label": 0
                },
                {
                    "sent": "The whole section here is an entity.",
                    "label": 1
                },
                {
                    "sent": "It's got an identifier.",
                    "label": 0
                },
                {
                    "sent": "And then we've got a set of mentions, so these are the different places.",
                    "label": 1
                },
                {
                    "sent": "These are different places in the text where we found some information about something that we think refers to the same thing.",
                    "label": 1
                },
                {
                    "sent": "In this case, the National Air Traffic services.",
                    "label": 0
                },
                {
                    "sent": "Which was sold off by Tony Blair recently.",
                    "label": 0
                },
                {
                    "sent": "So think about that next time you're flying over Britain, and the fact that you fly through privatized airspace.",
                    "label": 0
                },
                {
                    "sent": "I make a profit by doing it for as low cost as possible.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the smaller side.",
                    "label": 0
                },
                {
                    "sent": "Totals for doing this kind of details for the value for annotating corpora here.",
                    "label": 0
                },
                {
                    "sent": "This is great in action.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We look at a system called out and back in a minute.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do I stop it going?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You got a text in the middle here.",
                    "label": 0
                },
                {
                    "sent": "It's not very clear, but you've got a text in the middle on the right hand side you got all the different annotations in the text underneath.",
                    "label": 0
                },
                {
                    "sent": "You've got a kind of database view of the annotation, which tells you where these things came from.",
                    "label": 0
                },
                {
                    "sent": "The pointers I mentioned earlier, standoff market pointing back into the text.",
                    "label": 0
                },
                {
                    "sent": "And there's all sorts of facility for navigating around this kind of information space so you can click on the click on the database view and you see where in the text something happens.",
                    "label": 0
                },
                {
                    "sent": "Click in the text and it will see show you the other views, and so on.",
                    "label": 0
                },
                {
                    "sent": "And you can turn on and off.",
                    "label": 0
                },
                {
                    "sent": "All the different sorts of annotation on the outside to the point is whizzing around and do some and at hand annotate.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another popular total for doing this kind of thing is a thing called lambeck ambiguous from mitre in the US.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing about my arm because it combines the basic facility for doing manual annotation with a kind of bootstrapping approach that learns some of the examples as you go on.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can tell are big here.",
                    "label": 0
                },
                {
                    "sent": "All these examples of names and then you can run it's learning.",
                    "label": 0
                },
                {
                    "sent": "Strategy and then it will make some propositions or propose more names in subsequent documents.",
                    "label": 0
                },
                {
                    "sent": "So how do you know them assist?",
                    "label": 0
                },
                {
                    "sent": "How do they have assistance performing?",
                    "label": 0
                },
                {
                    "sent": "You have an evaluation metric which mathematically defines the performance in relation to that gold standard that you've created with these annotation tools.",
                    "label": 0
                },
                {
                    "sent": "And then you have a scoring program that implements the metrics and provides various measures.",
                    "label": 0
                },
                {
                    "sent": "These run out both over documents, another corpus level for each different type of thing that you're trying to extract.",
                    "label": 0
                },
                {
                    "sent": "The most common evaluation metrics.",
                    "label": 0
                },
                {
                    "sent": "In this field, are things called precision and recall.",
                    "label": 0
                },
                {
                    "sent": "Precision is a measure of how well you've recognized things.",
                    "label": 1
                },
                {
                    "sent": "Recall is a measure of how many of the things out there that you manage to find.",
                    "label": 0
                },
                {
                    "sent": "So the formula is that precision is the correct answers divided by the number of answers that you found.",
                    "label": 0
                },
                {
                    "sent": "The recall is the correct answers divided by the total possible correct answers.",
                    "label": 1
                },
                {
                    "sent": "You can typically set up systems to have a tradeoff between precision and recall.",
                    "label": 0
                },
                {
                    "sent": "You can say OK, I'm only interested in the cases where you're really, really sure that this is correct.",
                    "label": 0
                },
                {
                    "sent": "In other words, you want very high precision system.",
                    "label": 0
                },
                {
                    "sent": "File for the recall down because you won't.",
                    "label": 0
                },
                {
                    "sent": "You won't be able to include the ones that you're not sure of, right, so you won't get very many bug.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, you can say I want all the data that you can possibly find, whether they are right or not.",
                    "label": 0
                },
                {
                    "sent": "Allow this diatribe the precision down because you'll include stuff that you're not really sure about.",
                    "label": 0
                },
                {
                    "sent": "Typically people don't report precision and recall independently they were caught.",
                    "label": 0
                },
                {
                    "sent": "They report a thing called the F measure, which is the weighted harmonic mean of the two of them.",
                    "label": 0
                },
                {
                    "sent": "There are people in the world understand what that means.",
                    "label": 0
                },
                {
                    "sent": "I'm not one.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And and those are the figures I was giving earlier on things like 90% of what have you?",
                    "label": 0
                },
                {
                    "sent": "That will be the F measure, the combined precision and recall on the task.",
                    "label": 0
                },
                {
                    "sent": "It's not always.",
                    "label": 0
                },
                {
                    "sent": "This is very, very prevalent kind of measurement.",
                    "label": 0
                },
                {
                    "sent": "Metric is not always exactly the right thing to do.",
                    "label": 0
                },
                {
                    "sent": "It tends to be sensitive, for example to the amount of data you have, the amount of entities that you have in a particular document.",
                    "label": 0
                },
                {
                    "sent": "So if you're if you're concerned about that, you might use instead something called false positives.",
                    "label": 0
                },
                {
                    "sent": "It's also you want in certain cases too.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to have an idea given different application parameters given different conditions are operating in your application.",
                    "label": 0
                },
                {
                    "sent": "Whether the thing when the performance go up or down or not.",
                    "label": 0
                },
                {
                    "sent": "An ace, for example, user cost based models.",
                    "label": 0
                },
                {
                    "sent": "So you could tweak the parameters and see if the thing would go up and down.",
                    "label": 0
                },
                {
                    "sent": "In different application scenarios.",
                    "label": 0
                },
                {
                    "sent": "The other twist in the story is that sometimes things are partially correct.",
                    "label": 0
                },
                {
                    "sent": "If you've got Blair, if you got string saying Tony Blair and we've only recognized Blair, then that's kind of half right.",
                    "label": 0
                },
                {
                    "sent": "So people quite often modify the formula to take that into account.",
                    "label": 0
                },
                {
                    "sent": "And you really want a tool to generate all these figures for you.",
                    "label": 0
                },
                {
                    "sent": "This is the one that comes in gate.",
                    "label": 0
                },
                {
                    "sent": "This is a document level view of both the differences between the gold standard in the machine and the metrics that those difference the measures that those differences result in the figures that they resulted.",
                    "label": 0
                },
                {
                    "sent": "So essentially it's like one of these visual diff programs.",
                    "label": 0
                },
                {
                    "sent": "If you've ever used some.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like TK death for lots of programming development environments that allow you to look at the difference between your current version of a file on the one that is stored in some repository somewhere.",
                    "label": 0
                },
                {
                    "sent": "So you've got the key document here.",
                    "label": 0
                },
                {
                    "sent": "That's the human annotated one, and the response document, the machine, the machine.",
                    "label": 0
                },
                {
                    "sent": "I rotated one, and what you've got is a list of all the annotations are in these these two documents.",
                    "label": 0
                },
                {
                    "sent": "But it tells you down the bottom here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "While your precision and recall your ass measure further over the screen that you can't see it false positives and so on.",
                    "label": 0
                },
                {
                    "sent": "So typically what you're doing when you're producing extraction system.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just iterating over this kind of this kind of picture of how the performance is improving, hopefully improving.",
                    "label": 0
                },
                {
                    "sent": "You also need to track the system performance overtime so when a change is made we want to know what the implications are over the whole corpus number of a development methods for these types of systems can result in a change in one place.",
                    "label": 0
                },
                {
                    "sent": "Drives down performance in another place, so you need to be able to.",
                    "label": 0
                },
                {
                    "sent": "You need to be able to measure this.",
                    "label": 1
                },
                {
                    "sent": "So you need a tool or do regression testing over the whole corpus.",
                    "label": 0
                },
                {
                    "sent": "Similar kind of thing, but corpus corpus level.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "Evaluation in the context specifically of the semantic Web, strung up a whole set of new challenges.",
                    "label": 0
                },
                {
                    "sent": "Most of which haven't really been solved yet.",
                    "label": 0
                },
                {
                    "sent": "Most of them are currently the subject of research.",
                    "label": 0
                },
                {
                    "sent": "The Semantic Web task takes this ultra.",
                    "label": 0
                },
                {
                    "sent": "This basic extraction problem because you're now trying to detect entities and events and so on in the context of a target ontology of the domain.",
                    "label": 0
                },
                {
                    "sent": "You're trying to disambiguate the entities and events from the document, so your extraction pulls out with respect to the given ontology.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, if you found Cambridge in a text and you correctly figured out that Cambridge is a location, maybe you want to try and actually define it.",
                    "label": 0
                },
                {
                    "sent": "This is Cambridge, UK versus Cambridge, MA.",
                    "label": 1
                },
                {
                    "sent": "And you also need to decide when you've got an instance that isn't actually present in your in your knowledge base yet.",
                    "label": 0
                },
                {
                    "sent": "You know, maybe you haven't seen this thing before and it should be added to the knowledge base.",
                    "label": 1
                },
                {
                    "sent": "It's not a mention of a pre existing entity.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Unless throws up a number of challenges, and in fact we need to adjust the metrics because of these challenges when your evaluating in this kind of hierarchical ontology based kind of picture, we need to take account distance in the hierarchy because we can.",
                    "label": 0
                },
                {
                    "sent": "That we have a we have a different kind of partial correctness problem.",
                    "label": 0
                },
                {
                    "sent": "If you find a company and.",
                    "label": 0
                },
                {
                    "sent": "It was actually a charity or the other way around.",
                    "label": 0
                },
                {
                    "sent": "Then that's probably less right than finding a company and saying it's a weapon of mass destruction or something like this.",
                    "label": 0
                },
                {
                    "sent": "So you need something you need to make your metrics and metrics sensitive to that to the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "OK. About halfway through my bit.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "How do how do people typically do this extraction task?",
                    "label": 0
                },
                {
                    "sent": "That's what we're going to talk about in the next section.",
                    "label": 0
                },
                {
                    "sent": "So approaches to information extraction.",
                    "label": 0
                },
                {
                    "sent": "There are two kinds of approaches to building this course with building this sort of system.",
                    "label": 0
                },
                {
                    "sent": "There's a kind of knowledge engineering approach in this sort of learning approach machine learning approach, so the knowledge engineering approach is a kind of rule based typically rule based.",
                    "label": 0
                },
                {
                    "sent": "It's developed by experienced language engineers, people who know about language processing.",
                    "label": 0
                },
                {
                    "sent": "People have some linguistic program background.",
                    "label": 0
                },
                {
                    "sent": "And it makes use of their human intuition.",
                    "label": 0
                },
                {
                    "sent": "And trying to understand what's going on in the text and how you can process it using various kinds of tools that inquires only a small amount of training data because human beings are very good at generalizing.",
                    "label": 0
                },
                {
                    "sent": "Obviously from the examples that they see.",
                    "label": 0
                },
                {
                    "sent": "Development can be very time consuming and costly, and when you make changes to if the information needs changes and it can also be quite costly to to change the system.",
                    "label": 0
                },
                {
                    "sent": "To the new information need.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, learning systems, the idea here is to get rid of the expertise, get rid of the expert people and replace them with somewhat less expert people who can just markup text.",
                    "label": 0
                },
                {
                    "sent": "Give you lots of examples and then get the machine to learn from it using some kind of statistical model from the developers quite often then don't need so much linguistic knowledge.",
                    "label": 0
                },
                {
                    "sent": "The downside is it requires a large amount of annotated training data.",
                    "label": 0
                },
                {
                    "sent": "If you make changes in the information need, you may have to go back and re annotate all your training data.",
                    "label": 0
                },
                {
                    "sent": "And although people doing the allocation of cheap, you get what you pay for.",
                    "label": 0
                },
                {
                    "sent": "In other words, when you ask somebody to do a boring job, you don't pay them very much money.",
                    "label": 0
                },
                {
                    "sent": "They don't typically do it very well.",
                    "label": 0
                },
                {
                    "sent": "So there's a kind of tradeoff between these two different approaches.",
                    "label": 0
                },
                {
                    "sent": "A lot of the.",
                    "label": 0
                },
                {
                    "sent": "Quite a number of leading systems these days actually trying to combine these two approaches in various various sorts of ways now will go and the rest of this section will go through some examples of how these these approaches tend to workout in practice.",
                    "label": 0
                },
                {
                    "sent": "So the very simplest sort of approach to my identity that you can think about using a baseline is just to have a long list of named entities and store them in things that, for historical reasons, tend to be called gazetteers.",
                    "label": 0
                },
                {
                    "sent": "And this is simple, it's fast.",
                    "label": 0
                },
                {
                    "sent": "It's language independent is that you don't need to have any specific knowledge about particular languages, and it's easy to retarget.",
                    "label": 0
                },
                {
                    "sent": "You just recreate the lists lists.",
                    "label": 0
                },
                {
                    "sent": "But names are very productive things.",
                    "label": 0
                },
                {
                    "sent": "It's impossible to pre enumerate all the names that you're going to encounter in any kind of realistic test collections, so this approach goes a certain distance, but it basically breaks in almost all cases.",
                    "label": 0
                },
                {
                    "sent": "So moving getting a little bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "People use a sort of shallow parsing approach which takes into account some of the internal structure of the neighbors.",
                    "label": 0
                },
                {
                    "sent": "So there are some kinds of typical components of names which give you a clue that they are names and give you a clue what kind of what kind of name they are.",
                    "label": 0
                },
                {
                    "sent": "So you've got for example in locations.",
                    "label": 0
                },
                {
                    "sent": "Town might often be called something City, something forest blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "So if you have a capitalized word followed by one of these trigger expressions and you can figure out that it's a name.",
                    "label": 0
                },
                {
                    "sent": "What this doesn't get you is that it doesn't deal with these various different sorts of ambiguity, so you get.",
                    "label": 0
                },
                {
                    "sent": "Ambiguously capitalized words so that the study switches state police preceded by all.",
                    "label": 0
                },
                {
                    "sent": "It doesn't get you the kind.",
                    "label": 0
                },
                {
                    "sent": "It doesn't help you with the semantic ambiguity that you get between for in this case, for example, between the location and a person John John F Kennedy is at the airport, or the person Philip Morris is a person or organization, and it doesn't deal with the kinds of structural ambiguity that you get in cases like this.",
                    "label": 0
                },
                {
                    "sent": "So cable and wireless, that's one thing.",
                    "label": 0
                },
                {
                    "sent": "Microsoft and Dell are two things.",
                    "label": 0
                },
                {
                    "sent": "How do you tell the difference between those those cases?",
                    "label": 0
                },
                {
                    "sent": "So the next step is to try try and use shallow parsing shallow analysis with some of the context around the names you've done.",
                    "label": 0
                },
                {
                    "sent": "Then you've got the internal structure.",
                    "label": 0
                },
                {
                    "sent": "Now you're looking at the context of the names appearing.",
                    "label": 0
                },
                {
                    "sent": "So here's another example where we can't.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A priority figure out.",
                    "label": 0
                },
                {
                    "sent": "The difference between these two things.",
                    "label": 0
                },
                {
                    "sent": "Let's say that in this case Goldman Sachs.",
                    "label": 0
                },
                {
                    "sent": "We're talking about company in this case.",
                    "label": 0
                },
                {
                    "sent": "David Wilson is a person we can't really figure out just from those things themselves.",
                    "label": 0
                },
                {
                    "sent": "What those types are.",
                    "label": 0
                },
                {
                    "sent": "But if you go.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The phrase David Walton of Goldman Sachs and you know that David Walton, the person, then we can use a pattern that if you have person of organization than the second entity, there is going to be an organization.",
                    "label": 0
                },
                {
                    "sent": "Under hope long lists of these kinds of patterns that you can use.",
                    "label": 0
                },
                {
                    "sent": "A person and money and organization as a headquarters in a location.",
                    "label": 0
                },
                {
                    "sent": "Organization is worth money and so.",
                    "label": 0
                },
                {
                    "sent": "Sarah, look at an example of a roadway system called Annie.",
                    "label": 0
                },
                {
                    "sent": "Honey.",
                    "label": 0
                },
                {
                    "sent": "Stands for nearly new information extraction systems.",
                    "label": 0
                },
                {
                    "sent": "When it was born at Balsam, Strange resemblance to certain other previous ones.",
                    "label": 0
                },
                {
                    "sent": "Let's open source is giving away free gate.",
                    "label": 0
                },
                {
                    "sent": "Does some of the infrastructural stuff underneath dealing with document formats, saving results, evaluation, visualization and editing and so on.",
                    "label": 0
                },
                {
                    "sent": "It's based on a finite State Park national language.",
                    "label": 0
                },
                {
                    "sent": "Annie is based largely on this on this rule language.",
                    "label": 0
                },
                {
                    "sent": "What are things that people want to approach is that people started started doing started using a lot for this kind of shallow extraction task was pattern based with pattern matching based on regular expressions and what they found was that you use a language like Perl and it's good for the first stage.",
                    "label": 0
                },
                {
                    "sent": "You know you've got powerful regular expression capabilities, but then you've got these.",
                    "label": 0
                },
                {
                    "sent": "You have pulled some information out of the text you want to store that information somehow.",
                    "label": 0
                },
                {
                    "sent": "And then feed it into the next level of your pattern analyzer.",
                    "label": 0
                },
                {
                    "sent": "And where do you store that?",
                    "label": 0
                },
                {
                    "sent": "Do stuff it back into the text.",
                    "label": 0
                },
                {
                    "sent": "If so, your patterns get.",
                    "label": 0
                },
                {
                    "sent": "They tend to mushroom and get more and more complicated, so one of the things that was done was to.",
                    "label": 0
                },
                {
                    "sent": "Abstract away from the text itself and due to finite state pattern matching over the over the annotation data and that's what this kind of rule based system is, is often.",
                    "label": 0
                },
                {
                    "sent": "Based on.",
                    "label": 0
                },
                {
                    "sent": "So the various components that this example system has.",
                    "label": 0
                },
                {
                    "sent": "The red and the black boxes.",
                    "label": 0
                },
                {
                    "sent": "The boxes are components and the overall kind of things are the resources.",
                    "label": 0
                },
                {
                    "sent": "The data that they used to do their job.",
                    "label": 0
                },
                {
                    "sent": "So we've got kind of processing and data boxes in this little sausage machine, so you got a document coming in here.",
                    "label": 0
                },
                {
                    "sent": "It's going through all these things.",
                    "label": 0
                },
                {
                    "sent": "Only your extraction is coming out the end in a variety of different formats.",
                    "label": 0
                },
                {
                    "sent": "So we begin just by chopping up the text until it all units into tokens and this system uses the Unicode character classes to figure out what those chunks should be.",
                    "label": 0
                },
                {
                    "sent": "So Unicode defines what is punctuation, what's capitalized word, etc, etc.",
                    "label": 0
                },
                {
                    "sent": "With space for lots of different languages.",
                    "label": 0
                },
                {
                    "sent": "We do the simple baseline thing that we mentioned at the start of gazeteer look up so we have a bunch of lists of things.",
                    "label": 0
                },
                {
                    "sent": "In this case, they're mainly trigger trigger words like incorporated or limited or GmbH or whatever for recognizing companies.",
                    "label": 0
                },
                {
                    "sent": "And we try and identify the sentence boundaries.",
                    "label": 0
                },
                {
                    "sent": "And here we start using that kind of pattern language stuff.",
                    "label": 0
                },
                {
                    "sent": "I talked about a minute ago.",
                    "label": 0
                },
                {
                    "sent": "We don't do part of speech tagging.",
                    "label": 0
                },
                {
                    "sent": "Figure out the syntactic constituents in the text, whether it's a noun or a verb or whatever, and then the main the main chunk of The thing is to do this semantic tagging using the patterns.",
                    "label": 0
                },
                {
                    "sent": "The kinds of patterns that we looked at under the structural.",
                    "label": 0
                },
                {
                    "sent": "Ambiguity slide earlier.",
                    "label": 0
                },
                {
                    "sent": "Couple of other things that happen later on.",
                    "label": 0
                },
                {
                    "sent": "You can solve some of the ambiguity problems by.",
                    "label": 0
                },
                {
                    "sent": "Looking at where else in attacks occur, similar kinds web when names with similar properties occur in the text.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you got IBM in the text and you don't know what sort of name is but somewhere else, you've got international business machines limited when you figured out that that's a company.",
                    "label": 0
                },
                {
                    "sent": "This component then goes through the text and sees that IBM is probably acronym for.",
                    "label": 0
                },
                {
                    "sent": "A Big Blue.",
                    "label": 0
                },
                {
                    "sent": "And fixes that one.",
                    "label": 0
                },
                {
                    "sent": "And finally we do some nominal coreference and again this is a pattern based step.",
                    "label": 0
                },
                {
                    "sent": "South side most of this already.",
                    "label": 0
                },
                {
                    "sent": "The catalyst is storing these location into indicators.",
                    "label": 0
                },
                {
                    "sent": "So that kind of these are this is just a from about the internal structure of the names.",
                    "label": 0
                },
                {
                    "sent": "The little more detail about the about the semantic tagging computer components.",
                    "label": 0
                },
                {
                    "sent": "This is again a fairly standard approach to the problem.",
                    "label": 0
                },
                {
                    "sent": "You've got a set of phases of pattern matching rules that compiled and compiled into state machines, finite state transducers.",
                    "label": 0
                },
                {
                    "sent": "Honey run these in the cascade over the.",
                    "label": 0
                },
                {
                    "sent": "Input text this kind of cascaded transducer approach.",
                    "label": 0
                },
                {
                    "sent": "For some reason, turns out to be a lot easier to write than than most of the other ways of doing this kind of pattern matching stuff.",
                    "label": 0
                },
                {
                    "sent": "We got a bunch of annotations for from the format Alesis of Tokenizer.",
                    "label": 0
                },
                {
                    "sent": "The sentence part of the part of speech, and so on, and then we apply the contextual information and it does.",
                    "label": 0
                },
                {
                    "sent": "The semantic tagging.",
                    "label": 0
                },
                {
                    "sent": "Does the entity recognition.",
                    "label": 0
                },
                {
                    "sent": "Here's a very simple example.",
                    "label": 0
                },
                {
                    "sent": "Um, this kind of light regular expression based approach was become fairly common in the extraction community.",
                    "label": 0
                },
                {
                    "sent": "Jape is a language that implements this over annotations.",
                    "label": 0
                },
                {
                    "sent": "To solve that problem with being able to store information between different phases.",
                    "label": 0
                },
                {
                    "sent": "And you have things like you have rules that on the left hand side of a pattern and on the right hand side have some action to take when you match that pattern and the action is typically to add some more annotation to the pie that you can then either use to output as a result of your extraction, or you can use it in a subsequent matching phase.",
                    "label": 0
                },
                {
                    "sent": "Further, the basic smallest elements are things like things in curly brackets like this basic pattern elements.",
                    "label": 0
                },
                {
                    "sent": "This is saying that you've got a token annotation.",
                    "label": 0
                },
                {
                    "sent": "It's got a feature of typography.",
                    "label": 0
                },
                {
                    "sent": "The value of the feature is upper initial, so it's a word with an uppercase first letter.",
                    "label": 0
                },
                {
                    "sent": "Regular expression operator.",
                    "label": 0
                },
                {
                    "sent": "One or more of these things followed by look up annotation that something out of your list with an attribute kind value company designator.",
                    "label": 0
                },
                {
                    "sent": "So you've got something like in Core GmbH or limited.",
                    "label": 0
                },
                {
                    "sent": "I need find company and on the right side of the rule you create a new annotation with the same span of what you saw on the left hand side and you called it named entity and so it's a company.",
                    "label": 0
                },
                {
                    "sent": "Come from this room so very simple stuff.",
                    "label": 0
                },
                {
                    "sent": "I have seen this one earlier on.",
                    "label": 0
                },
                {
                    "sent": "This is just a view of text with.",
                    "label": 0
                },
                {
                    "sent": "With named entities highlighted like I showed you in the annotation, but.",
                    "label": 0
                },
                {
                    "sent": "OK, when you've done some of this matching and you've got a bunch of ambiguous names, so you figure out their names, but you don't know quite what type they are, then you can use coreference resolution to figure out what those types are.",
                    "label": 0
                },
                {
                    "sent": "Again, I gave you example this earlier on.",
                    "label": 0
                },
                {
                    "sent": "Maybe I will.",
                    "label": 0
                },
                {
                    "sent": "Myself.",
                    "label": 0
                },
                {
                    "sent": "Here's a different view of the nine deadly space.",
                    "label": 0
                },
                {
                    "sent": "This is highlighted all the ones are the same thing, so 18 T is highlighted in the same color.",
                    "label": 0
                },
                {
                    "sent": "Mike Armstrong and Armstrong.",
                    "label": 0
                },
                {
                    "sent": "Here they figured out, and this is the same guy.",
                    "label": 0
                },
                {
                    "sent": "These are.",
                    "label": 0
                },
                {
                    "sent": "These are basically chains in the text.",
                    "label": 0
                },
                {
                    "sent": "When you've coauthored these things, you ended up with chains going through the text and you can turn them off on the right hand side here.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Pretty much done.",
                    "label": 0
                },
                {
                    "sent": "My bit fountain is going to take over and look at learning based approaches to instruction.",
                    "label": 0
                },
                {
                    "sent": "So we currently running on about 5% attention.",
                    "label": 0
                },
                {
                    "sent": "Honey, honey questions.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Semantics is to have entities of different types and their relations, yeah.",
                    "label": 0
                },
                {
                    "sent": "She is mainly focusing on entity identification.",
                    "label": 0
                },
                {
                    "sent": "Well, there's two answers why it will come to that in the second half of the talk talk.",
                    "label": 0
                },
                {
                    "sent": "And the other is that a lot of the work up until now has been relatively simple, so it's been a lot of stuff about entities, but we will deal with this in the second half on semantic tagging and ontology based extraction and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "Coat.",
                    "label": 0
                },
                {
                    "sent": "What are they talking about?",
                    "label": 0
                },
                {
                    "sent": "Using machine learning for information extraction?",
                    "label": 1
                },
                {
                    "sent": "So I want to 1st information extraction system are being developed.",
                    "label": 0
                },
                {
                    "sent": "People first thought of using load engineering, which is what the Hammers talked about.",
                    "label": 0
                },
                {
                    "sent": "So getting the you gather training corpus from the papers and you start building your own system you.",
                    "label": 0
                },
                {
                    "sent": "Engineer it yourself.",
                    "label": 0
                },
                {
                    "sent": "You create rules, work with the priorities and you get the information extraction system.",
                    "label": 0
                },
                {
                    "sent": "Then they thought, well, we're getting this annotated corpus of the data and actually creating the system is pretty much the hard work.",
                    "label": 0
                },
                {
                    "sent": "So why not let the computer the hard work so the idea is to use the annotated corpus to train automatically assistant.",
                    "label": 0
                },
                {
                    "sent": "That will learn how to recognize things that were annotated in the training corpus, and that's the first approach there, which is to train machine learning models.",
                    "label": 0
                },
                {
                    "sent": "On the manually annotated text.",
                    "label": 0
                },
                {
                    "sent": "Then the next step was people realize that actually creating the annotated corpus was pretty much hard work as well, so why not get the computer to help with that one?",
                    "label": 0
                },
                {
                    "sent": "So for instance, in arnocorps we can have same kind of MPs mentioned many many, many times, and once the user out is a few of them, smart machine learning algorithm can actually recognize most of the other ones.",
                    "label": 0
                },
                {
                    "sent": "So why waste the users time which is expensive?",
                    "label": 0
                },
                {
                    "sent": "By asking him to annotate the all dimensions in a document when you can have a computer that.",
                    "label": 0
                },
                {
                    "sent": "So that's one.",
                    "label": 0
                },
                {
                    "sent": "The idea of mixed initiative learning appeared where they're going to use all the information along every kernel information available from the mentation.",
                    "label": 0
                },
                {
                    "sent": "At each Step 2 is the work of the annotator and the first reason for doing this is to help and to speed up the production of training data.",
                    "label": 1
                },
                {
                    "sent": "Then people realize that as the system evolves and as the user aren't, it's more and more animal.",
                    "label": 0
                },
                {
                    "sent": "Data model more text.",
                    "label": 0
                },
                {
                    "sent": "The machine learning algorithm that runs in the background actually can get quite good and can in the end.",
                    "label": 0
                },
                {
                    "sent": "In an ideal case, act as the final product as the actual information extraction system that you're trying to build.",
                    "label": 0
                },
                {
                    "sent": "So that's the second reason for using mixed initiative learning.",
                    "label": 0
                },
                {
                    "sent": "Now there's a variety of machine learning methods that have been used and the first ones that will try their doing symbolic learning, symbolic learning, and that's mostly.",
                    "label": 0
                },
                {
                    "sent": "List of rose.",
                    "label": 0
                },
                {
                    "sent": "That's because the knowledge engineered systems were based on list of rows.",
                    "label": 0
                },
                {
                    "sent": "So humans are getting those rules.",
                    "label": 0
                },
                {
                    "sent": "So the first logical step was OK. Let's get the machines to create those rows.",
                    "label": 0
                },
                {
                    "sent": "The main advantage of that is that we end up with the same style of things like you did in the engineering system.",
                    "label": 0
                },
                {
                    "sent": "You end up with a list of rules which are human readable, so they can be inspected.",
                    "label": 0
                },
                {
                    "sent": "Then they can even be corrected or improved by a good engineer, but the performer brace you can.",
                    "label": 0
                },
                {
                    "sent": "Is there other classical symbolic machine learning methods like decision trees which are required the quite successful?",
                    "label": 0
                },
                {
                    "sent": "Another style of machine learning is statistical models.",
                    "label": 0
                },
                {
                    "sent": "Now this is not as nice because pretty much a black box I mean a model for us at this grandmother is a huge table of probabilities in it.",
                    "label": 0
                },
                {
                    "sent": "No human can possibly understand anything out of that, so they're harder to is.",
                    "label": 0
                },
                {
                    "sent": "They cannot be inspector improved by the humans, but they tend to perform quite well, specially hmm, so hidden Markov models and maximum entropy have been used successfully, so you can't actually not use them just because you can't understand what they're doing is there.",
                    "label": 0
                },
                {
                    "sent": "Weathering is good then why not use them?",
                    "label": 0
                },
                {
                    "sent": "So that's the statistical models.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to talk about machine learning.",
                    "label": 0
                },
                {
                    "sent": "Let's get our terms right.",
                    "label": 0
                },
                {
                    "sent": "First, machine learning is very wide field and the very same issue.",
                    "label": 0
                },
                {
                    "sent": "Learning.",
                    "label": 0
                },
                {
                    "sent": "I mean one of many things in the context of information extraction, we usually talk about classification, which is one of the main problems of machine learning.",
                    "label": 0
                },
                {
                    "sent": "And if we think about classification, have this concepts have instances which are examples of a particular phenomenon that happens, and that the.",
                    "label": 0
                },
                {
                    "sent": "Machine learning algorithm tries to model so it looks at those instances.",
                    "label": 0
                },
                {
                    "sent": "None instance and saying it's an example of a phenomenon that's a very abstract concept.",
                    "label": 0
                },
                {
                    "sent": "Computers don't work very well with abstract concept, so the way we define instances by a set of attributes which have values.",
                    "label": 0
                },
                {
                    "sent": "So we have all the attributes.",
                    "label": 0
                },
                {
                    "sent": "If you have the values for all the attributes of an instance then you know everything there is to know about that instance, at least as far as the machine learning system is concerned.",
                    "label": 0
                },
                {
                    "sent": "And then below what that actually tries to do is to split the.",
                    "label": 0
                },
                {
                    "sent": "We would set of instances in two sets of businesses that are similar from some point of view and those are classes.",
                    "label": 0
                },
                {
                    "sent": "So all this is that share something they belong in the same class and the way it works.",
                    "label": 0
                },
                {
                    "sent": "You normally start with a set of instances which are pre classified given to the algorithm, which learns from that pre classification and then after it's trained you start giving it instances without the class value and it returns to be the class value for each instance that you.",
                    "label": 0
                },
                {
                    "sent": "Providers input.",
                    "label": 0
                },
                {
                    "sent": "Now how you solve this thing?",
                    "label": 0
                },
                {
                    "sent": "For information extraction, the testing information extraction is the story is quite complex and it from different application can be quite different from from others.",
                    "label": 0
                },
                {
                    "sent": "So there have been several things that have been used, one being for instance to find the boundaries of entities.",
                    "label": 0
                },
                {
                    "sent": "So I'm not looking for a person in the text.",
                    "label": 0
                },
                {
                    "sent": "We are looking for the place between 2 words were a person name begins and then you look for the place between towards or.",
                    "label": 0
                },
                {
                    "sent": "Personally.",
                    "label": 0
                },
                {
                    "sent": "Ends and that's sometimes, well, it's.",
                    "label": 0
                },
                {
                    "sent": "It's mostly a technical reason for doing this kind of thing, so I mean, if you're another option, would be to look at each word and decide if it is or not part of an entity.",
                    "label": 0
                },
                {
                    "sent": "So other classified the words or classify the spaces between the words.",
                    "label": 0
                },
                {
                    "sent": "So if classified words, then you you're classifying tokens, otherwise you're fine.",
                    "label": 0
                },
                {
                    "sent": "You're doing boundary detection.",
                    "label": 0
                },
                {
                    "sent": "Now you could train the system to only find entities, not also tell you what the entity types are.",
                    "label": 0
                },
                {
                    "sent": "And then it can be something else.",
                    "label": 0
                },
                {
                    "sent": "Another classifier which will do the the actual classification of the all the entities that are found in two different named entity types.",
                    "label": 0
                },
                {
                    "sent": "And that's also basically why you would want to do this is because it allows you to use different algorithms for different problems, and some algorithms are better than others that particular tasks.",
                    "label": 0
                },
                {
                    "sent": "So everything we want to do the entire to solve entire problem, you spread the problem to solve problems in your address, each of them with the most appropriate algorithm.",
                    "label": 0
                },
                {
                    "sent": "Oh my God, that has been tried this to you several models in the in the same time and do something that's called the president can do call training but it train to models in the same time and the output of one.",
                    "label": 0
                },
                {
                    "sent": "It feels to train the output trained other model and the other way around.",
                    "label": 0
                },
                {
                    "sent": "And you do this several times, that's kind of bootstrapping until they start agreeing with each other and when they go on the two models give the same result.",
                    "label": 0
                },
                {
                    "sent": "Then it means they converge to something.",
                    "label": 0
                },
                {
                    "sent": "So it's like that you've got good results.",
                    "label": 1
                },
                {
                    "sent": "We also agreed about training or.",
                    "label": 0
                },
                {
                    "sent": "Call testing what you could do.",
                    "label": 0
                },
                {
                    "sent": "You use this to models, train them together and only ask the user to notate the examples of the two models disagree, so that's a problem.",
                    "label": 0
                },
                {
                    "sent": "There you go to algorithm cannot figure it out, so that's why you have this.",
                    "label": 0
                },
                {
                    "sent": "Only.",
                    "label": 0
                },
                {
                    "sent": "Only use the humans time when you really can't do it automatically.",
                    "label": 0
                },
                {
                    "sent": "Also, you may want to leave if you don't do court training.",
                    "label": 0
                },
                {
                    "sent": "If you can afford it from a hardware point of, you may want to run several algorithms because there are some that train very quickly, so from a few examples they already start giving you results, but they level up quite quickly as well.",
                    "label": 0
                },
                {
                    "sent": "So as you increase the level, the amount of input data performance doesn't crease that well, so you can use that to start up the process and in the meantime in the background the trainer better algorithm that will reach higher levels of performance in the end, but that requires more training data initially.",
                    "label": 0
                },
                {
                    "sent": "So in order not to let the user completely unaided at the initial phase, user less good algorithm.",
                    "label": 0
                },
                {
                    "sent": "But that has the in the 1st place and then you switch to the better run and there's lots of things that can be tried.",
                    "label": 0
                },
                {
                    "sent": "Now somewhere ideas that have been used if you're doing a boundary detection occur, you're basically looking for things like start and end.",
                    "label": 0
                },
                {
                    "sent": "If you're only looking for entities that that's all you look at, and then if you want, for instance can look straight for start of organization and organization.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this text for instance, this would be marked up with boundary detection, including the actual named entity classification.",
                    "label": 0
                },
                {
                    "sent": "Another idea that has been used as they'll be notation which stands for inside, outside and beginning of.",
                    "label": 0
                },
                {
                    "sent": "Then you have the same text there and you mark the inside an organization outside and inside person inside location.",
                    "label": 0
                },
                {
                    "sent": "You only need to use beginning of when you have 20 years of the same Type, 1 after the other, and use beginning of to mark the place or the first one, and then the second one begins.",
                    "label": 0
                },
                {
                    "sent": "And it's obviously the two models can be converted from one to the other.",
                    "label": 0
                },
                {
                    "sent": "Pretty straightforward, they represent the same data really.",
                    "label": 0
                },
                {
                    "sent": "Well, I said that the.",
                    "label": 0
                },
                {
                    "sent": "An instance is defined by a set of features, and if we're talking about information extraction, that means similar language technology, and these are the kind of features that have been used first.",
                    "label": 0
                },
                {
                    "sent": "First thing you can use this document structure and if you're starting from something like HTML pages, then you can use the original markup, and that's what so-called wrapper induction methods methods do.",
                    "label": 0
                },
                {
                    "sent": "So those are very good for HTML pages that are generated from CGI scripts like from databases.",
                    "label": 0
                },
                {
                    "sent": "List of prices.",
                    "label": 0
                },
                {
                    "sent": "For instance, in on a website you use report induction and they're very successful for those kind of input.",
                    "label": 0
                },
                {
                    "sent": "You can also look at stuff like paragraph and sentence structure.",
                    "label": 0
                },
                {
                    "sent": "For instance, many times the entities tend to be.",
                    "label": 0
                },
                {
                    "sent": "Mentioned towards the beginning of a sentence.",
                    "label": 0
                },
                {
                    "sent": "Of course, the beginning of the paragraph, and that would be 1 feature that will help in the burning the the model.",
                    "label": 0
                },
                {
                    "sent": "The ML model.",
                    "label": 0
                },
                {
                    "sent": "Then you can move into higher level features like token length, capitalization, the stuff that he showed you that it's used in rules created by humans.",
                    "label": 0
                },
                {
                    "sent": "Machine learning methods usually use the same kind of features.",
                    "label": 0
                },
                {
                    "sent": "Talk on type.",
                    "label": 0
                },
                {
                    "sent": "It's a word punctuation symbol for it's quite unlikely to have a symbol instead of person name so.",
                    "label": 0
                },
                {
                    "sent": "That kind of information can be important.",
                    "label": 0
                },
                {
                    "sent": "Then if you've got the MLP machinery behind the camera actually drive linguistic features like part of speech, morphology, syntax, we can do look up some lexicons like word, net or others and as we're moving towards our days you can start using.",
                    "label": 0
                },
                {
                    "sent": "Look up in ontologies.",
                    "label": 0
                },
                {
                    "sent": "For instance, you have an ontology that models domain.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you have some terms linked into the technology and the fact that particular term is linked to a particular class is quite an important indication over.",
                    "label": 0
                },
                {
                    "sent": "What does meant anything else?",
                    "label": 0
                },
                {
                    "sent": "I mean, there are lots of experiments that have been done at all kinds of features, and that is because the selection of features so called feature engineering is the most difficult part in using machine learning for permission extraction and the right set of features can give a success.",
                    "label": 0
                },
                {
                    "sent": "The run set of features will give you complete failure regardless of the fact that you're using the best state of the art algorithm.",
                    "label": 0
                },
                {
                    "sent": "If you don't get the right features, then you'll probably get nothing out of it.",
                    "label": 0
                },
                {
                    "sent": "If you have a large set of features and you want to find out which are the best ones, there are some automatic methods that can be used to score the features.",
                    "label": 0
                },
                {
                    "sent": "Things like information gain or entropy measures that can tell you that this feature is very important for us.",
                    "label": 0
                },
                {
                    "sent": "This other one is actually not doing much becauses for instance depends on the other one.",
                    "label": 0
                },
                {
                    "sent": "If you have the features that depend on each other and one of them is useless normally.",
                    "label": 0
                },
                {
                    "sent": "But more about the next initiative learning.",
                    "label": 0
                },
                {
                    "sent": "So it's crucial idea behind this is to have the human and the computer cooperate in order to achieve the common goal.",
                    "label": 1
                },
                {
                    "sent": "So don't have the human start by annotating text, which is a boring task and it's time consuming, and then give the data to the computer instead of the computer in the human work together to achieve the goal.",
                    "label": 0
                },
                {
                    "sent": "The first reason to do this is to speed up the creation of training data which other allows you.",
                    "label": 0
                },
                {
                    "sent": "Cheaper training corpora were bigger ones for the same amount of money.",
                    "label": 0
                },
                {
                    "sent": "Which is always a good thing.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned before, like you can end up with a working system in the end, so that's a bonus.",
                    "label": 0
                },
                {
                    "sent": "Or sometimes it's actually what you're after now, probably the first implementation of a mixed initiative learning or active learning system is the Olympic Workbench in 97, which was presented by thinking part of the MC 7 conference and probably the most recent one is Mercury in Melita but you furniture event, which was presented last year.",
                    "label": 0
                },
                {
                    "sent": "So how this thing works?",
                    "label": 0
                },
                {
                    "sent": "Usually start with a blank document.",
                    "label": 0
                },
                {
                    "sent": "So Unannotated data the user annotates, and that's where it used to stop the corpus creation procedure is stop there, but now in the background we have machine learning system being trained, which learns from the annotation as far as the user is concerned, nothing exchanges like before he's annotating data, and that's all he does at some point.",
                    "label": 0
                },
                {
                    "sent": "OK, during all this process the system learns and.",
                    "label": 0
                },
                {
                    "sent": "Test itself so tries to re annotate the same document and compares the results.",
                    "label": 0
                },
                {
                    "sent": "So you can have a figure for the level of performance that's being attained by the system when a particular threshold is reached, which means that the suggestions made by the user out by the system are actually useful, and they're more overhead than a hindrance to the annotation process.",
                    "label": 0
                },
                {
                    "sent": "Then the system enters the loop and it actually starts pre annotating the Pine annotated data and when the user first is, the document is not blank as before.",
                    "label": 0
                },
                {
                    "sent": "It already has some data Internet and then, well, these are listed there is only correct that pre annotation which means other remove some of the wrong ones or add some of the mist ones and the system continues to learn in the background from the mistakes it made which were corrected by the human.",
                    "label": 0
                },
                {
                    "sent": "And this is the loop that just continues and you get to your other documents.",
                    "label": 0
                },
                {
                    "sent": "Now if your target is to actually get a fully trained system you set another threshold which means the level of performance unhappy enough that's good enough for my problem.",
                    "label": 0
                },
                {
                    "sent": "So if I reach that I'm happy.",
                    "label": 0
                },
                {
                    "sent": "And you have the user annotate until the system reaches this level of performance, after which you have the system by itself doing all the job and the user goes by the pool somewhere.",
                    "label": 1
                },
                {
                    "sent": "First example is 1 made by Bay at others in the Mitre Corporation.",
                    "label": 0
                },
                {
                    "sent": "They already have a lambic alembic.",
                    "label": 0
                },
                {
                    "sent": "It was not true for manual annotation of of corporate.",
                    "label": 0
                },
                {
                    "sent": "I think it was used in a lot in the creation of corpora for the mood competitions and at some point I decided well this work of creating corpies soon too hard.",
                    "label": 0
                },
                {
                    "sent": "So let's try and help the user with some machine learning.",
                    "label": 0
                },
                {
                    "sent": "They also had a lot of tools because they took part in the competitions.",
                    "label": 0
                },
                {
                    "sent": "They had a lot of NLP tools like part of speech, taggers and all these kind of things that help you induce.",
                    "label": 0
                },
                {
                    "sent": "Feature values so their drink of bootstrapping procedure where the user starts with some documents.",
                    "label": 0
                },
                {
                    "sent": "They take some documents and then the system.",
                    "label": 0
                },
                {
                    "sent": "Piano ties is not very interactive because at that time it was next serving.",
                    "label": 0
                },
                {
                    "sent": "The hardware wasn't that good, so they couldn't afford train to retrain the system very often, so it was based on a document by document basis.",
                    "label": 0
                },
                {
                    "sent": "These are fully annotate one document and then the system will train and there was much interaction between the two.",
                    "label": 0
                },
                {
                    "sent": "Really, but the main point is that the process of manalan tation gets transformed.",
                    "label": 0
                },
                {
                    "sent": "The process of review of existing annotation and sometimes you end up with a working system.",
                    "label": 0
                },
                {
                    "sent": "Because it does the first system this style, it was generating the kind of roles that are being used in their knowledge engineered systems.",
                    "label": 0
                },
                {
                    "sent": "So the user was able to actually look at the roles and edit them if they are skilled enough to do this kind of things and the learning itself is birth style, it generates rules.",
                    "label": 0
                },
                {
                    "sent": "You apply them and measure for each role.",
                    "label": 0
                },
                {
                    "sent": "The kind of results that it generates and you give you only keep the best rose from a pool of roles.",
                    "label": 0
                },
                {
                    "sent": "No, this may sound like an ideal thing, so you have the machine will do you do your work, so everything is fine.",
                    "label": 0
                },
                {
                    "sent": "Well, not truly.",
                    "label": 0
                },
                {
                    "sent": "There are some problems with the mixed initiative idea.",
                    "label": 0
                },
                {
                    "sent": "If the system has very high recall and I'll remind you that means that it finds most of the entities in a document, then the manual annotator may get used to this and may become over reliant on general assistance.",
                    "label": 0
                },
                {
                    "sent": "OK, fine, so I think I'm not going to check the rest of the text because I know it finds everything.",
                    "label": 0
                },
                {
                    "sent": "And what you're trying to create is a gold standard.",
                    "label": 0
                },
                {
                    "sent": "It's really important that data is annotated properly.",
                    "label": 0
                },
                {
                    "sent": "So if you start missing entities in the manual annotated corpus now, all the systems that will be created based on that will not actually find entities there.",
                    "label": 0
                },
                {
                    "sent": "Emulate whatever the learning system did, which is not the task definition.",
                    "label": 0
                },
                {
                    "sent": "Conversely, if you have too much precision, which means most of the interface it finds are correct, then the user will start looking at those.",
                    "label": 0
                },
                {
                    "sent": "So OK, I'm not going to check what it does because I know it works well.",
                    "label": 0
                },
                {
                    "sent": "So again, you may get mistakes in the output, so that's a problem and there isn't really an answer to that so far.",
                    "label": 0
                },
                {
                    "sent": "This is also called the theory creepware loser.",
                    "label": 0
                },
                {
                    "sent": "Once the user becomes over Latin overreliant from the system and they stab not correct in the system, you end up with the corpus that's annotated the way the system wants, not the way the annotation manual says, and that's not not what you're after.",
                    "label": 0
                },
                {
                    "sent": "Another example, probably the most recent one, or at least the most recent I've heard of is the milita system.",
                    "label": 0
                },
                {
                    "sent": "That's the mixed initiative system, which is based on the Amilcar a learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "America is also symbolic.",
                    "label": 0
                },
                {
                    "sent": "Learning algorithm is a rule learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "It started from the idea of the wrapper induction and then it got changed a bit.",
                    "label": 0
                },
                {
                    "sent": "It has a tagging rules which insert back into the text, then it have correction rules which can move the inserted packs around or can delete some of them.",
                    "label": 0
                },
                {
                    "sent": "One interesting thing about it is that it learns begin and end tags independently, so as far as it's concerned there is no relation between start organization and organization.",
                    "label": 0
                },
                {
                    "sent": "Now I'm not saying that necessarily a good thing is just it's original.",
                    "label": 0
                },
                {
                    "sent": "It's something different from other systems so that some alcohol there's the learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then there's a system called Melitta which is based on amilkar and which does adaptive, adaptive information extraction is a different name for machine learning for information extraction.",
                    "label": 0
                },
                {
                    "sent": "Amber OK Manitowoc picture does it the active learning because the user in the system cooperate to annotate the text.",
                    "label": 0
                },
                {
                    "sent": "Recently it's being extended because they got more funding, so it's being expanded as part of the semantic web effort, and we're excited to see what they do with those money.",
                    "label": 0
                },
                {
                    "sent": "All the basic idea behind Alembic Workbench and Melita is really the same, and they're both rule induction systems, so they are quite similar.",
                    "label": 0
                },
                {
                    "sent": "The main difference between them is that Alembic is oriented towards language engineers, so people who would be able to look at the rules and change them and who understand very well what the problem is and what they're actually trying to achieve, whereas Melitta is.",
                    "label": 0
                },
                {
                    "sent": "Oriented towards end users.",
                    "label": 0
                },
                {
                    "sent": "So as they say, naive users, so people who aren't necessarily very experienced in this kind of problems because of that, lambeck exposes more of the internals of the system, whereas America is just a nice interface you don't really know what's happening underneath and just get some sliders, move them around and use it.",
                    "label": 0
                },
                {
                    "sent": "Now, because of it was developed last year, military is able to talk about families and intrusiveness, so there are some options we can tell the system how often to intervene and so that you get the most satisfying experience for the user so they don't get bothered too often with the wrong intervention from the system and.",
                    "label": 0
                },
                {
                    "sent": "This kind of gradually take into account Olympic does not do that, but that's probably because at that time you couldn't really afford to decide when to run the algorithm.",
                    "label": 0
                },
                {
                    "sent": "You run it when you have the time, because the hardware wasn't that powerful, both of them acknowledged the problem of theory Crippen, the over reliance, but they don't have a solution for it.",
                    "label": 0
                },
                {
                    "sent": "The machine learning behind the both of them is pretty much the same.",
                    "label": 0
                },
                {
                    "sent": "It's very similar.",
                    "label": 0
                },
                {
                    "sent": "Right, so as crucial saying will be given a lot of examples from gate as Alembic, Gate is a system that allows manual annotation, has a lot of NLP machinery behind it, so it's a good place to start implementing machine learning as well.",
                    "label": 0
                },
                {
                    "sent": "Also, defining machine learning's classification, you have a set of attributes and then you have to infer the class from them.",
                    "label": 0
                },
                {
                    "sent": "The objects that are instances in this case are the annotations over the text.",
                    "label": 0
                },
                {
                    "sent": "Another simple interesting promises document classification which we're not addressing directly, but it can be addressed if you have annotation type that it's a one translation of documents.",
                    "label": 0
                },
                {
                    "sent": "Each document has only one of that annotation type, and then you're classifying those annotations.",
                    "label": 0
                },
                {
                    "sent": "You're actually classifying the document, so you can do document classification, although it's not really obvious from the first step how you would do that.",
                    "label": 0
                },
                {
                    "sent": "Oh operations considered as expenses have to be the same type, so you define a particular type of my instances and then you work with them.",
                    "label": 0
                },
                {
                    "sent": "The features are extracted from the instance annotation or from the context because as you saw in Hamish is part when you try to find entities.",
                    "label": 0
                },
                {
                    "sent": "You have to look inside the text, but many times the context gives you useful clues as well.",
                    "label": 0
                },
                {
                    "sent": "So you need to be able to get to the information from the context.",
                    "label": 0
                },
                {
                    "sent": "There is a generic implementation which.",
                    "label": 0
                },
                {
                    "sent": "Processes gave documents to collect the attributes and then that can be linked to any machine learning engine which is external.",
                    "label": 0
                },
                {
                    "sent": "We figure that, well, we're not specialist in machine learning, so it makes more sense for us to implement yet another machine learning algorithm will be using some of the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Once we just make them work with textual data, the kind of data that we're using in human language technology.",
                    "label": 0
                },
                {
                    "sent": "Currently we have integrated wake up, which is a very good library with lots of implementation for the classic.",
                    "label": 0
                },
                {
                    "sent": "Algorithms and we have an HMM implementation from auto text and we're working in including maximum entropy and support vector machines, which are algorithms that work well with text.",
                    "label": 0
                },
                {
                    "sent": "So you have a personal resource in gate which does the machine learning capabilities, does both training and application of the models.",
                    "label": 0
                },
                {
                    "sent": "The configuration is in an XML file you have a data set definition which tell us what the instances are in what, how to collect the values for attributes or features.",
                    "label": 0
                },
                {
                    "sent": "Then you have another element which defines which engine to use, which external engine to use.",
                    "label": 0
                },
                {
                    "sent": "Now, if you think of this as annotation, so we have the text somewhere in this annotations covering various parts of the text, and you decide the tokens are instances.",
                    "label": 0
                },
                {
                    "sent": "So here we have a sequence of tokens, and this is the current instance.",
                    "label": 0
                },
                {
                    "sent": "The values for attributes are collected either from the annotation type and those are Boolean attribute telling for instance that over the current instance there is a look up annotation.",
                    "label": 0
                },
                {
                    "sent": "That's what that means.",
                    "label": 0
                },
                {
                    "sent": "Or we can collect values from the value of the features.",
                    "label": 0
                },
                {
                    "sent": "And in order to get to the context, you have this positional value here.",
                    "label": 1
                },
                {
                    "sent": "So for example have minus one.",
                    "label": 0
                },
                {
                    "sent": "The value for this instance will be taken from the annotations overlapping the previous one.",
                    "label": 0
                },
                {
                    "sent": "That's how you get to the context.",
                    "label": 0
                },
                {
                    "sent": "Or you can have context towards the right side as well.",
                    "label": 0
                },
                {
                    "sent": "How the way it works?",
                    "label": 0
                },
                {
                    "sent": "The main later flow is started, documents you use all the MLP machinery you have at your disposal to enrich the documents as much data as possible in order to create features.",
                    "label": 0
                },
                {
                    "sent": "Then the feature collection implementation creates the kind of structures that are usually used by machine learning algorithms, which makes them easy to use interface towards the machine learning engine itself.",
                    "label": 0
                },
                {
                    "sent": "So once you want to integrate and machine learning you just need to.",
                    "label": 0
                },
                {
                    "sent": "Rewrite this interface.",
                    "label": 0
                },
                {
                    "sent": "Everything is already implemented.",
                    "label": 0
                },
                {
                    "sent": "Round ocean.",
                    "label": 0
                },
                {
                    "sent": "Learn and get the results and then this is also part of the core gate and you get generated documents.",
                    "label": 0
                },
                {
                    "sent": "So that was the idea was pluggability.",
                    "label": 0
                },
                {
                    "sent": "In order to allow to play with as many machine learning engines as possible.",
                    "label": 0
                },
                {
                    "sent": "And I think that's my part.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Should we break now?",
                    "label": 0
                },
                {
                    "sent": "It early, but rather than start something else.",
                    "label": 0
                },
                {
                    "sent": "OK. My colleague anime North is going to talk about I want aladji based information extraction which are systems which explicitly use ontologies to perform the information extraction task, and then I'll give you some examples from large scale processing systems in the area as well.",
                    "label": 0
                },
                {
                    "sent": "So just a brief reminder from what he's saying earlier on.",
                    "label": 0
                },
                {
                    "sent": "If you think about the book named Entity Recognition Task, the tags in text were just parts of the segment, a part of the text, and these parts of the text were referring to a particular entity, like a location or an organization.",
                    "label": 0
                },
                {
                    "sent": "But there is no specific effort to relay.",
                    "label": 0
                },
                {
                    "sent": "Those two are two owned Aladji.",
                    "label": 0
                },
                {
                    "sent": "So for example have a representation of the domain.",
                    "label": 0
                },
                {
                    "sent": "In question like we have organizations that are sub classified in companies and nongovernmental organizations, and for example universities, etc, etc.",
                    "label": 0
                },
                {
                    "sent": "So there is no ontology of the domain in mark, you just sort of identifying strings in the text and saying, OK, here is a location.",
                    "label": 0
                },
                {
                    "sent": "Here is another organization, but there's no kind of relationship between those.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, walked we want to do when we haven't until GS to perform semantic tagging, and in this case the idea is to identify mentions in the text and say OK here.",
                    "label": 0
                },
                {
                    "sent": "This piece of text Tony Blair for example, is talking about a particular instance Indian teologi, and that instance has an identifier 123 or whatever.",
                    "label": 0
                },
                {
                    "sent": "And here are all the mentions in that text of this particular instance.",
                    "label": 0
                },
                {
                    "sent": "So these all all these things are referring to one in same instance in our ontology.",
                    "label": 0
                },
                {
                    "sent": "And then we have another instance, another person, and these are all the mentions in the text from regarding that instance in deontology.",
                    "label": 0
                },
                {
                    "sent": "So if we think about all the tasks could be there 3 three aspects of these.",
                    "label": 0
                },
                {
                    "sent": "So first of all we need to again look at the text and find all the mentions of particular entities, pretty much like you so up till now for traditional information extraction, then we need to disintegrate those references with respect to the ontology.",
                    "label": 0
                },
                {
                    "sent": "So we need to decide.",
                    "label": 0
                },
                {
                    "sent": "OK here this instance this.",
                    "label": 0
                },
                {
                    "sent": "Piece of string Tony Blair or the Prime Minister is refering to instance 123 in the ontology and it's a type instance of concept person and sometimes maybe we just don't have that instance in our ontology at all.",
                    "label": 0
                },
                {
                    "sent": "Maybe just something new that just come up in the text.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you are analyzing use texts, that could be a completely new company that's just being formed and this is the first text that you've come across about that company.",
                    "label": 0
                },
                {
                    "sent": "So for example, when Halifax Bank joined with the Royal Bank of Scotland in.",
                    "label": 0
                },
                {
                    "sent": "In England some time ago there were all these new texts mentioning this new company called H Boss and up to now in your ontology you wouldn't have an instance about age boss, so you have to identify that.",
                    "label": 0
                },
                {
                    "sent": "OK, we have a new instance.",
                    "label": 0
                },
                {
                    "sent": "It's above class company and we need to add it to entology because this is a brand new instance that we've not seen before.",
                    "label": 0
                },
                {
                    "sent": "And then the third aspect of the task is the third type of task is to identify in the text attributes and relations with regards to these instances.",
                    "label": 0
                },
                {
                    "sent": "So where they mentioned and we can do that, for example, using information from the ontology about what kind of domains and ranges can have properties can have certain properties.",
                    "label": 0
                },
                {
                    "sent": "So here I want to give you an example of that.",
                    "label": 0
                },
                {
                    "sent": "It's from Kim System, which we'll talk about later on.",
                    "label": 0
                },
                {
                    "sent": "But the example is just trying to show the different aspects of these tasks, so we start off with that text on top and the different highlighted parts are the entities.",
                    "label": 0
                },
                {
                    "sent": "So XY, Zed's 3rd of November, Bulgaria, London, etc.",
                    "label": 0
                },
                {
                    "sent": "These are the entities, and here is our ontology and.",
                    "label": 0
                },
                {
                    "sent": "So it has different instances like Bulgaria, UK, London etc.",
                    "label": 0
                },
                {
                    "sent": "So we first identify them in a text.",
                    "label": 0
                },
                {
                    "sent": "Then we identified the correct distances in our ontology which they are and once we have done that, the last step is to identify also the relations between them.",
                    "label": 0
                },
                {
                    "sent": "So we have the company that is established on that date and it has certain headquarters.",
                    "label": 0
                },
                {
                    "sent": "So these are this is kind of an example of these tasks that need to be carried out.",
                    "label": 0
                },
                {
                    "sent": "In another, if you look at that from the ontology perspective just to make it slightly more clear what's happening is if we have that piece of text.",
                    "label": 0
                },
                {
                    "sent": "Gordon Brown make my George Bush during his two day visit.",
                    "label": 0
                },
                {
                    "sent": "Here is entology.",
                    "label": 0
                },
                {
                    "sent": "On the left.",
                    "label": 0
                },
                {
                    "sent": "We have this simple ontology of entities and persons and we have an instance for George Bush.",
                    "label": 0
                },
                {
                    "sent": "So we identify the entities and then we identify that we need to add a new instance for Gordon Brown because he's not being in the ontology before.",
                    "label": 0
                },
                {
                    "sent": "And then we call referred to things and then finally what we have in the text is this kind of metadata which says this is where differences from traditional information extraction.",
                    "label": 0
                },
                {
                    "sent": "It gives you directly references to the class of the ontology and the instance identifier in that ontology, so we're not anymore just saying OK in this text, we have Gordon Brown, and that's a person in George Bush.",
                    "label": 0
                },
                {
                    "sent": "And that's a person.",
                    "label": 0
                },
                {
                    "sent": "But what we're doing?",
                    "label": 0
                },
                {
                    "sent": "I mean, they're no longer tags.",
                    "label": 0
                },
                {
                    "sent": "Like you so before you know it just had to talk person what we have in here is in the ontology based information extraction or semantic tagging.",
                    "label": 0
                },
                {
                    "sent": "What you're trying to do is to assign automatically these information of classes given the ontology and instances to these occurrences in the text.",
                    "label": 0
                },
                {
                    "sent": "So you have in dramatic dated descriptions about text you have which parts of the text are concerned there.",
                    "label": 0
                },
                {
                    "sent": "So from from where this is starting, this is the end.",
                    "label": 0
                },
                {
                    "sent": "And what is the string?",
                    "label": 0
                },
                {
                    "sent": "So we have Gordon round there and we have world class and instance it belongs to.",
                    "label": 0
                },
                {
                    "sent": "And this is the game for the next one.",
                    "label": 0
                },
                {
                    "sent": "So these are the.",
                    "label": 0
                },
                {
                    "sent": "This is the difference is quite a different task in comparison to before.",
                    "label": 0
                },
                {
                    "sent": "So what happens if you have some more text cloud entology changes?",
                    "label": 0
                },
                {
                    "sent": "Again the same thing but we have to add another instance for Tony Blair because it's not been there before and again we have the same kind of metadata.",
                    "label": 0
                },
                {
                    "sent": "Here we have the same.",
                    "label": 0
                },
                {
                    "sent": "Instance and class is before, but it's just a different mention because it's part of a different document and we have another mention of this new entity that we have there with businesses that we have just created and it's a gain of a class person according to our ontology.",
                    "label": 0
                },
                {
                    "sent": "So if we look at the problem of metadata creation with information extraction.",
                    "label": 0
                },
                {
                    "sent": "What we can say is there are two ways in which we can do it.",
                    "label": 0
                },
                {
                    "sent": "One is too.",
                    "label": 0
                },
                {
                    "sent": "If you remember in previous life I had the meta data here on the right and it was referring back to the original text in a standard fashion.",
                    "label": 0
                },
                {
                    "sent": "Or you can insert all this information with the UI's for the instances in classes back into the document.",
                    "label": 0
                },
                {
                    "sent": "Like is inline XML or whatever.",
                    "label": 0
                },
                {
                    "sent": "So these are the two ways of doing putting the metadata.",
                    "label": 0
                },
                {
                    "sent": "Into the text or separately and then also two other ways in which you can do at the metadata creation when you're using information extraction.",
                    "label": 0
                },
                {
                    "sent": "When is semi automatic, so you have the information extraction system carry out the task.",
                    "label": 0
                },
                {
                    "sent": "So identify concepts in instances as good as it can, and then you have a user which who is post editing that and creating the markup.",
                    "label": 0
                },
                {
                    "sent": "Finally, validated human human validated markup and.",
                    "label": 0
                },
                {
                    "sent": "This is good because you know it gives you very correct markup, but the downside of it is that we have only one view, which is to say that the user is using one particular ontology and they're creating metadata with respect to that particular ontology.",
                    "label": 0
                },
                {
                    "sent": "And once we have that metadata it's already created.",
                    "label": 0
                },
                {
                    "sent": "It said it's not very easy to change it if there are some changes in geology because we need to ask the user to look at this again.",
                    "label": 0
                },
                {
                    "sent": "So in some sense you can think of it as.",
                    "label": 0
                },
                {
                    "sent": "Human authored HTML where once you have the links in, that's it, you can't change them.",
                    "label": 0
                },
                {
                    "sent": "And then we have the automatic metadata creation aspect where we have many different information extraction systems that can each run.",
                    "label": 0
                },
                {
                    "sent": "We using different ontologies on the same text.",
                    "label": 0
                },
                {
                    "sent": "They can create you separate different metadata sets for depending on which ontologies used.",
                    "label": 0
                },
                {
                    "sent": "So if the ontology in some cases if one ontology has only persons, then Tony Blair, George Bush etc will be all persons.",
                    "label": 0
                },
                {
                    "sent": "But if we have a more complex ontology in a different application that distinguishes between politicians and.",
                    "label": 0
                },
                {
                    "sent": "I don't know researchers and other types of persons.",
                    "label": 0
                },
                {
                    "sent": "Then you will have, according to that new entology, you will have a different information extraction application that will automatically classify politicians on their politicians and actors and directors etc.",
                    "label": 0
                },
                {
                    "sent": "So you have different types of metadata according to the ontology.",
                    "label": 0
                },
                {
                    "sent": "So this is the advantage of using different information extraction systems automatically on the same pages.",
                    "label": 0
                },
                {
                    "sent": "The other advantage is that if the ontology is changed, then the meta data can be changed automatically because you just rerun it.",
                    "label": 0
                },
                {
                    "sent": "There's no human who needs to go and validate each of the decisions, but the problem is that it's less reliable, so it makes mistakes.",
                    "label": 0
                },
                {
                    "sent": "And in this tutorial will show both aspects and different systems.",
                    "label": 0
                },
                {
                    "sent": "Now the first thing that people tried was OK.",
                    "label": 0
                },
                {
                    "sent": "They'll take a traditional information extraction system in this type in the same style is like say, system created to identify Monk named entities or something like that and supply to the semantic web to create some metadata and that work has been done as part of this cream which stands for semi automatic creation of metadata and it's a joint work between.",
                    "label": 0
                },
                {
                    "sent": "Where and people in Sheffield and there are main problem there is that there are semantic tags from information extraction.",
                    "label": 0
                },
                {
                    "sent": "In this case it was all about hotels and rooms and prices and things like that.",
                    "label": 0
                },
                {
                    "sent": "So I'll show you what kind of tags the information extraction system was trained to produce and also show you what was the target output of that system in terms of concepts and instances and attributes.",
                    "label": 0
                },
                {
                    "sent": "So you see that there is quite a quite a big gap.",
                    "label": 0
                },
                {
                    "sent": "Between those and the other problem with applying the the traditional information extraction approaches was that the majority of machine learning systems for information extraction, they don't deal very well with relations.",
                    "label": 0
                },
                {
                    "sent": "Going back to a question that we had very earlier on.",
                    "label": 0
                },
                {
                    "sent": "They've been mainly trained to identify entities or roles of entities in a text.",
                    "label": 0
                },
                {
                    "sent": "So for example, to identify speakers, seminars, or to identify.",
                    "label": 0
                },
                {
                    "sent": "Certain job descriptions or things like that, but nevertheless, although they're not named entities as much, defines them, so they're not necessarily people and locations and organizations.",
                    "label": 0
                },
                {
                    "sent": "There are still kind of entities.",
                    "label": 0
                },
                {
                    "sent": "Their concept in ontology.",
                    "label": 0
                },
                {
                    "sent": "So if you're trying to identify automatically attributes or relations, so what's the with what had two concepts are connected?",
                    "label": 0
                },
                {
                    "sent": "Or two instances are connected in the text?",
                    "label": 0
                },
                {
                    "sent": "This is quite difficult.",
                    "label": 0
                },
                {
                    "sent": "It's still an open issue.",
                    "label": 0
                },
                {
                    "sent": "And the other problem that was found was a particular system that they used amilkar, which we introduced earlier on.",
                    "label": 0
                },
                {
                    "sent": "It doesn't handle anaphora resolution.",
                    "label": 0
                },
                {
                    "sent": "ORCA reference according to the class definitions earlier on so engaged we have such a component, but it wasn't used as part of the email correct system and they did have a struggle quite a lot with the lack of anaphora resolution, and this is because if you don't know all the mentions in the text which refer to the same entity, it's really hard to identify.",
                    "label": 0
                },
                {
                    "sent": "The relations between the different instances in the text because you have to know, is this the same room that has been talked about earlier, or is this the same hotel?",
                    "label": 0
                },
                {
                    "sent": "So to get around this, what they did was they implemented a discourse model which is based on logical rules, and that discourse model was fixing up the results from the information extraction system and deciding it knew about the ontology.",
                    "label": 0
                },
                {
                    "sent": "So it's only at that point in the discourse model where it was taking the output of the information extraction system and saying OK, according to my ontology, this is probably an instance of my hotel concept.",
                    "label": 0
                },
                {
                    "sent": "And this is probably an instance of a room, and this is its price.",
                    "label": 0
                },
                {
                    "sent": "And show examples about how this was done, but the main point is that there is a problem with using this kind of approach for information to obtain metadata with respect to ontology.",
                    "label": 0
                },
                {
                    "sent": "The problem is that this kind of discourse models they are very specific to a domain and you risztics that you see are later on in a minute very specific to the particular domain as well.",
                    "label": 0
                },
                {
                    "sent": "So they're not very robust.",
                    "label": 0
                },
                {
                    "sent": "And if you want to port them to a new domain.",
                    "label": 0
                },
                {
                    "sent": "Well, we have to start from scratch basically, so it's not.",
                    "label": 0
                },
                {
                    "sent": "It's a bit difficult to reuse them and write a generic system for that.",
                    "label": 0
                },
                {
                    "sent": "So here is the example on the left hand side are the.",
                    "label": 0
                },
                {
                    "sent": "Is the output that was created by manual annotators with respect to the ontology that I mentioned of hotels, cities, rooms, etc.",
                    "label": 0
                },
                {
                    "sent": "So you can see that the manual annotators or created quite a lot of information like a particular instance filing then was a hotel and is located at a particular place dobbertin and it's an instance of a city, etc etc.",
                    "label": 0
                },
                {
                    "sent": "Whereas the information extraction system will be produces art is kind of.",
                    "label": 0
                },
                {
                    "sent": "Entities.",
                    "label": 0
                },
                {
                    "sent": "And they are mainly, you know.",
                    "label": 0
                },
                {
                    "sent": "It says OK, we have a hotel.",
                    "label": 0
                },
                {
                    "sent": "We have a city.",
                    "label": 0
                },
                {
                    "sent": "We have a single room and we have a price, currency etc.",
                    "label": 0
                },
                {
                    "sent": "But what is missing here?",
                    "label": 0
                },
                {
                    "sent": "Is all this information that this here is an instance of a particular concept and that there is a located that relation between the two and that you know we have room which has a price etc.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the information was missing there and this is a problem when you just take an information extraction system that doesn't know about the ontology.",
                    "label": 0
                },
                {
                    "sent": "And you try to use its output to create the kind of meta data that you had there on the left.",
                    "label": 0
                },
                {
                    "sent": "So coming back to the discourse rules.",
                    "label": 0
                },
                {
                    "sent": "They had several basic types of rules.",
                    "label": 0
                },
                {
                    "sent": "The first type was that you allowed to attach instances to entology only when the when you have the correct class.",
                    "label": 0
                },
                {
                    "sent": "So for example, you cannot attach prices to cities because the ontology says that only only rooms have prices.",
                    "label": 0
                },
                {
                    "sent": "So if the ontology says only rooms have prices and you have a price and you're trying to attach it to something, you automatically have to disqualify all all the concepts that don't match.",
                    "label": 0
                },
                {
                    "sent": "According to the ontology.",
                    "label": 0
                },
                {
                    "sent": "Then the next step is OK. We have this qualified.",
                    "label": 0
                },
                {
                    "sent": "Some of the things from the some of the instances in the text because they don't match.",
                    "label": 0
                },
                {
                    "sent": "What do Entology tells us, but still we have left with several.",
                    "label": 0
                },
                {
                    "sent": "So which one are we going to choose?",
                    "label": 0
                },
                {
                    "sent": "And according to various models of this course?",
                    "label": 0
                },
                {
                    "sent": "Times it makes most sense to choose the nearest preceding compatible entity, so you're treating the discourse like a stack and you're thinking OK from this from the beginning of the text, we've talked about a hotel, then about a city, and then we've just spoken about a room, and now we found a price, and the question is, where do I put that price?",
                    "label": 0
                },
                {
                    "sent": "First of all, OK, I checked my the entity on top of my stack is a is a room.",
                    "label": 0
                },
                {
                    "sent": "Can it have a price?",
                    "label": 0
                },
                {
                    "sent": "Yes it can OK, and then we think OK. Because this is the nearest preceding entity, most probably that price is about this entity, because this is how typically tell text work.",
                    "label": 0
                },
                {
                    "sent": "So this is another heuristic.",
                    "label": 0
                },
                {
                    "sent": "We attach it the price to the lightest room mentioned in the text.",
                    "label": 0
                },
                {
                    "sent": "And there are also these kind of complex objects which which defy which combines several types of.",
                    "label": 0
                },
                {
                    "sent": "Of outputs of the information extraction system.",
                    "label": 0
                },
                {
                    "sent": "So, for example, the information extraction system can recognize currencies and numbers, and in the anthology we have this complex concept which is a rate and is defined.",
                    "label": 0
                },
                {
                    "sent": "So there are some discourse rules which say that OK if we have a number followed by currency then we have this rate.",
                    "label": 0
                },
                {
                    "sent": "So again, it's a bit like these.",
                    "label": 0
                },
                {
                    "sent": "These rules that you saw earlier on about how you recognize entities.",
                    "label": 0
                },
                {
                    "sent": "This is not that different.",
                    "label": 0
                },
                {
                    "sent": "In that respect, and finally you can have experienced users.",
                    "label": 0
                },
                {
                    "sent": "Users write such kind of discourse rules, but generally it's quite difficult.",
                    "label": 0
                },
                {
                    "sent": "So I mean basically, this is the pros and the cons are of this approach are that it works quite well if you have a limited domain you can have these rules and you can get it off the ground quite quickly so you can use a traditional information extraction system that knows nothing about the ontology.",
                    "label": 0
                },
                {
                    "sent": "But the downside of that is that you have a very specific system which is hard to Portland, ME.",
                    "label": 0
                },
                {
                    "sent": "So if we think about what the challenges are for information extraction for the semantic web, we have these problems.",
                    "label": 0
                },
                {
                    "sent": "We need to address portability because there are different ontologies even for the same domain according to different applications, they change overtime.",
                    "label": 0
                },
                {
                    "sent": "There are different text types structured free texts, any structures, etc.",
                    "label": 0
                },
                {
                    "sent": "We really need to be able to use the ontology information as much as possible and directly have outputs.",
                    "label": 0
                },
                {
                    "sent": "From the information extraction system with respect to concepts and relations in the ontology not having to post process them like they did in scream and they need to train from small amounts of data.",
                    "label": 0
                },
                {
                    "sent": "But preferably if we're going to use a machine learning approach because many want station is very expensive.",
                    "label": 0
                },
                {
                    "sent": "As I said to output the results with respect to the given ontology and also there is a problem of how at what level.",
                    "label": 0
                },
                {
                    "sent": "If you're doing machine learning at what level you have to direct to train the system, because ontologies hierarchical so you can choose to identify certain concepts.",
                    "label": 0
                },
                {
                    "sent": "For example only identified persons and then not the train.",
                    "label": 0
                },
                {
                    "sent": "The system on the subtypes of persons like politicians, artists etc.",
                    "label": 0
                },
                {
                    "sent": "Or you can decide.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to train it separately for politicians and artists and all that.",
                    "label": 0
                },
                {
                    "sent": "The problem is that the more concepts you're trying to learn, the more data you're going to need to do to have.",
                    "label": 0
                },
                {
                    "sent": "And it's quite expensive to get that data and also the the finer grained distinctions you need.",
                    "label": 0
                },
                {
                    "sent": "The more data you need to train that algorithm in order to be able to make those distinctions, so there is.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of challenges in that area and.",
                    "label": 0
                },
                {
                    "sent": "These challenges have started to be addressed in.com project and they are going to be addressed in the site project as well.",
                    "label": 1
                },
                {
                    "sent": "At this point I'm going to hand over to Diana to tell you about system that uses or the ontology as part of the information extraction task.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Tell me about Toronto G based I and.",
                    "label": 0
                },
                {
                    "sent": "Some of the stuff we've been doing with gate.",
                    "label": 0
                },
                {
                    "sent": "Sungate, you've had a mission?",
                    "label": 0
                },
                {
                    "sent": "Valentin, I'm talking about both learning and rule based methods of doing information extraction.",
                    "label": 0
                },
                {
                    "sent": "Gate also enables us to combine the two in application.",
                    "label": 0
                },
                {
                    "sent": "It also enables us to combine not just information extraction but also information retrieval and this can help us.",
                    "label": 0
                },
                {
                    "sent": "With with respect to doing meta data extraction from the semantic web as I'll explain.",
                    "label": 1
                },
                {
                    "sent": "Also, because gates and architecture where you can plug in various components as you want.",
                    "label": 0
                },
                {
                    "sent": "So it means that you can stick into it.",
                    "label": 0
                },
                {
                    "sent": "Large scale linguistic resource is for IE.",
                    "label": 0
                },
                {
                    "sent": "For example word, net or any other.",
                    "label": 0
                },
                {
                    "sent": "Any kinds of ontologies you want and various other applications.",
                    "label": 0
                },
                {
                    "sent": "An other said it supports a montage is as part of the eye applications, so we can do ontology based, IE.",
                    "label": 0
                },
                {
                    "sent": "So, for example, here's a screenshot of um.",
                    "label": 0
                },
                {
                    "sent": "An ontology in gate using protege.",
                    "label": 0
                },
                {
                    "sent": "So we plugged in Potamia protege.",
                    "label": 0
                },
                {
                    "sent": "Into it and you can see here in the main window.",
                    "label": 0
                },
                {
                    "sent": "Sorry, you can see as more section of an ontology and you've got the various features and attributes and so within the gate architecture you can.",
                    "label": 0
                },
                {
                    "sent": "You can view your ontologies.",
                    "label": 0
                },
                {
                    "sent": "You can create new ontologies, you can manage them, you can edit them whatever.",
                    "label": 0
                },
                {
                    "sent": "So that just enables you to do this as part of part of the application.",
                    "label": 0
                },
                {
                    "sent": "Information retrieval, and when you're doing traditional information extraction, you typically have a corpus of documents about a certain topic.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the competitions each year there was a specific very specific topic and you got a bunch of news texts about, for example, company takeovers in the eight evaluation, similar kind of thing.",
                    "label": 0
                },
                {
                    "sent": "There were a predefined corpus of news text when you're doing them.",
                    "label": 0
                },
                {
                    "sent": "Until you based information extraction well, when you're creating data for the semantic web, for example, typically you're using the whole of the web or a subsection of it, so you may not already have a predefined corpus, so you can combine information extraction information retrieval by first of all using an information retrieval system to find the documents about the particular topic you want, and then performing your information extraction on them.",
                    "label": 0
                },
                {
                    "sent": "So again, in gate we can we can plug in an IR engine such as Lucene.",
                    "label": 0
                },
                {
                    "sent": "And which is useful for combining as a semantic and keyword based search?",
                    "label": 0
                },
                {
                    "sent": "So here we've just got a screenshot of leucine and gate, and we've searched for something like company takeovers, an here we've got a list of documents which are sorry Mr Documents which are relevant to our to our search, sorted by frequent by relevance.",
                    "label": 0
                },
                {
                    "sent": "Um, funny as I said, we've got.",
                    "label": 0
                },
                {
                    "sent": "We can also plug in things like word net into gate an we can use this to help us with with our application.",
                    "label": 0
                },
                {
                    "sent": "So here we've got section of Word Net.",
                    "label": 0
                },
                {
                    "sent": "And again, you can do.",
                    "label": 0
                },
                {
                    "sent": "You can perform various searches for different.",
                    "label": 0
                },
                {
                    "sent": "Different types, such as nouns and verbs.",
                    "label": 0
                },
                {
                    "sent": "You can also look for relations like hypernyms and antonyms and all kinds of things, so again, you can.",
                    "label": 0
                },
                {
                    "sent": "You can play around with that.",
                    "label": 0
                },
                {
                    "sent": "So probably ontologies with IE as cleaner mentioned, this is just a different viewpoint of student of the same thing that cleaner showed before I think.",
                    "label": 0
                },
                {
                    "sent": "So in the left hand side, we've got a text which has been annotated in gate, similar to things we've seen before, so we got examples of people in blue and various things, and then we can output the result of the annotations into an ontology.",
                    "label": 0
                },
                {
                    "sent": "So I'ma right we've got the DML ontology.",
                    "label": 0
                },
                {
                    "sent": "Square with attached instances.",
                    "label": 0
                },
                {
                    "sent": "So for example Pakistan has been attached to location and plasma Putin's been attached to person and so on.",
                    "label": 0
                },
                {
                    "sent": "So that's what it all looks like in gate.",
                    "label": 0
                },
                {
                    "sent": "I will give an example of an ontology based information extraction application which we've been developing.",
                    "label": 0
                },
                {
                    "sent": "It's easier to see what we're talking about by showing a real application.",
                    "label": 0
                },
                {
                    "sent": "I think HX Light is a is a project which we've been involved in.",
                    "label": 0
                },
                {
                    "sent": "Which aims to essentially track technological change overtime using terminological analysis.",
                    "label": 0
                },
                {
                    "sent": "So in the project we've been using ontology based information extraction for the semantic tagging, tagging of things like job advertisements, news company reports in the domain of chemical engineering.",
                    "label": 0
                },
                {
                    "sent": "So fundamental to the application is a domain specific ontology, so this is where it differs from traditional IE, because the whole basis is to start from from the set of texts and an ontology.",
                    "label": 0
                },
                {
                    "sent": "We use instead of using a flat gazetteer structure as is using.",
                    "label": 0
                },
                {
                    "sent": "Traditionally we have a set of terminological gazetteer lists which are linked to classes in the ontology.",
                    "label": 0
                },
                {
                    "sent": "So we start from the ontology and build the lists and say from the ontology.",
                    "label": 0
                },
                {
                    "sent": "So the lists contain typical instances of classes in the ontology, and then we use a rule based system to classify mentions in the text with respect to the domain ontology.",
                    "label": 0
                },
                {
                    "sent": "So what we're using is.",
                    "label": 0
                },
                {
                    "sent": "An adaptation of the default I sister money which Hamish talked about earlier.",
                    "label": 0
                },
                {
                    "sent": "We don't use any machine learning in in this application, mainly becausw in order to use machine learning application we'd need a lot of pre annotated text which we didn't have an appetite quite time consuming to create these and you need a domain expert, so we've used a rule based system.",
                    "label": 0
                },
                {
                    "sent": "And because the domains in which we're working and the applications at the moment kind of sample applications, so the ontologies are quite small and they're very specific as well to the particular application.",
                    "label": 0
                },
                {
                    "sent": "So one of the important things is that we use, for example, a different ontology for each kind of domain in each application.",
                    "label": 0
                },
                {
                    "sent": "So we use one ontology for tagging job advertisements, because the kind of things we're looking for in job advertisements are different from the kind of things we're looking for.",
                    "label": 0
                },
                {
                    "sent": "In general news, text or.",
                    "label": 0
                },
                {
                    "sent": "Technical reports.",
                    "label": 0
                },
                {
                    "sent": "So the the system goes off and annotates the all the mentions in the text and say with respect to the ontology.",
                    "label": 0
                },
                {
                    "sent": "Then outputs these annotations.",
                    "label": 0
                },
                {
                    "sent": "It can output them as an ontology, as that you've seen in the example just now.",
                    "label": 0
                },
                {
                    "sent": "We also output the annotations into a database, and this is used for further processing.",
                    "label": 0
                },
                {
                    "sent": "So the point of the application is says to track change overtime.",
                    "label": 0
                },
                {
                    "sent": "So we output the annotations in database format as well, where they're totally independent of the texts.",
                    "label": 0
                },
                {
                    "sent": "At this point we don't care about the texts anymore, that's kind of irrelevant, and we then look at how the the.",
                    "label": 0
                },
                {
                    "sent": "Frequency of thing instances appearing in the text and how those change overtime so we can manipulate the instances and the results and say use that for statistical analysis.",
                    "label": 0
                },
                {
                    "sent": "So the few screenshots now, this is, here's an ontology.",
                    "label": 0
                },
                {
                    "sent": "Keep doing that.",
                    "label": 0
                },
                {
                    "sent": "His mental energy of which is used for tagging job advertisements.",
                    "label": 0
                },
                {
                    "sent": "So in the center we've got, I don't seem to have a point or anywhere in the center.",
                    "label": 0
                },
                {
                    "sent": "There's the ontology with the concepts and then to the right we've got various lists, lists of lists.",
                    "label": 0
                },
                {
                    "sent": "And on the right stop touching it on the right.",
                    "label": 0
                },
                {
                    "sent": "We've got.",
                    "label": 0
                },
                {
                    "sent": "We've got an example of a list, so we've got programming types of programming packages.",
                    "label": 0
                },
                {
                    "sent": "And then in the bottom center we've got some definite definition file which Maps instances to the ontology.",
                    "label": 0
                },
                {
                    "sent": "So that's the.",
                    "label": 0
                },
                {
                    "sent": "That's the gazetteers structure linked to the ontology an that's users say for finding the instances.",
                    "label": 0
                },
                {
                    "sent": "His screenshot of the tagging gate, again very similar to what you've seen earlier, so we've got examples here.",
                    "label": 0
                },
                {
                    "sent": "We've got things like we got typical things like locations and organizations, and we've got other things, like application which is methods of application for applying for jobs.",
                    "label": 0
                },
                {
                    "sent": "Things like resumes is a Word document is the method of application for this particular job advertisement, and there are other things annotated, such as kinds of qualifications needed, references, what kind of sector, this kind of thing, and again at the bottom we've got list of the annotations an I don't know if it's big enough to see, but you've got the.",
                    "label": 0
                },
                {
                    "sent": "Again, the information about the class information about where in the ontology these are linked.",
                    "label": 0
                },
                {
                    "sent": "An another said we can export the results of this into a database and then we can say we can examine things like frequency, how often they occur overtime in different documents and this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "An answer to the question earlier again about relations.",
                    "label": 0
                },
                {
                    "sent": "This is something else we've been able to do.",
                    "label": 0
                },
                {
                    "sent": "I haven't got any examples of this in this lines because it's something we've just done very, very recently, but we can also use more than one ontology.",
                    "label": 0
                },
                {
                    "sent": "There's nothing to say we have to only use one ontology for this sort of application, so we can stick in as many ontologies as we like an, and we've been able to to add to the application some relational extraction.",
                    "label": 0
                },
                {
                    "sent": "Whereby, for example, we can find instances from different ontologies Ann and we can map.",
                    "label": 0
                },
                {
                    "sent": "We can find relations between two instances from different ontologies Ann and say an extract that information and export it again into database or into a new ontology.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially the rich text like product, which is to say is is an example of ontology based information extraction.",
                    "label": 0
                },
                {
                    "sent": "I'm going to hand you back to Kalina, who's sorry.",
                    "label": 0
                },
                {
                    "sent": "Oh yes, I will take questions if there are any, otherwise I'll hand you back to to clean and we'll talk about some large scale processing platforms.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The donkeys.",
                    "label": 0
                },
                {
                    "sent": "Side note about knowledge about knowledge or information.",
                    "label": 0
                },
                {
                    "sent": "Play versus united.",
                    "label": 0
                },
                {
                    "sent": "Sorry I didn't hear the last part of us, please.",
                    "label": 0
                },
                {
                    "sent": "That's not something we've we've done any work on at the moment, and but yeah.",
                    "label": 0
                },
                {
                    "sent": "Find reviews of president.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but those are kind of stage further into into understanding when you start looking at things like intentions, which I mean that there is quite difficult to deal with with the sort of shallow I that we're doing here, you really need to say more deeper kind of models, But for doing this so at the moment that's that's not something we've really looked into, but I mean, you're right that it's it.",
                    "label": 1
                },
                {
                    "sent": "It could be very useful.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm in the past year or so, there's been a couple of works on applying information extraction technology on a very large scale, which means that in thousands or hundreds of thousands or even millions of documents, and I'm going to show you some examples here.",
                    "label": 0
                },
                {
                    "sent": "There are some commonalities across all those approaches and platforms.",
                    "label": 0
                },
                {
                    "sent": "The advantage of when you have really large scale so many documents.",
                    "label": 0
                },
                {
                    "sent": "The advantage of having doubts is that you can run corpus white statistics to improve the quality of your information extraction results.",
                    "label": 0
                },
                {
                    "sent": "So for example, you can have these ambiguation.",
                    "label": 0
                },
                {
                    "sent": "And the more data you have, so the more examples you have, and it allows you to train your algorithms better.",
                    "label": 0
                },
                {
                    "sent": "And also for example, if you have only a certain types of rules that are very limited but you have a lot of data, then it's very likely that they will apply quite a lot of time.",
                    "label": 0
                },
                {
                    "sent": "So you're going to collect a lot of examples.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have some very simple rules that identify persons only by using.",
                    "label": 0
                },
                {
                    "sent": "One rule in fact title like Mr or Mrs or Doctor followed by one or more tokens in upper case.",
                    "label": 0
                },
                {
                    "sent": "So that's the only rule we have.",
                    "label": 0
                },
                {
                    "sent": "We run it on a really big corpus over the web and the chances are adults it will pick up a lot of examples of names like Mr. Blair and Mr.",
                    "label": 0
                },
                {
                    "sent": "I don't know John Smith and others, so you can use those then match those strings against that large corpus and use that to derive new examples for your learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Where the these same strings are going, different concept of context.",
                    "label": 0
                },
                {
                    "sent": "So then you're just you get more examples because you have a very big corpus.",
                    "label": 0
                },
                {
                    "sent": "You can also use the same statistics to disintegrate.",
                    "label": 0
                },
                {
                    "sent": "So for example are we talking about Paris in Paris in France or are we talking about Paris in America?",
                    "label": 0
                },
                {
                    "sent": "Based on how frequently they occur in the corpus for example.",
                    "label": 0
                },
                {
                    "sent": "Also, you can automatically discover aliases.",
                    "label": 0
                },
                {
                    "sent": "So in your ontology.",
                    "label": 0
                },
                {
                    "sent": "Each instance can have one or more aliases, which are the textual strings used to refer to those instances.",
                    "label": 0
                },
                {
                    "sent": "So for people you can have John Smith, Mr Smith, he, etc.",
                    "label": 0
                },
                {
                    "sent": "So if you have a big corpus, you can derive many aliases automatically using information extraction for one in the same instance.",
                    "label": 0
                },
                {
                    "sent": "They all tend to generate semantic web output like RDF or OWL.",
                    "label": 0
                },
                {
                    "sent": "They tend to use standoff annotation like XML or RDF and to index the metadata that has been discovered in the text and allow some kind of query and retrieval over it.",
                    "label": 0
                },
                {
                    "sent": "They have very large instance basis to the zombie greater so they deal with thousands and thousands of instances in their ontology.",
                    "label": 0
                },
                {
                    "sent": "It's not just an ontology that has 100 or 200 instances in it, it really has very large.",
                    "label": 0
                },
                {
                    "sent": "A number of instances, and so they tend to use things like ontology servers for reasoning and access so that data and.",
                    "label": 0
                },
                {
                    "sent": "To have many things in common, like components like crawlers which go over the web to find those documents to store the ontology and do reasoning with it, then do some document indexing of that big corpus, something to carry out queries and annotators.",
                    "label": 0
                },
                {
                    "sent": "These are the information extraction systems that automatically produce that data, but the main point here is that all of these automatically produced by today.",
                    "label": 0
                },
                {
                    "sent": "There's no human involved.",
                    "label": 0
                },
                {
                    "sent": "You have one system, it works up to a certain standard, but because you have this big corpus which you couldn't annotate otherwise.",
                    "label": 0
                },
                {
                    "sent": "That's the only thing you can do, but because you have that much data, there's a lot to find.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of redundancy that you can explore, so that's the good side of it, and they are used for many applications like semantic browsing, some authoring, etc.",
                    "label": 0
                },
                {
                    "sent": "First example is the same tax system, it's from IBM, and it was presented last last years.",
                    "label": 0
                },
                {
                    "sent": "Well, why web conference?",
                    "label": 0
                },
                {
                    "sent": "Chooses the top ontology and that's Intellige has 65,000 instances.",
                    "label": 0
                },
                {
                    "sent": "The ontology is mainly about entities.",
                    "label": 0
                },
                {
                    "sent": "Again, things like people and their subclassified into politicians and other types of people like that location subclassified in cities and others.",
                    "label": 0
                },
                {
                    "sent": "And the idea there are two types of disintegration that can occur when you have an instance in the when you have mentioned in the text.",
                    "label": 0
                },
                {
                    "sent": "There are two types.",
                    "label": 0
                },
                {
                    "sent": "You either have one of these instances in the taxonomy so you have John Smith as person in your taxonomy, and you need to identify that this is particular instance from from your ontology or taxonomy, or it's not present in that in your ontology.",
                    "label": 0
                },
                {
                    "sent": "So you have John Smith, but in your according to your ontology there is no instance.",
                    "label": 0
                },
                {
                    "sent": "Potentially can be called John Smith and they they.",
                    "label": 0
                },
                {
                    "sent": "Distinction approach here.",
                    "label": 0
                },
                {
                    "sent": "The distinctive approach here is that they think that the ontology has all the instances that are relevant to this task.",
                    "label": 0
                },
                {
                    "sent": "We're not going to add new instances at all.",
                    "label": 0
                },
                {
                    "sent": "Or are we going to do is say OK in this text?",
                    "label": 0
                },
                {
                    "sent": "Here is John Smith.",
                    "label": 0
                },
                {
                    "sent": "Is this an instance in our ontology?",
                    "label": 0
                },
                {
                    "sent": "And then if it is which one, or otherwise we just think OK, it's not relevant to our application, so that's what we're trying to do here in the same tax system.",
                    "label": 0
                },
                {
                    "sent": "I'm going to the other thing that's characteristic is that according to the top ontology, there isn't very high ambiguity between instances with the same label.",
                    "label": 0
                },
                {
                    "sent": "So if we say for example, Paris, according to according to tap, maybe there will be just one one instance that will have the label Paris, which will be the Paris in France.",
                    "label": 0
                },
                {
                    "sent": "They want that there isn't.",
                    "label": 0
                },
                {
                    "sent": "There aren't very many.",
                    "label": 0
                },
                {
                    "sent": "There aren't very many instances which have the same alias, an it means that they have focused mostly on the.",
                    "label": 0
                },
                {
                    "sent": "On the second problem, which is not so much disambiguating between the possible instances according to the ontology, but deciding is this an instance in our ontology or is it not?",
                    "label": 0
                },
                {
                    "sent": "And so for disintegration, I don't think I'll have time to go into that.",
                    "label": 0
                },
                {
                    "sent": "So, but basically what they use for it to do that.",
                    "label": 0
                },
                {
                    "sent": "Disintegration is like a bag of words approach where they building the context where in the text of this particular instance occurs.",
                    "label": 0
                },
                {
                    "sent": "So for example, if it's talking about the person they're taking all the words on the left and right of that and saying, OK, we have John Smith and it's talking about presidency and it's talking about no attending meetings and things like that.",
                    "label": 0
                },
                {
                    "sent": "So if you're matching that to an instance and then in each instance in the ontology they have similar contexts of where those instances have occurred previously in texts and then they match the two using information retrieval methods like cosine similarity, and if there is sufficient similarity between the two contexts, they say up the between the context in the text and the content.",
                    "label": 0
                },
                {
                    "sent": "That instance entology.",
                    "label": 0
                },
                {
                    "sent": "Then they say, OK, we have a match, so this is the same instance.",
                    "label": 0
                },
                {
                    "sent": "And if there isn't then they say OK according to our ontology we don't have such an instance and we're just not going to into annotate.",
                    "label": 0
                },
                {
                    "sent": "It's not relevant.",
                    "label": 0
                },
                {
                    "sent": "They use some people to manually annotate what are the instances in urology for a given 200 labels and their context in texts.",
                    "label": 0
                },
                {
                    "sent": "And it was quite interesting.",
                    "label": 0
                },
                {
                    "sent": "I mean, I really encourage you to read the paper because the Inter Annotator agreement on some of these concepts was not very high.",
                    "label": 0
                },
                {
                    "sent": "It was close to 70% and the reason for that is because entology there could be materna misuse.",
                    "label": 0
                },
                {
                    "sent": "Of the same instances.",
                    "label": 0
                },
                {
                    "sent": "So if we're talking about France, for example, if we have in our ontology, France is a country.",
                    "label": 0
                },
                {
                    "sent": "But we can also have.",
                    "label": 0
                },
                {
                    "sent": "France is a location over France is.",
                    "label": 0
                },
                {
                    "sent": "As a governing body in the sense of the governing body of the of the country, right?",
                    "label": 0
                },
                {
                    "sent": "So you can have the same instance potentially relevant to different concepts like the country.",
                    "label": 0
                },
                {
                    "sent": "Or is it the governing body of that country?",
                    "label": 0
                },
                {
                    "sent": "Or is it something else and this has been dealt with in Ace as well?",
                    "label": 0
                },
                {
                    "sent": "What Hamish mentioned earlier on and the problem is that this kind of detecting the metonymic use of the same the same words or the same label in text is very very hard.",
                    "label": 0
                },
                {
                    "sent": "So I mean, it's even hard for humans to make that distinction according to these texts.",
                    "label": 0
                },
                {
                    "sent": "Are we talking about France?",
                    "label": 0
                },
                {
                    "sent": "Is the location as in the part of the country located this geographical position?",
                    "label": 0
                },
                {
                    "sent": "Are we talking to France?",
                    "label": 0
                },
                {
                    "sent": "Is the country is in the sort of abstract sense of country?",
                    "label": 0
                },
                {
                    "sent": "Are we talking in France in terms of the government of France?",
                    "label": 0
                },
                {
                    "sent": "So this is very difficult to make even for human to agree on.",
                    "label": 0
                },
                {
                    "sent": "And this is the problem.",
                    "label": 0
                },
                {
                    "sent": "When you ask humans to classify instances from text according to an ontology.",
                    "label": 0
                },
                {
                    "sent": "That's entology should speak sort of well engineered so that humans can make reliably this sort of distinctions, because if they can't make them, then there is very little hope that you can actually train a machine to do them reliably as well.",
                    "label": 0
                },
                {
                    "sent": "The goal very quickly over this, but the high performance of that system is based on the Seeker architecture.",
                    "label": 0
                },
                {
                    "sent": "It's a distributed architecture and it runs on.",
                    "label": 0
                },
                {
                    "sent": "128 dual processor machines and separate storage and IT processes quite large number of documents is based on soap and there are different parts of that architecture.",
                    "label": 0
                },
                {
                    "sent": "Kinda sees crawlers storage join us which are for cooling the indices that the analysis, which are the information extraction modules and the corresponding applications that browse that data.",
                    "label": 0
                },
                {
                    "sent": "The second example that I wanted to cover is the Kim system, and it stands for Knowledge and information management management platform.",
                    "label": 0
                },
                {
                    "sent": "It has an ontology called Chemo and it has different number of instances depending on which instance based you load.",
                    "label": 0
                },
                {
                    "sent": "There is a smaller one which is about 90,000 document instances.",
                    "label": 0
                },
                {
                    "sent": "There is a larger one which is 200 thousands and I think that they now have got even larger one, but I'm not sure about that.",
                    "label": 0
                },
                {
                    "sent": "There's going to be a demo of that on Wednesday, so if you're interested in further information you can go and see it.",
                    "label": 0
                },
                {
                    "sent": "The difference from the top ontology is that there is high ambiguity of instances with the same label, so there is a need to disambiguate again.",
                    "label": 0
                },
                {
                    "sent": "Are we talking about Paris in France?",
                    "label": 0
                },
                {
                    "sent": "Are we talking about Paris in the US because they have large number of geographic instances and it's a full geographical gazetteer, so these have a lot of ambiguity, unlike type.",
                    "label": 0
                },
                {
                    "sent": "And so during the initial phase, they directly use the ontology to help the information extraction system in a similar way to which Diana was presenting.",
                    "label": 0
                },
                {
                    "sent": "But the difference is that they don't use gazetteer lists.",
                    "label": 0
                },
                {
                    "sent": "Instead, the information extraction system directly hooks into the knowledge server and extracts automatically from there via queries.",
                    "label": 0
                },
                {
                    "sent": "All the instances of each which concept and just uses them to annotate the text.",
                    "label": 0
                },
                {
                    "sent": "So there are no gazetteers at all, you're just directly looking at looking into the ontology to identify all the instances that you have and then annotate dousing the text and then combine that with rule based information extraction system to recognize other aliases of the same instances or new instances that have not been mentioned before and are those to do entology.",
                    "label": 0
                },
                {
                    "sent": "So this is the next step, is the knowledge base enrichment where you have these new instances which have been identified for the first time by the system to be added to the ontology for future use.",
                    "label": 0
                },
                {
                    "sent": "And in order to disambiguate how.",
                    "label": 0
                },
                {
                    "sent": "What instance is used in the text from the several possible ones with the same label?",
                    "label": 0
                },
                {
                    "sent": "They have the so called entity ranking algorithm and it implements basically priority ordering advantages based on some corpus statistics.",
                    "label": 0
                },
                {
                    "sent": "And if you want some further details aside, ask them at the demo, but it's a very good example of how you can use a large corpus of thousands of documents to derive such kind of disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Statistics.",
                    "label": 0
                },
                {
                    "sent": "So in terms of technology, the information extraction pipeline uses quite is quite similar to what you saw where you're on shown by Hamish Indiani system, but there's the so-called Semantic Gazetteer, which directly uses to ontology and to obtain the instances instead of having lists.",
                    "label": 0
                },
                {
                    "sent": "And then you have the information extraction algorithms, the rules, but there are they use directly.",
                    "label": 0
                },
                {
                    "sent": "Ontology and subsumption from the ontology to carry out some of the tasks.",
                    "label": 0
                },
                {
                    "sent": "And they also have these these integration algorithms that I mentioned, and they also have some relation extraction, which is quite small.",
                    "label": 0
                },
                {
                    "sent": "Set of relations according to the ontology.",
                    "label": 0
                },
                {
                    "sent": "They're basically things like located at, so identifying what is the location of a particular person at the given time, or things like that.",
                    "label": 0
                },
                {
                    "sent": "Some things related to time as well, I think, and also rolls like.",
                    "label": 0
                },
                {
                    "sent": "What is the profession of a person and some other examples like that?",
                    "label": 0
                },
                {
                    "sent": "They come from the ontology.",
                    "label": 0
                },
                {
                    "sent": "So if you like some further information, have a look at their ontology and you can also update demo online for that system.",
                    "label": 0
                },
                {
                    "sent": "So to compare briefly, these two systems, there is a big difference between them in terms of their aims.",
                    "label": 0
                },
                {
                    "sent": "So in the same tag approach.",
                    "label": 0
                },
                {
                    "sent": "But they're mainly aiming for accuracy.",
                    "label": 0
                },
                {
                    "sent": "In other words, precision, so that's what they want to do is OK every time we find something in the text, we want to be sure that this is the instance in deontology that we say is we want to have very precise algorithm was what they try to do in Kim.",
                    "label": 0
                },
                {
                    "sent": "Is to also in full coverage, which is the recall aspect.",
                    "label": 0
                },
                {
                    "sent": "So what we're trying to do is to identify absolutely all mentions in the text, because they're trying to identify relations.",
                    "label": 0
                },
                {
                    "sent": "So if you are trying to identify like located at relation and you have person on one side and location on the other, if you have missed the location then you cannot find the located at relation because you only have person right?",
                    "label": 0
                },
                {
                    "sent": "And this is the difference because they're trying to identify relations and because of that they have to identify all mentions.",
                    "label": 0
                },
                {
                    "sent": "In the text, so for them, recall is very important ways in.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they're just trying to find OK. Have we got this instance in the text or have we not got it?",
                    "label": 0
                },
                {
                    "sent": "So it's mainly for like information retrieval, sort of purposes, and it's not important to identify always occurrences, so we try.",
                    "label": 0
                },
                {
                    "sent": "There is a tradeoff here, as he said between precision and recall, and each application has to decide whether it's better to go like the same tag approach or the other approach.",
                    "label": 0
                },
                {
                    "sent": "It really is a decision to.",
                    "label": 0
                },
                {
                    "sent": "Be made by the application.",
                    "label": 0
                },
                {
                    "sent": "The other difference is that sometimes does not attempt to discover and expand the instance base with new instances.",
                    "label": 0
                },
                {
                    "sent": "So for example, new companies.",
                    "label": 0
                },
                {
                    "sent": "And some.",
                    "label": 0
                },
                {
                    "sent": "In other words, it depends what we're trying to do.",
                    "label": 0
                },
                {
                    "sent": "Again, if it's important for us to discover new instances as part of the information extraction process, then perhaps we shouldn't.",
                    "label": 0
                },
                {
                    "sent": "We should consider approach like that in Kim, where it can be handled.",
                    "label": 0
                },
                {
                    "sent": "The differences to demonstrate this slightly more clearly is OK in the same tag approach we have this, it's fine, some instances and some in some tack.",
                    "label": 0
                },
                {
                    "sent": "It doesn't find relations, but in Kimi does find some relations.",
                    "label": 0
                },
                {
                    "sent": "And maybe that's enough we don't care so much about the mentions in the text, because what we're more interested in is in actually finding the syntactic in other semantic information, creating this and populating this with information extraction.",
                    "label": 0
                },
                {
                    "sent": "So in this case, this is what we're interested in.",
                    "label": 0
                },
                {
                    "sent": "Have we found those part of relations?",
                    "label": 0
                },
                {
                    "sent": "Have we found the airport?",
                    "label": 0
                },
                {
                    "sent": "So if this is enough, then this is considerably less problematic.",
                    "label": 1
                },
                {
                    "sent": "It's easier to attain that goal then it is to try and identify.",
                    "label": 0
                },
                {
                    "sent": "All of the relations in all dimensions in the texts, so to give it more clear example, if we go back to our previous case again, we find those.",
                    "label": 0
                },
                {
                    "sent": "And we're comparing in this case, what we're trying to do is to just find these from teologi in all its instances.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if that's all we're trying to do, OK, we have 100% success because we have identified both instances here and our ontology looks like we want it to look, and we're not so interested about all these in the text.",
                    "label": 0
                },
                {
                    "sent": "The fact that we missed President Bush up there is not relevant to us because we have still identified it, at least in one place.",
                    "label": 0
                },
                {
                    "sent": "But the second growth scenario is where we really want to identify all the mentions in the text right at the curse, and the reason for it is because if we want to have sentence based or paragraphs based exploration of the top of the text, then we need to really have all them.",
                    "label": 0
                },
                {
                    "sent": "All the semantic information, but it's really hard to achieve.",
                    "label": 0
                },
                {
                    "sent": "So what we're talking about here is this.",
                    "label": 0
                },
                {
                    "sent": "So we are comparing the fact that we have missed their President Bush and now we have a success rate of 66% because we have only found these two, whereas what we've set out to find originally was also this.",
                    "label": 0
                },
                {
                    "sent": "And this is missing.",
                    "label": 0
                },
                {
                    "sent": "So you can see that given same text and the same results from the information extraction depending on what your application is trying to do, you can have quite different results.",
                    "label": 0
                },
                {
                    "sent": "So it's really important to have that in mind.",
                    "label": 0
                },
                {
                    "sent": "And the third example is this one.",
                    "label": 0
                },
                {
                    "sent": "It's a semantic web annotator.",
                    "label": 0
                },
                {
                    "sent": "It's an ongoing collaboration between Dairy and Sheffield University.",
                    "label": 0
                },
                {
                    "sent": "It's being hosted the dairy, and it comprises of the gate system that we shall do so earlier on.",
                    "label": 0
                },
                {
                    "sent": "The Kim.",
                    "label": 0
                },
                {
                    "sent": "Form that I just discussed and Psycho.",
                    "label": 0
                },
                {
                    "sent": "It's an RDF color and the basic goals of these work are two.",
                    "label": 0
                },
                {
                    "sent": "Similarly.",
                    "label": 0
                },
                {
                    "sent": "Again, a large scale annotation effort aiming to annotate thousands of pages at the moment is performing custom indexing of news and in the future other types of web protects.",
                    "label": 0
                },
                {
                    "sent": "Further uses ended quantitative media reporting.",
                    "label": 0
                },
                {
                    "sent": "Annotated Web Workbench service and custom knowledge services, but for further information there will be a demo and poster on Wednesday.",
                    "label": 0
                },
                {
                    "sent": "So before you do that, because I think we don't have time.",
                    "label": 0
                },
                {
                    "sent": "For in depth discussion here, basically the logical architecture is very similar to what you saw in Sam tagging Seeker.",
                    "label": 0
                },
                {
                    "sent": "You have the web and you have a focused crawling there and then you have many processors, different machines that carry out the information extraction task you collect the annotations in a database and there is no knowledge base with instances and ontology.",
                    "label": 0
                },
                {
                    "sent": "And then you have a lot of web services.",
                    "label": 0
                },
                {
                    "sent": "That's allowing access to all the data.",
                    "label": 0
                },
                {
                    "sent": "For example, to have conceptual search and their different users here via web services or via user interface for human users.",
                    "label": 0
                },
                {
                    "sent": "So one interesting thing here is that it has a console for controlling the cluster, so you can enable and disable machines which run the different information extraction tasks and so forth.",
                    "label": 0
                },
                {
                    "sent": "So I'll go very briefly into this because we don't have very much time.",
                    "label": 0
                },
                {
                    "sent": "The next step is to carry out the reference disambiguation cell to identify when we have many instances in the text which are the.",
                    "label": 0
                },
                {
                    "sent": "Referring to the same to, say, Mr. Synology and which are referring to different ones, there are several possible approaches that have been explored.",
                    "label": 0
                },
                {
                    "sent": "Young girl very much detail, but I'll point you at some of them so we can read them or yourself further, there's the vector space models as I mentioned in the systems like some tag where they compare basically context similarity, building vectors of the context and they run over corpora.",
                    "label": 0
                },
                {
                    "sent": "There's also cross document Coreference work from the computational linguistics field, which is quite similar, but the difference here is that the cross document Coreference work is not concerned with ontologies per say, it's.",
                    "label": 0
                },
                {
                    "sent": "Just a question.",
                    "label": 0
                },
                {
                    "sent": "There was weather.",
                    "label": 0
                },
                {
                    "sent": "Weather 2 documents that talk about, for example, John Smith are talking about the same John Smith, which is quite similar, but you don't have a specific explicit ontology of the domain and all the instances in that domain.",
                    "label": 0
                },
                {
                    "sent": "There's also approached from knowledge management and its communities of practice.",
                    "label": 0
                },
                {
                    "sent": "These are automatically identified on the basis of the ontology itself, so no reference to text whatsoever or the occurrences in the text.",
                    "label": 0
                },
                {
                    "sent": "It just identification of weather 2 instances are actually the same instance on the basis of the ontology and the links that exist in the ontology by the different relations.",
                    "label": 0
                },
                {
                    "sent": "There is a paper on that here at the SWS.",
                    "label": 0
                },
                {
                    "sent": "It's about the CS active space.",
                    "label": 0
                },
                {
                    "sent": "And you can have further details from that paper and then the final one is you can use some kind of reasoning to identify some to have some identity criteria from the ontology.",
                    "label": 0
                },
                {
                    "sent": "So for example if we say OK, all people who have the same date of birth and name and place of birth are identical.",
                    "label": 0
                },
                {
                    "sent": "Presumably if we have that kind of axiom in our ontology and we have identified using information extraction system that we have a person called.",
                    "label": 0
                },
                {
                    "sent": "John Smith and he was born on 1st of January in London.",
                    "label": 0
                },
                {
                    "sent": "Then you can say you can ask the ontology reason.",
                    "label": 0
                },
                {
                    "sent": "There you have an instance that has the same name, the same date of birth and same location and because of the because the reason will say OK, this is these are the same person so you can disambiguate at that point saying OK that John Smith that I have in my text is the same as the instance of John Smith from Genealogy because there.",
                    "label": 0
                },
                {
                    "sent": "That's what my reason are tells me they are identical.",
                    "label": 0
                },
                {
                    "sent": "So one thing I'll skip that, but can somebody tell me 10 minutes?",
                    "label": 0
                }
            ]
        }
    }
}