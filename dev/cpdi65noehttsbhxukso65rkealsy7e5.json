{
    "id": "cpdi65noehttsbhxukso65rkealsy7e5",
    "title": "Scalable Modeling of Real Graphs using Kronecker Multiplication",
    "info": {
        "author": [
            "Jure Leskovec, Computer Science Department, Stanford University"
        ],
        "published": "June 23, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/icml07_leskovec_smrg/",
    "segmentation": [
        [
            "OK, hello everyone.",
            "So what I'll talk about is how to generate large synthetic realistic graphs.",
            "So we will want to have like a model with a few parameters.",
            "We want to estimate these parameters to generate a graph of let's say 100,000 nodes that has similar properties."
        ],
        [
            "Then the real graph, so I'll start with motivation, right?",
            "We want we have this large network networks like web, Internet and online social networks that have like millions of nodes in 10s of millions of edges.",
            "And what we model or to understand them we need some statistical methods.",
            "To be an models to be able to quant."
        ],
        [
            "Invite them right and here is the problem I'm trying to solve, so we're given a large real world network.",
            "We would like to generate a synthetic synthetic network and then if I go and compare this to network through some kind of properties, for example, I can go and plot the degree distributions of both networks.",
            "I would like this to to match OK, and when doing this there are three questions we need to ask.",
            "First one is what are the relevant properties we care about.",
            "So what are the things we should?",
            "Measure on the network.",
            "Second one is what is a good, analytically tractable model to use that will be able to generate these kinds of networks.",
            "And once we have the model, how can we estimate the?"
        ],
        [
            "Parameters.",
            "Um?",
            "So why would you want to do this?",
            "For example, one way one of the basic reasons is this will give you some kind of insight into the topology.",
            "The structure of the network of.",
            "Inside in the graph formation process and so on.",
            "But it's also useful for example for anomaly detection, when you would like to detect abnormal behavior, abnormal abnormal graphs or predictions asking given the graph of the Internet today, what can I say about it in a year from now?",
            "Use synthetic graphs for simulations of network protocols and so on, or for simulations of the networks that are impossible to collect in real life, you could do graph sampling, meaning you have a big graph and you would like to get a smaller graph.",
            "That has similar properties or you would like to do a measurement on the smaller graph and then tell something about the bigger graph and so on."
        ],
        [
            "OK, so.",
            "There has been a lot of work in this area, right?",
            "And there has been a large number of properties that are observed through throughout the different networks coming from various domains, right?",
            "There is like well known things like small world effect, which means that networks have small diameter.",
            "We have heavy tailed and power law degree distributions.",
            "There are some spectral properties that are shared among networks from various domains and so on.",
            "And once we have this type of properties of networks then we can go and ask how can we design?",
            "Generative models that will give us graphs with that properties, and again there is.",
            "There's a long laundry list of such works right.",
            "The most famous is like preferential attachment that is a simple, simple, mechanistic way of how to attach nodes in the graph in order to get to get power law degree distributions.",
            "There are a few things that are sort of wrong with these models, right?",
            "They're usually meant to like explain just for model, just a single property of the network, like a power law, degree distribution or something like that.",
            "And the other thing is usually they can be analytically intractable."
        ],
        [
            "So the one the model we will work with here is called Chronicle graphs.",
            "And what is good about Chronicle graphs is that you can go and prove a large.",
            "You can prove properties of Chronicle graphs, meaning you can go and prove that they will have power law degree distributions that will have small diameters, power loss in eigen values and eigen vectors of graph adjacency matrix and so on.",
            "Yeah, and we introduce this modeling."
        ],
        [
            "Go fight.",
            "So what is the idea?",
            "The idea is to generate graphs like recursively, right, so?",
            "And why do we want to use like recursion?",
            "Is 'cause I know many times power loss appear in like in combination of self similarity or some kind of recursive structure.",
            "So the goal is to try to mimic the recursive graph and community growth.",
            "So what we'll do is we'll start start with some initial graph and then we will expand its nodes.",
            "Weed again with a copy of itself, right and?",
            "There are several ways to do this, and this is for example of wrong way of doing it.",
            "But if we're using a Chronicle product or a tensor product."
        ],
        [
            "That works nicely, so here's the idea.",
            "Here are the graphs, and here are corresponding adjacency matrices.",
            "We start with the initial graph we go through this intermediate stage of like replacing every node with a with a copy of the initial graph, and then introducing additional edges into a graph.",
            "And if you look what is going on with the adjacency matrix, here's our original adjacency matrix corresponding to this graph, and this is the second adjacency matrix.",
            "This one is 3 by 3.",
            "This one is 9 by 9 where now every non 0 cell is like replaced with the whole matrix itself."
        ],
        [
            "Right, and more precisely, so chronic product right of two matrices.",
            "What is the following right?",
            "Basically we go and for every cell of matrix A will I put in the whole matrix being multiplied with an appropriate constant and also notice that the size of this matrix is now like the product of the sizes of the corresponding matrices and what we will do.",
            "We will do this type of operation on graph adjacency matrices to get bigger."
        ],
        [
            "The graphs.",
            "OK, so.",
            "We want to use this recursion.",
            "We want to start with some initial initiator graph that has one anyone.",
            "Edges, nodes and edges, and then we want to generate a sequence of graphs, each one having more nodes.",
            "And here is how we do it right.",
            "We just do Kronecker product between the same initiator graph K times and this will give us a graph of size and one to the K."
        ],
        [
            "OK, so here is.",
            "Here's an example.",
            "If I take this simple adjacency matrix and Chronicle multiplied with itself four times, this is the adjacency matrix I get here.",
            "The dots represent nonzero elements of adjacency matrix and you can see this like nice recursive structure of the matrix where we have this block of zeros which corresponds to here and then we have the non zero blocks which again are like recursively similar to whatever we have on top."
        ],
        [
            "And this is this is the model.",
            "So the model I introduced so far is like deterministic.",
            "We had zeros and ones.",
            "Now I want to introduce a like a stochastic or a random version of it.",
            "So instead of working with initiator graph will work with some kind of probabilistic analog of it, and the idea is to start with this probability matrix where every cell is now like a probability of an edge occurring so every every element of the cell is now a probability like.",
            "I know and then we do the Chronicle multiplication of this of this matrix will get a bigger matrix and to sample a graph from it.",
            "Now we just go in for every cell.",
            "If we flip a Bernoulli coin, that gives me heads with this probability and this way we obtain we obtain obtain realization of the graph OK."
        ],
        [
            "Um?",
            "And so there are.",
            "So I showed you this.",
            "Process that is sort of artificial, but here are two two ways how you can think about it, and maybe find how things are going in real life.",
            "So first, 1st way to think about this is is to think about like have nodes to be like to expand into little communities.",
            "This community's links link among themselves and link across each other, right?",
            "So each node in the graph will get expanded into a miniature copy of the original thing, and we will also have this cross edges so communities link.",
            "So this would now correspond to communities they link among each other and we also get some cross edges.",
            "The other way to think about this is completely different.",
            "So now assume you have a set of nodes and you describe each node with a set of features.",
            "For example, if you have two features, whether the person likes the ice cream and whether they like the chocolate, right?",
            "So now do you like the ice cream but doesn't like the chocolate and not he likes both?",
            "So now the parameter matrix encodes me the probability of an edge, right?",
            "So I can say what's the probability of an edge from you to be it's .5 because they agree on liking chocolate, sorry.",
            "Agree on liking ice cream and it's .3 right?",
            "This should be this element because one doesn't like it and likes it.",
            "So it would should be.",
            "This one would be the and if I multiply them I get the probability of an error.",
            "So this is a different way of thinking.",
            "So one way is to think about this recursive growth communities.",
            "The other one is by having no described by binary features and just checking how many features two nodes share and the more they shared, the higher the."
        ],
        [
            "They'll be connected.",
            "So I said if you use this model you can go improve many little things about it.",
            "So the good news is that it seems that Chronicle graphs have all the expressive power we need.",
            "What is not so good news is that I still haven't told you how to choose the parameters to try to match all of this, right?",
            "I can I can easily send parameters to have good degree distributions, But then the question is, what can I do being limited to degree distribution?"
        ],
        [
            "Some other property, so our approach to find the parameters is through maximum likelihood estimation, right?",
            "So we are given a real graph, the data and we want to estimate the Chronicle initiator graph.",
            "Basically this this this probability matrix or this graph is like by just maximizing maximizing the probability that we observe the graph given the parameters.",
            "And what do we need to do?",
            "So basically we need to be able to calculate this likelihood and then we need to be able to maximize.",
            "Over the parameters using, let's say."
        ],
        [
            "In dissent.",
            "And now what I was showing, the rest is basically how we can do this efficiently for graphs of an order of like that have 100,000 nodes and more so this is how we define the likelihood, right?",
            "We are given the real graph and here is the.",
            "Corresponding adjacency matrix.",
            "Assume somebody tells us the parameters and we'd like to calculate the likelihood.",
            "The idea is very simple, right for every edge that occurred we would take the we take the probability that the edge happened and for every edge, for example, that did not occur, we take 1 minus the probability that the edge did not occur right?",
            "And this is how we define the likelihood.",
            "So basically we just ask what is the probability that this?",
            "Probability this probability matrix generated adjacency matrix like this and there are."
        ],
        [
            "2 problems with this.",
            "So first problem is note correspondence, right?",
            "So this node labels are sort of arbitrary, right?",
            "We're given unlabeled graphs, So what is going on is that I have the same graph.",
            "I just label the nodes in a different way, so it means my adjacency matrix looks different, and if I would use the formula I showed on the previous page, I would get different likelihoods.",
            "So the idea is to go and sort of average over all possible permutations, right?",
            "So now I have this permutation.",
            "That sort of encodes.",
            "How do how does this adjacency matrix labeled map on the on the probability adjacency matrix, right?",
            "So I need to I need to.",
            "Go over over this N factorial permutations so this this will clearly be infeasible to do in practice, so."
        ],
        [
            "Is 1 one problem or one challenge?",
            "The other challenges that even calculating the likelihood is too expensive, right?",
            "If I want to calculate the likelihood as I introduced it, I need to go through the full adjacency matrix and then check if there is a one.",
            "I take point .25 is there's a zero.",
            "I take 1 minus the value there, right?",
            "And I need to multiply these things together, which means that I have to traverse the whole adjacency matrix, which means this will run in order N squared time, which for.",
            "Decent sized networks."
        ],
        [
            "Too slow.",
            "And so naively estimating the parameters takes like order N factorial N squared time we need.",
            "N factorial time to go over through the permutations.",
            "Or you can think of this as some kind of isomorphism testing.",
            "Our solution here is to use Metropolis sampling to get from factorial to basically constant.",
            "And for the NN squared term, which corresponds to traversing the graph adjacency matrix, we can exploit the properties of Chronicle, product and sparsity of real graphs to basically get from North squared to linear time.",
            "So the whole we can estimate the parameters in order it I'm so.",
            "The number of edges.",
            "So in linear time we can estimate the little probability matrix I showed at the beginning."
        ],
        [
            "So now I will very briefly briefly show how do we do this right?",
            "We start with the log likelihood.",
            "We just want to calculate the gradient of the log likelihood so that we can do gradient descent, dissent, or something similar.",
            "If you cleverly rearrange the derivative of the log likelihood, what you get an expression like this which immediately suggest sampling right?",
            "Given the graph in the parameter cycle sample to distribute the permutation.",
            "Now I have everything and I can evaluate the derivative.",
            "I can repeat this many times and use the stochastic gradient to guide."
        ],
        [
            "By my search.",
            "How how do we go about not correspond?",
            "Not so the.",
            "So here is.",
            "Here is what I want to do.",
            "Now I want to sample a permutation.",
            "How do I do that?",
            "This is this is just a sketch of Metropolis sampling, right?",
            "I will start with some random permutation, so like a random labeling of the nodes I want to do local moves on the permutation, which means I want to swap the labels of two nodes chosen uniformly at random.",
            "And then if this gives me if this local move gives me a better fit, higher likelihood, I will accept this local move.",
            "If it gives me a worse move.",
            "I will accept with some probability.",
            "OK, so this is also.",
            "I'm basically sort of greedily climbing and from time to time, jumping aside.",
            "So in pictures let this be the graph we have now we decide to swap the labels of nodes one and two, so right now this would be sort of our permutation.",
            "So now now we re labeled the nodes one and two.",
            "So what happened was that now I had to like swap.",
            "These these yellow rows and columns.",
            "So what this means is that I can for every such local move I can, we can very efficiently evaluate the likelihood right?",
            "If we have the likelihood in previous time step, all we need to update is basically once and zeros that change and this part of the adjacency matrix did not change, so we don't really need to worry about it."
        ],
        [
            "Um?",
            "OK, so the other thing that we need to figure out how to do is now calculate the likelihood right so we have the parameters we have the permutation.",
            "How do we get the likelihood?",
            "Naively doing it takes N squared, but so here's the idea.",
            "Idea is to 1st calculate the likelihood of an empty graph.",
            "So given the parameters, how likely it is that the observation we get from the parameters has no edges, right?",
            "So we only have the notes in zero edges, and then the idea is all we need to do now is to go over the edges that actually succeeded and sort of corrected the likelihood and the good thing here is that we can exploit the structure of the Kronecker product to get a closed form solution for the likelihood of an empty graph."
        ],
        [
            "Palm so.",
            "So here's the idea, right?",
            "I can calculate this basically constant time, which is the likelihood that we see no edges in the graph and all we need to do now is to go over all the edges in the graph.",
            "So probability of observing an empty graph.",
            "This is now I go over all the edges, I subtract the like the contribution to the likelihood of not seeing that edge and adding a contribution in the graph for seeing the edge.",
            "So basically all we're doing is we're going through the edges that actually succeeded and add add their contribution to the likelihood.",
            "What is to see here is that the sum only goes over the edges in the graphs that, so this should take order in time and the good thing in real graphs is that they are sparse, meaning that number of edges is much much smaller than the number of nodes, right?",
            "Usually the number of edges is like 10 or 20 times the number of nodes."
        ],
        [
            "OK, so now I will briefly show some of the experimental results.",
            "The first sanity check we did was just can we can we can we recover the true parameters and which is the same question as how nice is our optimization space right?",
            "It's easy to see that the optimization problem we're solving is non convex and the question is can we given a synthetic given Chronicle graph we generated with some parameters?",
            "Can we can we recover those parameters and the answer is yes.",
            "So we like 98% of the times the gradient descent converge to the true parameters, which means that our optimization space is not too bad and we were sort of."
        ],
        [
            "OK, so for for comparing now in real networks here is what we'll do right?",
            "We take the real graph.",
            "We will be doing stochastic gradient descent from some random initial point, so we randomly set the parameters and start our gradient descent.",
            "There will repeat.",
            "This obtains estimated parameters given the parameters will generate a synthetic graph and then compare.",
            "Compare the real and synthetic graph.",
            "Note that we are not really fitting the properties themselves, right?",
            "So we're not saying we want to match.",
            "I know these 3 four properties and now sort of defining an objective function over them, but we are.",
            "We are fitting the likelihood and then we would just like to see how well are we doing on something that we were."
        ],
        [
            "Not really fitting over.",
            "So the first graph we tried was autonomous systems, which is basically a graph of the Internet that has 6500 nodes and 26,000 edges.",
            "So the space of the permutation is like of the size of 10 to the 50,000 and fitting takes like 20 minutes.",
            "And this is the parameter matrix.",
            "We recover.",
            "What's interesting to see here is that since autonomous systems graph is undirected, our parameter matrix is symmetric.",
            "So without biasing it, we can.",
            "We can recover this, which is nice."
        ],
        [
            "And now to further see what's going on, we are now having the real autonomous system graph and some realization of the Chronicle graph and we compare it with calculate several statistics from the two graphs and plot them and sort of eyeball and see whether they are similar.",
            "So what I'm showing here is the are the degree distributions, so this is the log degree and here is the count.",
            "So the number of nodes with that particular degree and these things are heavy tailed so they will sort of follow be on the line.",
            "And here the the circle.",
            "The empty circles are the true data and this is our estimate.",
            "And it's close.",
            "Here is I'm showing like a cumulative distribution over the path length.",
            "So this sort of tells us how many pairs of nodes are reachable at particular distance.",
            "This would be the diameter and again you can see.",
            "It matches well."
        ],
        [
            "You can do similar thing and check the spectral properties.",
            "So I'm taking the adjacency matrices and all I'm doing here is.",
            "First I'm calculating the top few eigenvalues and then plotting rank versus eigenvalue on log log scales.",
            "And the other thing that I'm plotting here is the log rank versus the log value of the first eigenvector and again.",
            "They sort of have the same shape."
        ],
        [
            "The other graph we tried this on is opinions graph that's a bit larger, so this is 76,000 nodes and half a million edges.",
            "Here the space of all permutations we're searching over is like 10 to the million it takes about 2 hours on just a normal machine to fit this.",
            "Here are the results for the same 4 degree distribution hop plot and.",
            "The spectral properties are shown later.",
            "What is interesting is for example here is defeated adjacency matrix and what you can see is that like we have this very, very high value up here, which sort of suggests that our graphs we always have like some core of the network that is densely linked and then we have some small part that then links with these probabilities to it right?",
            "So the."
        ],
        [
            "Choose one, these are the, again the same spectral properties here.",
            "Here's the distribution of eigenvalues.",
            "This is the distribution of the components of the first eigenvector.",
            "So just to conclude what we did right, I showed Chronicle graphs that have provable properties and basically a very small number of parameters.",
            "We develop scalable fitting algorithms to estimating these parameters.",
            "We can efficiently search very large spaces of permutations.",
            "We saw that we can fix.",
            "Graphs well using just four parameters and what is also nice that we match graph properties without actually fitting on them, right?",
            "We're just optimizing likelihood and whatever we get is similar.",
            "Also in this structural properties type of space.",
            "OK thanks.",
            "Testing the traps.",
            "Sure.",
            "Trying on another, you know, knowledge sharing side part.",
            "The networking one separated into the metadata about it, sure, but this.",
            "This assumes that that.",
            "I think this assumes a lot, right?",
            "You're basically what I'm doing here.",
            "I'm essentially like working with a single data point, right?",
            "Yeah, but shouldn't what you usually do, right?",
            "You split your data in half and say I don't know do cross validation.",
            "I can't do cross validation right?",
            "Picking up with this thing like for example other knowledge.",
            "Because then you know that you discovered something about how the web works as opposed to something to it description, anything.",
            "I'm sure, for example, we could do this for for autonomous systems, so you could take a graph on a particular day and take a similar.",
            "Take a graph on the next day, right that that that that is definitely doable.",
            "I doubt a bit about taking another Idol knowledge sharing type of graph 'cause it's right different.",
            "Different websites have different user interfaces and it's not.",
            "I know clear how much.",
            "Apartments.",
            "Sure, we could do that.",
            "What happens?",
            "Who?",
            "The last point slide there without it.",
            "Very exciting with properties, but I mean that that seems strong, right?",
            "Your whole model set for your graph is a self similar skill tree graph, right?",
            "So you've already limited yourself to a very small family of rats, sure.",
            "OK, so you have it.",
            "Aside alot about set property care about.",
            "Um, yeah, but so I agree that yeah, we let's say set up our model very carefully to like sort of limit ourselves to certain classes of graphs, right this we cannot generate circle.",
            "I think we cannot generate agreed and things like that, right?",
            "But?",
            "What in nature you don't find such graphs right?",
            "I don't think so we can.",
            "We can generate a line we could generate.",
            "Square.",
            "Evolution of grass.",
            "Nebraska testing on different days.",
            "A year later, you know, can we use it as a donor?",
            "Yeah, So what I would like next is basically what sort of what fan was doing.",
            "So like I would like to have some kind of evolution model over the parameters and the things you see the observe your observation is a graph over like over certain times, overtime, different time steps, right?",
            "And this way then you could see our parameters changing our parameters remaining constant and this should be very interesting.",
            "It can be anything right?",
            "So here I was just using two by two, but BIC nicely applies.",
            "In the paper we show that you can recover the true strength through number of parameters used, so you can use more right?",
            "You can use three by three, 4 by 4.",
            "Sure you'll feel better, but you'll have more parameters.",
            "OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, hello everyone.",
                    "label": 0
                },
                {
                    "sent": "So what I'll talk about is how to generate large synthetic realistic graphs.",
                    "label": 0
                },
                {
                    "sent": "So we will want to have like a model with a few parameters.",
                    "label": 0
                },
                {
                    "sent": "We want to estimate these parameters to generate a graph of let's say 100,000 nodes that has similar properties.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the real graph, so I'll start with motivation, right?",
                    "label": 0
                },
                {
                    "sent": "We want we have this large network networks like web, Internet and online social networks that have like millions of nodes in 10s of millions of edges.",
                    "label": 1
                },
                {
                    "sent": "And what we model or to understand them we need some statistical methods.",
                    "label": 0
                },
                {
                    "sent": "To be an models to be able to quant.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Invite them right and here is the problem I'm trying to solve, so we're given a large real world network.",
                    "label": 1
                },
                {
                    "sent": "We would like to generate a synthetic synthetic network and then if I go and compare this to network through some kind of properties, for example, I can go and plot the degree distributions of both networks.",
                    "label": 0
                },
                {
                    "sent": "I would like this to to match OK, and when doing this there are three questions we need to ask.",
                    "label": 0
                },
                {
                    "sent": "First one is what are the relevant properties we care about.",
                    "label": 1
                },
                {
                    "sent": "So what are the things we should?",
                    "label": 0
                },
                {
                    "sent": "Measure on the network.",
                    "label": 1
                },
                {
                    "sent": "Second one is what is a good, analytically tractable model to use that will be able to generate these kinds of networks.",
                    "label": 1
                },
                {
                    "sent": "And once we have the model, how can we estimate the?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parameters.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So why would you want to do this?",
                    "label": 0
                },
                {
                    "sent": "For example, one way one of the basic reasons is this will give you some kind of insight into the topology.",
                    "label": 1
                },
                {
                    "sent": "The structure of the network of.",
                    "label": 0
                },
                {
                    "sent": "Inside in the graph formation process and so on.",
                    "label": 1
                },
                {
                    "sent": "But it's also useful for example for anomaly detection, when you would like to detect abnormal behavior, abnormal abnormal graphs or predictions asking given the graph of the Internet today, what can I say about it in a year from now?",
                    "label": 0
                },
                {
                    "sent": "Use synthetic graphs for simulations of network protocols and so on, or for simulations of the networks that are impossible to collect in real life, you could do graph sampling, meaning you have a big graph and you would like to get a smaller graph.",
                    "label": 0
                },
                {
                    "sent": "That has similar properties or you would like to do a measurement on the smaller graph and then tell something about the bigger graph and so on.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "There has been a lot of work in this area, right?",
                    "label": 0
                },
                {
                    "sent": "And there has been a large number of properties that are observed through throughout the different networks coming from various domains, right?",
                    "label": 0
                },
                {
                    "sent": "There is like well known things like small world effect, which means that networks have small diameter.",
                    "label": 0
                },
                {
                    "sent": "We have heavy tailed and power law degree distributions.",
                    "label": 1
                },
                {
                    "sent": "There are some spectral properties that are shared among networks from various domains and so on.",
                    "label": 1
                },
                {
                    "sent": "And once we have this type of properties of networks then we can go and ask how can we design?",
                    "label": 0
                },
                {
                    "sent": "Generative models that will give us graphs with that properties, and again there is.",
                    "label": 0
                },
                {
                    "sent": "There's a long laundry list of such works right.",
                    "label": 0
                },
                {
                    "sent": "The most famous is like preferential attachment that is a simple, simple, mechanistic way of how to attach nodes in the graph in order to get to get power law degree distributions.",
                    "label": 0
                },
                {
                    "sent": "There are a few things that are sort of wrong with these models, right?",
                    "label": 0
                },
                {
                    "sent": "They're usually meant to like explain just for model, just a single property of the network, like a power law, degree distribution or something like that.",
                    "label": 0
                },
                {
                    "sent": "And the other thing is usually they can be analytically intractable.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the one the model we will work with here is called Chronicle graphs.",
                    "label": 1
                },
                {
                    "sent": "And what is good about Chronicle graphs is that you can go and prove a large.",
                    "label": 0
                },
                {
                    "sent": "You can prove properties of Chronicle graphs, meaning you can go and prove that they will have power law degree distributions that will have small diameters, power loss in eigen values and eigen vectors of graph adjacency matrix and so on.",
                    "label": 1
                },
                {
                    "sent": "Yeah, and we introduce this modeling.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go fight.",
                    "label": 0
                },
                {
                    "sent": "So what is the idea?",
                    "label": 0
                },
                {
                    "sent": "The idea is to generate graphs like recursively, right, so?",
                    "label": 0
                },
                {
                    "sent": "And why do we want to use like recursion?",
                    "label": 0
                },
                {
                    "sent": "Is 'cause I know many times power loss appear in like in combination of self similarity or some kind of recursive structure.",
                    "label": 0
                },
                {
                    "sent": "So the goal is to try to mimic the recursive graph and community growth.",
                    "label": 1
                },
                {
                    "sent": "So what we'll do is we'll start start with some initial graph and then we will expand its nodes.",
                    "label": 0
                },
                {
                    "sent": "Weed again with a copy of itself, right and?",
                    "label": 1
                },
                {
                    "sent": "There are several ways to do this, and this is for example of wrong way of doing it.",
                    "label": 0
                },
                {
                    "sent": "But if we're using a Chronicle product or a tensor product.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That works nicely, so here's the idea.",
                    "label": 0
                },
                {
                    "sent": "Here are the graphs, and here are corresponding adjacency matrices.",
                    "label": 0
                },
                {
                    "sent": "We start with the initial graph we go through this intermediate stage of like replacing every node with a with a copy of the initial graph, and then introducing additional edges into a graph.",
                    "label": 0
                },
                {
                    "sent": "And if you look what is going on with the adjacency matrix, here's our original adjacency matrix corresponding to this graph, and this is the second adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "This one is 3 by 3.",
                    "label": 0
                },
                {
                    "sent": "This one is 9 by 9 where now every non 0 cell is like replaced with the whole matrix itself.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, and more precisely, so chronic product right of two matrices.",
                    "label": 1
                },
                {
                    "sent": "What is the following right?",
                    "label": 0
                },
                {
                    "sent": "Basically we go and for every cell of matrix A will I put in the whole matrix being multiplied with an appropriate constant and also notice that the size of this matrix is now like the product of the sizes of the corresponding matrices and what we will do.",
                    "label": 1
                },
                {
                    "sent": "We will do this type of operation on graph adjacency matrices to get bigger.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "We want to use this recursion.",
                    "label": 0
                },
                {
                    "sent": "We want to start with some initial initiator graph that has one anyone.",
                    "label": 1
                },
                {
                    "sent": "Edges, nodes and edges, and then we want to generate a sequence of graphs, each one having more nodes.",
                    "label": 1
                },
                {
                    "sent": "And here is how we do it right.",
                    "label": 0
                },
                {
                    "sent": "We just do Kronecker product between the same initiator graph K times and this will give us a graph of size and one to the K.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here is.",
                    "label": 0
                },
                {
                    "sent": "Here's an example.",
                    "label": 0
                },
                {
                    "sent": "If I take this simple adjacency matrix and Chronicle multiplied with itself four times, this is the adjacency matrix I get here.",
                    "label": 1
                },
                {
                    "sent": "The dots represent nonzero elements of adjacency matrix and you can see this like nice recursive structure of the matrix where we have this block of zeros which corresponds to here and then we have the non zero blocks which again are like recursively similar to whatever we have on top.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is this is the model.",
                    "label": 0
                },
                {
                    "sent": "So the model I introduced so far is like deterministic.",
                    "label": 0
                },
                {
                    "sent": "We had zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "Now I want to introduce a like a stochastic or a random version of it.",
                    "label": 0
                },
                {
                    "sent": "So instead of working with initiator graph will work with some kind of probabilistic analog of it, and the idea is to start with this probability matrix where every cell is now like a probability of an edge occurring so every every element of the cell is now a probability like.",
                    "label": 1
                },
                {
                    "sent": "I know and then we do the Chronicle multiplication of this of this matrix will get a bigger matrix and to sample a graph from it.",
                    "label": 0
                },
                {
                    "sent": "Now we just go in for every cell.",
                    "label": 1
                },
                {
                    "sent": "If we flip a Bernoulli coin, that gives me heads with this probability and this way we obtain we obtain obtain realization of the graph OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so there are.",
                    "label": 0
                },
                {
                    "sent": "So I showed you this.",
                    "label": 0
                },
                {
                    "sent": "Process that is sort of artificial, but here are two two ways how you can think about it, and maybe find how things are going in real life.",
                    "label": 0
                },
                {
                    "sent": "So first, 1st way to think about this is is to think about like have nodes to be like to expand into little communities.",
                    "label": 0
                },
                {
                    "sent": "This community's links link among themselves and link across each other, right?",
                    "label": 1
                },
                {
                    "sent": "So each node in the graph will get expanded into a miniature copy of the original thing, and we will also have this cross edges so communities link.",
                    "label": 0
                },
                {
                    "sent": "So this would now correspond to communities they link among each other and we also get some cross edges.",
                    "label": 0
                },
                {
                    "sent": "The other way to think about this is completely different.",
                    "label": 0
                },
                {
                    "sent": "So now assume you have a set of nodes and you describe each node with a set of features.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have two features, whether the person likes the ice cream and whether they like the chocolate, right?",
                    "label": 0
                },
                {
                    "sent": "So now do you like the ice cream but doesn't like the chocolate and not he likes both?",
                    "label": 1
                },
                {
                    "sent": "So now the parameter matrix encodes me the probability of an edge, right?",
                    "label": 0
                },
                {
                    "sent": "So I can say what's the probability of an edge from you to be it's .5 because they agree on liking chocolate, sorry.",
                    "label": 1
                },
                {
                    "sent": "Agree on liking ice cream and it's .3 right?",
                    "label": 0
                },
                {
                    "sent": "This should be this element because one doesn't like it and likes it.",
                    "label": 0
                },
                {
                    "sent": "So it would should be.",
                    "label": 0
                },
                {
                    "sent": "This one would be the and if I multiply them I get the probability of an error.",
                    "label": 1
                },
                {
                    "sent": "So this is a different way of thinking.",
                    "label": 0
                },
                {
                    "sent": "So one way is to think about this recursive growth communities.",
                    "label": 0
                },
                {
                    "sent": "The other one is by having no described by binary features and just checking how many features two nodes share and the more they shared, the higher the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They'll be connected.",
                    "label": 0
                },
                {
                    "sent": "So I said if you use this model you can go improve many little things about it.",
                    "label": 0
                },
                {
                    "sent": "So the good news is that it seems that Chronicle graphs have all the expressive power we need.",
                    "label": 1
                },
                {
                    "sent": "What is not so good news is that I still haven't told you how to choose the parameters to try to match all of this, right?",
                    "label": 1
                },
                {
                    "sent": "I can I can easily send parameters to have good degree distributions, But then the question is, what can I do being limited to degree distribution?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some other property, so our approach to find the parameters is through maximum likelihood estimation, right?",
                    "label": 1
                },
                {
                    "sent": "So we are given a real graph, the data and we want to estimate the Chronicle initiator graph.",
                    "label": 0
                },
                {
                    "sent": "Basically this this this probability matrix or this graph is like by just maximizing maximizing the probability that we observe the graph given the parameters.",
                    "label": 0
                },
                {
                    "sent": "And what do we need to do?",
                    "label": 1
                },
                {
                    "sent": "So basically we need to be able to calculate this likelihood and then we need to be able to maximize.",
                    "label": 0
                },
                {
                    "sent": "Over the parameters using, let's say.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In dissent.",
                    "label": 0
                },
                {
                    "sent": "And now what I was showing, the rest is basically how we can do this efficiently for graphs of an order of like that have 100,000 nodes and more so this is how we define the likelihood, right?",
                    "label": 0
                },
                {
                    "sent": "We are given the real graph and here is the.",
                    "label": 0
                },
                {
                    "sent": "Corresponding adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "Assume somebody tells us the parameters and we'd like to calculate the likelihood.",
                    "label": 0
                },
                {
                    "sent": "The idea is very simple, right for every edge that occurred we would take the we take the probability that the edge happened and for every edge, for example, that did not occur, we take 1 minus the probability that the edge did not occur right?",
                    "label": 0
                },
                {
                    "sent": "And this is how we define the likelihood.",
                    "label": 0
                },
                {
                    "sent": "So basically we just ask what is the probability that this?",
                    "label": 0
                },
                {
                    "sent": "Probability this probability matrix generated adjacency matrix like this and there are.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2 problems with this.",
                    "label": 0
                },
                {
                    "sent": "So first problem is note correspondence, right?",
                    "label": 0
                },
                {
                    "sent": "So this node labels are sort of arbitrary, right?",
                    "label": 0
                },
                {
                    "sent": "We're given unlabeled graphs, So what is going on is that I have the same graph.",
                    "label": 0
                },
                {
                    "sent": "I just label the nodes in a different way, so it means my adjacency matrix looks different, and if I would use the formula I showed on the previous page, I would get different likelihoods.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to go and sort of average over all possible permutations, right?",
                    "label": 0
                },
                {
                    "sent": "So now I have this permutation.",
                    "label": 0
                },
                {
                    "sent": "That sort of encodes.",
                    "label": 0
                },
                {
                    "sent": "How do how does this adjacency matrix labeled map on the on the probability adjacency matrix, right?",
                    "label": 0
                },
                {
                    "sent": "So I need to I need to.",
                    "label": 0
                },
                {
                    "sent": "Go over over this N factorial permutations so this this will clearly be infeasible to do in practice, so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is 1 one problem or one challenge?",
                    "label": 0
                },
                {
                    "sent": "The other challenges that even calculating the likelihood is too expensive, right?",
                    "label": 0
                },
                {
                    "sent": "If I want to calculate the likelihood as I introduced it, I need to go through the full adjacency matrix and then check if there is a one.",
                    "label": 0
                },
                {
                    "sent": "I take point .25 is there's a zero.",
                    "label": 0
                },
                {
                    "sent": "I take 1 minus the value there, right?",
                    "label": 0
                },
                {
                    "sent": "And I need to multiply these things together, which means that I have to traverse the whole adjacency matrix, which means this will run in order N squared time, which for.",
                    "label": 0
                },
                {
                    "sent": "Decent sized networks.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Too slow.",
                    "label": 0
                },
                {
                    "sent": "And so naively estimating the parameters takes like order N factorial N squared time we need.",
                    "label": 1
                },
                {
                    "sent": "N factorial time to go over through the permutations.",
                    "label": 0
                },
                {
                    "sent": "Or you can think of this as some kind of isomorphism testing.",
                    "label": 0
                },
                {
                    "sent": "Our solution here is to use Metropolis sampling to get from factorial to basically constant.",
                    "label": 0
                },
                {
                    "sent": "And for the NN squared term, which corresponds to traversing the graph adjacency matrix, we can exploit the properties of Chronicle, product and sparsity of real graphs to basically get from North squared to linear time.",
                    "label": 1
                },
                {
                    "sent": "So the whole we can estimate the parameters in order it I'm so.",
                    "label": 0
                },
                {
                    "sent": "The number of edges.",
                    "label": 0
                },
                {
                    "sent": "So in linear time we can estimate the little probability matrix I showed at the beginning.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I will very briefly briefly show how do we do this right?",
                    "label": 0
                },
                {
                    "sent": "We start with the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "We just want to calculate the gradient of the log likelihood so that we can do gradient descent, dissent, or something similar.",
                    "label": 1
                },
                {
                    "sent": "If you cleverly rearrange the derivative of the log likelihood, what you get an expression like this which immediately suggest sampling right?",
                    "label": 0
                },
                {
                    "sent": "Given the graph in the parameter cycle sample to distribute the permutation.",
                    "label": 0
                },
                {
                    "sent": "Now I have everything and I can evaluate the derivative.",
                    "label": 0
                },
                {
                    "sent": "I can repeat this many times and use the stochastic gradient to guide.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By my search.",
                    "label": 0
                },
                {
                    "sent": "How how do we go about not correspond?",
                    "label": 0
                },
                {
                    "sent": "Not so the.",
                    "label": 0
                },
                {
                    "sent": "So here is.",
                    "label": 0
                },
                {
                    "sent": "Here is what I want to do.",
                    "label": 0
                },
                {
                    "sent": "Now I want to sample a permutation.",
                    "label": 0
                },
                {
                    "sent": "How do I do that?",
                    "label": 0
                },
                {
                    "sent": "This is this is just a sketch of Metropolis sampling, right?",
                    "label": 1
                },
                {
                    "sent": "I will start with some random permutation, so like a random labeling of the nodes I want to do local moves on the permutation, which means I want to swap the labels of two nodes chosen uniformly at random.",
                    "label": 1
                },
                {
                    "sent": "And then if this gives me if this local move gives me a better fit, higher likelihood, I will accept this local move.",
                    "label": 0
                },
                {
                    "sent": "If it gives me a worse move.",
                    "label": 1
                },
                {
                    "sent": "I will accept with some probability.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is also.",
                    "label": 0
                },
                {
                    "sent": "I'm basically sort of greedily climbing and from time to time, jumping aside.",
                    "label": 0
                },
                {
                    "sent": "So in pictures let this be the graph we have now we decide to swap the labels of nodes one and two, so right now this would be sort of our permutation.",
                    "label": 0
                },
                {
                    "sent": "So now now we re labeled the nodes one and two.",
                    "label": 0
                },
                {
                    "sent": "So what happened was that now I had to like swap.",
                    "label": 0
                },
                {
                    "sent": "These these yellow rows and columns.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that I can for every such local move I can, we can very efficiently evaluate the likelihood right?",
                    "label": 0
                },
                {
                    "sent": "If we have the likelihood in previous time step, all we need to update is basically once and zeros that change and this part of the adjacency matrix did not change, so we don't really need to worry about it.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so the other thing that we need to figure out how to do is now calculate the likelihood right so we have the parameters we have the permutation.",
                    "label": 0
                },
                {
                    "sent": "How do we get the likelihood?",
                    "label": 0
                },
                {
                    "sent": "Naively doing it takes N squared, but so here's the idea.",
                    "label": 0
                },
                {
                    "sent": "Idea is to 1st calculate the likelihood of an empty graph.",
                    "label": 0
                },
                {
                    "sent": "So given the parameters, how likely it is that the observation we get from the parameters has no edges, right?",
                    "label": 0
                },
                {
                    "sent": "So we only have the notes in zero edges, and then the idea is all we need to do now is to go over the edges that actually succeeded and sort of corrected the likelihood and the good thing here is that we can exploit the structure of the Kronecker product to get a closed form solution for the likelihood of an empty graph.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Palm so.",
                    "label": 0
                },
                {
                    "sent": "So here's the idea, right?",
                    "label": 0
                },
                {
                    "sent": "I can calculate this basically constant time, which is the likelihood that we see no edges in the graph and all we need to do now is to go over all the edges in the graph.",
                    "label": 0
                },
                {
                    "sent": "So probability of observing an empty graph.",
                    "label": 1
                },
                {
                    "sent": "This is now I go over all the edges, I subtract the like the contribution to the likelihood of not seeing that edge and adding a contribution in the graph for seeing the edge.",
                    "label": 0
                },
                {
                    "sent": "So basically all we're doing is we're going through the edges that actually succeeded and add add their contribution to the likelihood.",
                    "label": 0
                },
                {
                    "sent": "What is to see here is that the sum only goes over the edges in the graphs that, so this should take order in time and the good thing in real graphs is that they are sparse, meaning that number of edges is much much smaller than the number of nodes, right?",
                    "label": 1
                },
                {
                    "sent": "Usually the number of edges is like 10 or 20 times the number of nodes.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I will briefly show some of the experimental results.",
                    "label": 0
                },
                {
                    "sent": "The first sanity check we did was just can we can we can we recover the true parameters and which is the same question as how nice is our optimization space right?",
                    "label": 0
                },
                {
                    "sent": "It's easy to see that the optimization problem we're solving is non convex and the question is can we given a synthetic given Chronicle graph we generated with some parameters?",
                    "label": 0
                },
                {
                    "sent": "Can we can we recover those parameters and the answer is yes.",
                    "label": 0
                },
                {
                    "sent": "So we like 98% of the times the gradient descent converge to the true parameters, which means that our optimization space is not too bad and we were sort of.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so for for comparing now in real networks here is what we'll do right?",
                    "label": 0
                },
                {
                    "sent": "We take the real graph.",
                    "label": 1
                },
                {
                    "sent": "We will be doing stochastic gradient descent from some random initial point, so we randomly set the parameters and start our gradient descent.",
                    "label": 1
                },
                {
                    "sent": "There will repeat.",
                    "label": 1
                },
                {
                    "sent": "This obtains estimated parameters given the parameters will generate a synthetic graph and then compare.",
                    "label": 1
                },
                {
                    "sent": "Compare the real and synthetic graph.",
                    "label": 0
                },
                {
                    "sent": "Note that we are not really fitting the properties themselves, right?",
                    "label": 0
                },
                {
                    "sent": "So we're not saying we want to match.",
                    "label": 0
                },
                {
                    "sent": "I know these 3 four properties and now sort of defining an objective function over them, but we are.",
                    "label": 0
                },
                {
                    "sent": "We are fitting the likelihood and then we would just like to see how well are we doing on something that we were.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not really fitting over.",
                    "label": 0
                },
                {
                    "sent": "So the first graph we tried was autonomous systems, which is basically a graph of the Internet that has 6500 nodes and 26,000 edges.",
                    "label": 0
                },
                {
                    "sent": "So the space of the permutation is like of the size of 10 to the 50,000 and fitting takes like 20 minutes.",
                    "label": 1
                },
                {
                    "sent": "And this is the parameter matrix.",
                    "label": 0
                },
                {
                    "sent": "We recover.",
                    "label": 0
                },
                {
                    "sent": "What's interesting to see here is that since autonomous systems graph is undirected, our parameter matrix is symmetric.",
                    "label": 1
                },
                {
                    "sent": "So without biasing it, we can.",
                    "label": 0
                },
                {
                    "sent": "We can recover this, which is nice.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now to further see what's going on, we are now having the real autonomous system graph and some realization of the Chronicle graph and we compare it with calculate several statistics from the two graphs and plot them and sort of eyeball and see whether they are similar.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing here is the are the degree distributions, so this is the log degree and here is the count.",
                    "label": 1
                },
                {
                    "sent": "So the number of nodes with that particular degree and these things are heavy tailed so they will sort of follow be on the line.",
                    "label": 0
                },
                {
                    "sent": "And here the the circle.",
                    "label": 0
                },
                {
                    "sent": "The empty circles are the true data and this is our estimate.",
                    "label": 0
                },
                {
                    "sent": "And it's close.",
                    "label": 0
                },
                {
                    "sent": "Here is I'm showing like a cumulative distribution over the path length.",
                    "label": 0
                },
                {
                    "sent": "So this sort of tells us how many pairs of nodes are reachable at particular distance.",
                    "label": 0
                },
                {
                    "sent": "This would be the diameter and again you can see.",
                    "label": 0
                },
                {
                    "sent": "It matches well.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can do similar thing and check the spectral properties.",
                    "label": 1
                },
                {
                    "sent": "So I'm taking the adjacency matrices and all I'm doing here is.",
                    "label": 0
                },
                {
                    "sent": "First I'm calculating the top few eigenvalues and then plotting rank versus eigenvalue on log log scales.",
                    "label": 0
                },
                {
                    "sent": "And the other thing that I'm plotting here is the log rank versus the log value of the first eigenvector and again.",
                    "label": 1
                },
                {
                    "sent": "They sort of have the same shape.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other graph we tried this on is opinions graph that's a bit larger, so this is 76,000 nodes and half a million edges.",
                    "label": 0
                },
                {
                    "sent": "Here the space of all permutations we're searching over is like 10 to the million it takes about 2 hours on just a normal machine to fit this.",
                    "label": 1
                },
                {
                    "sent": "Here are the results for the same 4 degree distribution hop plot and.",
                    "label": 1
                },
                {
                    "sent": "The spectral properties are shown later.",
                    "label": 0
                },
                {
                    "sent": "What is interesting is for example here is defeated adjacency matrix and what you can see is that like we have this very, very high value up here, which sort of suggests that our graphs we always have like some core of the network that is densely linked and then we have some small part that then links with these probabilities to it right?",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Choose one, these are the, again the same spectral properties here.",
                    "label": 0
                },
                {
                    "sent": "Here's the distribution of eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "This is the distribution of the components of the first eigenvector.",
                    "label": 0
                },
                {
                    "sent": "So just to conclude what we did right, I showed Chronicle graphs that have provable properties and basically a very small number of parameters.",
                    "label": 0
                },
                {
                    "sent": "We develop scalable fitting algorithms to estimating these parameters.",
                    "label": 0
                },
                {
                    "sent": "We can efficiently search very large spaces of permutations.",
                    "label": 0
                },
                {
                    "sent": "We saw that we can fix.",
                    "label": 0
                },
                {
                    "sent": "Graphs well using just four parameters and what is also nice that we match graph properties without actually fitting on them, right?",
                    "label": 0
                },
                {
                    "sent": "We're just optimizing likelihood and whatever we get is similar.",
                    "label": 0
                },
                {
                    "sent": "Also in this structural properties type of space.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                },
                {
                    "sent": "Testing the traps.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "Trying on another, you know, knowledge sharing side part.",
                    "label": 0
                },
                {
                    "sent": "The networking one separated into the metadata about it, sure, but this.",
                    "label": 0
                },
                {
                    "sent": "This assumes that that.",
                    "label": 0
                },
                {
                    "sent": "I think this assumes a lot, right?",
                    "label": 0
                },
                {
                    "sent": "You're basically what I'm doing here.",
                    "label": 0
                },
                {
                    "sent": "I'm essentially like working with a single data point, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but shouldn't what you usually do, right?",
                    "label": 0
                },
                {
                    "sent": "You split your data in half and say I don't know do cross validation.",
                    "label": 0
                },
                {
                    "sent": "I can't do cross validation right?",
                    "label": 0
                },
                {
                    "sent": "Picking up with this thing like for example other knowledge.",
                    "label": 0
                },
                {
                    "sent": "Because then you know that you discovered something about how the web works as opposed to something to it description, anything.",
                    "label": 0
                },
                {
                    "sent": "I'm sure, for example, we could do this for for autonomous systems, so you could take a graph on a particular day and take a similar.",
                    "label": 0
                },
                {
                    "sent": "Take a graph on the next day, right that that that that is definitely doable.",
                    "label": 0
                },
                {
                    "sent": "I doubt a bit about taking another Idol knowledge sharing type of graph 'cause it's right different.",
                    "label": 0
                },
                {
                    "sent": "Different websites have different user interfaces and it's not.",
                    "label": 0
                },
                {
                    "sent": "I know clear how much.",
                    "label": 0
                },
                {
                    "sent": "Apartments.",
                    "label": 0
                },
                {
                    "sent": "Sure, we could do that.",
                    "label": 0
                },
                {
                    "sent": "What happens?",
                    "label": 0
                },
                {
                    "sent": "Who?",
                    "label": 0
                },
                {
                    "sent": "The last point slide there without it.",
                    "label": 0
                },
                {
                    "sent": "Very exciting with properties, but I mean that that seems strong, right?",
                    "label": 0
                },
                {
                    "sent": "Your whole model set for your graph is a self similar skill tree graph, right?",
                    "label": 0
                },
                {
                    "sent": "So you've already limited yourself to a very small family of rats, sure.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have it.",
                    "label": 0
                },
                {
                    "sent": "Aside alot about set property care about.",
                    "label": 0
                },
                {
                    "sent": "Um, yeah, but so I agree that yeah, we let's say set up our model very carefully to like sort of limit ourselves to certain classes of graphs, right this we cannot generate circle.",
                    "label": 0
                },
                {
                    "sent": "I think we cannot generate agreed and things like that, right?",
                    "label": 0
                },
                {
                    "sent": "But?",
                    "label": 0
                },
                {
                    "sent": "What in nature you don't find such graphs right?",
                    "label": 0
                },
                {
                    "sent": "I don't think so we can.",
                    "label": 0
                },
                {
                    "sent": "We can generate a line we could generate.",
                    "label": 0
                },
                {
                    "sent": "Square.",
                    "label": 0
                },
                {
                    "sent": "Evolution of grass.",
                    "label": 0
                },
                {
                    "sent": "Nebraska testing on different days.",
                    "label": 0
                },
                {
                    "sent": "A year later, you know, can we use it as a donor?",
                    "label": 0
                },
                {
                    "sent": "Yeah, So what I would like next is basically what sort of what fan was doing.",
                    "label": 0
                },
                {
                    "sent": "So like I would like to have some kind of evolution model over the parameters and the things you see the observe your observation is a graph over like over certain times, overtime, different time steps, right?",
                    "label": 0
                },
                {
                    "sent": "And this way then you could see our parameters changing our parameters remaining constant and this should be very interesting.",
                    "label": 0
                },
                {
                    "sent": "It can be anything right?",
                    "label": 0
                },
                {
                    "sent": "So here I was just using two by two, but BIC nicely applies.",
                    "label": 0
                },
                {
                    "sent": "In the paper we show that you can recover the true strength through number of parameters used, so you can use more right?",
                    "label": 0
                },
                {
                    "sent": "You can use three by three, 4 by 4.",
                    "label": 0
                },
                {
                    "sent": "Sure you'll feel better, but you'll have more parameters.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        }
    }
}