{
    "id": "l6vbajykiuemteg55wmd3vinxjbcscsj",
    "title": "Piecewise-Stationary Bandit Problems with Side Observations",
    "info": {
        "author": [
            "Jia Yuan Yu, Electrical and Computer Engineering Department, McGill University"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_yu_psbp/",
    "segmentation": [
        [
            "The the slot machines have a random distribution that's fixed of the reward, but you don't know the distribution, so you're kind of trying to minimize your loss and we're going to consider a special type of such problems.",
            "And the best way to look at it is from another."
        ],
        [
            "Spective the perspective of an investment problem where you have a bunch of experts, so they run.",
            "Each one runs a block and you can look up the investment advice is and after following their advice you can check up on the performance of their advice from the stock market.",
            "So what we assume is that the reward following each."
        ],
        [
            "Each expert's advice is stationary for long periods of time, but that sudden times and times that are unknown, the distribution of the reward is going to change, and the next distribution is going to be also unknown.",
            "So for example.",
            "You might have an expert who's who knows about vaccines and all of a sudden there's a flu outbreak, and if you follow that guy's advice after the flu outbreak, you might get a very good reward.",
            "But before that he might not perform very well.",
            "Hi, just a word of warning.",
            "I'm not an expert in.",
            "In flu vaccine or investment?",
            "OK, so the way this problem?",
            "Works more in detail is that."
        ],
        [
            "Each time instant.",
            "You choose an expert and you follow his advice and we introduce another concept of querying other people.",
            "Other experts advices without actually following their advice.",
            "And doing these two actions you.",
            "Obtain the reward by following the experts advice and you also observe what the other experts that you queried advise you.",
            "And there is a constraint that you don't have all the time in the world, so you cannot query every other expert out there.",
            "So this can be incorporated into a cost of querying additional experts.",
            "And the goal is actually quite simple.",
            "You want to do as well as you could have done by if you had known.",
            "What are the distributions of the rewards at every time instant.",
            "So the reason why we choose this model is."
        ],
        [
            "'cause in the multi armed bandit problem alot of people have looked at stationary case where the word distribution is fixed.",
            "Overall time and other people have look at the adversarial case where they assume that an adversary is actually giving you the rewards.",
            "But we're kind of interested in what happens in between the two because arguably in nature is not all the time stationary nor is it trying to screw you."
        ],
        [
            "OK, just some notation.",
            "We're going to make vectors out of the rewards, and each vector is going to be.",
            "Represent.",
            "However, these elements, the rewards of the experts.",
            "And we're going to denote the unknown changepoints by the news.",
            "So, and we use better to denote the mean of the distribution that we don't know.",
            "And just for simplicity, we assume that the rewards are from finite interval 01."
        ],
        [
            "Alright, so a little bit more notation.",
            "So the actions of the that you take following the advice is are going to be a 80s.",
            "And the rewards that you get is BT of 80.",
            "The observations they're going to be denoted by the set S. And the cost of your queries will depend on the number of queries you make, and it's going to be CQ of S."
        ],
        [
            "OK, so the objective.",
            "In precise terms, is that you want to do as well?",
            "As if the reward distribution is going to be known in advance, and the way you measure this is.",
            "Here you have the baseline where you know what are the words in advance.",
            "You take the Max at every time instant.",
            "And the other term is the expected reward you get.",
            "Now if you include the cost of querying."
        ],
        [
            "Can you divide by you take the average overall time, then this expression.",
            "Will be the average cost at every time step.",
            "OK, so let me just situate our model with respect to other well known problems.",
            "So there's the stochastic multi armed bandit where.",
            "There are no change point at all and you don't make additional queries.",
            "This is very well known.",
            "And in this case.",
            "Because."
        ],
        [
            "Because there are no change points, you don't really need the benefit.",
            "You don't reap many benefits from query on the side, and it's well known that.",
            "The expected grade in this case is going to be linear in the number of experts and logarithmic at the time."
        ],
        [
            "Now, there's also an adversarial version of this problem.",
            "In this problem, you.",
            "There can be arbitrarily many change points, so.",
            "And also there are two versions of this, one in which you know the prediction.",
            "You can actually query for free every other expert and another one where you don't have additional queries.",
            "So for this problem, the notion of regret is actually."
        ],
        [
            "Different.",
            "They're looking at a single action over all time.",
            "For the baseline.",
            "And in this problem also by adding the notion of queries you only have a little change.",
            "Which is the term.",
            "Poly polynomial term in the number of.",
            "Experts now, in terms of our model, it has been studied by."
        ],
        [
            "Two other groups of people.",
            "Harden and his colleagues they provided a partial solution when?",
            "I wear the music they try to detect change this changes in the distribution of the best arm only.",
            "The best expert only without regard to querying the other experts.",
            "And.",
            "Get ivn moulinas moulinas.",
            "Case where they assume that you know in advance how many change points you can expect.",
            "And in this case, they show that a bunch of algorithms will give you.",
            "A regret that's polynomial in T around square root.",
            "And they also show that in this case, without additional queries, you have a lower bound of square root of T for the threat.",
            "Now all contribution is to show that.",
            "If you."
        ],
        [
            "Avicide queries.",
            "You can reduce the regret from polynomial square root of T to something that logarithmically.",
            "And Moreover, our solution doesn't require prior knowledge.",
            "The number of change points that are to be expected."
        ],
        [
            "OK approach we take is that.",
            "We're going to make an algorithm by combining 2 sub algorithms.",
            "The first one is a standard algorithm for the multi and stochastic multi armed bandit problem.",
            "For example, you can use the UCB.",
            "Upper confidence bound type of algorithms.",
            "And another side algorithm that sub algorithm that detects when you have a change in distribution.",
            "So the naive way of detecting a change would be to use the so called."
        ],
        [
            "Optimal change detection algorithms so example of these are the Q Summon other algorithms, But these algorithms they had some drawbacks they're using.",
            "Likelihood ratio tests and for these we actually have to know the prior and posterior distributions.",
            "So our solution will use something much simpler.",
            "We're going to.",
            "Look at the empirical averages.",
            "Of the rewards and try to detect changes in search."
        ],
        [
            "Average is over.",
            "Appropriate windows of times.",
            "So."
        ],
        [
            "I will propose is going to break the time into those of linked data.",
            "Tao so basically this is a sequence of.",
            "All of the rewards at all times and we just bring them at length of Tau.",
            "And.",
            "Within each interval you basically just compute the average mean, thanks.",
            "You compute this average mean based on the additional side queries.",
            "And at every time step you just follow a UCB algorithm that basically looks at the average.",
            "The empirical average of the rewards of each arm and chooses the one that has the best.",
            "Such reward, modified by an extra term that.",
            "Takes into account how many times you have sampled these experts.",
            "And we query is very simple with query.",
            "Each expert sequentially and approximately as many times each time.",
            "Each expert as the others, and.",
            "The way we detect changes, we set an epsilon and once the difference mean goes above the epsilon, which basically raise an alarm.",
            "And we said.",
            "The UCB algorithm doing.",
            "That's choosing the experts.",
            "So."
        ],
        [
            "So the guarantee that we can provide.",
            "Is that suppose every time distribution change occurs, we assume that you know.",
            "There's a lower bound on the change, a lower bound of two epsilon, and based on this two epsilon, you can choose an appropriate length of the windows over which you compute the mean of the rewards, and after that you follow the previous album.",
            "Can show that the regret will be.",
            "Logarithmic in time and linear in both the number of.",
            "Changes and the number of experts.",
            "So this bound becomes meaningful when.",
            "The key is actually much smaller or relatively smaller compared to T so that you have some linear regret.",
            "So the proof is quite simple.",
            "There are two components."
        ],
        [
            "For the regret, one comes from the delay in detecting when the change occurs and the other.",
            "Is due to.",
            "The number of times you reset the algorithm.",
            "And basically we bound these two quantities using tail probabilities and.",
            "Pretty straightforward.",
            "No."
        ],
        [
            "So we can also show a lower bound, but this lower bound is is only works for algorithms that actually will tell you when the changes occur.",
            "And for these, for this lower bound, we use a result that says.",
            "You need logarithmic number of time steps in order to detect a change.",
            "And these are.",
            "This lower bound.",
            "This result is based on the optimal change detection argument that such as COO summoned.",
            "Sure we are Evan Roberts."
        ],
        [
            "Now we also ran some experiments in which we looked at rewards that are Bernoulli random variables, whose parameter will change suddenly with.",
            "So in this example we compare."
        ],
        [
            "Sometimes I'll do this comparison.",
            "Doesn't tell you much, because for some algorithms we'll assume that they know the number of changes to come.",
            "Where is our albums?",
            "We assumed that.",
            "It is allowed to take one side query.",
            "At the time step.",
            "So here you can see that.",
            "The time these are the times vertical lines, they represent the times in which the true changes occur.",
            "And the little little diamonds represent when you detect a change, thanks.",
            "No after this.",
            "You can.",
            "Like trade off the cost of querying, such as going on."
        ],
        [
            "Sign and reading somebody plug and investing time into checking how each expert performance versus the the the regret that you get.",
            "And if you assume that each query costs constant, then you can do a simple optimization in the number of queries you should do at each time step.",
            "And you can find the optimal one.",
            "No."
        ],
        [
            "There are some open problems that are.",
            "That are to be solved so there can be more fancier versions of querying the site experts the exposure you didn't follow, so I think you might be able to use some ideas from Francesco's talk I think.",
            "Where they queried.",
            "In the context of active learning.",
            "And another possible version is where the queries might fail with a certain probability.",
            "And, um.",
            "Another model would be the case where you query 1st and then you query both experts and then you actually kind of follow the actions.",
            "The advisors of both experts and you receive the best word of the two.",
            "And there can be other models of.",
            "The non non stationary reward so just one that follows Markovian dynamics as in the restless bandit problem.",
            "And with this I'm going to thank you for coming."
        ],
        [
            "Question.",
            "Your mother is a Delta.",
            "So I forgot to say that in the bound there is a constant term that depends on the minimum difference between the best expert and the second best experts average reward.",
            "Um at all times for the whole company.",
            "Nerd.",
            "We don't need to know it a priority, but the bound will depend on the constant.",
            "Within we did need to know the epsilon for the minimum change from 1 one time.",
            "One time interval to another one.",
            "But I think there we can avoid this kind of.",
            "Assumption by using more sophisticated change detection algorithms.",
            "Or maybe you're in your life.",
            "Like before.",
            "Independent.",
            "Having a very progressive.",
            "Regret.",
            "Teen times number times.",
            "Logan tomorrow.",
            "Music.",
            "Found.",
            "Try the question into that when you compare the lucky bounce about in the lunch is quality growth of tea.",
            "Is it a fair comparison because it's?",
            "It's not the same model because we have additional queries and they had to know in advance the number of changes they are expecting.",
            "Which one is that you have lucky?",
            "And if you optimize over 1000, probably.",
            "It doesn't prove that you are gaining something.",
            "OK.",
            "I'd be happy to discuss a little bit later.",
            "You discover.",
            "Also doesn't seem to be consistent about the yes, and if you did.",
            "Would you really done is you've introduced with Epsilon machine?",
            "Epsilon away because you don't really need to switch.",
            "So if you're up epsilon or.",
            "Pok\u00e9mon door you might get something that's polynomial in time.",
            "It is.",
            "Absolutely.",
            "And that's not.",
            "Square one.",
            "Double.",
            "OK, so thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The the slot machines have a random distribution that's fixed of the reward, but you don't know the distribution, so you're kind of trying to minimize your loss and we're going to consider a special type of such problems.",
                    "label": 0
                },
                {
                    "sent": "And the best way to look at it is from another.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spective the perspective of an investment problem where you have a bunch of experts, so they run.",
                    "label": 0
                },
                {
                    "sent": "Each one runs a block and you can look up the investment advice is and after following their advice you can check up on the performance of their advice from the stock market.",
                    "label": 0
                },
                {
                    "sent": "So what we assume is that the reward following each.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each expert's advice is stationary for long periods of time, but that sudden times and times that are unknown, the distribution of the reward is going to change, and the next distribution is going to be also unknown.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "You might have an expert who's who knows about vaccines and all of a sudden there's a flu outbreak, and if you follow that guy's advice after the flu outbreak, you might get a very good reward.",
                    "label": 0
                },
                {
                    "sent": "But before that he might not perform very well.",
                    "label": 0
                },
                {
                    "sent": "Hi, just a word of warning.",
                    "label": 0
                },
                {
                    "sent": "I'm not an expert in.",
                    "label": 0
                },
                {
                    "sent": "In flu vaccine or investment?",
                    "label": 0
                },
                {
                    "sent": "OK, so the way this problem?",
                    "label": 0
                },
                {
                    "sent": "Works more in detail is that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each time instant.",
                    "label": 0
                },
                {
                    "sent": "You choose an expert and you follow his advice and we introduce another concept of querying other people.",
                    "label": 0
                },
                {
                    "sent": "Other experts advices without actually following their advice.",
                    "label": 0
                },
                {
                    "sent": "And doing these two actions you.",
                    "label": 0
                },
                {
                    "sent": "Obtain the reward by following the experts advice and you also observe what the other experts that you queried advise you.",
                    "label": 1
                },
                {
                    "sent": "And there is a constraint that you don't have all the time in the world, so you cannot query every other expert out there.",
                    "label": 0
                },
                {
                    "sent": "So this can be incorporated into a cost of querying additional experts.",
                    "label": 0
                },
                {
                    "sent": "And the goal is actually quite simple.",
                    "label": 1
                },
                {
                    "sent": "You want to do as well as you could have done by if you had known.",
                    "label": 1
                },
                {
                    "sent": "What are the distributions of the rewards at every time instant.",
                    "label": 0
                },
                {
                    "sent": "So the reason why we choose this model is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "'cause in the multi armed bandit problem alot of people have looked at stationary case where the word distribution is fixed.",
                    "label": 0
                },
                {
                    "sent": "Overall time and other people have look at the adversarial case where they assume that an adversary is actually giving you the rewards.",
                    "label": 0
                },
                {
                    "sent": "But we're kind of interested in what happens in between the two because arguably in nature is not all the time stationary nor is it trying to screw you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, just some notation.",
                    "label": 0
                },
                {
                    "sent": "We're going to make vectors out of the rewards, and each vector is going to be.",
                    "label": 0
                },
                {
                    "sent": "Represent.",
                    "label": 0
                },
                {
                    "sent": "However, these elements, the rewards of the experts.",
                    "label": 0
                },
                {
                    "sent": "And we're going to denote the unknown changepoints by the news.",
                    "label": 0
                },
                {
                    "sent": "So, and we use better to denote the mean of the distribution that we don't know.",
                    "label": 0
                },
                {
                    "sent": "And just for simplicity, we assume that the rewards are from finite interval 01.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so a little bit more notation.",
                    "label": 0
                },
                {
                    "sent": "So the actions of the that you take following the advice is are going to be a 80s.",
                    "label": 0
                },
                {
                    "sent": "And the rewards that you get is BT of 80.",
                    "label": 0
                },
                {
                    "sent": "The observations they're going to be denoted by the set S. And the cost of your queries will depend on the number of queries you make, and it's going to be CQ of S.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the objective.",
                    "label": 0
                },
                {
                    "sent": "In precise terms, is that you want to do as well?",
                    "label": 0
                },
                {
                    "sent": "As if the reward distribution is going to be known in advance, and the way you measure this is.",
                    "label": 1
                },
                {
                    "sent": "Here you have the baseline where you know what are the words in advance.",
                    "label": 0
                },
                {
                    "sent": "You take the Max at every time instant.",
                    "label": 1
                },
                {
                    "sent": "And the other term is the expected reward you get.",
                    "label": 0
                },
                {
                    "sent": "Now if you include the cost of querying.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can you divide by you take the average overall time, then this expression.",
                    "label": 0
                },
                {
                    "sent": "Will be the average cost at every time step.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me just situate our model with respect to other well known problems.",
                    "label": 0
                },
                {
                    "sent": "So there's the stochastic multi armed bandit where.",
                    "label": 0
                },
                {
                    "sent": "There are no change point at all and you don't make additional queries.",
                    "label": 0
                },
                {
                    "sent": "This is very well known.",
                    "label": 0
                },
                {
                    "sent": "And in this case.",
                    "label": 0
                },
                {
                    "sent": "Because.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because there are no change points, you don't really need the benefit.",
                    "label": 0
                },
                {
                    "sent": "You don't reap many benefits from query on the side, and it's well known that.",
                    "label": 0
                },
                {
                    "sent": "The expected grade in this case is going to be linear in the number of experts and logarithmic at the time.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, there's also an adversarial version of this problem.",
                    "label": 0
                },
                {
                    "sent": "In this problem, you.",
                    "label": 0
                },
                {
                    "sent": "There can be arbitrarily many change points, so.",
                    "label": 1
                },
                {
                    "sent": "And also there are two versions of this, one in which you know the prediction.",
                    "label": 0
                },
                {
                    "sent": "You can actually query for free every other expert and another one where you don't have additional queries.",
                    "label": 1
                },
                {
                    "sent": "So for this problem, the notion of regret is actually.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different.",
                    "label": 0
                },
                {
                    "sent": "They're looking at a single action over all time.",
                    "label": 0
                },
                {
                    "sent": "For the baseline.",
                    "label": 0
                },
                {
                    "sent": "And in this problem also by adding the notion of queries you only have a little change.",
                    "label": 0
                },
                {
                    "sent": "Which is the term.",
                    "label": 0
                },
                {
                    "sent": "Poly polynomial term in the number of.",
                    "label": 0
                },
                {
                    "sent": "Experts now, in terms of our model, it has been studied by.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two other groups of people.",
                    "label": 0
                },
                {
                    "sent": "Harden and his colleagues they provided a partial solution when?",
                    "label": 1
                },
                {
                    "sent": "I wear the music they try to detect change this changes in the distribution of the best arm only.",
                    "label": 0
                },
                {
                    "sent": "The best expert only without regard to querying the other experts.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Get ivn moulinas moulinas.",
                    "label": 0
                },
                {
                    "sent": "Case where they assume that you know in advance how many change points you can expect.",
                    "label": 1
                },
                {
                    "sent": "And in this case, they show that a bunch of algorithms will give you.",
                    "label": 0
                },
                {
                    "sent": "A regret that's polynomial in T around square root.",
                    "label": 0
                },
                {
                    "sent": "And they also show that in this case, without additional queries, you have a lower bound of square root of T for the threat.",
                    "label": 0
                },
                {
                    "sent": "Now all contribution is to show that.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Avicide queries.",
                    "label": 0
                },
                {
                    "sent": "You can reduce the regret from polynomial square root of T to something that logarithmically.",
                    "label": 1
                },
                {
                    "sent": "And Moreover, our solution doesn't require prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "The number of change points that are to be expected.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK approach we take is that.",
                    "label": 0
                },
                {
                    "sent": "We're going to make an algorithm by combining 2 sub algorithms.",
                    "label": 0
                },
                {
                    "sent": "The first one is a standard algorithm for the multi and stochastic multi armed bandit problem.",
                    "label": 1
                },
                {
                    "sent": "For example, you can use the UCB.",
                    "label": 0
                },
                {
                    "sent": "Upper confidence bound type of algorithms.",
                    "label": 0
                },
                {
                    "sent": "And another side algorithm that sub algorithm that detects when you have a change in distribution.",
                    "label": 0
                },
                {
                    "sent": "So the naive way of detecting a change would be to use the so called.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optimal change detection algorithms so example of these are the Q Summon other algorithms, But these algorithms they had some drawbacks they're using.",
                    "label": 0
                },
                {
                    "sent": "Likelihood ratio tests and for these we actually have to know the prior and posterior distributions.",
                    "label": 0
                },
                {
                    "sent": "So our solution will use something much simpler.",
                    "label": 0
                },
                {
                    "sent": "We're going to.",
                    "label": 0
                },
                {
                    "sent": "Look at the empirical averages.",
                    "label": 1
                },
                {
                    "sent": "Of the rewards and try to detect changes in search.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Average is over.",
                    "label": 0
                },
                {
                    "sent": "Appropriate windows of times.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will propose is going to break the time into those of linked data.",
                    "label": 0
                },
                {
                    "sent": "Tao so basically this is a sequence of.",
                    "label": 0
                },
                {
                    "sent": "All of the rewards at all times and we just bring them at length of Tau.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Within each interval you basically just compute the average mean, thanks.",
                    "label": 0
                },
                {
                    "sent": "You compute this average mean based on the additional side queries.",
                    "label": 0
                },
                {
                    "sent": "And at every time step you just follow a UCB algorithm that basically looks at the average.",
                    "label": 1
                },
                {
                    "sent": "The empirical average of the rewards of each arm and chooses the one that has the best.",
                    "label": 0
                },
                {
                    "sent": "Such reward, modified by an extra term that.",
                    "label": 0
                },
                {
                    "sent": "Takes into account how many times you have sampled these experts.",
                    "label": 0
                },
                {
                    "sent": "And we query is very simple with query.",
                    "label": 0
                },
                {
                    "sent": "Each expert sequentially and approximately as many times each time.",
                    "label": 0
                },
                {
                    "sent": "Each expert as the others, and.",
                    "label": 0
                },
                {
                    "sent": "The way we detect changes, we set an epsilon and once the difference mean goes above the epsilon, which basically raise an alarm.",
                    "label": 0
                },
                {
                    "sent": "And we said.",
                    "label": 0
                },
                {
                    "sent": "The UCB algorithm doing.",
                    "label": 0
                },
                {
                    "sent": "That's choosing the experts.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the guarantee that we can provide.",
                    "label": 0
                },
                {
                    "sent": "Is that suppose every time distribution change occurs, we assume that you know.",
                    "label": 0
                },
                {
                    "sent": "There's a lower bound on the change, a lower bound of two epsilon, and based on this two epsilon, you can choose an appropriate length of the windows over which you compute the mean of the rewards, and after that you follow the previous album.",
                    "label": 0
                },
                {
                    "sent": "Can show that the regret will be.",
                    "label": 0
                },
                {
                    "sent": "Logarithmic in time and linear in both the number of.",
                    "label": 0
                },
                {
                    "sent": "Changes and the number of experts.",
                    "label": 0
                },
                {
                    "sent": "So this bound becomes meaningful when.",
                    "label": 0
                },
                {
                    "sent": "The key is actually much smaller or relatively smaller compared to T so that you have some linear regret.",
                    "label": 0
                },
                {
                    "sent": "So the proof is quite simple.",
                    "label": 0
                },
                {
                    "sent": "There are two components.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the regret, one comes from the delay in detecting when the change occurs and the other.",
                    "label": 1
                },
                {
                    "sent": "Is due to.",
                    "label": 1
                },
                {
                    "sent": "The number of times you reset the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And basically we bound these two quantities using tail probabilities and.",
                    "label": 0
                },
                {
                    "sent": "Pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can also show a lower bound, but this lower bound is is only works for algorithms that actually will tell you when the changes occur.",
                    "label": 1
                },
                {
                    "sent": "And for these, for this lower bound, we use a result that says.",
                    "label": 0
                },
                {
                    "sent": "You need logarithmic number of time steps in order to detect a change.",
                    "label": 0
                },
                {
                    "sent": "And these are.",
                    "label": 0
                },
                {
                    "sent": "This lower bound.",
                    "label": 0
                },
                {
                    "sent": "This result is based on the optimal change detection argument that such as COO summoned.",
                    "label": 0
                },
                {
                    "sent": "Sure we are Evan Roberts.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we also ran some experiments in which we looked at rewards that are Bernoulli random variables, whose parameter will change suddenly with.",
                    "label": 0
                },
                {
                    "sent": "So in this example we compare.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sometimes I'll do this comparison.",
                    "label": 0
                },
                {
                    "sent": "Doesn't tell you much, because for some algorithms we'll assume that they know the number of changes to come.",
                    "label": 1
                },
                {
                    "sent": "Where is our albums?",
                    "label": 0
                },
                {
                    "sent": "We assumed that.",
                    "label": 0
                },
                {
                    "sent": "It is allowed to take one side query.",
                    "label": 0
                },
                {
                    "sent": "At the time step.",
                    "label": 0
                },
                {
                    "sent": "So here you can see that.",
                    "label": 0
                },
                {
                    "sent": "The time these are the times vertical lines, they represent the times in which the true changes occur.",
                    "label": 0
                },
                {
                    "sent": "And the little little diamonds represent when you detect a change, thanks.",
                    "label": 0
                },
                {
                    "sent": "No after this.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "Like trade off the cost of querying, such as going on.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sign and reading somebody plug and investing time into checking how each expert performance versus the the the regret that you get.",
                    "label": 0
                },
                {
                    "sent": "And if you assume that each query costs constant, then you can do a simple optimization in the number of queries you should do at each time step.",
                    "label": 0
                },
                {
                    "sent": "And you can find the optimal one.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some open problems that are.",
                    "label": 0
                },
                {
                    "sent": "That are to be solved so there can be more fancier versions of querying the site experts the exposure you didn't follow, so I think you might be able to use some ideas from Francesco's talk I think.",
                    "label": 0
                },
                {
                    "sent": "Where they queried.",
                    "label": 0
                },
                {
                    "sent": "In the context of active learning.",
                    "label": 0
                },
                {
                    "sent": "And another possible version is where the queries might fail with a certain probability.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "Another model would be the case where you query 1st and then you query both experts and then you actually kind of follow the actions.",
                    "label": 0
                },
                {
                    "sent": "The advisors of both experts and you receive the best word of the two.",
                    "label": 1
                },
                {
                    "sent": "And there can be other models of.",
                    "label": 0
                },
                {
                    "sent": "The non non stationary reward so just one that follows Markovian dynamics as in the restless bandit problem.",
                    "label": 0
                },
                {
                    "sent": "And with this I'm going to thank you for coming.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Your mother is a Delta.",
                    "label": 0
                },
                {
                    "sent": "So I forgot to say that in the bound there is a constant term that depends on the minimum difference between the best expert and the second best experts average reward.",
                    "label": 0
                },
                {
                    "sent": "Um at all times for the whole company.",
                    "label": 0
                },
                {
                    "sent": "Nerd.",
                    "label": 0
                },
                {
                    "sent": "We don't need to know it a priority, but the bound will depend on the constant.",
                    "label": 0
                },
                {
                    "sent": "Within we did need to know the epsilon for the minimum change from 1 one time.",
                    "label": 0
                },
                {
                    "sent": "One time interval to another one.",
                    "label": 0
                },
                {
                    "sent": "But I think there we can avoid this kind of.",
                    "label": 0
                },
                {
                    "sent": "Assumption by using more sophisticated change detection algorithms.",
                    "label": 0
                },
                {
                    "sent": "Or maybe you're in your life.",
                    "label": 0
                },
                {
                    "sent": "Like before.",
                    "label": 0
                },
                {
                    "sent": "Independent.",
                    "label": 0
                },
                {
                    "sent": "Having a very progressive.",
                    "label": 0
                },
                {
                    "sent": "Regret.",
                    "label": 0
                },
                {
                    "sent": "Teen times number times.",
                    "label": 0
                },
                {
                    "sent": "Logan tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Music.",
                    "label": 0
                },
                {
                    "sent": "Found.",
                    "label": 0
                },
                {
                    "sent": "Try the question into that when you compare the lucky bounce about in the lunch is quality growth of tea.",
                    "label": 0
                },
                {
                    "sent": "Is it a fair comparison because it's?",
                    "label": 0
                },
                {
                    "sent": "It's not the same model because we have additional queries and they had to know in advance the number of changes they are expecting.",
                    "label": 0
                },
                {
                    "sent": "Which one is that you have lucky?",
                    "label": 0
                },
                {
                    "sent": "And if you optimize over 1000, probably.",
                    "label": 0
                },
                {
                    "sent": "It doesn't prove that you are gaining something.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I'd be happy to discuss a little bit later.",
                    "label": 0
                },
                {
                    "sent": "You discover.",
                    "label": 0
                },
                {
                    "sent": "Also doesn't seem to be consistent about the yes, and if you did.",
                    "label": 0
                },
                {
                    "sent": "Would you really done is you've introduced with Epsilon machine?",
                    "label": 0
                },
                {
                    "sent": "Epsilon away because you don't really need to switch.",
                    "label": 0
                },
                {
                    "sent": "So if you're up epsilon or.",
                    "label": 0
                },
                {
                    "sent": "Pok\u00e9mon door you might get something that's polynomial in time.",
                    "label": 0
                },
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "Absolutely.",
                    "label": 0
                },
                {
                    "sent": "And that's not.",
                    "label": 0
                },
                {
                    "sent": "Square one.",
                    "label": 0
                },
                {
                    "sent": "Double.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you.",
                    "label": 0
                }
            ]
        }
    }
}