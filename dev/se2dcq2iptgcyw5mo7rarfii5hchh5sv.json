{
    "id": "se2dcq2iptgcyw5mo7rarfii5hchh5sv",
    "title": "Privacy-Preserving Reinforcement Learning",
    "info": {
        "author": [
            "Jun Sakuma, Tokyo Institute of Technology"
        ],
        "published": "Aug. 4, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_sakuma_ppr/",
    "segmentation": [
        [
            "Thank you very much.",
            "My name is June.",
            "Stuck in my from Tokyo Institute of Technology and you see the joint work with Professor Quashie at also from Tokyo.",
            "Install Tech An with professor right from Rutgers University."
        ],
        [
            "Ann, let me introduce a motivating application fastball.",
            "Do you have a pointer?",
            "Thank you very much.",
            "Letter BA2 factories and to customers here an at each time step.",
            "The customer orders their job with sample probability and the job is processed at the factory with the fixed probability and there is a queue at the factory and the queue size of the queue is limited.",
            "So if heavy load the job might be redirected to the other factory.",
            "And factories obtained every word by processing a job at each time step about the fact we may suffers a large penalty if heavy loaded.",
            "So the problem of the problem over this setting is that healthy factory make decision to re Direct a job to the other factory or not to re direct an as you may know, this problem can be modeled as a Markov decision process.",
            "So this can be solved by a regular reinforcement learning."
        ],
        [
            "About if these two factories are in a competitive relationship, there might be problem on, for example, the frequency of orders from the customer and the speed of production at each factory might be desired to be kept private each other and debug log of each factory and the perfect pitch is obtained by processing.",
            "A job might be desired to be kept private, so in such a situation of privacy preservation.",
            "Between each agent to process or enforcement planning is required.",
            "An INFP.",
            "Each state variables an action.",
            "Variables and reward rewards are should not be shared between agent, but in the end of the protocol the land policy should be shared between agents."
        ],
        [
            "And to clarify what the private information between agent, we prepared two different types of private model.",
            "And the first one is called path shown by time, and in this Model 2 or more agents cannot have interact with the environment at the same time.",
            "And the privacy information in this model is the observation at some specific time without by agent.",
            "And this observation cannot be revealed to other agent."
        ],
        [
            "And the second model is called a partial by observation in FICC two or more agents can have can have interaction with the environment at the same time.",
            "And in this model, the perceptions of each agent is need to need to be kept private, and the space state space and action space in this model is defined to be mutually exclusive."
        ],
        [
            "OK, so let's see if existing renforcement learning algorithm can treat 5ACP serving setting.",
            "And in this case, let's be several engines having interaction with environment independently and in this setting all information absorbed by agent is centralized to a leader agent and the policy is learned by this leader agent and in this case privacy preservation is not achieved at all because all the leader isn't knows all information but the optimality of the policy might be.",
            "Result achieved becausw if as a learning algorithm used by leader agent guarantees some kind of optimality.",
            "On the other hand, if there are no interactions between agents, privacy is achieved.",
            "Privacy preservation is achieved completely, but the performance would be very bad.",
            "'cause there are no interactions between agent, especially when some collaboration behavior is required to achieve the task.",
            "Independent distributed reinforcement learning will not work well an as an intermediate setting.",
            "Distributed reinforcement learning is known.",
            "And in this setting, partial information observed by agent will be shared between agents and in this case the privacy is preserved partially.",
            "And automatically optimized it would be intermediate.",
            "And the emphasis of distributed manifold spent learning is put on for the reduction of the space complexity or reduction of the computational time.",
            "So, and this is not designed for the privacy preservation, so our motivation is to design A protocol to achieve which achieves the complete privacy preservation without sacrificing the optimality."
        ],
        [
            "Gay and basically our algorithm or protocol follows the traditional setting.",
            "Fabulous answer, Learning our vision, greedy action selection and which can be expanded to the Q learning or kilometer or TD, Lambda, or like Sam traditional algorithms.",
            "But in this talk we focus on this setting.",
            "And this is the old view of our protocol.",
            "And if it's includes A3 building blocks for security defaults, first one is a called homomorphic Rip system and second one is the random shares and the third one is a private comparison by secure function evaluation.",
            "So before taking a closer look at the each step of this protocol, I would like to introduce these building blocks for security."
        ],
        [
            "So in a public key crypt system, we need to prepare a pair of public key and secret key.",
            "And let's say there is an value M you want to you want to encrypt then to overtake the cipher you need to apply encryption function to N in feed.",
            "The public key is taken as input and to recover the cleartext to recover the message from Cipher C. You need to apply decryption function in which the secret key is taken out of the input and if we say the public key cryptosystem has homomorphic property, these two identities are satisfied in the first identity, the encryption of M1 multiplied by encryption or M2 responds to the encryption of M1 plus M2.",
            "And in the second identity, the encryption of M to the power of K corresponds to the encryption of KN.",
            "So these homomorphic properties are always asked to multiply or addition of cipher.",
            "So let's say you have some secret number and you encrypt the number by your own public key in, send the value to me.",
            "So from the cipher sent from you I cannot know what the true value is, but I can add.",
            "Any number to the cipher and I can multiply any number to the cipher.",
            "So let's say your secret number is a Q values and you send the encrypted cubers to me.",
            "Then I can update the Q values with these homomorphic property."
        ],
        [
            "K and the third one, the second one is a random shares.",
            "So let's say data secret, number X and public number N. And, um.",
            "When this secret number X, you split the secret number.",
            "X-22 numbers A&B and we call this the pair A&B are random shares when A&B distributes uniformly in the integer with satisfying that the air plus B = 2 X MoD N, for example."
        ],
        [
            "Assuming X = 6, The Secret X = 6 In the public number N = 23.",
            "Uh, you can split this secret X into 15 and 14 and this is going to be a random shares becausw.",
            "15 + 14 more 23 is 6.",
            "And Please remember that from random share one random shares.",
            "You cannot know what the secret is, but if you send this random share to the other party, this party can know what the secret is by adding two random shares."
        ],
        [
            "And the third one is private comparison.",
            "Let's say there are two agents and each agent has a private input X&Y.",
            "And what these agents are going to do is compare these two private inputs and to know which is greater.",
            "And without revealing their inputs.",
            "And this problem can be solved by secure function evaluation, which is a classical applicative in a secure protocol community.",
            "And secure functional evaluation allows us to all parties to evaluate a specified function.",
            "F biking taking their inputs.",
            "So if the secure function evaluation is designed specified for this tablet comparison at this private comparison problem can be solved by a secure function evaluation.",
            "And you may wonder why I do not implement the whole procedure renforcement learning by means of secure function evaluation.",
            "And it's technically and theoretically it's possible.",
            "But the problem here is that the secure function evaluation consumes a huge amount of computational time and communication load, so it's realistic.",
            "So what we did is.",
            "We most of the computation is carried out by means of the homomorphic property over the public equipped system and only for a small portion of the computation is carried out by means of secure function evaluation."
        ],
        [
            "OK, so let's take a closer look at that block code.",
            "In the first step.",
            "Q values are initialized."
        ],
        [
            "And in this talk, I focus on the partitioned by time model and during from time septic was able to tickle T1.",
            "Alice had interaction with the environment.",
            "And using these using ice observation, she can learn Q values.",
            "And after she learned."
        ],
        [
            "She generate a pair of public key and secret key and encrypt Q values and say."
        ],
        [
            "This table to bowl.",
            "And please bear in mind that Bob cannot know what I siskyou values are because this is encrypted."
        ],
        [
            "And next are.",
            "Take a look at observation from the environment and public action selection."
        ],
        [
            "So now Bob observes our state from embarrassment, and let's say is observed state is is 1."
        ],
        [
            "Now what Bob needs to do is to take a greedy action and to do take a greedy action.",
            "Bob need to know each Q value is greater, but he does not know which is greater because this is their encrypted."
        ],
        [
            "So Bob split these encrypted Q values into random shares and one random shares are sent to Alice Ann between Bob and Alice."
        ],
        [
            "Private comparison is performed."
        ],
        [
            "And as the outcome he knows which is greater and in the end he can take the grapes.",
            "And then he can take the greedy action.",
            "Let's say the greedy action is a one."
        ],
        [
            "OK, so next.",
            "Is a private update over Q values."
        ],
        [
            "So now what Bob needs to do is to update this Q value by taking the observed reverse as input.",
            "But this isn't regular update by fast learning.",
            "As you may know very well and this isn't the difference of the cables to the update, and the difference is added to the old Q value.",
            "But what he has now is only a encrypted Q values.",
            "So Bob need to use Sam Modificate modified.",
            "Update the equations to update encrypted Q bodies."
        ],
        [
            "Like this, so this is an encrypted Q value and this would be the difference of the encryption of the difference of Q values."
        ],
        [
            "So now I'm going to modify the encrypted value encrypted version of update equation."
        ],
        [
            "So first we prepare a two large integers KNL an air is multiplied to reward R and care is multiplied to both both sides of equation.",
            "And this is a performance such that all computation on this equation is closed in the integer becausw homomorphic Clip system can only take integers inputs."
        ],
        [
            "And then the Bulls both side of this update.",
            "Equation is encrypted and so this is an encryption of cada que and the right hand side is encryption of this quantity and this encryption of this quantity is divided into 3 parts by means of homomorphic property.",
            "And let's take a closer look at this part."
        ],
        [
            "An Alpha K Alpha gamma KN minus, I'll forget, is known to both parties, so this is public.",
            "And the encryption of RT.",
            "It can be computed by both becausw Bob observes.",
            "This reward by himself.",
            "And this encrypted Q values and it's encrypted values is held by bold.",
            "So after all, Bob can compute the encryption over K Delta Q by himself."
        ],
        [
            "So in the end, by applying this quantity to this equation, the new version of application for encrypting the Cuba is obtained like this and Bob can update the encrypted Q value without any knowledge about real Q value and without knowledge of a secret key."
        ],
        [
            "So and I did not mention in this talk about this political can be expanded for private by observation model.",
            "And if some great action selection and Q learning and also TD Lambda an kilometer can be.",
            "Is possible to by using this protocol?"
        ],
        [
            "OK, so let's go to the expense.",
            "Experimental parts.",
            "Um, this is a.",
            "This isn't problem of load balancing as I talked in the beginning of the presentation and with some probability our jobs is assigned to the factory and with some probability the job is processed at each time step and there's a limit on the queue and.",
            "Each factory can we direct our job to the other factory?",
            "And the state, state, state, state space is defined as a backlog of the queue.",
            "So it ranges from zero to five and action space is defined as the decision of the agent to Re dialect.",
            "A job or not to re direct Azure.",
            "And we word is defined as a summation of our cost for backlog and cost for redirection and cost for overflow.",
            "And the objective of this problem is to maximum the system rewards which is defined as a summation of the reward of factory a an factory B.",
            "And this is an online performance over three learning algorithms.",
            "The first one is independent distributed with enforcement learning.",
            "And the second is a distributed reinforcement learning in feature.",
            "Only reverse our share shared among agents, and the third one is a regular enforcement learning and privacy preserving reinforcement learning and.",
            "The behavior of these two protocols are completely the same and it is guaranteed guaranteed by the theorem.",
            "So in this.",
            "Independent distributor enforcement.",
            "Learning new cases.",
            "The performance is very bad because to achieve this task very well, the two factories need to collaborate each other.",
            "But in this setting agents do not have any communication, so the performance is not good.",
            "And on the other hand, in the regular enforcement learning an hour protocol, it achieves a very good performance an in in case of distributed when forssmann learning only reverse are shared shared between agents.",
            "So the performance is intermediate."
        ],
        [
            "And this is a detailed comparison of five approaches.",
            "So as I said in the previous slide, in the center renforcement learning centralized reinforcement learning, all information is shared.",
            "So privacy is not preserved at all, but the performance is very good.",
            "Annina distributed.",
            "Independent distributed when forcement learning.",
            "Privacy preservation is achieved perfectly about performance is very bad and in a distributed reinforcement learning there are intermediate results and in case of a protocol, privacy preserving reinforcement, learning in feet, Security protocol is adapted in the intermediate steps which achieves the perfect privacy, preservation and the optimality.",
            "But the problem here is that the computational time is much larger.",
            "Then existing protocols, existing reinforcement algorithms.",
            "This is because the secure function Evaluation Encrypt system is used to compute the Q values.",
            "But please look at this setting and in this case rainforest all all procedures of renforcement learning is implemented by means of secure function evaluation.",
            "In this case, privacy preservation ends optimality.",
            "Are is achieved together, but the computational time is much much better than the setting of privacy preserving reinforcement learning.",
            "This is because the computational load or secure function evaluation is very very large, so we can say that.",
            "Our protocol is not very fast, but we did very well, very we did.",
            "We did there more than this setting an we achieved the optimality and the privacy preservation together."
        ],
        [
            "Now I'm going to conclude my talk.",
            "We propose Darwin Forcement learning from private private observations and protocol achieves automatically as regular reinforcement learning algorithm does.",
            "An privacy preservation is guaranteed so vertically now.",
            "Also, I did not mention how the theorem is and the computational load is higher than regular enforcement.",
            "Learning about it works efficiently with 36 four states of 36 state for action problem.",
            "And the future for Future Works is improvement of scalability for sure and the other direction over research is the treatment of agents with competing weird functions.",
            "So in this experiment I showed in the previous slide what agent maximizes the summation of the.",
            "EJ Gentry worth, but in actual setting the if they need to keep keep privacy each other, their rewards might be also competitive so.",
            "I would like to.",
            "Pursue this research direction and in fish the game theoretic analysis will be required I guess and this is end my talk.",
            "Thank you very much.",
            "Time for a couple of questions.",
            "I'm not exactly sold on your motivational example and the reason is that the whole pie approach is known to be prompt malicious attacks, and it's not secure in that sense.",
            "This is a known resulting.",
            "And your motivational example is actually a scenario which is quite likely prone to attacks by the competitive environment.",
            "So I think that the amorphic encryption approaches for privacy version are very usable in this situation.",
            "We don't protect against inadvertent exposure to advise standard, but I I'm not exactly convinced they are the right technique to protect against malicious attacks.",
            "And my second question is about scalability because.",
            "There is a significant communication cost in setting up the keys, and you know all the exchanges.",
            "So is it really scalable in that sense?",
            "For the first question I'm I'm quite sure that our protocol is not secure against the malicious parties, so our.",
            "Up security proof is based on the same honest model, so I'm quite sure about your thing so.",
            "Uh-huh so, but it's possible to extend our protocol to against malicious party by using their noise proof by by using a commitment.",
            "But it's quite complicated and it's you know it's useless for presenting such a work in ICM conference.",
            "So my phone, now my proof is based on the center honest model as privacy preserving data mining research as does and for the second question.",
            "But was that?",
            "Scalability.",
            "He's an exchange, isn't."
        ],
        [
            "OK, and I'm also quite sure that this is not scalable, but the key exchange itself is not very time consuming.",
            "The problem here is that the.",
            "Anne."
        ],
        [
            "Problem here is that that secure function evaluation is used for choosing the greedy action.",
            "And it costs for example by.",
            "So it takes about one second to do one comparison, and for the other for the rest of the computation is not very time consuming, so the only problem is I think this is secure function validation and.",
            "If there is some good technique to do private comparison in other way, the schedule will be improved, this is.",
            "You're very quick, second Pascal.",
            "The other agent can only observe the actions that one agent is taking and also just see West State or she ends up in.",
            "Can we just infer something about the policy?",
            "And maybe if you function and so on about the other agent despite all of this machine?",
            "Yes, Anna."
        ],
        [
            "In this in this factory example, the agent can see what other agent action is and the state can be might be inferred from the sequence of taking actions.",
            "So you are sure.",
            "But let's say example that one agent only observes the state and the other agent only takes an action and this is possible in this framework.",
            "In such a situation, privacy is completely preserved, so our proof is based on that.",
            "What can be infirmed?",
            "What can be rebuilt for after the execution of this protocol?",
            "Is the policy itself and what can be infirmed from the sequence of actions?",
            "So Sarah itself is consistent but.",
            "I agree with you that some information might be infirmed from the sequence of actions.",
            "Sequence of the states cannot be observed by the other agent.",
            "State.",
            "I want the action of the other agent.",
            "Screw that, probably home 'cause we ended up in this state that maybe the other agent to this action and so on.",
            "So I don't think that you could ever have here something that will preserve completely privacy.",
            "So yes, the other isn't.",
            "Might infer something.",
            "But yes, you are right."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "My name is June.",
                    "label": 0
                },
                {
                    "sent": "Stuck in my from Tokyo Institute of Technology and you see the joint work with Professor Quashie at also from Tokyo.",
                    "label": 0
                },
                {
                    "sent": "Install Tech An with professor right from Rutgers University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ann, let me introduce a motivating application fastball.",
                    "label": 1
                },
                {
                    "sent": "Do you have a pointer?",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Letter BA2 factories and to customers here an at each time step.",
                    "label": 0
                },
                {
                    "sent": "The customer orders their job with sample probability and the job is processed at the factory with the fixed probability and there is a queue at the factory and the queue size of the queue is limited.",
                    "label": 0
                },
                {
                    "sent": "So if heavy load the job might be redirected to the other factory.",
                    "label": 1
                },
                {
                    "sent": "And factories obtained every word by processing a job at each time step about the fact we may suffers a large penalty if heavy loaded.",
                    "label": 1
                },
                {
                    "sent": "So the problem of the problem over this setting is that healthy factory make decision to re Direct a job to the other factory or not to re direct an as you may know, this problem can be modeled as a Markov decision process.",
                    "label": 0
                },
                {
                    "sent": "So this can be solved by a regular reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About if these two factories are in a competitive relationship, there might be problem on, for example, the frequency of orders from the customer and the speed of production at each factory might be desired to be kept private each other and debug log of each factory and the perfect pitch is obtained by processing.",
                    "label": 1
                },
                {
                    "sent": "A job might be desired to be kept private, so in such a situation of privacy preservation.",
                    "label": 0
                },
                {
                    "sent": "Between each agent to process or enforcement planning is required.",
                    "label": 0
                },
                {
                    "sent": "An INFP.",
                    "label": 0
                },
                {
                    "sent": "Each state variables an action.",
                    "label": 1
                },
                {
                    "sent": "Variables and reward rewards are should not be shared between agent, but in the end of the protocol the land policy should be shared between agents.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to clarify what the private information between agent, we prepared two different types of private model.",
                    "label": 0
                },
                {
                    "sent": "And the first one is called path shown by time, and in this Model 2 or more agents cannot have interact with the environment at the same time.",
                    "label": 1
                },
                {
                    "sent": "And the privacy information in this model is the observation at some specific time without by agent.",
                    "label": 0
                },
                {
                    "sent": "And this observation cannot be revealed to other agent.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second model is called a partial by observation in FICC two or more agents can have can have interaction with the environment at the same time.",
                    "label": 0
                },
                {
                    "sent": "And in this model, the perceptions of each agent is need to need to be kept private, and the space state space and action space in this model is defined to be mutually exclusive.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's see if existing renforcement learning algorithm can treat 5ACP serving setting.",
                    "label": 0
                },
                {
                    "sent": "And in this case, let's be several engines having interaction with environment independently and in this setting all information absorbed by agent is centralized to a leader agent and the policy is learned by this leader agent and in this case privacy preservation is not achieved at all because all the leader isn't knows all information but the optimality of the policy might be.",
                    "label": 0
                },
                {
                    "sent": "Result achieved becausw if as a learning algorithm used by leader agent guarantees some kind of optimality.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if there are no interactions between agents, privacy is achieved.",
                    "label": 0
                },
                {
                    "sent": "Privacy preservation is achieved completely, but the performance would be very bad.",
                    "label": 1
                },
                {
                    "sent": "'cause there are no interactions between agent, especially when some collaboration behavior is required to achieve the task.",
                    "label": 0
                },
                {
                    "sent": "Independent distributed reinforcement learning will not work well an as an intermediate setting.",
                    "label": 0
                },
                {
                    "sent": "Distributed reinforcement learning is known.",
                    "label": 0
                },
                {
                    "sent": "And in this setting, partial information observed by agent will be shared between agents and in this case the privacy is preserved partially.",
                    "label": 0
                },
                {
                    "sent": "And automatically optimized it would be intermediate.",
                    "label": 0
                },
                {
                    "sent": "And the emphasis of distributed manifold spent learning is put on for the reduction of the space complexity or reduction of the computational time.",
                    "label": 0
                },
                {
                    "sent": "So, and this is not designed for the privacy preservation, so our motivation is to design A protocol to achieve which achieves the complete privacy preservation without sacrificing the optimality.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gay and basically our algorithm or protocol follows the traditional setting.",
                    "label": 0
                },
                {
                    "sent": "Fabulous answer, Learning our vision, greedy action selection and which can be expanded to the Q learning or kilometer or TD, Lambda, or like Sam traditional algorithms.",
                    "label": 1
                },
                {
                    "sent": "But in this talk we focus on this setting.",
                    "label": 1
                },
                {
                    "sent": "And this is the old view of our protocol.",
                    "label": 0
                },
                {
                    "sent": "And if it's includes A3 building blocks for security defaults, first one is a called homomorphic Rip system and second one is the random shares and the third one is a private comparison by secure function evaluation.",
                    "label": 0
                },
                {
                    "sent": "So before taking a closer look at the each step of this protocol, I would like to introduce these building blocks for security.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in a public key crypt system, we need to prepare a pair of public key and secret key.",
                    "label": 1
                },
                {
                    "sent": "And let's say there is an value M you want to you want to encrypt then to overtake the cipher you need to apply encryption function to N in feed.",
                    "label": 0
                },
                {
                    "sent": "The public key is taken as input and to recover the cleartext to recover the message from Cipher C. You need to apply decryption function in which the secret key is taken out of the input and if we say the public key cryptosystem has homomorphic property, these two identities are satisfied in the first identity, the encryption of M1 multiplied by encryption or M2 responds to the encryption of M1 plus M2.",
                    "label": 0
                },
                {
                    "sent": "And in the second identity, the encryption of M to the power of K corresponds to the encryption of KN.",
                    "label": 1
                },
                {
                    "sent": "So these homomorphic properties are always asked to multiply or addition of cipher.",
                    "label": 0
                },
                {
                    "sent": "So let's say you have some secret number and you encrypt the number by your own public key in, send the value to me.",
                    "label": 0
                },
                {
                    "sent": "So from the cipher sent from you I cannot know what the true value is, but I can add.",
                    "label": 0
                },
                {
                    "sent": "Any number to the cipher and I can multiply any number to the cipher.",
                    "label": 0
                },
                {
                    "sent": "So let's say your secret number is a Q values and you send the encrypted cubers to me.",
                    "label": 0
                },
                {
                    "sent": "Then I can update the Q values with these homomorphic property.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "K and the third one, the second one is a random shares.",
                    "label": 0
                },
                {
                    "sent": "So let's say data secret, number X and public number N. And, um.",
                    "label": 0
                },
                {
                    "sent": "When this secret number X, you split the secret number.",
                    "label": 0
                },
                {
                    "sent": "X-22 numbers A&B and we call this the pair A&B are random shares when A&B distributes uniformly in the integer with satisfying that the air plus B = 2 X MoD N, for example.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assuming X = 6, The Secret X = 6 In the public number N = 23.",
                    "label": 0
                },
                {
                    "sent": "Uh, you can split this secret X into 15 and 14 and this is going to be a random shares becausw.",
                    "label": 0
                },
                {
                    "sent": "15 + 14 more 23 is 6.",
                    "label": 1
                },
                {
                    "sent": "And Please remember that from random share one random shares.",
                    "label": 1
                },
                {
                    "sent": "You cannot know what the secret is, but if you send this random share to the other party, this party can know what the secret is by adding two random shares.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the third one is private comparison.",
                    "label": 1
                },
                {
                    "sent": "Let's say there are two agents and each agent has a private input X&Y.",
                    "label": 0
                },
                {
                    "sent": "And what these agents are going to do is compare these two private inputs and to know which is greater.",
                    "label": 0
                },
                {
                    "sent": "And without revealing their inputs.",
                    "label": 0
                },
                {
                    "sent": "And this problem can be solved by secure function evaluation, which is a classical applicative in a secure protocol community.",
                    "label": 0
                },
                {
                    "sent": "And secure functional evaluation allows us to all parties to evaluate a specified function.",
                    "label": 1
                },
                {
                    "sent": "F biking taking their inputs.",
                    "label": 0
                },
                {
                    "sent": "So if the secure function evaluation is designed specified for this tablet comparison at this private comparison problem can be solved by a secure function evaluation.",
                    "label": 0
                },
                {
                    "sent": "And you may wonder why I do not implement the whole procedure renforcement learning by means of secure function evaluation.",
                    "label": 0
                },
                {
                    "sent": "And it's technically and theoretically it's possible.",
                    "label": 0
                },
                {
                    "sent": "But the problem here is that the secure function evaluation consumes a huge amount of computational time and communication load, so it's realistic.",
                    "label": 0
                },
                {
                    "sent": "So what we did is.",
                    "label": 0
                },
                {
                    "sent": "We most of the computation is carried out by means of the homomorphic property over the public equipped system and only for a small portion of the computation is carried out by means of secure function evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's take a closer look at that block code.",
                    "label": 0
                },
                {
                    "sent": "In the first step.",
                    "label": 0
                },
                {
                    "sent": "Q values are initialized.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this talk, I focus on the partitioned by time model and during from time septic was able to tickle T1.",
                    "label": 0
                },
                {
                    "sent": "Alice had interaction with the environment.",
                    "label": 0
                },
                {
                    "sent": "And using these using ice observation, she can learn Q values.",
                    "label": 0
                },
                {
                    "sent": "And after she learned.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She generate a pair of public key and secret key and encrypt Q values and say.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This table to bowl.",
                    "label": 0
                },
                {
                    "sent": "And please bear in mind that Bob cannot know what I siskyou values are because this is encrypted.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And next are.",
                    "label": 0
                },
                {
                    "sent": "Take a look at observation from the environment and public action selection.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now Bob observes our state from embarrassment, and let's say is observed state is is 1.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what Bob needs to do is to take a greedy action and to do take a greedy action.",
                    "label": 0
                },
                {
                    "sent": "Bob need to know each Q value is greater, but he does not know which is greater because this is their encrypted.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Bob split these encrypted Q values into random shares and one random shares are sent to Alice Ann between Bob and Alice.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Private comparison is performed.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as the outcome he knows which is greater and in the end he can take the grapes.",
                    "label": 0
                },
                {
                    "sent": "And then he can take the greedy action.",
                    "label": 0
                },
                {
                    "sent": "Let's say the greedy action is a one.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so next.",
                    "label": 0
                },
                {
                    "sent": "Is a private update over Q values.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now what Bob needs to do is to update this Q value by taking the observed reverse as input.",
                    "label": 0
                },
                {
                    "sent": "But this isn't regular update by fast learning.",
                    "label": 1
                },
                {
                    "sent": "As you may know very well and this isn't the difference of the cables to the update, and the difference is added to the old Q value.",
                    "label": 0
                },
                {
                    "sent": "But what he has now is only a encrypted Q values.",
                    "label": 0
                },
                {
                    "sent": "So Bob need to use Sam Modificate modified.",
                    "label": 1
                },
                {
                    "sent": "Update the equations to update encrypted Q bodies.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like this, so this is an encrypted Q value and this would be the difference of the encryption of the difference of Q values.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm going to modify the encrypted value encrypted version of update equation.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first we prepare a two large integers KNL an air is multiplied to reward R and care is multiplied to both both sides of equation.",
                    "label": 0
                },
                {
                    "sent": "And this is a performance such that all computation on this equation is closed in the integer becausw homomorphic Clip system can only take integers inputs.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then the Bulls both side of this update.",
                    "label": 0
                },
                {
                    "sent": "Equation is encrypted and so this is an encryption of cada que and the right hand side is encryption of this quantity and this encryption of this quantity is divided into 3 parts by means of homomorphic property.",
                    "label": 0
                },
                {
                    "sent": "And let's take a closer look at this part.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An Alpha K Alpha gamma KN minus, I'll forget, is known to both parties, so this is public.",
                    "label": 0
                },
                {
                    "sent": "And the encryption of RT.",
                    "label": 0
                },
                {
                    "sent": "It can be computed by both becausw Bob observes.",
                    "label": 0
                },
                {
                    "sent": "This reward by himself.",
                    "label": 0
                },
                {
                    "sent": "And this encrypted Q values and it's encrypted values is held by bold.",
                    "label": 0
                },
                {
                    "sent": "So after all, Bob can compute the encryption over K Delta Q by himself.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the end, by applying this quantity to this equation, the new version of application for encrypting the Cuba is obtained like this and Bob can update the encrypted Q value without any knowledge about real Q value and without knowledge of a secret key.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So and I did not mention in this talk about this political can be expanded for private by observation model.",
                    "label": 1
                },
                {
                    "sent": "And if some great action selection and Q learning and also TD Lambda an kilometer can be.",
                    "label": 0
                },
                {
                    "sent": "Is possible to by using this protocol?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's go to the expense.",
                    "label": 0
                },
                {
                    "sent": "Experimental parts.",
                    "label": 0
                },
                {
                    "sent": "Um, this is a.",
                    "label": 0
                },
                {
                    "sent": "This isn't problem of load balancing as I talked in the beginning of the presentation and with some probability our jobs is assigned to the factory and with some probability the job is processed at each time step and there's a limit on the queue and.",
                    "label": 1
                },
                {
                    "sent": "Each factory can we direct our job to the other factory?",
                    "label": 0
                },
                {
                    "sent": "And the state, state, state, state space is defined as a backlog of the queue.",
                    "label": 0
                },
                {
                    "sent": "So it ranges from zero to five and action space is defined as the decision of the agent to Re dialect.",
                    "label": 0
                },
                {
                    "sent": "A job or not to re direct Azure.",
                    "label": 0
                },
                {
                    "sent": "And we word is defined as a summation of our cost for backlog and cost for redirection and cost for overflow.",
                    "label": 1
                },
                {
                    "sent": "And the objective of this problem is to maximum the system rewards which is defined as a summation of the reward of factory a an factory B.",
                    "label": 0
                },
                {
                    "sent": "And this is an online performance over three learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "The first one is independent distributed with enforcement learning.",
                    "label": 0
                },
                {
                    "sent": "And the second is a distributed reinforcement learning in feature.",
                    "label": 0
                },
                {
                    "sent": "Only reverse our share shared among agents, and the third one is a regular enforcement learning and privacy preserving reinforcement learning and.",
                    "label": 0
                },
                {
                    "sent": "The behavior of these two protocols are completely the same and it is guaranteed guaranteed by the theorem.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                },
                {
                    "sent": "Independent distributor enforcement.",
                    "label": 0
                },
                {
                    "sent": "Learning new cases.",
                    "label": 0
                },
                {
                    "sent": "The performance is very bad because to achieve this task very well, the two factories need to collaborate each other.",
                    "label": 0
                },
                {
                    "sent": "But in this setting agents do not have any communication, so the performance is not good.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, in the regular enforcement learning an hour protocol, it achieves a very good performance an in in case of distributed when forssmann learning only reverse are shared shared between agents.",
                    "label": 0
                },
                {
                    "sent": "So the performance is intermediate.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a detailed comparison of five approaches.",
                    "label": 0
                },
                {
                    "sent": "So as I said in the previous slide, in the center renforcement learning centralized reinforcement learning, all information is shared.",
                    "label": 0
                },
                {
                    "sent": "So privacy is not preserved at all, but the performance is very good.",
                    "label": 0
                },
                {
                    "sent": "Annina distributed.",
                    "label": 0
                },
                {
                    "sent": "Independent distributed when forcement learning.",
                    "label": 0
                },
                {
                    "sent": "Privacy preservation is achieved perfectly about performance is very bad and in a distributed reinforcement learning there are intermediate results and in case of a protocol, privacy preserving reinforcement, learning in feet, Security protocol is adapted in the intermediate steps which achieves the perfect privacy, preservation and the optimality.",
                    "label": 0
                },
                {
                    "sent": "But the problem here is that the computational time is much larger.",
                    "label": 0
                },
                {
                    "sent": "Then existing protocols, existing reinforcement algorithms.",
                    "label": 0
                },
                {
                    "sent": "This is because the secure function Evaluation Encrypt system is used to compute the Q values.",
                    "label": 0
                },
                {
                    "sent": "But please look at this setting and in this case rainforest all all procedures of renforcement learning is implemented by means of secure function evaluation.",
                    "label": 0
                },
                {
                    "sent": "In this case, privacy preservation ends optimality.",
                    "label": 0
                },
                {
                    "sent": "Are is achieved together, but the computational time is much much better than the setting of privacy preserving reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "This is because the computational load or secure function evaluation is very very large, so we can say that.",
                    "label": 0
                },
                {
                    "sent": "Our protocol is not very fast, but we did very well, very we did.",
                    "label": 0
                },
                {
                    "sent": "We did there more than this setting an we achieved the optimality and the privacy preservation together.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to conclude my talk.",
                    "label": 0
                },
                {
                    "sent": "We propose Darwin Forcement learning from private private observations and protocol achieves automatically as regular reinforcement learning algorithm does.",
                    "label": 1
                },
                {
                    "sent": "An privacy preservation is guaranteed so vertically now.",
                    "label": 1
                },
                {
                    "sent": "Also, I did not mention how the theorem is and the computational load is higher than regular enforcement.",
                    "label": 1
                },
                {
                    "sent": "Learning about it works efficiently with 36 four states of 36 state for action problem.",
                    "label": 0
                },
                {
                    "sent": "And the future for Future Works is improvement of scalability for sure and the other direction over research is the treatment of agents with competing weird functions.",
                    "label": 0
                },
                {
                    "sent": "So in this experiment I showed in the previous slide what agent maximizes the summation of the.",
                    "label": 0
                },
                {
                    "sent": "EJ Gentry worth, but in actual setting the if they need to keep keep privacy each other, their rewards might be also competitive so.",
                    "label": 0
                },
                {
                    "sent": "I would like to.",
                    "label": 0
                },
                {
                    "sent": "Pursue this research direction and in fish the game theoretic analysis will be required I guess and this is end my talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Time for a couple of questions.",
                    "label": 0
                },
                {
                    "sent": "I'm not exactly sold on your motivational example and the reason is that the whole pie approach is known to be prompt malicious attacks, and it's not secure in that sense.",
                    "label": 0
                },
                {
                    "sent": "This is a known resulting.",
                    "label": 0
                },
                {
                    "sent": "And your motivational example is actually a scenario which is quite likely prone to attacks by the competitive environment.",
                    "label": 0
                },
                {
                    "sent": "So I think that the amorphic encryption approaches for privacy version are very usable in this situation.",
                    "label": 0
                },
                {
                    "sent": "We don't protect against inadvertent exposure to advise standard, but I I'm not exactly convinced they are the right technique to protect against malicious attacks.",
                    "label": 0
                },
                {
                    "sent": "And my second question is about scalability because.",
                    "label": 0
                },
                {
                    "sent": "There is a significant communication cost in setting up the keys, and you know all the exchanges.",
                    "label": 0
                },
                {
                    "sent": "So is it really scalable in that sense?",
                    "label": 0
                },
                {
                    "sent": "For the first question I'm I'm quite sure that our protocol is not secure against the malicious parties, so our.",
                    "label": 0
                },
                {
                    "sent": "Up security proof is based on the same honest model, so I'm quite sure about your thing so.",
                    "label": 0
                },
                {
                    "sent": "Uh-huh so, but it's possible to extend our protocol to against malicious party by using their noise proof by by using a commitment.",
                    "label": 0
                },
                {
                    "sent": "But it's quite complicated and it's you know it's useless for presenting such a work in ICM conference.",
                    "label": 0
                },
                {
                    "sent": "So my phone, now my proof is based on the center honest model as privacy preserving data mining research as does and for the second question.",
                    "label": 0
                },
                {
                    "sent": "But was that?",
                    "label": 0
                },
                {
                    "sent": "Scalability.",
                    "label": 0
                },
                {
                    "sent": "He's an exchange, isn't.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and I'm also quite sure that this is not scalable, but the key exchange itself is not very time consuming.",
                    "label": 0
                },
                {
                    "sent": "The problem here is that the.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem here is that that secure function evaluation is used for choosing the greedy action.",
                    "label": 1
                },
                {
                    "sent": "And it costs for example by.",
                    "label": 0
                },
                {
                    "sent": "So it takes about one second to do one comparison, and for the other for the rest of the computation is not very time consuming, so the only problem is I think this is secure function validation and.",
                    "label": 1
                },
                {
                    "sent": "If there is some good technique to do private comparison in other way, the schedule will be improved, this is.",
                    "label": 0
                },
                {
                    "sent": "You're very quick, second Pascal.",
                    "label": 0
                },
                {
                    "sent": "The other agent can only observe the actions that one agent is taking and also just see West State or she ends up in.",
                    "label": 0
                },
                {
                    "sent": "Can we just infer something about the policy?",
                    "label": 0
                },
                {
                    "sent": "And maybe if you function and so on about the other agent despite all of this machine?",
                    "label": 0
                },
                {
                    "sent": "Yes, Anna.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this in this factory example, the agent can see what other agent action is and the state can be might be inferred from the sequence of taking actions.",
                    "label": 0
                },
                {
                    "sent": "So you are sure.",
                    "label": 0
                },
                {
                    "sent": "But let's say example that one agent only observes the state and the other agent only takes an action and this is possible in this framework.",
                    "label": 0
                },
                {
                    "sent": "In such a situation, privacy is completely preserved, so our proof is based on that.",
                    "label": 0
                },
                {
                    "sent": "What can be infirmed?",
                    "label": 0
                },
                {
                    "sent": "What can be rebuilt for after the execution of this protocol?",
                    "label": 0
                },
                {
                    "sent": "Is the policy itself and what can be infirmed from the sequence of actions?",
                    "label": 0
                },
                {
                    "sent": "So Sarah itself is consistent but.",
                    "label": 0
                },
                {
                    "sent": "I agree with you that some information might be infirmed from the sequence of actions.",
                    "label": 0
                },
                {
                    "sent": "Sequence of the states cannot be observed by the other agent.",
                    "label": 0
                },
                {
                    "sent": "State.",
                    "label": 0
                },
                {
                    "sent": "I want the action of the other agent.",
                    "label": 0
                },
                {
                    "sent": "Screw that, probably home 'cause we ended up in this state that maybe the other agent to this action and so on.",
                    "label": 0
                },
                {
                    "sent": "So I don't think that you could ever have here something that will preserve completely privacy.",
                    "label": 0
                },
                {
                    "sent": "So yes, the other isn't.",
                    "label": 0
                },
                {
                    "sent": "Might infer something.",
                    "label": 0
                },
                {
                    "sent": "But yes, you are right.",
                    "label": 0
                }
            ]
        }
    }
}