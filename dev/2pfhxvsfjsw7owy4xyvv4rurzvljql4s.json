{
    "id": "2pfhxvsfjsw7owy4xyvv4rurzvljql4s",
    "title": "Generating Diverse Realistic Data Sets for Episode Mining",
    "info": {
        "author": [
            "Albrecht Zimmermann, KU Leuven"
        ],
        "published": "Jan. 16, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Data Mining->Temporal Data"
        ]
    },
    "url": "http://videolectures.net/ptdm2012_zimmermann_episode_mining/",
    "segmentation": [
        [
            "This is going to be a very different talk from what we just heard.",
            "But the reason that it's ended up in the workshop is because the description of the workshop specifically in talking about the disconnect between.",
            "The theory of data mining as we do that the University and the practical applications spoke to me.",
            "An I apologize to anybody who's listened to me talk in the last year because you probably noticed."
        ],
        [
            "3 already.",
            "'cause what happened to me is that at some point I was given some real life data.",
            "Pretty much for the first time in my research career, which took the form of timestamped event data.",
            "So you just have this long sequence of events.",
            "Each one has a timestamp and this is say for me or was for me an unusual mining setting because instead of a lot of supposedly independent instances that you can use.",
            "To mine on you have this one stream and you have to figure out how to derive patterns."
        ],
        [
            "This.",
            "And a couple of approaches.",
            "One is that you just take a sliding window of a certain size defined in terms of those time steps."
        ],
        [
            "Steps and you push it over there and you always count.",
            "Often something appears.",
            "And what you end up with then is quickly, as you might have seen, that for instance in the first window you have the A and the B as an episode, and then you slide the window over and you keep the same, maybe, but you can't."
        ],
        [
            "It again and then you continue."
        ],
        [
            "Doing this and."
        ],
        [
            "This can lead."
        ],
        [
            "Some overcounting, so this is a potential problem when you're counting those things so."
        ],
        [
            "Alternative is that you look at what they call minimal occurrences.",
            "We're just looking at the smallest window that contains such an episode, but there are a couple of others, so this mining approach is different from transactional mining.",
            "For instance, in the sense that.",
            "It's not entirely clear what an occurrence is.",
            "What in occurrences depends on which technique you use.",
            "And, well, I didn't know anything about the field when I had this data.",
            "So what I did was I took it off the shelf minor, which is actually rather difficult because there are not that many implementations out there and I played with a couple of parameter settings."
        ],
        [
            "And it turns out that I had no idea what to do with the resulting patterns.",
            "I got different amount of patterns, different shape patterns, and I had no idea whether they meant anything.",
            "And because I'm a firm believer in the Reese."
        ],
        [
            "Search of data mining.",
            "I then went to literature to get some guidance that helped me to figure out which of those patterns are important.",
            "And in a sense, what I found is that the literature doesn't give me this.",
            "There's not really guidance here that says, you know, we have this different semantics for finding episodes.",
            "This is the one that you should use in these situations.",
            "There is some little work on significance measures, but not very much and interesting Lee for me.",
            "Some people have proposed ways of identifying significant episodes.",
            "Do not pick up their own technique in the next paper, so they have the standalone proposal and say this is the way to do it.",
            "And then I write a paper a year later, but they're not using their own methods, so it's I didn't exactly know what I should use this.",
            "There is therefore also not a lot of guidance where in the output you find the relevant patterns.",
            "And there's no guarantees that the patterns that you are find have anything to do with what's in the data at all, and all this is the result of the last 15 years of research."
        ],
        [
            "And then spend some more time with the literature trying to figure out what the reason for this is, and the first reason that you can identify for the episode mining setting."
        ],
        [
            "Is that there are very few real life temporal datasets and a lot of those that are in existence are covered by NDA's, and this is actually an OSI Bethesda statement in the booklet that he says research that cannot be duplicated is not research, and there's actually the situation with a lot of this research that has been done on one real life data set and you can't get the data, so it's kind of difficult to run something else on it and to figure out where the similarities and differences of techniques are.",
            "Even if you could get the data however, real life data usually doesn't have any ground truth.",
            "You don't know what kind of patterns are in there.",
            "If it's unsupervised, which means you can run an algorithm on it, and you can use some statistical testing and then you get a bunch of patterns, but you still don't know whether this is actually what is in the data.",
            "Now what has been done is some post hoc evaluation by domain experts so that they mind patterns, and then they show them to experts and ask them whether those patterns are interesting.",
            "Whether those patterns are make sense.",
            "I believe I'm not an expert on this, but I believe that this is actually a very dangerous thing to do because you're going to the expert and you're saying listen my data mining algorithm created this is it meaningful, so you're biasing the expert already towards assuming that there's something in there.",
            "I would love to do, but I don't think it's possible to do is to get a couple of those experts just a random patterns and real patterns at them and see whether they can tell apart which is which.",
            "And this is opposed to class labels in supervised learning, which in many cases are not generated by saying listen.",
            "So we assume that this this class, do you agree?",
            "And then giving you the class label."
        ],
        [
            "That's actually a problem that not only the episode mining has, but that all of the unsupervised parents at mining pattern mining.",
            "It has that you have real life datasets where you don't know the ground truth."
        ],
        [
            "And.",
            "Well.",
            "As my supervisor set many years ago, I'm more of a practical guide, so I thought my solution is basically I'm going to generate artificial data, of which I know the patterns, and then I'm going to figure out whether you know techniques are able to recover them and whether particular techniques are better at recovering data in certain settings, and one that I've found, and this is also a work that was trying to establish this."
        ],
        [
            "Offensive patterns was a data generator in a paper by Laxman who was trying to relate the episodes that they could mine and Hmm's that could have generated them.",
            "And then, you know, give you a probability on the file patterns in terms of the learned hmm and then my idea was to extensively evaluate a lot of different techniques and or measures and develop guidelines.",
            "Simply tell you when.",
            "A certain method is supposed to work, and yeah, how well it actually recovered recovers the patterns that are in the data.",
            "Now."
        ],
        [
            "But now I've moved on a little bit because I think what I would actually do.",
            "And after admit that, I'm not entirely sure about this, so I invite you all to tell me that this might work or might not work at all.",
            "Is that you get some real life data, then use a data generator and you generate data that has the same characteristics and then you mind patterns on the artificial data and figure out how well your algorithm does where in the output the real patterns are and then use this to look at the real life data.",
            "Because if you just take this step, you take the real life data.",
            "You mind the patterns and then you have a lot of patterns there.",
            "There's nothing in between that actually helps you to real knowledge discovery from the patterns that you've that you've mined.",
            "So got work to work on this and the original generator that lacks my proposed."
        ],
        [
            "Gives you a couple of parameters that helps you control characteristics of the data, how many patterns there are in there, how big the patterns are.",
            "Pick the alphabet is how high the noise probability."
        ],
        [
            "Use, but even in this paper it's a very limited setting if you will.",
            "So for me the most interesting part is actually this that there is no no sharing of elements and an episode there's no repetition of elements.",
            "Episodes are explicitly interleaved, there always embedded concurrently, so that's a very specific setting that has been evaluated with this generator that exists.",
            "So I wanted to go beyond this and make this setting realistic."
        ],
        [
            "Now the thing with this is that the question is of course what is real."
        ],
        [
            "Stick and what I did is I took the data that I had and I took the information that the industry partners gave us so.",
            "My assumption is that I'm information matters and specifically my."
        ],
        [
            "Assumption is that.",
            "Episodes are probably time constraint so that when something happens in an episode, the next event, yeah is somehow time constrained to this event.",
            "It will not happen.",
            "You know, at some random point in time.",
            "And so this is something that I think should definitely be in the data.",
            "Then from what our partners have told us, there's a good chance that events are actually locked so that you have some episode that generates patterns in the data.",
            "But sometimes an event that route appear does not appear.",
            "There might be several patterns, of course, but it might be possible that those patterns are actually not do not have the same probability.",
            "Some of those might be very commonly occurring things.",
            "Some might be rarer, they might be interleaved.",
            "I don't disagree, but they don't necessarily have to be.",
            "They might occur successively because you might have a generating system like a machine, for instance, that had different states that might be working very well, might be degrading, might be about to breakdown, so the behavior might change, and I think that it's risky and probably not realistic to assume that noise distribution timestamp distribution that this stuff only happens in a uniform manner."
        ],
        [
            "So I added a lot of additional parameters to set up the data that I had."
        ],
        [
            "And then I use this to explore what happened on before and how those data compare.",
            "And so when you look at this, this is the data from Laxman's paper."
        ],
        [
            "With noise probability of zero point through three, by the way, and so you see that you have this very expressed block of events that belong to the patterns, and then you have a little bit of noise."
        ],
        [
            "In comparison with this.",
            "And this is from a paper by Nikolaj Tatti, where he mind closed episodes and wanted to demonstrate how it is possible to, well, pull the close episodes out of a pattern space that might include a lot of subsets that are related but are not significant.",
            "And this is how the data then looks that you actually have a very wide alphabet."
        ],
        [
            "And this small peak of very very very high expressed pattern.",
            "So those are two sets that have been used to to explore episode mining approaches in the."
        ],
        [
            "Literature.",
            "And then this is what I've gotten from the real life data, so it's it's slightly different."
        ],
        [
            "And distribution, which also makes me believe and I can't prove this, this is basically this is a bit of gut feeling and some empirical exploration, but basically I would assume that episode minor behaves very differently on this kind of data then on the data that has been used in prior papers or other real life datasets that maybe have different disk."
        ],
        [
            "Fusions now the question is of course whether I'm capable of rebuilding this.",
            "And this is also where a little bit becomes a little bit at hoc, because and this is a thing where it could be important that we get the kind of formalization done that the workshop talks about.",
            "It's kind of unclear whether you can how you recover the kind of data that you did.",
            "You see the color kind of phenomenon."
        ],
        [
            "You see, in real life data.",
            "So I started out just sticking with the uniform noise model, but changing a couple of things around, among other things, increasing the noise probably much higher than what has been done in the literature.",
            "And when I get something that looks less extreme than the artificial datasets but is still too abrupt."
        ],
        [
            "And then you can."
        ],
        [
            "Then you can give episode patterns different weights and you see how the distribution shift a little bit.",
            "And for instance how you can have an episode that's very weakly expressed because it's not very likely, but I'm still sticking with, you know."
        ],
        [
            "More noise and not until."
        ],
        [
            "At posso noise I'm starting to get something that looks closer to the real life data.",
            "It does look like the real life data, but it looks closer.",
            "So basically by varying a couple of parameters of this data generator I can get something that behaves kind of like the real life date."
        ],
        [
            "To have.",
            "Now this becomes harder for timestamps.",
            "This is from the original X men paper where basically time values are uniformly distributed and not enforced and you."
        ],
        [
            "That's what you see now.",
            "As soon as you enforce a maximum delay on the episodes, you see that it jumps quite a bit up because, well, you're pushing in.",
            "Pattern events at points where weather usually would not show up because, well, the time has come and you see that you get a very different distribution of timestamps.",
            "Which was actually what Rich was, however."
        ],
        [
            "But useless to me because this is how my real life data looks.",
            "So you have those peaks at multiples of 300, which actually go on with successively lower peaks to four and a half thousand.",
            "And so I figured looking at this that some kind of normally distributed noise."
        ],
        [
            "Might do the trick, but it turns out that when you do this, you get much higher peaks and for a lot of different variances actually and you get much narrower peaks, so just recovering the right kind of delays is a lot harder and I have to admit that I don't know enough about the statistics to go onto a principled track to figure out how I can recover the real life data that I have.",
            "That didn't stop me from doing it."
        ],
        [
            "Moments, however, and.",
            "What I've seen in the experiments is that when you have this when you have to stay there with those embedded patterns and actually with only a single embedded pattern, the first thing that I found very interesting is that the time constraint and how you set the time constraint seemed to be more important than the different matching semantics.",
            "So I've looked at the sliding Windows minimum occurrences, nonoverlapping patterns, non overlapping occurrences, and closed.",
            "Patterns and basically what you get is that the sliding window behaves pretty badly, but the other three behave very similarly and that the setting of the temporal constraint, the setting of what's the most in terms of maximum gaps or maximum windows that you use, seems to have a much bigger influence on what you get out there then the different matching semantics.",
            "Now, in the best case, the actual pattern was within the top 10.",
            "And this was really absolute best case, it quickly deteriorated for different settings.",
            "If you several patterns that can interleave, this becomes very quickly very hard.",
            "So that basically for all of those settings, either they're not capable of finding anything, or you have all of those patterns showing up somewhere in the in the low hundreds.",
            "And at this point, of course it becomes really, really difficult to sift through all the patterns that you would get on real life data and figure out.",
            "Where, where the actual patterns are that you want to see, and when I tried on the well it shouldn't say real life data, but the real life like data.",
            "What I saw is that the patterns quickly gets wiped out by a lot of other stuff that fills up before them, so you know each of the patterns might rank in the in the 90s student one hundreds.",
            "But there are a lot of other patterns in there or another lot of other episodes in there that look well as likely basically.",
            "So after seeing this I'm a bit dubious that episode mining will actually give you something useful.",
            "But on the other hand, if I see where the patterns show up on the real life, like data, well, I might just focus on this part of the output and say, OK, I forget everything that's highly ranked.",
            "Now I think."
        ],
        [
            "And this might be a bit optimistic that you could take the same thing and well, do it to other pattern mining approaches as well.",
            "Because when you look at itemset mining, for instance, we have pretty much the same situation.",
            "We have a lot of different.",
            "Well, we have not a lot, but we have more different datasets that are easily accessible on which item set mining has been done.",
            "But for most of those we have no idea what the underlying patterns are.",
            "We just know that you can mine patterns and we know ways of filtering them out, and you know doing significance testing and trying to figure out whether those things could be a fluke or not.",
            "But we don't know in the end whether we actually recovering the patterns that generated the data, and I've done some experiments on this that hinted that some of the measures that are currently used.",
            "I'm not very good at recovering the patterns that are actually in the data.",
            "I also think that it could be interesting to extend this to supervise data data to supervise settings, in part because I've heard the argument or fret the argument a couple of times that the UCI data set my data collection might not be good collection to do evaluation of supervised machine learning and data mining approaches, because some of those settings are very easy.",
            "A lot of those settings are much more balanced than you would expect in the real world and stuff like this.",
            "I just assumed that it would be a lot harder to generate data for a supervised setting.",
            "There is this line from cryptography and security research that everybody is smart enough to build a code to create a code that they themselves can't correct, and I think the same thing holds for supervised data that everybody is smart enough to build a model where he says, OK, this is not a simple model.",
            "You can't simply get this from looking at the data, but since we.",
            "Understand much less how supervised data comes to pause.",
            "This might still be much more challenging than what I'm trying to do.",
            "And that's basically it, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is going to be a very different talk from what we just heard.",
                    "label": 0
                },
                {
                    "sent": "But the reason that it's ended up in the workshop is because the description of the workshop specifically in talking about the disconnect between.",
                    "label": 0
                },
                {
                    "sent": "The theory of data mining as we do that the University and the practical applications spoke to me.",
                    "label": 1
                },
                {
                    "sent": "An I apologize to anybody who's listened to me talk in the last year because you probably noticed.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "3 already.",
                    "label": 0
                },
                {
                    "sent": "'cause what happened to me is that at some point I was given some real life data.",
                    "label": 0
                },
                {
                    "sent": "Pretty much for the first time in my research career, which took the form of timestamped event data.",
                    "label": 1
                },
                {
                    "sent": "So you just have this long sequence of events.",
                    "label": 0
                },
                {
                    "sent": "Each one has a timestamp and this is say for me or was for me an unusual mining setting because instead of a lot of supposedly independent instances that you can use.",
                    "label": 0
                },
                {
                    "sent": "To mine on you have this one stream and you have to figure out how to derive patterns.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "And a couple of approaches.",
                    "label": 0
                },
                {
                    "sent": "One is that you just take a sliding window of a certain size defined in terms of those time steps.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Steps and you push it over there and you always count.",
                    "label": 0
                },
                {
                    "sent": "Often something appears.",
                    "label": 0
                },
                {
                    "sent": "And what you end up with then is quickly, as you might have seen, that for instance in the first window you have the A and the B as an episode, and then you slide the window over and you keep the same, maybe, but you can't.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It again and then you continue.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing this and.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This can lead.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some overcounting, so this is a potential problem when you're counting those things so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alternative is that you look at what they call minimal occurrences.",
                    "label": 0
                },
                {
                    "sent": "We're just looking at the smallest window that contains such an episode, but there are a couple of others, so this mining approach is different from transactional mining.",
                    "label": 0
                },
                {
                    "sent": "For instance, in the sense that.",
                    "label": 0
                },
                {
                    "sent": "It's not entirely clear what an occurrence is.",
                    "label": 0
                },
                {
                    "sent": "What in occurrences depends on which technique you use.",
                    "label": 0
                },
                {
                    "sent": "And, well, I didn't know anything about the field when I had this data.",
                    "label": 0
                },
                {
                    "sent": "So what I did was I took it off the shelf minor, which is actually rather difficult because there are not that many implementations out there and I played with a couple of parameter settings.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it turns out that I had no idea what to do with the resulting patterns.",
                    "label": 1
                },
                {
                    "sent": "I got different amount of patterns, different shape patterns, and I had no idea whether they meant anything.",
                    "label": 0
                },
                {
                    "sent": "And because I'm a firm believer in the Reese.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Search of data mining.",
                    "label": 0
                },
                {
                    "sent": "I then went to literature to get some guidance that helped me to figure out which of those patterns are important.",
                    "label": 0
                },
                {
                    "sent": "And in a sense, what I found is that the literature doesn't give me this.",
                    "label": 0
                },
                {
                    "sent": "There's not really guidance here that says, you know, we have this different semantics for finding episodes.",
                    "label": 0
                },
                {
                    "sent": "This is the one that you should use in these situations.",
                    "label": 0
                },
                {
                    "sent": "There is some little work on significance measures, but not very much and interesting Lee for me.",
                    "label": 0
                },
                {
                    "sent": "Some people have proposed ways of identifying significant episodes.",
                    "label": 0
                },
                {
                    "sent": "Do not pick up their own technique in the next paper, so they have the standalone proposal and say this is the way to do it.",
                    "label": 0
                },
                {
                    "sent": "And then I write a paper a year later, but they're not using their own methods, so it's I didn't exactly know what I should use this.",
                    "label": 0
                },
                {
                    "sent": "There is therefore also not a lot of guidance where in the output you find the relevant patterns.",
                    "label": 1
                },
                {
                    "sent": "And there's no guarantees that the patterns that you are find have anything to do with what's in the data at all, and all this is the result of the last 15 years of research.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then spend some more time with the literature trying to figure out what the reason for this is, and the first reason that you can identify for the episode mining setting.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that there are very few real life temporal datasets and a lot of those that are in existence are covered by NDA's, and this is actually an OSI Bethesda statement in the booklet that he says research that cannot be duplicated is not research, and there's actually the situation with a lot of this research that has been done on one real life data set and you can't get the data, so it's kind of difficult to run something else on it and to figure out where the similarities and differences of techniques are.",
                    "label": 0
                },
                {
                    "sent": "Even if you could get the data however, real life data usually doesn't have any ground truth.",
                    "label": 0
                },
                {
                    "sent": "You don't know what kind of patterns are in there.",
                    "label": 0
                },
                {
                    "sent": "If it's unsupervised, which means you can run an algorithm on it, and you can use some statistical testing and then you get a bunch of patterns, but you still don't know whether this is actually what is in the data.",
                    "label": 0
                },
                {
                    "sent": "Now what has been done is some post hoc evaluation by domain experts so that they mind patterns, and then they show them to experts and ask them whether those patterns are interesting.",
                    "label": 1
                },
                {
                    "sent": "Whether those patterns are make sense.",
                    "label": 0
                },
                {
                    "sent": "I believe I'm not an expert on this, but I believe that this is actually a very dangerous thing to do because you're going to the expert and you're saying listen my data mining algorithm created this is it meaningful, so you're biasing the expert already towards assuming that there's something in there.",
                    "label": 0
                },
                {
                    "sent": "I would love to do, but I don't think it's possible to do is to get a couple of those experts just a random patterns and real patterns at them and see whether they can tell apart which is which.",
                    "label": 1
                },
                {
                    "sent": "And this is opposed to class labels in supervised learning, which in many cases are not generated by saying listen.",
                    "label": 0
                },
                {
                    "sent": "So we assume that this this class, do you agree?",
                    "label": 0
                },
                {
                    "sent": "And then giving you the class label.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's actually a problem that not only the episode mining has, but that all of the unsupervised parents at mining pattern mining.",
                    "label": 0
                },
                {
                    "sent": "It has that you have real life datasets where you don't know the ground truth.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "As my supervisor set many years ago, I'm more of a practical guide, so I thought my solution is basically I'm going to generate artificial data, of which I know the patterns, and then I'm going to figure out whether you know techniques are able to recover them and whether particular techniques are better at recovering data in certain settings, and one that I've found, and this is also a work that was trying to establish this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Offensive patterns was a data generator in a paper by Laxman who was trying to relate the episodes that they could mine and Hmm's that could have generated them.",
                    "label": 0
                },
                {
                    "sent": "And then, you know, give you a probability on the file patterns in terms of the learned hmm and then my idea was to extensively evaluate a lot of different techniques and or measures and develop guidelines.",
                    "label": 1
                },
                {
                    "sent": "Simply tell you when.",
                    "label": 0
                },
                {
                    "sent": "A certain method is supposed to work, and yeah, how well it actually recovered recovers the patterns that are in the data.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But now I've moved on a little bit because I think what I would actually do.",
                    "label": 0
                },
                {
                    "sent": "And after admit that, I'm not entirely sure about this, so I invite you all to tell me that this might work or might not work at all.",
                    "label": 0
                },
                {
                    "sent": "Is that you get some real life data, then use a data generator and you generate data that has the same characteristics and then you mind patterns on the artificial data and figure out how well your algorithm does where in the output the real patterns are and then use this to look at the real life data.",
                    "label": 1
                },
                {
                    "sent": "Because if you just take this step, you take the real life data.",
                    "label": 0
                },
                {
                    "sent": "You mind the patterns and then you have a lot of patterns there.",
                    "label": 0
                },
                {
                    "sent": "There's nothing in between that actually helps you to real knowledge discovery from the patterns that you've that you've mined.",
                    "label": 0
                },
                {
                    "sent": "So got work to work on this and the original generator that lacks my proposed.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gives you a couple of parameters that helps you control characteristics of the data, how many patterns there are in there, how big the patterns are.",
                    "label": 0
                },
                {
                    "sent": "Pick the alphabet is how high the noise probability.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use, but even in this paper it's a very limited setting if you will.",
                    "label": 0
                },
                {
                    "sent": "So for me the most interesting part is actually this that there is no no sharing of elements and an episode there's no repetition of elements.",
                    "label": 0
                },
                {
                    "sent": "Episodes are explicitly interleaved, there always embedded concurrently, so that's a very specific setting that has been evaluated with this generator that exists.",
                    "label": 0
                },
                {
                    "sent": "So I wanted to go beyond this and make this setting realistic.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the thing with this is that the question is of course what is real.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stick and what I did is I took the data that I had and I took the information that the industry partners gave us so.",
                    "label": 0
                },
                {
                    "sent": "My assumption is that I'm information matters and specifically my.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assumption is that.",
                    "label": 0
                },
                {
                    "sent": "Episodes are probably time constraint so that when something happens in an episode, the next event, yeah is somehow time constrained to this event.",
                    "label": 0
                },
                {
                    "sent": "It will not happen.",
                    "label": 0
                },
                {
                    "sent": "You know, at some random point in time.",
                    "label": 0
                },
                {
                    "sent": "And so this is something that I think should definitely be in the data.",
                    "label": 0
                },
                {
                    "sent": "Then from what our partners have told us, there's a good chance that events are actually locked so that you have some episode that generates patterns in the data.",
                    "label": 0
                },
                {
                    "sent": "But sometimes an event that route appear does not appear.",
                    "label": 0
                },
                {
                    "sent": "There might be several patterns, of course, but it might be possible that those patterns are actually not do not have the same probability.",
                    "label": 1
                },
                {
                    "sent": "Some of those might be very commonly occurring things.",
                    "label": 0
                },
                {
                    "sent": "Some might be rarer, they might be interleaved.",
                    "label": 0
                },
                {
                    "sent": "I don't disagree, but they don't necessarily have to be.",
                    "label": 0
                },
                {
                    "sent": "They might occur successively because you might have a generating system like a machine, for instance, that had different states that might be working very well, might be degrading, might be about to breakdown, so the behavior might change, and I think that it's risky and probably not realistic to assume that noise distribution timestamp distribution that this stuff only happens in a uniform manner.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I added a lot of additional parameters to set up the data that I had.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I use this to explore what happened on before and how those data compare.",
                    "label": 0
                },
                {
                    "sent": "And so when you look at this, this is the data from Laxman's paper.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With noise probability of zero point through three, by the way, and so you see that you have this very expressed block of events that belong to the patterns, and then you have a little bit of noise.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In comparison with this.",
                    "label": 0
                },
                {
                    "sent": "And this is from a paper by Nikolaj Tatti, where he mind closed episodes and wanted to demonstrate how it is possible to, well, pull the close episodes out of a pattern space that might include a lot of subsets that are related but are not significant.",
                    "label": 0
                },
                {
                    "sent": "And this is how the data then looks that you actually have a very wide alphabet.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this small peak of very very very high expressed pattern.",
                    "label": 0
                },
                {
                    "sent": "So those are two sets that have been used to to explore episode mining approaches in the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Literature.",
                    "label": 0
                },
                {
                    "sent": "And then this is what I've gotten from the real life data, so it's it's slightly different.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And distribution, which also makes me believe and I can't prove this, this is basically this is a bit of gut feeling and some empirical exploration, but basically I would assume that episode minor behaves very differently on this kind of data then on the data that has been used in prior papers or other real life datasets that maybe have different disk.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fusions now the question is of course whether I'm capable of rebuilding this.",
                    "label": 0
                },
                {
                    "sent": "And this is also where a little bit becomes a little bit at hoc, because and this is a thing where it could be important that we get the kind of formalization done that the workshop talks about.",
                    "label": 0
                },
                {
                    "sent": "It's kind of unclear whether you can how you recover the kind of data that you did.",
                    "label": 0
                },
                {
                    "sent": "You see the color kind of phenomenon.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see, in real life data.",
                    "label": 0
                },
                {
                    "sent": "So I started out just sticking with the uniform noise model, but changing a couple of things around, among other things, increasing the noise probably much higher than what has been done in the literature.",
                    "label": 0
                },
                {
                    "sent": "And when I get something that looks less extreme than the artificial datasets but is still too abrupt.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you can give episode patterns different weights and you see how the distribution shift a little bit.",
                    "label": 0
                },
                {
                    "sent": "And for instance how you can have an episode that's very weakly expressed because it's not very likely, but I'm still sticking with, you know.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More noise and not until.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At posso noise I'm starting to get something that looks closer to the real life data.",
                    "label": 0
                },
                {
                    "sent": "It does look like the real life data, but it looks closer.",
                    "label": 0
                },
                {
                    "sent": "So basically by varying a couple of parameters of this data generator I can get something that behaves kind of like the real life date.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To have.",
                    "label": 0
                },
                {
                    "sent": "Now this becomes harder for timestamps.",
                    "label": 1
                },
                {
                    "sent": "This is from the original X men paper where basically time values are uniformly distributed and not enforced and you.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's what you see now.",
                    "label": 0
                },
                {
                    "sent": "As soon as you enforce a maximum delay on the episodes, you see that it jumps quite a bit up because, well, you're pushing in.",
                    "label": 0
                },
                {
                    "sent": "Pattern events at points where weather usually would not show up because, well, the time has come and you see that you get a very different distribution of timestamps.",
                    "label": 0
                },
                {
                    "sent": "Which was actually what Rich was, however.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But useless to me because this is how my real life data looks.",
                    "label": 1
                },
                {
                    "sent": "So you have those peaks at multiples of 300, which actually go on with successively lower peaks to four and a half thousand.",
                    "label": 0
                },
                {
                    "sent": "And so I figured looking at this that some kind of normally distributed noise.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might do the trick, but it turns out that when you do this, you get much higher peaks and for a lot of different variances actually and you get much narrower peaks, so just recovering the right kind of delays is a lot harder and I have to admit that I don't know enough about the statistics to go onto a principled track to figure out how I can recover the real life data that I have.",
                    "label": 0
                },
                {
                    "sent": "That didn't stop me from doing it.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moments, however, and.",
                    "label": 0
                },
                {
                    "sent": "What I've seen in the experiments is that when you have this when you have to stay there with those embedded patterns and actually with only a single embedded pattern, the first thing that I found very interesting is that the time constraint and how you set the time constraint seemed to be more important than the different matching semantics.",
                    "label": 0
                },
                {
                    "sent": "So I've looked at the sliding Windows minimum occurrences, nonoverlapping patterns, non overlapping occurrences, and closed.",
                    "label": 0
                },
                {
                    "sent": "Patterns and basically what you get is that the sliding window behaves pretty badly, but the other three behave very similarly and that the setting of the temporal constraint, the setting of what's the most in terms of maximum gaps or maximum windows that you use, seems to have a much bigger influence on what you get out there then the different matching semantics.",
                    "label": 0
                },
                {
                    "sent": "Now, in the best case, the actual pattern was within the top 10.",
                    "label": 1
                },
                {
                    "sent": "And this was really absolute best case, it quickly deteriorated for different settings.",
                    "label": 0
                },
                {
                    "sent": "If you several patterns that can interleave, this becomes very quickly very hard.",
                    "label": 1
                },
                {
                    "sent": "So that basically for all of those settings, either they're not capable of finding anything, or you have all of those patterns showing up somewhere in the in the low hundreds.",
                    "label": 1
                },
                {
                    "sent": "And at this point, of course it becomes really, really difficult to sift through all the patterns that you would get on real life data and figure out.",
                    "label": 0
                },
                {
                    "sent": "Where, where the actual patterns are that you want to see, and when I tried on the well it shouldn't say real life data, but the real life like data.",
                    "label": 0
                },
                {
                    "sent": "What I saw is that the patterns quickly gets wiped out by a lot of other stuff that fills up before them, so you know each of the patterns might rank in the in the 90s student one hundreds.",
                    "label": 0
                },
                {
                    "sent": "But there are a lot of other patterns in there or another lot of other episodes in there that look well as likely basically.",
                    "label": 0
                },
                {
                    "sent": "So after seeing this I'm a bit dubious that episode mining will actually give you something useful.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, if I see where the patterns show up on the real life, like data, well, I might just focus on this part of the output and say, OK, I forget everything that's highly ranked.",
                    "label": 0
                },
                {
                    "sent": "Now I think.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this might be a bit optimistic that you could take the same thing and well, do it to other pattern mining approaches as well.",
                    "label": 0
                },
                {
                    "sent": "Because when you look at itemset mining, for instance, we have pretty much the same situation.",
                    "label": 1
                },
                {
                    "sent": "We have a lot of different.",
                    "label": 0
                },
                {
                    "sent": "Well, we have not a lot, but we have more different datasets that are easily accessible on which item set mining has been done.",
                    "label": 0
                },
                {
                    "sent": "But for most of those we have no idea what the underlying patterns are.",
                    "label": 0
                },
                {
                    "sent": "We just know that you can mine patterns and we know ways of filtering them out, and you know doing significance testing and trying to figure out whether those things could be a fluke or not.",
                    "label": 0
                },
                {
                    "sent": "But we don't know in the end whether we actually recovering the patterns that generated the data, and I've done some experiments on this that hinted that some of the measures that are currently used.",
                    "label": 0
                },
                {
                    "sent": "I'm not very good at recovering the patterns that are actually in the data.",
                    "label": 0
                },
                {
                    "sent": "I also think that it could be interesting to extend this to supervise data data to supervise settings, in part because I've heard the argument or fret the argument a couple of times that the UCI data set my data collection might not be good collection to do evaluation of supervised machine learning and data mining approaches, because some of those settings are very easy.",
                    "label": 0
                },
                {
                    "sent": "A lot of those settings are much more balanced than you would expect in the real world and stuff like this.",
                    "label": 0
                },
                {
                    "sent": "I just assumed that it would be a lot harder to generate data for a supervised setting.",
                    "label": 1
                },
                {
                    "sent": "There is this line from cryptography and security research that everybody is smart enough to build a code to create a code that they themselves can't correct, and I think the same thing holds for supervised data that everybody is smart enough to build a model where he says, OK, this is not a simple model.",
                    "label": 0
                },
                {
                    "sent": "You can't simply get this from looking at the data, but since we.",
                    "label": 0
                },
                {
                    "sent": "Understand much less how supervised data comes to pause.",
                    "label": 0
                },
                {
                    "sent": "This might still be much more challenging than what I'm trying to do.",
                    "label": 0
                },
                {
                    "sent": "And that's basically it, thank you.",
                    "label": 0
                }
            ]
        }
    }
}