{
    "id": "3pdqicrq5k5tbdnobdmtfe6lslqei7ns",
    "title": "Marrying Graphical Models & Deep Learning",
    "info": {
        "author": [
            "Max Welling, Informatics Institute, University of Amsterdam"
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_welling_inference/",
    "segmentation": [
        [
            "So today I'm going to talk about.",
            "Graphical models and their relationship to deep learning.",
            "So maybe a bit different than what you've heard, but there's also going to be a lot of overlap because of the variational inference parts."
        ],
        [
            "Here is the overview is this.",
            "Can you read this?",
            "So I'm going to 1st talk about a little bit about machine learning as statistics, not as optimization only.",
            "And then I'm going to talk a bit about.",
            "I just give you a very simple introduction, very quick introduction into graphical models.",
            "So that did people already somebody already teach about graphical models in general is just.",
            "Yeah, did you retaliate?",
            "A minute lecture intro to OK, so that's OK.",
            "It's going to be a little bit of repetition, nothing, but it's good to hear it from different perspectives.",
            "Then I'm going to talk a little bit about inference.",
            "Variational inference in that MCMC.",
            "And then learning expectation maximization, amortized iemon variational autoencoder just a little bit because we already had that as well.",
            "Going to talk about generative versus discriminative modeling, pros and cons and why they're both important.",
            "Then we're going to talk about very, very briefly say few words about deep learning.",
            "CNN's yeah, I'm sure it's been covered extensively and just say one word about dropout because we need it.",
            "Then in the last part of the lecture, which is about Bayesian inference, which is basically an application of how graphical models, Bayesian statistics and deep learning can be combined and actually can be applied to something very cool, which I think is is compression.",
            "And there's some surprising results."
        ],
        [
            "OK, so.",
            "Oftentimes, deep learning is seen perhaps as an optimization problem, which is you have an objective.",
            "You have a data set, and then you should try as hard as you can to optimize the objective, and then actually often you know you train for a week and the learning curve still goes becomes better and better right?",
            "So this is a new way.",
            "This is it didn't used to be like that and statistics is not like that.",
            "So there's clearly a strong case to be made that optimization is extremely important for deep learning, but I want to sort of emphasize that a learning problem is more than just an optimization problem.",
            "So in this case, let's say we have some data.",
            "Here we have some X&Y's X being the inputs by being the labels, perhaps which are drawn from a joint distribution.",
            "Right and then you know, I can write down some likelihood function here.",
            "Maybe the log likelihood of the data given the parameters.",
            "This could be an unsupervised learning problem and then we maximize over the parameters.",
            "We could look at a supervised learning problem where we look at the conditional distribution of Y given X for X.",
            "Is the input wise.",
            "The labels you know there could be a hidden there could be a deep net sort of lurking inside here for instance.",
            "And then we maximize over the parameters.",
            "Or we could more generally define some kind of loss function where we try to match the label to the prediction of that label as you pull Y hat.",
            "Now, why is it more than an optimization problem, right?",
            "So that's the question we want to answer now.",
            "So let's so first of all, we assume that the data is drawn from some sort of a data distribution, let's say IID drawn.",
            "But we only get to see one sample of that data distribution.",
            "And so I could imagine sort of drawing multiple datasets from that distribution fee.",
            "Right now, let's imagine that every one of those you know, let's say 10 different datasets.",
            "I would sort of do my optimization right, and I would get the optimal parameters Theta for that particular sort of data set.",
            "Now, since these datasets are slightly different because it randomly drawn also the optimal parameters are going to be slightly different, right?",
            "So there's going to be sort of a distribution of maximum likelihood estimates in this parameter space.",
            "So one question you can ask yourself, does it make sense to maximize further than this sort of shape of this distribution, right?",
            "So if we have like sort of a let's say it's distributed like a normal distribution with a certain variance.",
            "You know, and we know that there's this sort of distribution over parameters.",
            "Now for our if we look at one particular data set, does it make sense to you know, once you enter that region to sort of try to actually optimize all the way down to the sort of the mean of that distribution?",
            "And my argument is no, you don't, because that's exactly when you start to overfit on your distribution, right?",
            "Because if you only seen one of these datasets, it could have been another one, and so the fluctuations.",
            "That you get in these Emily estimates basically determine the scale at which you should sort of optimize."
        ],
        [
            "So you can think of that as a bias variance tradeoff, which I think is you know if you want to take one thing one thing away from this lecture, or basically your summer school, then it's the bias variance tradeoff.",
            "I think that's to the very very core of machine learning, and it has to do with this statistical nature.",
            "And it has to do with overfitting and generalization in general.",
            "So the idea is that you can imagine trying to, you know, let's say you build a machine that's trying to throw darts in a target, right?",
            "So he's a target these four targets.",
            "And you know the machine might be a bit wiggly because it's you know it's an unstable underground or something like that, which means that you might not.",
            "Every time you shoot a dart it might not hit the target at the same spot.",
            "Also, there might be a systematic mistake in this machine and error which which means that actually you know the mean of all the darts is also off from the center.",
            "Right now we call sort of this we call a bias systematic error.",
            "This we call a variance.",
            "Right, and of course you could have both bysina variance, which is even worse, and this is a very lucky if you and have exactly the right model that's stable and shoots in the middle.",
            "Then we have low bias and low variance.",
            "That's really what you want to shoot for, but it requires you to basically know exactly what the data distribution is that generated the data.",
            "Now, in a little bit more set of equations so that we have Y is the label you know there's some underlying function F of X they were trying to estimate, and then there is some label noise epsilon drawn from a normal distribution.",
            "And then sort of we are interested in the error here.",
            "The error for a point X, which is the difference between the true label Y and our estimate.",
            "F hat you know there's the model that's trying to predict Y.",
            "When we look at the squared error here and then you can decompose that is the famous bias variance sort of decomposition.",
            "You can decompose that into three terms and the first term is the bias because it looks at the difference between the expected value of your estimate expectation taken over many datasets.",
            "Trying to estimate F by repeating sort of estimating it on multiple datasets.",
            "So that's the bias.",
            "And then the next term is the variance, so that only depends on the estimator, right?",
            "So the first name is acting very hard to estimate because you don't know F, But the second term you can definitely estimate because it only depends on the estimator and is the variance of the estimator.",
            "And then there's the theater, which is basically the label noise.",
            "Right and then the name of the game is to try to, you know, get either the by is down or the variance down you know in order to get the total error down.",
            "And sometimes it's better to get the bias now and sometimes it's better to get the variance down right, but you're really interested into some of these two things, and so that's what you see here now on the X axis is model complexity.",
            "So if you have a really simple model with very few parameters, let's say you know you're trying to fit a linear regression model.",
            "Very few parameters, then the variance is going to be very small, and so you're on the left hand side.",
            "Here the variance is going to be very small, but the bias is very large, because if the true line you're trying to fit this curvy you're trying to fit it with a linear line.",
            "Clearly you're making a big mistake.",
            "Alright, and on the other end of the spectrum, devise is going to be small or it's very complicated model.",
            "It can fit basically everything, but on a particular data set you might still get a large error, which means that the variance is high, and then you want to sort of trade these two often optimal point, which is where the bias squared in the variance added up is minimal.",
            "And there's a total error or the risk."
        ],
        [
            "OK, so so that's sort of the introduction and you know machine learning in some sense.",
            "You know the basic concepts, but this bias variance tradeoff will keep coming back.",
            "Now first do a very quick introduction, an graphical model, so this is sort of old style machine learning if you want, but I still think it's really important.",
            "There's also bubbles here, like in neural Nets, but they mean something else.",
            "In this case, they mean stochastic random variables, and typically when you model something like with a Bayes net or some graphical model, you have a pretty good sense of what these variables mean, right?",
            "So let's say in this case you know there is rush hour, bad weather accident and rush hour.",
            "An bet whether they.",
            "Cause traffic jams in bad weather also causes accidents.",
            "And and then accidents also cause sirens, right?",
            "So there's a bit of a causal relationships between all these variables.",
            "They mean something and you're trying to fit that model to the data.",
            "And this is what we actually.",
            "This is what I think of as the classical way of actually modeling.",
            "You write down a model that you understand the variables mean something.",
            "The relationships mean something.",
            "Typically these models are not huge black boxes where none of the parameters make sense anymore.",
            "And then the beauty of graphical models is that you can write down for every one of those diagrams.",
            "Here in this case, with arrows, you can write down a joint probability distribution over all of these random variables.",
            "So in this case the joint probability is the probability of traffic jam given all of its parents, which is the inflowing arrows here.",
            "So, given rush hour, bet whether an accident.",
            "Alright, and then times the probability of in this case or sirens, which is this one here given its parent which is accident and then the probability of accident given its peer in bad weather and in two marginals probability of rush hour and the probability of bad weather, right?",
            "So you decompose this and then there's a certain rules which I'll explain in a minute that will basically allow you to read off from the diagram.",
            "All the marginal and conditional independence relationships that are implied by that graph, and that's the power of it, because you could look at it, you can communicate about it and you just at some point you start to read these things and you see all the conditional independence relationships right.",
            "It makes sense.",
            "For instance in this case is rush hour is marginally independent from bad weather, you know they don't influence each other.",
            "There are two independent processes which influence other things, right?",
            "But for instance, traffic jam is not going to be conditionally independent.",
            "Of sort of rush hour is not going to be conditionally independent of bad weather.",
            "If I observe a traffic jam.",
            "And that's called explaining away because if I explain traffic jam for instance by bad weather, then my probability or my belief that the rush hour would be the cause of the traffic jam is going to shift is going to change because I've already.",
            "I've already explained it by another parameter, so the power is now that the claim is that which ever conditional probability distribution.",
            "You can read out from that graph by the rules I'll see in a minute.",
            "It will correspond to doing a calculation in that graphical model, so you know you have to marginalise out some things that you have to condition on some things.",
            "But then if you after you do that, the conditional probability distributions match, and that's a really powerful statement."
        ],
        [
            "Alright, so then what is the?",
            "I'm going to speed up a little bit of time now.",
            "So what is the algorithm that you can use in order to visually figure out what the conditional independence relationships are?",
            "And that's called the baseball algorithm.",
            "I didn't notice it's new to you.",
            "So the baseball algorithm basically is a bunch of rules which says if two variables are independent, there can be no path between those two variables and so filled variables is when you condition on them, which sort of means you observe them and other variables that you don't condition are open right.",
            "And so if we can sort of, say, whether rush hour and bad weather or marginally independent, there should be no path between these two, and that's because you know this is path is blocked here.",
            "And that's that's the explaining away path.",
            "Well, if you would if you would marginalise it out, you know you know, then you would.",
            "There should be no, it should be.",
            "Pass between those two when there's not conditioning on them, and then.",
            "Sorry, when you conditioning on them then you then you are here and then you're let through.",
            "So if you are let through, in fact there is dependencies.",
            "If you condition there is dependencies when you're not conditioning on it there, there is no dependencies because you cannot go from here to here and there's all these rules can help you figure out these conditional independence relationship."
        ],
        [
            "Now there's a similar sort of process for another class of models, which is called Markov random fields, so these are the undirected models, like if you have an image, you can put every pixel is a random variable, and there is symmetric relationship between the pixels which could say something like.",
            "This pixel has a particular color, the likely hood of probability that the neighbor has the same color is a bit higher, right?",
            "And here the conditional independence relationships look as follows.",
            "If you want to figure out whether this node is independent of this node.",
            "Given this node, you should see if there's any path going through it.",
            "And essentially conditioning on these two nodes here, you know.",
            "Basically there's no.",
            "There's no pass, every pass gets blocked from here to here, which means that they are conditioning independent and there's a similar theorem, which is that if you write the probability distribution as the product over positive clicks, so these have to be positive where click or a maximal clique is actually a group of variables which are all connected and cannot be extended.",
            "So this is a clique and this is a clique and this is the click etc.",
            "If you take that product and you normalize it.",
            "Then if you compute your conditional independence relationships using that equation, you'll get the same answer as you could read out from the equations."
        ],
        [
            "So one particular.",
            "Class of latent variable models.",
            "So certain class of Bayesian neural network, which is particularly powerful is called a latent variable model.",
            "I'm sure you've seen already quite a bit of this, so in the latent variable model you have some observed random variables and you model them by basic introducing some latent stochastic random variables.",
            "Here is that once was at M, you don't necessarily know what these are, but you know you could try to interpret them after the fact.",
            "These could be topics which could describe, for instance.",
            "Documents or something like that, and then the distribution over the observed random variables X is given as the marginal over this graphical model, right?",
            "So this is X given Zed Bayes net, so it's X Givens at times to prior P of Z and then you marginalized out set variable here to get P of X.",
            "And because you marginalized over a potentially exponential number of joint states, zed is actually a very powerful model.",
            "You know this is, you know, it's nice to write down something like that, but in order to use it you have to do inference.",
            "An inference is, for instance, computing the probability of the latent variables given the observed variables.",
            "You know that's the thing that's interesting in its own right.",
            "You might want to compute the probability of this topic.",
            "You know, in this particular document, but you also turns out you also needed for learning inside the EM algorithm.",
            "I'll say a few words about that in a minute.",
            "OK, so then there is 2."
        ],
        [
            "Class.",
            "Two classes of variable algorithms that you can use to do this approximate inference.",
            "And there is a variational inference class, and then there is the MCMC sampling class of approximate inference, and I'll say a little bit about both of these class of algorithms.",
            "So variational inference is as follows.",
            "So you have a target distribution P. This could be the posterior P of Z given X.",
            "Right, and you're trying to find a approximating distribution within a family that's fully tractable.",
            "For instance, you could decide that you just want to work with normal distributions, and then you're trying to find the normal distribution with, let's say, the best mean and variance or covariance matrix that approximate it gets close as possible to the true distribution.",
            "And and close in closest you use the KL there, virgins.",
            "In order to measure what closeness means.",
            "In this case, KL between Q&P.",
            "Now in sampling, however, what you do is you take your distribution.",
            "Let's say P is here this distribution and you're going to represent it with a bunch of points, right?",
            "Just a collection of randomly sampled points.",
            "And then an expectation is computed instead of computing the actual expectation over the probability P, you evaluate the function that you want to compute the expectation over at these dots.",
            "And then you sum them and average them over the number of dots.",
            "Now, both of these families advantages and disadvantages, and here again, the theme of bias and variance returns.",
            "So this is just an optimization algorithm, so you turn inference in optimization in some sense is deterministic, so it's quite easy to figure out whether you've converged or not, as you can throw all your optimization tools at the problem.",
            "Fortunately, there are local minima, so it's not trivial to do the optimization, but the most important part is that it's biased, right?",
            "Because this is never going to be this if it needs to stay within Distractible distribution.",
            "So it's bias, but it doesn't have variance because you know in principle when you do your work, you always get to the same Q star.",
            "Now, in terms of sampling is to reverse?",
            "Or if you have a proper procedure then in principle you should be unbiased.",
            "You should get the right sort of answer on average.",
            "If you repeat an infinite number of times, but for any particular instance of your MCMC run, you know you get a different answer than the next one, and so there is variance in your error now.",
            "So there's there's error related to the variance of that estimation procedure.",
            "Now the the multiple modes issue doesn't go away.",
            "So here you have multiple Optima to do your optimization.",
            "Here you have multiple modes in your sampling distribution is very hard to sort of mix between one mode in another mode you have to work really hard to make that happen, and it's very difficult to assess convergence."
        ],
        [
            "OK, so there's a bunch of really sort of simple sort of.",
            "Maybe your first idea would be something very simple like, well, you know what if this is my true distribution?",
            "I'm trying to sample from and this is my.",
            "This is a very simple distribution I just draw from this bigger distribution and then delete everything in a smart way.",
            "That's not, you know, inside the region of the true distribution, right?",
            "That's called rejection sampling.",
            "It really doesn't work in high dimensions, or you should forget it actually.",
            "And then there's important sampling.",
            "We do something similar.",
            "But it assigns weights to each one of the data points where data points which are close to the true distribution are have higher weight than the than the ones that you draw far away.",
            "All of these things really don't work in high dimensions.",
            "The thing that does work in high dimensions is called Markov chain Monte Carlo, and I'll say a few words about that in a minute, and the idea is basically that you start just like an optimization problem.",
            "You draw your first sample from a completely wrong distribution that could be very far away from the distribution you're interested in.",
            "And then you have a transition kernel, so the next sample you draw from a different distribution and then the next sample you draw again from a different distribution and the distributions from which you are sampling are actually slowly converging to the true distribution, right?",
            "Because the first sample is actually drawn from the wrong distribution, you should throw them away.",
            "That's called the burn in and the ones which are you know at the right sort of.",
            "You know when it arrives at the correct distribution then you should collect these samples.",
            "So this is similar to sort of what I said in the beginning, where if you have, you know if you know that for different datasets you know you would have different maximum likelihood estimators.",
            "There is a certain range in which these maximum likelihood estimators lie.",
            "Now this is a you know I haven't talked about it a little in a minute.",
            "This is a is a Bayesian procedure where you try to estimate.",
            "We try to sample the parameters of a model given the data and you know you could sort of think of that range that posterior distribution as.",
            "The range in which you sort of sample models from that distribution and note that it doesn't all the way optimize down to the middle here because it doesn't make sense.",
            "It basically says there is a particular optimal optimal scale over which I should not optimize any further at the point when I get to that scale here, I should really draw samples from that distribution."
        ],
        [
            "So in a little bit more detail, so the way that works is you start with the.",
            "You know with an initial parameter estimate.",
            "So let's say we do invasion running, but I'm sort of fast tracking a little bit because I'll talk more about this in, you know, little further down.",
            "So you start you start with your first parameter, estimate that you can think of this system random variable and then you go.",
            "So you take the first one.",
            "You know, given this one and then the second one given this one, and this chain keeps on going until you sort of reach the place where you know the posterior distribution lies.",
            "So you can think of these as weights of a neural net.",
            "And then as you go sampling in the beginning, they're just random, so there didn't look like anything.",
            "And then they didn't do much and then.",
            "Around convergence you know you have sort of trained your whole neural net and then you sort of sampling from the parameters from the right distribution.",
            "Again, the burden should be thrown away and then here there is this very important object which is a transition probability, which is the probability of picking your next point given your previous point, and that's the object that you have that you can design yourself so you can sort of design A distribution T. Now it has to have a property that it will eventually the sequence will sample from the correct equilibrium distribution.",
            "And there's a bunch of tricks I won't really go into detail.",
            "Balance is one of them.",
            "That would guarantee that you would go to the correct distribution, but unfortunately, you know you can come up with quite simple ones.",
            "But the problem is that they mix very slowly, so you can think of that.",
            "Perhaps as I'll show a few demos in a minute, but if they're mixing is very slow and sort of this optimization process, or this way that this sort of sequence progress is very slow.",
            "Now here you can see an example of that.",
            "You know when it's already sampling from the correct distribution.",
            "So when the mixing is very slow, two subsequent samples are highly correlated.",
            "So you can think of, like you know, this is my current sample, and when I'm drawing my next sample just very closely around me, then of course the next sample in the previous sample are going to be highly correlated with each other and that's very slow mixing, so that's what you're going to see here.",
            "So these autocorrelation is very high, so this is a much better sampler where basically every next sample is almost.",
            "Independent.",
            "And you're going to pay a price for the fact that you have this autocorrelation in your MCM MCMC chain, because it's very easy to come up with very badly mixing samplers, but you pay a big price.",
            "So here again, we have the variance bias decomposition.",
            "So as I said, if I want to compute some integral I, which is an expectation over a function F over my target distribution S 0, then I'm going to instead of doing the exact computation I'm going to replace that by evaluating the function.",
            "At the parameter estimates data, which are my samples and then sort of averaging over those samples.",
            "And again I can compute a bias in a variance and there is just like I talked about before, there's a bias variance decomposition, so the bias is basically the difference between the expected estimate off your integral minus the true value.",
            "Now if you do your work rights, if you get if you sample eventually from the correct distribution, then this body should be 0 in this case, so the expectation is basically taking over.",
            "Many, many MCMC runs, so if you take a thousands and thousands of MCMC runs, you take the expectation over all of these.",
            "Then there's expectation should go to 0, so the bias is there's no bias is an unbiased estimator, but there is variance.",
            "Clearly, because every single set of MCMC run looks different from the other and then, so the variance of this estimate of the integral is a bunch of terms.",
            "First, the variance of the function F itself.",
            "So how much does it vary?",
            "And then divide it by T, which is the number of samples that you're averaging over.",
            "Clearly, if you draw more samples than the variance goes down, But there's this Tau here, which is the article relation coefficient, which basically tells you if Tau equals one, then every.",
            "Now equals one in every sample counts as independent, but otherwise you know if targets bigger, then unfortunately you know there every sample counts as a fraction of a sort of a sample, right?",
            "Because if this is a very large then the variance is very high and you need many more draw need to draw many more samples in order to get the same variance.",
            "If you would have an independent sample for instance."
        ],
        [
            "OK, so as I said, the transition kernel is at your disposal, so you can.",
            "You can design it and smart MCMC algorithms basically have smart kernels.",
            "And here's this very simple one that I argue, and you know many people argue it doesn't really work very well, But anyway it's very convenient.",
            "So what you do is you propose your next parameter value or random variable.",
            "Given your, you're currently at Theta T, which is your current random variable and then you propose a new parameter value from some distribution Q and you can choose.",
            "Queue whatever you want.",
            "So there's some Q distribution, so typically you want to choose cube quite close to where you currently are.",
            "So let's say Gaussian distribution centered around.",
            "You know where you currently are.",
            "And then you have to compute the probability of accepting that particular proposed sample.",
            "So if you accept it, you added to the stack.",
            "If you reject it, then you add a copy of the previous sample to this deck so you get 2 copies of the same sample.",
            "Then and the way that you sort of compute that is to say, well, there's this fraction here, as is the target distribution, so it's the ratio between the target distribution at the new sample divided by the old sample.",
            "So in other words, if the probability of the new sample is.",
            "Much higher you tend to accept that sample, so you going up in probability and then there's this one here, which basically says the probability of going backwards.",
            "This has to do with detailed balance because you want the total probability flow from Theta T to Theta prime to be the same as the total probability flow from Theta prime back to Theta, and if these two match then you can prove detailed balance.",
            "You can prove that you converge to the correct distribution South here.",
            "So if this whole thing is larger than one, then you know you accept all the time.",
            "If it's if it's smaller than one that you accept with probability given by that fraction.",
            "OK, so now there's one really big problem with this, so let's say we're doing again Vision Vision.",
            "Sampling the problem is that it this is order N and the reason is that the probability this target distribution here is the prior times the product over all the data points of XT given Theta an.",
            "It's two sort of expensive to compute that if you have a really large data set, right?",
            "So if you have like a billion data points and for every sample that you want to draw you need to compute this thing for a billion data points and that's just way too slow.",
            "In fact there is this thing which I call a big data test.",
            "You can imagine if you have like an infinite data set right?",
            "Could you?",
            "Would you make any progress?",
            "Would you get a good estimator in a finite amount of town time right?",
            "And so you should right, because you know if you have a very large data set you could always choose to ignore the fraction of that data set.",
            "And so you should be able to create in a finite amount of time a pretty good model.",
            "But this procedure doesn't progress at all in infinite and infinite data set.",
            "What was going to happen is that you know you will never.",
            "This computation here will never end, and so it's a very bad procedure instead of the big data limit."
        ],
        [
            "And so again, going back to this bias variance decomposition idea.",
            "So could we do something about this?",
            "Well, one way you know we know that from variational inference.",
            "We're not afraid of a biased procedure, right?",
            "So if that helps us a lot, then maybe buys isn't all that bad.",
            "So one question you could ask yourself, could we make an MCMC procedure biased right?",
            "But but but the fact that it becomes biased in return will get a much more efficient, faster sampling procedures.",
            "So we get lots more samples and you have a lot more samples then we can get the variance down our estimator.",
            "Right, and so the idea is, let's say, well, OK, let's say this is the true distribution you want to sample from.",
            "Well, maybe I can just relax a little bit on that distribution.",
            "Perhaps I can draw a lot of samples so my bias will go up, but my variance will go down.",
            "Right on the other end, you know if I have a procedure with the NOB, they could sort of trade these things off and the other end, you know, I would have to completely unbiased procedure, which is the normal MCMC procedure.",
            "Unforeseen is very expensive, right?",
            "Because if I have a billion data points, you would have to do lots and lots of computations, so can only in a finite amount of time can only draw three samples and then they might have a very large variance in my in my error.",
            "Right now.",
            "The idea is you know, can I trade up?"
        ],
        [
            "Between these things, right?",
            "So here's again, sort of this decomposition.",
            "This is the integral that they want to compute.",
            "I'm looking at the squared error averaged over sort of any sort of sample, so efforts over the distribution and there's a bias term, which is, you know, the expected value under P minus the expected value under my on the true distribution, mine is expected under the estimated distribution and enters the variance term.",
            "Now if I'm giving myself a finite amount of computation, I think everybody should sort of think in terms of, you know, a procedure.",
            "Death is allowed to compute only for a finite amount of time, right?",
            "Because there is not infinite amount of time in 40, so that's pretty reasonable.",
            "And when you have a big data set to take time and computation time into account, so let's say I'm now.",
            "I'm going to allow myself, let's say one hour to do my computation, right.",
            "This is the typical sort of, you know, before the nips.",
            "Deadline is 1 hour before the dip nips deadline.",
            "I need to run another experiment, right?",
            "You know how?",
            "How should I set epsilon so there's one curve which is to buy a switch here on this axis here is epsilon, which is my trade off parameter I. I'm assuming I have this bias variance tradeoff parameter, so if it's all the way to the left you my bias is very low, right?",
            "But my variance is very high because it not drawing a lot of samples.",
            "And then the optimal risk you know is sort of here.",
            "So this is where you should set your epsilon, but they're going to allow myself a lot of computation time.",
            "Let's say I have you know, a day before the deadline, then what happens is that here the variance is not going to be super high because I have a lot of time to draw my samples anyway, right?",
            "So the variance error is not so high and the bias is zero anyway.",
            "And then when I draw my nob to the right and I'm sort of increasing my bias, then yes, the variance goes down.",
            "And bias goes up, but then the optimal here for epsilon different.",
            "Right, and this is the take home message that you know in MCMC procedure, whatever you do will have, you will have to run it for a finite amount of time, right?",
            "You might have very large datasets or this tradeoff in computation time is always there, and if you have this nob where you can trade of bias and variance in its nest is not necessarily the case that setting that NOB 20 bias, which is the normal MCMC procedure, is the optimal way.",
            "Optimal way of going.",
            "OK, so then."
        ],
        [
            "So here's a very, very simple algorithm that.",
            "Basically, mimic stochastic gradient descent.",
            "An Bob has this property that you know when it gets close to the target distribution, it will start approximately sampling from the correct to the posterior distribution.",
            "Now we all know sort of stochastic gradient descent, so there's a prior over parameters, and then there's a likelihood term here right?",
            "And we take a gradient with respect to Theta.",
            "We take a step in Theta in parameter space which is epsilon over 2 times.",
            "You know tempted gradient of the log prior terms of grading of the log likelihood term.",
            "So that's easy.",
            "So that's actually gradient descent.",
            "Now stochastic gradient descent looks like this.",
            "Instead of, you know, so this will not pass the big data test clearly, because if this is infinite, you will not make a single step.",
            "So to create something that actually will compute for, you know for an infinite data set, use a procedure where you draw a finite subsample from your full data set, and then you replace.",
            "So that's a stochastic.",
            "That's sort of an unbiased estimator of this.",
            "Some right you add this vector capital N over small and to make sure that it's at the right scale.",
            "Niantic rating of the likelihood and then what people typically do is you.",
            "You pick up mini batch, you take a gradient, pick another mini batch, take another gradient step, etc.",
            "And then you anneal the step size is kind of important.",
            "There's some properties that you have to satisfy to guarantee you know to convert to the correct distribution.",
            "So you need the step size in order to get to the correct distribution.",
            "Now in neural networks, clearly that's the way to go.",
            "We all know this.",
            "Now here's a tiny, so here's another algorithm.",
            "It really looks like stochastic.",
            "Looks like gradient descent, which is larger than dynamics, and what that does is you take a step according to the gradient of the.",
            "You know the the prior plus the log likelihood, but then you add a bit of noise and the thing to observe is, although it's pretty hard to see unfortunately.",
            "The there's a step size here, which is epsilon over 2 and the noise variance that you're adding has a variance of apps of epsilon.",
            "So the important variance of the noise that you're adding.",
            "Is the same as two times the step size, so that's a if you don't do that, then it won't.",
            "You know even approximately sampling the correct distribution.",
            "Now there you have to still add in Metropolis Hastings accept reject step to do the correct sampling, but in the limit when epsilon goes to 0 actually everything will be accepted.",
            "This kind of nice property if the if you take tiny steps then you will always accept.",
            "The problem is that you did not mixing very fast.",
            "So here's to you, know the little modification.",
            "You say, well, let's just look like, you know, make it look like stochastic gradient descent place, you know, make a small mini batch and do the sum over that.",
            "Keep adding the noise as you did before.",
            "You want annealing as before, but skip the metropolis Hastings accept reject step.",
            "Now that's just the same as the guesser grading to send, but you just add noise was very cheap, right?",
            "And the miracle is that this actually in the limit for small step size will sample from the correct distribution, but since we're not doing a metropolis, Hastings accept reject step and actually we have a finite step size.",
            "There is a bit of bias in this distribution, right?",
            "So the step size will now be Arnab.",
            "The trades of bias and variance."
        ],
        [
            "OK, so here's a little demo on.",
            "Firstly, also the resolution makes this look a little bit ugly, but you know this is a distribution here 2 dimensional distribution.",
            "An here this little snake that's running around is our sample is the last 10 samples.",
            "Sometimes it makes it jump to sort of speed up the movie little bit.",
            "Right here you see sort of the estimate of the distribution after sort of a certain amount of time of sampling, and it's basically the histogram of the counts of where it's been.",
            "And you see that you know it's annealing, so the step size gets smaller, so the progress is that it's making is also smaller, so that's the mixing problem, right?",
            "So this is really not what you necessarily want."
        ],
        [
            "So let's have a closer look at these terms.",
            "So there's two.",
            "Two places where we inject noise, right?",
            "The first is because we subsample from the from the.",
            "Data distribution.",
            "Here we take a mini batch and that's an estimate of the full gradient and so that actually is a sort of an unbiased but noisy estimator of the full gradient, and so you can say that this is drawn from a normal distribution.",
            "You know if this sum is large enough due to central Limit theorem.",
            "From a normal distribution with the right mean, the mean that we want, but it has a bit of various feet.",
            "Right, and then there's a second noise distribution, which is this one is what we add, so there's two noise injections here.",
            "Now when you start optimizing, you take a big step size, right?",
            "Because remember, we were kneeling, so we started with the big step size and then it turns out that this noise created by the subsampling is completely dominating the other noise.",
            "The noise that we're injecting ourselves.",
            "So basically you can ignore that noise, which means that you just doing stochastic gradient descent.",
            "This is just a test.",
            "Agree to send with a little bit of overhead.",
            "Namely, that you have to draw normal random variable.",
            "Now when you get closer."
        ],
        [
            "So the optimal distribution.",
            "So you're you're kneeling and you're closer to the distribution to the sort of the true posterior.",
            "What's happening is that now this noise term is starting to sort.",
            "This noise term is starting to dominate the injected noise, and this actually is not dominant, so it means that it's like you're just getting the right gradient and you know this.",
            "Your own noise that you're adding by hand is dominating the whole thing, so this means that at this point you're actually sampling from.",
            "From the posterior distribution and you're not bothered by the fact that you have you actually do have a sort of a noisy estimate of your gradient."
        ],
        [
            "Now you can again there is this tradeoff between large step size and small step size.",
            "If the step sizes larger going to mix alot so you had a step size is big and so this snake is moving from left to right very quickly, but the price you pay is that the distribution you're sampling from is a poor approximation of the true distribution.",
            "So here's what you see.",
            "So it basically estimates you know this distribution with spherical distribution right things?",
            "It's like a isotropic Gaussian or something.",
            "Now you."
        ],
        [
            "I can do better, which is you can decrease the step size now.",
            "The price you're going to pay for that is that the mixing is slower, so you have to wait longer.",
            "So for a fixed amount of sampling time, it means you have less samples.",
            "You will have higher variance, but it turns out that the distribution you're going to get is looks a lot better, right?",
            "So this is again a fixed step size, but now we've chosen to be small and now you can see that the details of the distribution are much better approximated.",
            "OK, so this you could try to use this on neural networks and deep learning, and of course we've tried it.",
            "It works to some degree, so you can make it work reasonably well, but you know if you just look at classification performance.",
            "In fact, putting a smart regularizer like dropout actually works just as well, so in that sense it's not super useful for this particular deep learning case."
        ],
        [
            "Now it's been a lot of research afterwards which proved convergence in distribution, and all these things, so it's a valid procedure in that sense.",
            "OK, so the second class, yeah?",
            "So in principle we so the question is why don't we need the metropolis facing step.",
            "So in principle we needed, but we choose to not use it, which will introduce bias, right?",
            "So there's this tradeoff between bias and variance, and I'm explicitly choosing to trade off.",
            "Some of the basically the variance with the by.",
            "So I'm creating bias, but because I don't have to do the metropolis Hastings step, I can go much faster and so the draw more samples in a finite amount of time and effort reduce variance.",
            "So the second class of algorithms is variational inference, and you've seen already quite a bit of variational inference, so I will go a little fast in variational inference.",
            "Again, we choose Attractable set of distributions queues at given X.",
            "That we know how to handle and we minimize the KL divergent between these posterior distribution between the true posterior distribution piece that given X and approximate distribution cues out of X.",
            "And then in fact you can write this out an sort of do things to it that don't matter for the optimization, and then it looks like this elbow is called Elbow is coming from objective for the expected value of Z given X over the joint distribution PX, said.",
            "And there is this entropy term here which tries to keep the Q fuzzy and not actually collapse onto a spike.",
            "And so the picture you should."
        ],
        [
            "In mind is like if Q is the approximation distribution in red and P is the true distribution.",
            "Here you're trying to fit a Q which is typically smaller than P is inside 22P, but you try to make the fit as good as possible.",
            "Now that is so expectation maximization that people already did.",
            "Somebody already talk about expectation maximization.",
            "OK, so expectation maximization is basically a way to train a model which has latent variables set.",
            "So axes observed set as latent.",
            "Right, and it fits really nicely with this.",
            "Adopt tails you could say with this variational inference.",
            "Is there actually a very simple algorithm viewed in this particular generalized way?",
            "So you're going to say that the log of P of X given Theta.",
            "That's the object we are really interested in, because we want to find parameters Theta such that the probability of the data set X is maximized.",
            "Now we agreed that X is a latent variable model, so we're going to write it as X, given zed times P of Z, and I've sort of said, well, let's put all the parameters in this.",
            "In this likelihood Duramax given Zed and let's not put it in this prior term, but you could put parameters there too.",
            "So this is just writing out the definition of P of X given Theta.",
            "Now you could easily upper bound this by this elbow, so again the same the same term here.",
            "So this is upper bounded by.",
            "Basically introducing or variational Q distribution.",
            "Here is the average over cues that given X with its own parameter set five, so we can tune this parameter set five times.",
            "The log of P of X, given that Theta PP set, which is the log join model distribution and Q's at given X. OK.",
            "So now learning is very simple now because learning basically says there's two steps, E&M step and the E step we re going to do inference, which is we're going to train up RQ distribution.",
            "And that's basically take this bound, so we're going to write this as our bound, and in fact the nice thing is that this the gap between this bound and the the marginal P of X given Theta is precisely given by this KL between the posterior approximate posterior to true posterior, right?",
            "So if you get Q to be flexible enough to actually model P, then you know that the gap is actually all the way down to zero.",
            "And also note that this is exactly the objective that we're trying to minimize when we do inference over Q.",
            "Right when the E step we have to do inference, which is we take the bound and we maximize it over the distributed over the parameters Phi which live in our approximate posterior distribution Q. OK, and then in the M step we just look at the same objective.",
            "Here, abound, but now we maximize it over the parameters Theta and so it's really just coordinate descend on that bound.",
            "That's all there is to it.",
            "It's really, really simple algorithm feud.",
            "This way if you look at into statistics literature, it looks much more complicated, but if you view it this way, which is equivalent, its way is actually quite trivial."
        ],
        [
            "OK, so then more recently there was A and I think I'm sure you know, maybe Aaron talked about it or somebody else already.",
            "This idea of amortized inference, which actually Interestingly quite a big step.",
            "But it goes all the way back to Jeff Hinton and Brendan Frey and resemble, you know, and I don't know.",
            "Somewhere in the 90s, ninety eight or something or 95.",
            "Anne.",
            "And architecture, which I called the Helmholtz machine.",
            "I'm not sure if you've heard of it, but it was basically a neural net.",
            "You know from that going to X and then a recognition network going back from XCOM 2Z.",
            "So that's you can just directly map this onto the neural net, going from zed going to X.",
            "It is, you know, we have a prior reset and then X given zed.",
            "And then they had a recognition network.",
            "Will neural net going from X2 sets?",
            "There's a queue of zed given X.",
            "Now the the so they had to wake sleep algorithm to train it, which unfortunately optimizes two different objectives and it was a bit hacky innocence.",
            "So the so the idea here and I'm sure they tried it was to say, well, let's stick with the original objective one bound, so we should just optimize this one bound right?",
            "This is disbound here.",
            "This is the bound, so we're going to stick with that bound right?",
            "But the first trick to make this fast is to basically say that instead of writing a queue of zed which is separate for every data point which every data point has its own set of parameters which also.",
            "We did a test time.",
            "You would actually have to do inference over that data point to compute that Q.",
            "We're going to turn it into sort of a conditional distribution zed given X.",
            "So now surely the distribution is different for every input X, right?",
            "But the parameters fire now shared between all the data points, right?",
            "So one set of parameters 5, like my model parameters data, which are the same for every data point.",
            "And so it basically means I only have to train this once in my data set, and then it's fixed and now on test time you're really fast because you stick in your data point and swoop.",
            "You go up through your neural net and you sample.",
            "You said you don't have to do iterative inference to compute your queue for that particular data point, so that's actually a very important step."
        ],
        [
            "So OK, so sidetracked now a little bit to say that what's the relationship between deep learning and.",
            "You know, in graphical models, one way to look at this is that in graphical models we deal with random variables right.",
            "Every bubble is a random variable.",
            "We're in a neural net.",
            "Every bubble is just, you know, an activation which could be a deterministic function of.",
            "It's fast, but we're going to do is we're going to say, well, you know every time there is this conditional distribution, we're going to insert and deep neural net.",
            "Alright, so wherever there is a conditional distribution, I could do something very simple, but I could also do something very complicated, so that's just something very complicated and take deep neural net.",
            "And then."
        ],
        [
            "Long time ago when I was talking, I think it was with semrau ice.",
            "He he had this interesting idea that you know when you want to write lots of papers, you should really invent a new operator.",
            "You shouldn't invent a new model, because if you invent a new model, you only get the right one paper, right?",
            "If you invent a new operator, you can apply the operator to a million models and then you can write lots of papers.",
            "So here is a new operator that's a deep if I operator.",
            "So the way to do it is that you know you take.",
            "You look, you look for these conditional distributions in your model that you already know, and then you insert a deep neural net right?",
            "So that's what we did for variational auto encoders.",
            "We just took a factor analysis, linear Gaussian and we stuck in a deep neural net.",
            "But there's a couple of other ones.",
            "I think there's a lot, you know, deep logistic regression becomes deep neural Nets, right?",
            "So that's another obvious one.",
            "But there's a lot of ground to cover.",
            "Actually, how about survival analysis?",
            "I'm not sure if you know about survival analysis.",
            "It's trying to figure out, you know if you if you buy something you you know how long will it take for it to breakdown and basically.",
            "And there's his Cox model, and inside this Cox model there's this little linear gression part here right now.",
            "If you replace this with the deep neural net, you will have deep survival analysis an I actually don't think it exists, right?",
            "So you could just take it as a collective project.",
            "You at the end of this summer school you know you have implemented and tested the trivial analysis.",
            "And so the variation autoencoder is 1 example."
        ],
        [
            "This is well, so here we go.",
            "You know here is our little set of M framework with, you know with two conditional distributions and we do provide this and we decide that and then we have the various."
        ],
        [
            "Auto encoder.",
            "So if a prior probability of zed here and given PM said you know we have a deterministic set of sort of.",
            "In this case I use these sort of a diamond shaped nodes to produce the probabilities.",
            "Let's say for an output variable X and then there is the backward pass, the recognition model which goes from Xbox back to Z.",
            "And that's the Q distribution."
        ],
        [
            "Now.",
            "In order to avoid the big data in order to pass the big data test right, we cannot run every update on all the data points because you have a billion data points.",
            "I will not make any progress.",
            "So what do I need to do?",
            "I need to actually subsample the datasets or there's actually two places again where I need to sample in order to make this work.",
            "So here's our friend.",
            "Again, this is the bound that we know by now all.",
            "Love you've seen it so many times right?",
            "And then if you actually compute the gradient with respect to five, so I should say taking the train with respect to Theta, which are the parameters of the model distribution is really simple, so that part we're going to skip.",
            "But if you take the hard part is actually taking the gradient with respect to five, which is from the recognition model.",
            "If you take that, then you get basically get this right, and I'm pretty sure that the gang from you know the Hinton and Frey and everybody they tried this right.",
            "I'm sure they must have tried it because it's the obvious thing to do.",
            "But then if you want to make it work, you'll have to start sampling at a couple of places so the 1st place you want to sample is from this distribution Q, because that's just a neural net and you cannot really easily integrate this log P over this.",
            "It's a neural net, but it's a Gaussian distribution, so so that's OK, but you know.",
            "This might be very difficult.",
            "It might be a neural net in itself, and so you can actually not do these integrations very well.",
            "So that's where you have to sample from Q of zed.",
            "OK, that's fine, but you also have to subsample your data set which log P of XI.",
            "Given Zed I evaluated at sample S from our Q distribution and now we have two places where we sample and now if you try this it doesn't work right.",
            "So now here is, I think why the wake sleep algorithm got inserted 'cause this just doesn't work and I think it's also a recent insight that we figured out why this doesn't work.",
            "And this has to do with the fact that the variance is too high, so the variance of this estimator, again this is an estimator that the variance it is estimator is too high.",
            "So it basically you're trying to figure out which direction to move, but it's so noisy that you know it's all over the place, so you're not making a lot of progress."
        ],
        [
            "So the thing that made this work is reducing the variance, and there's been a lot of work by different groups to try to reduce the variance right?",
            "And every time you know the variance got reduced, the method works a bit better.",
            "Now, the trick that we used was this representation trick, and I think Aaron did talk a bit about this, but the most important reason that you know this is important is to reduce the variance, and the idea is actually quite simple.",
            "You write down a conditional distribution of a random variable set given its parents, and you externalize the random variable.",
            "You can say, well, that's actually the same as a deterministic sort of function, right where I also add a random variable epsilon to that random function.",
            "That's exactly the same as equivalent.",
            "Right and now what we're going to do is we're going to say, OK, so I'm sampling over Q5 here, but I'm going to introduce a transformation on Zed going to epsilons.",
            "I'm transforming zattoo epsilon Brezet comes from a standard normal distribution.",
            "Such that in this case you know the integral over Q.",
            "Is going to be now an integral over epsilon and I'm going to rewrite disease now as functions off this epsilon Ann 5.",
            "OK, so you know you do that, you compute the derivative and it looks quite simple now to convince you that that actually reduces the variance enormously.",
            "Let's look at an example.",
            "So here's an example where I tried to integrate.",
            "I take the derivative with respect to the parameter mu of a normal distribution integrated over zed, so we all know the answer because this integral is mu and then taking the derivative with respect to mu is going to give one right?",
            "So we know the answer up front.",
            "But if we try to do it this way right by basically, you know.",
            "Or not this way, but this way so we write out basically how we would have to do it this way.",
            "So we bring in the integral.",
            "We take the derivatives, right and then we have to sample over normal distribution, then the then the estimator looks like this and this is a huge variance in fact.",
            "So you're not trying to estimate something trivial by sampling from a distribution, but you're sampling.",
            "Variance is enormous, where if you would do the re parameterisation trick.",
            "In fact what you would get is 1 and you would be sampling with some one as times and divided by S. So there is no variance left at all.",
            "Right, generally speaking, there is of course various left, but typically the variance is reduced enormously.",
            "Important lesson is that when you have noise in your estimators, you're taking gradients right?",
            "And you're sampling and so you're getting noise in these estimators don't give up if it doesn't work, the answer could just be reduced variance, and then it might work."
        ],
        [
            "OK, so I'm going to skip this because of time, so there is a semi supervised versions of this which are quite natural."
        ],
        [
            "And if you do that, you can basically.",
            "Makes you know.",
            "In this case there's why label, which is clearly 029 and then zed.",
            "We flying through Z space here, which is the latent variable space and you can see that Z nicely models the writing style of the digits, right?",
            "So it has learned to the model the writing style of the digit, and it did so by using a large data set with no labels and a small data set with labels which is semi supervised.",
            "Learning and combine these using the variational auto.",
            "Order"
        ],
        [
            "OK, so sort of backing off a little bit from the discussion.",
            "Now we have seen in the various autoencoder we have a generative model and we have a discriminative model right?",
            "So two legs are sort of connected in this framework and these are two different philosophies in modeling, right?",
            "If you go to an economist or basically everybody outside of machine learning if you ask them what is modeling, they would say oh, you know I write down.",
            "I think about them all.",
            "I write down causal relationships.",
            "I know my parameters.",
            "I know the relationships.",
            "I understand what they mean.",
            "I put some parameters in and then I do some statistical estimation procedure and then I'm done right but every time they write down a model they know what that model means.",
            "They can interpret the model.",
            "That's a generative model, right?",
            "So Bayesian networks are generative models.",
            "Probabilistic programs are generative models in distance, or their people have built beautiful sort of languages around probabilistic models.",
            "It's a whole different field I think.",
            "Probably somebody talked about this already.",
            "An you know simulators which is basically what everybody does outside of machine learning.",
            "You know if you ask an astronomer what's your model, they probably show you a sophisticated simulator.",
            "See here, I can simulate the universe.",
            "I understand the universe right.",
            "If you ask, a medical scientist would probably show you a simulation of the heart or something like that.",
            "So that's also a generative model, because you can generate basically data artificially and match them up with observations.",
            "OK, so now there's a bunch of advantages of generative models that I want to emphasize.",
            "So first of all, because you understand the process, you can inject knowledge into the model, because you can actually say you know this influences this and this influences this every time you do that, you basically put inductive bias into your modeling.",
            "And sort of, you're not asking your data to decide on which things depend on walk, but you were deciding it, so that's injecting expert knowledge.",
            "You can you can actually model causal relationships, and that's actually quite important too, because you know calls are relationships are much more stable to use the non causal down just correlations right?",
            "In the Netherlands they have actually raised the fees, the insurance fees for people who drive black cars.",
            "People got upset about that because, you know, the blackness of the car doesn't cause you know the person to get into an accident.",
            "There's probably something else like a testosterone level or something like that from the male driving the car, right?",
            "So really what you need is you need the causal model, because that would actually generalize much better that, say, to another country if you go to Japan.",
            "Maybe you know males drive fast in red cars.",
            "Who knows, right?",
            "And so having blackness, Azure sort of, your measure of how much you should pay that doesn't generalize well to other countries, right?",
            "So causal models are much more stable in the sense of predictions, and the models are interpretable, which is important there.",
            "Data efficient because you're putting all your expert knowledge in there.",
            "You can use it for semi supervised learning.",
            "Again that speaks to data efficiency.",
            "They're more robust to domain shifts as I already said.",
            "And then on the other side of the world there is the black box set of deep learning.",
            "Now this is taking off and working really well, and the old days were kernel methods and random forests and boosting, right?",
            "But these are the black box set of models where you stick in your data and you predict directly and you let the data speak.",
            "Basically what that mapping should look like an again, here's a bias variance decomposition maybe so in this case because you have so many parameters, the variance might actually be quite high in these models.",
            "But the bias is probably quite small, because you let the data speak, you know, put in a lot of inductive bias when the other model on the other side to generate the model, you put lots of your assumptions into the model, which actually increases the bias but reduces the variance, right?",
            "Because the world is always more complicated than you can imagine.",
            "Basically, so you're going to make at some point you're going to make mistakes, and you're going to see those mistakes when your data set is large.",
            "So there is clearly very efficient training algorithms available for this.",
            "Deep learning algorithms is really good, and importantly, you're actually solve the problem that you want to solve right?",
            "Because at Test time you want to stick in some input you want to predict some output, so training that mapping directly is better than first training the inverse mapping and then inverting again with Bayes rule, right?",
            "So that seems cumbersome, and so both of these have advantages and disadvantages."
        ],
        [
            "And sort of you do this from a slightly different perspective.",
            "Then is you know in when you have a lot of data you should have today to speak.",
            "Oh yeah, she talked about."
        ],
        [
            "That I'm going to come back to that.",
            "So, but that's an interesting story because I think what the sort of various non quarter has basically two legs.",
            "But actually there's a slide on this.",
            "I'll come back to it, sorry."
        ],
        [
            "So from a different perspective.",
            "You know, when you're in Silicon Valley an your you know you're working away on your deep learning algorithms, right?",
            "Mostly maybe always in a domain where you have huge amount of data by click data or a video from YouTube or images or something like that, right?",
            "So there your game is really optimization, right?",
            "You know trying to really fit these large models today to the statistical efficiency really doesn't isn't all that important because overfitting might not be a huge problem at that point.",
            "Now when the data set is very small though, right?",
            "Actually you're looking for statistical efficiency and not so much computational efficiency, which basically means you want to put the right inductive biases.",
            "The right assumptions into your model, and so for instance, in healthcare, this is typically the case.",
            "Fortunately, there typically are not a huge amount of patience and privacy regulations.",
            "Actually, you know, unfortunately, make due to privacy regulations very hard to get your data, your hands, all that data.",
            "And so there you have to work with typically situation where the number of data points is much smaller than the number of things you measure about a patient.",
            "For instance, you could measure the DNA sequence.",
            "You could measure all the voxels of an MRI scan and a PET scan, and all these kinds of things and so here the game is statistical efficiency in their index."
        ],
        [
            "Advisors are very good, so here's my slide about.",
            "You know how that relates to autoencoders.",
            "So in outer core is you basically have two legs, so you have both the generator and discriminator, so the generative model is we have, for instance the label you measure something about the hospital.",
            "Let's say you have a latent variable, you push it through, maybe the neural net, or a better maybe through a simulator model to get your data.",
            "Let's say this could be an echo cardio, gram or something like that of a heart.",
            "Right and then the other model is the discriminative model where you take your observables, you push it through the neural net and then sort of, let's say, produce first your latent representations Ed, which is a compressed representation of the big high dimensional input.",
            "And then from there you can predict the labels Y.",
            "So this is your classifier and this is your generative model.",
            "And then the idea is that your.",
            "Use your generative model as a way to insert injective bias into the recognition model.",
            "The classifier, right?",
            "So you're not exactly inverting it, but you know you could use it to sort of help the.",
            "The classification model too, you know, to jump start or something like that.",
            "Right, so these two feed off of each other.",
            "You know you could.",
            "You could think of this as a regularizer for the discriminative model, but if you're interested in the generative sort of part, then this just becomes your recognition model.",
            "Your inference model for inferring these these latent variables, E."
        ],
        [
            "OK, so do that.",
            "I'm going to skip this.",
            "You all know about this.",
            "There's some examples about dermatology that I really like on.",
            "CNN's are really good results.",
            "I'm going to skip this a little bit."
        ],
        [
            "So.",
            "What I've been inspired with recently is the fact that.",
            "You know we have all these deep neural networks CNN's, but they have.",
            "They have a huge amount of parameters, right?",
            "And in fact, it turns out there's way too many and you can prune a lot of those parameters out and keep the same performance right.",
            "And the point is actually that it has an impact too, because they consume a lot of energy.",
            "Actually run these networks.",
            "Going to consume a lot of energy and pretty soon, and I think it's already there.",
            "The bottleneck is actually going to be.",
            "You know, how efficient can you make these neural networks?",
            "B because you know if you put them on your phone right?",
            "You know if you make them too big, there's interest too much energy.",
            "You know that you need.",
            "Not only does your battery drain, but it burns out of your pockets, right?",
            "And so there's only a certain amount of computation that you can do before it gets too hot.",
            "There's nothing you can do about it because the heat will have to go somewhere.",
            "Right and so making them more efficient actually might actually make the difference in making them sort of better as well."
        ],
        [
            "So and I've been working on Bayesian deep learning because, you know, I like to combine the graphical model perspective and the Bayesian perspective of the deep learning perspective and we have pushed.",
            "You know, we've really concentrated on uncertainty estimation, which I really think is still is a very important application, right?",
            "So, for instance, if you doctor and somebody comes in and your algorithm your black box algorithm tells you person has disease X right as a doctor, you want to know is that probability 99%.",
            "Or is that probability 51% right?",
            "Because in one way you would decide to do additional tests in the other way, you would just go ahead with the treatment right away.",
            "Right, so basically every time you want to make a decision, I think you need the probabilities.",
            "But it turns out that there is a much nicer.",
            "It's very hard to measure how well you're doing actually, in terms of uncertainty quantification.",
            "So as there's no good benchmarks, it's not even clear precisely what it what it means to actually have the right uncertainty on your predictions.",
            "And so there's a much more beautiful application of Asian deep learning and."
        ],
        [
            "Compression."
        ],
        [
            "Did you already do basean learning?",
            "Measure measuring that you're estimating your certainty properly?",
            "Well, let me give you the.",
            "I see what you're saying, but let's let's assume, for instance, that.",
            "You build a model and your data set is only living here, right?",
            "Let's say you have a self driving car.",
            "You know you only have seen this data now.",
            "Let's say you move to a new environment.",
            "Now, does the model have to be uncertain there?",
            "Or not right?",
            "This is important question because if you have a decision boundary, if you sort of move out, you would think it's pretty reasonable to become more and more certain.",
            "If you go away from the decision boundary if you.",
            "But if you move too far out from the data, you should actually become more uncertain, but to me it's not so precisely clear what what it means to measure how well you're doing their friends.",
            "If you take it, you know.",
            "So let's say you take a digit of two, you start rotating it, right, you know.",
            "Should you become uncertain if it's a 2 on the side or should you stay?",
            "Or is it estimating at two with high certainty still very good, you know?",
            "I don't precisely know what is the right answer there, but we should figure it out, though.",
            "I mean we should come up with benchmarks here.",
            "I think this isn't representative.",
            "Yes, yes, that's right, but you can always build that test set, unfortunately.",
            "So question, did people already do Beijing or is it already somebody treat visionary?",
            "Join us, yeah.",
            "OK, so maybe let me say a few words about them.",
            "Then I have only 5 more minutes.",
            "Where is not fair though right?",
            "Is the thing broke down?",
            "OK?",
            "OK so.",
            "Invasion learning, there's the posterior distribution of the parameters given XM as the model.",
            "That's the object you're really interested in.",
            "To compute the posterior distribution and then in prediction you have to average your models over.",
            "Basically, you have to wait your models by that posterior distribution, right?",
            "And again, there is a bias variance decomposition going in here, which is that if you have a very simple model like a linear regression model, then it can only model A very small subset of data, right?",
            "Namely all the straight lines.",
            "You can model fine with a linear model, but.",
            "In a space of all possible datasets, that's only putting your probability measure on a very small subset, so that's the blue line here.",
            "Now, if you have a very flexible model, then it can model all sorts of things, right?",
            "So it puts a probability mass everywhere.",
            "Unfortunately, a probability distribution has to be normalized, so if you spread your bets, you know your probability has to be lower at every possible every X.",
            "Right now, if the true axis here or you know if you review true access here, right?",
            "And you had your sort of two simple model peeking here, you know the probability of X is going to be very low, right?",
            "If it's too complex, you know it covers X, but since it has to normalize this pretty low right and so somewhere in the middle is the right sort of model complexity.",
            "OK."
        ],
        [
            "So what we can do is we can do variational Bayes.",
            "Exactly the same way as we did before with the variational autoencoder, so we can write down exactly the same bound, but now we replace sets by parameters data.",
            "So you look at P of X now marginally over the parameters and we bounded by exactly the same way.",
            "So this you know average over Q, which is your variational distribution log P of X given Theta, log P of Theta and minus the entropy term, which is again the bound and it's written out here.",
            "If I will."
        ],
        [
            "You need to stop.",
            "You gotta tell me it's OK. OK, so Karen is going to talk about, you know, one way of quantizing and compressing these neural networks using sort of this equation here I'll just differ.",
            "Skip it now here.",
            "I'll just talk about something else.",
            "But you know, there is this term, which is really the loss of the.",
            "Let me let me write it this way.",
            "So if I'm going to have to send you my data, but I can imagine that there is a game where I have to send my data to somebody else and have to encode it somehow.",
            "So one way to encode it is to 1st fit the model here, then send you the parameters, which is quite cheap.",
            "And then you use the model on the other side to make the predictions right, and then given those predictions, there's going to be some errors.",
            "And I'm going to send you the error still.",
            "Right, but since the errors are small compared to the original data points, I can encode them quite efficiently and it's this term which turns out to be the complexity cost, which is a very complex model.",
            "You'll pay a lot of you pay a lot for the complexity, and is this term which is the other was sending.",
            "The model is measured here, and this is the.",
            "The error, the error terms that you will still have to measure, since that's the this particular term here."
        ],
        [
            "OK, So what we're going to do is we're going to.",
            "So look at a neural net and we're going to say that you know if you have a posterior distribution over your parameters.",
            "You're basically injecting noise over those parameters of your model, right?",
            "So basically you're sampling models from your posterior over the parameters here, and that uncertainty will actually translate into uncertainty over your over hidden variables here, simply because the information all has to go through this bottleneck, right?",
            "An it's nice because dropout is actually also sort of putting noise on these latent variables.",
            "So the plan is to marginalized, marginalized out the weights now in for the price of introducing stochastic hidden units.",
            "So you take a neural net we have.",
            "We have a posterior distribution over these weights, but we're going to do is we're going to marginalized out these weights and move the stochasticity from these weights to hit the latent variables here.",
            "And so hidden variables then become latent variables if you want.",
            "They were going to reinterpret the stochastic stochastic city here as dropout noise, basically very reminiscent of dropout.",
            "The original dropout algorithm.",
            "And then in the end we're going to use sparsity inducing priors to prune weights an entire hidden units to get compression over a neural net."
        ],
        [
            "So maybe I should skip this for now."
        ],
        [
            "Let me just.",
            "Explain the local representation trick so there's in order to integrate out these parameters here in favor of stochasticity on the latent variables.",
            "What we're going to do is once again we're going to look at this bound so it's again the posterior distribution over Q&W times a log of Y given X&W and enters the complexity term here Now this week, and often compute exactly so we don't have to worry about it, so that part we can often just compute is this part that we have to worry about.",
            "Now let's rewrite this.",
            "As you know, this log P of Y given X&W.",
            "That's really going to write it as a loss function over Y and then file F is the prediction of Y&F.",
            "You can think of as W * 5 the previous, so B is the activation of these units.",
            "Here they get multiplied by W or they get through non linearity.",
            "Then they get multiplied by W and then they get they're predicting F here.",
            "So I can sort of introduce this extra integral over F over the F variables here and this indicator function here and then I can now integrate out the WS in favor of the FS and then it looks like this.",
            "So it turns out that now you write down L Y5F, which is these activations here and the Q distribution becomes a distribution over these activations given the previous text of activations.",
            "This could be.",
            "You might have to.",
            "Read about this to fully understand it, but the conclusion is that this is a trick to again reduce the variance and replace Stochastic city on the hidden units by stochasticity on the latent variables."
        ],
        [
            "You know, if you do multiple layers, it looks more like this, so you have a queue of.",
            "OK, so you have a.",
            "You have two of these layers.",
            "Now.",
            "The probability of the final layer given the layer before, which is here.",
            "Then the probability of this layer given the layer before, which is this thing here, and so it looks."
        ],
        [
            "OK, so I'll just skip now the."
        ],
        [
            "Last sort of details on how to process this, but now putting sparse priors on the weights and actually, you know, turning it into priors over the latent variables, you can actually start sort of pruning out weights, and here this is a demo by these guys here these Russian guys.",
            "And so this is.",
            "These are the weights of.",
            "So these are the patches of a convolutional neural net, and what you can see is that you know the runs.",
            "Basically the compression ratio goes up over 250 or something, or surpasses 250.",
            "But the accuracy doesn't change, which is very interesting, right?",
            "So you're basically pruning almost everything away, but the accuracy doesn't change."
        ],
        [
            "And here is for a fully connected neural net.",
            "Again the accuracy."
        ],
        [
            "He doesn't change.",
            "Right, but almost all of the units.",
            "All of the weights basically get removed."
        ],
        [
            "OK, so this is not readable unfortunately, but maybe let me say that.",
            "Here is compression rate of 700 times.",
            "So what does that mean?",
            "It means that out of every 700 weights, you keep one and all the rest are gone, right?",
            "And the amazing fact is that.",
            "It doesn't hurt performance.",
            "So we basically overparameterized that particular model by a factor of 700.",
            "OK, so maybe that's not actually, you know, that's the sparsity level.",
            "That's probably 0.6%, but this is after you actually do all the compression.",
            "You know the actual compression algorithm itself.",
            "There's by effect or 700.",
            "The other really nice thing about this is that you can actually also compute the fixed point precision of your weights, because you have a posterior distribution over your weight.",
            "You can just figure out which bits are significant and which bits of your weights are fluctuate ING under your posterior.",
            "And you can just remove them.",
            "And so you also get compression on your.",
            "And you're sort of representation of your weights, OK?"
        ],
        [
            "So then to conclude.",
            "So I would say that deep learning is not necessarily a silver bullet.",
            "It's particularly good at signal processing, so it's very good at auditory signals, image language as well, but it doesn't apply to everything.",
            "If you have just structured data, then I think gradient boosting machine just work is fine as a neural net.",
            "Optimization plays an important role in deep learning.",
            "In order to get good solutions.",
            "And in this talk, for instance, we looked at reducing the variance of the gradients in order to get be able to learn the variation autoencoder.",
            "And you know also the Bayesian deep learning model.",
            "We always remember that you know it's you know deep learning is not just.",
            "Optimization is also statistics.",
            "So you can combine your classical graphical model ideas with sort of deep learning by thinking of them as a conditional distribution and the various not encoder is an example of that.",
            "Bayesian deep Learning is an elegant way to combine to sort of more traditional statistics and graphical models with deep learning, and it helps a lot with compression.",
            "This get amazing compression rates.",
            "But it's a lot of things that we really don't know about deep learning, one of them being.",
            "Already a little bit addressed before, so why do they actually not overfit?",
            "You know it's kind of strange to have so much capacity of these models yet if you train them well with SGD, then you know they don't really overfit and the previous talk addressed that.",
            "Why'd as regular writers just SGD regularize so effectively?",
            "There's these adverse aerial examples for as many companies and people worry about a lot, so that's kind of strange behavior as well.",
            "So where does that come from?",
            "The first is a huge overpressurization.",
            "I still have 400 here, but sometimes it's 700, so why is it that we have to Stuart in order to optimize these algorithms?",
            "We have over parameterized by a factor of a couple of 100 and then prune them back down to a much smaller one.",
            "That's going to interesting is much harder to train them if you start with a small size in the beginning.",
            "Alright, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "Graphical models and their relationship to deep learning.",
                    "label": 0
                },
                {
                    "sent": "So maybe a bit different than what you've heard, but there's also going to be a lot of overlap because of the variational inference parts.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is the overview is this.",
                    "label": 0
                },
                {
                    "sent": "Can you read this?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to 1st talk about a little bit about machine learning as statistics, not as optimization only.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to talk a bit about.",
                    "label": 0
                },
                {
                    "sent": "I just give you a very simple introduction, very quick introduction into graphical models.",
                    "label": 0
                },
                {
                    "sent": "So that did people already somebody already teach about graphical models in general is just.",
                    "label": 0
                },
                {
                    "sent": "Yeah, did you retaliate?",
                    "label": 0
                },
                {
                    "sent": "A minute lecture intro to OK, so that's OK.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a little bit of repetition, nothing, but it's good to hear it from different perspectives.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to talk a little bit about inference.",
                    "label": 0
                },
                {
                    "sent": "Variational inference in that MCMC.",
                    "label": 1
                },
                {
                    "sent": "And then learning expectation maximization, amortized iemon variational autoencoder just a little bit because we already had that as well.",
                    "label": 0
                },
                {
                    "sent": "Going to talk about generative versus discriminative modeling, pros and cons and why they're both important.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to talk about very, very briefly say few words about deep learning.",
                    "label": 0
                },
                {
                    "sent": "CNN's yeah, I'm sure it's been covered extensively and just say one word about dropout because we need it.",
                    "label": 0
                },
                {
                    "sent": "Then in the last part of the lecture, which is about Bayesian inference, which is basically an application of how graphical models, Bayesian statistics and deep learning can be combined and actually can be applied to something very cool, which I think is is compression.",
                    "label": 0
                },
                {
                    "sent": "And there's some surprising results.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Oftentimes, deep learning is seen perhaps as an optimization problem, which is you have an objective.",
                    "label": 0
                },
                {
                    "sent": "You have a data set, and then you should try as hard as you can to optimize the objective, and then actually often you know you train for a week and the learning curve still goes becomes better and better right?",
                    "label": 0
                },
                {
                    "sent": "So this is a new way.",
                    "label": 0
                },
                {
                    "sent": "This is it didn't used to be like that and statistics is not like that.",
                    "label": 0
                },
                {
                    "sent": "So there's clearly a strong case to be made that optimization is extremely important for deep learning, but I want to sort of emphasize that a learning problem is more than just an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So in this case, let's say we have some data.",
                    "label": 0
                },
                {
                    "sent": "Here we have some X&Y's X being the inputs by being the labels, perhaps which are drawn from a joint distribution.",
                    "label": 0
                },
                {
                    "sent": "Right and then you know, I can write down some likelihood function here.",
                    "label": 0
                },
                {
                    "sent": "Maybe the log likelihood of the data given the parameters.",
                    "label": 0
                },
                {
                    "sent": "This could be an unsupervised learning problem and then we maximize over the parameters.",
                    "label": 0
                },
                {
                    "sent": "We could look at a supervised learning problem where we look at the conditional distribution of Y given X for X.",
                    "label": 0
                },
                {
                    "sent": "Is the input wise.",
                    "label": 0
                },
                {
                    "sent": "The labels you know there could be a hidden there could be a deep net sort of lurking inside here for instance.",
                    "label": 0
                },
                {
                    "sent": "And then we maximize over the parameters.",
                    "label": 0
                },
                {
                    "sent": "Or we could more generally define some kind of loss function where we try to match the label to the prediction of that label as you pull Y hat.",
                    "label": 0
                },
                {
                    "sent": "Now, why is it more than an optimization problem, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the question we want to answer now.",
                    "label": 0
                },
                {
                    "sent": "So let's so first of all, we assume that the data is drawn from some sort of a data distribution, let's say IID drawn.",
                    "label": 0
                },
                {
                    "sent": "But we only get to see one sample of that data distribution.",
                    "label": 0
                },
                {
                    "sent": "And so I could imagine sort of drawing multiple datasets from that distribution fee.",
                    "label": 0
                },
                {
                    "sent": "Right now, let's imagine that every one of those you know, let's say 10 different datasets.",
                    "label": 0
                },
                {
                    "sent": "I would sort of do my optimization right, and I would get the optimal parameters Theta for that particular sort of data set.",
                    "label": 0
                },
                {
                    "sent": "Now, since these datasets are slightly different because it randomly drawn also the optimal parameters are going to be slightly different, right?",
                    "label": 0
                },
                {
                    "sent": "So there's going to be sort of a distribution of maximum likelihood estimates in this parameter space.",
                    "label": 0
                },
                {
                    "sent": "So one question you can ask yourself, does it make sense to maximize further than this sort of shape of this distribution, right?",
                    "label": 0
                },
                {
                    "sent": "So if we have like sort of a let's say it's distributed like a normal distribution with a certain variance.",
                    "label": 0
                },
                {
                    "sent": "You know, and we know that there's this sort of distribution over parameters.",
                    "label": 0
                },
                {
                    "sent": "Now for our if we look at one particular data set, does it make sense to you know, once you enter that region to sort of try to actually optimize all the way down to the sort of the mean of that distribution?",
                    "label": 0
                },
                {
                    "sent": "And my argument is no, you don't, because that's exactly when you start to overfit on your distribution, right?",
                    "label": 0
                },
                {
                    "sent": "Because if you only seen one of these datasets, it could have been another one, and so the fluctuations.",
                    "label": 0
                },
                {
                    "sent": "That you get in these Emily estimates basically determine the scale at which you should sort of optimize.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can think of that as a bias variance tradeoff, which I think is you know if you want to take one thing one thing away from this lecture, or basically your summer school, then it's the bias variance tradeoff.",
                    "label": 0
                },
                {
                    "sent": "I think that's to the very very core of machine learning, and it has to do with this statistical nature.",
                    "label": 0
                },
                {
                    "sent": "And it has to do with overfitting and generalization in general.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you can imagine trying to, you know, let's say you build a machine that's trying to throw darts in a target, right?",
                    "label": 0
                },
                {
                    "sent": "So he's a target these four targets.",
                    "label": 0
                },
                {
                    "sent": "And you know the machine might be a bit wiggly because it's you know it's an unstable underground or something like that, which means that you might not.",
                    "label": 0
                },
                {
                    "sent": "Every time you shoot a dart it might not hit the target at the same spot.",
                    "label": 0
                },
                {
                    "sent": "Also, there might be a systematic mistake in this machine and error which which means that actually you know the mean of all the darts is also off from the center.",
                    "label": 0
                },
                {
                    "sent": "Right now we call sort of this we call a bias systematic error.",
                    "label": 0
                },
                {
                    "sent": "This we call a variance.",
                    "label": 0
                },
                {
                    "sent": "Right, and of course you could have both bysina variance, which is even worse, and this is a very lucky if you and have exactly the right model that's stable and shoots in the middle.",
                    "label": 0
                },
                {
                    "sent": "Then we have low bias and low variance.",
                    "label": 0
                },
                {
                    "sent": "That's really what you want to shoot for, but it requires you to basically know exactly what the data distribution is that generated the data.",
                    "label": 0
                },
                {
                    "sent": "Now, in a little bit more set of equations so that we have Y is the label you know there's some underlying function F of X they were trying to estimate, and then there is some label noise epsilon drawn from a normal distribution.",
                    "label": 0
                },
                {
                    "sent": "And then sort of we are interested in the error here.",
                    "label": 0
                },
                {
                    "sent": "The error for a point X, which is the difference between the true label Y and our estimate.",
                    "label": 0
                },
                {
                    "sent": "F hat you know there's the model that's trying to predict Y.",
                    "label": 0
                },
                {
                    "sent": "When we look at the squared error here and then you can decompose that is the famous bias variance sort of decomposition.",
                    "label": 0
                },
                {
                    "sent": "You can decompose that into three terms and the first term is the bias because it looks at the difference between the expected value of your estimate expectation taken over many datasets.",
                    "label": 0
                },
                {
                    "sent": "Trying to estimate F by repeating sort of estimating it on multiple datasets.",
                    "label": 0
                },
                {
                    "sent": "So that's the bias.",
                    "label": 0
                },
                {
                    "sent": "And then the next term is the variance, so that only depends on the estimator, right?",
                    "label": 0
                },
                {
                    "sent": "So the first name is acting very hard to estimate because you don't know F, But the second term you can definitely estimate because it only depends on the estimator and is the variance of the estimator.",
                    "label": 0
                },
                {
                    "sent": "And then there's the theater, which is basically the label noise.",
                    "label": 0
                },
                {
                    "sent": "Right and then the name of the game is to try to, you know, get either the by is down or the variance down you know in order to get the total error down.",
                    "label": 0
                },
                {
                    "sent": "And sometimes it's better to get the bias now and sometimes it's better to get the variance down right, but you're really interested into some of these two things, and so that's what you see here now on the X axis is model complexity.",
                    "label": 0
                },
                {
                    "sent": "So if you have a really simple model with very few parameters, let's say you know you're trying to fit a linear regression model.",
                    "label": 0
                },
                {
                    "sent": "Very few parameters, then the variance is going to be very small, and so you're on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "Here the variance is going to be very small, but the bias is very large, because if the true line you're trying to fit this curvy you're trying to fit it with a linear line.",
                    "label": 0
                },
                {
                    "sent": "Clearly you're making a big mistake.",
                    "label": 0
                },
                {
                    "sent": "Alright, and on the other end of the spectrum, devise is going to be small or it's very complicated model.",
                    "label": 0
                },
                {
                    "sent": "It can fit basically everything, but on a particular data set you might still get a large error, which means that the variance is high, and then you want to sort of trade these two often optimal point, which is where the bias squared in the variance added up is minimal.",
                    "label": 0
                },
                {
                    "sent": "And there's a total error or the risk.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so so that's sort of the introduction and you know machine learning in some sense.",
                    "label": 0
                },
                {
                    "sent": "You know the basic concepts, but this bias variance tradeoff will keep coming back.",
                    "label": 0
                },
                {
                    "sent": "Now first do a very quick introduction, an graphical model, so this is sort of old style machine learning if you want, but I still think it's really important.",
                    "label": 0
                },
                {
                    "sent": "There's also bubbles here, like in neural Nets, but they mean something else.",
                    "label": 0
                },
                {
                    "sent": "In this case, they mean stochastic random variables, and typically when you model something like with a Bayes net or some graphical model, you have a pretty good sense of what these variables mean, right?",
                    "label": 0
                },
                {
                    "sent": "So let's say in this case you know there is rush hour, bad weather accident and rush hour.",
                    "label": 0
                },
                {
                    "sent": "An bet whether they.",
                    "label": 0
                },
                {
                    "sent": "Cause traffic jams in bad weather also causes accidents.",
                    "label": 0
                },
                {
                    "sent": "And and then accidents also cause sirens, right?",
                    "label": 0
                },
                {
                    "sent": "So there's a bit of a causal relationships between all these variables.",
                    "label": 0
                },
                {
                    "sent": "They mean something and you're trying to fit that model to the data.",
                    "label": 0
                },
                {
                    "sent": "And this is what we actually.",
                    "label": 0
                },
                {
                    "sent": "This is what I think of as the classical way of actually modeling.",
                    "label": 0
                },
                {
                    "sent": "You write down a model that you understand the variables mean something.",
                    "label": 0
                },
                {
                    "sent": "The relationships mean something.",
                    "label": 0
                },
                {
                    "sent": "Typically these models are not huge black boxes where none of the parameters make sense anymore.",
                    "label": 0
                },
                {
                    "sent": "And then the beauty of graphical models is that you can write down for every one of those diagrams.",
                    "label": 0
                },
                {
                    "sent": "Here in this case, with arrows, you can write down a joint probability distribution over all of these random variables.",
                    "label": 0
                },
                {
                    "sent": "So in this case the joint probability is the probability of traffic jam given all of its parents, which is the inflowing arrows here.",
                    "label": 0
                },
                {
                    "sent": "So, given rush hour, bet whether an accident.",
                    "label": 0
                },
                {
                    "sent": "Alright, and then times the probability of in this case or sirens, which is this one here given its parent which is accident and then the probability of accident given its peer in bad weather and in two marginals probability of rush hour and the probability of bad weather, right?",
                    "label": 0
                },
                {
                    "sent": "So you decompose this and then there's a certain rules which I'll explain in a minute that will basically allow you to read off from the diagram.",
                    "label": 0
                },
                {
                    "sent": "All the marginal and conditional independence relationships that are implied by that graph, and that's the power of it, because you could look at it, you can communicate about it and you just at some point you start to read these things and you see all the conditional independence relationships right.",
                    "label": 0
                },
                {
                    "sent": "It makes sense.",
                    "label": 0
                },
                {
                    "sent": "For instance in this case is rush hour is marginally independent from bad weather, you know they don't influence each other.",
                    "label": 0
                },
                {
                    "sent": "There are two independent processes which influence other things, right?",
                    "label": 0
                },
                {
                    "sent": "But for instance, traffic jam is not going to be conditionally independent.",
                    "label": 0
                },
                {
                    "sent": "Of sort of rush hour is not going to be conditionally independent of bad weather.",
                    "label": 0
                },
                {
                    "sent": "If I observe a traffic jam.",
                    "label": 0
                },
                {
                    "sent": "And that's called explaining away because if I explain traffic jam for instance by bad weather, then my probability or my belief that the rush hour would be the cause of the traffic jam is going to shift is going to change because I've already.",
                    "label": 0
                },
                {
                    "sent": "I've already explained it by another parameter, so the power is now that the claim is that which ever conditional probability distribution.",
                    "label": 0
                },
                {
                    "sent": "You can read out from that graph by the rules I'll see in a minute.",
                    "label": 0
                },
                {
                    "sent": "It will correspond to doing a calculation in that graphical model, so you know you have to marginalise out some things that you have to condition on some things.",
                    "label": 0
                },
                {
                    "sent": "But then if you after you do that, the conditional probability distributions match, and that's a really powerful statement.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so then what is the?",
                    "label": 0
                },
                {
                    "sent": "I'm going to speed up a little bit of time now.",
                    "label": 0
                },
                {
                    "sent": "So what is the algorithm that you can use in order to visually figure out what the conditional independence relationships are?",
                    "label": 0
                },
                {
                    "sent": "And that's called the baseball algorithm.",
                    "label": 0
                },
                {
                    "sent": "I didn't notice it's new to you.",
                    "label": 0
                },
                {
                    "sent": "So the baseball algorithm basically is a bunch of rules which says if two variables are independent, there can be no path between those two variables and so filled variables is when you condition on them, which sort of means you observe them and other variables that you don't condition are open right.",
                    "label": 0
                },
                {
                    "sent": "And so if we can sort of, say, whether rush hour and bad weather or marginally independent, there should be no path between these two, and that's because you know this is path is blocked here.",
                    "label": 0
                },
                {
                    "sent": "And that's that's the explaining away path.",
                    "label": 0
                },
                {
                    "sent": "Well, if you would if you would marginalise it out, you know you know, then you would.",
                    "label": 0
                },
                {
                    "sent": "There should be no, it should be.",
                    "label": 0
                },
                {
                    "sent": "Pass between those two when there's not conditioning on them, and then.",
                    "label": 0
                },
                {
                    "sent": "Sorry, when you conditioning on them then you then you are here and then you're let through.",
                    "label": 0
                },
                {
                    "sent": "So if you are let through, in fact there is dependencies.",
                    "label": 0
                },
                {
                    "sent": "If you condition there is dependencies when you're not conditioning on it there, there is no dependencies because you cannot go from here to here and there's all these rules can help you figure out these conditional independence relationship.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's a similar sort of process for another class of models, which is called Markov random fields, so these are the undirected models, like if you have an image, you can put every pixel is a random variable, and there is symmetric relationship between the pixels which could say something like.",
                    "label": 0
                },
                {
                    "sent": "This pixel has a particular color, the likely hood of probability that the neighbor has the same color is a bit higher, right?",
                    "label": 0
                },
                {
                    "sent": "And here the conditional independence relationships look as follows.",
                    "label": 0
                },
                {
                    "sent": "If you want to figure out whether this node is independent of this node.",
                    "label": 0
                },
                {
                    "sent": "Given this node, you should see if there's any path going through it.",
                    "label": 0
                },
                {
                    "sent": "And essentially conditioning on these two nodes here, you know.",
                    "label": 0
                },
                {
                    "sent": "Basically there's no.",
                    "label": 0
                },
                {
                    "sent": "There's no pass, every pass gets blocked from here to here, which means that they are conditioning independent and there's a similar theorem, which is that if you write the probability distribution as the product over positive clicks, so these have to be positive where click or a maximal clique is actually a group of variables which are all connected and cannot be extended.",
                    "label": 0
                },
                {
                    "sent": "So this is a clique and this is a clique and this is the click etc.",
                    "label": 0
                },
                {
                    "sent": "If you take that product and you normalize it.",
                    "label": 0
                },
                {
                    "sent": "Then if you compute your conditional independence relationships using that equation, you'll get the same answer as you could read out from the equations.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one particular.",
                    "label": 0
                },
                {
                    "sent": "Class of latent variable models.",
                    "label": 0
                },
                {
                    "sent": "So certain class of Bayesian neural network, which is particularly powerful is called a latent variable model.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you've seen already quite a bit of this, so in the latent variable model you have some observed random variables and you model them by basic introducing some latent stochastic random variables.",
                    "label": 0
                },
                {
                    "sent": "Here is that once was at M, you don't necessarily know what these are, but you know you could try to interpret them after the fact.",
                    "label": 0
                },
                {
                    "sent": "These could be topics which could describe, for instance.",
                    "label": 0
                },
                {
                    "sent": "Documents or something like that, and then the distribution over the observed random variables X is given as the marginal over this graphical model, right?",
                    "label": 0
                },
                {
                    "sent": "So this is X given Zed Bayes net, so it's X Givens at times to prior P of Z and then you marginalized out set variable here to get P of X.",
                    "label": 0
                },
                {
                    "sent": "And because you marginalized over a potentially exponential number of joint states, zed is actually a very powerful model.",
                    "label": 0
                },
                {
                    "sent": "You know this is, you know, it's nice to write down something like that, but in order to use it you have to do inference.",
                    "label": 0
                },
                {
                    "sent": "An inference is, for instance, computing the probability of the latent variables given the observed variables.",
                    "label": 0
                },
                {
                    "sent": "You know that's the thing that's interesting in its own right.",
                    "label": 0
                },
                {
                    "sent": "You might want to compute the probability of this topic.",
                    "label": 0
                },
                {
                    "sent": "You know, in this particular document, but you also turns out you also needed for learning inside the EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'll say a few words about that in a minute.",
                    "label": 0
                },
                {
                    "sent": "OK, so then there is 2.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Class.",
                    "label": 0
                },
                {
                    "sent": "Two classes of variable algorithms that you can use to do this approximate inference.",
                    "label": 0
                },
                {
                    "sent": "And there is a variational inference class, and then there is the MCMC sampling class of approximate inference, and I'll say a little bit about both of these class of algorithms.",
                    "label": 0
                },
                {
                    "sent": "So variational inference is as follows.",
                    "label": 1
                },
                {
                    "sent": "So you have a target distribution P. This could be the posterior P of Z given X.",
                    "label": 0
                },
                {
                    "sent": "Right, and you're trying to find a approximating distribution within a family that's fully tractable.",
                    "label": 0
                },
                {
                    "sent": "For instance, you could decide that you just want to work with normal distributions, and then you're trying to find the normal distribution with, let's say, the best mean and variance or covariance matrix that approximate it gets close as possible to the true distribution.",
                    "label": 0
                },
                {
                    "sent": "And and close in closest you use the KL there, virgins.",
                    "label": 0
                },
                {
                    "sent": "In order to measure what closeness means.",
                    "label": 0
                },
                {
                    "sent": "In this case, KL between Q&P.",
                    "label": 0
                },
                {
                    "sent": "Now in sampling, however, what you do is you take your distribution.",
                    "label": 0
                },
                {
                    "sent": "Let's say P is here this distribution and you're going to represent it with a bunch of points, right?",
                    "label": 0
                },
                {
                    "sent": "Just a collection of randomly sampled points.",
                    "label": 0
                },
                {
                    "sent": "And then an expectation is computed instead of computing the actual expectation over the probability P, you evaluate the function that you want to compute the expectation over at these dots.",
                    "label": 0
                },
                {
                    "sent": "And then you sum them and average them over the number of dots.",
                    "label": 0
                },
                {
                    "sent": "Now, both of these families advantages and disadvantages, and here again, the theme of bias and variance returns.",
                    "label": 0
                },
                {
                    "sent": "So this is just an optimization algorithm, so you turn inference in optimization in some sense is deterministic, so it's quite easy to figure out whether you've converged or not, as you can throw all your optimization tools at the problem.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, there are local minima, so it's not trivial to do the optimization, but the most important part is that it's biased, right?",
                    "label": 0
                },
                {
                    "sent": "Because this is never going to be this if it needs to stay within Distractible distribution.",
                    "label": 0
                },
                {
                    "sent": "So it's bias, but it doesn't have variance because you know in principle when you do your work, you always get to the same Q star.",
                    "label": 0
                },
                {
                    "sent": "Now, in terms of sampling is to reverse?",
                    "label": 0
                },
                {
                    "sent": "Or if you have a proper procedure then in principle you should be unbiased.",
                    "label": 0
                },
                {
                    "sent": "You should get the right sort of answer on average.",
                    "label": 0
                },
                {
                    "sent": "If you repeat an infinite number of times, but for any particular instance of your MCMC run, you know you get a different answer than the next one, and so there is variance in your error now.",
                    "label": 0
                },
                {
                    "sent": "So there's there's error related to the variance of that estimation procedure.",
                    "label": 0
                },
                {
                    "sent": "Now the the multiple modes issue doesn't go away.",
                    "label": 0
                },
                {
                    "sent": "So here you have multiple Optima to do your optimization.",
                    "label": 0
                },
                {
                    "sent": "Here you have multiple modes in your sampling distribution is very hard to sort of mix between one mode in another mode you have to work really hard to make that happen, and it's very difficult to assess convergence.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so there's a bunch of really sort of simple sort of.",
                    "label": 0
                },
                {
                    "sent": "Maybe your first idea would be something very simple like, well, you know what if this is my true distribution?",
                    "label": 0
                },
                {
                    "sent": "I'm trying to sample from and this is my.",
                    "label": 0
                },
                {
                    "sent": "This is a very simple distribution I just draw from this bigger distribution and then delete everything in a smart way.",
                    "label": 0
                },
                {
                    "sent": "That's not, you know, inside the region of the true distribution, right?",
                    "label": 0
                },
                {
                    "sent": "That's called rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "It really doesn't work in high dimensions, or you should forget it actually.",
                    "label": 0
                },
                {
                    "sent": "And then there's important sampling.",
                    "label": 0
                },
                {
                    "sent": "We do something similar.",
                    "label": 0
                },
                {
                    "sent": "But it assigns weights to each one of the data points where data points which are close to the true distribution are have higher weight than the than the ones that you draw far away.",
                    "label": 0
                },
                {
                    "sent": "All of these things really don't work in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "The thing that does work in high dimensions is called Markov chain Monte Carlo, and I'll say a few words about that in a minute, and the idea is basically that you start just like an optimization problem.",
                    "label": 1
                },
                {
                    "sent": "You draw your first sample from a completely wrong distribution that could be very far away from the distribution you're interested in.",
                    "label": 0
                },
                {
                    "sent": "And then you have a transition kernel, so the next sample you draw from a different distribution and then the next sample you draw again from a different distribution and the distributions from which you are sampling are actually slowly converging to the true distribution, right?",
                    "label": 0
                },
                {
                    "sent": "Because the first sample is actually drawn from the wrong distribution, you should throw them away.",
                    "label": 0
                },
                {
                    "sent": "That's called the burn in and the ones which are you know at the right sort of.",
                    "label": 0
                },
                {
                    "sent": "You know when it arrives at the correct distribution then you should collect these samples.",
                    "label": 0
                },
                {
                    "sent": "So this is similar to sort of what I said in the beginning, where if you have, you know if you know that for different datasets you know you would have different maximum likelihood estimators.",
                    "label": 0
                },
                {
                    "sent": "There is a certain range in which these maximum likelihood estimators lie.",
                    "label": 0
                },
                {
                    "sent": "Now this is a you know I haven't talked about it a little in a minute.",
                    "label": 0
                },
                {
                    "sent": "This is a is a Bayesian procedure where you try to estimate.",
                    "label": 0
                },
                {
                    "sent": "We try to sample the parameters of a model given the data and you know you could sort of think of that range that posterior distribution as.",
                    "label": 0
                },
                {
                    "sent": "The range in which you sort of sample models from that distribution and note that it doesn't all the way optimize down to the middle here because it doesn't make sense.",
                    "label": 0
                },
                {
                    "sent": "It basically says there is a particular optimal optimal scale over which I should not optimize any further at the point when I get to that scale here, I should really draw samples from that distribution.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in a little bit more detail, so the way that works is you start with the.",
                    "label": 0
                },
                {
                    "sent": "You know with an initial parameter estimate.",
                    "label": 0
                },
                {
                    "sent": "So let's say we do invasion running, but I'm sort of fast tracking a little bit because I'll talk more about this in, you know, little further down.",
                    "label": 0
                },
                {
                    "sent": "So you start you start with your first parameter, estimate that you can think of this system random variable and then you go.",
                    "label": 0
                },
                {
                    "sent": "So you take the first one.",
                    "label": 0
                },
                {
                    "sent": "You know, given this one and then the second one given this one, and this chain keeps on going until you sort of reach the place where you know the posterior distribution lies.",
                    "label": 0
                },
                {
                    "sent": "So you can think of these as weights of a neural net.",
                    "label": 0
                },
                {
                    "sent": "And then as you go sampling in the beginning, they're just random, so there didn't look like anything.",
                    "label": 0
                },
                {
                    "sent": "And then they didn't do much and then.",
                    "label": 0
                },
                {
                    "sent": "Around convergence you know you have sort of trained your whole neural net and then you sort of sampling from the parameters from the right distribution.",
                    "label": 0
                },
                {
                    "sent": "Again, the burden should be thrown away and then here there is this very important object which is a transition probability, which is the probability of picking your next point given your previous point, and that's the object that you have that you can design yourself so you can sort of design A distribution T. Now it has to have a property that it will eventually the sequence will sample from the correct equilibrium distribution.",
                    "label": 0
                },
                {
                    "sent": "And there's a bunch of tricks I won't really go into detail.",
                    "label": 0
                },
                {
                    "sent": "Balance is one of them.",
                    "label": 0
                },
                {
                    "sent": "That would guarantee that you would go to the correct distribution, but unfortunately, you know you can come up with quite simple ones.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that they mix very slowly, so you can think of that.",
                    "label": 0
                },
                {
                    "sent": "Perhaps as I'll show a few demos in a minute, but if they're mixing is very slow and sort of this optimization process, or this way that this sort of sequence progress is very slow.",
                    "label": 0
                },
                {
                    "sent": "Now here you can see an example of that.",
                    "label": 0
                },
                {
                    "sent": "You know when it's already sampling from the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "So when the mixing is very slow, two subsequent samples are highly correlated.",
                    "label": 0
                },
                {
                    "sent": "So you can think of, like you know, this is my current sample, and when I'm drawing my next sample just very closely around me, then of course the next sample in the previous sample are going to be highly correlated with each other and that's very slow mixing, so that's what you're going to see here.",
                    "label": 0
                },
                {
                    "sent": "So these autocorrelation is very high, so this is a much better sampler where basically every next sample is almost.",
                    "label": 0
                },
                {
                    "sent": "Independent.",
                    "label": 0
                },
                {
                    "sent": "And you're going to pay a price for the fact that you have this autocorrelation in your MCM MCMC chain, because it's very easy to come up with very badly mixing samplers, but you pay a big price.",
                    "label": 0
                },
                {
                    "sent": "So here again, we have the variance bias decomposition.",
                    "label": 0
                },
                {
                    "sent": "So as I said, if I want to compute some integral I, which is an expectation over a function F over my target distribution S 0, then I'm going to instead of doing the exact computation I'm going to replace that by evaluating the function.",
                    "label": 0
                },
                {
                    "sent": "At the parameter estimates data, which are my samples and then sort of averaging over those samples.",
                    "label": 0
                },
                {
                    "sent": "And again I can compute a bias in a variance and there is just like I talked about before, there's a bias variance decomposition, so the bias is basically the difference between the expected estimate off your integral minus the true value.",
                    "label": 0
                },
                {
                    "sent": "Now if you do your work rights, if you get if you sample eventually from the correct distribution, then this body should be 0 in this case, so the expectation is basically taking over.",
                    "label": 0
                },
                {
                    "sent": "Many, many MCMC runs, so if you take a thousands and thousands of MCMC runs, you take the expectation over all of these.",
                    "label": 0
                },
                {
                    "sent": "Then there's expectation should go to 0, so the bias is there's no bias is an unbiased estimator, but there is variance.",
                    "label": 0
                },
                {
                    "sent": "Clearly, because every single set of MCMC run looks different from the other and then, so the variance of this estimate of the integral is a bunch of terms.",
                    "label": 0
                },
                {
                    "sent": "First, the variance of the function F itself.",
                    "label": 0
                },
                {
                    "sent": "So how much does it vary?",
                    "label": 0
                },
                {
                    "sent": "And then divide it by T, which is the number of samples that you're averaging over.",
                    "label": 0
                },
                {
                    "sent": "Clearly, if you draw more samples than the variance goes down, But there's this Tau here, which is the article relation coefficient, which basically tells you if Tau equals one, then every.",
                    "label": 0
                },
                {
                    "sent": "Now equals one in every sample counts as independent, but otherwise you know if targets bigger, then unfortunately you know there every sample counts as a fraction of a sort of a sample, right?",
                    "label": 0
                },
                {
                    "sent": "Because if this is a very large then the variance is very high and you need many more draw need to draw many more samples in order to get the same variance.",
                    "label": 0
                },
                {
                    "sent": "If you would have an independent sample for instance.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so as I said, the transition kernel is at your disposal, so you can.",
                    "label": 1
                },
                {
                    "sent": "You can design it and smart MCMC algorithms basically have smart kernels.",
                    "label": 0
                },
                {
                    "sent": "And here's this very simple one that I argue, and you know many people argue it doesn't really work very well, But anyway it's very convenient.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you propose your next parameter value or random variable.",
                    "label": 0
                },
                {
                    "sent": "Given your, you're currently at Theta T, which is your current random variable and then you propose a new parameter value from some distribution Q and you can choose.",
                    "label": 0
                },
                {
                    "sent": "Queue whatever you want.",
                    "label": 0
                },
                {
                    "sent": "So there's some Q distribution, so typically you want to choose cube quite close to where you currently are.",
                    "label": 0
                },
                {
                    "sent": "So let's say Gaussian distribution centered around.",
                    "label": 0
                },
                {
                    "sent": "You know where you currently are.",
                    "label": 0
                },
                {
                    "sent": "And then you have to compute the probability of accepting that particular proposed sample.",
                    "label": 0
                },
                {
                    "sent": "So if you accept it, you added to the stack.",
                    "label": 1
                },
                {
                    "sent": "If you reject it, then you add a copy of the previous sample to this deck so you get 2 copies of the same sample.",
                    "label": 0
                },
                {
                    "sent": "Then and the way that you sort of compute that is to say, well, there's this fraction here, as is the target distribution, so it's the ratio between the target distribution at the new sample divided by the old sample.",
                    "label": 1
                },
                {
                    "sent": "So in other words, if the probability of the new sample is.",
                    "label": 0
                },
                {
                    "sent": "Much higher you tend to accept that sample, so you going up in probability and then there's this one here, which basically says the probability of going backwards.",
                    "label": 0
                },
                {
                    "sent": "This has to do with detailed balance because you want the total probability flow from Theta T to Theta prime to be the same as the total probability flow from Theta prime back to Theta, and if these two match then you can prove detailed balance.",
                    "label": 1
                },
                {
                    "sent": "You can prove that you converge to the correct distribution South here.",
                    "label": 0
                },
                {
                    "sent": "So if this whole thing is larger than one, then you know you accept all the time.",
                    "label": 0
                },
                {
                    "sent": "If it's if it's smaller than one that you accept with probability given by that fraction.",
                    "label": 0
                },
                {
                    "sent": "OK, so now there's one really big problem with this, so let's say we're doing again Vision Vision.",
                    "label": 0
                },
                {
                    "sent": "Sampling the problem is that it this is order N and the reason is that the probability this target distribution here is the prior times the product over all the data points of XT given Theta an.",
                    "label": 0
                },
                {
                    "sent": "It's two sort of expensive to compute that if you have a really large data set, right?",
                    "label": 0
                },
                {
                    "sent": "So if you have like a billion data points and for every sample that you want to draw you need to compute this thing for a billion data points and that's just way too slow.",
                    "label": 0
                },
                {
                    "sent": "In fact there is this thing which I call a big data test.",
                    "label": 0
                },
                {
                    "sent": "You can imagine if you have like an infinite data set right?",
                    "label": 0
                },
                {
                    "sent": "Could you?",
                    "label": 0
                },
                {
                    "sent": "Would you make any progress?",
                    "label": 0
                },
                {
                    "sent": "Would you get a good estimator in a finite amount of town time right?",
                    "label": 0
                },
                {
                    "sent": "And so you should right, because you know if you have a very large data set you could always choose to ignore the fraction of that data set.",
                    "label": 0
                },
                {
                    "sent": "And so you should be able to create in a finite amount of time a pretty good model.",
                    "label": 0
                },
                {
                    "sent": "But this procedure doesn't progress at all in infinite and infinite data set.",
                    "label": 0
                },
                {
                    "sent": "What was going to happen is that you know you will never.",
                    "label": 0
                },
                {
                    "sent": "This computation here will never end, and so it's a very bad procedure instead of the big data limit.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so again, going back to this bias variance decomposition idea.",
                    "label": 0
                },
                {
                    "sent": "So could we do something about this?",
                    "label": 0
                },
                {
                    "sent": "Well, one way you know we know that from variational inference.",
                    "label": 0
                },
                {
                    "sent": "We're not afraid of a biased procedure, right?",
                    "label": 0
                },
                {
                    "sent": "So if that helps us a lot, then maybe buys isn't all that bad.",
                    "label": 0
                },
                {
                    "sent": "So one question you could ask yourself, could we make an MCMC procedure biased right?",
                    "label": 0
                },
                {
                    "sent": "But but but the fact that it becomes biased in return will get a much more efficient, faster sampling procedures.",
                    "label": 0
                },
                {
                    "sent": "So we get lots more samples and you have a lot more samples then we can get the variance down our estimator.",
                    "label": 0
                },
                {
                    "sent": "Right, and so the idea is, let's say, well, OK, let's say this is the true distribution you want to sample from.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe I can just relax a little bit on that distribution.",
                    "label": 0
                },
                {
                    "sent": "Perhaps I can draw a lot of samples so my bias will go up, but my variance will go down.",
                    "label": 0
                },
                {
                    "sent": "Right on the other end, you know if I have a procedure with the NOB, they could sort of trade these things off and the other end, you know, I would have to completely unbiased procedure, which is the normal MCMC procedure.",
                    "label": 0
                },
                {
                    "sent": "Unforeseen is very expensive, right?",
                    "label": 0
                },
                {
                    "sent": "Because if I have a billion data points, you would have to do lots and lots of computations, so can only in a finite amount of time can only draw three samples and then they might have a very large variance in my in my error.",
                    "label": 0
                },
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "The idea is you know, can I trade up?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Between these things, right?",
                    "label": 0
                },
                {
                    "sent": "So here's again, sort of this decomposition.",
                    "label": 0
                },
                {
                    "sent": "This is the integral that they want to compute.",
                    "label": 0
                },
                {
                    "sent": "I'm looking at the squared error averaged over sort of any sort of sample, so efforts over the distribution and there's a bias term, which is, you know, the expected value under P minus the expected value under my on the true distribution, mine is expected under the estimated distribution and enters the variance term.",
                    "label": 0
                },
                {
                    "sent": "Now if I'm giving myself a finite amount of computation, I think everybody should sort of think in terms of, you know, a procedure.",
                    "label": 0
                },
                {
                    "sent": "Death is allowed to compute only for a finite amount of time, right?",
                    "label": 0
                },
                {
                    "sent": "Because there is not infinite amount of time in 40, so that's pretty reasonable.",
                    "label": 1
                },
                {
                    "sent": "And when you have a big data set to take time and computation time into account, so let's say I'm now.",
                    "label": 0
                },
                {
                    "sent": "I'm going to allow myself, let's say one hour to do my computation, right.",
                    "label": 0
                },
                {
                    "sent": "This is the typical sort of, you know, before the nips.",
                    "label": 0
                },
                {
                    "sent": "Deadline is 1 hour before the dip nips deadline.",
                    "label": 0
                },
                {
                    "sent": "I need to run another experiment, right?",
                    "label": 0
                },
                {
                    "sent": "You know how?",
                    "label": 0
                },
                {
                    "sent": "How should I set epsilon so there's one curve which is to buy a switch here on this axis here is epsilon, which is my trade off parameter I. I'm assuming I have this bias variance tradeoff parameter, so if it's all the way to the left you my bias is very low, right?",
                    "label": 0
                },
                {
                    "sent": "But my variance is very high because it not drawing a lot of samples.",
                    "label": 0
                },
                {
                    "sent": "And then the optimal risk you know is sort of here.",
                    "label": 1
                },
                {
                    "sent": "So this is where you should set your epsilon, but they're going to allow myself a lot of computation time.",
                    "label": 0
                },
                {
                    "sent": "Let's say I have you know, a day before the deadline, then what happens is that here the variance is not going to be super high because I have a lot of time to draw my samples anyway, right?",
                    "label": 0
                },
                {
                    "sent": "So the variance error is not so high and the bias is zero anyway.",
                    "label": 0
                },
                {
                    "sent": "And then when I draw my nob to the right and I'm sort of increasing my bias, then yes, the variance goes down.",
                    "label": 0
                },
                {
                    "sent": "And bias goes up, but then the optimal here for epsilon different.",
                    "label": 0
                },
                {
                    "sent": "Right, and this is the take home message that you know in MCMC procedure, whatever you do will have, you will have to run it for a finite amount of time, right?",
                    "label": 0
                },
                {
                    "sent": "You might have very large datasets or this tradeoff in computation time is always there, and if you have this nob where you can trade of bias and variance in its nest is not necessarily the case that setting that NOB 20 bias, which is the normal MCMC procedure, is the optimal way.",
                    "label": 0
                },
                {
                    "sent": "Optimal way of going.",
                    "label": 0
                },
                {
                    "sent": "OK, so then.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a very, very simple algorithm that.",
                    "label": 0
                },
                {
                    "sent": "Basically, mimic stochastic gradient descent.",
                    "label": 1
                },
                {
                    "sent": "An Bob has this property that you know when it gets close to the target distribution, it will start approximately sampling from the correct to the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Now we all know sort of stochastic gradient descent, so there's a prior over parameters, and then there's a likelihood term here right?",
                    "label": 0
                },
                {
                    "sent": "And we take a gradient with respect to Theta.",
                    "label": 0
                },
                {
                    "sent": "We take a step in Theta in parameter space which is epsilon over 2 times.",
                    "label": 0
                },
                {
                    "sent": "You know tempted gradient of the log prior terms of grading of the log likelihood term.",
                    "label": 0
                },
                {
                    "sent": "So that's easy.",
                    "label": 0
                },
                {
                    "sent": "So that's actually gradient descent.",
                    "label": 1
                },
                {
                    "sent": "Now stochastic gradient descent looks like this.",
                    "label": 0
                },
                {
                    "sent": "Instead of, you know, so this will not pass the big data test clearly, because if this is infinite, you will not make a single step.",
                    "label": 0
                },
                {
                    "sent": "So to create something that actually will compute for, you know for an infinite data set, use a procedure where you draw a finite subsample from your full data set, and then you replace.",
                    "label": 0
                },
                {
                    "sent": "So that's a stochastic.",
                    "label": 0
                },
                {
                    "sent": "That's sort of an unbiased estimator of this.",
                    "label": 0
                },
                {
                    "sent": "Some right you add this vector capital N over small and to make sure that it's at the right scale.",
                    "label": 0
                },
                {
                    "sent": "Niantic rating of the likelihood and then what people typically do is you.",
                    "label": 0
                },
                {
                    "sent": "You pick up mini batch, you take a gradient, pick another mini batch, take another gradient step, etc.",
                    "label": 0
                },
                {
                    "sent": "And then you anneal the step size is kind of important.",
                    "label": 0
                },
                {
                    "sent": "There's some properties that you have to satisfy to guarantee you know to convert to the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "So you need the step size in order to get to the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "Now in neural networks, clearly that's the way to go.",
                    "label": 0
                },
                {
                    "sent": "We all know this.",
                    "label": 0
                },
                {
                    "sent": "Now here's a tiny, so here's another algorithm.",
                    "label": 0
                },
                {
                    "sent": "It really looks like stochastic.",
                    "label": 0
                },
                {
                    "sent": "Looks like gradient descent, which is larger than dynamics, and what that does is you take a step according to the gradient of the.",
                    "label": 0
                },
                {
                    "sent": "You know the the prior plus the log likelihood, but then you add a bit of noise and the thing to observe is, although it's pretty hard to see unfortunately.",
                    "label": 0
                },
                {
                    "sent": "The there's a step size here, which is epsilon over 2 and the noise variance that you're adding has a variance of apps of epsilon.",
                    "label": 0
                },
                {
                    "sent": "So the important variance of the noise that you're adding.",
                    "label": 0
                },
                {
                    "sent": "Is the same as two times the step size, so that's a if you don't do that, then it won't.",
                    "label": 0
                },
                {
                    "sent": "You know even approximately sampling the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "Now there you have to still add in Metropolis Hastings accept reject step to do the correct sampling, but in the limit when epsilon goes to 0 actually everything will be accepted.",
                    "label": 0
                },
                {
                    "sent": "This kind of nice property if the if you take tiny steps then you will always accept.",
                    "label": 0
                },
                {
                    "sent": "The problem is that you did not mixing very fast.",
                    "label": 0
                },
                {
                    "sent": "So here's to you, know the little modification.",
                    "label": 0
                },
                {
                    "sent": "You say, well, let's just look like, you know, make it look like stochastic gradient descent place, you know, make a small mini batch and do the sum over that.",
                    "label": 0
                },
                {
                    "sent": "Keep adding the noise as you did before.",
                    "label": 0
                },
                {
                    "sent": "You want annealing as before, but skip the metropolis Hastings accept reject step.",
                    "label": 0
                },
                {
                    "sent": "Now that's just the same as the guesser grading to send, but you just add noise was very cheap, right?",
                    "label": 0
                },
                {
                    "sent": "And the miracle is that this actually in the limit for small step size will sample from the correct distribution, but since we're not doing a metropolis, Hastings accept reject step and actually we have a finite step size.",
                    "label": 0
                },
                {
                    "sent": "There is a bit of bias in this distribution, right?",
                    "label": 0
                },
                {
                    "sent": "So the step size will now be Arnab.",
                    "label": 0
                },
                {
                    "sent": "The trades of bias and variance.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's a little demo on.",
                    "label": 0
                },
                {
                    "sent": "Firstly, also the resolution makes this look a little bit ugly, but you know this is a distribution here 2 dimensional distribution.",
                    "label": 0
                },
                {
                    "sent": "An here this little snake that's running around is our sample is the last 10 samples.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it makes it jump to sort of speed up the movie little bit.",
                    "label": 0
                },
                {
                    "sent": "Right here you see sort of the estimate of the distribution after sort of a certain amount of time of sampling, and it's basically the histogram of the counts of where it's been.",
                    "label": 0
                },
                {
                    "sent": "And you see that you know it's annealing, so the step size gets smaller, so the progress is that it's making is also smaller, so that's the mixing problem, right?",
                    "label": 0
                },
                {
                    "sent": "So this is really not what you necessarily want.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's have a closer look at these terms.",
                    "label": 1
                },
                {
                    "sent": "So there's two.",
                    "label": 0
                },
                {
                    "sent": "Two places where we inject noise, right?",
                    "label": 0
                },
                {
                    "sent": "The first is because we subsample from the from the.",
                    "label": 0
                },
                {
                    "sent": "Data distribution.",
                    "label": 0
                },
                {
                    "sent": "Here we take a mini batch and that's an estimate of the full gradient and so that actually is a sort of an unbiased but noisy estimator of the full gradient, and so you can say that this is drawn from a normal distribution.",
                    "label": 0
                },
                {
                    "sent": "You know if this sum is large enough due to central Limit theorem.",
                    "label": 0
                },
                {
                    "sent": "From a normal distribution with the right mean, the mean that we want, but it has a bit of various feet.",
                    "label": 0
                },
                {
                    "sent": "Right, and then there's a second noise distribution, which is this one is what we add, so there's two noise injections here.",
                    "label": 0
                },
                {
                    "sent": "Now when you start optimizing, you take a big step size, right?",
                    "label": 0
                },
                {
                    "sent": "Because remember, we were kneeling, so we started with the big step size and then it turns out that this noise created by the subsampling is completely dominating the other noise.",
                    "label": 0
                },
                {
                    "sent": "The noise that we're injecting ourselves.",
                    "label": 0
                },
                {
                    "sent": "So basically you can ignore that noise, which means that you just doing stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "This is just a test.",
                    "label": 0
                },
                {
                    "sent": "Agree to send with a little bit of overhead.",
                    "label": 0
                },
                {
                    "sent": "Namely, that you have to draw normal random variable.",
                    "label": 0
                },
                {
                    "sent": "Now when you get closer.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the optimal distribution.",
                    "label": 0
                },
                {
                    "sent": "So you're you're kneeling and you're closer to the distribution to the sort of the true posterior.",
                    "label": 0
                },
                {
                    "sent": "What's happening is that now this noise term is starting to sort.",
                    "label": 0
                },
                {
                    "sent": "This noise term is starting to dominate the injected noise, and this actually is not dominant, so it means that it's like you're just getting the right gradient and you know this.",
                    "label": 0
                },
                {
                    "sent": "Your own noise that you're adding by hand is dominating the whole thing, so this means that at this point you're actually sampling from.",
                    "label": 0
                },
                {
                    "sent": "From the posterior distribution and you're not bothered by the fact that you have you actually do have a sort of a noisy estimate of your gradient.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now you can again there is this tradeoff between large step size and small step size.",
                    "label": 0
                },
                {
                    "sent": "If the step sizes larger going to mix alot so you had a step size is big and so this snake is moving from left to right very quickly, but the price you pay is that the distribution you're sampling from is a poor approximation of the true distribution.",
                    "label": 0
                },
                {
                    "sent": "So here's what you see.",
                    "label": 0
                },
                {
                    "sent": "So it basically estimates you know this distribution with spherical distribution right things?",
                    "label": 0
                },
                {
                    "sent": "It's like a isotropic Gaussian or something.",
                    "label": 0
                },
                {
                    "sent": "Now you.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can do better, which is you can decrease the step size now.",
                    "label": 0
                },
                {
                    "sent": "The price you're going to pay for that is that the mixing is slower, so you have to wait longer.",
                    "label": 0
                },
                {
                    "sent": "So for a fixed amount of sampling time, it means you have less samples.",
                    "label": 0
                },
                {
                    "sent": "You will have higher variance, but it turns out that the distribution you're going to get is looks a lot better, right?",
                    "label": 0
                },
                {
                    "sent": "So this is again a fixed step size, but now we've chosen to be small and now you can see that the details of the distribution are much better approximated.",
                    "label": 0
                },
                {
                    "sent": "OK, so this you could try to use this on neural networks and deep learning, and of course we've tried it.",
                    "label": 0
                },
                {
                    "sent": "It works to some degree, so you can make it work reasonably well, but you know if you just look at classification performance.",
                    "label": 0
                },
                {
                    "sent": "In fact, putting a smart regularizer like dropout actually works just as well, so in that sense it's not super useful for this particular deep learning case.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it's been a lot of research afterwards which proved convergence in distribution, and all these things, so it's a valid procedure in that sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so the second class, yeah?",
                    "label": 0
                },
                {
                    "sent": "So in principle we so the question is why don't we need the metropolis facing step.",
                    "label": 0
                },
                {
                    "sent": "So in principle we needed, but we choose to not use it, which will introduce bias, right?",
                    "label": 0
                },
                {
                    "sent": "So there's this tradeoff between bias and variance, and I'm explicitly choosing to trade off.",
                    "label": 0
                },
                {
                    "sent": "Some of the basically the variance with the by.",
                    "label": 0
                },
                {
                    "sent": "So I'm creating bias, but because I don't have to do the metropolis Hastings step, I can go much faster and so the draw more samples in a finite amount of time and effort reduce variance.",
                    "label": 0
                },
                {
                    "sent": "So the second class of algorithms is variational inference, and you've seen already quite a bit of variational inference, so I will go a little fast in variational inference.",
                    "label": 1
                },
                {
                    "sent": "Again, we choose Attractable set of distributions queues at given X.",
                    "label": 0
                },
                {
                    "sent": "That we know how to handle and we minimize the KL divergent between these posterior distribution between the true posterior distribution piece that given X and approximate distribution cues out of X.",
                    "label": 0
                },
                {
                    "sent": "And then in fact you can write this out an sort of do things to it that don't matter for the optimization, and then it looks like this elbow is called Elbow is coming from objective for the expected value of Z given X over the joint distribution PX, said.",
                    "label": 0
                },
                {
                    "sent": "And there is this entropy term here which tries to keep the Q fuzzy and not actually collapse onto a spike.",
                    "label": 0
                },
                {
                    "sent": "And so the picture you should.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In mind is like if Q is the approximation distribution in red and P is the true distribution.",
                    "label": 0
                },
                {
                    "sent": "Here you're trying to fit a Q which is typically smaller than P is inside 22P, but you try to make the fit as good as possible.",
                    "label": 0
                },
                {
                    "sent": "Now that is so expectation maximization that people already did.",
                    "label": 0
                },
                {
                    "sent": "Somebody already talk about expectation maximization.",
                    "label": 0
                },
                {
                    "sent": "OK, so expectation maximization is basically a way to train a model which has latent variables set.",
                    "label": 0
                },
                {
                    "sent": "So axes observed set as latent.",
                    "label": 0
                },
                {
                    "sent": "Right, and it fits really nicely with this.",
                    "label": 0
                },
                {
                    "sent": "Adopt tails you could say with this variational inference.",
                    "label": 1
                },
                {
                    "sent": "Is there actually a very simple algorithm viewed in this particular generalized way?",
                    "label": 0
                },
                {
                    "sent": "So you're going to say that the log of P of X given Theta.",
                    "label": 0
                },
                {
                    "sent": "That's the object we are really interested in, because we want to find parameters Theta such that the probability of the data set X is maximized.",
                    "label": 0
                },
                {
                    "sent": "Now we agreed that X is a latent variable model, so we're going to write it as X, given zed times P of Z, and I've sort of said, well, let's put all the parameters in this.",
                    "label": 0
                },
                {
                    "sent": "In this likelihood Duramax given Zed and let's not put it in this prior term, but you could put parameters there too.",
                    "label": 0
                },
                {
                    "sent": "So this is just writing out the definition of P of X given Theta.",
                    "label": 0
                },
                {
                    "sent": "Now you could easily upper bound this by this elbow, so again the same the same term here.",
                    "label": 0
                },
                {
                    "sent": "So this is upper bounded by.",
                    "label": 0
                },
                {
                    "sent": "Basically introducing or variational Q distribution.",
                    "label": 0
                },
                {
                    "sent": "Here is the average over cues that given X with its own parameter set five, so we can tune this parameter set five times.",
                    "label": 0
                },
                {
                    "sent": "The log of P of X, given that Theta PP set, which is the log join model distribution and Q's at given X. OK.",
                    "label": 0
                },
                {
                    "sent": "So now learning is very simple now because learning basically says there's two steps, E&M step and the E step we re going to do inference, which is we're going to train up RQ distribution.",
                    "label": 0
                },
                {
                    "sent": "And that's basically take this bound, so we're going to write this as our bound, and in fact the nice thing is that this the gap between this bound and the the marginal P of X given Theta is precisely given by this KL between the posterior approximate posterior to true posterior, right?",
                    "label": 0
                },
                {
                    "sent": "So if you get Q to be flexible enough to actually model P, then you know that the gap is actually all the way down to zero.",
                    "label": 0
                },
                {
                    "sent": "And also note that this is exactly the objective that we're trying to minimize when we do inference over Q.",
                    "label": 0
                },
                {
                    "sent": "Right when the E step we have to do inference, which is we take the bound and we maximize it over the distributed over the parameters Phi which live in our approximate posterior distribution Q. OK, and then in the M step we just look at the same objective.",
                    "label": 0
                },
                {
                    "sent": "Here, abound, but now we maximize it over the parameters Theta and so it's really just coordinate descend on that bound.",
                    "label": 0
                },
                {
                    "sent": "That's all there is to it.",
                    "label": 0
                },
                {
                    "sent": "It's really, really simple algorithm feud.",
                    "label": 0
                },
                {
                    "sent": "This way if you look at into statistics literature, it looks much more complicated, but if you view it this way, which is equivalent, its way is actually quite trivial.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so then more recently there was A and I think I'm sure you know, maybe Aaron talked about it or somebody else already.",
                    "label": 0
                },
                {
                    "sent": "This idea of amortized inference, which actually Interestingly quite a big step.",
                    "label": 0
                },
                {
                    "sent": "But it goes all the way back to Jeff Hinton and Brendan Frey and resemble, you know, and I don't know.",
                    "label": 0
                },
                {
                    "sent": "Somewhere in the 90s, ninety eight or something or 95.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And architecture, which I called the Helmholtz machine.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if you've heard of it, but it was basically a neural net.",
                    "label": 0
                },
                {
                    "sent": "You know from that going to X and then a recognition network going back from XCOM 2Z.",
                    "label": 0
                },
                {
                    "sent": "So that's you can just directly map this onto the neural net, going from zed going to X.",
                    "label": 0
                },
                {
                    "sent": "It is, you know, we have a prior reset and then X given zed.",
                    "label": 0
                },
                {
                    "sent": "And then they had a recognition network.",
                    "label": 0
                },
                {
                    "sent": "Will neural net going from X2 sets?",
                    "label": 0
                },
                {
                    "sent": "There's a queue of zed given X.",
                    "label": 0
                },
                {
                    "sent": "Now the the so they had to wake sleep algorithm to train it, which unfortunately optimizes two different objectives and it was a bit hacky innocence.",
                    "label": 0
                },
                {
                    "sent": "So the so the idea here and I'm sure they tried it was to say, well, let's stick with the original objective one bound, so we should just optimize this one bound right?",
                    "label": 0
                },
                {
                    "sent": "This is disbound here.",
                    "label": 0
                },
                {
                    "sent": "This is the bound, so we're going to stick with that bound right?",
                    "label": 0
                },
                {
                    "sent": "But the first trick to make this fast is to basically say that instead of writing a queue of zed which is separate for every data point which every data point has its own set of parameters which also.",
                    "label": 0
                },
                {
                    "sent": "We did a test time.",
                    "label": 0
                },
                {
                    "sent": "You would actually have to do inference over that data point to compute that Q.",
                    "label": 0
                },
                {
                    "sent": "We're going to turn it into sort of a conditional distribution zed given X.",
                    "label": 0
                },
                {
                    "sent": "So now surely the distribution is different for every input X, right?",
                    "label": 0
                },
                {
                    "sent": "But the parameters fire now shared between all the data points, right?",
                    "label": 0
                },
                {
                    "sent": "So one set of parameters 5, like my model parameters data, which are the same for every data point.",
                    "label": 0
                },
                {
                    "sent": "And so it basically means I only have to train this once in my data set, and then it's fixed and now on test time you're really fast because you stick in your data point and swoop.",
                    "label": 0
                },
                {
                    "sent": "You go up through your neural net and you sample.",
                    "label": 0
                },
                {
                    "sent": "You said you don't have to do iterative inference to compute your queue for that particular data point, so that's actually a very important step.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so sidetracked now a little bit to say that what's the relationship between deep learning and.",
                    "label": 0
                },
                {
                    "sent": "You know, in graphical models, one way to look at this is that in graphical models we deal with random variables right.",
                    "label": 0
                },
                {
                    "sent": "Every bubble is a random variable.",
                    "label": 0
                },
                {
                    "sent": "We're in a neural net.",
                    "label": 0
                },
                {
                    "sent": "Every bubble is just, you know, an activation which could be a deterministic function of.",
                    "label": 0
                },
                {
                    "sent": "It's fast, but we're going to do is we're going to say, well, you know every time there is this conditional distribution, we're going to insert and deep neural net.",
                    "label": 0
                },
                {
                    "sent": "Alright, so wherever there is a conditional distribution, I could do something very simple, but I could also do something very complicated, so that's just something very complicated and take deep neural net.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Long time ago when I was talking, I think it was with semrau ice.",
                    "label": 0
                },
                {
                    "sent": "He he had this interesting idea that you know when you want to write lots of papers, you should really invent a new operator.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't invent a new model, because if you invent a new model, you only get the right one paper, right?",
                    "label": 0
                },
                {
                    "sent": "If you invent a new operator, you can apply the operator to a million models and then you can write lots of papers.",
                    "label": 0
                },
                {
                    "sent": "So here is a new operator that's a deep if I operator.",
                    "label": 0
                },
                {
                    "sent": "So the way to do it is that you know you take.",
                    "label": 0
                },
                {
                    "sent": "You look, you look for these conditional distributions in your model that you already know, and then you insert a deep neural net right?",
                    "label": 0
                },
                {
                    "sent": "So that's what we did for variational auto encoders.",
                    "label": 0
                },
                {
                    "sent": "We just took a factor analysis, linear Gaussian and we stuck in a deep neural net.",
                    "label": 0
                },
                {
                    "sent": "But there's a couple of other ones.",
                    "label": 0
                },
                {
                    "sent": "I think there's a lot, you know, deep logistic regression becomes deep neural Nets, right?",
                    "label": 0
                },
                {
                    "sent": "So that's another obvious one.",
                    "label": 0
                },
                {
                    "sent": "But there's a lot of ground to cover.",
                    "label": 0
                },
                {
                    "sent": "Actually, how about survival analysis?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if you know about survival analysis.",
                    "label": 0
                },
                {
                    "sent": "It's trying to figure out, you know if you if you buy something you you know how long will it take for it to breakdown and basically.",
                    "label": 0
                },
                {
                    "sent": "And there's his Cox model, and inside this Cox model there's this little linear gression part here right now.",
                    "label": 0
                },
                {
                    "sent": "If you replace this with the deep neural net, you will have deep survival analysis an I actually don't think it exists, right?",
                    "label": 0
                },
                {
                    "sent": "So you could just take it as a collective project.",
                    "label": 0
                },
                {
                    "sent": "You at the end of this summer school you know you have implemented and tested the trivial analysis.",
                    "label": 0
                },
                {
                    "sent": "And so the variation autoencoder is 1 example.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is well, so here we go.",
                    "label": 0
                },
                {
                    "sent": "You know here is our little set of M framework with, you know with two conditional distributions and we do provide this and we decide that and then we have the various.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Auto encoder.",
                    "label": 0
                },
                {
                    "sent": "So if a prior probability of zed here and given PM said you know we have a deterministic set of sort of.",
                    "label": 0
                },
                {
                    "sent": "In this case I use these sort of a diamond shaped nodes to produce the probabilities.",
                    "label": 0
                },
                {
                    "sent": "Let's say for an output variable X and then there is the backward pass, the recognition model which goes from Xbox back to Z.",
                    "label": 0
                },
                {
                    "sent": "And that's the Q distribution.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "In order to avoid the big data in order to pass the big data test right, we cannot run every update on all the data points because you have a billion data points.",
                    "label": 0
                },
                {
                    "sent": "I will not make any progress.",
                    "label": 0
                },
                {
                    "sent": "So what do I need to do?",
                    "label": 0
                },
                {
                    "sent": "I need to actually subsample the datasets or there's actually two places again where I need to sample in order to make this work.",
                    "label": 0
                },
                {
                    "sent": "So here's our friend.",
                    "label": 0
                },
                {
                    "sent": "Again, this is the bound that we know by now all.",
                    "label": 0
                },
                {
                    "sent": "Love you've seen it so many times right?",
                    "label": 0
                },
                {
                    "sent": "And then if you actually compute the gradient with respect to five, so I should say taking the train with respect to Theta, which are the parameters of the model distribution is really simple, so that part we're going to skip.",
                    "label": 0
                },
                {
                    "sent": "But if you take the hard part is actually taking the gradient with respect to five, which is from the recognition model.",
                    "label": 0
                },
                {
                    "sent": "If you take that, then you get basically get this right, and I'm pretty sure that the gang from you know the Hinton and Frey and everybody they tried this right.",
                    "label": 0
                },
                {
                    "sent": "I'm sure they must have tried it because it's the obvious thing to do.",
                    "label": 0
                },
                {
                    "sent": "But then if you want to make it work, you'll have to start sampling at a couple of places so the 1st place you want to sample is from this distribution Q, because that's just a neural net and you cannot really easily integrate this log P over this.",
                    "label": 0
                },
                {
                    "sent": "It's a neural net, but it's a Gaussian distribution, so so that's OK, but you know.",
                    "label": 0
                },
                {
                    "sent": "This might be very difficult.",
                    "label": 0
                },
                {
                    "sent": "It might be a neural net in itself, and so you can actually not do these integrations very well.",
                    "label": 0
                },
                {
                    "sent": "So that's where you have to sample from Q of zed.",
                    "label": 0
                },
                {
                    "sent": "OK, that's fine, but you also have to subsample your data set which log P of XI.",
                    "label": 0
                },
                {
                    "sent": "Given Zed I evaluated at sample S from our Q distribution and now we have two places where we sample and now if you try this it doesn't work right.",
                    "label": 0
                },
                {
                    "sent": "So now here is, I think why the wake sleep algorithm got inserted 'cause this just doesn't work and I think it's also a recent insight that we figured out why this doesn't work.",
                    "label": 0
                },
                {
                    "sent": "And this has to do with the fact that the variance is too high, so the variance of this estimator, again this is an estimator that the variance it is estimator is too high.",
                    "label": 0
                },
                {
                    "sent": "So it basically you're trying to figure out which direction to move, but it's so noisy that you know it's all over the place, so you're not making a lot of progress.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the thing that made this work is reducing the variance, and there's been a lot of work by different groups to try to reduce the variance right?",
                    "label": 0
                },
                {
                    "sent": "And every time you know the variance got reduced, the method works a bit better.",
                    "label": 0
                },
                {
                    "sent": "Now, the trick that we used was this representation trick, and I think Aaron did talk a bit about this, but the most important reason that you know this is important is to reduce the variance, and the idea is actually quite simple.",
                    "label": 0
                },
                {
                    "sent": "You write down a conditional distribution of a random variable set given its parents, and you externalize the random variable.",
                    "label": 0
                },
                {
                    "sent": "You can say, well, that's actually the same as a deterministic sort of function, right where I also add a random variable epsilon to that random function.",
                    "label": 0
                },
                {
                    "sent": "That's exactly the same as equivalent.",
                    "label": 0
                },
                {
                    "sent": "Right and now what we're going to do is we're going to say, OK, so I'm sampling over Q5 here, but I'm going to introduce a transformation on Zed going to epsilons.",
                    "label": 0
                },
                {
                    "sent": "I'm transforming zattoo epsilon Brezet comes from a standard normal distribution.",
                    "label": 0
                },
                {
                    "sent": "Such that in this case you know the integral over Q.",
                    "label": 0
                },
                {
                    "sent": "Is going to be now an integral over epsilon and I'm going to rewrite disease now as functions off this epsilon Ann 5.",
                    "label": 0
                },
                {
                    "sent": "OK, so you know you do that, you compute the derivative and it looks quite simple now to convince you that that actually reduces the variance enormously.",
                    "label": 0
                },
                {
                    "sent": "Let's look at an example.",
                    "label": 0
                },
                {
                    "sent": "So here's an example where I tried to integrate.",
                    "label": 0
                },
                {
                    "sent": "I take the derivative with respect to the parameter mu of a normal distribution integrated over zed, so we all know the answer because this integral is mu and then taking the derivative with respect to mu is going to give one right?",
                    "label": 0
                },
                {
                    "sent": "So we know the answer up front.",
                    "label": 0
                },
                {
                    "sent": "But if we try to do it this way right by basically, you know.",
                    "label": 0
                },
                {
                    "sent": "Or not this way, but this way so we write out basically how we would have to do it this way.",
                    "label": 0
                },
                {
                    "sent": "So we bring in the integral.",
                    "label": 0
                },
                {
                    "sent": "We take the derivatives, right and then we have to sample over normal distribution, then the then the estimator looks like this and this is a huge variance in fact.",
                    "label": 0
                },
                {
                    "sent": "So you're not trying to estimate something trivial by sampling from a distribution, but you're sampling.",
                    "label": 0
                },
                {
                    "sent": "Variance is enormous, where if you would do the re parameterisation trick.",
                    "label": 0
                },
                {
                    "sent": "In fact what you would get is 1 and you would be sampling with some one as times and divided by S. So there is no variance left at all.",
                    "label": 0
                },
                {
                    "sent": "Right, generally speaking, there is of course various left, but typically the variance is reduced enormously.",
                    "label": 0
                },
                {
                    "sent": "Important lesson is that when you have noise in your estimators, you're taking gradients right?",
                    "label": 0
                },
                {
                    "sent": "And you're sampling and so you're getting noise in these estimators don't give up if it doesn't work, the answer could just be reduced variance, and then it might work.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to skip this because of time, so there is a semi supervised versions of this which are quite natural.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you do that, you can basically.",
                    "label": 0
                },
                {
                    "sent": "Makes you know.",
                    "label": 0
                },
                {
                    "sent": "In this case there's why label, which is clearly 029 and then zed.",
                    "label": 0
                },
                {
                    "sent": "We flying through Z space here, which is the latent variable space and you can see that Z nicely models the writing style of the digits, right?",
                    "label": 0
                },
                {
                    "sent": "So it has learned to the model the writing style of the digit, and it did so by using a large data set with no labels and a small data set with labels which is semi supervised.",
                    "label": 0
                },
                {
                    "sent": "Learning and combine these using the variational auto.",
                    "label": 0
                },
                {
                    "sent": "Order",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so sort of backing off a little bit from the discussion.",
                    "label": 0
                },
                {
                    "sent": "Now we have seen in the various autoencoder we have a generative model and we have a discriminative model right?",
                    "label": 0
                },
                {
                    "sent": "So two legs are sort of connected in this framework and these are two different philosophies in modeling, right?",
                    "label": 0
                },
                {
                    "sent": "If you go to an economist or basically everybody outside of machine learning if you ask them what is modeling, they would say oh, you know I write down.",
                    "label": 0
                },
                {
                    "sent": "I think about them all.",
                    "label": 0
                },
                {
                    "sent": "I write down causal relationships.",
                    "label": 0
                },
                {
                    "sent": "I know my parameters.",
                    "label": 0
                },
                {
                    "sent": "I know the relationships.",
                    "label": 0
                },
                {
                    "sent": "I understand what they mean.",
                    "label": 0
                },
                {
                    "sent": "I put some parameters in and then I do some statistical estimation procedure and then I'm done right but every time they write down a model they know what that model means.",
                    "label": 0
                },
                {
                    "sent": "They can interpret the model.",
                    "label": 0
                },
                {
                    "sent": "That's a generative model, right?",
                    "label": 0
                },
                {
                    "sent": "So Bayesian networks are generative models.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic programs are generative models in distance, or their people have built beautiful sort of languages around probabilistic models.",
                    "label": 0
                },
                {
                    "sent": "It's a whole different field I think.",
                    "label": 0
                },
                {
                    "sent": "Probably somebody talked about this already.",
                    "label": 0
                },
                {
                    "sent": "An you know simulators which is basically what everybody does outside of machine learning.",
                    "label": 0
                },
                {
                    "sent": "You know if you ask an astronomer what's your model, they probably show you a sophisticated simulator.",
                    "label": 0
                },
                {
                    "sent": "See here, I can simulate the universe.",
                    "label": 0
                },
                {
                    "sent": "I understand the universe right.",
                    "label": 0
                },
                {
                    "sent": "If you ask, a medical scientist would probably show you a simulation of the heart or something like that.",
                    "label": 0
                },
                {
                    "sent": "So that's also a generative model, because you can generate basically data artificially and match them up with observations.",
                    "label": 0
                },
                {
                    "sent": "OK, so now there's a bunch of advantages of generative models that I want to emphasize.",
                    "label": 0
                },
                {
                    "sent": "So first of all, because you understand the process, you can inject knowledge into the model, because you can actually say you know this influences this and this influences this every time you do that, you basically put inductive bias into your modeling.",
                    "label": 0
                },
                {
                    "sent": "And sort of, you're not asking your data to decide on which things depend on walk, but you were deciding it, so that's injecting expert knowledge.",
                    "label": 0
                },
                {
                    "sent": "You can you can actually model causal relationships, and that's actually quite important too, because you know calls are relationships are much more stable to use the non causal down just correlations right?",
                    "label": 0
                },
                {
                    "sent": "In the Netherlands they have actually raised the fees, the insurance fees for people who drive black cars.",
                    "label": 0
                },
                {
                    "sent": "People got upset about that because, you know, the blackness of the car doesn't cause you know the person to get into an accident.",
                    "label": 0
                },
                {
                    "sent": "There's probably something else like a testosterone level or something like that from the male driving the car, right?",
                    "label": 0
                },
                {
                    "sent": "So really what you need is you need the causal model, because that would actually generalize much better that, say, to another country if you go to Japan.",
                    "label": 0
                },
                {
                    "sent": "Maybe you know males drive fast in red cars.",
                    "label": 0
                },
                {
                    "sent": "Who knows, right?",
                    "label": 0
                },
                {
                    "sent": "And so having blackness, Azure sort of, your measure of how much you should pay that doesn't generalize well to other countries, right?",
                    "label": 0
                },
                {
                    "sent": "So causal models are much more stable in the sense of predictions, and the models are interpretable, which is important there.",
                    "label": 0
                },
                {
                    "sent": "Data efficient because you're putting all your expert knowledge in there.",
                    "label": 0
                },
                {
                    "sent": "You can use it for semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Again that speaks to data efficiency.",
                    "label": 0
                },
                {
                    "sent": "They're more robust to domain shifts as I already said.",
                    "label": 0
                },
                {
                    "sent": "And then on the other side of the world there is the black box set of deep learning.",
                    "label": 0
                },
                {
                    "sent": "Now this is taking off and working really well, and the old days were kernel methods and random forests and boosting, right?",
                    "label": 0
                },
                {
                    "sent": "But these are the black box set of models where you stick in your data and you predict directly and you let the data speak.",
                    "label": 0
                },
                {
                    "sent": "Basically what that mapping should look like an again, here's a bias variance decomposition maybe so in this case because you have so many parameters, the variance might actually be quite high in these models.",
                    "label": 0
                },
                {
                    "sent": "But the bias is probably quite small, because you let the data speak, you know, put in a lot of inductive bias when the other model on the other side to generate the model, you put lots of your assumptions into the model, which actually increases the bias but reduces the variance, right?",
                    "label": 0
                },
                {
                    "sent": "Because the world is always more complicated than you can imagine.",
                    "label": 0
                },
                {
                    "sent": "Basically, so you're going to make at some point you're going to make mistakes, and you're going to see those mistakes when your data set is large.",
                    "label": 0
                },
                {
                    "sent": "So there is clearly very efficient training algorithms available for this.",
                    "label": 0
                },
                {
                    "sent": "Deep learning algorithms is really good, and importantly, you're actually solve the problem that you want to solve right?",
                    "label": 0
                },
                {
                    "sent": "Because at Test time you want to stick in some input you want to predict some output, so training that mapping directly is better than first training the inverse mapping and then inverting again with Bayes rule, right?",
                    "label": 0
                },
                {
                    "sent": "So that seems cumbersome, and so both of these have advantages and disadvantages.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And sort of you do this from a slightly different perspective.",
                    "label": 0
                },
                {
                    "sent": "Then is you know in when you have a lot of data you should have today to speak.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, she talked about.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That I'm going to come back to that.",
                    "label": 0
                },
                {
                    "sent": "So, but that's an interesting story because I think what the sort of various non quarter has basically two legs.",
                    "label": 0
                },
                {
                    "sent": "But actually there's a slide on this.",
                    "label": 0
                },
                {
                    "sent": "I'll come back to it, sorry.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So from a different perspective.",
                    "label": 0
                },
                {
                    "sent": "You know, when you're in Silicon Valley an your you know you're working away on your deep learning algorithms, right?",
                    "label": 0
                },
                {
                    "sent": "Mostly maybe always in a domain where you have huge amount of data by click data or a video from YouTube or images or something like that, right?",
                    "label": 0
                },
                {
                    "sent": "So there your game is really optimization, right?",
                    "label": 0
                },
                {
                    "sent": "You know trying to really fit these large models today to the statistical efficiency really doesn't isn't all that important because overfitting might not be a huge problem at that point.",
                    "label": 0
                },
                {
                    "sent": "Now when the data set is very small though, right?",
                    "label": 0
                },
                {
                    "sent": "Actually you're looking for statistical efficiency and not so much computational efficiency, which basically means you want to put the right inductive biases.",
                    "label": 0
                },
                {
                    "sent": "The right assumptions into your model, and so for instance, in healthcare, this is typically the case.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, there typically are not a huge amount of patience and privacy regulations.",
                    "label": 0
                },
                {
                    "sent": "Actually, you know, unfortunately, make due to privacy regulations very hard to get your data, your hands, all that data.",
                    "label": 0
                },
                {
                    "sent": "And so there you have to work with typically situation where the number of data points is much smaller than the number of things you measure about a patient.",
                    "label": 0
                },
                {
                    "sent": "For instance, you could measure the DNA sequence.",
                    "label": 0
                },
                {
                    "sent": "You could measure all the voxels of an MRI scan and a PET scan, and all these kinds of things and so here the game is statistical efficiency in their index.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Advisors are very good, so here's my slide about.",
                    "label": 0
                },
                {
                    "sent": "You know how that relates to autoencoders.",
                    "label": 0
                },
                {
                    "sent": "So in outer core is you basically have two legs, so you have both the generator and discriminator, so the generative model is we have, for instance the label you measure something about the hospital.",
                    "label": 0
                },
                {
                    "sent": "Let's say you have a latent variable, you push it through, maybe the neural net, or a better maybe through a simulator model to get your data.",
                    "label": 0
                },
                {
                    "sent": "Let's say this could be an echo cardio, gram or something like that of a heart.",
                    "label": 0
                },
                {
                    "sent": "Right and then the other model is the discriminative model where you take your observables, you push it through the neural net and then sort of, let's say, produce first your latent representations Ed, which is a compressed representation of the big high dimensional input.",
                    "label": 0
                },
                {
                    "sent": "And then from there you can predict the labels Y.",
                    "label": 0
                },
                {
                    "sent": "So this is your classifier and this is your generative model.",
                    "label": 0
                },
                {
                    "sent": "And then the idea is that your.",
                    "label": 0
                },
                {
                    "sent": "Use your generative model as a way to insert injective bias into the recognition model.",
                    "label": 0
                },
                {
                    "sent": "The classifier, right?",
                    "label": 0
                },
                {
                    "sent": "So you're not exactly inverting it, but you know you could use it to sort of help the.",
                    "label": 0
                },
                {
                    "sent": "The classification model too, you know, to jump start or something like that.",
                    "label": 0
                },
                {
                    "sent": "Right, so these two feed off of each other.",
                    "label": 0
                },
                {
                    "sent": "You know you could.",
                    "label": 0
                },
                {
                    "sent": "You could think of this as a regularizer for the discriminative model, but if you're interested in the generative sort of part, then this just becomes your recognition model.",
                    "label": 0
                },
                {
                    "sent": "Your inference model for inferring these these latent variables, E.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so do that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip this.",
                    "label": 0
                },
                {
                    "sent": "You all know about this.",
                    "label": 0
                },
                {
                    "sent": "There's some examples about dermatology that I really like on.",
                    "label": 0
                },
                {
                    "sent": "CNN's are really good results.",
                    "label": 0
                },
                {
                    "sent": "I'm going to skip this a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What I've been inspired with recently is the fact that.",
                    "label": 0
                },
                {
                    "sent": "You know we have all these deep neural networks CNN's, but they have.",
                    "label": 0
                },
                {
                    "sent": "They have a huge amount of parameters, right?",
                    "label": 0
                },
                {
                    "sent": "And in fact, it turns out there's way too many and you can prune a lot of those parameters out and keep the same performance right.",
                    "label": 0
                },
                {
                    "sent": "And the point is actually that it has an impact too, because they consume a lot of energy.",
                    "label": 0
                },
                {
                    "sent": "Actually run these networks.",
                    "label": 0
                },
                {
                    "sent": "Going to consume a lot of energy and pretty soon, and I think it's already there.",
                    "label": 0
                },
                {
                    "sent": "The bottleneck is actually going to be.",
                    "label": 0
                },
                {
                    "sent": "You know, how efficient can you make these neural networks?",
                    "label": 0
                },
                {
                    "sent": "B because you know if you put them on your phone right?",
                    "label": 0
                },
                {
                    "sent": "You know if you make them too big, there's interest too much energy.",
                    "label": 1
                },
                {
                    "sent": "You know that you need.",
                    "label": 0
                },
                {
                    "sent": "Not only does your battery drain, but it burns out of your pockets, right?",
                    "label": 0
                },
                {
                    "sent": "And so there's only a certain amount of computation that you can do before it gets too hot.",
                    "label": 0
                },
                {
                    "sent": "There's nothing you can do about it because the heat will have to go somewhere.",
                    "label": 1
                },
                {
                    "sent": "Right and so making them more efficient actually might actually make the difference in making them sort of better as well.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and I've been working on Bayesian deep learning because, you know, I like to combine the graphical model perspective and the Bayesian perspective of the deep learning perspective and we have pushed.",
                    "label": 0
                },
                {
                    "sent": "You know, we've really concentrated on uncertainty estimation, which I really think is still is a very important application, right?",
                    "label": 0
                },
                {
                    "sent": "So, for instance, if you doctor and somebody comes in and your algorithm your black box algorithm tells you person has disease X right as a doctor, you want to know is that probability 99%.",
                    "label": 0
                },
                {
                    "sent": "Or is that probability 51% right?",
                    "label": 0
                },
                {
                    "sent": "Because in one way you would decide to do additional tests in the other way, you would just go ahead with the treatment right away.",
                    "label": 0
                },
                {
                    "sent": "Right, so basically every time you want to make a decision, I think you need the probabilities.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that there is a much nicer.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to measure how well you're doing actually, in terms of uncertainty quantification.",
                    "label": 0
                },
                {
                    "sent": "So as there's no good benchmarks, it's not even clear precisely what it what it means to actually have the right uncertainty on your predictions.",
                    "label": 0
                },
                {
                    "sent": "And so there's a much more beautiful application of Asian deep learning and.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compression.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did you already do basean learning?",
                    "label": 0
                },
                {
                    "sent": "Measure measuring that you're estimating your certainty properly?",
                    "label": 0
                },
                {
                    "sent": "Well, let me give you the.",
                    "label": 0
                },
                {
                    "sent": "I see what you're saying, but let's let's assume, for instance, that.",
                    "label": 0
                },
                {
                    "sent": "You build a model and your data set is only living here, right?",
                    "label": 0
                },
                {
                    "sent": "Let's say you have a self driving car.",
                    "label": 0
                },
                {
                    "sent": "You know you only have seen this data now.",
                    "label": 0
                },
                {
                    "sent": "Let's say you move to a new environment.",
                    "label": 0
                },
                {
                    "sent": "Now, does the model have to be uncertain there?",
                    "label": 0
                },
                {
                    "sent": "Or not right?",
                    "label": 0
                },
                {
                    "sent": "This is important question because if you have a decision boundary, if you sort of move out, you would think it's pretty reasonable to become more and more certain.",
                    "label": 0
                },
                {
                    "sent": "If you go away from the decision boundary if you.",
                    "label": 0
                },
                {
                    "sent": "But if you move too far out from the data, you should actually become more uncertain, but to me it's not so precisely clear what what it means to measure how well you're doing their friends.",
                    "label": 0
                },
                {
                    "sent": "If you take it, you know.",
                    "label": 0
                },
                {
                    "sent": "So let's say you take a digit of two, you start rotating it, right, you know.",
                    "label": 0
                },
                {
                    "sent": "Should you become uncertain if it's a 2 on the side or should you stay?",
                    "label": 0
                },
                {
                    "sent": "Or is it estimating at two with high certainty still very good, you know?",
                    "label": 0
                },
                {
                    "sent": "I don't precisely know what is the right answer there, but we should figure it out, though.",
                    "label": 0
                },
                {
                    "sent": "I mean we should come up with benchmarks here.",
                    "label": 0
                },
                {
                    "sent": "I think this isn't representative.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, that's right, but you can always build that test set, unfortunately.",
                    "label": 0
                },
                {
                    "sent": "So question, did people already do Beijing or is it already somebody treat visionary?",
                    "label": 0
                },
                {
                    "sent": "Join us, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe let me say a few words about them.",
                    "label": 0
                },
                {
                    "sent": "Then I have only 5 more minutes.",
                    "label": 0
                },
                {
                    "sent": "Where is not fair though right?",
                    "label": 0
                },
                {
                    "sent": "Is the thing broke down?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Invasion learning, there's the posterior distribution of the parameters given XM as the model.",
                    "label": 0
                },
                {
                    "sent": "That's the object you're really interested in.",
                    "label": 0
                },
                {
                    "sent": "To compute the posterior distribution and then in prediction you have to average your models over.",
                    "label": 0
                },
                {
                    "sent": "Basically, you have to wait your models by that posterior distribution, right?",
                    "label": 0
                },
                {
                    "sent": "And again, there is a bias variance decomposition going in here, which is that if you have a very simple model like a linear regression model, then it can only model A very small subset of data, right?",
                    "label": 0
                },
                {
                    "sent": "Namely all the straight lines.",
                    "label": 0
                },
                {
                    "sent": "You can model fine with a linear model, but.",
                    "label": 0
                },
                {
                    "sent": "In a space of all possible datasets, that's only putting your probability measure on a very small subset, so that's the blue line here.",
                    "label": 0
                },
                {
                    "sent": "Now, if you have a very flexible model, then it can model all sorts of things, right?",
                    "label": 0
                },
                {
                    "sent": "So it puts a probability mass everywhere.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, a probability distribution has to be normalized, so if you spread your bets, you know your probability has to be lower at every possible every X.",
                    "label": 0
                },
                {
                    "sent": "Right now, if the true axis here or you know if you review true access here, right?",
                    "label": 0
                },
                {
                    "sent": "And you had your sort of two simple model peeking here, you know the probability of X is going to be very low, right?",
                    "label": 0
                },
                {
                    "sent": "If it's too complex, you know it covers X, but since it has to normalize this pretty low right and so somewhere in the middle is the right sort of model complexity.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we can do is we can do variational Bayes.",
                    "label": 1
                },
                {
                    "sent": "Exactly the same way as we did before with the variational autoencoder, so we can write down exactly the same bound, but now we replace sets by parameters data.",
                    "label": 0
                },
                {
                    "sent": "So you look at P of X now marginally over the parameters and we bounded by exactly the same way.",
                    "label": 0
                },
                {
                    "sent": "So this you know average over Q, which is your variational distribution log P of X given Theta, log P of Theta and minus the entropy term, which is again the bound and it's written out here.",
                    "label": 0
                },
                {
                    "sent": "If I will.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You need to stop.",
                    "label": 0
                },
                {
                    "sent": "You gotta tell me it's OK. OK, so Karen is going to talk about, you know, one way of quantizing and compressing these neural networks using sort of this equation here I'll just differ.",
                    "label": 0
                },
                {
                    "sent": "Skip it now here.",
                    "label": 0
                },
                {
                    "sent": "I'll just talk about something else.",
                    "label": 0
                },
                {
                    "sent": "But you know, there is this term, which is really the loss of the.",
                    "label": 0
                },
                {
                    "sent": "Let me let me write it this way.",
                    "label": 0
                },
                {
                    "sent": "So if I'm going to have to send you my data, but I can imagine that there is a game where I have to send my data to somebody else and have to encode it somehow.",
                    "label": 0
                },
                {
                    "sent": "So one way to encode it is to 1st fit the model here, then send you the parameters, which is quite cheap.",
                    "label": 0
                },
                {
                    "sent": "And then you use the model on the other side to make the predictions right, and then given those predictions, there's going to be some errors.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to send you the error still.",
                    "label": 0
                },
                {
                    "sent": "Right, but since the errors are small compared to the original data points, I can encode them quite efficiently and it's this term which turns out to be the complexity cost, which is a very complex model.",
                    "label": 0
                },
                {
                    "sent": "You'll pay a lot of you pay a lot for the complexity, and is this term which is the other was sending.",
                    "label": 0
                },
                {
                    "sent": "The model is measured here, and this is the.",
                    "label": 0
                },
                {
                    "sent": "The error, the error terms that you will still have to measure, since that's the this particular term here.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we're going to do is we're going to.",
                    "label": 0
                },
                {
                    "sent": "So look at a neural net and we're going to say that you know if you have a posterior distribution over your parameters.",
                    "label": 0
                },
                {
                    "sent": "You're basically injecting noise over those parameters of your model, right?",
                    "label": 0
                },
                {
                    "sent": "So basically you're sampling models from your posterior over the parameters here, and that uncertainty will actually translate into uncertainty over your over hidden variables here, simply because the information all has to go through this bottleneck, right?",
                    "label": 0
                },
                {
                    "sent": "An it's nice because dropout is actually also sort of putting noise on these latent variables.",
                    "label": 0
                },
                {
                    "sent": "So the plan is to marginalized, marginalized out the weights now in for the price of introducing stochastic hidden units.",
                    "label": 0
                },
                {
                    "sent": "So you take a neural net we have.",
                    "label": 0
                },
                {
                    "sent": "We have a posterior distribution over these weights, but we're going to do is we're going to marginalized out these weights and move the stochasticity from these weights to hit the latent variables here.",
                    "label": 0
                },
                {
                    "sent": "And so hidden variables then become latent variables if you want.",
                    "label": 0
                },
                {
                    "sent": "They were going to reinterpret the stochastic stochastic city here as dropout noise, basically very reminiscent of dropout.",
                    "label": 0
                },
                {
                    "sent": "The original dropout algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then in the end we're going to use sparsity inducing priors to prune weights an entire hidden units to get compression over a neural net.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So maybe I should skip this for now.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just.",
                    "label": 0
                },
                {
                    "sent": "Explain the local representation trick so there's in order to integrate out these parameters here in favor of stochasticity on the latent variables.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do is once again we're going to look at this bound so it's again the posterior distribution over Q&W times a log of Y given X&W and enters the complexity term here Now this week, and often compute exactly so we don't have to worry about it, so that part we can often just compute is this part that we have to worry about.",
                    "label": 0
                },
                {
                    "sent": "Now let's rewrite this.",
                    "label": 0
                },
                {
                    "sent": "As you know, this log P of Y given X&W.",
                    "label": 0
                },
                {
                    "sent": "That's really going to write it as a loss function over Y and then file F is the prediction of Y&F.",
                    "label": 0
                },
                {
                    "sent": "You can think of as W * 5 the previous, so B is the activation of these units.",
                    "label": 0
                },
                {
                    "sent": "Here they get multiplied by W or they get through non linearity.",
                    "label": 0
                },
                {
                    "sent": "Then they get multiplied by W and then they get they're predicting F here.",
                    "label": 0
                },
                {
                    "sent": "So I can sort of introduce this extra integral over F over the F variables here and this indicator function here and then I can now integrate out the WS in favor of the FS and then it looks like this.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that now you write down L Y5F, which is these activations here and the Q distribution becomes a distribution over these activations given the previous text of activations.",
                    "label": 0
                },
                {
                    "sent": "This could be.",
                    "label": 0
                },
                {
                    "sent": "You might have to.",
                    "label": 0
                },
                {
                    "sent": "Read about this to fully understand it, but the conclusion is that this is a trick to again reduce the variance and replace Stochastic city on the hidden units by stochasticity on the latent variables.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, if you do multiple layers, it looks more like this, so you have a queue of.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have a.",
                    "label": 0
                },
                {
                    "sent": "You have two of these layers.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The probability of the final layer given the layer before, which is here.",
                    "label": 0
                },
                {
                    "sent": "Then the probability of this layer given the layer before, which is this thing here, and so it looks.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'll just skip now the.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last sort of details on how to process this, but now putting sparse priors on the weights and actually, you know, turning it into priors over the latent variables, you can actually start sort of pruning out weights, and here this is a demo by these guys here these Russian guys.",
                    "label": 0
                },
                {
                    "sent": "And so this is.",
                    "label": 0
                },
                {
                    "sent": "These are the weights of.",
                    "label": 0
                },
                {
                    "sent": "So these are the patches of a convolutional neural net, and what you can see is that you know the runs.",
                    "label": 0
                },
                {
                    "sent": "Basically the compression ratio goes up over 250 or something, or surpasses 250.",
                    "label": 0
                },
                {
                    "sent": "But the accuracy doesn't change, which is very interesting, right?",
                    "label": 0
                },
                {
                    "sent": "So you're basically pruning almost everything away, but the accuracy doesn't change.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is for a fully connected neural net.",
                    "label": 0
                },
                {
                    "sent": "Again the accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He doesn't change.",
                    "label": 0
                },
                {
                    "sent": "Right, but almost all of the units.",
                    "label": 0
                },
                {
                    "sent": "All of the weights basically get removed.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is not readable unfortunately, but maybe let me say that.",
                    "label": 0
                },
                {
                    "sent": "Here is compression rate of 700 times.",
                    "label": 0
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "It means that out of every 700 weights, you keep one and all the rest are gone, right?",
                    "label": 0
                },
                {
                    "sent": "And the amazing fact is that.",
                    "label": 0
                },
                {
                    "sent": "It doesn't hurt performance.",
                    "label": 0
                },
                {
                    "sent": "So we basically overparameterized that particular model by a factor of 700.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe that's not actually, you know, that's the sparsity level.",
                    "label": 0
                },
                {
                    "sent": "That's probably 0.6%, but this is after you actually do all the compression.",
                    "label": 0
                },
                {
                    "sent": "You know the actual compression algorithm itself.",
                    "label": 0
                },
                {
                    "sent": "There's by effect or 700.",
                    "label": 0
                },
                {
                    "sent": "The other really nice thing about this is that you can actually also compute the fixed point precision of your weights, because you have a posterior distribution over your weight.",
                    "label": 0
                },
                {
                    "sent": "You can just figure out which bits are significant and which bits of your weights are fluctuate ING under your posterior.",
                    "label": 0
                },
                {
                    "sent": "And you can just remove them.",
                    "label": 0
                },
                {
                    "sent": "And so you also get compression on your.",
                    "label": 0
                },
                {
                    "sent": "And you're sort of representation of your weights, OK?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then to conclude.",
                    "label": 0
                },
                {
                    "sent": "So I would say that deep learning is not necessarily a silver bullet.",
                    "label": 0
                },
                {
                    "sent": "It's particularly good at signal processing, so it's very good at auditory signals, image language as well, but it doesn't apply to everything.",
                    "label": 0
                },
                {
                    "sent": "If you have just structured data, then I think gradient boosting machine just work is fine as a neural net.",
                    "label": 0
                },
                {
                    "sent": "Optimization plays an important role in deep learning.",
                    "label": 0
                },
                {
                    "sent": "In order to get good solutions.",
                    "label": 0
                },
                {
                    "sent": "And in this talk, for instance, we looked at reducing the variance of the gradients in order to get be able to learn the variation autoencoder.",
                    "label": 0
                },
                {
                    "sent": "And you know also the Bayesian deep learning model.",
                    "label": 0
                },
                {
                    "sent": "We always remember that you know it's you know deep learning is not just.",
                    "label": 0
                },
                {
                    "sent": "Optimization is also statistics.",
                    "label": 0
                },
                {
                    "sent": "So you can combine your classical graphical model ideas with sort of deep learning by thinking of them as a conditional distribution and the various not encoder is an example of that.",
                    "label": 0
                },
                {
                    "sent": "Bayesian deep Learning is an elegant way to combine to sort of more traditional statistics and graphical models with deep learning, and it helps a lot with compression.",
                    "label": 0
                },
                {
                    "sent": "This get amazing compression rates.",
                    "label": 0
                },
                {
                    "sent": "But it's a lot of things that we really don't know about deep learning, one of them being.",
                    "label": 0
                },
                {
                    "sent": "Already a little bit addressed before, so why do they actually not overfit?",
                    "label": 0
                },
                {
                    "sent": "You know it's kind of strange to have so much capacity of these models yet if you train them well with SGD, then you know they don't really overfit and the previous talk addressed that.",
                    "label": 0
                },
                {
                    "sent": "Why'd as regular writers just SGD regularize so effectively?",
                    "label": 0
                },
                {
                    "sent": "There's these adverse aerial examples for as many companies and people worry about a lot, so that's kind of strange behavior as well.",
                    "label": 0
                },
                {
                    "sent": "So where does that come from?",
                    "label": 0
                },
                {
                    "sent": "The first is a huge overpressurization.",
                    "label": 0
                },
                {
                    "sent": "I still have 400 here, but sometimes it's 700, so why is it that we have to Stuart in order to optimize these algorithms?",
                    "label": 0
                },
                {
                    "sent": "We have over parameterized by a factor of a couple of 100 and then prune them back down to a much smaller one.",
                    "label": 0
                },
                {
                    "sent": "That's going to interesting is much harder to train them if you start with a small size in the beginning.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}