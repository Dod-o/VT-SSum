{
    "id": "nyuqr5ykewtgji7ysh5zzafqifmvhymf",
    "title": "Linking Named Entities in Tweets with Knowledge Base via User Interest Modeling",
    "info": {
        "author": [
            "Wei Shen, Department of Computer Science and Technology, Tsinghua University"
        ],
        "published": "Sept. 27, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2013_shen_interest_modeling/",
    "segmentation": [
        [
            "Everyone, Ann Wilson.",
            "Functional University, Ann.",
            "Today I'm going to print paper titled linking them entities.",
            "Intuits with naughty base.",
            "Where are your interest modeling?"
        ],
        [
            "This outline or this talk.",
            "Firstly, we talk about the motivation and problem definition and then we introduce Curry framework and April results and not the we conclude this paper."
        ],
        [
            "OK, let's first have a look at."
        ],
        [
            "Motivation Twitter has become an increasingly important source of information and on Twitter, users can publish and share information in short posts about topics ranging from daily lives to do's events.",
            "And the huge correctional tweets embodying invaluable knowledge about name entities which appear into its frequently.",
            "And here we show example for the entity mentioning some in the 22 they can.",
            "Dimensions interests are potentially ambiguous.",
            "The animation song can refer to the star at the center of the Solar System, multinational computer company, or a fictional character name.",
            "So cool and many other entities we can be called soon.",
            "On the other."
        ],
        [
            "Paint the success of Wikipedia and the proposed vision of linked open data has facilitated the automated construction of large scale loaded basis.",
            "And this loaded bases contain information about.",
            "Words, entities their semantic categories and their mutual relationships.",
            "And here in figure one we shouldn't example the yogurt base and there are many famous knowledge base such as DB Pedia, Jago, Freebase and Pro Base.",
            "Bridging this knowledge basis with the correctional traits is beneficial for the understanding of this huge collection of personal data on the web."
        ],
        [
            "OK, now we give out the problem definition for this task."
        ],
        [
            "The 20 linking it defies the task to link that actual name entity mentions detective from traits with their map entities existing in along the base and Figure 2 issue.",
            "An illustration of this task and on the left hand side there are totally four treats we obtain from sound Twitter user and there are totally server name entity mentions which are detected from these four traits and they are in both facing the figure.",
            "And for each entity mentioned in the trades, we show its candidate map entities using adults and this candidate map entities obtained from the yoga body base and this entities can retrieve Bio dictionary based method an.",
            "They are true that true might be entities for each entity.",
            "Mention is underlying this figure and the input of this task is the correction treats.",
            "Form sound Twitter user and allow the base and the output of this task is for each entity.",
            "Mention detailed from the toilet we output it's true mapping entity in a large base."
        ],
        [
            "This task is significantly help for the for many applications about Twitter, mine mining, for example, detecting and linking them entities, Twitter user mention in their tweets is helpful for the task of user interest discovery and after we obtain the user interest for Twitter users we can recommend other interesting Twitter users or other interesting tweets for this user and also there needs to collect.",
            "Information or and opinions about some products, celebrities and some other name entities from Twitter also requires the process of link entities in traits we loaded base."
        ],
        [
            "And this task is challenging firstly because the entity ambiguity problem and also for this past week 20 linking task is challenging due to the lowly short and informal nature or threats.",
            "Previous interlinking methods, many focus on link entities details from the web documents.",
            "And if they do reach the feature of context, similarity between the context around the dimension in the web documents and the context associated with the entity in along the base and also some previous methods leverage the feature of topical coherence between entities within one web document.",
            "However, this previous methods cannot be effectively effectively applied to the 20 linking task due to the insufficient contact information embedded in each tweet.",
            "For example, for this figure for Twitch T1 and T3.",
            "The context in these two traits are short and and ambiguous, so previous methods may lack sufficient context information to link them correctly.",
            "So."
        ],
        [
            "Besides the interest rates, local information in order to increase the linking accuracy, we leverage the Inter tweet user interests information to help interlinking.",
            "That's easy to say."
        ],
        [
            "We want to leverage the information embedded in 22 and 24 to help link entities in 21 history."
        ],
        [
            "To achieve this goal, we propose a full work called Curry and this framework is a graph based framework that can unify these two categories in formation and can collectively link all the entity mentions in all traits.",
            "Published by Sound Twitter user.",
            "Where modeling this, users tops or interests."
        ],
        [
            "In order to model this problem, we have the following three assumptions.",
            "The assumption one is each Twitter user has underlying topical interest distribution over various topics or name entities and assumption too is if some name entity is mentioned by user interest rate, the user is likely to be interested in this name.",
            "Entity assumption three is if one name entity is highly topically related to the entities user in each city in the user is likely to be interested in this limited entity as well.",
            "So based on these three assumptions, we model that we sent a linking problem into a graph based interest propagation problem."
        ],
        [
            "And for each Twitter user, we construct a graph whose structure can encode the interdependency information between different candidate map entities.",
            "And using this graph and here we should run example that example one and in this example we just consider the tweet entity linking task for 2134 for the purpose or simplicity and for this issue."
        ],
        [
            "Number one we construct.",
            "Construct the graph and we show this graph here.",
            "And for each candidate, maybe entity in the.",
            "In the example we create load for it, and for each pair of loads and if the wait between them is larger than zero, we create an edge between them and each edge in the graph is associated with the with the weight which indicates the strength of the interdependence between them.",
            "And this wait can be calculated using the Wikipedia link based measure and this measure is based on the Wikipedia hybrid.",
            "Bring structure and the main idea of this measure is 2.",
            "Wikipedia entities is considered to be topically related if there are many Wikipedia entities that sitting next to them in Wikipedia."
        ],
        [
            "And each each node in the graph represents candidate mapping entity RJQ.",
            "And based on assumption.",
            "One we can see that each candidate entity in the graph is associated with an interest goal, which indicates the strength of the user's interest in it.",
            "And based on assumption too."
        ],
        [
            "We can see that the more likely meant it is mentioned by user interest rates, the more interested this user is in this name entity.",
            "So given that wait where the entity mention appears, we can estimate its initial interest score PHQ, based on the interest rate.",
            "Local information."
        ],
        [
            "And in order to estimate the initial interest goal, we leverage 3 interest rates, local features.",
            "The first one is prior probability and we estimate this feature using entity frequency in the Wikipedia article corpus.",
            "And in this figure, all the candidates and map entities are ranked by their prior probabilities in decreasing order an from this figure we can see that our notion of fire probability can conceivably press the popularity or entity.",
            "And for this."
        ],
        [
            "Second, feature context similarity.",
            "We calculated this feature using back over cosine similarity between the context around any dimension in the toilet and the context associated with the entity in a loaded base.",
            "And the third feature is topical coherence into it.",
            "Which means we calculate that optical coherence between entities within the tweet.",
            "And however, the map entities for any dimension in the Tracy on loan to us and need to be assigning this task.",
            "So to solve this problem, we utilize an effective.",
            "Greedy algorithm called iterative substituting algorithm to jointly optimize the identification identification of the map entities for any dimensions for this tweet.",
            "And we estimate to the initial interest score as a weighted sum of these three interest rates, local features, and in order to automatically learn the weights, we utilize the maximizing technique based on the training data."
        ],
        [
            "And for this running example, we can estimate the initial injury score for each candidate ITI and we should result in Table 2.",
            "And.",
            "Despite the entity told Adam Basketball the prior probability of this entity is lower than this entity.",
            "But our notion of initial interest score can give this true map entity to Dad.",
            "In basketball, the higher score than this this entity and cause this entity is more topically related to the other two entity within the same trait.",
            "From this we can see that our notion of initial interest score can effectively include the interpreter local features and, however.",
            "Folder 21 as the context in which T1 is limited.",
            "So our notion of initial into score can give the true mappings additional boost the high score.",
            "So in order to link this entity mentioned correctly, we have to leverage the interface user interest information to help link it.",
            "So."
        ],
        [
            "In order to combine the interest rates are local in formation with interpret user interest information.",
            "We propose a user interest propagation algorithm and this algorithm can propagate the interest goal associated with the.",
            "Different candidates might be entities.",
            "Using the graph structure, we construct it and this formula is a little similar to the topic sensitive Pagerank algorithm and this vector is is a final interest called Victor.",
            "And the vector P initial interest for Victor we can calculate using the last step.",
            "And the matrix B is interested propagation strength matrix.",
            "We can estimate from the graph structure and this matrix is a column normalized matrix.",
            "And the parameter Lambda is parimeter that balances the two parts.",
            "The first part is initial interest score which can Smith from the interest rates local feature and the other parts is propagated score of the other.",
            "Related loads in the graph and this part to express the integrate user interest in formation.",
            "As this formula is in a recursive also, in order to calculate the final interest quickly as we first initialize, biocide P2S and then we apply this formula iteratively until Victor S stabilized within some threshold."
        ],
        [
            "Also, for this running example, we can calculate the final interest goal for the candy map entities and we should results in Table 3 and firstly we can see that our user interest propagation algorithm can assign the true maybe entities.",
            "The highest goal among the different candidate candidate might be entities for each dimension in this example and also.",
            "Despite the need for the entity, mention grows the initial interest score for the true map entity Chicago Boots, it loads the highest, but our algorithm can correct it and decide that room I painted the Chicago boots the highest score among the different candidate.",
            "Maybe entities for this entity mention Becausw.",
            "Our algorithm can propagate the interest goal associated with these three entities and propagate their interest score to this entity using the strong weight between them.",
            "From this we can see that our algorithm can effectively includes the interface user in user information to help Andy linking."
        ],
        [
            "In order to demonstrate the performance or algorithm over real datasets."
        ],
        [
            "We created a Golden standard data set and we firstly we running sampled 20 Twitter users and for each Twitter user we collect the most reason.",
            "200 tweets and not leave.",
            "We obtain three of us about 3000 traits and we manually allocate these tweets with yogurt base and the last day we obtain 2617 so and they mention dimensions for evaluation."
        ],
        [
            "Here we should read out and the method of Linda in this table is a method we propose to deal with the task of link entities with in quantities in web documents.",
            "And the framework local is either truncated framework with which just consider the initial interest score as the final interest score and do not leverage the user interest propagation propagation algorithm in Curry.",
            "And in this table we not only show the performance of framework Curry and local using all the using all the interpreter local features which we denote as colorful but also we show the performance of these two free work by leveraging a subset of interest rates.",
            "Local features for example.",
            "For this method it means when we calculate the initial interest score using this formula with that data to zero and come to zero and we just leverage the.",
            "Feature of prior probability to calculate the initial interest score.",
            "And from this table we can see that our framework colorful campaign the best result and it outperforms the baseline method Linden and all the different confirmation of the framework local.",
            "And also each configuration of the framework Curry obtained much higher accuracy than the thing configuration of the framework local.",
            "It means the interface user interests information is very important and our user interest propagation algorithm is effective for the 20 linking task.",
            "And also have a look at the results for this difference.",
            "Cooperation with the framework Curry.",
            "We can see that each interface local feature has a positive impact to the performance or Curry and all that.",
            "With all the interested local features are free workout refill campaign.",
            "The best result."
        ],
        [
            "And and here we show the improvement update performance, our framework, and well, in this experiment, we assume that at each time we receive 10 new traits for each Twitter user.",
            "And when we can create the graph, we only consider the treats in the latest latest tweet sliding window of size 115 tweets an from this result we can see that as each time when we receive new tweets.",
            "We in our framework can obtain stable, stable, high accuracy and the incremental agitation time is about linear to the number of added edges, which also demonstrates the scalability our algorithm."
        ],
        [
            "OK, let's."
        ],
        [
            "Conclude this paper.",
            "In this paper we study a lower problem about 20 linking and to solve this problem with proposed framework Curry, which is a graph based framework that unifies the interest rates, local information with the integrate user interest in formation and departmental results demonstrates the effectiveness our framework and also our framework is efficient and scale well to the history."
        ],
        [
            "OK, that's all, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everyone, Ann Wilson.",
                    "label": 0
                },
                {
                    "sent": "Functional University, Ann.",
                    "label": 0
                },
                {
                    "sent": "Today I'm going to print paper titled linking them entities.",
                    "label": 0
                },
                {
                    "sent": "Intuits with naughty base.",
                    "label": 0
                },
                {
                    "sent": "Where are your interest modeling?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This outline or this talk.",
                    "label": 0
                },
                {
                    "sent": "Firstly, we talk about the motivation and problem definition and then we introduce Curry framework and April results and not the we conclude this paper.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's first have a look at.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Motivation Twitter has become an increasingly important source of information and on Twitter, users can publish and share information in short posts about topics ranging from daily lives to do's events.",
                    "label": 1
                },
                {
                    "sent": "And the huge correctional tweets embodying invaluable knowledge about name entities which appear into its frequently.",
                    "label": 0
                },
                {
                    "sent": "And here we show example for the entity mentioning some in the 22 they can.",
                    "label": 0
                },
                {
                    "sent": "Dimensions interests are potentially ambiguous.",
                    "label": 0
                },
                {
                    "sent": "The animation song can refer to the star at the center of the Solar System, multinational computer company, or a fictional character name.",
                    "label": 0
                },
                {
                    "sent": "So cool and many other entities we can be called soon.",
                    "label": 0
                },
                {
                    "sent": "On the other.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Paint the success of Wikipedia and the proposed vision of linked open data has facilitated the automated construction of large scale loaded basis.",
                    "label": 1
                },
                {
                    "sent": "And this loaded bases contain information about.",
                    "label": 0
                },
                {
                    "sent": "Words, entities their semantic categories and their mutual relationships.",
                    "label": 1
                },
                {
                    "sent": "And here in figure one we shouldn't example the yogurt base and there are many famous knowledge base such as DB Pedia, Jago, Freebase and Pro Base.",
                    "label": 0
                },
                {
                    "sent": "Bridging this knowledge basis with the correctional traits is beneficial for the understanding of this huge collection of personal data on the web.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now we give out the problem definition for this task.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The 20 linking it defies the task to link that actual name entity mentions detective from traits with their map entities existing in along the base and Figure 2 issue.",
                    "label": 1
                },
                {
                    "sent": "An illustration of this task and on the left hand side there are totally four treats we obtain from sound Twitter user and there are totally server name entity mentions which are detected from these four traits and they are in both facing the figure.",
                    "label": 0
                },
                {
                    "sent": "And for each entity mentioned in the trades, we show its candidate map entities using adults and this candidate map entities obtained from the yoga body base and this entities can retrieve Bio dictionary based method an.",
                    "label": 1
                },
                {
                    "sent": "They are true that true might be entities for each entity.",
                    "label": 0
                },
                {
                    "sent": "Mention is underlying this figure and the input of this task is the correction treats.",
                    "label": 1
                },
                {
                    "sent": "Form sound Twitter user and allow the base and the output of this task is for each entity.",
                    "label": 0
                },
                {
                    "sent": "Mention detailed from the toilet we output it's true mapping entity in a large base.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This task is significantly help for the for many applications about Twitter, mine mining, for example, detecting and linking them entities, Twitter user mention in their tweets is helpful for the task of user interest discovery and after we obtain the user interest for Twitter users we can recommend other interesting Twitter users or other interesting tweets for this user and also there needs to collect.",
                    "label": 0
                },
                {
                    "sent": "Information or and opinions about some products, celebrities and some other name entities from Twitter also requires the process of link entities in traits we loaded base.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this task is challenging firstly because the entity ambiguity problem and also for this past week 20 linking task is challenging due to the lowly short and informal nature or threats.",
                    "label": 1
                },
                {
                    "sent": "Previous interlinking methods, many focus on link entities details from the web documents.",
                    "label": 0
                },
                {
                    "sent": "And if they do reach the feature of context, similarity between the context around the dimension in the web documents and the context associated with the entity in along the base and also some previous methods leverage the feature of topical coherence between entities within one web document.",
                    "label": 0
                },
                {
                    "sent": "However, this previous methods cannot be effectively effectively applied to the 20 linking task due to the insufficient contact information embedded in each tweet.",
                    "label": 0
                },
                {
                    "sent": "For example, for this figure for Twitch T1 and T3.",
                    "label": 0
                },
                {
                    "sent": "The context in these two traits are short and and ambiguous, so previous methods may lack sufficient context information to link them correctly.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Besides the interest rates, local information in order to increase the linking accuracy, we leverage the Inter tweet user interests information to help interlinking.",
                    "label": 0
                },
                {
                    "sent": "That's easy to say.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to leverage the information embedded in 22 and 24 to help link entities in 21 history.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To achieve this goal, we propose a full work called Curry and this framework is a graph based framework that can unify these two categories in formation and can collectively link all the entity mentions in all traits.",
                    "label": 0
                },
                {
                    "sent": "Published by Sound Twitter user.",
                    "label": 0
                },
                {
                    "sent": "Where modeling this, users tops or interests.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to model this problem, we have the following three assumptions.",
                    "label": 0
                },
                {
                    "sent": "The assumption one is each Twitter user has underlying topical interest distribution over various topics or name entities and assumption too is if some name entity is mentioned by user interest rate, the user is likely to be interested in this name.",
                    "label": 1
                },
                {
                    "sent": "Entity assumption three is if one name entity is highly topically related to the entities user in each city in the user is likely to be interested in this limited entity as well.",
                    "label": 1
                },
                {
                    "sent": "So based on these three assumptions, we model that we sent a linking problem into a graph based interest propagation problem.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for each Twitter user, we construct a graph whose structure can encode the interdependency information between different candidate map entities.",
                    "label": 0
                },
                {
                    "sent": "And using this graph and here we should run example that example one and in this example we just consider the tweet entity linking task for 2134 for the purpose or simplicity and for this issue.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Number one we construct.",
                    "label": 0
                },
                {
                    "sent": "Construct the graph and we show this graph here.",
                    "label": 0
                },
                {
                    "sent": "And for each candidate, maybe entity in the.",
                    "label": 0
                },
                {
                    "sent": "In the example we create load for it, and for each pair of loads and if the wait between them is larger than zero, we create an edge between them and each edge in the graph is associated with the with the weight which indicates the strength of the interdependence between them.",
                    "label": 0
                },
                {
                    "sent": "And this wait can be calculated using the Wikipedia link based measure and this measure is based on the Wikipedia hybrid.",
                    "label": 1
                },
                {
                    "sent": "Bring structure and the main idea of this measure is 2.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia entities is considered to be topically related if there are many Wikipedia entities that sitting next to them in Wikipedia.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And each each node in the graph represents candidate mapping entity RJQ.",
                    "label": 1
                },
                {
                    "sent": "And based on assumption.",
                    "label": 0
                },
                {
                    "sent": "One we can see that each candidate entity in the graph is associated with an interest goal, which indicates the strength of the user's interest in it.",
                    "label": 1
                },
                {
                    "sent": "And based on assumption too.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can see that the more likely meant it is mentioned by user interest rates, the more interested this user is in this name entity.",
                    "label": 1
                },
                {
                    "sent": "So given that wait where the entity mention appears, we can estimate its initial interest score PHQ, based on the interest rate.",
                    "label": 0
                },
                {
                    "sent": "Local information.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in order to estimate the initial interest goal, we leverage 3 interest rates, local features.",
                    "label": 0
                },
                {
                    "sent": "The first one is prior probability and we estimate this feature using entity frequency in the Wikipedia article corpus.",
                    "label": 1
                },
                {
                    "sent": "And in this figure, all the candidates and map entities are ranked by their prior probabilities in decreasing order an from this figure we can see that our notion of fire probability can conceivably press the popularity or entity.",
                    "label": 0
                },
                {
                    "sent": "And for this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second, feature context similarity.",
                    "label": 0
                },
                {
                    "sent": "We calculated this feature using back over cosine similarity between the context around any dimension in the toilet and the context associated with the entity in a loaded base.",
                    "label": 0
                },
                {
                    "sent": "And the third feature is topical coherence into it.",
                    "label": 1
                },
                {
                    "sent": "Which means we calculate that optical coherence between entities within the tweet.",
                    "label": 0
                },
                {
                    "sent": "And however, the map entities for any dimension in the Tracy on loan to us and need to be assigning this task.",
                    "label": 0
                },
                {
                    "sent": "So to solve this problem, we utilize an effective.",
                    "label": 0
                },
                {
                    "sent": "Greedy algorithm called iterative substituting algorithm to jointly optimize the identification identification of the map entities for any dimensions for this tweet.",
                    "label": 0
                },
                {
                    "sent": "And we estimate to the initial interest score as a weighted sum of these three interest rates, local features, and in order to automatically learn the weights, we utilize the maximizing technique based on the training data.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for this running example, we can estimate the initial injury score for each candidate ITI and we should result in Table 2.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Despite the entity told Adam Basketball the prior probability of this entity is lower than this entity.",
                    "label": 0
                },
                {
                    "sent": "But our notion of initial interest score can give this true map entity to Dad.",
                    "label": 1
                },
                {
                    "sent": "In basketball, the higher score than this this entity and cause this entity is more topically related to the other two entity within the same trait.",
                    "label": 0
                },
                {
                    "sent": "From this we can see that our notion of initial interest score can effectively include the interpreter local features and, however.",
                    "label": 0
                },
                {
                    "sent": "Folder 21 as the context in which T1 is limited.",
                    "label": 0
                },
                {
                    "sent": "So our notion of initial into score can give the true mappings additional boost the high score.",
                    "label": 0
                },
                {
                    "sent": "So in order to link this entity mentioned correctly, we have to leverage the interface user interest information to help link it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to combine the interest rates are local in formation with interpret user interest information.",
                    "label": 0
                },
                {
                    "sent": "We propose a user interest propagation algorithm and this algorithm can propagate the interest goal associated with the.",
                    "label": 1
                },
                {
                    "sent": "Different candidates might be entities.",
                    "label": 0
                },
                {
                    "sent": "Using the graph structure, we construct it and this formula is a little similar to the topic sensitive Pagerank algorithm and this vector is is a final interest called Victor.",
                    "label": 0
                },
                {
                    "sent": "And the vector P initial interest for Victor we can calculate using the last step.",
                    "label": 1
                },
                {
                    "sent": "And the matrix B is interested propagation strength matrix.",
                    "label": 0
                },
                {
                    "sent": "We can estimate from the graph structure and this matrix is a column normalized matrix.",
                    "label": 0
                },
                {
                    "sent": "And the parameter Lambda is parimeter that balances the two parts.",
                    "label": 0
                },
                {
                    "sent": "The first part is initial interest score which can Smith from the interest rates local feature and the other parts is propagated score of the other.",
                    "label": 0
                },
                {
                    "sent": "Related loads in the graph and this part to express the integrate user interest in formation.",
                    "label": 0
                },
                {
                    "sent": "As this formula is in a recursive also, in order to calculate the final interest quickly as we first initialize, biocide P2S and then we apply this formula iteratively until Victor S stabilized within some threshold.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, for this running example, we can calculate the final interest goal for the candy map entities and we should results in Table 3 and firstly we can see that our user interest propagation algorithm can assign the true maybe entities.",
                    "label": 1
                },
                {
                    "sent": "The highest goal among the different candidate candidate might be entities for each dimension in this example and also.",
                    "label": 0
                },
                {
                    "sent": "Despite the need for the entity, mention grows the initial interest score for the true map entity Chicago Boots, it loads the highest, but our algorithm can correct it and decide that room I painted the Chicago boots the highest score among the different candidate.",
                    "label": 0
                },
                {
                    "sent": "Maybe entities for this entity mention Becausw.",
                    "label": 0
                },
                {
                    "sent": "Our algorithm can propagate the interest goal associated with these three entities and propagate their interest score to this entity using the strong weight between them.",
                    "label": 0
                },
                {
                    "sent": "From this we can see that our algorithm can effectively includes the interface user in user information to help Andy linking.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to demonstrate the performance or algorithm over real datasets.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We created a Golden standard data set and we firstly we running sampled 20 Twitter users and for each Twitter user we collect the most reason.",
                    "label": 1
                },
                {
                    "sent": "200 tweets and not leave.",
                    "label": 0
                },
                {
                    "sent": "We obtain three of us about 3000 traits and we manually allocate these tweets with yogurt base and the last day we obtain 2617 so and they mention dimensions for evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we should read out and the method of Linda in this table is a method we propose to deal with the task of link entities with in quantities in web documents.",
                    "label": 1
                },
                {
                    "sent": "And the framework local is either truncated framework with which just consider the initial interest score as the final interest score and do not leverage the user interest propagation propagation algorithm in Curry.",
                    "label": 0
                },
                {
                    "sent": "And in this table we not only show the performance of framework Curry and local using all the using all the interpreter local features which we denote as colorful but also we show the performance of these two free work by leveraging a subset of interest rates.",
                    "label": 0
                },
                {
                    "sent": "Local features for example.",
                    "label": 0
                },
                {
                    "sent": "For this method it means when we calculate the initial interest score using this formula with that data to zero and come to zero and we just leverage the.",
                    "label": 0
                },
                {
                    "sent": "Feature of prior probability to calculate the initial interest score.",
                    "label": 0
                },
                {
                    "sent": "And from this table we can see that our framework colorful campaign the best result and it outperforms the baseline method Linden and all the different confirmation of the framework local.",
                    "label": 0
                },
                {
                    "sent": "And also each configuration of the framework Curry obtained much higher accuracy than the thing configuration of the framework local.",
                    "label": 0
                },
                {
                    "sent": "It means the interface user interests information is very important and our user interest propagation algorithm is effective for the 20 linking task.",
                    "label": 0
                },
                {
                    "sent": "And also have a look at the results for this difference.",
                    "label": 0
                },
                {
                    "sent": "Cooperation with the framework Curry.",
                    "label": 0
                },
                {
                    "sent": "We can see that each interface local feature has a positive impact to the performance or Curry and all that.",
                    "label": 0
                },
                {
                    "sent": "With all the interested local features are free workout refill campaign.",
                    "label": 0
                },
                {
                    "sent": "The best result.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And and here we show the improvement update performance, our framework, and well, in this experiment, we assume that at each time we receive 10 new traits for each Twitter user.",
                    "label": 0
                },
                {
                    "sent": "And when we can create the graph, we only consider the treats in the latest latest tweet sliding window of size 115 tweets an from this result we can see that as each time when we receive new tweets.",
                    "label": 0
                },
                {
                    "sent": "We in our framework can obtain stable, stable, high accuracy and the incremental agitation time is about linear to the number of added edges, which also demonstrates the scalability our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Conclude this paper.",
                    "label": 0
                },
                {
                    "sent": "In this paper we study a lower problem about 20 linking and to solve this problem with proposed framework Curry, which is a graph based framework that unifies the interest rates, local information with the integrate user interest in formation and departmental results demonstrates the effectiveness our framework and also our framework is efficient and scale well to the history.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, that's all, thanks.",
                    "label": 0
                }
            ]
        }
    }
}