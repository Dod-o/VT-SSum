{
    "id": "4aknxx6knwpjavh3parzg3huzq4zej2z",
    "title": "Statistical Learning as the Ultimate Agile Development Tool",
    "info": {
        "author": [
            "Peter Norvig, Google, Inc."
        ],
        "published": "Nov. 19, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Business->Management->Knowledge Management"
        ]
    },
    "url": "http://videolectures.net/cikm08_norvig_slatuad/",
    "segmentation": [
        [
            "OK.",
            "So what I want to talk about."
        ],
        [
            "Day is the use of data in search and in computing in general, and you know the model.",
            "I want to talk about is how can you get software done quickly and you hear a lot about different methodologies and these agile development methodologies.",
            "And my lesson is that data is the ultimate agile development tool 'cause data is always more agile than code."
        ],
        [
            "OK, so if you you know go to these consultants and they or you go.",
            "This is from Wikipedia and tells you what these agile development principles are, how you focus on customers and you work quickly and you measure your progress and so on so on.",
            "And you want simplicity and adaptation.",
            "These are all qualities that we see in data more than code.",
            "Code is static and you need these kinds of tools to fight against it.",
            "Whereas data is sort of self updating and simple and adaptable kind of by default.",
            "And if you want another take on this you can see my colleague Steve Yaggi has a blog post called Good Agile Bad Agile.",
            "He focuses mostly on the bad, but he's always got his own take on things.",
            "I see Greg in the audience there smiling, he knows."
        ],
        [
            "Alright, what's what's the use of data?",
            "Or why is it important?",
            "And so this is a chart from paper by Banko and Brill from Microsoft Research in 2001, and they did a meta analysis of five different learning algorithms on the task of word sense disambiguation.",
            "So this is a task where the algorithms given a sentence and a word ambiguous word like, say, bank is in the middle of the sentence.",
            "And it has to tag that and say that's the money bank sense of the word, or that's the riverbank sense of the word and you start out and you give it some training data and you get a standardized training set, say with 1,000,000 words, training data and then you apply your different learning algorithms and see how well they do an.",
            "If you come up with this new algorithm called this X here and I don't know what that is, it's naive Bayes classifier or it's a decision tree.",
            "Or it's a support vector machine or whatever.",
            "But if yours does better than everybody else is, then you get to write a paper about it and submit it to a conference like this and you get famous.",
            "But what banking Bill said, yeah, well that's where all the academic game is is arguing along this dimension.",
            "But really, there's a lot more room to play in this other dimension.",
            "So instead of thinking really hard and coding up a better algorithm, if you just went out and gathered 10,000,000."
        ],
        [
            "Words of training data as opposed to 1,000,000.",
            "Now we see that the very worst possible algorithm that anybody was able to come up with this performing better than the very best possible algorithm at 1,000,000 words.",
            "And if you do that again, you go."
        ],
        [
            "And collect 100 million words.",
            "The same thing happens.",
            "All good things come to an."
        ],
        [
            "And eventually, and at some point you ask him to it out.",
            "And so now when you're at a billion words of training data, you no longer the worst is better than the best there.",
            "But also note that now this is the time when we should start having the academic arguments.",
            "So now when we've asked him to doubt and gathering more data doesn't help as much.",
            "Now let's start arguing about which algorithm is the best, and we would start that argument by saying the square algorithm is the best and not that the cross algorithm is the best."
        ],
        [
            "OK, so data driven programming.",
            "Another way to look at this is I like to talk of it as being rational programming or what to do when you don't know what to do.",
            "And you can think of it as saying what any program should do is to maximize expected utility.",
            "If there is uncertainty, then there's different possible outcomes for each action.",
            "So you look at all the possible actions you can take.",
            "You look at the expected utility of each one and choose the actions.",
            "That's the best where the expected utility is just the utility of each possible outcome times the probability of that outcome.",
            "And now the whole game is saying, how do we learn or approximate the results for each action?",
            "The probability for each result in state and the utility of each state?",
            "And can we do that from data sources?",
            "And my argument is that for a large class of problems, this model does fit and you can make progress going this way."
        ],
        [
            "And I'm going to look at two sources of available data to do that.",
            "One is text data and the other is image data."
        ],
        [
            "OK, so text data will start off at the sort of the lowest level and work our way up.",
            "So will start at the level of individual characters with the problem of segmentation.",
            "So in Chinese and many other languages there are no spaces in between words and so to understand what this means you have to know is the first word consist of this one character or does it consist of two characters or what?",
            "Unfortunately I don't Chinese so I can't answer that for you.",
            "But we can artificially make a segmentation."
        ],
        [
            "Problem in English by taking an English phrase and just getting rid of all the letters.",
            "And now the problem is saying how do you convert this back into words and by looking at that you can probably solve this problem pretty well, so it's not that difficult problem.",
            "What is the source of information that you need in order to do that?",
            "Do you need knowledge of quotations?",
            "Do you need knowledge of syntax of semantics or what?"
        ],
        [
            "OK, so I tried to tackle that."
        ],
        [
            "Woman, and if you use this rational approach, you say, well, the probability of a potential segmentation is will make an independence assumption and will say it's the probability of the first word times the probability of the segmentation."
        ],
        [
            "The rest of it.",
            "And the best segmentation is the one with the high."
        ],
        [
            "Probability an will estimate the probability of a word just by counting from a large corpus.",
            "So this sort of the simplest possible attack will see if this is good enough."
        ],
        [
            "So now the probably the segmentation for that phrase that I gave you.",
            "We look at all the candidates.",
            "Probability that end is first word times.",
            "This is the rest.",
            "What's probably the Tenno is the first word.",
            "That's probably a lot higher times.",
            "This is the rest.",
            "What's probably you know, W is the first word that's also pretty high times.",
            "This is a rest NOWI that's going to be pretty low and you just go."
        ],
        [
            "Down fill out the table.",
            "It looks like this.",
            "And out of those.",
            "Now is a.",
            "10 to the Fifth Times better than any of the alternatives, and now so you got your first word jumped off, and then you recursively look at the rest of the week."
        ],
        [
            "Words.",
            "And it turns out that this is the whole program.",
            "You can write it down on one page and not even one page that fits on your large 30 inch terminal, but one page that fits on this tiny little projector screen.",
            "This is the whole thing.",
            "I cheated a little bit.",
            "I had utility file that has this.",
            "Some utility for doing probably basic probability, but this is a way to split up the segmentation into all possible splits.",
            "The probability of word is just a sequence of words is just the product of the individual words, probabilities and the segmentation is just repeating this recursive idea of the best segmentation and then you minimize it to get the dynamic programming."
        ],
        [
            "So a very simple approach.",
            "How well does it do?",
            "Well, I happen to have 1.7 billion words hanging around on my laptop.",
            "If I was trying to do this seriously, I would take a larger corpus, but one point, 7 billion was fine."
        ],
        [
            "And I achieved.",
            "I've made a little test case for myself.",
            "I got 98% word accuracy."
        ],
        [
            "There were some errors, so this one.",
            "Can you guys segment that?"
        ],
        [
            "Well, I got base rates ought to when it should have been.",
            "Base rates ought to, so they're both pretty good segmentation."
        ],
        [
            "And I happen to choose the wrong one, this one."
        ],
        [
            "I got small anin significant when it should have been."
        ],
        [
            "Small and insignificant.",
            "So this is a case where knowing some semantics would have helped or just knowing some probabilities over multiple word sequences rather than just one word."
        ],
        [
            "Time.",
            "Here's another one.",
            "This one's harder.",
            "Can you segment that?"
        ],
        [
            "I got G enormouse go but it should have been ginormous ego and so this was an example where I wanted to have an out of vocabulary word out of all 1.7 billion words I had never seen gianormous before, and that's kind of the hard part.",
            "He is making these models for what to do to smooth when you haven't seen words before, and my trivial program didn't do a good job of smoothing.",
            "And so it got the wrong answer."
        ],
        [
            "OK, and this stuff really matters, so obviously it matters in Chinese and other languages like that where you want to do the segmentation right on the web.",
            "There's also segmentation problems.",
            "People type in queries and they get them wrong.",
            "They leave out spaces or they put in extra spaces and we want to fix it for them.",
            "And of course people write URLs without spaces in them and we want to recognize that and get them right.",
            "And people have made mistakes both in recognizing these and I. I claim that webmasters have made mistakes in the URLs that they register and so I applied my algorithm to some of these possible URLs."
        ],
        [
            "Here's one.",
            "So that's of course, who represents a great site where you can see which Hollywood stars are represented by which agents.",
            "And of course, that was the only possible segmentation right there.",
            "Or at least that's the best segmentation according to my algorithm.",
            "Who would have thought of another possible segmentation?",
            "Here's."
        ],
        [
            "Therapist Finder where you can find somebody for your therapeutical needs.",
            "Nobody could have segmented."
        ],
        [
            "That wrong here is experts exchange where you can hire an expert.",
            "And not get any kind of medical advice."
        ],
        [
            "Here's what I got wrong.",
            "Pen Island purveyor of fine writing implements my little test test pad.",
            "Told me I had an error there.",
            "Expected Pen Island, but I actually got, oh, it's cut off so.",
            "Shoot, I don't know what I actually got, but it's obviously I got something that has a contains a word with high probability among that 1.7 billion Woodward corpus."
        ],
        [
            "Ann is one more example.",
            "A purveyor of fine art supplies.",
            "OK, so these people had known more about segmentation and various different probabilities.",
            "Maybe they would have chosen DIF."
        ],
        [
            "URLs becoming we got from that, so step up from segmentation is spelling correction.",
            "Typical word processor used to seeing these square little red lines and my colleague and fellow machine learning connoisseur Mayron Sami always gets upset when he sees little red lines under his name and in a common office product.",
            "When he hits the OK."
        ],
        [
            "A button he gets that.",
            "Which is probably not the most likely capability, but you know, given that you're working from a dictionary and his name wasn't in the dictionary, that's the best you can do.",
            "But if you work from a larger corpus and said maybe you can do better."
        ],
        [
            "And so I wanted to compare get back to this idea of Agile programming, compare this corpus based approach to a more traditional programming based approach.",
            "And so we went on the web and I search for spelling corrector's and I found this one.",
            "And you know, so there's all this stuff in there under the case.",
            "See, you say do something if X is if it's CIA is in there or Ch or LCS is if in or if it's C or CE.",
            "Or see why it's dropped.",
            "And let's see I see IRS EERSEY and quick.",
            "Can you verify that they got every case right there?",
            "Can anybody do that?",
            "OK, well, you know, maybe we take you a little while to verify that every possible cases covered there, but then the next trick is I'll give you a couple of days to do that, and then I'll give you another day to say, well, just let's do a simple one more thing and just port this to Romanian.",
            "That couldn't be too hard, right?",
            "Just modify the code a little bit so it does remain instead of English.",
            "How hard could that be?",
            "And you can see that that's the fragility of this hand coded approach as opposed to the machine learning approach."
        ],
        [
            "OK so again."
        ],
        [
            "It's the same old model.",
            "You fall back to this probability probability of the spelling correction is depends on the probability that the correction C is a word, and the probability that it's impossible."
        ],
        [
            "Typo for the original word.",
            "Best corrections, one with the highest probability."
        ],
        [
            "The probability of a word we get again by count."
        ],
        [
            "Just like we did before, probability of a typo.",
            "You need some kind of a model to say given these two words.",
            "How similar are they to each other?",
            "And how probably could be a typo for another if you've been running a spelling correction service for a long time, you've got lots of examples of that.",
            "You could have a really good model of that.",
            "If you don't, you can just do something simple like count the edit distance between them and then."
        ],
        [
            "What I did.",
            "And then here's the whole program.",
            "It's a little bit longer, but not too much.",
            "Again, fits on one page and whoops.",
            "I guess I got something like I forget the exact number, but something like 80% correct with this.",
            "And if you wanted to do more, you probably want to take more context into account and do what is the probability of this word given that it appears before the next word so on.",
            "OK, now let's just."
        ],
        [
            "Up a little bit from there and say can we do something that's more semantic oriented and this is one of the first experiments we did at the Google Labs.",
            "Google Stats done by Simon Tong and the idea here is use all the information you have available on the web to suggest sets of things that are related to each other and so here I put in public kasoa."
        ],
        [
            "Matisse, an I get back Matisse Picasso, Van Gogh, Monet Picasso so it's concentrating on these Impressionist artist 1st and then it has other kinds of artists and it veers off a little bit.",
            "No, Ansel Adams is in the bottom.",
            "There's a slightly different medium that he uses and so on, but it looks like a pretty good clue."
        ],
        [
            "String.",
            "If I give it Lions and Tigers and bears, I get back.",
            "Tigers, Lions, elephants, monkeys, giraffes, dogs, cats, snakes and so on looks like it's doing pretty good.",
            "There's a couple of things in italics there that aren't quite right.",
            "It looks like so there's cotton and wooden musical and toddler and you might want to think about how did that sneak in there?",
            "And we'll see the answer soon.",
            "But like you guys do on that.",
            "So those were all kind of."
        ],
        [
            "Lated animals what if I gave it to different kinds of an animal?",
            "So what would it come up with then?"
        ],
        [
            "Well, of course that.",
            "And then you can see that you know they're sorted from central to peripheral, and so it does pick out that man and LS and CP in RMR, the prototypical Unix commands and make node and who am I?",
            "Or are more peripheral?",
            "So it does seem to have some kind of understanding there.",
            "So how would you do something like this?",
            "Well, I'm not going to show you the whole code 'cause that doesn't fit on one page, but I'm going to show you some of the data sources."
        ],
        [
            "So the first thing you can do is just go on the web and look for proximity and say look Lions and Tigers and bears curve close to each other.",
            "Maybe they're related and that's pretty good clue, but then you'd also have to say, well, summon mostly in, but also occur in that.",
            "Does that mean they're related?",
            "So maybe it's not."
        ],
        [
            "Stronger clue.",
            "But here is a case where that looks stronger where we have HTML structure in the.",
            "In the case of these list elements, in case of links, and maybe that's a stronger clue that those are related."
        ],
        [
            "And this is the example to the puzzle are of why did those weird things come in?",
            "Because the web does reflect reality, and so it does talk about animals.",
            "But the web also reflects an awful lot of Commerce, and you can't really buy Lions and Tigers and bears.",
            "But you can buy stuffed animals and toddler animals and cotton plush toys and so on.",
            "So those words get confused."
        ],
        [
            "Another thing you could do is look at your user logs and say, well, somebody was looking for Akita pics and then leopard pics soon afterwards.",
            "Maybe that's an indication."
        ],
        [
            "Chen and then you can try to understand the structure of English and you can either do that with a full parser that understands everything about sentences, or you can do it with restricted approaches.",
            "I think Marty Hearst at Berkeley was the first one to suggest using phrases that are highly indicative that are high precision but potentially low recall.",
            "And so if you want to find what things are like Lions, you could search for the phrase such as Lions, and then anything that shows up there.",
            "It's very likely.",
            "That that's going to be in the same set as Lions.",
            "Of course there is.",
            "You know countless numbers of different ways that you could say Lions and Tigers or similar, and you're going to miss all the other ones with this.",
            "But if the web is large enough and there's enough examples, you'll get what you need."
        ],
        [
            "OK, and then the final example for text they want to talk about is this statistical machine translation and this is a little bit harder.",
            "Not only do I need a large corpus of English text if I'm trying to translate into English, but if I'm trying to translate from German, I also need a corpus of parallel text and when I was in my hotel in Berlin, I was able to do that.",
            "They had a nice collection of parallel text.",
            "It got a little brochure and on one side with the English and the other side.",
            "But the German and now I can say that these are aligned with each other and if I've ever given.",
            "Exactly this phrase in German, then I know that this is the translation in English, but what if I'm not given exactly that?",
            "How can I use this information anyways?"
        ],
        [
            "Well, I've I start off knowing that this is the alignment and now I want to try to align word by word an.",
            "One possibility is that these two words are lined up according to each other, and so I'd assign."
        ],
        [
            "Probability to that, but it also might be that there lined up that those two words are are lined up and assign a probably."
        ],
        [
            "Be there or could."
        ],
        [
            "All the way to the end.",
            "Or it could be one word is aligned with two would have been vice versa.",
            "So from one sentence I get a very broad probability distribution.",
            "All these things are possible and then I just keep on adding him up over and over and over and notice that Gee, you know lots of times conston art occur in sentences that are aligned and constant luxury did not occur as often in the probabilities begin to converge."
        ],
        [
            "Then eventually you say, well, that's going to be the right alignment."
        ],
        [
            "How well does it do here?",
            "Some Arabic Tran."
        ],
        [
            "Late to English comes out like this.",
            "I've underlying the places where there's disfluencies, so you can't go more than a sentence or two without saying.",
            "Here's an example of something that's not quite fluent English text, but it is good enough that you get the idea of what's going on and all the right who's doing what to who is."
        ],
        [
            "Presented properly Chinese."
        ],
        [
            "Similar kind of thing there, it's more like.",
            "Two or so disfluencies per sentence rather than one, probably reflecting the fact that Chinese is more different from English there."
        ],
        [
            "Checkers.",
            "How do we go through the process?"
        ],
        [
            "Well, we start off we go one character at a time, get the first character, look up the probabilities for the alignments and he is the most likely you know it.",
            "In this case I haven't folded case together so he and capital here consider different tokens."
        ],
        [
            "Go to the next one and we have a set here an now notice when we want to do the probability.",
            "There's two probabilities we have to deal with.",
            "One is the probability of the translation from Chinese into English, and that's represented by these lists here, and the other is the probability that we generate is a sentence of English, and that we test against a corpus of English, and in that case we we'd probably recognize that the top probability here he letter.",
            "Is not very probable in English, but if you go down the list a little bit, his letter would be more probable, and so we'd be able to make that kind of correction there.",
            "Of course, we don't have to look just one character at it."
        ],
        [
            "Time we can also combine them, and in fact we've seen this sequence before and we have recognized that his letter is right alignment in many cases.",
            "For this more probable than he letter.",
            "But we also notice that it's this also is a proper name and that that's more probable."
        ],
        [
            "And in fact, in this case we've actually seen 3 character sequence corresponding to this already, so it's more case of vlookup than pasting."
        ],
        [
            "This together, but for the rest of it.",
            "Now we're going to."
        ],
        [
            "Start pasting together and what we're essentially doing is trying to find it."
        ],
        [
            "Path through this."
        ],
        [
            "Create probability."
        ],
        [
            "That's the highest probability.",
            "And this just chart here just echoes the first chart we had, saying that as we get more data, the scores keep going up and we haven't reached the point yet where the score is asymptotes, so there's still more to gain from the date."
        ],
        [
            "OK, now I want to switch a little and talk about image data."
        ],
        [
            "And here's an example from Google Image Search where you type in name.",
            "Here I've typed Mona Lisa and here's the results you get back.",
            "Pretty good, but there's a variety of ones there and who knows really what the best one is.",
            "And you know, it's it's no secret that Google, like most of the other providers of image search for the most part, until very recently have been throwing away the images and just looking at the surrounding words in filenames and things like that.",
            "And for the most part, that works pretty well, but we can improve that by looking at the data in the images themselves, and in this case, what we're really looking for is saying well, there is a Canonical answer.",
            "To this query and we want to be able to find that and on the web.",
            "We're very good at Canonical answers, so if you type IBM, all the search engines will give you ibm.com.",
            "That's an easy one because not because of the contents of what's on that page, but because of all the links that link to it.",
            "And so there's good agreement that that's the right answer to that query on the web itself, with pictures, that's not the case.",
            "There is one Canonical Mona Lisa image, or.",
            "Artifact in the real world, but that's not represented by one picture on the web.",
            "It's represented by lots of different pictures, and so we have to be able to figure out which ones of those represent the same object in the real world."
        ],
        [
            "And we do that by first looking at the images running sort of standard feature extractor and then conceptually looking at all pairs of images and lining up which features line up with each other.",
            "And then we get a measure of similarity between each pair of images.",
            "And of course you take shortcuts so you don't have to look at at all the possible end squared pairs, but just the ones that make sense to look."
        ],
        [
            "And now essentially we draw a graph of the connectedness between those of how close each images are to each other, an we're good at dealing with graphs, we know how to take a graph and figure out what the central ones are.",
            "And in fact this case it comes out that this one here is the central point of this graph, and that is a good choice as a Canonical image.",
            "OK, so that's a way of combining a little bit of image data from extracting these features from the images and then a lot of information from the web of what's connected to each other and what's import."
        ],
        [
            "OK, and here we blowing up just a portion of it and we can see how this one's in the middle and these ones are on the periphery.",
            "And that's pretty important, because people are easily distracted when they're searching for images and you know their task was really defined.",
            "This one.",
            "But if we show them a variety, they're going to get distracted and say, Oh well, you know, maybe this one or this one is different and more interesting, so I'll go off and look at that.",
            "Or this one is showing some skin.",
            "So yeah, I'll definitely click on that one.",
            "We've got to have a way to combat that and say we don't want to show as a number one result, something that's more interesting or novel.",
            "Maybe we want to show that somewhere in the results, but we want to show the Canonical 1 first, and this kind of technique allows us to do that.",
            "Out."
        ],
        [
            "OK, and another similar example for Starbucks were able to get that logo."
        ],
        [
            "Right in the middle.",
            "And then this is just an example of what the features are.",
            "So at each point there's a vector for that point.",
            "These so called sift features, and so it's abstract representation of.",
            "What the image is, but it's works well across rotations and scaling and so on, so it's easy to compare between images."
        ],
        [
            "OK, and here is just one more example showing this is for the Lincoln Monument.",
            "How they cluster into multiple different clusters, so there's necessarily in for Mona Lisa.",
            "There was sort of 1 Canonical here.",
            "It turns out that there's three Canonical there's inside during the day and inside during night.",
            "An exterior shot that get clustered together."
        ],
        [
            "OK, and one more piece of work by Yagnik and Islamic at Google.",
            "On learning people annotations."
        ],
        [
            "So here we have an image and the annotation says George Bush Merkel and a barrel of herring, photographed by Herbert proper.",
            "And so if you were searching for Merkel or Bush, this picture could potentially be retrieved.",
            "But you wouldn't really know which one was Bush and which was Merkel and which was a hearing.",
            "Anne, you wouldn't know that Herbert Roper isn't represented in the picture that he was, just the photographer.",
            "'cause all those words aren't differentiated.",
            "So what we'd like to be able to do is similar to what we do."
        ],
        [
            "The translation here is these faces for him and they get this model for Alan.",
            "All done here is these faces for him and notice that like with the Lincoln Monument, we don't have to map everything into a single model.",
            "We can have multiple clusters and so you get the young Alan Alda from mash days with dark hair and then the older Allen.",
            "Although with balding and glasses and so on, and that's OK for these types of data driven models.",
            "But we don't have to fit everything into one.",
            "OK."
        ],
        [
            "So incan."
        ],
        [
            "Version code is liability.",
            "Here's this guy used to be really good programmer than doesn't happen to him.",
            "He stopped coding, but he said measuring programming progress by lines of code is like measuring aircraft building progress by weight, right?",
            "So you don't really want to know as you're building your airplane G. It's everything is going great.",
            "It's getting heavier and heavier.",
            "Rather, what you want to say is it would be nice if it was getting lighter and lighter then it could fly better, and it's the same thing with lines of codes.",
            "Probably you know each line of code makes your project heavier and harder to change, so the fewer you have the better and this data driven approach is one way of getting to that ideal of having less code, more flexible, more heads up an.",
            "Wait time for reference."
        ],
        [
            "OK. Yeah.",
            "Um?",
            "Now this is the standard approach for for learning on those image databases.",
            "I think that image is an important image.",
            "Search is an important application, so they have been using the text to search the images.",
            "Is it possible to do the opposite?",
            "Use this all we learn on those graphs is out this this compilation.",
            "That you do on those.",
            "Those guys do this.",
            "Create some knowledge that can be used to retrieve the text.",
            "The concepts on the taxes.",
            "Is this possible to explore on the opposite way information?",
            "So you want to put in an image and get back out text?",
            "No, I mean you the user is searching for the text for the concept for the web page on the text, but since you have the this beautiful concept map the cluster can you can you profit from.",
            "This information to give him the right web page.",
            "Yeah, so I mean certainly we try to do that.",
            "You know, we if I'm not quite sure if you're asking what what types of queries and how the text versus images is work, but in all cases we want to integrate all the knowledge we have, right?",
            "So if you if we know synonyms for words we want to be able to add those in.",
            "If we know relationships between them, we should add that in.",
            "So far we have kept the web search and the image search separate, although we think they probably should be.",
            "Yeah, integrated together more and we'd like to be able to do that more in the future.",
            "Yeah.",
            "Hello, with Google Image there was kind of a community encouraging where people just could tag and there was another rewarded when people just tag it and said it was right or wrong.",
            "I wonder if you found it really interesting and it really helped retrieval of images in Google right now.",
            "Yeah, so I think that is interesting and so you know I think tags are helpful for pictures.",
            "You've seen that in Flickr.",
            "And then Luis von Ahn had this game to do it, and then Google license that from CMU.",
            "And now now we have a version of that where people are adding images, adding tags to images.",
            "I think it's pretty useful resource, and it's amazing how willing people are to to play these kinds of games, and you can get a lot of data quickly.",
            "You know we don't have definitive results yet.",
            "It still kind of in the research stage to say how far are we going to get.",
            "I think overall that it can help kind of bootstrap where we are, as can image searches and clicks.",
            "You know, I pointed out that the clicks are a little bit noisy.",
            "People get distracted and they click on the wrong thing, but still, that is another source that is pretty useful.",
            "But once you get past the bootstrap stage, I think there's more information than the images themselves, and particularly in the in the videos, and I think we'll get more out of that overtime.",
            "But it's but it's good to have it right at the beginning, 'cause otherwise you're lossed.",
            "Yeah.",
            "I have to preface this by saying I work for Google, so Luckily I'm not in this situation, but I mean your argument is that you know when you have a lot of data you win, or you you can do all these excellent things with statistical methods, but for a lot of problems you might not have the data or certainly not the kind of many, many orders of magnitude of data that you know we've seen here works right?",
            "What do you do then?",
            "Should you focus on data collection first?",
            "Should you bootstrap?",
            "Should you write code?",
            "I guess it depends on the problem.",
            "You know.",
            "I mean part of what I was saying is that it's not only the Googles that can do this, right?",
            "So I got some good results with only on the order of a billion words.",
            "That's not very much.",
            "Everybody in this room can go out and by the end of the day, you could have collected a billion words of text and you can store it on your laptop.",
            "You don't need a data center or large capability to do that.",
            "And Google also publishes the Ngram counts up to 5 grams, 4 trillion words of text.",
            "So you can buy that just for the cost of the of the DVD's.",
            "So you can go pretty far in terms of language data, other kinds of data.",
            "I guess that depends on the application, right?",
            "Right so.",
            "You know you gotta look on individual case.",
            "If you have what you need then then go ahead and use it.",
            "If you don't, you gotta try something else.",
            "That we have to look at those one by one.",
            "Chris and on top of that head of any projects where the data driven approach is a failure.",
            "Let's see.",
            "Where the data driven approach was a failure?",
            "Well, you know you know.",
            "I mean, we still don't have complete AI.",
            "You know we'd like to be able to just go and ask any question, and the computer tells us the final answer and we don't have that because I think that there's too many steps in between understanding all these links in the chain, and so the steps that do work seem to be where it's more focused where it's a simpler task, an where things are closer to being retrieval rather than inference, and I think those are good properties.",
            "To look for.",
            "Yeah, I think it's a good example of that.",
            "Is the current financial meltdown, which seems to be caused by the fact that people build models based on data and then these models make prediction based on data they'd never seen before, so they completely didn't predict.",
            "So how close are we to building both models that can?",
            "Tell you the correct answer, but also tell you when they have no idea what the right answer is.",
            "Yeah, so so that's a good idea, right?",
            "So you what you want?",
            "Not only do you want the result, but you want some sort of a confidence score on that.",
            "And then the question is when does the confidence score?",
            "When is that misleading and you know I mentioned if it's closer to retrieval, that's good, and I think it's this idea of you.",
            "Interpolating or extrapolating, and so if it's if you seen something that's very close to what you've seen before, and there's lots of neighbors around and those neighbors all agree, then maybe you feel pretty confident.",
            "If it's something that's out on the edge or beyond what you've seen and you're trying to extrapolate, then you should feel less confidence.",
            "And then I think you should also be monitoring the data and how it changes overtime, and you know, so I don't know.",
            "I haven't looked at the.",
            "At the current financial situation, but.",
            "So it seems like there were lots of people who were warning, you know, something unusual is happening and other people just said well, I don't care.",
            "I'm going to ignore that morning and go out of business as usual.",
            "So it looks like there were alerts there, and I think you know I started off by talking about this agile programming approach and part of Agile is being test driven, and I think that's also true for any data driven approach that you should be test driven.",
            "You should write these tests first an.",
            "But one of the difficulties is figuring out.",
            "An approach that allows us to do those kinds of tests 'cause you know you look at all the test suites and they all have things like assert true or assert equal and they don't have things like assert that the standard deviation of this result is within one standard deviation of what it was last week.",
            "And I think we want testing regimes that are more like that.",
            "Let's say not.",
            "Is this true or false?",
            "But here's the probability.",
            "Here's the bounds.",
            "Ann, and you know, alarms that go off that say things are different.",
            "Now things are changing more quickly than they used to be changing.",
            "I don't know if that's going to screw things up or not, but somebody was smart, should focus their attention here.",
            "Should close down."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So what I want to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Day is the use of data in search and in computing in general, and you know the model.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about is how can you get software done quickly and you hear a lot about different methodologies and these agile development methodologies.",
                    "label": 0
                },
                {
                    "sent": "And my lesson is that data is the ultimate agile development tool 'cause data is always more agile than code.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so if you you know go to these consultants and they or you go.",
                    "label": 0
                },
                {
                    "sent": "This is from Wikipedia and tells you what these agile development principles are, how you focus on customers and you work quickly and you measure your progress and so on so on.",
                    "label": 0
                },
                {
                    "sent": "And you want simplicity and adaptation.",
                    "label": 0
                },
                {
                    "sent": "These are all qualities that we see in data more than code.",
                    "label": 0
                },
                {
                    "sent": "Code is static and you need these kinds of tools to fight against it.",
                    "label": 0
                },
                {
                    "sent": "Whereas data is sort of self updating and simple and adaptable kind of by default.",
                    "label": 0
                },
                {
                    "sent": "And if you want another take on this you can see my colleague Steve Yaggi has a blog post called Good Agile Bad Agile.",
                    "label": 1
                },
                {
                    "sent": "He focuses mostly on the bad, but he's always got his own take on things.",
                    "label": 0
                },
                {
                    "sent": "I see Greg in the audience there smiling, he knows.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, what's what's the use of data?",
                    "label": 0
                },
                {
                    "sent": "Or why is it important?",
                    "label": 0
                },
                {
                    "sent": "And so this is a chart from paper by Banko and Brill from Microsoft Research in 2001, and they did a meta analysis of five different learning algorithms on the task of word sense disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So this is a task where the algorithms given a sentence and a word ambiguous word like, say, bank is in the middle of the sentence.",
                    "label": 0
                },
                {
                    "sent": "And it has to tag that and say that's the money bank sense of the word, or that's the riverbank sense of the word and you start out and you give it some training data and you get a standardized training set, say with 1,000,000 words, training data and then you apply your different learning algorithms and see how well they do an.",
                    "label": 0
                },
                {
                    "sent": "If you come up with this new algorithm called this X here and I don't know what that is, it's naive Bayes classifier or it's a decision tree.",
                    "label": 0
                },
                {
                    "sent": "Or it's a support vector machine or whatever.",
                    "label": 0
                },
                {
                    "sent": "But if yours does better than everybody else is, then you get to write a paper about it and submit it to a conference like this and you get famous.",
                    "label": 0
                },
                {
                    "sent": "But what banking Bill said, yeah, well that's where all the academic game is is arguing along this dimension.",
                    "label": 0
                },
                {
                    "sent": "But really, there's a lot more room to play in this other dimension.",
                    "label": 0
                },
                {
                    "sent": "So instead of thinking really hard and coding up a better algorithm, if you just went out and gathered 10,000,000.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Words of training data as opposed to 1,000,000.",
                    "label": 0
                },
                {
                    "sent": "Now we see that the very worst possible algorithm that anybody was able to come up with this performing better than the very best possible algorithm at 1,000,000 words.",
                    "label": 0
                },
                {
                    "sent": "And if you do that again, you go.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And collect 100 million words.",
                    "label": 0
                },
                {
                    "sent": "The same thing happens.",
                    "label": 0
                },
                {
                    "sent": "All good things come to an.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And eventually, and at some point you ask him to it out.",
                    "label": 0
                },
                {
                    "sent": "And so now when you're at a billion words of training data, you no longer the worst is better than the best there.",
                    "label": 0
                },
                {
                    "sent": "But also note that now this is the time when we should start having the academic arguments.",
                    "label": 0
                },
                {
                    "sent": "So now when we've asked him to doubt and gathering more data doesn't help as much.",
                    "label": 1
                },
                {
                    "sent": "Now let's start arguing about which algorithm is the best, and we would start that argument by saying the square algorithm is the best and not that the cross algorithm is the best.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so data driven programming.",
                    "label": 0
                },
                {
                    "sent": "Another way to look at this is I like to talk of it as being rational programming or what to do when you don't know what to do.",
                    "label": 1
                },
                {
                    "sent": "And you can think of it as saying what any program should do is to maximize expected utility.",
                    "label": 0
                },
                {
                    "sent": "If there is uncertainty, then there's different possible outcomes for each action.",
                    "label": 0
                },
                {
                    "sent": "So you look at all the possible actions you can take.",
                    "label": 0
                },
                {
                    "sent": "You look at the expected utility of each one and choose the actions.",
                    "label": 0
                },
                {
                    "sent": "That's the best where the expected utility is just the utility of each possible outcome times the probability of that outcome.",
                    "label": 0
                },
                {
                    "sent": "And now the whole game is saying, how do we learn or approximate the results for each action?",
                    "label": 0
                },
                {
                    "sent": "The probability for each result in state and the utility of each state?",
                    "label": 0
                },
                {
                    "sent": "And can we do that from data sources?",
                    "label": 0
                },
                {
                    "sent": "And my argument is that for a large class of problems, this model does fit and you can make progress going this way.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm going to look at two sources of available data to do that.",
                    "label": 0
                },
                {
                    "sent": "One is text data and the other is image data.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so text data will start off at the sort of the lowest level and work our way up.",
                    "label": 0
                },
                {
                    "sent": "So will start at the level of individual characters with the problem of segmentation.",
                    "label": 0
                },
                {
                    "sent": "So in Chinese and many other languages there are no spaces in between words and so to understand what this means you have to know is the first word consist of this one character or does it consist of two characters or what?",
                    "label": 0
                },
                {
                    "sent": "Unfortunately I don't Chinese so I can't answer that for you.",
                    "label": 0
                },
                {
                    "sent": "But we can artificially make a segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem in English by taking an English phrase and just getting rid of all the letters.",
                    "label": 0
                },
                {
                    "sent": "And now the problem is saying how do you convert this back into words and by looking at that you can probably solve this problem pretty well, so it's not that difficult problem.",
                    "label": 0
                },
                {
                    "sent": "What is the source of information that you need in order to do that?",
                    "label": 0
                },
                {
                    "sent": "Do you need knowledge of quotations?",
                    "label": 0
                },
                {
                    "sent": "Do you need knowledge of syntax of semantics or what?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I tried to tackle that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Woman, and if you use this rational approach, you say, well, the probability of a potential segmentation is will make an independence assumption and will say it's the probability of the first word times the probability of the segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The rest of it.",
                    "label": 0
                },
                {
                    "sent": "And the best segmentation is the one with the high.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probability an will estimate the probability of a word just by counting from a large corpus.",
                    "label": 0
                },
                {
                    "sent": "So this sort of the simplest possible attack will see if this is good enough.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the probably the segmentation for that phrase that I gave you.",
                    "label": 0
                },
                {
                    "sent": "We look at all the candidates.",
                    "label": 0
                },
                {
                    "sent": "Probability that end is first word times.",
                    "label": 0
                },
                {
                    "sent": "This is the rest.",
                    "label": 0
                },
                {
                    "sent": "What's probably the Tenno is the first word.",
                    "label": 0
                },
                {
                    "sent": "That's probably a lot higher times.",
                    "label": 0
                },
                {
                    "sent": "This is the rest.",
                    "label": 0
                },
                {
                    "sent": "What's probably you know, W is the first word that's also pretty high times.",
                    "label": 0
                },
                {
                    "sent": "This is a rest NOWI that's going to be pretty low and you just go.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Down fill out the table.",
                    "label": 0
                },
                {
                    "sent": "It looks like this.",
                    "label": 0
                },
                {
                    "sent": "And out of those.",
                    "label": 0
                },
                {
                    "sent": "Now is a.",
                    "label": 0
                },
                {
                    "sent": "10 to the Fifth Times better than any of the alternatives, and now so you got your first word jumped off, and then you recursively look at the rest of the week.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Words.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that this is the whole program.",
                    "label": 0
                },
                {
                    "sent": "You can write it down on one page and not even one page that fits on your large 30 inch terminal, but one page that fits on this tiny little projector screen.",
                    "label": 0
                },
                {
                    "sent": "This is the whole thing.",
                    "label": 0
                },
                {
                    "sent": "I cheated a little bit.",
                    "label": 0
                },
                {
                    "sent": "I had utility file that has this.",
                    "label": 0
                },
                {
                    "sent": "Some utility for doing probably basic probability, but this is a way to split up the segmentation into all possible splits.",
                    "label": 0
                },
                {
                    "sent": "The probability of word is just a sequence of words is just the product of the individual words, probabilities and the segmentation is just repeating this recursive idea of the best segmentation and then you minimize it to get the dynamic programming.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a very simple approach.",
                    "label": 0
                },
                {
                    "sent": "How well does it do?",
                    "label": 0
                },
                {
                    "sent": "Well, I happen to have 1.7 billion words hanging around on my laptop.",
                    "label": 0
                },
                {
                    "sent": "If I was trying to do this seriously, I would take a larger corpus, but one point, 7 billion was fine.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I achieved.",
                    "label": 0
                },
                {
                    "sent": "I've made a little test case for myself.",
                    "label": 0
                },
                {
                    "sent": "I got 98% word accuracy.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There were some errors, so this one.",
                    "label": 0
                },
                {
                    "sent": "Can you guys segment that?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, I got base rates ought to when it should have been.",
                    "label": 0
                },
                {
                    "sent": "Base rates ought to, so they're both pretty good segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I happen to choose the wrong one, this one.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I got small anin significant when it should have been.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Small and insignificant.",
                    "label": 0
                },
                {
                    "sent": "So this is a case where knowing some semantics would have helped or just knowing some probabilities over multiple word sequences rather than just one word.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time.",
                    "label": 0
                },
                {
                    "sent": "Here's another one.",
                    "label": 0
                },
                {
                    "sent": "This one's harder.",
                    "label": 0
                },
                {
                    "sent": "Can you segment that?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I got G enormouse go but it should have been ginormous ego and so this was an example where I wanted to have an out of vocabulary word out of all 1.7 billion words I had never seen gianormous before, and that's kind of the hard part.",
                    "label": 0
                },
                {
                    "sent": "He is making these models for what to do to smooth when you haven't seen words before, and my trivial program didn't do a good job of smoothing.",
                    "label": 0
                },
                {
                    "sent": "And so it got the wrong answer.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and this stuff really matters, so obviously it matters in Chinese and other languages like that where you want to do the segmentation right on the web.",
                    "label": 0
                },
                {
                    "sent": "There's also segmentation problems.",
                    "label": 0
                },
                {
                    "sent": "People type in queries and they get them wrong.",
                    "label": 0
                },
                {
                    "sent": "They leave out spaces or they put in extra spaces and we want to fix it for them.",
                    "label": 0
                },
                {
                    "sent": "And of course people write URLs without spaces in them and we want to recognize that and get them right.",
                    "label": 0
                },
                {
                    "sent": "And people have made mistakes both in recognizing these and I. I claim that webmasters have made mistakes in the URLs that they register and so I applied my algorithm to some of these possible URLs.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's one.",
                    "label": 0
                },
                {
                    "sent": "So that's of course, who represents a great site where you can see which Hollywood stars are represented by which agents.",
                    "label": 1
                },
                {
                    "sent": "And of course, that was the only possible segmentation right there.",
                    "label": 0
                },
                {
                    "sent": "Or at least that's the best segmentation according to my algorithm.",
                    "label": 0
                },
                {
                    "sent": "Who would have thought of another possible segmentation?",
                    "label": 0
                },
                {
                    "sent": "Here's.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therapist Finder where you can find somebody for your therapeutical needs.",
                    "label": 0
                },
                {
                    "sent": "Nobody could have segmented.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That wrong here is experts exchange where you can hire an expert.",
                    "label": 0
                },
                {
                    "sent": "And not get any kind of medical advice.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's what I got wrong.",
                    "label": 0
                },
                {
                    "sent": "Pen Island purveyor of fine writing implements my little test test pad.",
                    "label": 0
                },
                {
                    "sent": "Told me I had an error there.",
                    "label": 0
                },
                {
                    "sent": "Expected Pen Island, but I actually got, oh, it's cut off so.",
                    "label": 1
                },
                {
                    "sent": "Shoot, I don't know what I actually got, but it's obviously I got something that has a contains a word with high probability among that 1.7 billion Woodward corpus.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ann is one more example.",
                    "label": 0
                },
                {
                    "sent": "A purveyor of fine art supplies.",
                    "label": 0
                },
                {
                    "sent": "OK, so these people had known more about segmentation and various different probabilities.",
                    "label": 0
                },
                {
                    "sent": "Maybe they would have chosen DIF.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "URLs becoming we got from that, so step up from segmentation is spelling correction.",
                    "label": 0
                },
                {
                    "sent": "Typical word processor used to seeing these square little red lines and my colleague and fellow machine learning connoisseur Mayron Sami always gets upset when he sees little red lines under his name and in a common office product.",
                    "label": 1
                },
                {
                    "sent": "When he hits the OK.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A button he gets that.",
                    "label": 0
                },
                {
                    "sent": "Which is probably not the most likely capability, but you know, given that you're working from a dictionary and his name wasn't in the dictionary, that's the best you can do.",
                    "label": 0
                },
                {
                    "sent": "But if you work from a larger corpus and said maybe you can do better.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so I wanted to compare get back to this idea of Agile programming, compare this corpus based approach to a more traditional programming based approach.",
                    "label": 0
                },
                {
                    "sent": "And so we went on the web and I search for spelling corrector's and I found this one.",
                    "label": 0
                },
                {
                    "sent": "And you know, so there's all this stuff in there under the case.",
                    "label": 0
                },
                {
                    "sent": "See, you say do something if X is if it's CIA is in there or Ch or LCS is if in or if it's C or CE.",
                    "label": 0
                },
                {
                    "sent": "Or see why it's dropped.",
                    "label": 0
                },
                {
                    "sent": "And let's see I see IRS EERSEY and quick.",
                    "label": 0
                },
                {
                    "sent": "Can you verify that they got every case right there?",
                    "label": 0
                },
                {
                    "sent": "Can anybody do that?",
                    "label": 0
                },
                {
                    "sent": "OK, well, you know, maybe we take you a little while to verify that every possible cases covered there, but then the next trick is I'll give you a couple of days to do that, and then I'll give you another day to say, well, just let's do a simple one more thing and just port this to Romanian.",
                    "label": 0
                },
                {
                    "sent": "That couldn't be too hard, right?",
                    "label": 0
                },
                {
                    "sent": "Just modify the code a little bit so it does remain instead of English.",
                    "label": 0
                },
                {
                    "sent": "How hard could that be?",
                    "label": 0
                },
                {
                    "sent": "And you can see that that's the fragility of this hand coded approach as opposed to the machine learning approach.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so again.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's the same old model.",
                    "label": 0
                },
                {
                    "sent": "You fall back to this probability probability of the spelling correction is depends on the probability that the correction C is a word, and the probability that it's impossible.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Typo for the original word.",
                    "label": 0
                },
                {
                    "sent": "Best corrections, one with the highest probability.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The probability of a word we get again by count.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just like we did before, probability of a typo.",
                    "label": 1
                },
                {
                    "sent": "You need some kind of a model to say given these two words.",
                    "label": 0
                },
                {
                    "sent": "How similar are they to each other?",
                    "label": 1
                },
                {
                    "sent": "And how probably could be a typo for another if you've been running a spelling correction service for a long time, you've got lots of examples of that.",
                    "label": 0
                },
                {
                    "sent": "You could have a really good model of that.",
                    "label": 0
                },
                {
                    "sent": "If you don't, you can just do something simple like count the edit distance between them and then.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I did.",
                    "label": 0
                },
                {
                    "sent": "And then here's the whole program.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit longer, but not too much.",
                    "label": 0
                },
                {
                    "sent": "Again, fits on one page and whoops.",
                    "label": 0
                },
                {
                    "sent": "I guess I got something like I forget the exact number, but something like 80% correct with this.",
                    "label": 0
                },
                {
                    "sent": "And if you wanted to do more, you probably want to take more context into account and do what is the probability of this word given that it appears before the next word so on.",
                    "label": 0
                },
                {
                    "sent": "OK, now let's just.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up a little bit from there and say can we do something that's more semantic oriented and this is one of the first experiments we did at the Google Labs.",
                    "label": 0
                },
                {
                    "sent": "Google Stats done by Simon Tong and the idea here is use all the information you have available on the web to suggest sets of things that are related to each other and so here I put in public kasoa.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matisse, an I get back Matisse Picasso, Van Gogh, Monet Picasso so it's concentrating on these Impressionist artist 1st and then it has other kinds of artists and it veers off a little bit.",
                    "label": 0
                },
                {
                    "sent": "No, Ansel Adams is in the bottom.",
                    "label": 0
                },
                {
                    "sent": "There's a slightly different medium that he uses and so on, but it looks like a pretty good clue.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "String.",
                    "label": 0
                },
                {
                    "sent": "If I give it Lions and Tigers and bears, I get back.",
                    "label": 0
                },
                {
                    "sent": "Tigers, Lions, elephants, monkeys, giraffes, dogs, cats, snakes and so on looks like it's doing pretty good.",
                    "label": 0
                },
                {
                    "sent": "There's a couple of things in italics there that aren't quite right.",
                    "label": 0
                },
                {
                    "sent": "It looks like so there's cotton and wooden musical and toddler and you might want to think about how did that sneak in there?",
                    "label": 0
                },
                {
                    "sent": "And we'll see the answer soon.",
                    "label": 0
                },
                {
                    "sent": "But like you guys do on that.",
                    "label": 0
                },
                {
                    "sent": "So those were all kind of.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lated animals what if I gave it to different kinds of an animal?",
                    "label": 0
                },
                {
                    "sent": "So what would it come up with then?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, of course that.",
                    "label": 0
                },
                {
                    "sent": "And then you can see that you know they're sorted from central to peripheral, and so it does pick out that man and LS and CP in RMR, the prototypical Unix commands and make node and who am I?",
                    "label": 0
                },
                {
                    "sent": "Or are more peripheral?",
                    "label": 0
                },
                {
                    "sent": "So it does seem to have some kind of understanding there.",
                    "label": 0
                },
                {
                    "sent": "So how would you do something like this?",
                    "label": 0
                },
                {
                    "sent": "Well, I'm not going to show you the whole code 'cause that doesn't fit on one page, but I'm going to show you some of the data sources.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first thing you can do is just go on the web and look for proximity and say look Lions and Tigers and bears curve close to each other.",
                    "label": 1
                },
                {
                    "sent": "Maybe they're related and that's pretty good clue, but then you'd also have to say, well, summon mostly in, but also occur in that.",
                    "label": 0
                },
                {
                    "sent": "Does that mean they're related?",
                    "label": 0
                },
                {
                    "sent": "So maybe it's not.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stronger clue.",
                    "label": 0
                },
                {
                    "sent": "But here is a case where that looks stronger where we have HTML structure in the.",
                    "label": 0
                },
                {
                    "sent": "In the case of these list elements, in case of links, and maybe that's a stronger clue that those are related.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is the example to the puzzle are of why did those weird things come in?",
                    "label": 0
                },
                {
                    "sent": "Because the web does reflect reality, and so it does talk about animals.",
                    "label": 0
                },
                {
                    "sent": "But the web also reflects an awful lot of Commerce, and you can't really buy Lions and Tigers and bears.",
                    "label": 1
                },
                {
                    "sent": "But you can buy stuffed animals and toddler animals and cotton plush toys and so on.",
                    "label": 0
                },
                {
                    "sent": "So those words get confused.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing you could do is look at your user logs and say, well, somebody was looking for Akita pics and then leopard pics soon afterwards.",
                    "label": 0
                },
                {
                    "sent": "Maybe that's an indication.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chen and then you can try to understand the structure of English and you can either do that with a full parser that understands everything about sentences, or you can do it with restricted approaches.",
                    "label": 0
                },
                {
                    "sent": "I think Marty Hearst at Berkeley was the first one to suggest using phrases that are highly indicative that are high precision but potentially low recall.",
                    "label": 0
                },
                {
                    "sent": "And so if you want to find what things are like Lions, you could search for the phrase such as Lions, and then anything that shows up there.",
                    "label": 1
                },
                {
                    "sent": "It's very likely.",
                    "label": 0
                },
                {
                    "sent": "That that's going to be in the same set as Lions.",
                    "label": 0
                },
                {
                    "sent": "Of course there is.",
                    "label": 0
                },
                {
                    "sent": "You know countless numbers of different ways that you could say Lions and Tigers or similar, and you're going to miss all the other ones with this.",
                    "label": 0
                },
                {
                    "sent": "But if the web is large enough and there's enough examples, you'll get what you need.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and then the final example for text they want to talk about is this statistical machine translation and this is a little bit harder.",
                    "label": 1
                },
                {
                    "sent": "Not only do I need a large corpus of English text if I'm trying to translate into English, but if I'm trying to translate from German, I also need a corpus of parallel text and when I was in my hotel in Berlin, I was able to do that.",
                    "label": 0
                },
                {
                    "sent": "They had a nice collection of parallel text.",
                    "label": 0
                },
                {
                    "sent": "It got a little brochure and on one side with the English and the other side.",
                    "label": 0
                },
                {
                    "sent": "But the German and now I can say that these are aligned with each other and if I've ever given.",
                    "label": 0
                },
                {
                    "sent": "Exactly this phrase in German, then I know that this is the translation in English, but what if I'm not given exactly that?",
                    "label": 0
                },
                {
                    "sent": "How can I use this information anyways?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, I've I start off knowing that this is the alignment and now I want to try to align word by word an.",
                    "label": 0
                },
                {
                    "sent": "One possibility is that these two words are lined up according to each other, and so I'd assign.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probability to that, but it also might be that there lined up that those two words are are lined up and assign a probably.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be there or could.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the way to the end.",
                    "label": 0
                },
                {
                    "sent": "Or it could be one word is aligned with two would have been vice versa.",
                    "label": 0
                },
                {
                    "sent": "So from one sentence I get a very broad probability distribution.",
                    "label": 0
                },
                {
                    "sent": "All these things are possible and then I just keep on adding him up over and over and over and notice that Gee, you know lots of times conston art occur in sentences that are aligned and constant luxury did not occur as often in the probabilities begin to converge.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then eventually you say, well, that's going to be the right alignment.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How well does it do here?",
                    "label": 0
                },
                {
                    "sent": "Some Arabic Tran.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Late to English comes out like this.",
                    "label": 0
                },
                {
                    "sent": "I've underlying the places where there's disfluencies, so you can't go more than a sentence or two without saying.",
                    "label": 0
                },
                {
                    "sent": "Here's an example of something that's not quite fluent English text, but it is good enough that you get the idea of what's going on and all the right who's doing what to who is.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Presented properly Chinese.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar kind of thing there, it's more like.",
                    "label": 0
                },
                {
                    "sent": "Two or so disfluencies per sentence rather than one, probably reflecting the fact that Chinese is more different from English there.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Checkers.",
                    "label": 0
                },
                {
                    "sent": "How do we go through the process?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, we start off we go one character at a time, get the first character, look up the probabilities for the alignments and he is the most likely you know it.",
                    "label": 0
                },
                {
                    "sent": "In this case I haven't folded case together so he and capital here consider different tokens.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go to the next one and we have a set here an now notice when we want to do the probability.",
                    "label": 0
                },
                {
                    "sent": "There's two probabilities we have to deal with.",
                    "label": 0
                },
                {
                    "sent": "One is the probability of the translation from Chinese into English, and that's represented by these lists here, and the other is the probability that we generate is a sentence of English, and that we test against a corpus of English, and in that case we we'd probably recognize that the top probability here he letter.",
                    "label": 0
                },
                {
                    "sent": "Is not very probable in English, but if you go down the list a little bit, his letter would be more probable, and so we'd be able to make that kind of correction there.",
                    "label": 0
                },
                {
                    "sent": "Of course, we don't have to look just one character at it.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time we can also combine them, and in fact we've seen this sequence before and we have recognized that his letter is right alignment in many cases.",
                    "label": 0
                },
                {
                    "sent": "For this more probable than he letter.",
                    "label": 0
                },
                {
                    "sent": "But we also notice that it's this also is a proper name and that that's more probable.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in fact, in this case we've actually seen 3 character sequence corresponding to this already, so it's more case of vlookup than pasting.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This together, but for the rest of it.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start pasting together and what we're essentially doing is trying to find it.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Path through this.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Create probability.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's the highest probability.",
                    "label": 0
                },
                {
                    "sent": "And this just chart here just echoes the first chart we had, saying that as we get more data, the scores keep going up and we haven't reached the point yet where the score is asymptotes, so there's still more to gain from the date.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now I want to switch a little and talk about image data.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's an example from Google Image Search where you type in name.",
                    "label": 0
                },
                {
                    "sent": "Here I've typed Mona Lisa and here's the results you get back.",
                    "label": 0
                },
                {
                    "sent": "Pretty good, but there's a variety of ones there and who knows really what the best one is.",
                    "label": 0
                },
                {
                    "sent": "And you know, it's it's no secret that Google, like most of the other providers of image search for the most part, until very recently have been throwing away the images and just looking at the surrounding words in filenames and things like that.",
                    "label": 0
                },
                {
                    "sent": "And for the most part, that works pretty well, but we can improve that by looking at the data in the images themselves, and in this case, what we're really looking for is saying well, there is a Canonical answer.",
                    "label": 0
                },
                {
                    "sent": "To this query and we want to be able to find that and on the web.",
                    "label": 0
                },
                {
                    "sent": "We're very good at Canonical answers, so if you type IBM, all the search engines will give you ibm.com.",
                    "label": 0
                },
                {
                    "sent": "That's an easy one because not because of the contents of what's on that page, but because of all the links that link to it.",
                    "label": 0
                },
                {
                    "sent": "And so there's good agreement that that's the right answer to that query on the web itself, with pictures, that's not the case.",
                    "label": 0
                },
                {
                    "sent": "There is one Canonical Mona Lisa image, or.",
                    "label": 0
                },
                {
                    "sent": "Artifact in the real world, but that's not represented by one picture on the web.",
                    "label": 0
                },
                {
                    "sent": "It's represented by lots of different pictures, and so we have to be able to figure out which ones of those represent the same object in the real world.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we do that by first looking at the images running sort of standard feature extractor and then conceptually looking at all pairs of images and lining up which features line up with each other.",
                    "label": 0
                },
                {
                    "sent": "And then we get a measure of similarity between each pair of images.",
                    "label": 0
                },
                {
                    "sent": "And of course you take shortcuts so you don't have to look at at all the possible end squared pairs, but just the ones that make sense to look.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now essentially we draw a graph of the connectedness between those of how close each images are to each other, an we're good at dealing with graphs, we know how to take a graph and figure out what the central ones are.",
                    "label": 0
                },
                {
                    "sent": "And in fact this case it comes out that this one here is the central point of this graph, and that is a good choice as a Canonical image.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a way of combining a little bit of image data from extracting these features from the images and then a lot of information from the web of what's connected to each other and what's import.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and here we blowing up just a portion of it and we can see how this one's in the middle and these ones are on the periphery.",
                    "label": 0
                },
                {
                    "sent": "And that's pretty important, because people are easily distracted when they're searching for images and you know their task was really defined.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "But if we show them a variety, they're going to get distracted and say, Oh well, you know, maybe this one or this one is different and more interesting, so I'll go off and look at that.",
                    "label": 0
                },
                {
                    "sent": "Or this one is showing some skin.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'll definitely click on that one.",
                    "label": 0
                },
                {
                    "sent": "We've got to have a way to combat that and say we don't want to show as a number one result, something that's more interesting or novel.",
                    "label": 0
                },
                {
                    "sent": "Maybe we want to show that somewhere in the results, but we want to show the Canonical 1 first, and this kind of technique allows us to do that.",
                    "label": 0
                },
                {
                    "sent": "Out.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and another similar example for Starbucks were able to get that logo.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right in the middle.",
                    "label": 0
                },
                {
                    "sent": "And then this is just an example of what the features are.",
                    "label": 0
                },
                {
                    "sent": "So at each point there's a vector for that point.",
                    "label": 0
                },
                {
                    "sent": "These so called sift features, and so it's abstract representation of.",
                    "label": 0
                },
                {
                    "sent": "What the image is, but it's works well across rotations and scaling and so on, so it's easy to compare between images.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and here is just one more example showing this is for the Lincoln Monument.",
                    "label": 0
                },
                {
                    "sent": "How they cluster into multiple different clusters, so there's necessarily in for Mona Lisa.",
                    "label": 0
                },
                {
                    "sent": "There was sort of 1 Canonical here.",
                    "label": 0
                },
                {
                    "sent": "It turns out that there's three Canonical there's inside during the day and inside during night.",
                    "label": 0
                },
                {
                    "sent": "An exterior shot that get clustered together.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and one more piece of work by Yagnik and Islamic at Google.",
                    "label": 0
                },
                {
                    "sent": "On learning people annotations.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we have an image and the annotation says George Bush Merkel and a barrel of herring, photographed by Herbert proper.",
                    "label": 0
                },
                {
                    "sent": "And so if you were searching for Merkel or Bush, this picture could potentially be retrieved.",
                    "label": 0
                },
                {
                    "sent": "But you wouldn't really know which one was Bush and which was Merkel and which was a hearing.",
                    "label": 0
                },
                {
                    "sent": "Anne, you wouldn't know that Herbert Roper isn't represented in the picture that he was, just the photographer.",
                    "label": 0
                },
                {
                    "sent": "'cause all those words aren't differentiated.",
                    "label": 0
                },
                {
                    "sent": "So what we'd like to be able to do is similar to what we do.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The translation here is these faces for him and they get this model for Alan.",
                    "label": 0
                },
                {
                    "sent": "All done here is these faces for him and notice that like with the Lincoln Monument, we don't have to map everything into a single model.",
                    "label": 0
                },
                {
                    "sent": "We can have multiple clusters and so you get the young Alan Alda from mash days with dark hair and then the older Allen.",
                    "label": 0
                },
                {
                    "sent": "Although with balding and glasses and so on, and that's OK for these types of data driven models.",
                    "label": 0
                },
                {
                    "sent": "But we don't have to fit everything into one.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So incan.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Version code is liability.",
                    "label": 0
                },
                {
                    "sent": "Here's this guy used to be really good programmer than doesn't happen to him.",
                    "label": 0
                },
                {
                    "sent": "He stopped coding, but he said measuring programming progress by lines of code is like measuring aircraft building progress by weight, right?",
                    "label": 0
                },
                {
                    "sent": "So you don't really want to know as you're building your airplane G. It's everything is going great.",
                    "label": 0
                },
                {
                    "sent": "It's getting heavier and heavier.",
                    "label": 0
                },
                {
                    "sent": "Rather, what you want to say is it would be nice if it was getting lighter and lighter then it could fly better, and it's the same thing with lines of codes.",
                    "label": 0
                },
                {
                    "sent": "Probably you know each line of code makes your project heavier and harder to change, so the fewer you have the better and this data driven approach is one way of getting to that ideal of having less code, more flexible, more heads up an.",
                    "label": 0
                },
                {
                    "sent": "Wait time for reference.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Yeah.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now this is the standard approach for for learning on those image databases.",
                    "label": 0
                },
                {
                    "sent": "I think that image is an important image.",
                    "label": 0
                },
                {
                    "sent": "Search is an important application, so they have been using the text to search the images.",
                    "label": 0
                },
                {
                    "sent": "Is it possible to do the opposite?",
                    "label": 0
                },
                {
                    "sent": "Use this all we learn on those graphs is out this this compilation.",
                    "label": 0
                },
                {
                    "sent": "That you do on those.",
                    "label": 0
                },
                {
                    "sent": "Those guys do this.",
                    "label": 0
                },
                {
                    "sent": "Create some knowledge that can be used to retrieve the text.",
                    "label": 0
                },
                {
                    "sent": "The concepts on the taxes.",
                    "label": 0
                },
                {
                    "sent": "Is this possible to explore on the opposite way information?",
                    "label": 0
                },
                {
                    "sent": "So you want to put in an image and get back out text?",
                    "label": 0
                },
                {
                    "sent": "No, I mean you the user is searching for the text for the concept for the web page on the text, but since you have the this beautiful concept map the cluster can you can you profit from.",
                    "label": 0
                },
                {
                    "sent": "This information to give him the right web page.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I mean certainly we try to do that.",
                    "label": 0
                },
                {
                    "sent": "You know, we if I'm not quite sure if you're asking what what types of queries and how the text versus images is work, but in all cases we want to integrate all the knowledge we have, right?",
                    "label": 0
                },
                {
                    "sent": "So if you if we know synonyms for words we want to be able to add those in.",
                    "label": 0
                },
                {
                    "sent": "If we know relationships between them, we should add that in.",
                    "label": 0
                },
                {
                    "sent": "So far we have kept the web search and the image search separate, although we think they probably should be.",
                    "label": 0
                },
                {
                    "sent": "Yeah, integrated together more and we'd like to be able to do that more in the future.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Hello, with Google Image there was kind of a community encouraging where people just could tag and there was another rewarded when people just tag it and said it was right or wrong.",
                    "label": 0
                },
                {
                    "sent": "I wonder if you found it really interesting and it really helped retrieval of images in Google right now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I think that is interesting and so you know I think tags are helpful for pictures.",
                    "label": 0
                },
                {
                    "sent": "You've seen that in Flickr.",
                    "label": 0
                },
                {
                    "sent": "And then Luis von Ahn had this game to do it, and then Google license that from CMU.",
                    "label": 0
                },
                {
                    "sent": "And now now we have a version of that where people are adding images, adding tags to images.",
                    "label": 0
                },
                {
                    "sent": "I think it's pretty useful resource, and it's amazing how willing people are to to play these kinds of games, and you can get a lot of data quickly.",
                    "label": 0
                },
                {
                    "sent": "You know we don't have definitive results yet.",
                    "label": 0
                },
                {
                    "sent": "It still kind of in the research stage to say how far are we going to get.",
                    "label": 0
                },
                {
                    "sent": "I think overall that it can help kind of bootstrap where we are, as can image searches and clicks.",
                    "label": 0
                },
                {
                    "sent": "You know, I pointed out that the clicks are a little bit noisy.",
                    "label": 0
                },
                {
                    "sent": "People get distracted and they click on the wrong thing, but still, that is another source that is pretty useful.",
                    "label": 0
                },
                {
                    "sent": "But once you get past the bootstrap stage, I think there's more information than the images themselves, and particularly in the in the videos, and I think we'll get more out of that overtime.",
                    "label": 0
                },
                {
                    "sent": "But it's but it's good to have it right at the beginning, 'cause otherwise you're lossed.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I have to preface this by saying I work for Google, so Luckily I'm not in this situation, but I mean your argument is that you know when you have a lot of data you win, or you you can do all these excellent things with statistical methods, but for a lot of problems you might not have the data or certainly not the kind of many, many orders of magnitude of data that you know we've seen here works right?",
                    "label": 0
                },
                {
                    "sent": "What do you do then?",
                    "label": 0
                },
                {
                    "sent": "Should you focus on data collection first?",
                    "label": 0
                },
                {
                    "sent": "Should you bootstrap?",
                    "label": 0
                },
                {
                    "sent": "Should you write code?",
                    "label": 0
                },
                {
                    "sent": "I guess it depends on the problem.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "I mean part of what I was saying is that it's not only the Googles that can do this, right?",
                    "label": 0
                },
                {
                    "sent": "So I got some good results with only on the order of a billion words.",
                    "label": 0
                },
                {
                    "sent": "That's not very much.",
                    "label": 0
                },
                {
                    "sent": "Everybody in this room can go out and by the end of the day, you could have collected a billion words of text and you can store it on your laptop.",
                    "label": 0
                },
                {
                    "sent": "You don't need a data center or large capability to do that.",
                    "label": 0
                },
                {
                    "sent": "And Google also publishes the Ngram counts up to 5 grams, 4 trillion words of text.",
                    "label": 0
                },
                {
                    "sent": "So you can buy that just for the cost of the of the DVD's.",
                    "label": 0
                },
                {
                    "sent": "So you can go pretty far in terms of language data, other kinds of data.",
                    "label": 0
                },
                {
                    "sent": "I guess that depends on the application, right?",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "You know you gotta look on individual case.",
                    "label": 0
                },
                {
                    "sent": "If you have what you need then then go ahead and use it.",
                    "label": 0
                },
                {
                    "sent": "If you don't, you gotta try something else.",
                    "label": 0
                },
                {
                    "sent": "That we have to look at those one by one.",
                    "label": 0
                },
                {
                    "sent": "Chris and on top of that head of any projects where the data driven approach is a failure.",
                    "label": 0
                },
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "Where the data driven approach was a failure?",
                    "label": 0
                },
                {
                    "sent": "Well, you know you know.",
                    "label": 0
                },
                {
                    "sent": "I mean, we still don't have complete AI.",
                    "label": 0
                },
                {
                    "sent": "You know we'd like to be able to just go and ask any question, and the computer tells us the final answer and we don't have that because I think that there's too many steps in between understanding all these links in the chain, and so the steps that do work seem to be where it's more focused where it's a simpler task, an where things are closer to being retrieval rather than inference, and I think those are good properties.",
                    "label": 0
                },
                {
                    "sent": "To look for.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it's a good example of that.",
                    "label": 0
                },
                {
                    "sent": "Is the current financial meltdown, which seems to be caused by the fact that people build models based on data and then these models make prediction based on data they'd never seen before, so they completely didn't predict.",
                    "label": 0
                },
                {
                    "sent": "So how close are we to building both models that can?",
                    "label": 0
                },
                {
                    "sent": "Tell you the correct answer, but also tell you when they have no idea what the right answer is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so that's a good idea, right?",
                    "label": 0
                },
                {
                    "sent": "So you what you want?",
                    "label": 0
                },
                {
                    "sent": "Not only do you want the result, but you want some sort of a confidence score on that.",
                    "label": 0
                },
                {
                    "sent": "And then the question is when does the confidence score?",
                    "label": 0
                },
                {
                    "sent": "When is that misleading and you know I mentioned if it's closer to retrieval, that's good, and I think it's this idea of you.",
                    "label": 0
                },
                {
                    "sent": "Interpolating or extrapolating, and so if it's if you seen something that's very close to what you've seen before, and there's lots of neighbors around and those neighbors all agree, then maybe you feel pretty confident.",
                    "label": 0
                },
                {
                    "sent": "If it's something that's out on the edge or beyond what you've seen and you're trying to extrapolate, then you should feel less confidence.",
                    "label": 0
                },
                {
                    "sent": "And then I think you should also be monitoring the data and how it changes overtime, and you know, so I don't know.",
                    "label": 0
                },
                {
                    "sent": "I haven't looked at the.",
                    "label": 0
                },
                {
                    "sent": "At the current financial situation, but.",
                    "label": 0
                },
                {
                    "sent": "So it seems like there were lots of people who were warning, you know, something unusual is happening and other people just said well, I don't care.",
                    "label": 0
                },
                {
                    "sent": "I'm going to ignore that morning and go out of business as usual.",
                    "label": 0
                },
                {
                    "sent": "So it looks like there were alerts there, and I think you know I started off by talking about this agile programming approach and part of Agile is being test driven, and I think that's also true for any data driven approach that you should be test driven.",
                    "label": 0
                },
                {
                    "sent": "You should write these tests first an.",
                    "label": 0
                },
                {
                    "sent": "But one of the difficulties is figuring out.",
                    "label": 0
                },
                {
                    "sent": "An approach that allows us to do those kinds of tests 'cause you know you look at all the test suites and they all have things like assert true or assert equal and they don't have things like assert that the standard deviation of this result is within one standard deviation of what it was last week.",
                    "label": 0
                },
                {
                    "sent": "And I think we want testing regimes that are more like that.",
                    "label": 0
                },
                {
                    "sent": "Let's say not.",
                    "label": 0
                },
                {
                    "sent": "Is this true or false?",
                    "label": 0
                },
                {
                    "sent": "But here's the probability.",
                    "label": 0
                },
                {
                    "sent": "Here's the bounds.",
                    "label": 0
                },
                {
                    "sent": "Ann, and you know, alarms that go off that say things are different.",
                    "label": 0
                },
                {
                    "sent": "Now things are changing more quickly than they used to be changing.",
                    "label": 0
                },
                {
                    "sent": "I don't know if that's going to screw things up or not, but somebody was smart, should focus their attention here.",
                    "label": 0
                },
                {
                    "sent": "Should close down.",
                    "label": 0
                }
            ]
        }
    }
}