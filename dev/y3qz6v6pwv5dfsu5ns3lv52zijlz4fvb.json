{
    "id": "y3qz6v6pwv5dfsu5ns3lv52zijlz4fvb",
    "title": "A Compressed, Inference-enabled Encoding Scheme for RDF Stream Processing",
    "info": {
        "author": [
            "J\u00e9r\u00e9my Lhez, Laboratoire d'Informatique Gaspard-Monge (LIGM)"
        ],
        "published": "July 10, 2017",
        "recorded": "May 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_lhez_RDF_stream_processing/",
    "segmentation": [
        [
            "Hello everyone and thank you for attending this presentation.",
            "So as mentioned my name is Jeremy lies.",
            "I am a PhD student at the University of Paris Manner Valley in France and today we present your compressed inference enabled schema for stream processing.",
            "It is a work joint with Bad Robella.",
            "Best Angie and an arena who are also PhD student in the same University and Olivia Curae which is our PhD director.",
            "For the presentation I will follow this out."
        ],
        [
            "Line I will first give the context about our research project and the.",
            "Is the main.",
            "Problems and the main issues we address.",
            "And then I will develop about the algorithm represent divided into steps.",
            "The first step called light Matt, which will be for the compression part mostly, and then another part called Podbean which will be for the reasoning for each part.",
            "I will try to be as precise as possible and give along examples and then I will finish with a conclusion.",
            "So to start with, the can't."
        ],
        [
            "Next I will talk a bit about stream processing.",
            "You may have heard a lot about this on the previous date, so basically we have data streams coming from a lot of different sources.",
            "Nowadays we can have data streams coming from physical sources with sensors deployed on several several sites.",
            "For example, here we have seismic sensors for measuring seismic activities.",
            "We can have sensors deployed on over kind of physical networks.",
            "We can have streams coming from informatic sources, for example coming from social networks or data stored online, and we can have over kind of string more important generated by different means.",
            "For example, financial streams and so on.",
            "So we have a lot of streams, and each of the streams need to be processed in a specific way to be used the best way possible.",
            "In our use case, we are working on the."
        ],
        [
            "This project so it is a smart water network management system, so our use case is.",
            "About what their network so we have.",
            "Basically sensors on this network.",
            "Covering data and we want to identify anomalies present in this data.",
            "And once was anomalies has been identified to find the most probable sources of anomalies using external events.",
            "This is the main use case of our project.",
            "Our main partner for this project is a stressor.",
            "Previously code only authorize a it is a company well known in the domain of water management with more than 650 partners or around Europe and more 173 billion US dollars invested in.",
            "Research and development already.",
            "And the West project is French project, so you can access this URL For more information or if you want to."
        ],
        [
            "To contact the participants.",
            "So, are you scared?",
            "I am, as I mentioned, is water management.",
            "It is a very sensible issue because nowadays not all the water bill.",
            "Not all the water supplied to the network is directly billed to the client.",
            "There are some losses which we can call non revenue water with non revenue.",
            "Water represents around 35% of the water distributed to the network.",
            "49 billion of cubic meters are lost.",
            "Each year, which represent 14 billion dollars.",
            "It is about twice the annual domestic consumption of United States of America.",
            "So it is a big problem and very."
        ],
        [
            "Is not only financial and economical steak, there is also an environmental steak because 30 two millions of cubic meter are lost physically.",
            "So it's not you two errors or anomalies in the in the measures.",
            "It's due to physical leaks and 90% of physics are invisible.",
            "So it is really important to detect when there are potential leaks that are important and when it's only errors coming from the sensor or from.",
            "Outside events"
        ],
        [
            "So the main aspects of the project ways is to have real time processing platform managing RDF streamer with Sparkle queries to in order to identify the anomalies present in the measures.",
            "And we want inference and reasoning capabilities.",
            "So for the detection of anomalies and later the sorting, an identification of potential sources.",
            "Our objectives.",
            "Was to have a robust returning stream processing angina, modular, flexible, and distributed because we wanted our system to be applied on over application over use case, we thought about financial streams, climate and energy data, power consumption.",
            "We thought about a lot of cases."
        ],
        [
            "I make if I show rapidly the architecture of our project, here is how we talking.",
            "So we have data coming from the sensor.",
            "Input data are first cleaned and potentially sampled using native filters.",
            "Am so to detect the main anomalies in the sensor.",
            "So for example what I mean by that is if we have temperature of water of minus 50 degrees and we can obviously know the error is coming from the sensor.",
            "Not from an outside event.",
            "Then there is a definition, so passing of the data into RDF in your comment format compression after that for better performance and then each stream is managed separately according to its type, so it can be for example temperature.",
            "It can be pressure growing or things like that.",
            "So each stream has different filters applied on it to identify anomalies.",
            "So for example using the average of measure on a time window using.",
            "The offsets of values that can that cannot be passed etc etc.",
            "We can fetch data for for the filters from a static knowledge bed because we want our streams to be the most compact possible, so we will have all the other information about the network stored in a static triplestore.",
            "Once we have identified.",
            "The anomalies as a result, we have the visualization that can be made to show the final operator what anomalies were detected and with anomalies can be re sent to the programmer for applying a new filter, this time to identify the origin of the anomalies using this time, external data sources and once more once we have the result be passed to the visualization.",
            "For what I'm presenting today, the algorithm is separated into parts.",
            "As I mentioned we have light match will.",
            "Which will."
        ],
        [
            "In charge of the compression, so it will be located at this step of the program with the encoding of the A box.",
            "The encoding of the TEE box can be made offline, potentially.",
            "And we have had been, which is in charge of the reasoning which will be for everything, for the reasoning for the different filters.",
            "We chose to."
        ],
        [
            "To develop this algorithm, because there are some big issues in stream processing with high loads of data concerning the performance, is there are several system existing for compressions, but to our best knowledge there are no distributed compression systems for RDF, and there is also the problem of decompression if you have to make some reasoning.",
            "You always have to decompress the data so it is a cost of time and there is a further reasoning and we influences several process depending of the.",
            "The use case there is a materialization an query writing so for better reasoning and the materialization creates the trippers missing 4.",
            "For a specific queries for specifically, but this can create huge amounts of data so it can be problematic in some knowledge base, because the size will rapidly explode and there is query writing which consists in rewriting the query instead of adding new triples.",
            "But this time there is some execution time problem, so there is not very efficient solution for heavy data roads and there can be some lack of performances."
        ],
        [
            "Which is why we chose to develop."
        ],
        [
            "Our algorithm I will know talk about the first part light mat, which is an encoding for the concept and properties in some triples.",
            "It is a compressed form keeping the.",
            "So your key of concepts and properties."
        ],
        [
            "The principle is to use binary structure, conserving the Yaqui of concept or the hierarchy of properties.",
            "I will talk about concept specifically for the example, so each binary identifier is prefixed by the identifier of its parents.",
            "So in all the R key will always prefix, which will be done to fire of the parent and this way when we convert the binary structure.",
            "As an identifier as an integer and identifier, we have values that will allow to keep track of VCR key.",
            "We support RDF.",
            "So for light metal for the moment, but we want to go a bit further I will come back on that later.",
            "The main advantages of light Matt is that with the compression maintaining the yard key we have no need for the ontology at query runtime, so we have no need to fetch more information in the static basin.",
            "And we have better execution performances because we don't need to decompress the data.",
            "We can query directly uncompressed data.",
            "And also like math allows an easier way of rewriting queries, and it is a bit abstract I bet, so I will jump rapidly on."
        ],
        [
            "Example, if we take this extract from the SSN ontology, so semantic sensor network, it is an ontology of the double V3C4 representing sensors.",
            "We used it for our project an if we take this example of triples, let's say we have the triple saying that the sensor QB E 04 is of type sensing device.",
            "If this triple is explicit, will have over triple implicit saying that for example, it is also a sensor and the physical object.",
            "So we want to materialize this and also to materials for one.",
            "For example, if we have a sense of it is something that is a physical object, it can be potentially used and so on.",
            "And sensing device and we want to materialize this with light Matt.",
            "So using VCR key of concept for example.",
            "So I."
        ],
        [
            "Look, they are key on the left.",
            "We've each to each dependency.",
            "I added engine and social object just to make it a bit more complete.",
            "And here is how we encode.",
            "We have first all fingers so we have all thing an all nothing is the root concept.",
            "So we need just one bit to encode all thing because we have all seen and or nothing.",
            "So just two concepts within one minute.",
            "So all things will be just encoded on one.",
            "This concept is encoded.",
            "We move on to the next."
        ],
        [
            "So physical object and social objects are at the same level, so we use the prefix one of finger and we encode them on their own with their own indentify also.",
            "Basically we will have a physical object, social objects and the concept of 1 level.",
            "I also will need free values are free values are encoded on 2 bits, so we have zero just for the concept of 1 level higher will have 01 for physical object and 10 for social object.",
            "Once it's done, we move on."
        ],
        [
            "Next thing, same result.",
            "We use the prefix from the previous identifier.",
            "We have sensor engine and the Super concept, so we need once more to bits we encode.",
            "We move on."
        ],
        [
            "Once more, the same identifier as prefix.",
            "We have this time only sensing device and the Super concepts, so just one bit and that at this step we are done.",
            "We have encoded every concept in our key so we can normalize didn't if I order so they can have the same length and con."
        ],
        [
            "Got it.",
            "Other integer identifier.",
            "So with this we have still the jarki of concept that is kept in the compressed form and we can identify rapidly.",
            "The subclasses are specific to a concept in specific interval.",
            "For example, if we want all the physical objects, all we have to do is that we know that physical object is included on 101.",
            "We can make a shift because we know on what length it's encoded.",
            "We add just one, so we have 110 which is social object.",
            "If we make the normalization, we have 40 and 48 and this we know that all the sub concepts of physical object will be between 40 and 48 vessels."
        ],
        [
            "The easy way to rewrite query because we just have to use identifiers and make a filter on the value.",
            "So it is very easy for query writing.",
            "The usage of lightmaps in ways it is used for the encoding of streams and as data into static knowledge base and we use it also into Pasadena which I will."
        ],
        [
            "Present right now, so podbean is the part for the reasoning combining materialization and query rewriting using the compressed form from."
        ],
        [
            "So the motivation behind Podbean was first, as I mentioned, two query over compressed data and also to use some repetetive information that are always in the streams.",
            "Because when we user streams we have mostly continuous queries or queries that are executed all the time and in the streams we have some repetitive informations.",
            "What I mean is, for example in our use case we have data coming from some sensors so.",
            "Our stream will be always containing identifier of the sensor, the.",
            "The timestamp of the measure and the value measured, so all the values are objects in our three person.",
            "So subjects and predicates of the triples will mostly never change, so we wanted to use this repetetive information for the compression.",
            "So the principle of padman is as I mentioned, to combine the materialization and the query writing.",
            "And for that, we decomposed that ripples into two structures called the pattern and the binding, hence the name of the pattern being.",
            "Compressed form using vidente fires from light.",
            "Matt and the bindings holding the object of the triple.",
            "So the part that will change."
        ],
        [
            "This looks like exactly so the pattern.",
            "Use the predicates from light mats and preserve the triple interlinking.",
            "So in this example sixteen 2137 and 29 R identifiers encoding predicates.",
            "Each identifier supported by two points.",
            "Either at the same level, which means they share the same subject.",
            "So 1621 and 37 have the same subject and 29 is in between parentheses because it has the subject which is the object of 37.",
            "So the interlinking of the properties is kept in this form for the binding.",
            "We just store the object in the order of the patterns, so we have 250, which is the object of the property 16 with which is.",
            "Object of the property 29.",
            "A blog for property 37 because we are in presence of a blank node and pass card which is the object of the property 29 so the advantages of this form is that we have a pattern repetitive for the streams because we just use one pattern for all the streams.",
            "Because it's the same structure of properties that subject it will never change and only the binding.",
            "Come from the stream so it is a very compressed right and there is no need for decompression because we have like Matt and we can use this form for materialization.",
            "I will not give."
        ],
        [
            "An example rapidly.",
            "Let's suppose we have this trimmer in blue so we have data coming from the sensor Q 250 at this date.",
            "So there would be normally and timestamp behind with hours, minutes and seconds and it is a measure of pressure with the value 4.5.",
            "Using the dictionary from light math here with the identifiers attributed at each predicate, we can build this pattern an this binding.",
            "We thought the pattern in ascending order for better manipulation for the materialization.",
            "I will come back on that later."
        ],
        [
            "And we have this query to apply on the stream in red, so we select the identifier and the value from the stream so we can build once more the pattern and the binding using the dictionary.",
            "Here we can see that there is a small problem.",
            "It is that in the stream where is not the location of the sensor, because we want them to be very compact.",
            "So we have to materialize the location of the sensor."
        ],
        [
            "But we will have to 1st detect the property that need to be materialized so we can make the intersection of the patterns of the stream and the pattern of the query.",
            "So we have the common form and subtract this common form to the pattern of the query.",
            "So we will have only the predicate which is in the query and not in the streamer.",
            "Here we see the importance of the ascending order.",
            "It is for a better comparison.",
            "Once we have this property we can use query on the static.",
            "Knowledge Base which holds the structure of the network to get on which platform the sensor is diploid and."
        ],
        [
            "After that we have the pattern in the beginning to be materialized.",
            "We can enrich the stream.",
            "Three person.",
            "Verify the compatibility so the patterns will be the pattern of the query will be included in the pattern of the streams and we have to check if the the binding of the query is included in the binding of the stream.",
            "Here we have platform one so it is true we can just give the result.",
            "So this is how the metalization work for podbean.",
            "So."
        ],
        [
            "In conclusion, I have presented my research project which is a waste project.",
            "It is written in string processing, angina applied on the use case of drinkable water network management and I have presented the algorithm we have developed for the returning on this project, which is composed of two parts light math, which is a compression system with binary identifiers representing the ontology semantics and podbean, which is a reasoning scheme combining.",
            "Creating an metalization over compressed data for the."
        ],
        [
            "Feature works we plan for that matter to support our DFS press press.",
            "We've all same as and transitive and inverse properties.",
            "And for Podbean we want to go further.",
            "We are working currently on the aggregate, so min Max sum, average counts and property diverted.",
            "We want to support more operators with optional and filter.",
            "Thank you for your attention.",
            "If you have questions now, I will do my best to answer them."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone and thank you for attending this presentation.",
                    "label": 0
                },
                {
                    "sent": "So as mentioned my name is Jeremy lies.",
                    "label": 0
                },
                {
                    "sent": "I am a PhD student at the University of Paris Manner Valley in France and today we present your compressed inference enabled schema for stream processing.",
                    "label": 0
                },
                {
                    "sent": "It is a work joint with Bad Robella.",
                    "label": 0
                },
                {
                    "sent": "Best Angie and an arena who are also PhD student in the same University and Olivia Curae which is our PhD director.",
                    "label": 0
                },
                {
                    "sent": "For the presentation I will follow this out.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Line I will first give the context about our research project and the.",
                    "label": 0
                },
                {
                    "sent": "Is the main.",
                    "label": 0
                },
                {
                    "sent": "Problems and the main issues we address.",
                    "label": 0
                },
                {
                    "sent": "And then I will develop about the algorithm represent divided into steps.",
                    "label": 0
                },
                {
                    "sent": "The first step called light Matt, which will be for the compression part mostly, and then another part called Podbean which will be for the reasoning for each part.",
                    "label": 0
                },
                {
                    "sent": "I will try to be as precise as possible and give along examples and then I will finish with a conclusion.",
                    "label": 0
                },
                {
                    "sent": "So to start with, the can't.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next I will talk a bit about stream processing.",
                    "label": 0
                },
                {
                    "sent": "You may have heard a lot about this on the previous date, so basically we have data streams coming from a lot of different sources.",
                    "label": 0
                },
                {
                    "sent": "Nowadays we can have data streams coming from physical sources with sensors deployed on several several sites.",
                    "label": 1
                },
                {
                    "sent": "For example, here we have seismic sensors for measuring seismic activities.",
                    "label": 0
                },
                {
                    "sent": "We can have sensors deployed on over kind of physical networks.",
                    "label": 0
                },
                {
                    "sent": "We can have streams coming from informatic sources, for example coming from social networks or data stored online, and we can have over kind of string more important generated by different means.",
                    "label": 0
                },
                {
                    "sent": "For example, financial streams and so on.",
                    "label": 0
                },
                {
                    "sent": "So we have a lot of streams, and each of the streams need to be processed in a specific way to be used the best way possible.",
                    "label": 0
                },
                {
                    "sent": "In our use case, we are working on the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This project so it is a smart water network management system, so our use case is.",
                    "label": 1
                },
                {
                    "sent": "About what their network so we have.",
                    "label": 0
                },
                {
                    "sent": "Basically sensors on this network.",
                    "label": 0
                },
                {
                    "sent": "Covering data and we want to identify anomalies present in this data.",
                    "label": 0
                },
                {
                    "sent": "And once was anomalies has been identified to find the most probable sources of anomalies using external events.",
                    "label": 0
                },
                {
                    "sent": "This is the main use case of our project.",
                    "label": 1
                },
                {
                    "sent": "Our main partner for this project is a stressor.",
                    "label": 0
                },
                {
                    "sent": "Previously code only authorize a it is a company well known in the domain of water management with more than 650 partners or around Europe and more 173 billion US dollars invested in.",
                    "label": 0
                },
                {
                    "sent": "Research and development already.",
                    "label": 0
                },
                {
                    "sent": "And the West project is French project, so you can access this URL For more information or if you want to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To contact the participants.",
                    "label": 0
                },
                {
                    "sent": "So, are you scared?",
                    "label": 0
                },
                {
                    "sent": "I am, as I mentioned, is water management.",
                    "label": 1
                },
                {
                    "sent": "It is a very sensible issue because nowadays not all the water bill.",
                    "label": 1
                },
                {
                    "sent": "Not all the water supplied to the network is directly billed to the client.",
                    "label": 0
                },
                {
                    "sent": "There are some losses which we can call non revenue water with non revenue.",
                    "label": 0
                },
                {
                    "sent": "Water represents around 35% of the water distributed to the network.",
                    "label": 0
                },
                {
                    "sent": "49 billion of cubic meters are lost.",
                    "label": 0
                },
                {
                    "sent": "Each year, which represent 14 billion dollars.",
                    "label": 0
                },
                {
                    "sent": "It is about twice the annual domestic consumption of United States of America.",
                    "label": 0
                },
                {
                    "sent": "So it is a big problem and very.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is not only financial and economical steak, there is also an environmental steak because 30 two millions of cubic meter are lost physically.",
                    "label": 0
                },
                {
                    "sent": "So it's not you two errors or anomalies in the in the measures.",
                    "label": 0
                },
                {
                    "sent": "It's due to physical leaks and 90% of physics are invisible.",
                    "label": 1
                },
                {
                    "sent": "So it is really important to detect when there are potential leaks that are important and when it's only errors coming from the sensor or from.",
                    "label": 0
                },
                {
                    "sent": "Outside events",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main aspects of the project ways is to have real time processing platform managing RDF streamer with Sparkle queries to in order to identify the anomalies present in the measures.",
                    "label": 0
                },
                {
                    "sent": "And we want inference and reasoning capabilities.",
                    "label": 0
                },
                {
                    "sent": "So for the detection of anomalies and later the sorting, an identification of potential sources.",
                    "label": 0
                },
                {
                    "sent": "Our objectives.",
                    "label": 0
                },
                {
                    "sent": "Was to have a robust returning stream processing angina, modular, flexible, and distributed because we wanted our system to be applied on over application over use case, we thought about financial streams, climate and energy data, power consumption.",
                    "label": 0
                },
                {
                    "sent": "We thought about a lot of cases.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I make if I show rapidly the architecture of our project, here is how we talking.",
                    "label": 0
                },
                {
                    "sent": "So we have data coming from the sensor.",
                    "label": 0
                },
                {
                    "sent": "Input data are first cleaned and potentially sampled using native filters.",
                    "label": 0
                },
                {
                    "sent": "Am so to detect the main anomalies in the sensor.",
                    "label": 0
                },
                {
                    "sent": "So for example what I mean by that is if we have temperature of water of minus 50 degrees and we can obviously know the error is coming from the sensor.",
                    "label": 0
                },
                {
                    "sent": "Not from an outside event.",
                    "label": 0
                },
                {
                    "sent": "Then there is a definition, so passing of the data into RDF in your comment format compression after that for better performance and then each stream is managed separately according to its type, so it can be for example temperature.",
                    "label": 0
                },
                {
                    "sent": "It can be pressure growing or things like that.",
                    "label": 0
                },
                {
                    "sent": "So each stream has different filters applied on it to identify anomalies.",
                    "label": 0
                },
                {
                    "sent": "So for example using the average of measure on a time window using.",
                    "label": 0
                },
                {
                    "sent": "The offsets of values that can that cannot be passed etc etc.",
                    "label": 0
                },
                {
                    "sent": "We can fetch data for for the filters from a static knowledge bed because we want our streams to be the most compact possible, so we will have all the other information about the network stored in a static triplestore.",
                    "label": 0
                },
                {
                    "sent": "Once we have identified.",
                    "label": 0
                },
                {
                    "sent": "The anomalies as a result, we have the visualization that can be made to show the final operator what anomalies were detected and with anomalies can be re sent to the programmer for applying a new filter, this time to identify the origin of the anomalies using this time, external data sources and once more once we have the result be passed to the visualization.",
                    "label": 0
                },
                {
                    "sent": "For what I'm presenting today, the algorithm is separated into parts.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned we have light match will.",
                    "label": 0
                },
                {
                    "sent": "Which will.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In charge of the compression, so it will be located at this step of the program with the encoding of the A box.",
                    "label": 0
                },
                {
                    "sent": "The encoding of the TEE box can be made offline, potentially.",
                    "label": 0
                },
                {
                    "sent": "And we have had been, which is in charge of the reasoning which will be for everything, for the reasoning for the different filters.",
                    "label": 0
                },
                {
                    "sent": "We chose to.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To develop this algorithm, because there are some big issues in stream processing with high loads of data concerning the performance, is there are several system existing for compressions, but to our best knowledge there are no distributed compression systems for RDF, and there is also the problem of decompression if you have to make some reasoning.",
                    "label": 0
                },
                {
                    "sent": "You always have to decompress the data so it is a cost of time and there is a further reasoning and we influences several process depending of the.",
                    "label": 0
                },
                {
                    "sent": "The use case there is a materialization an query writing so for better reasoning and the materialization creates the trippers missing 4.",
                    "label": 0
                },
                {
                    "sent": "For a specific queries for specifically, but this can create huge amounts of data so it can be problematic in some knowledge base, because the size will rapidly explode and there is query writing which consists in rewriting the query instead of adding new triples.",
                    "label": 1
                },
                {
                    "sent": "But this time there is some execution time problem, so there is not very efficient solution for heavy data roads and there can be some lack of performances.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is why we chose to develop.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our algorithm I will know talk about the first part light mat, which is an encoding for the concept and properties in some triples.",
                    "label": 0
                },
                {
                    "sent": "It is a compressed form keeping the.",
                    "label": 1
                },
                {
                    "sent": "So your key of concepts and properties.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The principle is to use binary structure, conserving the Yaqui of concept or the hierarchy of properties.",
                    "label": 1
                },
                {
                    "sent": "I will talk about concept specifically for the example, so each binary identifier is prefixed by the identifier of its parents.",
                    "label": 1
                },
                {
                    "sent": "So in all the R key will always prefix, which will be done to fire of the parent and this way when we convert the binary structure.",
                    "label": 0
                },
                {
                    "sent": "As an identifier as an integer and identifier, we have values that will allow to keep track of VCR key.",
                    "label": 0
                },
                {
                    "sent": "We support RDF.",
                    "label": 0
                },
                {
                    "sent": "So for light metal for the moment, but we want to go a bit further I will come back on that later.",
                    "label": 0
                },
                {
                    "sent": "The main advantages of light Matt is that with the compression maintaining the yard key we have no need for the ontology at query runtime, so we have no need to fetch more information in the static basin.",
                    "label": 1
                },
                {
                    "sent": "And we have better execution performances because we don't need to decompress the data.",
                    "label": 0
                },
                {
                    "sent": "We can query directly uncompressed data.",
                    "label": 0
                },
                {
                    "sent": "And also like math allows an easier way of rewriting queries, and it is a bit abstract I bet, so I will jump rapidly on.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, if we take this extract from the SSN ontology, so semantic sensor network, it is an ontology of the double V3C4 representing sensors.",
                    "label": 0
                },
                {
                    "sent": "We used it for our project an if we take this example of triples, let's say we have the triple saying that the sensor QB E 04 is of type sensing device.",
                    "label": 0
                },
                {
                    "sent": "If this triple is explicit, will have over triple implicit saying that for example, it is also a sensor and the physical object.",
                    "label": 0
                },
                {
                    "sent": "So we want to materialize this and also to materials for one.",
                    "label": 0
                },
                {
                    "sent": "For example, if we have a sense of it is something that is a physical object, it can be potentially used and so on.",
                    "label": 0
                },
                {
                    "sent": "And sensing device and we want to materialize this with light Matt.",
                    "label": 0
                },
                {
                    "sent": "So using VCR key of concept for example.",
                    "label": 0
                },
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look, they are key on the left.",
                    "label": 0
                },
                {
                    "sent": "We've each to each dependency.",
                    "label": 0
                },
                {
                    "sent": "I added engine and social object just to make it a bit more complete.",
                    "label": 0
                },
                {
                    "sent": "And here is how we encode.",
                    "label": 0
                },
                {
                    "sent": "We have first all fingers so we have all thing an all nothing is the root concept.",
                    "label": 0
                },
                {
                    "sent": "So we need just one bit to encode all thing because we have all seen and or nothing.",
                    "label": 0
                },
                {
                    "sent": "So just two concepts within one minute.",
                    "label": 0
                },
                {
                    "sent": "So all things will be just encoded on one.",
                    "label": 0
                },
                {
                    "sent": "This concept is encoded.",
                    "label": 0
                },
                {
                    "sent": "We move on to the next.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So physical object and social objects are at the same level, so we use the prefix one of finger and we encode them on their own with their own indentify also.",
                    "label": 0
                },
                {
                    "sent": "Basically we will have a physical object, social objects and the concept of 1 level.",
                    "label": 0
                },
                {
                    "sent": "I also will need free values are free values are encoded on 2 bits, so we have zero just for the concept of 1 level higher will have 01 for physical object and 10 for social object.",
                    "label": 0
                },
                {
                    "sent": "Once it's done, we move on.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next thing, same result.",
                    "label": 0
                },
                {
                    "sent": "We use the prefix from the previous identifier.",
                    "label": 0
                },
                {
                    "sent": "We have sensor engine and the Super concept, so we need once more to bits we encode.",
                    "label": 0
                },
                {
                    "sent": "We move on.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once more, the same identifier as prefix.",
                    "label": 0
                },
                {
                    "sent": "We have this time only sensing device and the Super concepts, so just one bit and that at this step we are done.",
                    "label": 0
                },
                {
                    "sent": "We have encoded every concept in our key so we can normalize didn't if I order so they can have the same length and con.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Got it.",
                    "label": 0
                },
                {
                    "sent": "Other integer identifier.",
                    "label": 0
                },
                {
                    "sent": "So with this we have still the jarki of concept that is kept in the compressed form and we can identify rapidly.",
                    "label": 0
                },
                {
                    "sent": "The subclasses are specific to a concept in specific interval.",
                    "label": 1
                },
                {
                    "sent": "For example, if we want all the physical objects, all we have to do is that we know that physical object is included on 101.",
                    "label": 0
                },
                {
                    "sent": "We can make a shift because we know on what length it's encoded.",
                    "label": 0
                },
                {
                    "sent": "We add just one, so we have 110 which is social object.",
                    "label": 0
                },
                {
                    "sent": "If we make the normalization, we have 40 and 48 and this we know that all the sub concepts of physical object will be between 40 and 48 vessels.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The easy way to rewrite query because we just have to use identifiers and make a filter on the value.",
                    "label": 0
                },
                {
                    "sent": "So it is very easy for query writing.",
                    "label": 0
                },
                {
                    "sent": "The usage of lightmaps in ways it is used for the encoding of streams and as data into static knowledge base and we use it also into Pasadena which I will.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Present right now, so podbean is the part for the reasoning combining materialization and query rewriting using the compressed form from.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the motivation behind Podbean was first, as I mentioned, two query over compressed data and also to use some repetetive information that are always in the streams.",
                    "label": 0
                },
                {
                    "sent": "Because when we user streams we have mostly continuous queries or queries that are executed all the time and in the streams we have some repetitive informations.",
                    "label": 0
                },
                {
                    "sent": "What I mean is, for example in our use case we have data coming from some sensors so.",
                    "label": 0
                },
                {
                    "sent": "Our stream will be always containing identifier of the sensor, the.",
                    "label": 0
                },
                {
                    "sent": "The timestamp of the measure and the value measured, so all the values are objects in our three person.",
                    "label": 0
                },
                {
                    "sent": "So subjects and predicates of the triples will mostly never change, so we wanted to use this repetetive information for the compression.",
                    "label": 0
                },
                {
                    "sent": "So the principle of padman is as I mentioned, to combine the materialization and the query writing.",
                    "label": 0
                },
                {
                    "sent": "And for that, we decomposed that ripples into two structures called the pattern and the binding, hence the name of the pattern being.",
                    "label": 0
                },
                {
                    "sent": "Compressed form using vidente fires from light.",
                    "label": 0
                },
                {
                    "sent": "Matt and the bindings holding the object of the triple.",
                    "label": 1
                },
                {
                    "sent": "So the part that will change.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This looks like exactly so the pattern.",
                    "label": 0
                },
                {
                    "sent": "Use the predicates from light mats and preserve the triple interlinking.",
                    "label": 1
                },
                {
                    "sent": "So in this example sixteen 2137 and 29 R identifiers encoding predicates.",
                    "label": 0
                },
                {
                    "sent": "Each identifier supported by two points.",
                    "label": 0
                },
                {
                    "sent": "Either at the same level, which means they share the same subject.",
                    "label": 0
                },
                {
                    "sent": "So 1621 and 37 have the same subject and 29 is in between parentheses because it has the subject which is the object of 37.",
                    "label": 0
                },
                {
                    "sent": "So the interlinking of the properties is kept in this form for the binding.",
                    "label": 0
                },
                {
                    "sent": "We just store the object in the order of the patterns, so we have 250, which is the object of the property 16 with which is.",
                    "label": 0
                },
                {
                    "sent": "Object of the property 29.",
                    "label": 0
                },
                {
                    "sent": "A blog for property 37 because we are in presence of a blank node and pass card which is the object of the property 29 so the advantages of this form is that we have a pattern repetitive for the streams because we just use one pattern for all the streams.",
                    "label": 0
                },
                {
                    "sent": "Because it's the same structure of properties that subject it will never change and only the binding.",
                    "label": 0
                },
                {
                    "sent": "Come from the stream so it is a very compressed right and there is no need for decompression because we have like Matt and we can use this form for materialization.",
                    "label": 1
                },
                {
                    "sent": "I will not give.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An example rapidly.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose we have this trimmer in blue so we have data coming from the sensor Q 250 at this date.",
                    "label": 0
                },
                {
                    "sent": "So there would be normally and timestamp behind with hours, minutes and seconds and it is a measure of pressure with the value 4.5.",
                    "label": 0
                },
                {
                    "sent": "Using the dictionary from light math here with the identifiers attributed at each predicate, we can build this pattern an this binding.",
                    "label": 0
                },
                {
                    "sent": "We thought the pattern in ascending order for better manipulation for the materialization.",
                    "label": 0
                },
                {
                    "sent": "I will come back on that later.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have this query to apply on the stream in red, so we select the identifier and the value from the stream so we can build once more the pattern and the binding using the dictionary.",
                    "label": 0
                },
                {
                    "sent": "Here we can see that there is a small problem.",
                    "label": 0
                },
                {
                    "sent": "It is that in the stream where is not the location of the sensor, because we want them to be very compact.",
                    "label": 0
                },
                {
                    "sent": "So we have to materialize the location of the sensor.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we will have to 1st detect the property that need to be materialized so we can make the intersection of the patterns of the stream and the pattern of the query.",
                    "label": 0
                },
                {
                    "sent": "So we have the common form and subtract this common form to the pattern of the query.",
                    "label": 0
                },
                {
                    "sent": "So we will have only the predicate which is in the query and not in the streamer.",
                    "label": 0
                },
                {
                    "sent": "Here we see the importance of the ascending order.",
                    "label": 0
                },
                {
                    "sent": "It is for a better comparison.",
                    "label": 0
                },
                {
                    "sent": "Once we have this property we can use query on the static.",
                    "label": 0
                },
                {
                    "sent": "Knowledge Base which holds the structure of the network to get on which platform the sensor is diploid and.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After that we have the pattern in the beginning to be materialized.",
                    "label": 0
                },
                {
                    "sent": "We can enrich the stream.",
                    "label": 1
                },
                {
                    "sent": "Three person.",
                    "label": 0
                },
                {
                    "sent": "Verify the compatibility so the patterns will be the pattern of the query will be included in the pattern of the streams and we have to check if the the binding of the query is included in the binding of the stream.",
                    "label": 1
                },
                {
                    "sent": "Here we have platform one so it is true we can just give the result.",
                    "label": 0
                },
                {
                    "sent": "So this is how the metalization work for podbean.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In conclusion, I have presented my research project which is a waste project.",
                    "label": 0
                },
                {
                    "sent": "It is written in string processing, angina applied on the use case of drinkable water network management and I have presented the algorithm we have developed for the returning on this project, which is composed of two parts light math, which is a compression system with binary identifiers representing the ontology semantics and podbean, which is a reasoning scheme combining.",
                    "label": 1
                },
                {
                    "sent": "Creating an metalization over compressed data for the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Feature works we plan for that matter to support our DFS press press.",
                    "label": 0
                },
                {
                    "sent": "We've all same as and transitive and inverse properties.",
                    "label": 1
                },
                {
                    "sent": "And for Podbean we want to go further.",
                    "label": 0
                },
                {
                    "sent": "We are working currently on the aggregate, so min Max sum, average counts and property diverted.",
                    "label": 0
                },
                {
                    "sent": "We want to support more operators with optional and filter.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "If you have questions now, I will do my best to answer them.",
                    "label": 0
                }
            ]
        }
    }
}