{
    "id": "i63zubbfxzqsuluf2axl777nl2d46ivz",
    "title": "On Recent Trends in Extremely Large-Scale Convex Optimization",
    "info": {
        "author": [
            "Arkadi Nemirovski, Technion - Israel Institute of Technology"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Optimization Methods"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_nemirovksi_rte/",
    "segmentation": [
        [
            "I did not turn out yet.",
            "OK, let me do it.",
            "OK, I am very grateful to organizer for my take me here that the title of my talk of some recent trends in large scale convex optimization.",
            "Perhaps it would be better to say on some recent trends in less critical septum.",
            "Isation is joint research with an actually did steal extender shape."
        ],
        [
            "John: so this is the over your house.",
            "Say couple of words of practical scope of interior point methods then or what you can use beyond the grasp of those methods.",
            "I believe that those cheap first order methods and will speak about limits of their performance.",
            "What you can expect from those methods and then how could you utilize problem structure to accelerate 1st order methods and then there is another source of celebration.",
            "This is randomization.",
            "And then there will be a sample for examples.",
            "So there is clip on it."
        ],
        [
            "Programming is beyond the grasp of polynomial time, interior point methods.",
            "So what they can do, they can give her curacy solution and reasonably small number of iterations.",
            "Now there is a price for it there if intercoastal for iteration grows non linearly with the design dimension, the number of variables in your problem and eventually becomes prohibitively large.",
            "Single iteration last forever.",
            "What is eventually means it depends on the problem.",
            "In linear programming problems of decision-making bridge and the constraint matrix scientifically.",
            "Very, very sparse.",
            "Does the result you can solve problems with 10s and hundreds of thousands of variables and constraints if you switch to do the same LP's but in machine learning and signal processing then they it may happen that they have.",
            "Not not.",
            "Sparse constraint mattress is and here already we will see examples few thousands of variables, some constraints with domain in semi definite programming.",
            "If you do not have structure like the one which was discussed in Steve.",
            "I live in stock, then I would say few thousands of variables is already too much.",
            "So what is it?"
        ],
        [
            "The present level of our knowledge that missed raised it because nobody talk to us that there are no polynomial time computationally cheap algorithms at the present level of our knowledge.",
            "What what what you should use what makes sense to use beyond the grasp of interior point methods.",
            "I first order methods, we have cheap iterations and here is immediate example.",
            "There are two SVM instances.",
            "OK, I'm as the dimension of the feature vectors and then as the sample size OK, and that they're just both of them reduce just to LP.",
            "So this is what when you solve one of the problems by interior Point method by commercial solver music group.",
            "OK, you get predictive.",
            "Power 2.6% and it takes nearly 3000 seconds to solve the same problem for the 1st order methods you get in 141 seconds, exactly the same predictive power.",
            "Now you look at the larger data set, then interior point method based on the computer we used was just out of memory and the first automated still in 50 seconds.",
            "What 8% predictive accuracy?",
            "So what's good about first order methods?",
            "When you're solving large scale problems with favorable geometry, what is it we will discuss later then that that those methods exhibit nearly dimension independent rate of convergence, which of course is good, and you're speaking about large scale applications and what is not sold with the dimension independent rate of convergence is relatively slow.",
            "It's only subli.",
            "Here are more detailed examples, so this is the problem we are solving meaning."
        ],
        [
            "Raising the lips continuous convex function over Converse domain which is bounded and R as the diameter.",
            "Euclidean diameter of this domain.",
            "So what you can expect from first order method when solving this problem within our viewership cell.",
            "If your objective is smooth with Lipschitz continuous gradient, then this is how many steps of the method you should carry out is worse proportional to the square root of the date of their curation.",
            "If your objective was just Lipschitz, so instead of numerous continuity of the gradient you they're just bound on the difference of gradients.",
            "OK, then you still have dimension independent rate of convergence but much worse wanted accuracy is 1 divided by epsilon squared.",
            "Now at the step you should compute the value of the objective in its gradient at a point and there is certain computational overhead which for simple domains is that just linear in the dimension of the problem.",
            "No, we'll all you can do with your objective is to compute its values and subgradients, then those bounds in the last scale piece, say when X is.",
            "They're just unimprovable you cannot do, but.",
            "And the also important fact that if you start from measuring the distances in the space and two in the Euclidean norm, you switched over norm and consequently the regularity of the gradients you measure in Infinity moment the conjugate normal.",
            "Then the bonds remain essentially the same extra logarithmically name factor.",
            "So then the dimension is now nearly demand that the convergence rate is nearly dimension independent.",
            "No, all have first order methods.",
            "As a matter of fact, they use black box representation."
        ],
        [
            "Object are sold, they come.",
            "Get about this objective value, some gradients.",
            "They do not know how to use other information, so those rate of convergence which we have seen the best you can get in the large scale case.",
            "What are the consequences?",
            "First of all, we see that the diameter of the visible domain it just enters.",
            "The complexity bound.",
            "No cases here.",
            "The complexity is proportional to diameter and here it is.",
            "Proportional to squirt diameter.",
            "So the bounds of the feasible domain.",
            "This theoretical is of paramount importance, and it follows that, say, coneless settings like in Las.",
            "From the purely optimization you point there bit settings because here the domain is unbounded.",
            "OK, and then what is essentially we're better from that?",
            "Learn from the optimization point.",
            "I don't know.",
            "Perhaps there other reasons why you prefer models of this type.",
            "Wear them this to the parameter to models of that type where the you just size of the domain on which you optimize.",
            "Use the parameter, but from the optimization viewpoint those settings are much much better.",
            "OK, now since the rate of convergence we can get his only sub linear.",
            "You cannot hope to to solve the problem to hire furious Alexis certain digits OK, but as on the positive side, the kind of compare compensation if you end the last real case and you have favorite favorable geometry, those mid accuracy solutions can be obtained at the iteration cards in there, which is nearly dimension independent.",
            "This.",
            "OK, if you give Kim extract bound from this I don't understand her.",
            "OK, if you can extract won't solve this problem.",
            "This is my advice from the purely optimization viewpoint.",
            "Holding the computer both the constraint set again.",
            "Problem with.",
            "It depends on what will be the bond.",
            "If you're if you want to solve this problem within fixed accuracy 10 to the power minus three.",
            "And the end is very small.",
            "The solution may well happen, be very, very far.",
            "OK, if you don't, if you have an additional balance on the normal solution, this is another story.",
            "But the if you do not have this norm, yes, Anderson will be very, very far and it is very will be very difficult to solve the problem.",
            "OK, let me continue.",
            "OK, we will discuss it later.",
            "What I said.",
            "I said OK if you have something in addition.",
            "Talked about the solution.",
            "This is difficult to the different story.",
            "Then you also problem in a bounded domain with your penalization and you ask me, I don't understand for what the penalization, but you know.",
            "But I mean you can always binary search for that number for the final.",
            "Well, the the point is that if you learn this small will be very difficult for me to solve the problem.",
            "OK, so smooth problems are much better suited than non small for converse minimization."
        ],
        [
            "Hello for the 1st order methods, but the difficulty is that OK you need both the domain simple otherwise steps will be difficult and the objective Smith and this is rare commodity so as many other breakthroughs and this in components optimization there is a breakthrough due to urine Nesterov many others.",
            "There are many others breakthrough also due to him so notice very simple mindset fact that most mornings.",
            "In corners, optimization primarily arises from taking motion.",
            "So typically you can represent your non small subjective as maximum with respect to additional variable.",
            "Also random bounded convex set off a smooth convex concave function fireworks way.",
            "And then you can instead of solving this problem, you can use the knowledge of the structure to build such a representation and then solve this saddle point problem by first order methods and as a result you will get rid of convergence 1/4 of 1 / F said she's better than non smooth case, worse than smooth case but smooth.",
            "Again it's something which is very rare commodity.",
            "Let me give a bunch of examples of saddle point reformulations.",
            "No, this is the simplest example.",
            "You want to minimize maximum of smooth functions.",
            "Know you immediately right at the saddle point problem.",
            "Your way is just the standard SIM players.",
            "Semi definite problem.",
            "You want to minimize my maximal eigenvalue matter.",
            "It's definitely depends on your variables maximum."
        ],
        [
            "Eigenvalues much more fingerprint of trace products of your matrix and the positive semi definite matrices with trace one.",
            "So you get this.",
            "Reformulation so this is difficult muscle function and this is just be linear cost function.",
            "L1 minimization in this form new.",
            "First you can reduce it to can reduce it to small series of problems when you are minimizing residual or anyone bull and this can be immediately converted to the saddle point and then we linear saddle point problem.",
            "Nuclear norm minimization exactly is then the preview."
        ],
        [
            "Example, so nuclear normous sum of singular values.",
            "You want to minimize this nuclear norm given.",
            "Bound on the residual uncertain linear system, again, you can reduce it to small series of parametric problems.",
            "Everyone is on nuclear both.",
            "Ride your Swan and this again is a simple saddle point problem.",
            "SDP relaxation of low dimensional uniform approximation.",
            "The problem is laid with you here in unit vectors in certain Aryan and K&U want to find dimensional subspace such that the maximum over the distance from the point of the subspace see the smallest possible.",
            "It's not this problem by itself is a difficult problem.",
            "Then was optimization with respect to projectors, but in very few relax that the property to be projected.",
            "If you passed a semi definite relaxation you'll get settled point problem.",
            "Billionaire, now this is the problem, you know, better than me.",
            "OK, parametric SVM problem.",
            "First, if you have."
        ],
        [
            "Parameter here.",
            "Again, from the optimization, you point is better to re parameterized this problem and pose the norm bound on the norm of your separator and then those constraints.",
            "Under this restriction you minimize how you call.",
            "It said we have errors.",
            "Happy normal Day after of errors and the you can immediately rated Dallas billionaire saddle point problem one 1:30 is the set of.",
            "Alpha vectors with this kernel norm less than or equal than one and another set is very very cheap.",
            "Now, if you do not have kernel, have trivial kernel did this is the reformulation again linear saddle point problem.",
            "OK, now what can we get when we?"
        ],
        [
            "Solving those problems.",
            "But first I am going to speak about approximate solutions.",
            "We should agree have been measured you receive.",
            "This is the natural accuracy measure, which is OK. How you need 25.",
            "Issue of Peretz Way is approximate approximation to the saddle point of this function.",
            "This is that the natural definition you take fields X.",
            "And take the maximum of the cost function with respect to the second argument and subtract minimum.",
            "We should see here on the transparency, so then let me explain what's going on here.",
            "What does it mean to solve this certain point?",
            "Problem Minister solve a pair of dual to each other quantities optimization problems in the primal problem.",
            "You want to minimize over the set of spittle dysfunction overline for Fi, which is maximum of your cost function over way, and an adult problem.",
            "You want to minimize this underlying file, which is minimum of your cost function over X is.",
            "Those two problems have equal optimal values.",
            "We in this situation and despise convex concave.",
            "And the absence of which way is just some of inaccuracy is the.",
            "What is the inaccuracy in terms of the objective of Earth as the solution to the primal problem?",
            "And why is the solution to the do?"
        ],
        [
            "No, what the there are several claims family intend to.",
            "Support.",
            "When the 1st Congress County, when gradient of phase Lipschitz continuous, then you can solve this problem by a good first order method that you receive Salem at the iteration count is inverse proportional to this Excel.",
            "OK, now what is the cost of iteration?",
            "It is one or two depending on the method computations of gradient of Phi at a point plus some computational overhead.",
            "Those good methods there are several of them for the time being this is the very first Newton instead of new.",
            "Smoothing method and this is the algorithm I'll speak about in this talk.",
            "OK, now what are the constant factor hidden in this 01 divided by epsilon, not turns out that if X&Y possess favorable geometry, again, it will be explained later.",
            "What does it mean?",
            "OK, then the the those factors here, nearly independent of the dimension of the problem and the third claim is that you can further accelerate the 1st order methods by randomization.",
            "What is meant so they said the 1st order method?",
            "The deterministic requires computing the gradient of this fire to point at every step one or two gradients.",
            "Now you Firefly is.",
            "Say be linear as most of the examples we have seen.",
            "Then that this computing gradient that is 1 automotrice vector multiplications.",
            "If your problem is large.",
            "Then all of the metrics have multiplications may become time consuming, and then you may gain from replacing precise first of the information by randomized.",
            "Easier to compute estimates of the gradients and we'll see how we do it.",
            "No, here there are.",
            "There is also the complexity of the method.",
            "I'm going to speak about.",
            "So now the story.",
            "What would your battery so assume that the domain of our saddle point problem extends?",
            "Way belongs to assert, which is a direct product of K standard basic blocks.",
            "What are those basic blocks?",
            "You have a number of unit Euclidean balls, and you have a number of spectrograms, water spitter and they express of block diagonal.",
            "Symmetric matrices of given book diagonal structure.",
            "In this space you take positive semidefinite matrices of unit trace.",
            "This course.",
            "For example of your mattress is are just diagonal.",
            "Tell them what you get is a spectrum.",
            "Is the standard simplex coordination and negative and some of coordinates is equal to 1 diagonal matrix admits factory authority.",
            "Your old this vector on the diagonal of the matrix?",
            "OK, now if you have L1 bowl.",
            "As the part of the domain is block OK, then L1 bull's image of twice standard simplex of twice larger dimension unde."
        ],
        [
            "The simple made comparatively after awful one or not exceeding quantity can represent us difference of two non negative vectors with some of anyone non sequel to one.",
            "So you can eliminate if you have a block which is in one bowl you can eliminate it, replace it with simplex.",
            "And similarly for the nuclear bowl, pay for the nuclear bowl again at the nuclear ball is image of the standard torten standard spectator and positive definite matrices with trace one in twice larger dimension.",
            "You also you also can eliminate them.",
            "No.",
            "What is important?",
            "Also we so we are in this situation when we let's say normal off the domain.",
            "TV made the part of.",
            "Product of several Euclidean balls and several spectators, and that now embedding space of this Sir teaches product of several Euclidean spaces in several spaces of block diagonal symmetric matrices.",
            "We equipped with this norm Euclidean aggregation of Euclidean norms on the Euclidean companions of direct product and trace norm.",
            "Sum of a.",
            "Absolute values sum of singular values of a symmetric mattress for the matrix components.",
            "Now this is how the contributor."
        ],
        [
            "It will be important now.",
            "The result of camera on convergence complexity, so she assumed that you are solving the saddle point problem on the domain, which is part of the standard set.",
            "This product of several Euclidean balls and several Spectra adrants, and your objective satisfies the fight.",
            "The cost function satisfies the following bound.",
            "The difference in the gradients measured in the dual norm.",
            "We have equipped that the embedding space for this.",
            "Done."
        ],
        [
            "Meaning of our problem with certain norms.",
            "So the gradients you should measure in the dual mode.",
            "OK, is bounded by 8 times the distance between the points plus M, so we may think about phase.",
            "It has Lipschitz continuous gradient of acquisitions, continuous abounded component L is the.",
            "Leave just constant of delicious continuous component and M is the the norm of the bounded company.",
            "Now how we observe this favor have a sister stochastic Oracle which reports unbiased estimates of gradients.",
            "So when I called this Oracle at health step.",
            "I want to compute the gradient at point zed from this domain.",
            "So this is what I sent to the disk astic Oracle's input and this is what the Oracle returns them in certain deterministic function of that of the query point and Oracle noise Oracle noises from step to step independent, identically distributed and what we need is the following.",
            "That's G of that size should be unbiased estimate of the true gradient.",
            "And we imposed impose bounds on variability of this unbiased estimate.",
            "So we take the the conjugate norm of the difference.",
            "Or for estimating the trend, it's Expectation Square interview wanted this point it it should be less than miracle than M score.",
            "Look that there is the same constant payment to two places.",
            "Here it is responsible for not only should some component and Delta Phi here, this is for the responsible for the noise variability of my Oracle.",
            "Of course there should be in principle to different constants, but the point is that what actually matters is their maximum.",
            "And This is why I prefer to use the same constant and this is the result for every in the algorithm there is well defined.",
            "Algorithm, doesn't matter how it looks like OK, it generates a random solution to our problem with expected and accuracy which is bounded by absolute constant times.",
            "Not OK, we see here.",
            "Let's look what we see.",
            "First of all, what is this data?",
            "Data is responsible for the geometry of your problem, and this is exactly the following could do you take how many balls you have in the description of the problem and at the number of both the dimensions of those Euclidean both absolutely reliable.",
            "And some of the looks."
        ],
        [
            "Of the dimensions of the specter drones and you take square root of this and this is that.",
            "So this is something which reflects the geometry of your domain.",
            "OK, now alien them reflex variability of your gradient of your free N as the number of steps when we see there is let's say smooth part in the bond which goes to zero inverse proportional to the number of steps and there is none.",
            "Smooth the storm OK which she goes to zeros like 1 divided by square root of now it may say will happen that you have deterministic Oracle and M equal to 0 then this disappears you get come.",
            "Conversions one over the number of steps.",
            "OK, so this again is this bound.",
            "Now what we need to do at a step we need to call absolute constant times so.",
            "Two or three.",
            "I also did talk also exactly 2 twice cause the stock istick Oracle and we have sort of computational overhead of C arithmetic operations on the top of it.",
            "What we see depends on how what is yours at day hours.",
            "It was only part in this product of standard blocks.",
            "OK, if it is not very complicated, part of it that is the entire that password is cut off the plus by absolute constant number of linear inequalities.",
            "Then this is the what is the computational overhead dimension of the domain plus effort of value decomposition of the matrix for the product hospital address.",
            "What we see here.",
            "First of all, if.",
            "The number of blocks, ball blocks, and spectator and block.",
            "So I feel is fixed then the this efficiency estimate is nearly not affected by the dimension.",
            "The only place where dimension that comes in is that those logs of sizes of spectator and blows.",
            "But they're only lots of those sizes.",
            "OK, and Moreover, if yours at this product of the two bowl, so more than to both fixed number of both, then this efficiency is an improbable.",
            "In the last staircase.",
            "No, and if.",
            "Your all your spectrograms are Simplicius.",
            "OK, then the overhead is just linear in the dimension of the problem, the Methodist cheap."
        ],
        [
            "No, you have also.",
            "If you assume that your noises and Oracle have.",
            "Light deals more.",
            "Here is the exact.",
            "Go to see them that this OK, if you indeed you statistique not deterministic Oracle then you're.",
            "Solution is random and the previous result was only what is the expected inaccuracy.",
            "But you have also the slight taste stale assumption on the noises you have exponential bounds on large deviations.",
            "OK, now let's think how could we randomize first of the method.",
            "So let's look at problem with billing your cost function.",
            "Most of the problems in fact there like this.",
            "Many problems, at least like this.",
            "So in this situation, what is this first order information?",
            "You should compute the derivative with respect to X.",
            "It is a transposed way.",
            "And the derivative is stripped away is a year, so you should carry out to matrix vector multiplications, appoint from escaped or you should multiply by E and the poet from why you should multiply by transpose.",
            "OK, now how could you randomize such a competition?",
            "Sweet, easy.",
            "How could you randomize matrix vector multiplication?"
        ],
        [
            "The absolute values of interest in you reactor X and divide them by there you will get more negative of entry.",
            "Sequel to one.",
            "Think about this.",
            "Water is about probability distribution on the set of windows is pick a random index J according to this distribution there's J. Cole and I have materials B. Multiplying it by sign of Xion by L1 norm of X you will get a random vector just proportional to certain randomly chosen column and you be.",
            "Now, this immediately assume that the expectation of the swifter is the product BX we want to compute new.",
            "You have also controlling the norm of the theater.",
            "OK, but this is.",
            "Well, in upper bound on the normal this randomly actor.",
            "Now what is the call cost of this Oracle?",
            "OK, it's just linear indecisa so would be where you need or of B.",
            "There are times then you need often operations to generate this G and then you need air.",
            "My parations to extract the column from the Matrix.",
            "Now you can also call this query Oracle several times and tell David which of the answers in order to reduce the noise.",
            "OK, let's look how it works.",
            "So this is everyone minimes."
        ],
        [
            "Nation of uniform feet.",
            "So I want to minimize normal fares minus B Infinity.",
            "No more access from any one ball.",
            "You can immediately read this problem as Saddle point problem.",
            "What will be important for us is the maximum of absolute.",
            "Of magnitudes of entries in your mattress, see Now if the airmen there now large, then what is the best known complexity of finding epsilon solution for this problem?",
            "By deterministic algorithms, the number of steps is like elevated by epsilon elevated.",
            "But now you're silent, divided by its natural relative accuracy in our program.",
            "OK, the fence log of.",
            "Size of the problem.",
            "This is the number of steps at every step you need to carry out to matrix.",
            "We're multiplications, so the arithmetic complexity is quadratic is after this load factor is quadratic in the size by product of the sizes and inverse proportional to Excel.",
            "Now it turns out that if you randomize matrix you after multiplications you again.",
            "Adept and algorithm, which OK much larger number of steps Lunger.",
            "OK, OK, this algorithm produces upsell on solution with confidence 1 minus Britain birthday is you give to me and this is OK.",
            "It nearly doesn't affect the complexity as we see from the formal visit.",
            "The number of steps it is inversely proportional to the squirt accuracy instead of accuracy.",
            "But the steps that ship every step that effort is just linear in the sizes.",
            "So the total arithmetic effort is as you see here on the transparency.",
            "It is nearly linear in the size of the problem.",
            "Instead of being nearly quadratic.",
            "OK, so if you're ill and epsilon and better I fixed in them and then a large then did this method randomized algorithm by orders of magnitude outperforms the terministic algorithms and Moreover there's device what's called sub linear time behavior.",
            "Look, this is the total number of.",
            "Arithmetic operations will carry out so, so the the number of entries in the Matrix A which we inspected is less than what we see here, and mattress has entries.",
            "So when M and their knowledge and allow the same order, we get an epsilon solution with great confidence.",
            "You can take this better equal to temple to the power minus 12.",
            "OK bye inspected only negligible part of the data.",
            "This is not a new phenomenon.",
            "OK, sensually.",
            "This problem can be reduced from Automotrice game and for Mattress Games in mid 90s.",
            "But every Addison Richie and discovered the sub linear time algorithm and Donna closest inspection here hand said their algorithm is very very similar to what this."
        ],
        [
            "Stochastic mirror process.",
            "The advantage of stochastic mirror process that you build this algorithm is a particular case of certain general construction.",
            "You can use this construction also in other situations.",
            "OK, now when you instead of.",
            "Minimizing Infinity norm of the residual want to minimize two norm.",
            "Not let me just OK that the now what is responsible that the scale proper scale factor in the problem is maximum of Euclidean norms of columns in a not maximum of absolute value software.",
            "OK, in both cases this is the norm of this mapping.",
            "Earth is mapped to X when X is that we have two L1 norm.",
            "And if you use it with the norm dual to the what you see here 2 dual to the North Pole that is ITO.",
            "Sorry, we are exactly the same Long Beach.",
            "We measured the receipt though not the door.",
            "OK.",
            "So we will determine Istic methods that the complexity is as you see on the transparency and the number of arithmetic operations like MN divided by Epsilon view from the mistargeted.",
            "It is like this, you still fear quadratic in the size entry term in the complexity MN log, but this storm is not multiplied by one or web selling or whatever.",
            "OK, what is affected by accuracy?",
            "Is only that this linear in the moment or so it looks like you carry outfits number independent of upsell full matrix.",
            "We after multiplications that this logarithmic and number full mattress vector multiplications and then you start to extract roles and qualities.",
            "No, you cannot stand this.",
            "What was this L Infinity mean OK?"
        ],
        [
            "L1 minimization we will Infinity feet.",
            "In fact it was minimizing or with simplex maximum of M friend forms.",
            "You can replace those fine forms by polynomials of convex polynomial.",
            "So forgiven degree and you have essentially the same result.",
            "Also again you can randomize.",
            "OK, and now just numerical examples.",
            "How many what they might have.",
            "How many time I have?",
            "Say it again.",
            "Great.",
            "OK, so we'll start with the Terministic 1st order methods and then we will look water addition and it can be obtained via randomization.",
            "So this is an Infinity fit on one.",
            "Bull, your matrix is slave compensation.",
            "Set into matrix is obtained from.",
            "Discrete for their transform mattress.",
            "You just take a trend of em rose in the discrete."
        ],
        [
            "Via transform mattress and the data generated as follows, we start with generating the sparse signal.",
            "Actually we've still non zero entries of one on one.",
            "Then we multiplied by this matrix we add noise which in the uniform normal as you see on the transparency.",
            "This gives us B and now we want.",
            "To solve this problem to recover signal.",
            "So what we're interested in is not how we solve this optimization problem.",
            "What we're interested in is how the solution of it.",
            "How will it approximates the true signal?",
            "And here are the results in the table.",
            "So what we see in the accuracy columns L1 error of recovery, 2 error of recovery and Infinity error of recovery.",
            "Here are the sizes of the matrix.",
            "OK, this is relatively small example and we compared the terministic.",
            "Mirror pro salgari.",
            "We've interior point method with Mazda quote.",
            "Now what we see in this relatively small example.",
            "Mirror the interior point method worked, but it takes like 100 times more time then.",
            "The Terministic algorithm and also the.",
            "Up if worst solution again.",
            "Of course it better solve the optimization problem, but the record.",
            "But the what happens is kind of over here, but the notion build a.",
            "First of the method where Terry produces the true signal by factor of 10.",
            "Now of course, here that the this.",
            "The Terministic method uses the fact that you eat comes from discrete Fourier transform matrix.",
            "So metrics vector multiplications are cheap there nearly linear.",
            "You can use facts for you."
        ],
        [
            "Transform to compute those matrix vector multiplications.",
            "OK, now larger sizes 1000 * 4013 point method is already out of memory.",
            "Cannot do anything more and you see that this.",
            "First of the methods works perfectly well that the size is 4000 * 16,000.",
            "No interior point method to even be do not tested this discrete deterministic mirror process.",
            "Everything just fine.",
            "You solve the problem to reasonably high accuracy.",
            "In like less than one minute.",
            "So here are the pictures.",
            "The true signal trees and spirit.",
            "Don't know what the difference.",
            "Between.",
            "At the cabin.",
            "No, this is Jean 1 music.",
            "Patient will be said, OK, we've already know what is there right now."
        ],
        [
            "Oh my God this.",
            "It was Vietnam.",
            "In the OneNote.",
            "If you had one bowl, this is a problem in one of X given upper bound one.",
            "Pretty cool.",
            "In certain vineyards.",
            "They used to.",
            "Will you both you speak?",
            "Don't feed the people.",
            "Talk to Euclidean feet, not here.",
            "I had the results.",
            "Then I will say that there is also pretty good.",
            "With all that AIM assist within.",
            "90 seconds and accuracy is reasonably good.",
            "No, this is example."
        ],
        [
            "OK, couple minutes to explain.",
            "There's something about compressed sensing if you I incomprehension situation you may ask how could we justify that?",
            "Given sentient matrix and it allows to recover exactly all sparse signals with given number of non zero entries.",
            "If there is no observation noise, how could we check that they get whatever?",
            "If you still have 5 nonzeros then it will be recovered.",
            "Properly by L1 minimization, there is a simple verifiable sufficient condition for its distribution condition, as you see on the transparency and.",
            "Essentially it says optimal value on certain.",
            "Linear programming problem where your matrix A gives the date of this problem should be less than 1/2.",
            "If there's less than 1/2 that, then your mattress see OK.",
            "This problem depends on the parameters on the parameter of the number of nonzeros in the true signal and the case, or if the optimal values less than 1/2 that then.",
            "Every sheet movie first known zeros will be in the absence of noise will be recovered.",
            "Exactly.",
            "OK, but now OK, if you want to check this, if this is verifiable conditions reduces to help.",
            "If you want to check it, you need to solve this LP and if your mattress is not very large pits says this is a as you see on the transparency, not this LP.",
            "OK, the number of.",
            "Variables and constraints in this LP is quadratic in the larger size of the matrix C, so in the for this reasonably small matrix.",
            "Very small in scale of compensation that this problem LP has like 130,000 constraints and variables and linear programming solver which I have a is unable to solve it.",
            "No, but you can reduce this problem to settle point billionaire saddle point problem.",
            "Solve it with deterministic mirror prox.",
            "OK so that you know exactly as a result of this solution under the optimal value is less than or have a great OK and the computation.",
            "OK it's not first, but that is the sushi one hour plus something.",
            "OK, now what randomization can do in addition to what first of the deterministic 1st order methods, this again is the same problem with the starter.",
            "You fell one minimization in the simple setting have minimizing Infinity norm of the residual linear system or well one bowl.",
            "OK, but now your matrix is not.",
            "Submatrix of discrete for you or for DfT.",
            "It is sort of this analytically given matrix.",
            "OK, and here are examples of two is results of two experiments.",
            "Those are the sizes of the matrix.",
            "In the first experiment goes as a society that still I can store this matrix in ram of my computer.",
            "Morning baby will solve the problem by deterministic mirror professor by Stochastic Mirror Prox and you see that the terministic mirror process much, much better.",
            "It was like 3 times better in terms of time and that this like 10 times better in terms of the accuracy of the solution you get.",
            "The only wish OK with it.",
            "She's not very relevant in this situation, but the only thing is like this when you looking at this randomized matrix vector multiplication.",
            "1000 of them.",
            "You can think how many full matrix we have for multiplications will have the same complexity.",
            "And it turns out that that this stochastic mirror process carried out.",
            "I don't remember like 20,000 of those randomized matrix vector multiplications, but this was equivalent to like 30.",
            "Full matrix vector multiplications and the the Terministic algorithm.",
            "Credit out much more mattress with multiplications, but that doesn't matter in this size in the sizes because still the terministic method is faster and more accurate, but if you now increase the size as to what you see on the transparency, then now the matrix."
        ],
        [
            "I cannot store it in the memory of my computer, so together to operate to set up any mattress with multiplication, I should compute the Rose 1 by 1.",
            "Or the columns dependent for what they are multiplying the given total formulas.",
            "Oh OK, and now it turns out that single mattress with her multiplication cost like 500 of seconds, so 3 and 3000 seconds I allowed to algorithm to run the terministic algorithm was credited, was able to carry out five mattress with her, multiplication cannot get anything meaningful.",
            "Now in stock I stepped nearer crooks.",
            "Also totally of credit out even less than five mattress with multiplications, but they're warm.",
            "That they will like 30,000 of steps.",
            "Again, at the very least, if you just extract row and column from the matrix and the solution.",
            "OK, I wouldn't say that that you receive is were very, very evil, but the reasonable list if you see on the picture you do not see if you see anything that you definitely do not see difference between the true signal, the recovery.",
            "OK, in the last example is low dimensional approximation so that."
        ],
        [
            "Here the example is like this.",
            "You have 1100 thousand points.",
            "Unit vectors in of dimension 100.",
            "You know that there exist in the nature 10 dimensional linear subspace or to you from which all the points out the distance at most.",
            "Oh Point 2 and we want to find such a subspace.",
            "So this is the deep relaxation of the problem.",
            "You know?",
            "OK, if you pee would be the projector on the dimensional space, then what you are doing.",
            "You are so dear.",
            "Yes, exactly P should be the projector on 10 dimensional space.",
            "Then this minimum of all Asia.",
            "Unit we have to solve this minimum wage transposed PG or I is OK is the same as the maximal of the distances from the point P. Pay that for the distance to be less than oh point 2 this minimum should be greater than oh point 8.",
            "OK, that this the squad number of the projection on the subspace it should be large.",
            "OK, and then we maximize the food aspect appears but update with respect to projector something dimensional subspace this we don't know how to do its thing.",
            "Not real problem but we can relax it say OK that instead of maximizing respective projectors we can maximize respect to positive definite matrices.",
            "Very good values not exceeding one and sum of eigenvalues not exceeding 10 and then it becomes a good problem.",
            "OK, now given a solution to this problem AP, how we produce from a 10 dimensional subspace?",
            "Not very easy.",
            "You take take leading cable connectors and said the linear spam is disturbed dimensional space given by the speed and then when we run the algorithm you produce subsequent piece.",
            "Every time you check whether this subspace given 10 dimensional subspace driven by this P approximates all the points, we will not accuracy or .21 or point.",
            "We know that this is something which exists in the nature OK or use.",
            "Total waste.",
            "Those random samples.",
            "The problems turned out to be very very simple for discrete.",
            "For the Terministic 1st order methods repeat that so it was solved.",
            "Justin 17.",
            "Oracle calls 17 matrix where multiplication is the mattress maximal deviation of the points from the subspace we end up with is OK as it should be open to, but it took 507.",
            "Seconds if you randomize.",
            "The algorithm the number of calls to the stochastic Oracle is much higher 700 something, but all them totally amount to oh point 3 call to to deterministic Oracle you get a curious solution of nearly the same accuracy, But the time is like 12 by factor 12.",
            "This is all thank you.",
            "Let me see with the full OK. Don't OK. First aid dancewear is not I don't know the second I don't understand what would be average case complexity in this situation where from do you take distribution on the instances?",
            "Just a second I randomize by my own.",
            "I did not randomize the problem.",
            "Again, I did not randomize the problem.",
            "What I am saying is that whatever problem forgiven family you give to me, your probability, which again give me OK.",
            "The deer, meat and probability.",
            "1 -- 10 to the power minus 12.",
            "I'll solve this problem with this probability with this security and it and that number amount of with this and this computational effort.",
            "I don't know even how to pose the question like this.",
            "OK, you have ensemble of problems.",
            "I am ready to survive that.",
            "The fact that on 1% of those problems I will fail.",
            "So I'm interested what is the average performance for my algorithm ever is being taken over the distribution on problems I don't know how to pose this question because in my opinion there absolutely no natural distributions on the sets of problems.",
            "OK, maybe if you indeed have a situation when you know what is the distribution.",
            "Then the question could be posed.",
            "Bye bye.",
            "I just still sit that I do not know how to do it and they know do not know anybody who knows.",
            "OK.",
            "Specific things?",
            "Talking about getting the gradient.",
            "Response to when we were talking about dipping set in their noses random over there.",
            "OK, this situation yes.",
            "So.",
            "So let me OK this is so if I understood correctly the correct password.",
            "If you are in situation of genius stochastic programming problem, then again this could be applied.",
            "OK the I just said OK before I started deterministic problem I introduce randomness because I want to accelerate.",
            "You can also think about situations when my objective is given by the expectation.",
            "OK, and they do not know how I can only sample.",
            "Then again, all this becomes applicable.",
            "OK, the overhead and overhead is OK.",
            "It is just linear in the dimension.",
            "OK, but nevertheless this is over here.",
            "The number of simple iterations was like 30,000.",
            "OKM 30,000 times I was supposed to carry out projections.",
            "Those projections are linear, but nevertheless this is overhead.",
            "The number of matrix with vector multiplications is small equivalent number, but the overhead is the overhead.",
            "Yes.",
            "Can also be derived in the online adversarial setting, so at least the similar results.",
            "Excursion beginning destiny are valid only also in the online adversarial setting where the sequence of estimates is an arbitrary sequence and the performance is quite negative to the average over Saturday, and I'm not sure that OK, I'm not machine learning person, so I don't know.",
            "Similar results are described at the beginning of the results for US acoustic estimation.",
            "When you have the Lipschitz or smooth functions.",
            "Guarantees or almost exact thing where you don't assume that the estimates are custom, so you're using.",
            "This must be stochastic, must be unbiased.",
            "Acoustic estimates OK.",
            "So.",
            "So what not?",
            "Well, they could be the terministic, of course.",
            "Yes, look response to the situation is set empty row.",
            "M20.",
            "Doing the analysis on each step separately, so doing working as if you're in the stochastic setting, so I'm not doing not working with Mystic setting.",
            "Working when you're getting the best runtime guarantees because you're working in single estimates at the time, but these estimates are not actually estimate.",
            "There are serious.",
            "I'm not sure that they understood.",
            "OK, OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I did not turn out yet.",
                    "label": 0
                },
                {
                    "sent": "OK, let me do it.",
                    "label": 0
                },
                {
                    "sent": "OK, I am very grateful to organizer for my take me here that the title of my talk of some recent trends in large scale convex optimization.",
                    "label": 1
                },
                {
                    "sent": "Perhaps it would be better to say on some recent trends in less critical septum.",
                    "label": 1
                },
                {
                    "sent": "Isation is joint research with an actually did steal extender shape.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "John: so this is the over your house.",
                    "label": 0
                },
                {
                    "sent": "Say couple of words of practical scope of interior point methods then or what you can use beyond the grasp of those methods.",
                    "label": 1
                },
                {
                    "sent": "I believe that those cheap first order methods and will speak about limits of their performance.",
                    "label": 0
                },
                {
                    "sent": "What you can expect from those methods and then how could you utilize problem structure to accelerate 1st order methods and then there is another source of celebration.",
                    "label": 0
                },
                {
                    "sent": "This is randomization.",
                    "label": 0
                },
                {
                    "sent": "And then there will be a sample for examples.",
                    "label": 0
                },
                {
                    "sent": "So there is clip on it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Programming is beyond the grasp of polynomial time, interior point methods.",
                    "label": 1
                },
                {
                    "sent": "So what they can do, they can give her curacy solution and reasonably small number of iterations.",
                    "label": 1
                },
                {
                    "sent": "Now there is a price for it there if intercoastal for iteration grows non linearly with the design dimension, the number of variables in your problem and eventually becomes prohibitively large.",
                    "label": 1
                },
                {
                    "sent": "Single iteration last forever.",
                    "label": 0
                },
                {
                    "sent": "What is eventually means it depends on the problem.",
                    "label": 0
                },
                {
                    "sent": "In linear programming problems of decision-making bridge and the constraint matrix scientifically.",
                    "label": 0
                },
                {
                    "sent": "Very, very sparse.",
                    "label": 1
                },
                {
                    "sent": "Does the result you can solve problems with 10s and hundreds of thousands of variables and constraints if you switch to do the same LP's but in machine learning and signal processing then they it may happen that they have.",
                    "label": 1
                },
                {
                    "sent": "Not not.",
                    "label": 0
                },
                {
                    "sent": "Sparse constraint mattress is and here already we will see examples few thousands of variables, some constraints with domain in semi definite programming.",
                    "label": 0
                },
                {
                    "sent": "If you do not have structure like the one which was discussed in Steve.",
                    "label": 0
                },
                {
                    "sent": "I live in stock, then I would say few thousands of variables is already too much.",
                    "label": 0
                },
                {
                    "sent": "So what is it?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The present level of our knowledge that missed raised it because nobody talk to us that there are no polynomial time computationally cheap algorithms at the present level of our knowledge.",
                    "label": 1
                },
                {
                    "sent": "What what what you should use what makes sense to use beyond the grasp of interior point methods.",
                    "label": 1
                },
                {
                    "sent": "I first order methods, we have cheap iterations and here is immediate example.",
                    "label": 0
                },
                {
                    "sent": "There are two SVM instances.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm as the dimension of the feature vectors and then as the sample size OK, and that they're just both of them reduce just to LP.",
                    "label": 0
                },
                {
                    "sent": "So this is what when you solve one of the problems by interior Point method by commercial solver music group.",
                    "label": 0
                },
                {
                    "sent": "OK, you get predictive.",
                    "label": 0
                },
                {
                    "sent": "Power 2.6% and it takes nearly 3000 seconds to solve the same problem for the 1st order methods you get in 141 seconds, exactly the same predictive power.",
                    "label": 0
                },
                {
                    "sent": "Now you look at the larger data set, then interior point method based on the computer we used was just out of memory and the first automated still in 50 seconds.",
                    "label": 0
                },
                {
                    "sent": "What 8% predictive accuracy?",
                    "label": 0
                },
                {
                    "sent": "So what's good about first order methods?",
                    "label": 0
                },
                {
                    "sent": "When you're solving large scale problems with favorable geometry, what is it we will discuss later then that that those methods exhibit nearly dimension independent rate of convergence, which of course is good, and you're speaking about large scale applications and what is not sold with the dimension independent rate of convergence is relatively slow.",
                    "label": 1
                },
                {
                    "sent": "It's only subli.",
                    "label": 0
                },
                {
                    "sent": "Here are more detailed examples, so this is the problem we are solving meaning.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Raising the lips continuous convex function over Converse domain which is bounded and R as the diameter.",
                    "label": 0
                },
                {
                    "sent": "Euclidean diameter of this domain.",
                    "label": 1
                },
                {
                    "sent": "So what you can expect from first order method when solving this problem within our viewership cell.",
                    "label": 1
                },
                {
                    "sent": "If your objective is smooth with Lipschitz continuous gradient, then this is how many steps of the method you should carry out is worse proportional to the square root of the date of their curation.",
                    "label": 0
                },
                {
                    "sent": "If your objective was just Lipschitz, so instead of numerous continuity of the gradient you they're just bound on the difference of gradients.",
                    "label": 0
                },
                {
                    "sent": "OK, then you still have dimension independent rate of convergence but much worse wanted accuracy is 1 divided by epsilon squared.",
                    "label": 0
                },
                {
                    "sent": "Now at the step you should compute the value of the objective in its gradient at a point and there is certain computational overhead which for simple domains is that just linear in the dimension of the problem.",
                    "label": 1
                },
                {
                    "sent": "No, we'll all you can do with your objective is to compute its values and subgradients, then those bounds in the last scale piece, say when X is.",
                    "label": 0
                },
                {
                    "sent": "They're just unimprovable you cannot do, but.",
                    "label": 1
                },
                {
                    "sent": "And the also important fact that if you start from measuring the distances in the space and two in the Euclidean norm, you switched over norm and consequently the regularity of the gradients you measure in Infinity moment the conjugate normal.",
                    "label": 0
                },
                {
                    "sent": "Then the bonds remain essentially the same extra logarithmically name factor.",
                    "label": 1
                },
                {
                    "sent": "So then the dimension is now nearly demand that the convergence rate is nearly dimension independent.",
                    "label": 0
                },
                {
                    "sent": "No, all have first order methods.",
                    "label": 0
                },
                {
                    "sent": "As a matter of fact, they use black box representation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Object are sold, they come.",
                    "label": 0
                },
                {
                    "sent": "Get about this objective value, some gradients.",
                    "label": 0
                },
                {
                    "sent": "They do not know how to use other information, so those rate of convergence which we have seen the best you can get in the large scale case.",
                    "label": 0
                },
                {
                    "sent": "What are the consequences?",
                    "label": 0
                },
                {
                    "sent": "First of all, we see that the diameter of the visible domain it just enters.",
                    "label": 0
                },
                {
                    "sent": "The complexity bound.",
                    "label": 0
                },
                {
                    "sent": "No cases here.",
                    "label": 0
                },
                {
                    "sent": "The complexity is proportional to diameter and here it is.",
                    "label": 1
                },
                {
                    "sent": "Proportional to squirt diameter.",
                    "label": 0
                },
                {
                    "sent": "So the bounds of the feasible domain.",
                    "label": 1
                },
                {
                    "sent": "This theoretical is of paramount importance, and it follows that, say, coneless settings like in Las.",
                    "label": 1
                },
                {
                    "sent": "From the purely optimization you point there bit settings because here the domain is unbounded.",
                    "label": 0
                },
                {
                    "sent": "OK, and then what is essentially we're better from that?",
                    "label": 0
                },
                {
                    "sent": "Learn from the optimization point.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Perhaps there other reasons why you prefer models of this type.",
                    "label": 0
                },
                {
                    "sent": "Wear them this to the parameter to models of that type where the you just size of the domain on which you optimize.",
                    "label": 0
                },
                {
                    "sent": "Use the parameter, but from the optimization viewpoint those settings are much much better.",
                    "label": 1
                },
                {
                    "sent": "OK, now since the rate of convergence we can get his only sub linear.",
                    "label": 0
                },
                {
                    "sent": "You cannot hope to to solve the problem to hire furious Alexis certain digits OK, but as on the positive side, the kind of compare compensation if you end the last real case and you have favorite favorable geometry, those mid accuracy solutions can be obtained at the iteration cards in there, which is nearly dimension independent.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "OK, if you give Kim extract bound from this I don't understand her.",
                    "label": 0
                },
                {
                    "sent": "OK, if you can extract won't solve this problem.",
                    "label": 0
                },
                {
                    "sent": "This is my advice from the purely optimization viewpoint.",
                    "label": 0
                },
                {
                    "sent": "Holding the computer both the constraint set again.",
                    "label": 0
                },
                {
                    "sent": "Problem with.",
                    "label": 0
                },
                {
                    "sent": "It depends on what will be the bond.",
                    "label": 0
                },
                {
                    "sent": "If you're if you want to solve this problem within fixed accuracy 10 to the power minus three.",
                    "label": 0
                },
                {
                    "sent": "And the end is very small.",
                    "label": 0
                },
                {
                    "sent": "The solution may well happen, be very, very far.",
                    "label": 0
                },
                {
                    "sent": "OK, if you don't, if you have an additional balance on the normal solution, this is another story.",
                    "label": 0
                },
                {
                    "sent": "But the if you do not have this norm, yes, Anderson will be very, very far and it is very will be very difficult to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "OK, let me continue.",
                    "label": 0
                },
                {
                    "sent": "OK, we will discuss it later.",
                    "label": 0
                },
                {
                    "sent": "What I said.",
                    "label": 0
                },
                {
                    "sent": "I said OK if you have something in addition.",
                    "label": 0
                },
                {
                    "sent": "Talked about the solution.",
                    "label": 0
                },
                {
                    "sent": "This is difficult to the different story.",
                    "label": 0
                },
                {
                    "sent": "Then you also problem in a bounded domain with your penalization and you ask me, I don't understand for what the penalization, but you know.",
                    "label": 0
                },
                {
                    "sent": "But I mean you can always binary search for that number for the final.",
                    "label": 0
                },
                {
                    "sent": "Well, the the point is that if you learn this small will be very difficult for me to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so smooth problems are much better suited than non small for converse minimization.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello for the 1st order methods, but the difficulty is that OK you need both the domain simple otherwise steps will be difficult and the objective Smith and this is rare commodity so as many other breakthroughs and this in components optimization there is a breakthrough due to urine Nesterov many others.",
                    "label": 0
                },
                {
                    "sent": "There are many others breakthrough also due to him so notice very simple mindset fact that most mornings.",
                    "label": 0
                },
                {
                    "sent": "In corners, optimization primarily arises from taking motion.",
                    "label": 1
                },
                {
                    "sent": "So typically you can represent your non small subjective as maximum with respect to additional variable.",
                    "label": 0
                },
                {
                    "sent": "Also random bounded convex set off a smooth convex concave function fireworks way.",
                    "label": 0
                },
                {
                    "sent": "And then you can instead of solving this problem, you can use the knowledge of the structure to build such a representation and then solve this saddle point problem by first order methods and as a result you will get rid of convergence 1/4 of 1 / F said she's better than non smooth case, worse than smooth case but smooth.",
                    "label": 1
                },
                {
                    "sent": "Again it's something which is very rare commodity.",
                    "label": 0
                },
                {
                    "sent": "Let me give a bunch of examples of saddle point reformulations.",
                    "label": 0
                },
                {
                    "sent": "No, this is the simplest example.",
                    "label": 0
                },
                {
                    "sent": "You want to minimize maximum of smooth functions.",
                    "label": 0
                },
                {
                    "sent": "Know you immediately right at the saddle point problem.",
                    "label": 1
                },
                {
                    "sent": "Your way is just the standard SIM players.",
                    "label": 0
                },
                {
                    "sent": "Semi definite problem.",
                    "label": 0
                },
                {
                    "sent": "You want to minimize my maximal eigenvalue matter.",
                    "label": 0
                },
                {
                    "sent": "It's definitely depends on your variables maximum.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eigenvalues much more fingerprint of trace products of your matrix and the positive semi definite matrices with trace one.",
                    "label": 0
                },
                {
                    "sent": "So you get this.",
                    "label": 0
                },
                {
                    "sent": "Reformulation so this is difficult muscle function and this is just be linear cost function.",
                    "label": 0
                },
                {
                    "sent": "L1 minimization in this form new.",
                    "label": 0
                },
                {
                    "sent": "First you can reduce it to can reduce it to small series of problems when you are minimizing residual or anyone bull and this can be immediately converted to the saddle point and then we linear saddle point problem.",
                    "label": 0
                },
                {
                    "sent": "Nuclear norm minimization exactly is then the preview.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Example, so nuclear normous sum of singular values.",
                    "label": 0
                },
                {
                    "sent": "You want to minimize this nuclear norm given.",
                    "label": 1
                },
                {
                    "sent": "Bound on the residual uncertain linear system, again, you can reduce it to small series of parametric problems.",
                    "label": 1
                },
                {
                    "sent": "Everyone is on nuclear both.",
                    "label": 1
                },
                {
                    "sent": "Ride your Swan and this again is a simple saddle point problem.",
                    "label": 1
                },
                {
                    "sent": "SDP relaxation of low dimensional uniform approximation.",
                    "label": 0
                },
                {
                    "sent": "The problem is laid with you here in unit vectors in certain Aryan and K&U want to find dimensional subspace such that the maximum over the distance from the point of the subspace see the smallest possible.",
                    "label": 1
                },
                {
                    "sent": "It's not this problem by itself is a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "Then was optimization with respect to projectors, but in very few relax that the property to be projected.",
                    "label": 0
                },
                {
                    "sent": "If you passed a semi definite relaxation you'll get settled point problem.",
                    "label": 0
                },
                {
                    "sent": "Billionaire, now this is the problem, you know, better than me.",
                    "label": 0
                },
                {
                    "sent": "OK, parametric SVM problem.",
                    "label": 0
                },
                {
                    "sent": "First, if you have.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parameter here.",
                    "label": 0
                },
                {
                    "sent": "Again, from the optimization, you point is better to re parameterized this problem and pose the norm bound on the norm of your separator and then those constraints.",
                    "label": 0
                },
                {
                    "sent": "Under this restriction you minimize how you call.",
                    "label": 0
                },
                {
                    "sent": "It said we have errors.",
                    "label": 0
                },
                {
                    "sent": "Happy normal Day after of errors and the you can immediately rated Dallas billionaire saddle point problem one 1:30 is the set of.",
                    "label": 0
                },
                {
                    "sent": "Alpha vectors with this kernel norm less than or equal than one and another set is very very cheap.",
                    "label": 0
                },
                {
                    "sent": "Now, if you do not have kernel, have trivial kernel did this is the reformulation again linear saddle point problem.",
                    "label": 0
                },
                {
                    "sent": "OK, now what can we get when we?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solving those problems.",
                    "label": 0
                },
                {
                    "sent": "But first I am going to speak about approximate solutions.",
                    "label": 0
                },
                {
                    "sent": "We should agree have been measured you receive.",
                    "label": 0
                },
                {
                    "sent": "This is the natural accuracy measure, which is OK. How you need 25.",
                    "label": 1
                },
                {
                    "sent": "Issue of Peretz Way is approximate approximation to the saddle point of this function.",
                    "label": 0
                },
                {
                    "sent": "This is that the natural definition you take fields X.",
                    "label": 0
                },
                {
                    "sent": "And take the maximum of the cost function with respect to the second argument and subtract minimum.",
                    "label": 0
                },
                {
                    "sent": "We should see here on the transparency, so then let me explain what's going on here.",
                    "label": 0
                },
                {
                    "sent": "What does it mean to solve this certain point?",
                    "label": 0
                },
                {
                    "sent": "Problem Minister solve a pair of dual to each other quantities optimization problems in the primal problem.",
                    "label": 1
                },
                {
                    "sent": "You want to minimize over the set of spittle dysfunction overline for Fi, which is maximum of your cost function over way, and an adult problem.",
                    "label": 0
                },
                {
                    "sent": "You want to minimize this underlying file, which is minimum of your cost function over X is.",
                    "label": 0
                },
                {
                    "sent": "Those two problems have equal optimal values.",
                    "label": 1
                },
                {
                    "sent": "We in this situation and despise convex concave.",
                    "label": 1
                },
                {
                    "sent": "And the absence of which way is just some of inaccuracy is the.",
                    "label": 0
                },
                {
                    "sent": "What is the inaccuracy in terms of the objective of Earth as the solution to the primal problem?",
                    "label": 1
                },
                {
                    "sent": "And why is the solution to the do?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, what the there are several claims family intend to.",
                    "label": 0
                },
                {
                    "sent": "Support.",
                    "label": 0
                },
                {
                    "sent": "When the 1st Congress County, when gradient of phase Lipschitz continuous, then you can solve this problem by a good first order method that you receive Salem at the iteration count is inverse proportional to this Excel.",
                    "label": 1
                },
                {
                    "sent": "OK, now what is the cost of iteration?",
                    "label": 0
                },
                {
                    "sent": "It is one or two depending on the method computations of gradient of Phi at a point plus some computational overhead.",
                    "label": 1
                },
                {
                    "sent": "Those good methods there are several of them for the time being this is the very first Newton instead of new.",
                    "label": 0
                },
                {
                    "sent": "Smoothing method and this is the algorithm I'll speak about in this talk.",
                    "label": 0
                },
                {
                    "sent": "OK, now what are the constant factor hidden in this 01 divided by epsilon, not turns out that if X&Y possess favorable geometry, again, it will be explained later.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "OK, then the the those factors here, nearly independent of the dimension of the problem and the third claim is that you can further accelerate the 1st order methods by randomization.",
                    "label": 0
                },
                {
                    "sent": "What is meant so they said the 1st order method?",
                    "label": 0
                },
                {
                    "sent": "The deterministic requires computing the gradient of this fire to point at every step one or two gradients.",
                    "label": 0
                },
                {
                    "sent": "Now you Firefly is.",
                    "label": 0
                },
                {
                    "sent": "Say be linear as most of the examples we have seen.",
                    "label": 0
                },
                {
                    "sent": "Then that this computing gradient that is 1 automotrice vector multiplications.",
                    "label": 0
                },
                {
                    "sent": "If your problem is large.",
                    "label": 0
                },
                {
                    "sent": "Then all of the metrics have multiplications may become time consuming, and then you may gain from replacing precise first of the information by randomized.",
                    "label": 0
                },
                {
                    "sent": "Easier to compute estimates of the gradients and we'll see how we do it.",
                    "label": 0
                },
                {
                    "sent": "No, here there are.",
                    "label": 0
                },
                {
                    "sent": "There is also the complexity of the method.",
                    "label": 0
                },
                {
                    "sent": "I'm going to speak about.",
                    "label": 0
                },
                {
                    "sent": "So now the story.",
                    "label": 0
                },
                {
                    "sent": "What would your battery so assume that the domain of our saddle point problem extends?",
                    "label": 0
                },
                {
                    "sent": "Way belongs to assert, which is a direct product of K standard basic blocks.",
                    "label": 0
                },
                {
                    "sent": "What are those basic blocks?",
                    "label": 0
                },
                {
                    "sent": "You have a number of unit Euclidean balls, and you have a number of spectrograms, water spitter and they express of block diagonal.",
                    "label": 0
                },
                {
                    "sent": "Symmetric matrices of given book diagonal structure.",
                    "label": 0
                },
                {
                    "sent": "In this space you take positive semidefinite matrices of unit trace.",
                    "label": 0
                },
                {
                    "sent": "This course.",
                    "label": 0
                },
                {
                    "sent": "For example of your mattress is are just diagonal.",
                    "label": 0
                },
                {
                    "sent": "Tell them what you get is a spectrum.",
                    "label": 0
                },
                {
                    "sent": "Is the standard simplex coordination and negative and some of coordinates is equal to 1 diagonal matrix admits factory authority.",
                    "label": 0
                },
                {
                    "sent": "Your old this vector on the diagonal of the matrix?",
                    "label": 0
                },
                {
                    "sent": "OK, now if you have L1 bowl.",
                    "label": 0
                },
                {
                    "sent": "As the part of the domain is block OK, then L1 bull's image of twice standard simplex of twice larger dimension unde.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The simple made comparatively after awful one or not exceeding quantity can represent us difference of two non negative vectors with some of anyone non sequel to one.",
                    "label": 0
                },
                {
                    "sent": "So you can eliminate if you have a block which is in one bowl you can eliminate it, replace it with simplex.",
                    "label": 0
                },
                {
                    "sent": "And similarly for the nuclear bowl, pay for the nuclear bowl again at the nuclear ball is image of the standard torten standard spectator and positive definite matrices with trace one in twice larger dimension.",
                    "label": 1
                },
                {
                    "sent": "You also you also can eliminate them.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "What is important?",
                    "label": 0
                },
                {
                    "sent": "Also we so we are in this situation when we let's say normal off the domain.",
                    "label": 0
                },
                {
                    "sent": "TV made the part of.",
                    "label": 1
                },
                {
                    "sent": "Product of several Euclidean balls and several spectators, and that now embedding space of this Sir teaches product of several Euclidean spaces in several spaces of block diagonal symmetric matrices.",
                    "label": 1
                },
                {
                    "sent": "We equipped with this norm Euclidean aggregation of Euclidean norms on the Euclidean companions of direct product and trace norm.",
                    "label": 1
                },
                {
                    "sent": "Sum of a.",
                    "label": 0
                },
                {
                    "sent": "Absolute values sum of singular values of a symmetric mattress for the matrix components.",
                    "label": 0
                },
                {
                    "sent": "Now this is how the contributor.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It will be important now.",
                    "label": 0
                },
                {
                    "sent": "The result of camera on convergence complexity, so she assumed that you are solving the saddle point problem on the domain, which is part of the standard set.",
                    "label": 0
                },
                {
                    "sent": "This product of several Euclidean balls and several Spectra adrants, and your objective satisfies the fight.",
                    "label": 1
                },
                {
                    "sent": "The cost function satisfies the following bound.",
                    "label": 0
                },
                {
                    "sent": "The difference in the gradients measured in the dual norm.",
                    "label": 0
                },
                {
                    "sent": "We have equipped that the embedding space for this.",
                    "label": 1
                },
                {
                    "sent": "Done.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Meaning of our problem with certain norms.",
                    "label": 0
                },
                {
                    "sent": "So the gradients you should measure in the dual mode.",
                    "label": 0
                },
                {
                    "sent": "OK, is bounded by 8 times the distance between the points plus M, so we may think about phase.",
                    "label": 0
                },
                {
                    "sent": "It has Lipschitz continuous gradient of acquisitions, continuous abounded component L is the.",
                    "label": 0
                },
                {
                    "sent": "Leave just constant of delicious continuous component and M is the the norm of the bounded company.",
                    "label": 0
                },
                {
                    "sent": "Now how we observe this favor have a sister stochastic Oracle which reports unbiased estimates of gradients.",
                    "label": 0
                },
                {
                    "sent": "So when I called this Oracle at health step.",
                    "label": 0
                },
                {
                    "sent": "I want to compute the gradient at point zed from this domain.",
                    "label": 0
                },
                {
                    "sent": "So this is what I sent to the disk astic Oracle's input and this is what the Oracle returns them in certain deterministic function of that of the query point and Oracle noise Oracle noises from step to step independent, identically distributed and what we need is the following.",
                    "label": 1
                },
                {
                    "sent": "That's G of that size should be unbiased estimate of the true gradient.",
                    "label": 0
                },
                {
                    "sent": "And we imposed impose bounds on variability of this unbiased estimate.",
                    "label": 0
                },
                {
                    "sent": "So we take the the conjugate norm of the difference.",
                    "label": 0
                },
                {
                    "sent": "Or for estimating the trend, it's Expectation Square interview wanted this point it it should be less than miracle than M score.",
                    "label": 0
                },
                {
                    "sent": "Look that there is the same constant payment to two places.",
                    "label": 0
                },
                {
                    "sent": "Here it is responsible for not only should some component and Delta Phi here, this is for the responsible for the noise variability of my Oracle.",
                    "label": 0
                },
                {
                    "sent": "Of course there should be in principle to different constants, but the point is that what actually matters is their maximum.",
                    "label": 0
                },
                {
                    "sent": "And This is why I prefer to use the same constant and this is the result for every in the algorithm there is well defined.",
                    "label": 0
                },
                {
                    "sent": "Algorithm, doesn't matter how it looks like OK, it generates a random solution to our problem with expected and accuracy which is bounded by absolute constant times.",
                    "label": 0
                },
                {
                    "sent": "Not OK, we see here.",
                    "label": 0
                },
                {
                    "sent": "Let's look what we see.",
                    "label": 0
                },
                {
                    "sent": "First of all, what is this data?",
                    "label": 0
                },
                {
                    "sent": "Data is responsible for the geometry of your problem, and this is exactly the following could do you take how many balls you have in the description of the problem and at the number of both the dimensions of those Euclidean both absolutely reliable.",
                    "label": 0
                },
                {
                    "sent": "And some of the looks.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the dimensions of the specter drones and you take square root of this and this is that.",
                    "label": 0
                },
                {
                    "sent": "So this is something which reflects the geometry of your domain.",
                    "label": 0
                },
                {
                    "sent": "OK, now alien them reflex variability of your gradient of your free N as the number of steps when we see there is let's say smooth part in the bond which goes to zero inverse proportional to the number of steps and there is none.",
                    "label": 0
                },
                {
                    "sent": "Smooth the storm OK which she goes to zeros like 1 divided by square root of now it may say will happen that you have deterministic Oracle and M equal to 0 then this disappears you get come.",
                    "label": 0
                },
                {
                    "sent": "Conversions one over the number of steps.",
                    "label": 0
                },
                {
                    "sent": "OK, so this again is this bound.",
                    "label": 0
                },
                {
                    "sent": "Now what we need to do at a step we need to call absolute constant times so.",
                    "label": 0
                },
                {
                    "sent": "Two or three.",
                    "label": 0
                },
                {
                    "sent": "I also did talk also exactly 2 twice cause the stock istick Oracle and we have sort of computational overhead of C arithmetic operations on the top of it.",
                    "label": 0
                },
                {
                    "sent": "What we see depends on how what is yours at day hours.",
                    "label": 0
                },
                {
                    "sent": "It was only part in this product of standard blocks.",
                    "label": 1
                },
                {
                    "sent": "OK, if it is not very complicated, part of it that is the entire that password is cut off the plus by absolute constant number of linear inequalities.",
                    "label": 1
                },
                {
                    "sent": "Then this is the what is the computational overhead dimension of the domain plus effort of value decomposition of the matrix for the product hospital address.",
                    "label": 0
                },
                {
                    "sent": "What we see here.",
                    "label": 0
                },
                {
                    "sent": "First of all, if.",
                    "label": 1
                },
                {
                    "sent": "The number of blocks, ball blocks, and spectator and block.",
                    "label": 0
                },
                {
                    "sent": "So I feel is fixed then the this efficiency estimate is nearly not affected by the dimension.",
                    "label": 1
                },
                {
                    "sent": "The only place where dimension that comes in is that those logs of sizes of spectator and blows.",
                    "label": 0
                },
                {
                    "sent": "But they're only lots of those sizes.",
                    "label": 0
                },
                {
                    "sent": "OK, and Moreover, if yours at this product of the two bowl, so more than to both fixed number of both, then this efficiency is an improbable.",
                    "label": 0
                },
                {
                    "sent": "In the last staircase.",
                    "label": 0
                },
                {
                    "sent": "No, and if.",
                    "label": 0
                },
                {
                    "sent": "Your all your spectrograms are Simplicius.",
                    "label": 0
                },
                {
                    "sent": "OK, then the overhead is just linear in the dimension of the problem, the Methodist cheap.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, you have also.",
                    "label": 0
                },
                {
                    "sent": "If you assume that your noises and Oracle have.",
                    "label": 0
                },
                {
                    "sent": "Light deals more.",
                    "label": 0
                },
                {
                    "sent": "Here is the exact.",
                    "label": 0
                },
                {
                    "sent": "Go to see them that this OK, if you indeed you statistique not deterministic Oracle then you're.",
                    "label": 0
                },
                {
                    "sent": "Solution is random and the previous result was only what is the expected inaccuracy.",
                    "label": 0
                },
                {
                    "sent": "But you have also the slight taste stale assumption on the noises you have exponential bounds on large deviations.",
                    "label": 1
                },
                {
                    "sent": "OK, now let's think how could we randomize first of the method.",
                    "label": 0
                },
                {
                    "sent": "So let's look at problem with billing your cost function.",
                    "label": 1
                },
                {
                    "sent": "Most of the problems in fact there like this.",
                    "label": 0
                },
                {
                    "sent": "Many problems, at least like this.",
                    "label": 0
                },
                {
                    "sent": "So in this situation, what is this first order information?",
                    "label": 0
                },
                {
                    "sent": "You should compute the derivative with respect to X.",
                    "label": 0
                },
                {
                    "sent": "It is a transposed way.",
                    "label": 0
                },
                {
                    "sent": "And the derivative is stripped away is a year, so you should carry out to matrix vector multiplications, appoint from escaped or you should multiply by E and the poet from why you should multiply by transpose.",
                    "label": 0
                },
                {
                    "sent": "OK, now how could you randomize such a competition?",
                    "label": 0
                },
                {
                    "sent": "Sweet, easy.",
                    "label": 0
                },
                {
                    "sent": "How could you randomize matrix vector multiplication?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The absolute values of interest in you reactor X and divide them by there you will get more negative of entry.",
                    "label": 0
                },
                {
                    "sent": "Sequel to one.",
                    "label": 0
                },
                {
                    "sent": "Think about this.",
                    "label": 0
                },
                {
                    "sent": "Water is about probability distribution on the set of windows is pick a random index J according to this distribution there's J. Cole and I have materials B. Multiplying it by sign of Xion by L1 norm of X you will get a random vector just proportional to certain randomly chosen column and you be.",
                    "label": 1
                },
                {
                    "sent": "Now, this immediately assume that the expectation of the swifter is the product BX we want to compute new.",
                    "label": 0
                },
                {
                    "sent": "You have also controlling the norm of the theater.",
                    "label": 0
                },
                {
                    "sent": "OK, but this is.",
                    "label": 0
                },
                {
                    "sent": "Well, in upper bound on the normal this randomly actor.",
                    "label": 0
                },
                {
                    "sent": "Now what is the call cost of this Oracle?",
                    "label": 1
                },
                {
                    "sent": "OK, it's just linear indecisa so would be where you need or of B.",
                    "label": 0
                },
                {
                    "sent": "There are times then you need often operations to generate this G and then you need air.",
                    "label": 0
                },
                {
                    "sent": "My parations to extract the column from the Matrix.",
                    "label": 1
                },
                {
                    "sent": "Now you can also call this query Oracle several times and tell David which of the answers in order to reduce the noise.",
                    "label": 0
                },
                {
                    "sent": "OK, let's look how it works.",
                    "label": 0
                },
                {
                    "sent": "So this is everyone minimes.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation of uniform feet.",
                    "label": 0
                },
                {
                    "sent": "So I want to minimize normal fares minus B Infinity.",
                    "label": 0
                },
                {
                    "sent": "No more access from any one ball.",
                    "label": 0
                },
                {
                    "sent": "You can immediately read this problem as Saddle point problem.",
                    "label": 0
                },
                {
                    "sent": "What will be important for us is the maximum of absolute.",
                    "label": 0
                },
                {
                    "sent": "Of magnitudes of entries in your mattress, see Now if the airmen there now large, then what is the best known complexity of finding epsilon solution for this problem?",
                    "label": 1
                },
                {
                    "sent": "By deterministic algorithms, the number of steps is like elevated by epsilon elevated.",
                    "label": 0
                },
                {
                    "sent": "But now you're silent, divided by its natural relative accuracy in our program.",
                    "label": 0
                },
                {
                    "sent": "OK, the fence log of.",
                    "label": 0
                },
                {
                    "sent": "Size of the problem.",
                    "label": 0
                },
                {
                    "sent": "This is the number of steps at every step you need to carry out to matrix.",
                    "label": 0
                },
                {
                    "sent": "We're multiplications, so the arithmetic complexity is quadratic is after this load factor is quadratic in the size by product of the sizes and inverse proportional to Excel.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that if you randomize matrix you after multiplications you again.",
                    "label": 0
                },
                {
                    "sent": "Adept and algorithm, which OK much larger number of steps Lunger.",
                    "label": 1
                },
                {
                    "sent": "OK, OK, this algorithm produces upsell on solution with confidence 1 minus Britain birthday is you give to me and this is OK.",
                    "label": 0
                },
                {
                    "sent": "It nearly doesn't affect the complexity as we see from the formal visit.",
                    "label": 0
                },
                {
                    "sent": "The number of steps it is inversely proportional to the squirt accuracy instead of accuracy.",
                    "label": 0
                },
                {
                    "sent": "But the steps that ship every step that effort is just linear in the sizes.",
                    "label": 0
                },
                {
                    "sent": "So the total arithmetic effort is as you see here on the transparency.",
                    "label": 0
                },
                {
                    "sent": "It is nearly linear in the size of the problem.",
                    "label": 1
                },
                {
                    "sent": "Instead of being nearly quadratic.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you're ill and epsilon and better I fixed in them and then a large then did this method randomized algorithm by orders of magnitude outperforms the terministic algorithms and Moreover there's device what's called sub linear time behavior.",
                    "label": 0
                },
                {
                    "sent": "Look, this is the total number of.",
                    "label": 0
                },
                {
                    "sent": "Arithmetic operations will carry out so, so the the number of entries in the Matrix A which we inspected is less than what we see here, and mattress has entries.",
                    "label": 0
                },
                {
                    "sent": "So when M and their knowledge and allow the same order, we get an epsilon solution with great confidence.",
                    "label": 0
                },
                {
                    "sent": "You can take this better equal to temple to the power minus 12.",
                    "label": 1
                },
                {
                    "sent": "OK bye inspected only negligible part of the data.",
                    "label": 0
                },
                {
                    "sent": "This is not a new phenomenon.",
                    "label": 0
                },
                {
                    "sent": "OK, sensually.",
                    "label": 0
                },
                {
                    "sent": "This problem can be reduced from Automotrice game and for Mattress Games in mid 90s.",
                    "label": 0
                },
                {
                    "sent": "But every Addison Richie and discovered the sub linear time algorithm and Donna closest inspection here hand said their algorithm is very very similar to what this.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stochastic mirror process.",
                    "label": 0
                },
                {
                    "sent": "The advantage of stochastic mirror process that you build this algorithm is a particular case of certain general construction.",
                    "label": 0
                },
                {
                    "sent": "You can use this construction also in other situations.",
                    "label": 0
                },
                {
                    "sent": "OK, now when you instead of.",
                    "label": 0
                },
                {
                    "sent": "Minimizing Infinity norm of the residual want to minimize two norm.",
                    "label": 0
                },
                {
                    "sent": "Not let me just OK that the now what is responsible that the scale proper scale factor in the problem is maximum of Euclidean norms of columns in a not maximum of absolute value software.",
                    "label": 0
                },
                {
                    "sent": "OK, in both cases this is the norm of this mapping.",
                    "label": 0
                },
                {
                    "sent": "Earth is mapped to X when X is that we have two L1 norm.",
                    "label": 0
                },
                {
                    "sent": "And if you use it with the norm dual to the what you see here 2 dual to the North Pole that is ITO.",
                    "label": 0
                },
                {
                    "sent": "Sorry, we are exactly the same Long Beach.",
                    "label": 0
                },
                {
                    "sent": "We measured the receipt though not the door.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we will determine Istic methods that the complexity is as you see on the transparency and the number of arithmetic operations like MN divided by Epsilon view from the mistargeted.",
                    "label": 0
                },
                {
                    "sent": "It is like this, you still fear quadratic in the size entry term in the complexity MN log, but this storm is not multiplied by one or web selling or whatever.",
                    "label": 0
                },
                {
                    "sent": "OK, what is affected by accuracy?",
                    "label": 0
                },
                {
                    "sent": "Is only that this linear in the moment or so it looks like you carry outfits number independent of upsell full matrix.",
                    "label": 0
                },
                {
                    "sent": "We after multiplications that this logarithmic and number full mattress vector multiplications and then you start to extract roles and qualities.",
                    "label": 0
                },
                {
                    "sent": "No, you cannot stand this.",
                    "label": 0
                },
                {
                    "sent": "What was this L Infinity mean OK?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "L1 minimization we will Infinity feet.",
                    "label": 0
                },
                {
                    "sent": "In fact it was minimizing or with simplex maximum of M friend forms.",
                    "label": 0
                },
                {
                    "sent": "You can replace those fine forms by polynomials of convex polynomial.",
                    "label": 0
                },
                {
                    "sent": "So forgiven degree and you have essentially the same result.",
                    "label": 0
                },
                {
                    "sent": "Also again you can randomize.",
                    "label": 0
                },
                {
                    "sent": "OK, and now just numerical examples.",
                    "label": 0
                },
                {
                    "sent": "How many what they might have.",
                    "label": 0
                },
                {
                    "sent": "How many time I have?",
                    "label": 0
                },
                {
                    "sent": "Say it again.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "OK, so we'll start with the Terministic 1st order methods and then we will look water addition and it can be obtained via randomization.",
                    "label": 0
                },
                {
                    "sent": "So this is an Infinity fit on one.",
                    "label": 0
                },
                {
                    "sent": "Bull, your matrix is slave compensation.",
                    "label": 0
                },
                {
                    "sent": "Set into matrix is obtained from.",
                    "label": 0
                },
                {
                    "sent": "Discrete for their transform mattress.",
                    "label": 0
                },
                {
                    "sent": "You just take a trend of em rose in the discrete.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Via transform mattress and the data generated as follows, we start with generating the sparse signal.",
                    "label": 0
                },
                {
                    "sent": "Actually we've still non zero entries of one on one.",
                    "label": 0
                },
                {
                    "sent": "Then we multiplied by this matrix we add noise which in the uniform normal as you see on the transparency.",
                    "label": 0
                },
                {
                    "sent": "This gives us B and now we want.",
                    "label": 0
                },
                {
                    "sent": "To solve this problem to recover signal.",
                    "label": 0
                },
                {
                    "sent": "So what we're interested in is not how we solve this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "What we're interested in is how the solution of it.",
                    "label": 0
                },
                {
                    "sent": "How will it approximates the true signal?",
                    "label": 0
                },
                {
                    "sent": "And here are the results in the table.",
                    "label": 0
                },
                {
                    "sent": "So what we see in the accuracy columns L1 error of recovery, 2 error of recovery and Infinity error of recovery.",
                    "label": 0
                },
                {
                    "sent": "Here are the sizes of the matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, this is relatively small example and we compared the terministic.",
                    "label": 0
                },
                {
                    "sent": "Mirror pro salgari.",
                    "label": 0
                },
                {
                    "sent": "We've interior point method with Mazda quote.",
                    "label": 0
                },
                {
                    "sent": "Now what we see in this relatively small example.",
                    "label": 0
                },
                {
                    "sent": "Mirror the interior point method worked, but it takes like 100 times more time then.",
                    "label": 0
                },
                {
                    "sent": "The Terministic algorithm and also the.",
                    "label": 0
                },
                {
                    "sent": "Up if worst solution again.",
                    "label": 0
                },
                {
                    "sent": "Of course it better solve the optimization problem, but the record.",
                    "label": 0
                },
                {
                    "sent": "But the what happens is kind of over here, but the notion build a.",
                    "label": 0
                },
                {
                    "sent": "First of the method where Terry produces the true signal by factor of 10.",
                    "label": 0
                },
                {
                    "sent": "Now of course, here that the this.",
                    "label": 0
                },
                {
                    "sent": "The Terministic method uses the fact that you eat comes from discrete Fourier transform matrix.",
                    "label": 0
                },
                {
                    "sent": "So metrics vector multiplications are cheap there nearly linear.",
                    "label": 0
                },
                {
                    "sent": "You can use facts for you.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transform to compute those matrix vector multiplications.",
                    "label": 0
                },
                {
                    "sent": "OK, now larger sizes 1000 * 4013 point method is already out of memory.",
                    "label": 0
                },
                {
                    "sent": "Cannot do anything more and you see that this.",
                    "label": 0
                },
                {
                    "sent": "First of the methods works perfectly well that the size is 4000 * 16,000.",
                    "label": 0
                },
                {
                    "sent": "No interior point method to even be do not tested this discrete deterministic mirror process.",
                    "label": 0
                },
                {
                    "sent": "Everything just fine.",
                    "label": 0
                },
                {
                    "sent": "You solve the problem to reasonably high accuracy.",
                    "label": 0
                },
                {
                    "sent": "In like less than one minute.",
                    "label": 0
                },
                {
                    "sent": "So here are the pictures.",
                    "label": 0
                },
                {
                    "sent": "The true signal trees and spirit.",
                    "label": 0
                },
                {
                    "sent": "Don't know what the difference.",
                    "label": 0
                },
                {
                    "sent": "Between.",
                    "label": 0
                },
                {
                    "sent": "At the cabin.",
                    "label": 0
                },
                {
                    "sent": "No, this is Jean 1 music.",
                    "label": 0
                },
                {
                    "sent": "Patient will be said, OK, we've already know what is there right now.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh my God this.",
                    "label": 0
                },
                {
                    "sent": "It was Vietnam.",
                    "label": 0
                },
                {
                    "sent": "In the OneNote.",
                    "label": 0
                },
                {
                    "sent": "If you had one bowl, this is a problem in one of X given upper bound one.",
                    "label": 0
                },
                {
                    "sent": "Pretty cool.",
                    "label": 0
                },
                {
                    "sent": "In certain vineyards.",
                    "label": 0
                },
                {
                    "sent": "They used to.",
                    "label": 0
                },
                {
                    "sent": "Will you both you speak?",
                    "label": 0
                },
                {
                    "sent": "Don't feed the people.",
                    "label": 0
                },
                {
                    "sent": "Talk to Euclidean feet, not here.",
                    "label": 0
                },
                {
                    "sent": "I had the results.",
                    "label": 0
                },
                {
                    "sent": "Then I will say that there is also pretty good.",
                    "label": 0
                },
                {
                    "sent": "With all that AIM assist within.",
                    "label": 0
                },
                {
                    "sent": "90 seconds and accuracy is reasonably good.",
                    "label": 0
                },
                {
                    "sent": "No, this is example.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, couple minutes to explain.",
                    "label": 0
                },
                {
                    "sent": "There's something about compressed sensing if you I incomprehension situation you may ask how could we justify that?",
                    "label": 0
                },
                {
                    "sent": "Given sentient matrix and it allows to recover exactly all sparse signals with given number of non zero entries.",
                    "label": 0
                },
                {
                    "sent": "If there is no observation noise, how could we check that they get whatever?",
                    "label": 0
                },
                {
                    "sent": "If you still have 5 nonzeros then it will be recovered.",
                    "label": 0
                },
                {
                    "sent": "Properly by L1 minimization, there is a simple verifiable sufficient condition for its distribution condition, as you see on the transparency and.",
                    "label": 1
                },
                {
                    "sent": "Essentially it says optimal value on certain.",
                    "label": 0
                },
                {
                    "sent": "Linear programming problem where your matrix A gives the date of this problem should be less than 1/2.",
                    "label": 0
                },
                {
                    "sent": "If there's less than 1/2 that, then your mattress see OK.",
                    "label": 0
                },
                {
                    "sent": "This problem depends on the parameters on the parameter of the number of nonzeros in the true signal and the case, or if the optimal values less than 1/2 that then.",
                    "label": 0
                },
                {
                    "sent": "Every sheet movie first known zeros will be in the absence of noise will be recovered.",
                    "label": 0
                },
                {
                    "sent": "Exactly.",
                    "label": 0
                },
                {
                    "sent": "OK, but now OK, if you want to check this, if this is verifiable conditions reduces to help.",
                    "label": 0
                },
                {
                    "sent": "If you want to check it, you need to solve this LP and if your mattress is not very large pits says this is a as you see on the transparency, not this LP.",
                    "label": 0
                },
                {
                    "sent": "OK, the number of.",
                    "label": 1
                },
                {
                    "sent": "Variables and constraints in this LP is quadratic in the larger size of the matrix C, so in the for this reasonably small matrix.",
                    "label": 1
                },
                {
                    "sent": "Very small in scale of compensation that this problem LP has like 130,000 constraints and variables and linear programming solver which I have a is unable to solve it.",
                    "label": 0
                },
                {
                    "sent": "No, but you can reduce this problem to settle point billionaire saddle point problem.",
                    "label": 0
                },
                {
                    "sent": "Solve it with deterministic mirror prox.",
                    "label": 1
                },
                {
                    "sent": "OK so that you know exactly as a result of this solution under the optimal value is less than or have a great OK and the computation.",
                    "label": 0
                },
                {
                    "sent": "OK it's not first, but that is the sushi one hour plus something.",
                    "label": 0
                },
                {
                    "sent": "OK, now what randomization can do in addition to what first of the deterministic 1st order methods, this again is the same problem with the starter.",
                    "label": 0
                },
                {
                    "sent": "You fell one minimization in the simple setting have minimizing Infinity norm of the residual linear system or well one bowl.",
                    "label": 0
                },
                {
                    "sent": "OK, but now your matrix is not.",
                    "label": 0
                },
                {
                    "sent": "Submatrix of discrete for you or for DfT.",
                    "label": 0
                },
                {
                    "sent": "It is sort of this analytically given matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, and here are examples of two is results of two experiments.",
                    "label": 0
                },
                {
                    "sent": "Those are the sizes of the matrix.",
                    "label": 0
                },
                {
                    "sent": "In the first experiment goes as a society that still I can store this matrix in ram of my computer.",
                    "label": 0
                },
                {
                    "sent": "Morning baby will solve the problem by deterministic mirror professor by Stochastic Mirror Prox and you see that the terministic mirror process much, much better.",
                    "label": 0
                },
                {
                    "sent": "It was like 3 times better in terms of time and that this like 10 times better in terms of the accuracy of the solution you get.",
                    "label": 0
                },
                {
                    "sent": "The only wish OK with it.",
                    "label": 0
                },
                {
                    "sent": "She's not very relevant in this situation, but the only thing is like this when you looking at this randomized matrix vector multiplication.",
                    "label": 0
                },
                {
                    "sent": "1000 of them.",
                    "label": 0
                },
                {
                    "sent": "You can think how many full matrix we have for multiplications will have the same complexity.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that that this stochastic mirror process carried out.",
                    "label": 0
                },
                {
                    "sent": "I don't remember like 20,000 of those randomized matrix vector multiplications, but this was equivalent to like 30.",
                    "label": 0
                },
                {
                    "sent": "Full matrix vector multiplications and the the Terministic algorithm.",
                    "label": 0
                },
                {
                    "sent": "Credit out much more mattress with multiplications, but that doesn't matter in this size in the sizes because still the terministic method is faster and more accurate, but if you now increase the size as to what you see on the transparency, then now the matrix.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I cannot store it in the memory of my computer, so together to operate to set up any mattress with multiplication, I should compute the Rose 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "Or the columns dependent for what they are multiplying the given total formulas.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, and now it turns out that single mattress with her multiplication cost like 500 of seconds, so 3 and 3000 seconds I allowed to algorithm to run the terministic algorithm was credited, was able to carry out five mattress with her, multiplication cannot get anything meaningful.",
                    "label": 0
                },
                {
                    "sent": "Now in stock I stepped nearer crooks.",
                    "label": 0
                },
                {
                    "sent": "Also totally of credit out even less than five mattress with multiplications, but they're warm.",
                    "label": 0
                },
                {
                    "sent": "That they will like 30,000 of steps.",
                    "label": 0
                },
                {
                    "sent": "Again, at the very least, if you just extract row and column from the matrix and the solution.",
                    "label": 0
                },
                {
                    "sent": "OK, I wouldn't say that that you receive is were very, very evil, but the reasonable list if you see on the picture you do not see if you see anything that you definitely do not see difference between the true signal, the recovery.",
                    "label": 0
                },
                {
                    "sent": "OK, in the last example is low dimensional approximation so that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here the example is like this.",
                    "label": 0
                },
                {
                    "sent": "You have 1100 thousand points.",
                    "label": 0
                },
                {
                    "sent": "Unit vectors in of dimension 100.",
                    "label": 1
                },
                {
                    "sent": "You know that there exist in the nature 10 dimensional linear subspace or to you from which all the points out the distance at most.",
                    "label": 0
                },
                {
                    "sent": "Oh Point 2 and we want to find such a subspace.",
                    "label": 1
                },
                {
                    "sent": "So this is the deep relaxation of the problem.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "OK, if you pee would be the projector on the dimensional space, then what you are doing.",
                    "label": 0
                },
                {
                    "sent": "You are so dear.",
                    "label": 0
                },
                {
                    "sent": "Yes, exactly P should be the projector on 10 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Then this minimum of all Asia.",
                    "label": 0
                },
                {
                    "sent": "Unit we have to solve this minimum wage transposed PG or I is OK is the same as the maximal of the distances from the point P. Pay that for the distance to be less than oh point 2 this minimum should be greater than oh point 8.",
                    "label": 0
                },
                {
                    "sent": "OK, that this the squad number of the projection on the subspace it should be large.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we maximize the food aspect appears but update with respect to projector something dimensional subspace this we don't know how to do its thing.",
                    "label": 0
                },
                {
                    "sent": "Not real problem but we can relax it say OK that instead of maximizing respective projectors we can maximize respect to positive definite matrices.",
                    "label": 0
                },
                {
                    "sent": "Very good values not exceeding one and sum of eigenvalues not exceeding 10 and then it becomes a good problem.",
                    "label": 0
                },
                {
                    "sent": "OK, now given a solution to this problem AP, how we produce from a 10 dimensional subspace?",
                    "label": 0
                },
                {
                    "sent": "Not very easy.",
                    "label": 0
                },
                {
                    "sent": "You take take leading cable connectors and said the linear spam is disturbed dimensional space given by the speed and then when we run the algorithm you produce subsequent piece.",
                    "label": 0
                },
                {
                    "sent": "Every time you check whether this subspace given 10 dimensional subspace driven by this P approximates all the points, we will not accuracy or .21 or point.",
                    "label": 0
                },
                {
                    "sent": "We know that this is something which exists in the nature OK or use.",
                    "label": 0
                },
                {
                    "sent": "Total waste.",
                    "label": 0
                },
                {
                    "sent": "Those random samples.",
                    "label": 0
                },
                {
                    "sent": "The problems turned out to be very very simple for discrete.",
                    "label": 0
                },
                {
                    "sent": "For the Terministic 1st order methods repeat that so it was solved.",
                    "label": 0
                },
                {
                    "sent": "Justin 17.",
                    "label": 0
                },
                {
                    "sent": "Oracle calls 17 matrix where multiplication is the mattress maximal deviation of the points from the subspace we end up with is OK as it should be open to, but it took 507.",
                    "label": 1
                },
                {
                    "sent": "Seconds if you randomize.",
                    "label": 0
                },
                {
                    "sent": "The algorithm the number of calls to the stochastic Oracle is much higher 700 something, but all them totally amount to oh point 3 call to to deterministic Oracle you get a curious solution of nearly the same accuracy, But the time is like 12 by factor 12.",
                    "label": 0
                },
                {
                    "sent": "This is all thank you.",
                    "label": 0
                },
                {
                    "sent": "Let me see with the full OK. Don't OK. First aid dancewear is not I don't know the second I don't understand what would be average case complexity in this situation where from do you take distribution on the instances?",
                    "label": 0
                },
                {
                    "sent": "Just a second I randomize by my own.",
                    "label": 0
                },
                {
                    "sent": "I did not randomize the problem.",
                    "label": 0
                },
                {
                    "sent": "Again, I did not randomize the problem.",
                    "label": 0
                },
                {
                    "sent": "What I am saying is that whatever problem forgiven family you give to me, your probability, which again give me OK.",
                    "label": 0
                },
                {
                    "sent": "The deer, meat and probability.",
                    "label": 0
                },
                {
                    "sent": "1 -- 10 to the power minus 12.",
                    "label": 0
                },
                {
                    "sent": "I'll solve this problem with this probability with this security and it and that number amount of with this and this computational effort.",
                    "label": 0
                },
                {
                    "sent": "I don't know even how to pose the question like this.",
                    "label": 0
                },
                {
                    "sent": "OK, you have ensemble of problems.",
                    "label": 0
                },
                {
                    "sent": "I am ready to survive that.",
                    "label": 0
                },
                {
                    "sent": "The fact that on 1% of those problems I will fail.",
                    "label": 0
                },
                {
                    "sent": "So I'm interested what is the average performance for my algorithm ever is being taken over the distribution on problems I don't know how to pose this question because in my opinion there absolutely no natural distributions on the sets of problems.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe if you indeed have a situation when you know what is the distribution.",
                    "label": 0
                },
                {
                    "sent": "Then the question could be posed.",
                    "label": 0
                },
                {
                    "sent": "Bye bye.",
                    "label": 0
                },
                {
                    "sent": "I just still sit that I do not know how to do it and they know do not know anybody who knows.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Specific things?",
                    "label": 0
                },
                {
                    "sent": "Talking about getting the gradient.",
                    "label": 0
                },
                {
                    "sent": "Response to when we were talking about dipping set in their noses random over there.",
                    "label": 0
                },
                {
                    "sent": "OK, this situation yes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let me OK this is so if I understood correctly the correct password.",
                    "label": 0
                },
                {
                    "sent": "If you are in situation of genius stochastic programming problem, then again this could be applied.",
                    "label": 0
                },
                {
                    "sent": "OK the I just said OK before I started deterministic problem I introduce randomness because I want to accelerate.",
                    "label": 0
                },
                {
                    "sent": "You can also think about situations when my objective is given by the expectation.",
                    "label": 0
                },
                {
                    "sent": "OK, and they do not know how I can only sample.",
                    "label": 0
                },
                {
                    "sent": "Then again, all this becomes applicable.",
                    "label": 0
                },
                {
                    "sent": "OK, the overhead and overhead is OK.",
                    "label": 0
                },
                {
                    "sent": "It is just linear in the dimension.",
                    "label": 0
                },
                {
                    "sent": "OK, but nevertheless this is over here.",
                    "label": 0
                },
                {
                    "sent": "The number of simple iterations was like 30,000.",
                    "label": 0
                },
                {
                    "sent": "OKM 30,000 times I was supposed to carry out projections.",
                    "label": 0
                },
                {
                    "sent": "Those projections are linear, but nevertheless this is overhead.",
                    "label": 0
                },
                {
                    "sent": "The number of matrix with vector multiplications is small equivalent number, but the overhead is the overhead.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Can also be derived in the online adversarial setting, so at least the similar results.",
                    "label": 0
                },
                {
                    "sent": "Excursion beginning destiny are valid only also in the online adversarial setting where the sequence of estimates is an arbitrary sequence and the performance is quite negative to the average over Saturday, and I'm not sure that OK, I'm not machine learning person, so I don't know.",
                    "label": 0
                },
                {
                    "sent": "Similar results are described at the beginning of the results for US acoustic estimation.",
                    "label": 0
                },
                {
                    "sent": "When you have the Lipschitz or smooth functions.",
                    "label": 0
                },
                {
                    "sent": "Guarantees or almost exact thing where you don't assume that the estimates are custom, so you're using.",
                    "label": 0
                },
                {
                    "sent": "This must be stochastic, must be unbiased.",
                    "label": 0
                },
                {
                    "sent": "Acoustic estimates OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So what not?",
                    "label": 0
                },
                {
                    "sent": "Well, they could be the terministic, of course.",
                    "label": 0
                },
                {
                    "sent": "Yes, look response to the situation is set empty row.",
                    "label": 0
                },
                {
                    "sent": "M20.",
                    "label": 0
                },
                {
                    "sent": "Doing the analysis on each step separately, so doing working as if you're in the stochastic setting, so I'm not doing not working with Mystic setting.",
                    "label": 0
                },
                {
                    "sent": "Working when you're getting the best runtime guarantees because you're working in single estimates at the time, but these estimates are not actually estimate.",
                    "label": 0
                },
                {
                    "sent": "There are serious.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure that they understood.",
                    "label": 0
                },
                {
                    "sent": "OK, OK.",
                    "label": 0
                }
            ]
        }
    }
}