{
    "id": "mdsxdmf5wcapzqyyktse2z6w3susbens",
    "title": "Macquarie RT05s Speaker Diarisation System",
    "info": {
        "author": [
            "Steve Cassidy, Macquarie University"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2005",
        "category": [
            "Top->Computer Science->Social Media"
        ]
    },
    "url": "http://videolectures.net/mlmi04uk_cassidy_mrsds/",
    "segmentation": [
        [
            "Support wasn't quite able to make it to the to the meeting, but there you go.",
            "I made it this time.",
            "So the goal for.",
            "Project was to basically just from sort of basically scratch develop."
        ],
        [
            "Speaker system capable of performing the speaker task end to end.",
            "This is a fairly new thing for myself and so it's basically a matter of getting into the task and getting something working.",
            "Building a platform for experimentation for future work and student projects and so on.",
            "And hopefully this year anyway, improving on the RT 04 system that we put in last year to put into context the.",
            "Overall performance of my system is the."
        ],
        [
            "Blackline so basically, if you manage to do worse than me, you're doing something really, really wrong.",
            "This is a fairly simple."
        ],
        [
            "System the resources that I've got available to build it are fairly limited.",
            "I'd hope to have some funding this year to push this along a bit faster, but that's not that's not arrived, so it's basically a one person effort.",
            "So what I built is basically a very basic system that is able to form that ask users fairly standard materials and nothing will be very surprising here about how things go together.",
            "Single distant microphone task only I did had hoped to try the MDM task this year, but that didn't quite workout.",
            "I'll say something about that later on.",
            "Implemented in C and tickle, it runs around six times real time on a single system.",
            "And all the development was done with the RTO Four Test DEF test data set.",
            "So in particular I didn't see any.",
            "Am I or Vt data another BT that it wasn't available before hand but didn't look at our data before running the evaluation?",
            "The figure on the left just shows the sort of overall.",
            "Run of the system feature extraction.",
            "I mean it's all fairly standard.",
            "I'll go through each of these stages.",
            "I explain how this thing works.",
            "Feature extraction was 26 coefficients consisting of MFC CS 12."
        ],
        [
            "MCCS RMS energy in the Delta coefficients.",
            "For each of these top 10 milliseconds, mean subtraction based on the 1st 60 seconds of each file subtracted from the mean subtracted from the rest of the segments, and this is.",
            "Calculated using the Cth snack toolkit.",
            "The first step then is to do speech activity detection.",
            "Last year we had a system based."
        ],
        [
            "On energy thresholds this year, in sort of hope to improve on that, I introduced a GMM based speech nonspeech Classifier 2 model classifier.",
            "The speech model based on 32 mixtures and non speech model based on 8 mixtures trained on a small section of the RTO for dev test data is only trained on fairly small amount of data.",
            "In order to generate data for this, I took the standard reference labels and basically pulled out the OR agglomerated all the speaker sections and the silence region between.",
            "Ignoring science less than 3.3 seconds and just fed that name into this to class model.",
            "The overall forms of that is not not spectacular, so."
        ],
        [
            "We get non speech errors on unseen RTO.",
            "Four data of 32% and 90% on speech.",
            "This is being adjusted a little bit to basically mean the goal of the whole thing is not to throw away bits of speech.",
            "Obviously these are interesting throwing away bits of silence or nonspeech is not too much of a trouble.",
            "So we err on the side of throwing away silence.",
            "The performance on the RTO five data as shown below.",
            "So again we're getting a much higher rate of error on.",
            "Nonspeech and speech.",
            "To actually do the segmentation, though, those are the sort of raw speech, right?"
        ],
        [
            "Or frame rate errors to actually do the segmentation, we classify 10 frames at a time using the mixture models and label.",
            "Those either speech or nonspeech and then throw away any regions of nonspeech less than .35 seconds and then throw away regions of speech less than .15 seconds just to get some consecutive labelings.",
            "The one way of looking at the evaluation of this or a couple of valuation metrics.",
            "On this we can look at the flat frame based classification error.",
            "That is how many frames of speech or nonspeech we get wrong.",
            "Another way of looking at is to look at the number of boundaries that get missed.",
            "So the number of speech nonspeech boundaries that this algorithm doesn't find within half a second.",
            "That is, the boundary that over the that I've used, and the number of boundaries that get inserted inside real segments.",
            "The motivation behind this is that missing boundaries is a big deal.",
            "You don't want to do that too much.",
            "Inserting science things inside segments isn't such a big deal because you can sort of pass recover from that later.",
            "So these are the sort of results that we get for just a selection of the eval data, and you can see that."
        ],
        [
            "The nonspeech error is in the frame rate when we take into account the sort of agglomeration over the signal is quite high, spectacularly high on the Vt data where you can see so the column on the right.",
            "Here is the number of automatic segments found, so in this particular BT file, the algorithm found no snow nonspeech whatsoever, and so basically just put one marked the beginning of the end.",
            "So to start with, then the speech activity detector is not doing a particularly good job of finding bits of silence or bits of nonspeech.",
            "At least it's not throwing away a great deal of speech, and that was primarily the goal of this section was just to find whatever segmentations it was possible to find and not throw away anything interesting.",
            "We all have a missing an awful lot of the real boundaries, and inserting quite a lot of false boundaries.",
            "So once this segmentation is available then we want to sub segment these regions of speech."
        ],
        [
            "Two speaker sections.",
            "This is done using a big based segmenter, which compares the fit of a single Gaussian model to a pair of single Gaussian models on each side of the breaker.",
            "Standard BIC algorithm.",
            "The version that we used, or the algorithm used basically takes a fixed window of 200 frames of speech and just moves it along the portion of speech being segmented and then looks for pick peaks in the Delta big curve and takes those as.",
            "Segmentation change points is a bit of a change from last year.",
            "Last year we use the the sort of fairly standard method of having growing windows.",
            "We found that this produces essentially the same results in much less time, so it was it was famous for that reason.",
            "It doesn't produce particularly good results, but in this case, but at least produces a similar one, so the last time."
        ],
        [
            "So these are some of the results of the just the segmentation part of the task.",
            "So this then compounds the errors that we've already got from the silence detection.",
            "As you can see, the number of so the numbers next to the samples there 168 on the Vt cases, the number of boundaries that get inserted in this case, or number of boundaries that are found.",
            "So we find 168 speaker segments or single speaker segment boundaries.",
            "In the BT case.",
            "The red line there is the number of false positives.",
            "The number of boundaries that we insert inside of real speech segments and the green line is the number of speech segments or the proportion of speech segments boundaries that we miss, and so in most cases we're missing quite a lot and but not inserting too many.",
            "Unfortunately it's the green ones that are bad and the red ones that are not so bad, so things would be better.",
            "The approach to clustering and identification of speakers now is to first of all perform a turn clustering."
        ],
        [
            "Stage where we take the speaker turns and find any natural or the goal will be to try and find some natural clusters in that set of turns.",
            "Of course the number of clusters in each of these meetings is unknown, so requires either some guess as to how many there are or some metric and cluster evaluation metric that we can perform.",
            "So in order to do this we need some kind of distance metric on speaker turns so that we can compare speaker turns.",
            "Also your clustering album and.",
            "We need to be able to say how many clusters is the right number of clusters, cause some clustering albums.",
            "Sort of spit out the number of clusters as a byproduct.",
            "In the case that we looked at, we.",
            "Didn't we perform?"
        ],
        [
            "Oracle clustering are going to that in a second.",
            "This is just a picture to sort of illustrate are sort of debugging technique or a visualization technique that I was using to try and evaluate distance metrics between speaker clusters.",
            "This is just data taken from some of the reference files and the reference files are the RTM files nicely ordered on.",
            "The speakers, all the all one speaker to occurs first and two second speakers per second.",
            "So you can quite easily look at the distance matrix between the speakers and ideally what you'd see if you had a good nice speaker turn distance metric would be a diagram like this where the red indicates a close correlation between a close distance between the speakers and yellow indicates a further distance, and so we'd see a sort of checkerboard pattern like this.",
            "And so in searching for a reasonable and good and well performing distance metric, we're looking for something like this.",
            "The that wasn't supposed to happen.",
            "OK, so my slides not working so you can't see how.",
            "That looks underneath, so underneath there.",
            "If I was able to reveal that you'd see a real version of this distance metric that they mean, and variance of the feature vectors on the and KL distance.",
            "In this case doesn't perform very well.",
            "What you see is a trying to visualize this, a sort of at the bottom left hand corner looks reasonably good in terms of distance, and everything else looks sort of fuzzy and so on.",
            "So as part of the evaluation, the developer was not yet able to find a sort of good performing.",
            "Distance metric, and therefore any clustering that we try and perform on.",
            "This is not really going to be able to.",
            "Do as well, but it might be able to.",
            "The approach to clustering that I took in the system was to first of all select segments that are being fair."
        ],
        [
            "Under Iran with a duration of greater than 1 1/2 seconds.",
            "And then to perform a clustering based on a distance matrix based on KL distance between the means and variances, former hierarchical clustering.",
            "Just because that was easily available and then select from that hierarchal clustering labelings consisting of say 2345 and 6:00 or so on Labour speakers or clusters in that these sets of speaker labelings are then passed to the next stage which tries to evaluate which of those is the best.",
            "Because of time constraints in the evaluation I actually only ended up doing two or three.",
            "Speakers instead of two up to about seven or eight, which I would hope to do.",
            "So the final stage then tries to do speaker identification, where we take the."
        ],
        [
            "Labeled clusters as performed earlier and basically use those labeled turns to train gas mixture models for each of those speakers, and again, we're using 32 mixture GMM's to do that.",
            "And take all of the turns and re classify those relabel those.",
            "Part of that is to say, OK, we want to.",
            "Well, most of the time you'd expect to Re label the same things with the same speaker.",
            "Part of that is to sort of perhaps try and sort of purify things a little bit, in that you might.",
            "Get rid of some outliers and put them in the appropriate place in that state.",
            "Of course, in building these models there's a fairly small amount of data, and especially in some of the meetings and some of the strings that we get where they're actually my only be three or four turns to support this model, and so we don't get particularly good models.",
            "Unfortunately in that case.",
            "So here the overall results.",
            "As you can see, there's for most of the time we are.",
            "Nicely above."
        ],
        [
            "Of all of the rest, if only this wasn't an error curve, I'd be much happier.",
            "The observations here when it's obviously you can see from this plot that there are some meetings that are harder than others.",
            "The one of the second Dixie meeting and the second BT meeting, obviously difficult ones for all of the all of the systems.",
            "I'm particularly proud of this point here, where I'm not.",
            "I'm not the worst of the, so if you're either pink or or blue then boy you're bad no no.",
            "So the two meetings that we that that other see many sort of really good patterns.",
            "Yeah nice to be able to say well look what the problem is is that the meetings I hadn't seen before where we do particularly badly, but in fact the best score that I get is one of the team meetings.",
            "And the MI meetings seem to be particularly hard for for this system, and I think one of the reasons is the silent.",
            "The silent areas are quite difficult to find, not having models which which fit that data particularly well in the Vt case it was actually very hard to find any silence regions.",
            "I think this second one here was the one where we basically didn't find any any silence at all, and so.",
            "That's that's the problem there overall, of course that the main problems of this are in the segmentation.",
            "The models that we're using our sort of very fairly sparsely supported in the data.",
            "They're not trained on large amounts of data.",
            "They're not sophisticated, well fitting models.",
            "The big segmentation again is based on simple Gaussians which don't fit very well at all, and so there's a lot of work to go into the segmentation part and all the other bits and pieces as well.",
            "This wasn't the only thing I tried, So what ends up being in the final system was what basically worked."
        ],
        [
            "Uses answers at the end in building this and putting this together.",
            "A bunch of things that we tried that didn't work or produce suggestive results, but not not particularly good results.",
            "Not good enough to go into, they would have pushed the black line even higher.",
            "One of the things that we looked at, and this is sort of the attempt at the MDM system was to look at interchannel phase and level different differences.",
            "There's a PhD student that I'm working with, two who's looking at looking at multi channel.",
            "Speech and looking at interchannel phase and level differences to basically help in the segmentation process that at the moment is at the stage where it performs quite well on data that is nice and clean and sort of artificially created.",
            "Meeting room like data.",
            "But when we run it through the the real meeting data it produces basically line line noise.",
            "So there's work to be done there into in building that into a usable.",
            "System, but there is indicative results that suggest it might be a good thing to do.",
            "One thing I looked at in trying to do the segmentation as well was instead of looking at sort of just a plain acoustic signal, was to try and look at Exemplar speaker models.",
            "Mean motivation behind this part is that a lot of the models that I'm looking at here are very sparsely supported, and so you sort of think that well.",
            "If you've got lots of meeting data, values should be able to build good models to some extent.",
            "And one of the ways that I thought of using these models to take a number of exemplars, and instead of trying to segment based on on the acoustic models, try try and basically take each of the frames or turns and classify them according to some exemplars, and then try and then sort of segment according to that.",
            "Initial trials sort of suggested that this might be a reasonable thing to do in, but I didn't really have time to push that much further.",
            "The problem, I think, is choosing good exemplars.",
            "Ideally, I think if you had a if you were looking at particular series of meetings and had people that were at those all the time, then exemplars out of that sort of cohort of people elected to be there might be good ones to choose in doing that, and finally, just to mention one thing that's singular value decomposition based turn clustering, there's.",
            "Uh, this one and experimental or method of clustering that I was playing with based on SVD, SVD has a nice problem finding similar groups by factoring the distance matrix and is commonly used in sort of other areas, and one of the nice things about that is that one of the byproducts of it is a number of clusters, so it will not only tell you that this is a clustering, but you know that there are four or three or whatever clusters the thing that held that back basically was the lack of a good distance metric in the visualization, and I showed before.",
            "Didn't work very well, and that's all.",
            "Thanks very much.",
            "Question.",
            "If not, I'm just for one or two.",
            "So I'm I actually curious.",
            "I have since you're spending last year what your thoughts were on the transition from last year to this year.",
            "The new data sources and some other really you felt really learn more about meeting room Contacts about, yeah?",
            "The main problem in transition from last year to this year was.",
            "Basically time to put into development of any new system.",
            "So in fact, in practice what happened is that I almost worked on essentially the same data as last year and so then basically took the took the validator as it arrived and run it through so I didn't do a lot of transitioning from last year.",
            "I just talk more about this in the discussion.",
            "Yeah yeah.",
            "So we should move on to our next speaker over his waiting here.",
            "So next we'll hear from touring who will be speaking."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Support wasn't quite able to make it to the to the meeting, but there you go.",
                    "label": 0
                },
                {
                    "sent": "I made it this time.",
                    "label": 0
                },
                {
                    "sent": "So the goal for.",
                    "label": 0
                },
                {
                    "sent": "Project was to basically just from sort of basically scratch develop.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Speaker system capable of performing the speaker task end to end.",
                    "label": 0
                },
                {
                    "sent": "This is a fairly new thing for myself and so it's basically a matter of getting into the task and getting something working.",
                    "label": 0
                },
                {
                    "sent": "Building a platform for experimentation for future work and student projects and so on.",
                    "label": 1
                },
                {
                    "sent": "And hopefully this year anyway, improving on the RT 04 system that we put in last year to put into context the.",
                    "label": 0
                },
                {
                    "sent": "Overall performance of my system is the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Blackline so basically, if you manage to do worse than me, you're doing something really, really wrong.",
                    "label": 0
                },
                {
                    "sent": "This is a fairly simple.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "System the resources that I've got available to build it are fairly limited.",
                    "label": 0
                },
                {
                    "sent": "I'd hope to have some funding this year to push this along a bit faster, but that's not that's not arrived, so it's basically a one person effort.",
                    "label": 0
                },
                {
                    "sent": "So what I built is basically a very basic system that is able to form that ask users fairly standard materials and nothing will be very surprising here about how things go together.",
                    "label": 0
                },
                {
                    "sent": "Single distant microphone task only I did had hoped to try the MDM task this year, but that didn't quite workout.",
                    "label": 0
                },
                {
                    "sent": "I'll say something about that later on.",
                    "label": 0
                },
                {
                    "sent": "Implemented in C and tickle, it runs around six times real time on a single system.",
                    "label": 1
                },
                {
                    "sent": "And all the development was done with the RTO Four Test DEF test data set.",
                    "label": 0
                },
                {
                    "sent": "So in particular I didn't see any.",
                    "label": 0
                },
                {
                    "sent": "Am I or Vt data another BT that it wasn't available before hand but didn't look at our data before running the evaluation?",
                    "label": 0
                },
                {
                    "sent": "The figure on the left just shows the sort of overall.",
                    "label": 0
                },
                {
                    "sent": "Run of the system feature extraction.",
                    "label": 0
                },
                {
                    "sent": "I mean it's all fairly standard.",
                    "label": 0
                },
                {
                    "sent": "I'll go through each of these stages.",
                    "label": 0
                },
                {
                    "sent": "I explain how this thing works.",
                    "label": 0
                },
                {
                    "sent": "Feature extraction was 26 coefficients consisting of MFC CS 12.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "MCCS RMS energy in the Delta coefficients.",
                    "label": 1
                },
                {
                    "sent": "For each of these top 10 milliseconds, mean subtraction based on the 1st 60 seconds of each file subtracted from the mean subtracted from the rest of the segments, and this is.",
                    "label": 1
                },
                {
                    "sent": "Calculated using the Cth snack toolkit.",
                    "label": 0
                },
                {
                    "sent": "The first step then is to do speech activity detection.",
                    "label": 0
                },
                {
                    "sent": "Last year we had a system based.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On energy thresholds this year, in sort of hope to improve on that, I introduced a GMM based speech nonspeech Classifier 2 model classifier.",
                    "label": 0
                },
                {
                    "sent": "The speech model based on 32 mixtures and non speech model based on 8 mixtures trained on a small section of the RTO for dev test data is only trained on fairly small amount of data.",
                    "label": 0
                },
                {
                    "sent": "In order to generate data for this, I took the standard reference labels and basically pulled out the OR agglomerated all the speaker sections and the silence region between.",
                    "label": 0
                },
                {
                    "sent": "Ignoring science less than 3.3 seconds and just fed that name into this to class model.",
                    "label": 0
                },
                {
                    "sent": "The overall forms of that is not not spectacular, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We get non speech errors on unseen RTO.",
                    "label": 0
                },
                {
                    "sent": "Four data of 32% and 90% on speech.",
                    "label": 0
                },
                {
                    "sent": "This is being adjusted a little bit to basically mean the goal of the whole thing is not to throw away bits of speech.",
                    "label": 0
                },
                {
                    "sent": "Obviously these are interesting throwing away bits of silence or nonspeech is not too much of a trouble.",
                    "label": 0
                },
                {
                    "sent": "So we err on the side of throwing away silence.",
                    "label": 0
                },
                {
                    "sent": "The performance on the RTO five data as shown below.",
                    "label": 0
                },
                {
                    "sent": "So again we're getting a much higher rate of error on.",
                    "label": 0
                },
                {
                    "sent": "Nonspeech and speech.",
                    "label": 0
                },
                {
                    "sent": "To actually do the segmentation, though, those are the sort of raw speech, right?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or frame rate errors to actually do the segmentation, we classify 10 frames at a time using the mixture models and label.",
                    "label": 0
                },
                {
                    "sent": "Those either speech or nonspeech and then throw away any regions of nonspeech less than .35 seconds and then throw away regions of speech less than .15 seconds just to get some consecutive labelings.",
                    "label": 0
                },
                {
                    "sent": "The one way of looking at the evaluation of this or a couple of valuation metrics.",
                    "label": 0
                },
                {
                    "sent": "On this we can look at the flat frame based classification error.",
                    "label": 1
                },
                {
                    "sent": "That is how many frames of speech or nonspeech we get wrong.",
                    "label": 0
                },
                {
                    "sent": "Another way of looking at is to look at the number of boundaries that get missed.",
                    "label": 0
                },
                {
                    "sent": "So the number of speech nonspeech boundaries that this algorithm doesn't find within half a second.",
                    "label": 0
                },
                {
                    "sent": "That is, the boundary that over the that I've used, and the number of boundaries that get inserted inside real segments.",
                    "label": 1
                },
                {
                    "sent": "The motivation behind this is that missing boundaries is a big deal.",
                    "label": 0
                },
                {
                    "sent": "You don't want to do that too much.",
                    "label": 0
                },
                {
                    "sent": "Inserting science things inside segments isn't such a big deal because you can sort of pass recover from that later.",
                    "label": 0
                },
                {
                    "sent": "So these are the sort of results that we get for just a selection of the eval data, and you can see that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The nonspeech error is in the frame rate when we take into account the sort of agglomeration over the signal is quite high, spectacularly high on the Vt data where you can see so the column on the right.",
                    "label": 0
                },
                {
                    "sent": "Here is the number of automatic segments found, so in this particular BT file, the algorithm found no snow nonspeech whatsoever, and so basically just put one marked the beginning of the end.",
                    "label": 0
                },
                {
                    "sent": "So to start with, then the speech activity detector is not doing a particularly good job of finding bits of silence or bits of nonspeech.",
                    "label": 0
                },
                {
                    "sent": "At least it's not throwing away a great deal of speech, and that was primarily the goal of this section was just to find whatever segmentations it was possible to find and not throw away anything interesting.",
                    "label": 0
                },
                {
                    "sent": "We all have a missing an awful lot of the real boundaries, and inserting quite a lot of false boundaries.",
                    "label": 0
                },
                {
                    "sent": "So once this segmentation is available then we want to sub segment these regions of speech.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two speaker sections.",
                    "label": 0
                },
                {
                    "sent": "This is done using a big based segmenter, which compares the fit of a single Gaussian model to a pair of single Gaussian models on each side of the breaker.",
                    "label": 0
                },
                {
                    "sent": "Standard BIC algorithm.",
                    "label": 0
                },
                {
                    "sent": "The version that we used, or the algorithm used basically takes a fixed window of 200 frames of speech and just moves it along the portion of speech being segmented and then looks for pick peaks in the Delta big curve and takes those as.",
                    "label": 0
                },
                {
                    "sent": "Segmentation change points is a bit of a change from last year.",
                    "label": 0
                },
                {
                    "sent": "Last year we use the the sort of fairly standard method of having growing windows.",
                    "label": 0
                },
                {
                    "sent": "We found that this produces essentially the same results in much less time, so it was it was famous for that reason.",
                    "label": 0
                },
                {
                    "sent": "It doesn't produce particularly good results, but in this case, but at least produces a similar one, so the last time.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are some of the results of the just the segmentation part of the task.",
                    "label": 0
                },
                {
                    "sent": "So this then compounds the errors that we've already got from the silence detection.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the number of so the numbers next to the samples there 168 on the Vt cases, the number of boundaries that get inserted in this case, or number of boundaries that are found.",
                    "label": 0
                },
                {
                    "sent": "So we find 168 speaker segments or single speaker segment boundaries.",
                    "label": 0
                },
                {
                    "sent": "In the BT case.",
                    "label": 0
                },
                {
                    "sent": "The red line there is the number of false positives.",
                    "label": 0
                },
                {
                    "sent": "The number of boundaries that we insert inside of real speech segments and the green line is the number of speech segments or the proportion of speech segments boundaries that we miss, and so in most cases we're missing quite a lot and but not inserting too many.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately it's the green ones that are bad and the red ones that are not so bad, so things would be better.",
                    "label": 0
                },
                {
                    "sent": "The approach to clustering and identification of speakers now is to first of all perform a turn clustering.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stage where we take the speaker turns and find any natural or the goal will be to try and find some natural clusters in that set of turns.",
                    "label": 0
                },
                {
                    "sent": "Of course the number of clusters in each of these meetings is unknown, so requires either some guess as to how many there are or some metric and cluster evaluation metric that we can perform.",
                    "label": 0
                },
                {
                    "sent": "So in order to do this we need some kind of distance metric on speaker turns so that we can compare speaker turns.",
                    "label": 0
                },
                {
                    "sent": "Also your clustering album and.",
                    "label": 0
                },
                {
                    "sent": "We need to be able to say how many clusters is the right number of clusters, cause some clustering albums.",
                    "label": 0
                },
                {
                    "sent": "Sort of spit out the number of clusters as a byproduct.",
                    "label": 0
                },
                {
                    "sent": "In the case that we looked at, we.",
                    "label": 0
                },
                {
                    "sent": "Didn't we perform?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oracle clustering are going to that in a second.",
                    "label": 0
                },
                {
                    "sent": "This is just a picture to sort of illustrate are sort of debugging technique or a visualization technique that I was using to try and evaluate distance metrics between speaker clusters.",
                    "label": 0
                },
                {
                    "sent": "This is just data taken from some of the reference files and the reference files are the RTM files nicely ordered on.",
                    "label": 0
                },
                {
                    "sent": "The speakers, all the all one speaker to occurs first and two second speakers per second.",
                    "label": 0
                },
                {
                    "sent": "So you can quite easily look at the distance matrix between the speakers and ideally what you'd see if you had a good nice speaker turn distance metric would be a diagram like this where the red indicates a close correlation between a close distance between the speakers and yellow indicates a further distance, and so we'd see a sort of checkerboard pattern like this.",
                    "label": 0
                },
                {
                    "sent": "And so in searching for a reasonable and good and well performing distance metric, we're looking for something like this.",
                    "label": 0
                },
                {
                    "sent": "The that wasn't supposed to happen.",
                    "label": 0
                },
                {
                    "sent": "OK, so my slides not working so you can't see how.",
                    "label": 0
                },
                {
                    "sent": "That looks underneath, so underneath there.",
                    "label": 0
                },
                {
                    "sent": "If I was able to reveal that you'd see a real version of this distance metric that they mean, and variance of the feature vectors on the and KL distance.",
                    "label": 1
                },
                {
                    "sent": "In this case doesn't perform very well.",
                    "label": 0
                },
                {
                    "sent": "What you see is a trying to visualize this, a sort of at the bottom left hand corner looks reasonably good in terms of distance, and everything else looks sort of fuzzy and so on.",
                    "label": 0
                },
                {
                    "sent": "So as part of the evaluation, the developer was not yet able to find a sort of good performing.",
                    "label": 0
                },
                {
                    "sent": "Distance metric, and therefore any clustering that we try and perform on.",
                    "label": 0
                },
                {
                    "sent": "This is not really going to be able to.",
                    "label": 0
                },
                {
                    "sent": "Do as well, but it might be able to.",
                    "label": 0
                },
                {
                    "sent": "The approach to clustering that I took in the system was to first of all select segments that are being fair.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under Iran with a duration of greater than 1 1/2 seconds.",
                    "label": 0
                },
                {
                    "sent": "And then to perform a clustering based on a distance matrix based on KL distance between the means and variances, former hierarchical clustering.",
                    "label": 1
                },
                {
                    "sent": "Just because that was easily available and then select from that hierarchal clustering labelings consisting of say 2345 and 6:00 or so on Labour speakers or clusters in that these sets of speaker labelings are then passed to the next stage which tries to evaluate which of those is the best.",
                    "label": 0
                },
                {
                    "sent": "Because of time constraints in the evaluation I actually only ended up doing two or three.",
                    "label": 0
                },
                {
                    "sent": "Speakers instead of two up to about seven or eight, which I would hope to do.",
                    "label": 0
                },
                {
                    "sent": "So the final stage then tries to do speaker identification, where we take the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Labeled clusters as performed earlier and basically use those labeled turns to train gas mixture models for each of those speakers, and again, we're using 32 mixture GMM's to do that.",
                    "label": 1
                },
                {
                    "sent": "And take all of the turns and re classify those relabel those.",
                    "label": 0
                },
                {
                    "sent": "Part of that is to say, OK, we want to.",
                    "label": 0
                },
                {
                    "sent": "Well, most of the time you'd expect to Re label the same things with the same speaker.",
                    "label": 0
                },
                {
                    "sent": "Part of that is to sort of perhaps try and sort of purify things a little bit, in that you might.",
                    "label": 0
                },
                {
                    "sent": "Get rid of some outliers and put them in the appropriate place in that state.",
                    "label": 1
                },
                {
                    "sent": "Of course, in building these models there's a fairly small amount of data, and especially in some of the meetings and some of the strings that we get where they're actually my only be three or four turns to support this model, and so we don't get particularly good models.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately in that case.",
                    "label": 0
                },
                {
                    "sent": "So here the overall results.",
                    "label": 0
                },
                {
                    "sent": "As you can see, there's for most of the time we are.",
                    "label": 0
                },
                {
                    "sent": "Nicely above.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of all of the rest, if only this wasn't an error curve, I'd be much happier.",
                    "label": 0
                },
                {
                    "sent": "The observations here when it's obviously you can see from this plot that there are some meetings that are harder than others.",
                    "label": 0
                },
                {
                    "sent": "The one of the second Dixie meeting and the second BT meeting, obviously difficult ones for all of the all of the systems.",
                    "label": 0
                },
                {
                    "sent": "I'm particularly proud of this point here, where I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not the worst of the, so if you're either pink or or blue then boy you're bad no no.",
                    "label": 0
                },
                {
                    "sent": "So the two meetings that we that that other see many sort of really good patterns.",
                    "label": 0
                },
                {
                    "sent": "Yeah nice to be able to say well look what the problem is is that the meetings I hadn't seen before where we do particularly badly, but in fact the best score that I get is one of the team meetings.",
                    "label": 0
                },
                {
                    "sent": "And the MI meetings seem to be particularly hard for for this system, and I think one of the reasons is the silent.",
                    "label": 0
                },
                {
                    "sent": "The silent areas are quite difficult to find, not having models which which fit that data particularly well in the Vt case it was actually very hard to find any silence regions.",
                    "label": 0
                },
                {
                    "sent": "I think this second one here was the one where we basically didn't find any any silence at all, and so.",
                    "label": 0
                },
                {
                    "sent": "That's that's the problem there overall, of course that the main problems of this are in the segmentation.",
                    "label": 0
                },
                {
                    "sent": "The models that we're using our sort of very fairly sparsely supported in the data.",
                    "label": 0
                },
                {
                    "sent": "They're not trained on large amounts of data.",
                    "label": 0
                },
                {
                    "sent": "They're not sophisticated, well fitting models.",
                    "label": 0
                },
                {
                    "sent": "The big segmentation again is based on simple Gaussians which don't fit very well at all, and so there's a lot of work to go into the segmentation part and all the other bits and pieces as well.",
                    "label": 0
                },
                {
                    "sent": "This wasn't the only thing I tried, So what ends up being in the final system was what basically worked.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Uses answers at the end in building this and putting this together.",
                    "label": 0
                },
                {
                    "sent": "A bunch of things that we tried that didn't work or produce suggestive results, but not not particularly good results.",
                    "label": 0
                },
                {
                    "sent": "Not good enough to go into, they would have pushed the black line even higher.",
                    "label": 0
                },
                {
                    "sent": "One of the things that we looked at, and this is sort of the attempt at the MDM system was to look at interchannel phase and level different differences.",
                    "label": 0
                },
                {
                    "sent": "There's a PhD student that I'm working with, two who's looking at looking at multi channel.",
                    "label": 0
                },
                {
                    "sent": "Speech and looking at interchannel phase and level differences to basically help in the segmentation process that at the moment is at the stage where it performs quite well on data that is nice and clean and sort of artificially created.",
                    "label": 1
                },
                {
                    "sent": "Meeting room like data.",
                    "label": 0
                },
                {
                    "sent": "But when we run it through the the real meeting data it produces basically line line noise.",
                    "label": 0
                },
                {
                    "sent": "So there's work to be done there into in building that into a usable.",
                    "label": 0
                },
                {
                    "sent": "System, but there is indicative results that suggest it might be a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "One thing I looked at in trying to do the segmentation as well was instead of looking at sort of just a plain acoustic signal, was to try and look at Exemplar speaker models.",
                    "label": 0
                },
                {
                    "sent": "Mean motivation behind this part is that a lot of the models that I'm looking at here are very sparsely supported, and so you sort of think that well.",
                    "label": 0
                },
                {
                    "sent": "If you've got lots of meeting data, values should be able to build good models to some extent.",
                    "label": 0
                },
                {
                    "sent": "And one of the ways that I thought of using these models to take a number of exemplars, and instead of trying to segment based on on the acoustic models, try try and basically take each of the frames or turns and classify them according to some exemplars, and then try and then sort of segment according to that.",
                    "label": 0
                },
                {
                    "sent": "Initial trials sort of suggested that this might be a reasonable thing to do in, but I didn't really have time to push that much further.",
                    "label": 0
                },
                {
                    "sent": "The problem, I think, is choosing good exemplars.",
                    "label": 0
                },
                {
                    "sent": "Ideally, I think if you had a if you were looking at particular series of meetings and had people that were at those all the time, then exemplars out of that sort of cohort of people elected to be there might be good ones to choose in doing that, and finally, just to mention one thing that's singular value decomposition based turn clustering, there's.",
                    "label": 1
                },
                {
                    "sent": "Uh, this one and experimental or method of clustering that I was playing with based on SVD, SVD has a nice problem finding similar groups by factoring the distance matrix and is commonly used in sort of other areas, and one of the nice things about that is that one of the byproducts of it is a number of clusters, so it will not only tell you that this is a clustering, but you know that there are four or three or whatever clusters the thing that held that back basically was the lack of a good distance metric in the visualization, and I showed before.",
                    "label": 1
                },
                {
                    "sent": "Didn't work very well, and that's all.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "If not, I'm just for one or two.",
                    "label": 0
                },
                {
                    "sent": "So I'm I actually curious.",
                    "label": 0
                },
                {
                    "sent": "I have since you're spending last year what your thoughts were on the transition from last year to this year.",
                    "label": 0
                },
                {
                    "sent": "The new data sources and some other really you felt really learn more about meeting room Contacts about, yeah?",
                    "label": 0
                },
                {
                    "sent": "The main problem in transition from last year to this year was.",
                    "label": 0
                },
                {
                    "sent": "Basically time to put into development of any new system.",
                    "label": 0
                },
                {
                    "sent": "So in fact, in practice what happened is that I almost worked on essentially the same data as last year and so then basically took the took the validator as it arrived and run it through so I didn't do a lot of transitioning from last year.",
                    "label": 0
                },
                {
                    "sent": "I just talk more about this in the discussion.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "So we should move on to our next speaker over his waiting here.",
                    "label": 0
                },
                {
                    "sent": "So next we'll hear from touring who will be speaking.",
                    "label": 0
                }
            ]
        }
    }
}