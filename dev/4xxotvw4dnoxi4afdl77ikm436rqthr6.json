{
    "id": "4xxotvw4dnoxi4afdl77ikm436rqthr6",
    "title": "Building and Using a Knowledge Graph to Combat Human Trafficking",
    "info": {
        "author": [
            "Giuseppe Pirr\u00f2, Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR), National Research Council (CNR)"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_szekely_human_trafficking/",
    "segmentation": [
        [
            "My name is Pedro Zachary from the University of Southern California, so I'll present the work we've been doing on building and using a knowledge graph to combat human trafficking."
        ],
        [
            "So human trafficking is a really bad problem worldwide.",
            "I'll give you some statistic."
        ],
        [
            "The profits of the industry per year is 32 billion.",
            "The average entry of girls into prostitution in the US is 14 years old.",
            "Pimps make $150,000 a year per victim.",
            "And they often have six victims.",
            "The advertising budget on the Web is $45,000,000.",
            "Which means that there are lots and lots millions of classified ads for escorts which are really sex ads."
        ],
        [
            "So suppose you are a police investigator.",
            "You're trying to track down trafficker.",
            "And you want to know the cities.",
            "Where a potential victim has been advertised.",
            "So the tool that they used today is Google."
        ],
        [
            "So this is what they do.",
            "They put a search term Jessica Blue eyes, red hair supposed to be Swedish.",
            "And they get lots of results.",
            "Over 1,000,000 results through this query.",
            "You can see from the top results that San Diego is definitely one of the cities.",
            "But the investigator wants to know all the cities because they want to build a history of what has been done to this person.",
            "That means that they have to browse a lot of Google pages.",
            "Now the goal of our project is really to give them a better way of doing this."
        ],
        [
            "So if we look at the web pages.",
            "We see that the data that we need is in the web pages in the first one, we see that it mentions Santa Barbara.",
            "The second mentions Tyson Square in Washington DC.",
            "Problem is, there's about 100 million pages.",
            "So what we want to do?"
        ],
        [
            "Who?",
            "Is extract the information from this pages and build a knowledge graph.",
            "So a suitable model for this page is that it's about an offer.",
            "It's an offer for an adult service.",
            "The offer has a price, a date where the offer is valid and a place.",
            "And there's a seller.",
            "And very often in this domain we know very little about the sellers.",
            "Here we know a phone number.",
            "The item being provided is an adult service and we have some data about this service.",
            "You know we know the person is called Jessica has.",
            "Blue eyes and red hair.",
            "Now here's the."
        ],
        [
            "Another ad, so the goal is you know if we can build the same kind of graph for another ad and then connect these graphs together.",
            "Then we suddenly know there's two offers for the same service from the same seller."
        ],
        [
            "And then we can answer our question.",
            "The cities we can read them off the graph.",
            "Now of course the goal is to build a graph that can answer many, many more questions because investigators have many, many more questions."
        ],
        [
            "So what does this have to do with semantic web?",
            "We don't have linked data about escorts.",
            "But you know, we solve inspired by David Karger stock in 2013.",
            "Where he was asking us.",
            "You know we should be building applications that show how semantic web can solve problems that we have right now.",
            "So we have a human trafficking problem is a problem that police investigators need to solve right now.",
            "And you know, very appropriate for us is the idea that he said the Semantic Web application is 1 whose schema is expected to change.",
            "And in fact.",
            "The schema that I'm going to show you today in the slides is different from the schema that was on the paper.",
            "The schema has already evolved, it almost evolves every two weeks.",
            "When we discover a new way of thinking about the problem, new attributes that we can extract."
        ],
        [
            "So this is the architecture of the system.",
            "It's all like the Google chain we crawl because there's no link data we need to get the data from web pages.",
            "We run extractors and we welcome in our system any extractor.",
            "If you have an extractor that can extract some of the data, this data we can integrate it.",
            "What we end up is with a lot of structured data in all kinds of different schemas, because every extractor has its own schema.",
            "So the next step is to map all this data into a comment on teologi.",
            "So and after that.",
            "So what we end up with is this little graphs that are all using the same classes and properties but are disconnected.",
            "Entity linking is what connects these little pieces of grass into a soft, coherent large graph that then we can deploy and then search.",
            "So I'll show you what we do in each of these steps."
        ],
        [
            "The crawling were crawling the main sites for escort ads.",
            "They're listed there on that side of the slide.",
            "The crawlers are running continuously.",
            "Downloading about 2000 new pages per hour.",
            "By now we have a database with about 68 million web.",
            "No ads and we run the tool chain every hour.",
            "Refresh the database or police is always only one or two hours behind the latest ads that appear on the web."
        ],
        [
            "What do we do for extraction?"
        ],
        [
            "We do semi structured extraction.",
            "I'm showing here example from another domain.",
            "We work with firearms.",
            "And we use machine learning so that people can annotate two to five of these pages, and then the system generates regular expressions that can extract the structure fields, and we generate Jason.",
            "But this schema is really based on the page."
        ],
        [
            "Text extraction is very challenging in this domain.",
            "This is an example of a text in an ad.",
            "You can see their phone number is obfuscated, so that office police cannot search it on Google.",
            "The prices are also obfuscated because it's illegal to sell these services on the web.",
            "So HH 80 Roses means $80.00 for half hour.",
            "So we build the extractors that can extract this data.",
            "And again, produce off a different kind of schema with this of entities and text extraction."
        ],
        [
            "So how do we map the data to the ontology?"
        ],
        [
            "First of all, what we have is lots of data coming, different schemas.",
            "We want one ontology."
        ],
        [
            "We use a schema.org as our base ontology.",
            "The reason we do that is that schema.org already has about 600 classes and 1000 properties to represent the information that is commonly published on the web.",
            "We have offers.",
            "We have products.",
            "We have people.",
            "We have organizations.",
            "Schema.org doesn't have hair color doesn't have adult services.",
            "So we extended schema.org to had these properties that we need."
        ],
        [
            "Now to map the data to the ontology, we use our prior work on Karma.",
            "So Karma is really a tool that lets you map any kind of structured data to an ontology.",
            "In our case theontologyschema.org.",
            "The way Karma works is you load a small snippet of your data and use that to train karma to solve, recognize semantic classes and so on and what it does is it builds a model of the data and from that model we can generate Jason LD or RDF in triples."
        ],
        [
            "Here's an example of a model for one of the extractions.",
            "So you can't see anything.",
            "Sorry.",
            "You can see the classes.",
            "You can see the edges.",
            "So.",
            "Yeah, the top classes on offer.",
            "It's an offer, the item being offered this a person.",
            "This is human trafficking.",
            "And then you know, we map each of their properties to columns on the data so that we say you know the name of the person is in the name column.",
            "The age column contains the person age.",
            "Then we connect the offer to a person and organization via the seller property.",
            "And then what we know about the seller is information about the place.",
            "So in this model we are really modeling that the place is a place of the seller is not a place of the victim.",
            "And you know, we model all the properties like this."
        ],
        [
            "Now from these properties we can generate RDF.",
            "And for us are the F is Jason.",
            "We generate natively Jason LD, so you can read this J or any programmer can read this Jason and say OK, understand what you're giving me.",
            "It's an offer, has an item.",
            "Offered it as a seller.",
            "It has Geo location and so on, but this is really RDF, it's just Jason in Jason LD.",
            "So after."
        ],
        [
            "We run our system in all the documents.",
            "We basically have 68 million documents mapped to the ontology producing."
        ],
        [
            "Little Jason files that look like this."
        ],
        [
            "We need to link those graphs now.",
            "When you do the mapping in karma.",
            "If you have strong attributes such as phone numbers, you can define your eyes for them and then this means that this little graphs are joined by this strong attribute.",
            "So we know that these two offers are related by phone number.",
            "Now we need to also link on other attributes like other classes like offer and adult service and this is much more challenging because they only contain soft attributes like eye color and names that we don't even know are reliable."
        ],
        [
            "So how do we do entity linking?"
        ],
        [
            "What we're working on is on enriching the graph with additional properties to acquire more soft attributes to Lincoln.",
            "So we're for example doing text similarity to discover ads that have been authored by the same person.",
            "So clearly to us this looks like it was either authored by the same person or at least copy pasted from somebody else is an event or the names are different, which is really a very strong clue that maybe something bad is going on.",
            "So we use a min, hash and LSH.",
            "To do the clustering and then we just record additional links in the graph for this relationships."
        ],
        [
            "OK. We can also do relationships based on image similarity.",
            "So we're using a convolutional neural net to do basically image similarity among 80,000,000 images.",
            "And so we can discover similarities between adult services because they contain images that are very similar."
        ],
        [
            "Now.",
            "How we do this?",
            "Are your linking of this key entities like person.",
            "An adult service is working progress.",
            "So we haven't actually solved this problem yet.",
            "We're looking at techniques that actually resemble some of the ideas that Andrew was talking about this morning by using vectors and so on, but we don't have results yet."
        ],
        [
            "But it's important to do 'cause if we can do it, we can solve identify same traffickers, same victims."
        ],
        [
            "Well, the next step after we have the graph is to redeploy it in a knowledge base."
        ],
        [
            "Being us in here now, Semantic Web conference.",
            "You would say, well, you know you just gave triple slowed them on the Triple Store.",
            "We decided not to do that.",
            "We didn't even try.",
            "We have too much data.",
            "We have more than a building equivalent of a billion triples.",
            "And doing this in efficient queries in SPARQL is very difficult, but you know the size of data is not big for Elasticsearch.",
            "Our users want to do structured query on the extracted data plus text query on the text of the ants in a seamless way.",
            "This is again not easy to do in triple stores.",
            "It's natively supported in Elasticsearch, same with faceted browsing.",
            "It's hard to do efficiently because group by queries are slow in sparkle.",
            "This is super efficient in Elasticsearch.",
            "And finally we work in a big consortium.",
            "And we are not able to convince their other members of the conversion to learn sparkle, learn Turtle.",
            "They know they know Jason and they know Elasticsearch.",
            "So we use Elasticsearch."
        ],
        [
            "So the challenge is, how do we store a graph in a document store?"
        ],
        [
            "So what we do is we generate a document for every.",
            "Node.",
            "And we make it a route."
        ],
        [
            "So here's what we do say for offers.",
            "We we we take the graph around and offer and visit the neighborhood of that graph and create a document that includes also the adult service, the person, their phone number we do see."
        ],
        [
            "Clearly, for the adult services, so we make the documents where the route is the adult service and we denormalize the other data.",
            "And we do that for."
        ],
        [
            "All the main types.",
            "And we and then we index all these documents in Elasticsearch.",
            "So yes, we are making we have five times as more data, but it can be indexed on every attribute and search."
        ],
        [
            "Very fast."
        ],
        [
            "The user interface has a text box.",
            "It looks like Amazon.",
            "You can search by keywords at the top you have facets on the left you have results."
        ],
        [
            "In the middle.",
            "You can zoom in, look at all the data."
        ],
        [
            "Look at the text."
        ],
        [
            "And here's the answer to our question.",
            "Find their locations.",
            "That's easily easy to read from their location facet we see the person has been mostly in the San Diego and the South Bay in the South in California, but also in Washington and Chicago.",
            "And if you browse, you can see the dates."
        ],
        [
            "So what?"
        ],
        [
            "Impact our system has been diploid to law enforcement.",
            "Six officers are using it.",
            "They they told us that they have opened investigations based on data that they go forgot from the system.",
            "So we're really thrilled to hear that it's making a difference."
        ],
        [
            "Now for some conclusions.",
            "So summary, so the idea that using an ontology is useful for integrating data or that works really well for us.",
            "The idea that you know semantic Web is very useful when you have this continuous schema evolution that also worked really well for us.",
            "We showed that you can actually use Elasticsearch as an RDF store very very effectively, very cheaply and very scalably.",
            "We also showed that we can collaborate with people who are not semantic web people by using a completely Jason based toolchain, but still RDF.",
            "No, it's RDF all the way because it's Jason LD.",
            "And we've deployed a very large semantic web application."
        ],
        [
            "That's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Pedro Zachary from the University of Southern California, so I'll present the work we've been doing on building and using a knowledge graph to combat human trafficking.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So human trafficking is a really bad problem worldwide.",
                    "label": 0
                },
                {
                    "sent": "I'll give you some statistic.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The profits of the industry per year is 32 billion.",
                    "label": 0
                },
                {
                    "sent": "The average entry of girls into prostitution in the US is 14 years old.",
                    "label": 1
                },
                {
                    "sent": "Pimps make $150,000 a year per victim.",
                    "label": 0
                },
                {
                    "sent": "And they often have six victims.",
                    "label": 0
                },
                {
                    "sent": "The advertising budget on the Web is $45,000,000.",
                    "label": 1
                },
                {
                    "sent": "Which means that there are lots and lots millions of classified ads for escorts which are really sex ads.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So suppose you are a police investigator.",
                    "label": 0
                },
                {
                    "sent": "You're trying to track down trafficker.",
                    "label": 0
                },
                {
                    "sent": "And you want to know the cities.",
                    "label": 0
                },
                {
                    "sent": "Where a potential victim has been advertised.",
                    "label": 1
                },
                {
                    "sent": "So the tool that they used today is Google.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what they do.",
                    "label": 0
                },
                {
                    "sent": "They put a search term Jessica Blue eyes, red hair supposed to be Swedish.",
                    "label": 0
                },
                {
                    "sent": "And they get lots of results.",
                    "label": 0
                },
                {
                    "sent": "Over 1,000,000 results through this query.",
                    "label": 0
                },
                {
                    "sent": "You can see from the top results that San Diego is definitely one of the cities.",
                    "label": 0
                },
                {
                    "sent": "But the investigator wants to know all the cities because they want to build a history of what has been done to this person.",
                    "label": 0
                },
                {
                    "sent": "That means that they have to browse a lot of Google pages.",
                    "label": 0
                },
                {
                    "sent": "Now the goal of our project is really to give them a better way of doing this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we look at the web pages.",
                    "label": 0
                },
                {
                    "sent": "We see that the data that we need is in the web pages in the first one, we see that it mentions Santa Barbara.",
                    "label": 0
                },
                {
                    "sent": "The second mentions Tyson Square in Washington DC.",
                    "label": 0
                },
                {
                    "sent": "Problem is, there's about 100 million pages.",
                    "label": 1
                },
                {
                    "sent": "So what we want to do?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who?",
                    "label": 0
                },
                {
                    "sent": "Is extract the information from this pages and build a knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So a suitable model for this page is that it's about an offer.",
                    "label": 0
                },
                {
                    "sent": "It's an offer for an adult service.",
                    "label": 0
                },
                {
                    "sent": "The offer has a price, a date where the offer is valid and a place.",
                    "label": 0
                },
                {
                    "sent": "And there's a seller.",
                    "label": 0
                },
                {
                    "sent": "And very often in this domain we know very little about the sellers.",
                    "label": 0
                },
                {
                    "sent": "Here we know a phone number.",
                    "label": 0
                },
                {
                    "sent": "The item being provided is an adult service and we have some data about this service.",
                    "label": 0
                },
                {
                    "sent": "You know we know the person is called Jessica has.",
                    "label": 0
                },
                {
                    "sent": "Blue eyes and red hair.",
                    "label": 0
                },
                {
                    "sent": "Now here's the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another ad, so the goal is you know if we can build the same kind of graph for another ad and then connect these graphs together.",
                    "label": 0
                },
                {
                    "sent": "Then we suddenly know there's two offers for the same service from the same seller.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can answer our question.",
                    "label": 0
                },
                {
                    "sent": "The cities we can read them off the graph.",
                    "label": 0
                },
                {
                    "sent": "Now of course the goal is to build a graph that can answer many, many more questions because investigators have many, many more questions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what does this have to do with semantic web?",
                    "label": 0
                },
                {
                    "sent": "We don't have linked data about escorts.",
                    "label": 0
                },
                {
                    "sent": "But you know, we solve inspired by David Karger stock in 2013.",
                    "label": 0
                },
                {
                    "sent": "Where he was asking us.",
                    "label": 0
                },
                {
                    "sent": "You know we should be building applications that show how semantic web can solve problems that we have right now.",
                    "label": 1
                },
                {
                    "sent": "So we have a human trafficking problem is a problem that police investigators need to solve right now.",
                    "label": 0
                },
                {
                    "sent": "And you know, very appropriate for us is the idea that he said the Semantic Web application is 1 whose schema is expected to change.",
                    "label": 1
                },
                {
                    "sent": "And in fact.",
                    "label": 0
                },
                {
                    "sent": "The schema that I'm going to show you today in the slides is different from the schema that was on the paper.",
                    "label": 0
                },
                {
                    "sent": "The schema has already evolved, it almost evolves every two weeks.",
                    "label": 0
                },
                {
                    "sent": "When we discover a new way of thinking about the problem, new attributes that we can extract.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the architecture of the system.",
                    "label": 0
                },
                {
                    "sent": "It's all like the Google chain we crawl because there's no link data we need to get the data from web pages.",
                    "label": 0
                },
                {
                    "sent": "We run extractors and we welcome in our system any extractor.",
                    "label": 0
                },
                {
                    "sent": "If you have an extractor that can extract some of the data, this data we can integrate it.",
                    "label": 0
                },
                {
                    "sent": "What we end up is with a lot of structured data in all kinds of different schemas, because every extractor has its own schema.",
                    "label": 0
                },
                {
                    "sent": "So the next step is to map all this data into a comment on teologi.",
                    "label": 0
                },
                {
                    "sent": "So and after that.",
                    "label": 0
                },
                {
                    "sent": "So what we end up with is this little graphs that are all using the same classes and properties but are disconnected.",
                    "label": 0
                },
                {
                    "sent": "Entity linking is what connects these little pieces of grass into a soft, coherent large graph that then we can deploy and then search.",
                    "label": 0
                },
                {
                    "sent": "So I'll show you what we do in each of these steps.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The crawling were crawling the main sites for escort ads.",
                    "label": 0
                },
                {
                    "sent": "They're listed there on that side of the slide.",
                    "label": 0
                },
                {
                    "sent": "The crawlers are running continuously.",
                    "label": 0
                },
                {
                    "sent": "Downloading about 2000 new pages per hour.",
                    "label": 0
                },
                {
                    "sent": "By now we have a database with about 68 million web.",
                    "label": 0
                },
                {
                    "sent": "No ads and we run the tool chain every hour.",
                    "label": 0
                },
                {
                    "sent": "Refresh the database or police is always only one or two hours behind the latest ads that appear on the web.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What do we do for extraction?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do semi structured extraction.",
                    "label": 0
                },
                {
                    "sent": "I'm showing here example from another domain.",
                    "label": 0
                },
                {
                    "sent": "We work with firearms.",
                    "label": 0
                },
                {
                    "sent": "And we use machine learning so that people can annotate two to five of these pages, and then the system generates regular expressions that can extract the structure fields, and we generate Jason.",
                    "label": 0
                },
                {
                    "sent": "But this schema is really based on the page.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Text extraction is very challenging in this domain.",
                    "label": 0
                },
                {
                    "sent": "This is an example of a text in an ad.",
                    "label": 0
                },
                {
                    "sent": "You can see their phone number is obfuscated, so that office police cannot search it on Google.",
                    "label": 0
                },
                {
                    "sent": "The prices are also obfuscated because it's illegal to sell these services on the web.",
                    "label": 0
                },
                {
                    "sent": "So HH 80 Roses means $80.00 for half hour.",
                    "label": 1
                },
                {
                    "sent": "So we build the extractors that can extract this data.",
                    "label": 0
                },
                {
                    "sent": "And again, produce off a different kind of schema with this of entities and text extraction.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we map the data to the ontology?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First of all, what we have is lots of data coming, different schemas.",
                    "label": 0
                },
                {
                    "sent": "We want one ontology.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use a schema.org as our base ontology.",
                    "label": 0
                },
                {
                    "sent": "The reason we do that is that schema.org already has about 600 classes and 1000 properties to represent the information that is commonly published on the web.",
                    "label": 0
                },
                {
                    "sent": "We have offers.",
                    "label": 0
                },
                {
                    "sent": "We have products.",
                    "label": 0
                },
                {
                    "sent": "We have people.",
                    "label": 0
                },
                {
                    "sent": "We have organizations.",
                    "label": 0
                },
                {
                    "sent": "Schema.org doesn't have hair color doesn't have adult services.",
                    "label": 0
                },
                {
                    "sent": "So we extended schema.org to had these properties that we need.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now to map the data to the ontology, we use our prior work on Karma.",
                    "label": 1
                },
                {
                    "sent": "So Karma is really a tool that lets you map any kind of structured data to an ontology.",
                    "label": 0
                },
                {
                    "sent": "In our case theontologyschema.org.",
                    "label": 0
                },
                {
                    "sent": "The way Karma works is you load a small snippet of your data and use that to train karma to solve, recognize semantic classes and so on and what it does is it builds a model of the data and from that model we can generate Jason LD or RDF in triples.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's an example of a model for one of the extractions.",
                    "label": 0
                },
                {
                    "sent": "So you can't see anything.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "You can see the classes.",
                    "label": 0
                },
                {
                    "sent": "You can see the edges.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the top classes on offer.",
                    "label": 0
                },
                {
                    "sent": "It's an offer, the item being offered this a person.",
                    "label": 0
                },
                {
                    "sent": "This is human trafficking.",
                    "label": 0
                },
                {
                    "sent": "And then you know, we map each of their properties to columns on the data so that we say you know the name of the person is in the name column.",
                    "label": 0
                },
                {
                    "sent": "The age column contains the person age.",
                    "label": 0
                },
                {
                    "sent": "Then we connect the offer to a person and organization via the seller property.",
                    "label": 0
                },
                {
                    "sent": "And then what we know about the seller is information about the place.",
                    "label": 0
                },
                {
                    "sent": "So in this model we are really modeling that the place is a place of the seller is not a place of the victim.",
                    "label": 0
                },
                {
                    "sent": "And you know, we model all the properties like this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now from these properties we can generate RDF.",
                    "label": 0
                },
                {
                    "sent": "And for us are the F is Jason.",
                    "label": 0
                },
                {
                    "sent": "We generate natively Jason LD, so you can read this J or any programmer can read this Jason and say OK, understand what you're giving me.",
                    "label": 0
                },
                {
                    "sent": "It's an offer, has an item.",
                    "label": 0
                },
                {
                    "sent": "Offered it as a seller.",
                    "label": 0
                },
                {
                    "sent": "It has Geo location and so on, but this is really RDF, it's just Jason in Jason LD.",
                    "label": 0
                },
                {
                    "sent": "So after.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We run our system in all the documents.",
                    "label": 0
                },
                {
                    "sent": "We basically have 68 million documents mapped to the ontology producing.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Little Jason files that look like this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We need to link those graphs now.",
                    "label": 0
                },
                {
                    "sent": "When you do the mapping in karma.",
                    "label": 0
                },
                {
                    "sent": "If you have strong attributes such as phone numbers, you can define your eyes for them and then this means that this little graphs are joined by this strong attribute.",
                    "label": 0
                },
                {
                    "sent": "So we know that these two offers are related by phone number.",
                    "label": 0
                },
                {
                    "sent": "Now we need to also link on other attributes like other classes like offer and adult service and this is much more challenging because they only contain soft attributes like eye color and names that we don't even know are reliable.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do entity linking?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we're working on is on enriching the graph with additional properties to acquire more soft attributes to Lincoln.",
                    "label": 0
                },
                {
                    "sent": "So we're for example doing text similarity to discover ads that have been authored by the same person.",
                    "label": 1
                },
                {
                    "sent": "So clearly to us this looks like it was either authored by the same person or at least copy pasted from somebody else is an event or the names are different, which is really a very strong clue that maybe something bad is going on.",
                    "label": 0
                },
                {
                    "sent": "So we use a min, hash and LSH.",
                    "label": 0
                },
                {
                    "sent": "To do the clustering and then we just record additional links in the graph for this relationships.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. We can also do relationships based on image similarity.",
                    "label": 1
                },
                {
                    "sent": "So we're using a convolutional neural net to do basically image similarity among 80,000,000 images.",
                    "label": 0
                },
                {
                    "sent": "And so we can discover similarities between adult services because they contain images that are very similar.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "How we do this?",
                    "label": 0
                },
                {
                    "sent": "Are your linking of this key entities like person.",
                    "label": 0
                },
                {
                    "sent": "An adult service is working progress.",
                    "label": 0
                },
                {
                    "sent": "So we haven't actually solved this problem yet.",
                    "label": 0
                },
                {
                    "sent": "We're looking at techniques that actually resemble some of the ideas that Andrew was talking about this morning by using vectors and so on, but we don't have results yet.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it's important to do 'cause if we can do it, we can solve identify same traffickers, same victims.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, the next step after we have the graph is to redeploy it in a knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Being us in here now, Semantic Web conference.",
                    "label": 0
                },
                {
                    "sent": "You would say, well, you know you just gave triple slowed them on the Triple Store.",
                    "label": 0
                },
                {
                    "sent": "We decided not to do that.",
                    "label": 0
                },
                {
                    "sent": "We didn't even try.",
                    "label": 0
                },
                {
                    "sent": "We have too much data.",
                    "label": 0
                },
                {
                    "sent": "We have more than a building equivalent of a billion triples.",
                    "label": 1
                },
                {
                    "sent": "And doing this in efficient queries in SPARQL is very difficult, but you know the size of data is not big for Elasticsearch.",
                    "label": 0
                },
                {
                    "sent": "Our users want to do structured query on the extracted data plus text query on the text of the ants in a seamless way.",
                    "label": 0
                },
                {
                    "sent": "This is again not easy to do in triple stores.",
                    "label": 0
                },
                {
                    "sent": "It's natively supported in Elasticsearch, same with faceted browsing.",
                    "label": 1
                },
                {
                    "sent": "It's hard to do efficiently because group by queries are slow in sparkle.",
                    "label": 0
                },
                {
                    "sent": "This is super efficient in Elasticsearch.",
                    "label": 0
                },
                {
                    "sent": "And finally we work in a big consortium.",
                    "label": 0
                },
                {
                    "sent": "And we are not able to convince their other members of the conversion to learn sparkle, learn Turtle.",
                    "label": 0
                },
                {
                    "sent": "They know they know Jason and they know Elasticsearch.",
                    "label": 0
                },
                {
                    "sent": "So we use Elasticsearch.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the challenge is, how do we store a graph in a document store?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do is we generate a document for every.",
                    "label": 0
                },
                {
                    "sent": "Node.",
                    "label": 0
                },
                {
                    "sent": "And we make it a route.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what we do say for offers.",
                    "label": 0
                },
                {
                    "sent": "We we we take the graph around and offer and visit the neighborhood of that graph and create a document that includes also the adult service, the person, their phone number we do see.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clearly, for the adult services, so we make the documents where the route is the adult service and we denormalize the other data.",
                    "label": 0
                },
                {
                    "sent": "And we do that for.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the main types.",
                    "label": 0
                },
                {
                    "sent": "And we and then we index all these documents in Elasticsearch.",
                    "label": 0
                },
                {
                    "sent": "So yes, we are making we have five times as more data, but it can be indexed on every attribute and search.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very fast.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The user interface has a text box.",
                    "label": 0
                },
                {
                    "sent": "It looks like Amazon.",
                    "label": 0
                },
                {
                    "sent": "You can search by keywords at the top you have facets on the left you have results.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the middle.",
                    "label": 0
                },
                {
                    "sent": "You can zoom in, look at all the data.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at the text.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's the answer to our question.",
                    "label": 0
                },
                {
                    "sent": "Find their locations.",
                    "label": 0
                },
                {
                    "sent": "That's easily easy to read from their location facet we see the person has been mostly in the San Diego and the South Bay in the South in California, but also in Washington and Chicago.",
                    "label": 0
                },
                {
                    "sent": "And if you browse, you can see the dates.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Impact our system has been diploid to law enforcement.",
                    "label": 1
                },
                {
                    "sent": "Six officers are using it.",
                    "label": 0
                },
                {
                    "sent": "They they told us that they have opened investigations based on data that they go forgot from the system.",
                    "label": 0
                },
                {
                    "sent": "So we're really thrilled to hear that it's making a difference.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now for some conclusions.",
                    "label": 0
                },
                {
                    "sent": "So summary, so the idea that using an ontology is useful for integrating data or that works really well for us.",
                    "label": 0
                },
                {
                    "sent": "The idea that you know semantic Web is very useful when you have this continuous schema evolution that also worked really well for us.",
                    "label": 0
                },
                {
                    "sent": "We showed that you can actually use Elasticsearch as an RDF store very very effectively, very cheaply and very scalably.",
                    "label": 1
                },
                {
                    "sent": "We also showed that we can collaborate with people who are not semantic web people by using a completely Jason based toolchain, but still RDF.",
                    "label": 0
                },
                {
                    "sent": "No, it's RDF all the way because it's Jason LD.",
                    "label": 0
                },
                {
                    "sent": "And we've deployed a very large semantic web application.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it.",
                    "label": 0
                }
            ]
        }
    }
}