{
    "id": "55ltjaxec5xcez5ih7myybh2kotqzv2t",
    "title": "Discriminative Experimental Design",
    "info": {
        "produced by": [
            "Data & Web Mining Lab"
        ],
        "author": [
            "Yu Zhang, The Hong Kong University of Science and Technology"
        ],
        "published": "Nov. 29, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_zhang_design/",
    "segmentation": [
        [
            "Hello everyone, I'm young from Hong Kong University of Science and Technology.",
            "I print my paper discriminative, experimental design."
        ],
        [
            "So first we gave introduction to active learning.",
            "So different from other learning framework.",
            "Actually just select unlabeled data points to cook."
        ],
        [
            "Free some Oracle.",
            "And then expand the labeled data set.",
            "One coin problem in active learning is just to design the unlabeled data point criteria.",
            "So according to the different types of the data point selection criteria, we just classify the existing active learning method into several categories such as uncertainty sampling.",
            "An inquiry by community and also representative sampling.",
            "And it also acts SVM, active learning and transductive experimental design.",
            "Some typical methods in active learning.",
            "So this is a typical.",
            "Procedures of active learning.",
            "So the most important one is just the step point 2.1.",
            "We need to design unlabeled data selection criteria."
        ],
        [
            "Yeah.",
            "So we find some active learning methods are complementary, for example.",
            "SMSM active learning utilize descriptive information from classifiers and it can only select one data point in an iteration of active learning procedure.",
            "But in transductive experiment design TD use the data, discrete distribution information and it can select multiple data points in one iteration, so our work is just to propose a new active learning method called this screen.",
            "Discriminated native experiment design PD, which is to.",
            "Combine the strengths of both SM active learning and also the transductive experiment design and we utilize projection method to solve the optimizing problem and all methods achieve good performance on some benchmark."
        ],
        [
            "Set up set."
        ],
        [
            "And then before we introduce all methods, we just explain some annotations in our paper.",
            "Well, we here is just the data metrics for the total unlabeled data.",
            "X case just select the subset of unlabeled data metrics.",
            "Here is the number of selected data points.",
            "By here is just a feature mapping corresponding to some kernel function key."
        ],
        [
            "So we first review on the least squares them or richer regression.",
            "So the objective function of least square SVM is formatted as is on the Earth in problem one.",
            "So this problem consists.",
            "Custom is to measure the empirical loss the second time to paralyse the complexity of the W. So because we just deal with the binary classification problem, so it is equivalent to the problem too.",
            "So here the North Square knots in problem two is just the similar to the square hinge loss used in SVM.",
            "And we also define a function single scores for data point as the inverse of.",
            "The same function value."
        ],
        [
            "Of one point.",
            "So according to analysis of the existing transductive experiment design, the covariance matrix of the estimation error of W is for pushing 2 The CW, which is the inverse inverse Hessian matrix of the JW function.",
            "So then, based on The CW we can get the correct metrics of the predictive area on the haunted, unlabeled datasets.",
            "Which is publishing to the CF.",
            "Yes, the F is derived from CW.",
            "So we just want to minimize the predicted variance.",
            "We use the trace of the CF as a surrogate function of the predicted variance and we just minimize the trace of the self.",
            "So then the objective function of our Miss DD in is formulating the problem 3."
        ],
        [
            "So before we present our precision overall optimization procedure.",
            "We just to see the relationships between our method DD and the existing method TD here.",
            "So the optimization problem of linear needy is formatting problem.",
            "For here we define a new random new variable child X which is the latest version of the original data Points X.",
            "So this optimization is very similar to the act of the TD.",
            "So from this we can we can see that transductive experiment design TD is just a special case of all method with the data on database is equal equals of equal is of equal importance.",
            "And all method is just a weighted version of TD where the weights are related to the function scores of the data points.",
            "So if the function scores of one data point is larger than the weights is become larger in DD."
        ],
        [
            "So.",
            "All objects in our full optimization procedure we first define selection indicator matrix S. So each element is IJ in X is equal to 1 if.",
            "The address column of X * y X is just from the column of five times YV, otherwise it equals there.",
            "So here is the constraint set for the S matrix which.",
            "Only she can go there.",
            "The element guiding S is either zero or one and this is.",
            "Orthogonal matrix.",
            "Then we can, uh, reformatted object function of the D as in problem 5.",
            "You can see the objective function of this problem is similar to the objective function of the linear discriminant analysis.",
            "So only if there's no constraint, then the optimal solution of this problem has the form is the form of production product of West NP.",
            "Here is that consists of the top T even vectors of the column matrix cavey.",
            "And the P is just any also."
        ],
        [
            "No metrics.",
            "So.",
            "Yep, we using a projection method to project the optimal solution of the unconstrained optimization into the constraints set this we use the F norm as distance measure between two matrix.",
            "And her Q is just from is just the optimal solution in constraint set and it's.",
            "Start times piece the optimal solution of the unconstrained problem.",
            "So it is equivalent to the problem 7.",
            "Which is much simpler than the original problem 6.",
            "Since this problem have two in two variable P&Q it is not easy to optimize with respect to all of them.",
            "So we're using our alternating optimizing method to solve this problem."
        ],
        [
            "So the for the first subproblem.",
            "We just assume P on the matrix P is fixed and also.",
            "Optimizing album with respect to Q is formatted as appropriate.",
            "So this is just the integer programming which she has no efficient solution.",
            "But we can see from the objective function of problem it we can find this problem is just to find the teenage assignments in the matrix X start time P. Then based on there is also a constraint on animals that no two elements can be in the same column or the same row.",
            "Based on observation at largest elements in different columns of the start time, peanut usually lies in different roles, so we propose a greedy method to select not just the elements.",
            "In this time is short time P. That is, we just first find the largest element in the matrix and then delete the corresponding column and row, and then we find largest one element in the remaining remaining submatrix and this this procedure continues until we find the T not just one element."
        ],
        [
            "Was a problem too.",
            "We just fixed the Q and the optimization problem with respect to P is formed in.",
            "The problem I'm here by using underground multiple method you can get a closed form solution or the P star.",
            "Also P Stampede optimal solution piece the product of you and our metrics are metrics.",
            "Where the UNR is just you are from the SVD.",
            "The Matrix X star transpose time Q."
        ],
        [
            "Also, all the computational complexity of our method is all mystical in square time T and also our mass.",
            "By using the operating procedure or method is not sensitive to the regular fare meters in the objective function of least square SVM."
        ],
        [
            "So we compare for experiments.",
            "We compare our method with this swim active learning, transductive experimental design, another batch mode active learning method.",
            "We try and we just experiment our methods into benchmark datasets, use groups and Reuters.",
            "We're using the AUC score as a population.",
            "And the size of the purist T is said to be 5 and a.",
            "They recognize parameters in All in all methods is said to be a point there one.",
            "Also on.",
            "Before the active learning persist, us five labeled data points are provided.",
            "As for each class as the initial initial."
        ],
        [
            "It.",
            "So.",
            "This is the result for arenus groups on different categories.",
            "So we can see that when the Devil Data label data is.",
            "Very limited and our performance of our method is much better than the other methods such as the same as active learning is also TD which just verify that if the combination of the data distribution information and also the discriminative information is also very useful after the only stage."
        ],
        [
            "Another experiment on the Reuters data.",
            "Also.",
            "Our method achieve better performance on different categories."
        ],
        [
            "Moreover, we also compare comparison on two optimizing procedures.",
            "The first, the first one, is ours and other one is just proposed in the transductive experimental design.",
            "We can hear the red curve is just hours, we can see our method also achieve.",
            "A better performance over by using the existing optimizing procedure."
        ],
        [
            "So in this paper we just proposed a novel more active learning methods.",
            "And data selection criteria utilized discriminative information and also data distribution information.",
            "So.",
            "For future work, we just want to combine the active learning and semi supervised learning to achieve a better performance in some application."
        ],
        [
            "Things.",
            "So that's all.",
            "Thank you for attention.",
            "What is actually computational complexity of this approach, more or less?",
            "I may be missing you mean which slide.",
            "I'm asking about the computational complexity.",
            "OK, OK, so in competition versus the most Congo bottleneck is Justin.",
            "The SVD, SVD singular value decomposition in this part.",
            "So we just need to find the keen artist.",
            "Modular teenage, the singular vectors of the.",
            "I'm guys transpose times Q so the capacity the computational complexity is just the big ol N ^2 * T. We know we don't need to find all the single single manual vectors.",
            "OK.",
            "Yes.",
            "How much time it is connected to the SVM?",
            "Or can someone else figure out?",
            "If you sum different classifier with the same principle.",
            "OK, so for the SVM here which.",
            "Just for the discriminative information.",
            "We can see, so here the YB&YX here just contains some informations from GOG.",
            "And why it's just the dizzying function values of the current classifiers.",
            "So in this way, we just put the.",
            "Fungal function function value into the objective function of our method and then utilize the discriminative information and also the data participation information together.",
            "So the main goal is to minimize the predicted variance.",
            "I suppose yes.",
            "Would you be able to adapt this approach to try and minimize something else?",
            "Something OK?",
            "Here here we just using the trace of the CF K2 as a surrogate function of the predicted variance.",
            "But you can also, using the determinant of the self as other as another solid function.",
            "So I don't know.",
            "OK, I see.",
            "I have a question.",
            "Measuring success using AUC.",
            "In the experiment you're measuring success using the area under the receiver operating curve well fast and your games has shown how to use AUC as the objective function for training support vector machines.",
            "So did you compare results with an SVM train to maximize AUC?",
            "And with your method be compatible with that?",
            "Not China, but I think this is maybe a good suggestion for future direction.",
            "We just we just also using the conventional SVM as.",
            "Yes, I know for our method we just utilize based on the least squares PM, which is similar to the SVM now.",
            "So maybe we can also try to directly minimize the AUC scores in the future."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, I'm young from Hong Kong University of Science and Technology.",
                    "label": 0
                },
                {
                    "sent": "I print my paper discriminative, experimental design.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first we gave introduction to active learning.",
                    "label": 0
                },
                {
                    "sent": "So different from other learning framework.",
                    "label": 0
                },
                {
                    "sent": "Actually just select unlabeled data points to cook.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Free some Oracle.",
                    "label": 0
                },
                {
                    "sent": "And then expand the labeled data set.",
                    "label": 1
                },
                {
                    "sent": "One coin problem in active learning is just to design the unlabeled data point criteria.",
                    "label": 1
                },
                {
                    "sent": "So according to the different types of the data point selection criteria, we just classify the existing active learning method into several categories such as uncertainty sampling.",
                    "label": 1
                },
                {
                    "sent": "An inquiry by community and also representative sampling.",
                    "label": 0
                },
                {
                    "sent": "And it also acts SVM, active learning and transductive experimental design.",
                    "label": 1
                },
                {
                    "sent": "Some typical methods in active learning.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical.",
                    "label": 1
                },
                {
                    "sent": "Procedures of active learning.",
                    "label": 0
                },
                {
                    "sent": "So the most important one is just the step point 2.1.",
                    "label": 0
                },
                {
                    "sent": "We need to design unlabeled data selection criteria.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So we find some active learning methods are complementary, for example.",
                    "label": 1
                },
                {
                    "sent": "SMSM active learning utilize descriptive information from classifiers and it can only select one data point in an iteration of active learning procedure.",
                    "label": 0
                },
                {
                    "sent": "But in transductive experiment design TD use the data, discrete distribution information and it can select multiple data points in one iteration, so our work is just to propose a new active learning method called this screen.",
                    "label": 0
                },
                {
                    "sent": "Discriminated native experiment design PD, which is to.",
                    "label": 0
                },
                {
                    "sent": "Combine the strengths of both SM active learning and also the transductive experiment design and we utilize projection method to solve the optimizing problem and all methods achieve good performance on some benchmark.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set up set.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then before we introduce all methods, we just explain some annotations in our paper.",
                    "label": 0
                },
                {
                    "sent": "Well, we here is just the data metrics for the total unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "X case just select the subset of unlabeled data metrics.",
                    "label": 1
                },
                {
                    "sent": "Here is the number of selected data points.",
                    "label": 1
                },
                {
                    "sent": "By here is just a feature mapping corresponding to some kernel function key.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we first review on the least squares them or richer regression.",
                    "label": 0
                },
                {
                    "sent": "So the objective function of least square SVM is formatted as is on the Earth in problem one.",
                    "label": 1
                },
                {
                    "sent": "So this problem consists.",
                    "label": 0
                },
                {
                    "sent": "Custom is to measure the empirical loss the second time to paralyse the complexity of the W. So because we just deal with the binary classification problem, so it is equivalent to the problem too.",
                    "label": 0
                },
                {
                    "sent": "So here the North Square knots in problem two is just the similar to the square hinge loss used in SVM.",
                    "label": 1
                },
                {
                    "sent": "And we also define a function single scores for data point as the inverse of.",
                    "label": 0
                },
                {
                    "sent": "The same function value.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of one point.",
                    "label": 0
                },
                {
                    "sent": "So according to analysis of the existing transductive experiment design, the covariance matrix of the estimation error of W is for pushing 2 The CW, which is the inverse inverse Hessian matrix of the JW function.",
                    "label": 1
                },
                {
                    "sent": "So then, based on The CW we can get the correct metrics of the predictive area on the haunted, unlabeled datasets.",
                    "label": 0
                },
                {
                    "sent": "Which is publishing to the CF.",
                    "label": 0
                },
                {
                    "sent": "Yes, the F is derived from CW.",
                    "label": 1
                },
                {
                    "sent": "So we just want to minimize the predicted variance.",
                    "label": 1
                },
                {
                    "sent": "We use the trace of the CF as a surrogate function of the predicted variance and we just minimize the trace of the self.",
                    "label": 0
                },
                {
                    "sent": "So then the objective function of our Miss DD in is formulating the problem 3.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before we present our precision overall optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "We just to see the relationships between our method DD and the existing method TD here.",
                    "label": 0
                },
                {
                    "sent": "So the optimization problem of linear needy is formatting problem.",
                    "label": 1
                },
                {
                    "sent": "For here we define a new random new variable child X which is the latest version of the original data Points X.",
                    "label": 0
                },
                {
                    "sent": "So this optimization is very similar to the act of the TD.",
                    "label": 0
                },
                {
                    "sent": "So from this we can we can see that transductive experiment design TD is just a special case of all method with the data on database is equal equals of equal is of equal importance.",
                    "label": 0
                },
                {
                    "sent": "And all method is just a weighted version of TD where the weights are related to the function scores of the data points.",
                    "label": 1
                },
                {
                    "sent": "So if the function scores of one data point is larger than the weights is become larger in DD.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "All objects in our full optimization procedure we first define selection indicator matrix S. So each element is IJ in X is equal to 1 if.",
                    "label": 1
                },
                {
                    "sent": "The address column of X * y X is just from the column of five times YV, otherwise it equals there.",
                    "label": 0
                },
                {
                    "sent": "So here is the constraint set for the S matrix which.",
                    "label": 1
                },
                {
                    "sent": "Only she can go there.",
                    "label": 0
                },
                {
                    "sent": "The element guiding S is either zero or one and this is.",
                    "label": 0
                },
                {
                    "sent": "Orthogonal matrix.",
                    "label": 1
                },
                {
                    "sent": "Then we can, uh, reformatted object function of the D as in problem 5.",
                    "label": 0
                },
                {
                    "sent": "You can see the objective function of this problem is similar to the objective function of the linear discriminant analysis.",
                    "label": 0
                },
                {
                    "sent": "So only if there's no constraint, then the optimal solution of this problem has the form is the form of production product of West NP.",
                    "label": 1
                },
                {
                    "sent": "Here is that consists of the top T even vectors of the column matrix cavey.",
                    "label": 0
                },
                {
                    "sent": "And the P is just any also.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No metrics.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yep, we using a projection method to project the optimal solution of the unconstrained optimization into the constraints set this we use the F norm as distance measure between two matrix.",
                    "label": 0
                },
                {
                    "sent": "And her Q is just from is just the optimal solution in constraint set and it's.",
                    "label": 0
                },
                {
                    "sent": "Start times piece the optimal solution of the unconstrained problem.",
                    "label": 1
                },
                {
                    "sent": "So it is equivalent to the problem 7.",
                    "label": 0
                },
                {
                    "sent": "Which is much simpler than the original problem 6.",
                    "label": 0
                },
                {
                    "sent": "Since this problem have two in two variable P&Q it is not easy to optimize with respect to all of them.",
                    "label": 0
                },
                {
                    "sent": "So we're using our alternating optimizing method to solve this problem.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the for the first subproblem.",
                    "label": 0
                },
                {
                    "sent": "We just assume P on the matrix P is fixed and also.",
                    "label": 0
                },
                {
                    "sent": "Optimizing album with respect to Q is formatted as appropriate.",
                    "label": 1
                },
                {
                    "sent": "So this is just the integer programming which she has no efficient solution.",
                    "label": 0
                },
                {
                    "sent": "But we can see from the objective function of problem it we can find this problem is just to find the teenage assignments in the matrix X start time P. Then based on there is also a constraint on animals that no two elements can be in the same column or the same row.",
                    "label": 1
                },
                {
                    "sent": "Based on observation at largest elements in different columns of the start time, peanut usually lies in different roles, so we propose a greedy method to select not just the elements.",
                    "label": 0
                },
                {
                    "sent": "In this time is short time P. That is, we just first find the largest element in the matrix and then delete the corresponding column and row, and then we find largest one element in the remaining remaining submatrix and this this procedure continues until we find the T not just one element.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Was a problem too.",
                    "label": 0
                },
                {
                    "sent": "We just fixed the Q and the optimization problem with respect to P is formed in.",
                    "label": 1
                },
                {
                    "sent": "The problem I'm here by using underground multiple method you can get a closed form solution or the P star.",
                    "label": 0
                },
                {
                    "sent": "Also P Stampede optimal solution piece the product of you and our metrics are metrics.",
                    "label": 0
                },
                {
                    "sent": "Where the UNR is just you are from the SVD.",
                    "label": 0
                },
                {
                    "sent": "The Matrix X star transpose time Q.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, all the computational complexity of our method is all mystical in square time T and also our mass.",
                    "label": 0
                },
                {
                    "sent": "By using the operating procedure or method is not sensitive to the regular fare meters in the objective function of least square SVM.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we compare for experiments.",
                    "label": 0
                },
                {
                    "sent": "We compare our method with this swim active learning, transductive experimental design, another batch mode active learning method.",
                    "label": 1
                },
                {
                    "sent": "We try and we just experiment our methods into benchmark datasets, use groups and Reuters.",
                    "label": 0
                },
                {
                    "sent": "We're using the AUC score as a population.",
                    "label": 1
                },
                {
                    "sent": "And the size of the purist T is said to be 5 and a.",
                    "label": 0
                },
                {
                    "sent": "They recognize parameters in All in all methods is said to be a point there one.",
                    "label": 0
                },
                {
                    "sent": "Also on.",
                    "label": 1
                },
                {
                    "sent": "Before the active learning persist, us five labeled data points are provided.",
                    "label": 1
                },
                {
                    "sent": "As for each class as the initial initial.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is the result for arenus groups on different categories.",
                    "label": 0
                },
                {
                    "sent": "So we can see that when the Devil Data label data is.",
                    "label": 1
                },
                {
                    "sent": "Very limited and our performance of our method is much better than the other methods such as the same as active learning is also TD which just verify that if the combination of the data distribution information and also the discriminative information is also very useful after the only stage.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another experiment on the Reuters data.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "Our method achieve better performance on different categories.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moreover, we also compare comparison on two optimizing procedures.",
                    "label": 1
                },
                {
                    "sent": "The first, the first one, is ours and other one is just proposed in the transductive experimental design.",
                    "label": 0
                },
                {
                    "sent": "We can hear the red curve is just hours, we can see our method also achieve.",
                    "label": 0
                },
                {
                    "sent": "A better performance over by using the existing optimizing procedure.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this paper we just proposed a novel more active learning methods.",
                    "label": 0
                },
                {
                    "sent": "And data selection criteria utilized discriminative information and also data distribution information.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "For future work, we just want to combine the active learning and semi supervised learning to achieve a better performance in some application.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things.",
                    "label": 0
                },
                {
                    "sent": "So that's all.",
                    "label": 0
                },
                {
                    "sent": "Thank you for attention.",
                    "label": 0
                },
                {
                    "sent": "What is actually computational complexity of this approach, more or less?",
                    "label": 0
                },
                {
                    "sent": "I may be missing you mean which slide.",
                    "label": 0
                },
                {
                    "sent": "I'm asking about the computational complexity.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so in competition versus the most Congo bottleneck is Justin.",
                    "label": 0
                },
                {
                    "sent": "The SVD, SVD singular value decomposition in this part.",
                    "label": 0
                },
                {
                    "sent": "So we just need to find the keen artist.",
                    "label": 0
                },
                {
                    "sent": "Modular teenage, the singular vectors of the.",
                    "label": 0
                },
                {
                    "sent": "I'm guys transpose times Q so the capacity the computational complexity is just the big ol N ^2 * T. We know we don't need to find all the single single manual vectors.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "How much time it is connected to the SVM?",
                    "label": 0
                },
                {
                    "sent": "Or can someone else figure out?",
                    "label": 0
                },
                {
                    "sent": "If you sum different classifier with the same principle.",
                    "label": 0
                },
                {
                    "sent": "OK, so for the SVM here which.",
                    "label": 0
                },
                {
                    "sent": "Just for the discriminative information.",
                    "label": 0
                },
                {
                    "sent": "We can see, so here the YB&YX here just contains some informations from GOG.",
                    "label": 0
                },
                {
                    "sent": "And why it's just the dizzying function values of the current classifiers.",
                    "label": 0
                },
                {
                    "sent": "So in this way, we just put the.",
                    "label": 0
                },
                {
                    "sent": "Fungal function function value into the objective function of our method and then utilize the discriminative information and also the data participation information together.",
                    "label": 0
                },
                {
                    "sent": "So the main goal is to minimize the predicted variance.",
                    "label": 0
                },
                {
                    "sent": "I suppose yes.",
                    "label": 0
                },
                {
                    "sent": "Would you be able to adapt this approach to try and minimize something else?",
                    "label": 0
                },
                {
                    "sent": "Something OK?",
                    "label": 0
                },
                {
                    "sent": "Here here we just using the trace of the CF K2 as a surrogate function of the predicted variance.",
                    "label": 0
                },
                {
                    "sent": "But you can also, using the determinant of the self as other as another solid function.",
                    "label": 0
                },
                {
                    "sent": "So I don't know.",
                    "label": 0
                },
                {
                    "sent": "OK, I see.",
                    "label": 0
                },
                {
                    "sent": "I have a question.",
                    "label": 0
                },
                {
                    "sent": "Measuring success using AUC.",
                    "label": 0
                },
                {
                    "sent": "In the experiment you're measuring success using the area under the receiver operating curve well fast and your games has shown how to use AUC as the objective function for training support vector machines.",
                    "label": 0
                },
                {
                    "sent": "So did you compare results with an SVM train to maximize AUC?",
                    "label": 0
                },
                {
                    "sent": "And with your method be compatible with that?",
                    "label": 0
                },
                {
                    "sent": "Not China, but I think this is maybe a good suggestion for future direction.",
                    "label": 0
                },
                {
                    "sent": "We just we just also using the conventional SVM as.",
                    "label": 0
                },
                {
                    "sent": "Yes, I know for our method we just utilize based on the least squares PM, which is similar to the SVM now.",
                    "label": 0
                },
                {
                    "sent": "So maybe we can also try to directly minimize the AUC scores in the future.",
                    "label": 0
                }
            ]
        }
    }
}