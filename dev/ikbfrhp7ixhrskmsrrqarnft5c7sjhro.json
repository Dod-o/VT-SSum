{
    "id": "ikbfrhp7ixhrskmsrrqarnft5c7sjhro",
    "title": "MAP Estimation with Perfect Graphs",
    "info": {
        "author": [
            "Tony Jebara, Department of Computer Science, Columbia University"
        ],
        "published": "July 30, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/mlss09us_jebara_mapepg/",
    "segmentation": [
        [
            "Thank you and thanks for sticking around for the last session, so I'll be talking to you today about a new topic that I got excited about recently and actually took courses and did a lot of reading to basically develop my background.",
            "It's not really my area, but there was a lot of excitement about perfect graphs in the past few years and I thought there may be connection to machine learning and inference problems, and it turns out there is and I'll be talking about one possible contact point between this.",
            "Really active area in combinatorics called perfect graphs and how it can help with map estimation."
        ],
        [
            "OK, so today's talk is basically going to be a quick overview about what perfect graphs are.",
            "And how they connect to graphical models and graphical models is going to be the main application of the combinatorics.",
            "We're going to be talking about today and also talk about how I got excited about perfect wraps really from a.",
            "Prior work in matching zanin generalized matchings, which are specific incarnations of perfect graphs and then we'll talk about how to use this machinery by converting graphical models from their usual format which were used to in machine learning.",
            "It's something I call and and Markov random field and once we've done that conversion then we can start exploiting all these tools from perfect graph theory, including several theorems, algorithms and a lot of really important breakthroughs and once we start exploring those tools will be able to prove.",
            "Some nice map results, so one can we do maximum Maple story estimation exactly in graphical modeling using this perfect graphs machinery and then?",
            "In addition, I'll talk about some experiments and some other future work and future directions with perfect graphs.",
            "Can anyone hear me OK with the microphone?",
            "Or is it OK great?"
        ],
        [
            "OK, So what are perfect graphs?",
            "Perfect graphs have been around for a long time and they are very active area in the combinatorics community and the originator of perfect graphs.",
            "Is this fellow cloud Burge, who in 1960 proposed this interesting family of graphs.",
            "That he later on went on to call the perfect graph.",
            "And here's an example of one such perfect graph.",
            "This is the rooks graph, and he also proposed two conjectures.",
            "He had these two unproven theorems.",
            "The first one is called the weak conjecture and the other one is called a strong conjecture.",
            "An first let's just say what did Birge mean when he said perfect graph?",
            "So what burst means by the definition of a perfect graph is it's perfect if and only if every induced sub graph of your graph has click number equal to coloring number.",
            "So we'll come back and talk about that.",
            "More specifically, but if your graph satisfies the property, then it's called perfect.",
            "And then are these two conjectures.",
            "So we conjecture is if the graph G is perfect, then the complement of G has to also be perfect.",
            "That's called the weak theorem.",
            "And then there's a strong conjecture, which is all perfect.",
            "Graphs are Berge graphs and so we'll define burgraff later on, but that's another family of graphs, and it wasn't quite certain if they were basically one in the same thing.",
            "We're all first graphs, really.",
            "Just perfect graphs, whether the same family or there were some cases that were.",
            "And one one subset and not the other.",
            "And so these two theorems have been.",
            "Very important driving forces in the comment or community and the first one the week perfect graph theorem was solved by low Vashon, 1972.",
            "And in addition, in 1972 Lavash identified a nice link between perfect graphs and integral LP's, so integral LP's are crucial to map estimation with graphical models.",
            "And that's where the real contact point comes in.",
            "Let me just just this a little bit.",
            "But the other theorem, the strong perfect graph theorem, remained open for over four decades, and many, many researchers struggled this theorem, and it was only recently solved after over four decades of."
        ],
        [
            "Of a.",
            "Of serious effort and the final proof came out a couple of years ago in 2003.",
            "By these four folks, the Maria to Nowski Neil Robertson, Paul Seymour, and Robin Thomas and they finally said that this is no longer a conjecture.",
            "It's actually true.",
            "The strong, perfect graph theorem.",
            "As proven.",
            "Every birds graph is a perfect graph, and then right after they discovered they reported it to version was actually very old and weak and sick at the time.",
            "But they showed him the proof.",
            "He verified it was correct and then he passed away shortly thereafter.",
            "So there's a.",
            "A little story behind the whole thing, but it's nice to see that conclusion of this open problem that lasted for over for it for decades.",
            "OK, So what are perfect graphs good for?",
            "Well in?",
            "In algorithms, it turns out many algorithms when they're run on a perfect graph.",
            "Actually become polynomial an efficient when they were generally NP hard, so an NP hard algorithm if you if you run it on a perfect graph, you can get efficient solutions.",
            "And even if that algorithm is not just NP hard, but it's also NP hard to solve the problem exactly, so problem is NP hard or NP hard to approximate can be solved exactly if you work with perfect graphs instead of with a general graph, and so some of these examples are graph coloring.",
            "Which is NP hard to approximate maximum clique maximum independent set these problems if you.",
            "Try solving a perfect graph.",
            "You'll get efficient solutions, and it turns out also in 2006 after this paper, an algorithm for recognizing perfect graph.",
            "So if I give you a graph.",
            "Can you test if it's perfect or not?",
            "Also now exists which checks perfection and says yes.",
            "It's perfect or no.",
            "It's not perfect in order end to the 9th, so there's potential for improvement here, but at least now we know this is polynomial time.",
            "You can give me a graph.",
            "I can tell you if it's perfect or not and if it is perfect and all these other problems we can do efficiently.",
            "Hey, so how do?"
        ],
        [
            "This relates back to graphical models and so in machine learning and inference an an other statistical problems we usually work with graphs that are also called graphical models, where we're interested in finding the most likely configuration of random variables, and we use the graph to identify dependencies between the random variables.",
            "So most of you already comfortable with this notation, but a graphical model is basically a graph coupled with a probability distribution.",
            "And what the graph is basically saying about the probability distribution?",
            "Is it telling you how that probability distributions factorizes over all the variables?",
            "So every variable is associated with the node?",
            "And then instead of running this gigantic distribution arbitrarily, if I give you this graph over these six, let's say discrete variables X one to XN, this graph tells you that the distribution.",
            "Factorizes as a function as a product of these little functions.",
            "Over all the maximal cliques in the graph.",
            "So find all the fully connected sets of nodes and you can rewrite this big distribution this way and efficiently store the distribution and also sometimes do some efficient inference, and so in the case upstairs we can give it that distribution over 6 variables into these product of smaller functions which are more efficient to work with.",
            "So that's what a graphical model is."
        ],
        [
            "And one of the Canonical problems with graphical models and machine learning is the map problem.",
            "There's also the marginal inference problem computing, let's say small marginal distributions from the big joint distribution.",
            "There is also learning parameters, and then there's the map estimate problem, which says what's the most likely configuration of these X variables?",
            "Under this distribution, and spit that out and spit out the value of the Max.",
            "So that's the map problem, and it turns out this is useful in all sorts of interesting application areas from things like image processing, protein folding, it's useful encoding, communication theory, Turbo codes, and all these other really amazing codes are basically solving these types of problems there.",
            "Decoding by finding the most likely configuration.",
            "And if you look at this problem, these are.",
            "And discrete variables.",
            "If you really want to find the solution, brute force, you just go out and try every possible configuration and so brute force finding the most likely configuration takes a lot of time.",
            "OK, that's the product of the cardinality's of all your variables, and so we want to avoid that.",
            "And it turns out you can do efficient things and avoid this brute force.",
            "Let's say map problem if your graph is a tree and so people know since Perlin before as well that you can efficiently find the most likely configuration.",
            "If the graph is singly linked, there are no loops.",
            "However, paper by Shimony 1994 points out that in general this problem is NP hard if you give me an arbitrary graph.",
            "OK, so there's a big jump between all graphs and trees, and so then there's been a lot of.",
            "Extra work on finding other cases in between these two where we can also say that map is not hard.",
            "And so, in addition, there are ways of approximating the problem, and so in those settings you might be able to also show how you can estimate it with approximation there's, let's say, two out of many approaches that I'm going to be talking about today.",
            "The first approach is you relax the problem, so you soften this, otherwise, tutorial hard problem.",
            "The first one is the, let's say First order LP relaxation, which is what Wainwright worked on.",
            "Another variant is this true rated Max product approach?",
            "Higher order LP relaxations which have been working very well recently.",
            "And then other techniques to solve linear programs.",
            "That's what LP stands for.",
            "You solve a relaxation and then you round it to get back to discrete solution.",
            "And there's still the issue of one of these linear programs.",
            "Tight when are we solving the LP and really getting an answer that's true to the?",
            "That's closer.",
            "The exact discrete problem, and another approach is to run this really simple algorithm called Max product or message passing, which works well on trees and just to run it blindly on these otherwise non tree graph.",
            "So loopy graphs.",
            "So it's not guaranteed, and it turns out this works very well in practice."
        ],
        [
            "And it's actually one of the the best techniques.",
            "So Max product actually works well for images, for Turbo codes and all sorts of other practical problems.",
            "But there are very few guarantees on it, so here's the Max product algorithm I won't spend too much time discussing it.",
            "Basically, each node sends a message to the Clique clique, send messages to each node, and you keep going until these messages converge.",
            "It's a very simple, lightweight update rule and you're you're solving this map problem.",
            "By iterating and then eventually, once you've converged, you can read off the most likely setting for each variable.",
            "So here is the most likely setting for your first variable weight to the NTH variable.",
            "So it's very simple, very fast.",
            "That's exact for trees, and then in 2001 your wison Bill Freeman showed that you can also use this method for single loop graphs, so if your graph has a single loop, this will also, under some mild assumptions, also give you the optimal answer, and then Wainwright and others also showed that what it's doing when it converges it's finding.",
            "Locally optimal solution.",
            "So once it settles down you're still.",
            "You might not have found the global solution, but there are some local optimality guarantees and of course it seems to work well in practice.",
            "And then recently, Wainwright and others have pointed out that what Max product is doing is very similar to the 1st order LP relaxation, and if it is a tree then Max product is literally solving the 1st order LP relaxation.",
            "And so then later on another family of graphs have been thrown into the mix.",
            "So we know about trees.",
            "We know about single loop graphs and then recently people have showed that Max product this very lightweight map estimation algorithm also works for matching zanfer generalized matchings.",
            "So Biotie Sean Sharma 2005 said you can solve very loopy graphs called matchings where there's tons of loops and it will still give you the optimal answer and then recent work.",
            "We showed that you can also solve generalized matchings and I'll get to that in just a second.",
            "So here is."
        ],
        [
            "The simplest version of matching this is called bipartite matching, and the problem we're trying to solve is something like the Google AdWords problem.",
            "We've got 3 words and three advertisers.",
            "Each advertiser is bidding on a word, and here I'm looking at the offline version of the problem.",
            "Each advertiser says, well, if you show my ad when somebody types laptop, Apple will give Google $2.",
            "If you show the Apple ad when somebody types phone, Apple will give Google $3, and so there's a matrix of pay offs and we're interested in finding is, let's say the matching of the best.",
            "Match for each word to each advertiser to maximize dollars.",
            "So this is the.",
            "Bipartite matching problem because there's two sets of items we're trying to match and what we're going to do is, given the weights were given, the payoff matrix, we want to maximize the sum of the weights times.",
            "This selector variable C, which is binary which selects who gets matched with whom, and this binary matrix has to sum to one row wise and to one column wise, and so we want to find the most profitable configuration.",
            "And it turns out this problem has been solved since the early 60s, and even before with the classical Hungarian algorithm which takes N ^3.",
            "However, you can set this problem up as a graphical model.",
            "It's very loopy.",
            "We'll see that in just a second, but if you run Max product on this very loopy graphical model in cubic time, you'll get the optimal answer, and so Max Box will also work properly here and then.",
            "The proof of that is in BIOT, in 2005."
        ],
        [
            "I've.",
            "And so we generalize that to the setting of, let's say be matching, where instead of saying when I type laptop, show me one, add Google actually shows you three ads when you type a search.",
            "Here we're showing two ads.",
            "So what's the best two ads to show when someone types laptop?",
            "It's best to show Apple and IBM when someone types server.",
            "It's best to show, let's say, Motorola and IBM and so on, because at the end this matrix now is constrained to some role wise and column wise to two instead of to one.",
            "And so that's just the direct generalization of 1 matching.",
            "Now it's be matching.",
            "We're still maximizing the total payoff over this binary matrix, and has stuff to be role wise and column wise.",
            "And so this combinatorial be matching problem.",
            "People know you can solve in order BN cubed an.",
            "It's it's roughly like the Google AdWords problem, although the Google AdWords problem is a little different because it's it's solved in an online setting and this yet against creates a very loopy graphical model.",
            "Tons of loops, but if you run Max product.",
            "On this thing it will also give you the optimal answer even though it's not a tree.",
            "In order to be in cube and you'll get the exact map estimate very quickly and so."
        ],
        [
            "Here's what the graphical model looks like.",
            "It's two layers on the top layer are the.",
            "Let's say the advertisers.",
            "The bottom layer are the words.",
            "And then what we have is a bipartite graph, and we have these M functions which basically say.",
            "M of one of these variables is the set of neighbors it connects to.",
            "OK, so M Maps.",
            "Let's say one of these notes to the set of.",
            "Let's say one of these advertisers to the set of words that advertiser wants to pick.",
            "So this is a function and what we're going to find these random variables, which are the all the possible outputs of these functions.",
            "So XI are all the possible and choose B configurations for each one of these advertisers or or each one of these words.",
            "And then we can write the graphical model down.",
            "It looks just like this, and if you just follow the rule product of cliques in here for the partition function to normalize.",
            "These are all non negative functions defined over these pairs of variables and then also these Singleton potentials which just say how much value.",
            "Well, the exponentiated dollar amount basically is what's going on in these Singleton potentials.",
            "And then in these pairwise potentials all these pairwise potentials are saying is.",
            "If somebody picks you and you don't pick them back, the probability goes down to zero so it's enforcing reciprocity.",
            "So that's all this probability distribution function is saying and then we can run Max product on this and it turns out it has."
        ],
        [
            "To give you the optimal answer and so this is the theorem, it converges in order BN cubed and the way we figure this out and prove it is by unwrapping this message passing tree.",
            "This computation tree by acting like we have unrolled that network in time.",
            "So we've got the you later, then some vilayer some more you layer some more view layers and then we look at how many layers we have to unwrap before the inference problem on a tree.",
            "In this unwrapped graph is exactly equivalent to the inference problem on the loopy graph.",
            "And so we can show that in.",
            "Let's say that that much time we're going to get the optimal.",
            "And then recently there was a further refinement which shows that.",
            "This is actually not the best you can do.",
            "The Max product algorithm for one matching under mild assumptions on the edge weights can actually solve the matching problem in order N squared time, so that makes it very competitive with some of the best methods out there for solving matchings."
        ],
        [
            "OK, so here's how the algorithm is working.",
            "We're basically sending messages back and forth between the advertisers and the search terms.",
            "You can download this code.",
            "We've run it on large problems with hundreds of thousands of nodes on the Netflix data set.",
            "For example, things like this and it will converge so that at the end each node has two neighbors.",
            "So this is this is the be matching."
        ],
        [
            "Equals 2.",
            "And it turns out, if you compare this against the.",
            "The combinatorial solvers.",
            "It's three or four orders of magnitude faster.",
            "And you can also run it in the unit part time matching mode, and you can early stop it if the weights are picked, let's say according to that recipe by Saladin Shaw, and we've run this algorithm in clustering problems in classification problems and collaborative filtering problems, and semi supervised problems and visualization problems.",
            "And it's a very nice tool.",
            "It works as a great competitor to K nearest neighbors because it's forcing everybody to have only K neighbors, whereas K nearest neighbors because of greediness can sometimes give some nodes much more than K. And so again, this is very fast.",
            "And here's an example of."
        ],
        [
            "We use it in the unit partite setting.",
            "So now instead of having advertisers and search words, everybody is in one common category.",
            "Here's some data on two rings and I'm just going to scale the inner ring so that it gets bigger over here this way.",
            "So as I go to the right, the bigger rings get the little ring skinny bigger, and as I go from top to bottom, there are fewer samples on each ring.",
            "If I run K nearest neighbors of K = 2 on the top left, it does the right thing.",
            "It connects the two rings properly, but if I start scaling the inner ring, then K nearest neighbors getting confused and get more points connecting towards the middle, or if I downsample the inner ring as well, you get more points connecting to the middle.",
            "And that's because these points actually think these guys are closer to them than other points on the ring, and these points in the middle are getting too popular.",
            "Getting over selected.",
            "So if everybody picked their neighbor in this room who is closest to you, the people in the middle of the room will actually get picked more often because more people.",
            "So that's my neighbor then people at the periphery.",
            "And so this is the problem with K nearest neighbors.",
            "An if you just replace it with unique."
        ],
        [
            "Part IP matching you fix this issue.",
            "Now everybody's got two neighbors and we minimize the total amount of string to connect everybody here if you want to calculate the problem this way instead of a maximization here to minimizations and so.",
            "One application for this is in visualization."
        ],
        [
            "In machine learning we like to form these graphs to visualize manifold low dimensional manifold of data, here's a visualization algorithm that's been built on a number of websites and it turns out many websites are connecting to these really popular nodes that look very generic that have something to do with billing, and you don't see the structure because everybody's picking these really popular nodes at in this Euclidean space where we did K nearest neighbors.",
            "This noise happened to be in the middle, and so everybody thinks they're very close in high dimension.",
            "If you force everyone to have B = 4 neighbors, then you get a much nicer connectivity and then you get to see Yahoo and Google out here close to each other.",
            "You can see the airlines over here with American Orbitz and so forth.",
            "Southwest Airlines, Kmart in Best Buy, and Walmart and Sears and Home Depot popping out nearby because we don't get this artificial connectivity because of K nearest neighbors.",
            "OK, so that's just an application, but."
        ],
        [
            "It shows you how we can solve what looks like a very nasty problem exactly with just Max product.",
            "And here's the unit Partite version for the unit part diversion.",
            "It's really an asymmetric symmetric weight matrix, and all we're looking at our edges, so we're going to get a symmetric connectivity as well, and the problem just basically changes a little bit.",
            "We're going to maximize the pay offs and then we're going to force symmetry on the matrix here.",
            "Force it to be binary.",
            "Enforce it.",
            "Cedar on the diagonal so that you can't choose yourself as your own neighbor, so this.",
            ", further problems with solving that be matching an.",
            "We can again solve it by Max product and it turns out there is an efficient algorithm which is polynomial time which goes back to the 1960s by Edmunds.",
            "And what Edmunds pointed out is you can solve this by keeping track of an exponential number of linear inequality's in your.",
            "In this linear program, to enforce the integrality of the solution, these are called the Blossom inequality's, and there's an exponential number of them, but Edmonds.",
            "Devise a clever scheme to avoid enumerating all of them in a brute force way, so you can still get something cubic time that will solve this problem using Edmonds Blossom algorithm.",
            "It's a very beautiful approach to solving these types of problems, and later on in the in the in the uniparty case, sangavi proved that Max product will be exact if this LP is going to be integral.",
            "So it doesn't always work if the LP is not integral and he has this proof that followed our paper, which said you can still run this algorithm in the unit partite setting.",
            "It won't be optimal unless you're lucky in the LP's integral.",
            "So how do we know if the LP is integral?"
        ],
        [
            "So clearly.",
            "Max product and the solution for the map estimate both depend on this idea of LP integrality and it turns out matchings have some nice properties that can be used to argue for LP integrality and that's what Edmonds did to prove his algorithm.",
            "How do we generalize beyond matchings?",
            "And it turns out the natural path is through perfect graphs and if you have a perfect graph you can prove LP integrality.",
            "So that's the tool and that's where we're going next.",
            "Low vaches theorem right after his proof of the week.",
            "Perfect graph conjecture.",
            "So this is the theorem for any nonnegative vector F of weights.",
            "This linear program over X, which is now relaxed non binary vector subject to X being positive and acts being less than or equal to 1.",
            "So this set of linear constraints is always going to give back an integral solution if the undominated rows of this matrix A.",
            "This binary matrix a form the vertex versus maximal cliques.",
            "Incidence matrix of some perfect graph.",
            "So in other words, if I formed a from a perfect graph structure, this LP, also known as a set packing LP, is going to give me an integral solution."
        ],
        [
            "OK, So what does this a matrix look like?",
            "Well, here's what we're trying to solve this linear program.",
            "And if I'm given this graph.",
            "This happens to be a perfect graph.",
            "This graph has this a matrix for every clique we just put the variables that are involved in the clique.",
            "So there's X one X2X2 and X3 and so on.",
            "That's the matrix, so if you run this LP, you'll get a binary solution.",
            "OK, so that's."
        ],
        [
            "Right, but that's not quite what we want, because this lemma doesn't directly apply to the inference problem we had.",
            "It's not quite maximizing P of X on our graph G. We really have this different form.",
            "It's got these arbitrary clique functions.",
            "They're not necessarily binary like the a matrix, so how do we map this form so that it can be analyzed with low vaches lemma?",
            "OK, so we're going to try to figure out a way to plug this form into the lavash lemma and what we're going to do is.",
            "We're going to assume without loss of generality that all our cliques.",
            "Have, let's say one plus epsilon is their lowest value.",
            "OK, so that's not too bad.",
            "Used to find the minimum value for each clique divided by the by the values of the click and add a tiny epsilon, and then we're going to come up with the procedure to convert the graphical model into this thing called and and Markov random field.",
            "And that's called that's written as a curly G instead of G to distinguish it.",
            "OK, so this is a restrictive graphical model where instead of being arbitrary clique potential functions.",
            "An over arbitrary discrete variables.",
            "We're going to force all the variables in the NAND Markov random field to all be binary.",
            "We're going to call them Capital X.",
            "There's going to be capital N of them, and all the clique potential functions are pairwise NAND gates.",
            "OK, so for any pair of variables that are connected by an edge, only one of them can be on only one of them can be one, the other one has to be 0.",
            "So this is the inequality so they can both be 0.",
            "That's fine.",
            "That's still not aunt, but both can't be on simultaneously.",
            "OK, so that's the construct."
        ],
        [
            "And and here is an example.",
            "Here's a tiny little graphical model with two cliques, cliques, AB&BC and.",
            "Let's assume AB&C are all binary variables.",
            "Here's the NAND Markov random field on the right side.",
            "And how do we construct this when we first initialize the NAND mark of random field?",
            "Is the empty graph and then for each click in the graph in the original graph I look at every possible configuration of that clique and a former variable binary variable for every one of those configurations.",
            "OK, so for every click an every configuration to click, I create a binary variable and then I connect that binary variable to any other binary variables.",
            "So far in my graph, if they disagree.",
            "OK so here are all the possible configurations.",
            "Click a Beacon B and configuration 00011011 and there's edges between all those four.",
            "Because you can't be both in one configuration and another, and similarly over here and then there's also these edges between let's say BC00 on a B11 'cause this guy saying be has to be one.",
            "This guy saying he has to be zero.",
            "They disagree.",
            "There's also an edge so there's all these NAND edges between all the possible binary configurations and now we have something that plugs into lashes.",
            "Formula OK, so imagine now every edge here is just an and function."
        ],
        [
            "And so now here's the.",
            "Probability density implied by this graph, curly G. It's a product over all these non functions.",
            "If there are edges between these pairs of variables, XYK and SDL so.",
            "The ex came from click see and it's is seeing the calf configuration and the other ex came from click D in itself configuration.",
            "If they disagree then that that click function gets raised to the power of 1 and it's active and then over here we've got these weights for every possible configuration.",
            "We just set the weights to be the log potentials for that Cle configuration value.",
            "So this is a very simple conversion.",
            "Now we have this non Markov random field.",
            "It's got many more variables the size of this non marker random field.",
            "Has N variables, it's the sum of all the cliques.",
            "Overall their configurations, so things got exponentially big in each individual clique, but the graph still hasn't grown in terms of the total number of clicks.",
            "It's still only growing linearly in a number of the cliques, but the size of the cliques, the Max clique size is really the bottleneck here.",
            "OK, so now if I look at one of these binary variables and it says equal to 1, then I know that clique C is in configuration K out of all the possible EXE configurations.",
            "And this is clearly subjective.",
            "There's many more configurations of capital X then little X OK, because again, I've enumerated all these possible peaks, there's many.",
            "Disagreeing configurations, there's more total configurations in X, but the NAND relationship prevents any.",
            "Individual clique from having more than one configuration anyone time and then through this simple theorem if the weights are positive, the map estimate extar of this landmark of random field yields this constraint equal to 1 for all variables in that particular clique, and so it's basically saying is if you are looking to maximize this rovex, you're not going to get these silly configurations where nobody wants to be assigned in that clique, and you're going to say.",
            "Everything at exes unassigned.",
            "You're always going to get one assignment if you're doing that."
        ],
        [
            "So what's nice about this is now we can say that the map estimator for role of X on this non Markov random field recovers the map estimate for P of X by find the solution over here using the non Markov random field.",
            "I can use that to reconstruct them.",
            "An equivalent map estimate for the original graph.",
            "So I can now work with and and mark of random field and forget about the original graph and just use that as my my problem graph.",
            "And it's nice because now if I relax this map problem on row of X.",
            "And instead of considering binary variables in mine and marker annefield, I just considered variables between zero and one.",
            "That's the LP relaxation.",
            "This looks just like the set packing linear program that Lavash describes and formulates integrality arguments for.",
            "OK, so now if the graph G in the non Markov random field curly G. If that's perfect, then the LP efficiently solves the map problem and it's going to give you the integral answer.",
            "You're not going to get fractional solutions, so here it is.",
            "Again, this is the theorem, and now we can just say, well, this graph, if it has it's perfect, it will form the appropriate a matrix and we'll get back.",
            "A discrete solution instead of a fractional solution."
        ],
        [
            "OK. And so.",
            "Here is the the kind of more formally standing what I just said for any general graph we know map is NP hard, But if you convert the graph into the non Markov random field, that's a polynomial time conversion.",
            "If I know graph G is not is then perfect after I've converted it, then I just run this find maximal cliques procedure, which is also polynomial.",
            "And then I solve the math problem with the packing linear program, which is also polynomial.",
            "So if this is true then I can solve the problem in polynomial time.",
            "And so here's the theorem.",
            "The map estimate of any graphical model G with cliques see elements of capital, see all the maximal cliques if it forms and and Markov random field whose graph is is perfect, then the inference problem is polynomial.",
            "And it needs basically that number of variables in the LP cube.",
            "That's how long it takes to solve an LP.",
            "It's cubic time in the worst case, so we can solve in cubic time the map problem.",
            "If the graph is perfect.",
            "OK, so now some of you might say, well hold on a minute Tony.",
            "There is an if here and this might take."
        ],
        [
            "A lot of time an until very recently this could have taken.",
            "This could have been an NP hard step, so I tried to pull the wool over your eyes by saying Oh well if I can do this then I can do the rest of the stuff in polynomial time.",
            "So it turns out in 2006 Maria Trynowski showed that you can also check if the graph is perfect in."
        ],
        [
            "Polynomial time that result.",
            "We just talked about in the first slide and so now all these steps are polynomial time.",
            "So for any graph I can go through this conversion and check and solve in polynomial time.",
            "If it's perfect, get get an exact answer.",
            "So this defines a larger family of map problems where we can get the exact solution that goes beyond trees, let's say.",
            "OK, so now this is all polynomial."
        ],
        [
            "Time.",
            "Let's go back and talk a little bit about perfect graphs and this algorithm for second, so that the algorithm again to determine if G is perfect.",
            "If you want to.",
            "Not think about it.",
            "You can just run this algorithm and Delbert Duek implemented in my group it's order N to the 9th.",
            "So it only works on small graphs.",
            "It's close to the brute force search, almost because unless the graphs are really large.",
            "This is not going to be helpful.",
            "And you can do that check and then get a binary answer that yes, it's perfect or or notes.",
            "It's not perfect.",
            "Or you can use some of the tools from perfect graph theory instead of just running an algorithm blindly.",
            "OK, so you don't have to just use this algorithm, which looks like a nightmare of order N to the 9th.",
            "OK, so how do we?",
            "How do we?",
            "Some of the tools from perfect graph theory?",
            "Let's go through some of them.",
            "I can't possibly do the field justice because, again, there's many, many different papers in this area, but let's just recall what a perfect graph is.",
            "A perfect graph has clique number.",
            "Equal to coloring number for all its subgraphs, so the click number of a graph is a size of its maximum clique.",
            "What's the largest set of fully connected notes?",
            "The chromatic number of a graph is the minimum number of colors that I can paint all the vertices with such that no two adjacent vertices have the same color OK, and so perfect graph is a graph where every induced subgraph H which is inside G satisfies this property.",
            "So if I delete a node in its edges.",
            "That remaining sub graph also has to be perfect and also has to satisfy clique number equals coloring number.",
            "OK, so here is an example of a perfect graph.",
            "The fully connected graph over 5 nodes.",
            "If I delete any one of these nodes and all its edges, I still have a fully connected graph.",
            "So here I need five colors to color this and the maximum clique sizes 5.",
            "This is not a perfect graph because the maximum clique size is 2.",
            "An I need more than two colors to color this thing.",
            "I need three colors over here.",
            "The maximum size is 2 and I only need two colors color this thing just alternate between red, blue, red, blue, red, blue because it's an even cycle, so that's."
        ],
        [
            "That's giving us more detail about perfect graphs.",
            "And then now let's see how this relates back to Berge graph.",
            "So the strong perfect graph Theorem says a graph is perfect if and only if it is brush.",
            "So what is bersch iburst graph is not the same definition of the perfect graph.",
            "Otherwise this theorem would be trivial.",
            "The Burst Graph is a graph that contains no on whole and whose complement also has no odd hole.",
            "OK, so the theorem was basically proving that if that's the property then you have to have a perfect graph and vice versa.",
            "And so a whole is an induced sub graph.",
            "Which is a cordless cycle of length at least 5.",
            "OK, so cordless cycle, least length 5 and BYOD holy mean that the cycle length is odd, so 5, seven, 911 and so forth, but three in one or fine.",
            "OK, and.",
            "So the graph has to have no odd whole an it's compliments also has to have no idea what's the graph complement graph complement is just G bar where you take the same vertices as G and for all pairs of vertices if they're adjacent in G then they become non adjacent in G bar and vice versa.",
            "So whoever was not connected connects and whoever it was connected disconnects in G bar.",
            "So if there are no holes in G and there are no holes in G bar then it's a burst graph.",
            "So here is an odd hole.",
            "Here's an even whole.",
            "Here's a knothole and again, you know you can keep trying to recognize these structures in your birth graph and say, oh, this is not a birth graph because they found one of these five holes, or seven holes, nine holes and so on.",
            "OK.",
            "So."
        ],
        [
            "Nope.",
            "Once again, we could just run the order to the 9th algorithm, but you not ski, or we could use some of the lessons learned about Berge graphs and perfect graphs from the strong perfect graph theorem.",
            "So it turns out that they.",
            "In developing a strong perfect graph theorem, an algorithm popped out and a whole bunch of other theoretical tools popped out.",
            "So let's just review the algorithm very quickly before we look at some of the other theoretical tools.",
            "So if you give me a graph GI run tradeoff since algorithm in order to add to the 9 and that says.",
            "Version operation and then I run it on the compliment version, not version.",
            "If they both say first then I know it's a verse graph.",
            "And so here's the actual four steps of the algorithm.",
            "You first detect if the graph contains a pyramid structure.",
            "I don't want to spend too much time on this, but that's that.",
            "Basically, looks like this this pyramid in the graph.",
            "It's kind of a geometric analogy, and you do that by running all shortest paths on your graph.",
            "It's inefficient algorithm, and then you look at all new pools of vertices, so all subsets of nine vertices in a graph.",
            "That's where the order enter the knife comes in.",
            "That's the killer part.",
            "You have to look at all order into the night.",
            "So that's one step of the algorithm.",
            "We did try to detect other structures like a jewel structure and a few other easy to detect structures in the graph.",
            "And if you don't find those and keep going and then we perform a cleaning procedure which basically vertex in the graph is C major.",
            "If it's set of neighbors is not a subset of vertex set of any three vertex path.",
            "So there's this cleaning algorithm that corner way holes and a few other graph theorists developed.",
            "So you run the cleaning algorithm by corningware holes.",
            "And then there's a few other things you do with shortest odd holes, and you compute shortest paths between triples vertices, But that's much faster than the enano pools of vertices.",
            "And then you can decide if it's a perfect graph or not.",
            "Of course this is slow.",
            "It's order into ninth.",
            "There are faster methods that find all holes.",
            "The problem with this is all odd and even holes, and so the graph might still be perfect and this thing will tell you oh, it's got a hole, but it's OK if it's got a 6 hole or an 8 hole or a 10 hole, as long as it's not whole.",
            "But you can use this as a faster algorithm, which is roughly cubic time instead of an to the 9th.",
            "We've run this algorithm on 300 nodes.",
            "This thing is a good kind of quick check before you go to the full.",
            "Definitive algorithm.",
            "OK, so that's."
        ],
        [
            "That's how you run the algorithm, But it turns out the strong perfect graph theorem gives you a lot of machinery to do stuff with pencil and paper.",
            "Instead of running an algorithm, the first thing it tells you is a burst graph has to be one of these five graphs, which are these primitive Berge graphs has to be either a bipartite graph, 2 chunks compliments of a bipartite graph, line, graphs of bipartite graphs, compliments of line graphs are bipartite graphs, and double split graphs are the simplest types of birds, graphs, or.",
            "It's a combination of simple burst graphs where these four gluing procedures have been used to glue together many pieces of birth graphs to create a larger burst graph.",
            "So these are called graph primitives or decomposition, so there's ways of gluing two graphs together with the two join or two during the compliment and joined a balanced view partition, so these are four techniques for gluing perfect graphs together.",
            "We're not going to detail on that, but if you recognize these things in your grass then you say Oh well, now I can break it up and see if the pieces are still.",
            "Primitives themselves and so just for definitions, line graph is just a graph where you connect the vertex for each edge.",
            "If the two vertex vertices of the line graph adjacent only if the two edges of G had it common vertex.",
            "So you place you replace the edges in your graph with nodes in the line graph and you connect it up that way.",
            "So that's the line graph, the standard construction."
        ],
        [
            "And here are some nice, so here's a little more detail about some of these nice tools that the The Commodores community uses to investigate.",
            "Perfect graph so.",
            "You can decompose the graph by trying to find 2 joins and joins.",
            "Q partitions replication in the graph and that helps you diagnose if it's perfect or not without running this giant algorithm.",
            "So one really nice lemma going back to 1972 Lavash again if you have a perfect graph and you take and you know, do you try to stick it into that perfect graph by connecting it to one of the vertices.",
            "If you connected to vertex V Prime and all its neighbors, then the resulting graph is perfect.",
            "So if I have this graph here and I bring it, and you know it and I want to connect it to this guy, if I connect it to him and all his neighbors.",
            "This graph also has to be perfect.",
            "So I've connected X7 to X4, but I also have to connect to X3 and X5 because their neighbors, so that's the replication lemma.",
            "That's a tool you can use to make proofs about your graphs and say it is perfect or not."
        ],
        [
            "Here's another one.",
            "It's called the skew partition lemma, but the simpler way of thinking of this is gluing on cliques.",
            "So if I have two perfect graphs graph, G&G, prime.",
            "And if their intersection where I'm going to include them on top of each other forms of fully connected click or click cut set, then the resulting merge graph is also perfect.",
            "So here's one graph.",
            "Here's another if I glue them on top of each other.",
            "On top of this fully connected clique, this is fully connected X 3X Four that also has to be perfect so I can grow these really complicated perfect graphs using these lemmas.",
            "These four or five lemmas."
        ],
        [
            "And using these we can now prove and I won't go through the detail of this proof that trees form perfect MRF's.",
            "And the LP has to be integral, so we know this from Judea Pearl in the 80s.",
            "But let's just let's just verify it.",
            "So let's say G is a tree.",
            "You give me a tree graph and I convert it into an and mark of random field which is curly G. That curly G has to have a perfect graph connectivity.",
            "So here's the proof.",
            "You start off by just working with stars instead of trees, and then you only look at one of the configurations before you look at all possible configurations.",
            "And you recognize that you're going to be forming AV.",
            "Partite graph.",
            "Once you realize if you formed the party graph that is perfect, then he used the replication lemma and you start connecting all the configurations that your V partite graph that keeps it perfect.",
            "So then I've proven that G for a star is perfect.",
            "Then to connect up a tree, just keep gluing these stars together until you form your tree so you can always construct a tree with all these little star graphs, and that's by using the Cricut set or the gluing on cliques lemma.",
            "So this proves that.",
            "Trees have to give you perfect graphs for your Nan Makarena field."
        ],
        [
            "Similarly, here's the bipartite matching graphical model that was proven in in our previous papers.",
            "This is what it looks like.",
            "That's the decomposition of the graph the the the formula for it, but the graph it turns out when I convert it into MRF form creates this type of structure for bipartite matching.",
            "This is called the Rooks graph.",
            "It's basically all the movements the Rook can do on the chess board, and so a rooks graph is basically the line graph of a complete bipartite graph, so we know that's one of the basic types of primitive first graph, so this also has to be perfect.",
            "So therefore this also has to be.",
            "Integral, and that's why that that proof was true.",
            "For, for bipartite matchings from the previous papers.",
            "OK, and then here is the unit."
        ],
        [
            "Type version of the problem.",
            "We're now we're just maximizing weights, but it's not two parts, it's just an arbitrary set of points, and we're trying to do matching.",
            "There aren't males or females, or, let's say, advertisers and search words.",
            "This is the formula for the likelihood.",
            "The most likely setting now is just maximizing this, and it turns out here it's a little more subtle.",
            "You have to now investigate the actual graph that you're being given and see if it's a perfect rap or not.",
            "So that's why Sangavi's 2008 paper said.",
            "If and only if the LP's integral, because you can always say it's integral, you have to check the graph topology here.",
            "So this is only if the G graph happens to be a perfect graph.",
            "OK, so some."
        ],
        [
            "For extensions, there are ways to further prove your landmark of random field.",
            "To search for perfection and efficiency.",
            "By just removing some of the nodes that aren't going to affect your LP.",
            "OK, so here are two procedures I don't want to spend too much time on, but you can run this procedure called disconnect and Merge.",
            "They're both efficient for disconnect, we just look at each fully connected clique and we disconnect the weakest member of that clique.",
            "You're allowed to do that, and then you can still recover the map problem from this disconnected man Markov random field, but you might have something that's either more efficient or now looks perfect when the other one wasn't perfect.",
            "And so you can do some disconnections in your landmark around the field if you like.",
            "You can also do merging, so if a pair of nodes.",
            "Have the same neighborhoods.",
            "You can merge them together and say I'm going to just since they have the same neighborhoods.",
            "If one is on the other, one has to be on.",
            "If one is off, the other one has to be off.",
            "And so you can do this merging and then solve for a single variable instead of these two variables.",
            "You can solve for a single SDK and you replace its weight with the sum of the two.",
            "The two separate nodes weights.",
            "So these are two procedures you can run on the graph than an Markov random field that will speed things up.",
            "And then finally, instead of."
        ],
        [
            "Actually solving the LP, you can use these faster solvers based on Max product and this variant of it that was proposed in 2007 called Convergent Message passing and what's nice about convergent message passing is it's always guaranteed to solve the LP if the LP's integral and it's a binary relaxation.",
            "So that's the theorem by Globerson Yakola.",
            "Here's the algorithm.",
            "It's a slight variation of Max product.",
            "It's a little more work, but nothing major, and it will always solve the LP for you.",
            "Whereas match product might have some other problems and not converge, sometimes it'll get stuck and not not update.",
            "And so they."
        ],
        [
            "The theorem from global sinicola is if you have binary variables, then the fixed points of convergent convergent message passing recover the optimum of the LP, so you won't stop at a local sub optimal solution and so similarly as a nice corollary convergent message passing on an MRF with a perfect graph will find the map estimate.",
            "OK."
        ],
        [
            "So just want to close for some.",
            "Very quick experiments just to investigate if this really works.",
            "We implemented this and instead of looking at the LP, we actually ran message passing and we ran message passing on this unique partite matching problem.",
            "And so the theory tells you if the graph is perfect, you're going to get the right answer.",
            "If it's not perfect, you're going to get the wrong answer.",
            "OK, or possibly you could get lucky and still get the right answer and we can get the exact estimate by running Edmonds Blossom algorithm that will always give you the right answer.",
            "That's the common tutorial solution and we can compare the two.",
            "And so here's a graphical model.",
            "Again, this is the unit partite matching.",
            "These are the weights between all the pairs of points and then each point can Only Connect to one other neighbor.",
            "That's all this is saying these constraints so.",
            "Only pick one of your neighbors out of all your potential neighbors in the grass, so we compare the solution found by message passing on the MRF to Edmonds algorithm and we try different topologies.",
            "Try perfect graphs and non perfect graphs and so here are the results."
        ],
        [
            "Here if we fed the algorithm perfect graphs, the solution that the message passing algorithm gives is the same as the Edmonds algorithm.",
            "If we give it non perfect graphs, just random graphs afal Shorten doesn't find the best solution, so this kind of agrees with the LP integrality arguments, but now we can actually throw perfect graphs in there and see because we went out and actually generate perfect graphs.",
            "We basically did the four types of basic purge graph.",
            "So bipartite, complemented, bipartite.",
            "Line graph and component of line graph.",
            "When we set up those types of graphs, we've got the exact map estimate, otherwise we didn't get it.",
            "If we had random graphs.",
            "For for this matching problem it has to be it has to be perfect, yeah?",
            "And there are some slight issues with numerical and early stopping.",
            "That's why there's a couple of circles below the exact solution.",
            "But just to wrap up."
        ],
        [
            "Again, perfect graph theory is fascinating.",
            "There's a lot of great work, very recent development in this area.",
            "It's a crucial tool for exploring LP integrality LP relaxations.",
            "There's many great algorithms and theoretical breakthroughs, and we know that this is important for graphical modeling because the LP Integrality's is a central question when you're trying to find the map estimate for graphical models and inference and so now we can say for any graphical model, if the MRF's perfect map is going to be exact and it's going to be.",
            "Efficient and we can also test for perfection efficiently.",
            "Maximum clique and LP can be solved all efficiently.",
            "You can also use Max product or message passing instead of LP's and so now this extends the results for map beyond trees.",
            "Single link graphs, single loop wraps, matchings, and generalized matchings to this big family which really just contains these various crafts called the."
        ],
        [
            "For graph family, so there's some additional work.",
            "This paper will appear next week at the uncertainty in AI conference.",
            "There's some very nice survey paper by Martin Wainwright and Michael Jordan.",
            "This is our previous paper on the generalized matchings, and I'd like to thank Maria Trynowski, Delbert Deck and Bert Huang for collaborating on this work.",
            "Thank you.",
            "Yeah.",
            "Take into account.",
            "So that's a very good question.",
            "So in the first part of the talk it doesn't matter what your click potential functions are, you construct an and mark of random field.",
            "But when you want to run the disconnect and merge algorithms, then it matters what the potential functions are.",
            "And then it starts to give you a different topology because it's looking at what is the weakest configuration in your click function.",
            "Remember question such comment is so I would be surprised if you can so you can believe it for specifically for that process we can have one dresser abridgement for others.",
            "But other than that, I would be surprised if we come into that.",
            "If there are graphs that are not low huge graphs for which there is opening that graph without thinking 'cause people petrol, which resulting number is a perfect growth in recent ask?",
            "That is because.",
            "Actually, last we are showing for.",
            "Graduation is only easily on local corruption.",
            "You can't exactly position of grass in which vaccination is easy is valuable credits.",
            "So I think this is relying on similar both.",
            "Both people graphic Pen Supergirl conjectures, but this was not the case then that would be extremely interesting.",
            "So that's a very good point.",
            "So I'm not saying that what we've said here actually disagrees with your paper, and in fact I'm familiar with that work, because we haven't been able to identify situation in which it was perfect yet.",
            "So beyond those three known results, although we've explored were graphs where we also had to do some deletion to get perfect graphs, so maybe there are some settings that we just haven't explored it yet where we can say no deletion for any any click functions on this potential loopy graph, there's still a perfect graph in there.",
            "So we haven't found the counterexample.",
            "But we've explored those three families, matchings and trees, and then things with delete and disconnected merge running with them.",
            "So yeah, I don't have a concrete answer, and to say that there's an actual counterexample to two.",
            "You know the hardness claim in your paper.",
            "Yeah.",
            "So that's a very good question.",
            "We haven't really looked at at any particular scaling behavior with different types of perfect graphs.",
            "My hunch is if you're solving the LP and you have a really large clique incidence matrix, that's going to slow things down.",
            "So if you it's going to depend on the number of clicks, but also on this clique incidence matrix.",
            "But again, we haven't really pushed the envelope and saying can we characterize how things speed up or slow down depending on the different types of perfect graphs?",
            "One thing we did do though, is we looked at the effect of introducing some.",
            "Odd holes and it says current work with with Albert do ekanite does so.",
            "Some types of bottles are still not too damaging.",
            "You still get very good inference, but there is no theorem there yet.",
            "OK. Alright, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you and thanks for sticking around for the last session, so I'll be talking to you today about a new topic that I got excited about recently and actually took courses and did a lot of reading to basically develop my background.",
                    "label": 0
                },
                {
                    "sent": "It's not really my area, but there was a lot of excitement about perfect graphs in the past few years and I thought there may be connection to machine learning and inference problems, and it turns out there is and I'll be talking about one possible contact point between this.",
                    "label": 0
                },
                {
                    "sent": "Really active area in combinatorics called perfect graphs and how it can help with map estimation.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so today's talk is basically going to be a quick overview about what perfect graphs are.",
                    "label": 1
                },
                {
                    "sent": "And how they connect to graphical models and graphical models is going to be the main application of the combinatorics.",
                    "label": 0
                },
                {
                    "sent": "We're going to be talking about today and also talk about how I got excited about perfect wraps really from a.",
                    "label": 0
                },
                {
                    "sent": "Prior work in matching zanin generalized matchings, which are specific incarnations of perfect graphs and then we'll talk about how to use this machinery by converting graphical models from their usual format which were used to in machine learning.",
                    "label": 1
                },
                {
                    "sent": "It's something I call and and Markov random field and once we've done that conversion then we can start exploiting all these tools from perfect graph theory, including several theorems, algorithms and a lot of really important breakthroughs and once we start exploring those tools will be able to prove.",
                    "label": 1
                },
                {
                    "sent": "Some nice map results, so one can we do maximum Maple story estimation exactly in graphical modeling using this perfect graphs machinery and then?",
                    "label": 0
                },
                {
                    "sent": "In addition, I'll talk about some experiments and some other future work and future directions with perfect graphs.",
                    "label": 0
                },
                {
                    "sent": "Can anyone hear me OK with the microphone?",
                    "label": 0
                },
                {
                    "sent": "Or is it OK great?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what are perfect graphs?",
                    "label": 0
                },
                {
                    "sent": "Perfect graphs have been around for a long time and they are very active area in the combinatorics community and the originator of perfect graphs.",
                    "label": 0
                },
                {
                    "sent": "Is this fellow cloud Burge, who in 1960 proposed this interesting family of graphs.",
                    "label": 0
                },
                {
                    "sent": "That he later on went on to call the perfect graph.",
                    "label": 0
                },
                {
                    "sent": "And here's an example of one such perfect graph.",
                    "label": 0
                },
                {
                    "sent": "This is the rooks graph, and he also proposed two conjectures.",
                    "label": 0
                },
                {
                    "sent": "He had these two unproven theorems.",
                    "label": 0
                },
                {
                    "sent": "The first one is called the weak conjecture and the other one is called a strong conjecture.",
                    "label": 0
                },
                {
                    "sent": "An first let's just say what did Birge mean when he said perfect graph?",
                    "label": 0
                },
                {
                    "sent": "So what burst means by the definition of a perfect graph is it's perfect if and only if every induced sub graph of your graph has click number equal to coloring number.",
                    "label": 0
                },
                {
                    "sent": "So we'll come back and talk about that.",
                    "label": 0
                },
                {
                    "sent": "More specifically, but if your graph satisfies the property, then it's called perfect.",
                    "label": 0
                },
                {
                    "sent": "And then are these two conjectures.",
                    "label": 0
                },
                {
                    "sent": "So we conjecture is if the graph G is perfect, then the complement of G has to also be perfect.",
                    "label": 0
                },
                {
                    "sent": "That's called the weak theorem.",
                    "label": 0
                },
                {
                    "sent": "And then there's a strong conjecture, which is all perfect.",
                    "label": 1
                },
                {
                    "sent": "Graphs are Berge graphs and so we'll define burgraff later on, but that's another family of graphs, and it wasn't quite certain if they were basically one in the same thing.",
                    "label": 0
                },
                {
                    "sent": "We're all first graphs, really.",
                    "label": 0
                },
                {
                    "sent": "Just perfect graphs, whether the same family or there were some cases that were.",
                    "label": 0
                },
                {
                    "sent": "And one one subset and not the other.",
                    "label": 0
                },
                {
                    "sent": "And so these two theorems have been.",
                    "label": 0
                },
                {
                    "sent": "Very important driving forces in the comment or community and the first one the week perfect graph theorem was solved by low Vashon, 1972.",
                    "label": 0
                },
                {
                    "sent": "And in addition, in 1972 Lavash identified a nice link between perfect graphs and integral LP's, so integral LP's are crucial to map estimation with graphical models.",
                    "label": 1
                },
                {
                    "sent": "And that's where the real contact point comes in.",
                    "label": 0
                },
                {
                    "sent": "Let me just just this a little bit.",
                    "label": 1
                },
                {
                    "sent": "But the other theorem, the strong perfect graph theorem, remained open for over four decades, and many, many researchers struggled this theorem, and it was only recently solved after over four decades of.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of a.",
                    "label": 0
                },
                {
                    "sent": "Of serious effort and the final proof came out a couple of years ago in 2003.",
                    "label": 0
                },
                {
                    "sent": "By these four folks, the Maria to Nowski Neil Robertson, Paul Seymour, and Robin Thomas and they finally said that this is no longer a conjecture.",
                    "label": 0
                },
                {
                    "sent": "It's actually true.",
                    "label": 0
                },
                {
                    "sent": "The strong, perfect graph theorem.",
                    "label": 0
                },
                {
                    "sent": "As proven.",
                    "label": 0
                },
                {
                    "sent": "Every birds graph is a perfect graph, and then right after they discovered they reported it to version was actually very old and weak and sick at the time.",
                    "label": 0
                },
                {
                    "sent": "But they showed him the proof.",
                    "label": 1
                },
                {
                    "sent": "He verified it was correct and then he passed away shortly thereafter.",
                    "label": 0
                },
                {
                    "sent": "So there's a.",
                    "label": 0
                },
                {
                    "sent": "A little story behind the whole thing, but it's nice to see that conclusion of this open problem that lasted for over for it for decades.",
                    "label": 1
                },
                {
                    "sent": "OK, So what are perfect graphs good for?",
                    "label": 0
                },
                {
                    "sent": "Well in?",
                    "label": 0
                },
                {
                    "sent": "In algorithms, it turns out many algorithms when they're run on a perfect graph.",
                    "label": 0
                },
                {
                    "sent": "Actually become polynomial an efficient when they were generally NP hard, so an NP hard algorithm if you if you run it on a perfect graph, you can get efficient solutions.",
                    "label": 0
                },
                {
                    "sent": "And even if that algorithm is not just NP hard, but it's also NP hard to solve the problem exactly, so problem is NP hard or NP hard to approximate can be solved exactly if you work with perfect graphs instead of with a general graph, and so some of these examples are graph coloring.",
                    "label": 0
                },
                {
                    "sent": "Which is NP hard to approximate maximum clique maximum independent set these problems if you.",
                    "label": 1
                },
                {
                    "sent": "Try solving a perfect graph.",
                    "label": 0
                },
                {
                    "sent": "You'll get efficient solutions, and it turns out also in 2006 after this paper, an algorithm for recognizing perfect graph.",
                    "label": 0
                },
                {
                    "sent": "So if I give you a graph.",
                    "label": 0
                },
                {
                    "sent": "Can you test if it's perfect or not?",
                    "label": 0
                },
                {
                    "sent": "Also now exists which checks perfection and says yes.",
                    "label": 0
                },
                {
                    "sent": "It's perfect or no.",
                    "label": 0
                },
                {
                    "sent": "It's not perfect in order end to the 9th, so there's potential for improvement here, but at least now we know this is polynomial time.",
                    "label": 0
                },
                {
                    "sent": "You can give me a graph.",
                    "label": 0
                },
                {
                    "sent": "I can tell you if it's perfect or not and if it is perfect and all these other problems we can do efficiently.",
                    "label": 0
                },
                {
                    "sent": "Hey, so how do?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This relates back to graphical models and so in machine learning and inference an an other statistical problems we usually work with graphs that are also called graphical models, where we're interested in finding the most likely configuration of random variables, and we use the graph to identify dependencies between the random variables.",
                    "label": 0
                },
                {
                    "sent": "So most of you already comfortable with this notation, but a graphical model is basically a graph coupled with a probability distribution.",
                    "label": 1
                },
                {
                    "sent": "And what the graph is basically saying about the probability distribution?",
                    "label": 0
                },
                {
                    "sent": "Is it telling you how that probability distributions factorizes over all the variables?",
                    "label": 0
                },
                {
                    "sent": "So every variable is associated with the node?",
                    "label": 0
                },
                {
                    "sent": "And then instead of running this gigantic distribution arbitrarily, if I give you this graph over these six, let's say discrete variables X one to XN, this graph tells you that the distribution.",
                    "label": 1
                },
                {
                    "sent": "Factorizes as a function as a product of these little functions.",
                    "label": 0
                },
                {
                    "sent": "Over all the maximal cliques in the graph.",
                    "label": 0
                },
                {
                    "sent": "So find all the fully connected sets of nodes and you can rewrite this big distribution this way and efficiently store the distribution and also sometimes do some efficient inference, and so in the case upstairs we can give it that distribution over 6 variables into these product of smaller functions which are more efficient to work with.",
                    "label": 0
                },
                {
                    "sent": "So that's what a graphical model is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one of the Canonical problems with graphical models and machine learning is the map problem.",
                    "label": 0
                },
                {
                    "sent": "There's also the marginal inference problem computing, let's say small marginal distributions from the big joint distribution.",
                    "label": 0
                },
                {
                    "sent": "There is also learning parameters, and then there's the map estimate problem, which says what's the most likely configuration of these X variables?",
                    "label": 0
                },
                {
                    "sent": "Under this distribution, and spit that out and spit out the value of the Max.",
                    "label": 0
                },
                {
                    "sent": "So that's the map problem, and it turns out this is useful in all sorts of interesting application areas from things like image processing, protein folding, it's useful encoding, communication theory, Turbo codes, and all these other really amazing codes are basically solving these types of problems there.",
                    "label": 0
                },
                {
                    "sent": "Decoding by finding the most likely configuration.",
                    "label": 0
                },
                {
                    "sent": "And if you look at this problem, these are.",
                    "label": 0
                },
                {
                    "sent": "And discrete variables.",
                    "label": 0
                },
                {
                    "sent": "If you really want to find the solution, brute force, you just go out and try every possible configuration and so brute force finding the most likely configuration takes a lot of time.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the product of the cardinality's of all your variables, and so we want to avoid that.",
                    "label": 0
                },
                {
                    "sent": "And it turns out you can do efficient things and avoid this brute force.",
                    "label": 0
                },
                {
                    "sent": "Let's say map problem if your graph is a tree and so people know since Perlin before as well that you can efficiently find the most likely configuration.",
                    "label": 0
                },
                {
                    "sent": "If the graph is singly linked, there are no loops.",
                    "label": 0
                },
                {
                    "sent": "However, paper by Shimony 1994 points out that in general this problem is NP hard if you give me an arbitrary graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's a big jump between all graphs and trees, and so then there's been a lot of.",
                    "label": 0
                },
                {
                    "sent": "Extra work on finding other cases in between these two where we can also say that map is not hard.",
                    "label": 0
                },
                {
                    "sent": "And so, in addition, there are ways of approximating the problem, and so in those settings you might be able to also show how you can estimate it with approximation there's, let's say, two out of many approaches that I'm going to be talking about today.",
                    "label": 0
                },
                {
                    "sent": "The first approach is you relax the problem, so you soften this, otherwise, tutorial hard problem.",
                    "label": 0
                },
                {
                    "sent": "The first one is the, let's say First order LP relaxation, which is what Wainwright worked on.",
                    "label": 0
                },
                {
                    "sent": "Another variant is this true rated Max product approach?",
                    "label": 0
                },
                {
                    "sent": "Higher order LP relaxations which have been working very well recently.",
                    "label": 1
                },
                {
                    "sent": "And then other techniques to solve linear programs.",
                    "label": 0
                },
                {
                    "sent": "That's what LP stands for.",
                    "label": 0
                },
                {
                    "sent": "You solve a relaxation and then you round it to get back to discrete solution.",
                    "label": 0
                },
                {
                    "sent": "And there's still the issue of one of these linear programs.",
                    "label": 0
                },
                {
                    "sent": "Tight when are we solving the LP and really getting an answer that's true to the?",
                    "label": 0
                },
                {
                    "sent": "That's closer.",
                    "label": 0
                },
                {
                    "sent": "The exact discrete problem, and another approach is to run this really simple algorithm called Max product or message passing, which works well on trees and just to run it blindly on these otherwise non tree graph.",
                    "label": 0
                },
                {
                    "sent": "So loopy graphs.",
                    "label": 0
                },
                {
                    "sent": "So it's not guaranteed, and it turns out this works very well in practice.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's actually one of the the best techniques.",
                    "label": 0
                },
                {
                    "sent": "So Max product actually works well for images, for Turbo codes and all sorts of other practical problems.",
                    "label": 1
                },
                {
                    "sent": "But there are very few guarantees on it, so here's the Max product algorithm I won't spend too much time discussing it.",
                    "label": 0
                },
                {
                    "sent": "Basically, each node sends a message to the Clique clique, send messages to each node, and you keep going until these messages converge.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple, lightweight update rule and you're you're solving this map problem.",
                    "label": 0
                },
                {
                    "sent": "By iterating and then eventually, once you've converged, you can read off the most likely setting for each variable.",
                    "label": 0
                },
                {
                    "sent": "So here is the most likely setting for your first variable weight to the NTH variable.",
                    "label": 0
                },
                {
                    "sent": "So it's very simple, very fast.",
                    "label": 0
                },
                {
                    "sent": "That's exact for trees, and then in 2001 your wison Bill Freeman showed that you can also use this method for single loop graphs, so if your graph has a single loop, this will also, under some mild assumptions, also give you the optimal answer, and then Wainwright and others also showed that what it's doing when it converges it's finding.",
                    "label": 0
                },
                {
                    "sent": "Locally optimal solution.",
                    "label": 0
                },
                {
                    "sent": "So once it settles down you're still.",
                    "label": 1
                },
                {
                    "sent": "You might not have found the global solution, but there are some local optimality guarantees and of course it seems to work well in practice.",
                    "label": 1
                },
                {
                    "sent": "And then recently, Wainwright and others have pointed out that what Max product is doing is very similar to the 1st order LP relaxation, and if it is a tree then Max product is literally solving the 1st order LP relaxation.",
                    "label": 0
                },
                {
                    "sent": "And so then later on another family of graphs have been thrown into the mix.",
                    "label": 0
                },
                {
                    "sent": "So we know about trees.",
                    "label": 0
                },
                {
                    "sent": "We know about single loop graphs and then recently people have showed that Max product this very lightweight map estimation algorithm also works for matching zanfer generalized matchings.",
                    "label": 0
                },
                {
                    "sent": "So Biotie Sean Sharma 2005 said you can solve very loopy graphs called matchings where there's tons of loops and it will still give you the optimal answer and then recent work.",
                    "label": 0
                },
                {
                    "sent": "We showed that you can also solve generalized matchings and I'll get to that in just a second.",
                    "label": 0
                },
                {
                    "sent": "So here is.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The simplest version of matching this is called bipartite matching, and the problem we're trying to solve is something like the Google AdWords problem.",
                    "label": 0
                },
                {
                    "sent": "We've got 3 words and three advertisers.",
                    "label": 0
                },
                {
                    "sent": "Each advertiser is bidding on a word, and here I'm looking at the offline version of the problem.",
                    "label": 0
                },
                {
                    "sent": "Each advertiser says, well, if you show my ad when somebody types laptop, Apple will give Google $2.",
                    "label": 0
                },
                {
                    "sent": "If you show the Apple ad when somebody types phone, Apple will give Google $3, and so there's a matrix of pay offs and we're interested in finding is, let's say the matching of the best.",
                    "label": 0
                },
                {
                    "sent": "Match for each word to each advertiser to maximize dollars.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Bipartite matching problem because there's two sets of items we're trying to match and what we're going to do is, given the weights were given, the payoff matrix, we want to maximize the sum of the weights times.",
                    "label": 0
                },
                {
                    "sent": "This selector variable C, which is binary which selects who gets matched with whom, and this binary matrix has to sum to one row wise and to one column wise, and so we want to find the most profitable configuration.",
                    "label": 0
                },
                {
                    "sent": "And it turns out this problem has been solved since the early 60s, and even before with the classical Hungarian algorithm which takes N ^3.",
                    "label": 0
                },
                {
                    "sent": "However, you can set this problem up as a graphical model.",
                    "label": 0
                },
                {
                    "sent": "It's very loopy.",
                    "label": 0
                },
                {
                    "sent": "We'll see that in just a second, but if you run Max product on this very loopy graphical model in cubic time, you'll get the optimal answer, and so Max Box will also work properly here and then.",
                    "label": 1
                },
                {
                    "sent": "The proof of that is in BIOT, in 2005.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've.",
                    "label": 0
                },
                {
                    "sent": "And so we generalize that to the setting of, let's say be matching, where instead of saying when I type laptop, show me one, add Google actually shows you three ads when you type a search.",
                    "label": 0
                },
                {
                    "sent": "Here we're showing two ads.",
                    "label": 0
                },
                {
                    "sent": "So what's the best two ads to show when someone types laptop?",
                    "label": 0
                },
                {
                    "sent": "It's best to show Apple and IBM when someone types server.",
                    "label": 0
                },
                {
                    "sent": "It's best to show, let's say, Motorola and IBM and so on, because at the end this matrix now is constrained to some role wise and column wise to two instead of to one.",
                    "label": 0
                },
                {
                    "sent": "And so that's just the direct generalization of 1 matching.",
                    "label": 0
                },
                {
                    "sent": "Now it's be matching.",
                    "label": 0
                },
                {
                    "sent": "We're still maximizing the total payoff over this binary matrix, and has stuff to be role wise and column wise.",
                    "label": 0
                },
                {
                    "sent": "And so this combinatorial be matching problem.",
                    "label": 0
                },
                {
                    "sent": "People know you can solve in order BN cubed an.",
                    "label": 0
                },
                {
                    "sent": "It's it's roughly like the Google AdWords problem, although the Google AdWords problem is a little different because it's it's solved in an online setting and this yet against creates a very loopy graphical model.",
                    "label": 1
                },
                {
                    "sent": "Tons of loops, but if you run Max product.",
                    "label": 0
                },
                {
                    "sent": "On this thing it will also give you the optimal answer even though it's not a tree.",
                    "label": 0
                },
                {
                    "sent": "In order to be in cube and you'll get the exact map estimate very quickly and so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's what the graphical model looks like.",
                    "label": 0
                },
                {
                    "sent": "It's two layers on the top layer are the.",
                    "label": 0
                },
                {
                    "sent": "Let's say the advertisers.",
                    "label": 0
                },
                {
                    "sent": "The bottom layer are the words.",
                    "label": 0
                },
                {
                    "sent": "And then what we have is a bipartite graph, and we have these M functions which basically say.",
                    "label": 0
                },
                {
                    "sent": "M of one of these variables is the set of neighbors it connects to.",
                    "label": 0
                },
                {
                    "sent": "OK, so M Maps.",
                    "label": 0
                },
                {
                    "sent": "Let's say one of these notes to the set of.",
                    "label": 0
                },
                {
                    "sent": "Let's say one of these advertisers to the set of words that advertiser wants to pick.",
                    "label": 0
                },
                {
                    "sent": "So this is a function and what we're going to find these random variables, which are the all the possible outputs of these functions.",
                    "label": 0
                },
                {
                    "sent": "So XI are all the possible and choose B configurations for each one of these advertisers or or each one of these words.",
                    "label": 0
                },
                {
                    "sent": "And then we can write the graphical model down.",
                    "label": 0
                },
                {
                    "sent": "It looks just like this, and if you just follow the rule product of cliques in here for the partition function to normalize.",
                    "label": 0
                },
                {
                    "sent": "These are all non negative functions defined over these pairs of variables and then also these Singleton potentials which just say how much value.",
                    "label": 0
                },
                {
                    "sent": "Well, the exponentiated dollar amount basically is what's going on in these Singleton potentials.",
                    "label": 0
                },
                {
                    "sent": "And then in these pairwise potentials all these pairwise potentials are saying is.",
                    "label": 0
                },
                {
                    "sent": "If somebody picks you and you don't pick them back, the probability goes down to zero so it's enforcing reciprocity.",
                    "label": 0
                },
                {
                    "sent": "So that's all this probability distribution function is saying and then we can run Max product on this and it turns out it has.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To give you the optimal answer and so this is the theorem, it converges in order BN cubed and the way we figure this out and prove it is by unwrapping this message passing tree.",
                    "label": 0
                },
                {
                    "sent": "This computation tree by acting like we have unrolled that network in time.",
                    "label": 0
                },
                {
                    "sent": "So we've got the you later, then some vilayer some more you layer some more view layers and then we look at how many layers we have to unwrap before the inference problem on a tree.",
                    "label": 0
                },
                {
                    "sent": "In this unwrapped graph is exactly equivalent to the inference problem on the loopy graph.",
                    "label": 0
                },
                {
                    "sent": "And so we can show that in.",
                    "label": 0
                },
                {
                    "sent": "Let's say that that much time we're going to get the optimal.",
                    "label": 0
                },
                {
                    "sent": "And then recently there was a further refinement which shows that.",
                    "label": 0
                },
                {
                    "sent": "This is actually not the best you can do.",
                    "label": 0
                },
                {
                    "sent": "The Max product algorithm for one matching under mild assumptions on the edge weights can actually solve the matching problem in order N squared time, so that makes it very competitive with some of the best methods out there for solving matchings.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's how the algorithm is working.",
                    "label": 0
                },
                {
                    "sent": "We're basically sending messages back and forth between the advertisers and the search terms.",
                    "label": 0
                },
                {
                    "sent": "You can download this code.",
                    "label": 0
                },
                {
                    "sent": "We've run it on large problems with hundreds of thousands of nodes on the Netflix data set.",
                    "label": 0
                },
                {
                    "sent": "For example, things like this and it will converge so that at the end each node has two neighbors.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the be matching.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equals 2.",
                    "label": 0
                },
                {
                    "sent": "And it turns out, if you compare this against the.",
                    "label": 0
                },
                {
                    "sent": "The combinatorial solvers.",
                    "label": 0
                },
                {
                    "sent": "It's three or four orders of magnitude faster.",
                    "label": 0
                },
                {
                    "sent": "And you can also run it in the unit part time matching mode, and you can early stop it if the weights are picked, let's say according to that recipe by Saladin Shaw, and we've run this algorithm in clustering problems in classification problems and collaborative filtering problems, and semi supervised problems and visualization problems.",
                    "label": 0
                },
                {
                    "sent": "And it's a very nice tool.",
                    "label": 0
                },
                {
                    "sent": "It works as a great competitor to K nearest neighbors because it's forcing everybody to have only K neighbors, whereas K nearest neighbors because of greediness can sometimes give some nodes much more than K. And so again, this is very fast.",
                    "label": 0
                },
                {
                    "sent": "And here's an example of.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use it in the unit partite setting.",
                    "label": 0
                },
                {
                    "sent": "So now instead of having advertisers and search words, everybody is in one common category.",
                    "label": 0
                },
                {
                    "sent": "Here's some data on two rings and I'm just going to scale the inner ring so that it gets bigger over here this way.",
                    "label": 0
                },
                {
                    "sent": "So as I go to the right, the bigger rings get the little ring skinny bigger, and as I go from top to bottom, there are fewer samples on each ring.",
                    "label": 0
                },
                {
                    "sent": "If I run K nearest neighbors of K = 2 on the top left, it does the right thing.",
                    "label": 0
                },
                {
                    "sent": "It connects the two rings properly, but if I start scaling the inner ring, then K nearest neighbors getting confused and get more points connecting towards the middle, or if I downsample the inner ring as well, you get more points connecting to the middle.",
                    "label": 0
                },
                {
                    "sent": "And that's because these points actually think these guys are closer to them than other points on the ring, and these points in the middle are getting too popular.",
                    "label": 0
                },
                {
                    "sent": "Getting over selected.",
                    "label": 0
                },
                {
                    "sent": "So if everybody picked their neighbor in this room who is closest to you, the people in the middle of the room will actually get picked more often because more people.",
                    "label": 0
                },
                {
                    "sent": "So that's my neighbor then people at the periphery.",
                    "label": 0
                },
                {
                    "sent": "And so this is the problem with K nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "An if you just replace it with unique.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part IP matching you fix this issue.",
                    "label": 0
                },
                {
                    "sent": "Now everybody's got two neighbors and we minimize the total amount of string to connect everybody here if you want to calculate the problem this way instead of a maximization here to minimizations and so.",
                    "label": 0
                },
                {
                    "sent": "One application for this is in visualization.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In machine learning we like to form these graphs to visualize manifold low dimensional manifold of data, here's a visualization algorithm that's been built on a number of websites and it turns out many websites are connecting to these really popular nodes that look very generic that have something to do with billing, and you don't see the structure because everybody's picking these really popular nodes at in this Euclidean space where we did K nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "This noise happened to be in the middle, and so everybody thinks they're very close in high dimension.",
                    "label": 0
                },
                {
                    "sent": "If you force everyone to have B = 4 neighbors, then you get a much nicer connectivity and then you get to see Yahoo and Google out here close to each other.",
                    "label": 0
                },
                {
                    "sent": "You can see the airlines over here with American Orbitz and so forth.",
                    "label": 0
                },
                {
                    "sent": "Southwest Airlines, Kmart in Best Buy, and Walmart and Sears and Home Depot popping out nearby because we don't get this artificial connectivity because of K nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just an application, but.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It shows you how we can solve what looks like a very nasty problem exactly with just Max product.",
                    "label": 0
                },
                {
                    "sent": "And here's the unit Partite version for the unit part diversion.",
                    "label": 0
                },
                {
                    "sent": "It's really an asymmetric symmetric weight matrix, and all we're looking at our edges, so we're going to get a symmetric connectivity as well, and the problem just basically changes a little bit.",
                    "label": 0
                },
                {
                    "sent": "We're going to maximize the pay offs and then we're going to force symmetry on the matrix here.",
                    "label": 0
                },
                {
                    "sent": "Force it to be binary.",
                    "label": 0
                },
                {
                    "sent": "Enforce it.",
                    "label": 0
                },
                {
                    "sent": "Cedar on the diagonal so that you can't choose yourself as your own neighbor, so this.",
                    "label": 0
                },
                {
                    "sent": ", further problems with solving that be matching an.",
                    "label": 0
                },
                {
                    "sent": "We can again solve it by Max product and it turns out there is an efficient algorithm which is polynomial time which goes back to the 1960s by Edmunds.",
                    "label": 0
                },
                {
                    "sent": "And what Edmunds pointed out is you can solve this by keeping track of an exponential number of linear inequality's in your.",
                    "label": 0
                },
                {
                    "sent": "In this linear program, to enforce the integrality of the solution, these are called the Blossom inequality's, and there's an exponential number of them, but Edmonds.",
                    "label": 0
                },
                {
                    "sent": "Devise a clever scheme to avoid enumerating all of them in a brute force way, so you can still get something cubic time that will solve this problem using Edmonds Blossom algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's a very beautiful approach to solving these types of problems, and later on in the in the in the uniparty case, sangavi proved that Max product will be exact if this LP is going to be integral.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't always work if the LP is not integral and he has this proof that followed our paper, which said you can still run this algorithm in the unit partite setting.",
                    "label": 0
                },
                {
                    "sent": "It won't be optimal unless you're lucky in the LP's integral.",
                    "label": 0
                },
                {
                    "sent": "So how do we know if the LP is integral?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So clearly.",
                    "label": 0
                },
                {
                    "sent": "Max product and the solution for the map estimate both depend on this idea of LP integrality and it turns out matchings have some nice properties that can be used to argue for LP integrality and that's what Edmonds did to prove his algorithm.",
                    "label": 0
                },
                {
                    "sent": "How do we generalize beyond matchings?",
                    "label": 0
                },
                {
                    "sent": "And it turns out the natural path is through perfect graphs and if you have a perfect graph you can prove LP integrality.",
                    "label": 0
                },
                {
                    "sent": "So that's the tool and that's where we're going next.",
                    "label": 0
                },
                {
                    "sent": "Low vaches theorem right after his proof of the week.",
                    "label": 0
                },
                {
                    "sent": "Perfect graph conjecture.",
                    "label": 0
                },
                {
                    "sent": "So this is the theorem for any nonnegative vector F of weights.",
                    "label": 0
                },
                {
                    "sent": "This linear program over X, which is now relaxed non binary vector subject to X being positive and acts being less than or equal to 1.",
                    "label": 1
                },
                {
                    "sent": "So this set of linear constraints is always going to give back an integral solution if the undominated rows of this matrix A.",
                    "label": 0
                },
                {
                    "sent": "This binary matrix a form the vertex versus maximal cliques.",
                    "label": 1
                },
                {
                    "sent": "Incidence matrix of some perfect graph.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if I formed a from a perfect graph structure, this LP, also known as a set packing LP, is going to give me an integral solution.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what does this a matrix look like?",
                    "label": 0
                },
                {
                    "sent": "Well, here's what we're trying to solve this linear program.",
                    "label": 0
                },
                {
                    "sent": "And if I'm given this graph.",
                    "label": 0
                },
                {
                    "sent": "This happens to be a perfect graph.",
                    "label": 0
                },
                {
                    "sent": "This graph has this a matrix for every clique we just put the variables that are involved in the clique.",
                    "label": 0
                },
                {
                    "sent": "So there's X one X2X2 and X3 and so on.",
                    "label": 0
                },
                {
                    "sent": "That's the matrix, so if you run this LP, you'll get a binary solution.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, but that's not quite what we want, because this lemma doesn't directly apply to the inference problem we had.",
                    "label": 0
                },
                {
                    "sent": "It's not quite maximizing P of X on our graph G. We really have this different form.",
                    "label": 0
                },
                {
                    "sent": "It's got these arbitrary clique functions.",
                    "label": 0
                },
                {
                    "sent": "They're not necessarily binary like the a matrix, so how do we map this form so that it can be analyzed with low vaches lemma?",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to try to figure out a way to plug this form into the lavash lemma and what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume without loss of generality that all our cliques.",
                    "label": 1
                },
                {
                    "sent": "Have, let's say one plus epsilon is their lowest value.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's not too bad.",
                    "label": 0
                },
                {
                    "sent": "Used to find the minimum value for each clique divided by the by the values of the click and add a tiny epsilon, and then we're going to come up with the procedure to convert the graphical model into this thing called and and Markov random field.",
                    "label": 0
                },
                {
                    "sent": "And that's called that's written as a curly G instead of G to distinguish it.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a restrictive graphical model where instead of being arbitrary clique potential functions.",
                    "label": 0
                },
                {
                    "sent": "An over arbitrary discrete variables.",
                    "label": 1
                },
                {
                    "sent": "We're going to force all the variables in the NAND Markov random field to all be binary.",
                    "label": 0
                },
                {
                    "sent": "We're going to call them Capital X.",
                    "label": 0
                },
                {
                    "sent": "There's going to be capital N of them, and all the clique potential functions are pairwise NAND gates.",
                    "label": 1
                },
                {
                    "sent": "OK, so for any pair of variables that are connected by an edge, only one of them can be on only one of them can be one, the other one has to be 0.",
                    "label": 0
                },
                {
                    "sent": "So this is the inequality so they can both be 0.",
                    "label": 0
                },
                {
                    "sent": "That's fine.",
                    "label": 0
                },
                {
                    "sent": "That's still not aunt, but both can't be on simultaneously.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the construct.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And and here is an example.",
                    "label": 0
                },
                {
                    "sent": "Here's a tiny little graphical model with two cliques, cliques, AB&BC and.",
                    "label": 0
                },
                {
                    "sent": "Let's assume AB&C are all binary variables.",
                    "label": 0
                },
                {
                    "sent": "Here's the NAND Markov random field on the right side.",
                    "label": 1
                },
                {
                    "sent": "And how do we construct this when we first initialize the NAND mark of random field?",
                    "label": 0
                },
                {
                    "sent": "Is the empty graph and then for each click in the graph in the original graph I look at every possible configuration of that clique and a former variable binary variable for every one of those configurations.",
                    "label": 1
                },
                {
                    "sent": "OK, so for every click an every configuration to click, I create a binary variable and then I connect that binary variable to any other binary variables.",
                    "label": 0
                },
                {
                    "sent": "So far in my graph, if they disagree.",
                    "label": 0
                },
                {
                    "sent": "OK so here are all the possible configurations.",
                    "label": 0
                },
                {
                    "sent": "Click a Beacon B and configuration 00011011 and there's edges between all those four.",
                    "label": 0
                },
                {
                    "sent": "Because you can't be both in one configuration and another, and similarly over here and then there's also these edges between let's say BC00 on a B11 'cause this guy saying be has to be one.",
                    "label": 0
                },
                {
                    "sent": "This guy saying he has to be zero.",
                    "label": 0
                },
                {
                    "sent": "They disagree.",
                    "label": 0
                },
                {
                    "sent": "There's also an edge so there's all these NAND edges between all the possible binary configurations and now we have something that plugs into lashes.",
                    "label": 0
                },
                {
                    "sent": "Formula OK, so imagine now every edge here is just an and function.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so now here's the.",
                    "label": 0
                },
                {
                    "sent": "Probability density implied by this graph, curly G. It's a product over all these non functions.",
                    "label": 0
                },
                {
                    "sent": "If there are edges between these pairs of variables, XYK and SDL so.",
                    "label": 0
                },
                {
                    "sent": "The ex came from click see and it's is seeing the calf configuration and the other ex came from click D in itself configuration.",
                    "label": 0
                },
                {
                    "sent": "If they disagree then that that click function gets raised to the power of 1 and it's active and then over here we've got these weights for every possible configuration.",
                    "label": 0
                },
                {
                    "sent": "We just set the weights to be the log potentials for that Cle configuration value.",
                    "label": 0
                },
                {
                    "sent": "So this is a very simple conversion.",
                    "label": 0
                },
                {
                    "sent": "Now we have this non Markov random field.",
                    "label": 0
                },
                {
                    "sent": "It's got many more variables the size of this non marker random field.",
                    "label": 0
                },
                {
                    "sent": "Has N variables, it's the sum of all the cliques.",
                    "label": 0
                },
                {
                    "sent": "Overall their configurations, so things got exponentially big in each individual clique, but the graph still hasn't grown in terms of the total number of clicks.",
                    "label": 0
                },
                {
                    "sent": "It's still only growing linearly in a number of the cliques, but the size of the cliques, the Max clique size is really the bottleneck here.",
                    "label": 0
                },
                {
                    "sent": "OK, so now if I look at one of these binary variables and it says equal to 1, then I know that clique C is in configuration K out of all the possible EXE configurations.",
                    "label": 1
                },
                {
                    "sent": "And this is clearly subjective.",
                    "label": 0
                },
                {
                    "sent": "There's many more configurations of capital X then little X OK, because again, I've enumerated all these possible peaks, there's many.",
                    "label": 0
                },
                {
                    "sent": "Disagreeing configurations, there's more total configurations in X, but the NAND relationship prevents any.",
                    "label": 0
                },
                {
                    "sent": "Individual clique from having more than one configuration anyone time and then through this simple theorem if the weights are positive, the map estimate extar of this landmark of random field yields this constraint equal to 1 for all variables in that particular clique, and so it's basically saying is if you are looking to maximize this rovex, you're not going to get these silly configurations where nobody wants to be assigned in that clique, and you're going to say.",
                    "label": 0
                },
                {
                    "sent": "Everything at exes unassigned.",
                    "label": 0
                },
                {
                    "sent": "You're always going to get one assignment if you're doing that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what's nice about this is now we can say that the map estimator for role of X on this non Markov random field recovers the map estimate for P of X by find the solution over here using the non Markov random field.",
                    "label": 0
                },
                {
                    "sent": "I can use that to reconstruct them.",
                    "label": 0
                },
                {
                    "sent": "An equivalent map estimate for the original graph.",
                    "label": 1
                },
                {
                    "sent": "So I can now work with and and mark of random field and forget about the original graph and just use that as my my problem graph.",
                    "label": 0
                },
                {
                    "sent": "And it's nice because now if I relax this map problem on row of X.",
                    "label": 0
                },
                {
                    "sent": "And instead of considering binary variables in mine and marker annefield, I just considered variables between zero and one.",
                    "label": 0
                },
                {
                    "sent": "That's the LP relaxation.",
                    "label": 0
                },
                {
                    "sent": "This looks just like the set packing linear program that Lavash describes and formulates integrality arguments for.",
                    "label": 1
                },
                {
                    "sent": "OK, so now if the graph G in the non Markov random field curly G. If that's perfect, then the LP efficiently solves the map problem and it's going to give you the integral answer.",
                    "label": 1
                },
                {
                    "sent": "You're not going to get fractional solutions, so here it is.",
                    "label": 0
                },
                {
                    "sent": "Again, this is the theorem, and now we can just say, well, this graph, if it has it's perfect, it will form the appropriate a matrix and we'll get back.",
                    "label": 0
                },
                {
                    "sent": "A discrete solution instead of a fractional solution.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And so.",
                    "label": 0
                },
                {
                    "sent": "Here is the the kind of more formally standing what I just said for any general graph we know map is NP hard, But if you convert the graph into the non Markov random field, that's a polynomial time conversion.",
                    "label": 0
                },
                {
                    "sent": "If I know graph G is not is then perfect after I've converted it, then I just run this find maximal cliques procedure, which is also polynomial.",
                    "label": 0
                },
                {
                    "sent": "And then I solve the math problem with the packing linear program, which is also polynomial.",
                    "label": 0
                },
                {
                    "sent": "So if this is true then I can solve the problem in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "And so here's the theorem.",
                    "label": 0
                },
                {
                    "sent": "The map estimate of any graphical model G with cliques see elements of capital, see all the maximal cliques if it forms and and Markov random field whose graph is is perfect, then the inference problem is polynomial.",
                    "label": 1
                },
                {
                    "sent": "And it needs basically that number of variables in the LP cube.",
                    "label": 0
                },
                {
                    "sent": "That's how long it takes to solve an LP.",
                    "label": 0
                },
                {
                    "sent": "It's cubic time in the worst case, so we can solve in cubic time the map problem.",
                    "label": 0
                },
                {
                    "sent": "If the graph is perfect.",
                    "label": 0
                },
                {
                    "sent": "OK, so now some of you might say, well hold on a minute Tony.",
                    "label": 0
                },
                {
                    "sent": "There is an if here and this might take.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A lot of time an until very recently this could have taken.",
                    "label": 0
                },
                {
                    "sent": "This could have been an NP hard step, so I tried to pull the wool over your eyes by saying Oh well if I can do this then I can do the rest of the stuff in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "So it turns out in 2006 Maria Trynowski showed that you can also check if the graph is perfect in.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Polynomial time that result.",
                    "label": 0
                },
                {
                    "sent": "We just talked about in the first slide and so now all these steps are polynomial time.",
                    "label": 0
                },
                {
                    "sent": "So for any graph I can go through this conversion and check and solve in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "If it's perfect, get get an exact answer.",
                    "label": 0
                },
                {
                    "sent": "So this defines a larger family of map problems where we can get the exact solution that goes beyond trees, let's say.",
                    "label": 0
                },
                {
                    "sent": "OK, so now this is all polynomial.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Time.",
                    "label": 0
                },
                {
                    "sent": "Let's go back and talk a little bit about perfect graphs and this algorithm for second, so that the algorithm again to determine if G is perfect.",
                    "label": 0
                },
                {
                    "sent": "If you want to.",
                    "label": 0
                },
                {
                    "sent": "Not think about it.",
                    "label": 0
                },
                {
                    "sent": "You can just run this algorithm and Delbert Duek implemented in my group it's order N to the 9th.",
                    "label": 0
                },
                {
                    "sent": "So it only works on small graphs.",
                    "label": 0
                },
                {
                    "sent": "It's close to the brute force search, almost because unless the graphs are really large.",
                    "label": 0
                },
                {
                    "sent": "This is not going to be helpful.",
                    "label": 0
                },
                {
                    "sent": "And you can do that check and then get a binary answer that yes, it's perfect or or notes.",
                    "label": 0
                },
                {
                    "sent": "It's not perfect.",
                    "label": 0
                },
                {
                    "sent": "Or you can use some of the tools from perfect graph theory instead of just running an algorithm blindly.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't have to just use this algorithm, which looks like a nightmare of order N to the 9th.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "Some of the tools from perfect graph theory?",
                    "label": 1
                },
                {
                    "sent": "Let's go through some of them.",
                    "label": 0
                },
                {
                    "sent": "I can't possibly do the field justice because, again, there's many, many different papers in this area, but let's just recall what a perfect graph is.",
                    "label": 1
                },
                {
                    "sent": "A perfect graph has clique number.",
                    "label": 0
                },
                {
                    "sent": "Equal to coloring number for all its subgraphs, so the click number of a graph is a size of its maximum clique.",
                    "label": 1
                },
                {
                    "sent": "What's the largest set of fully connected notes?",
                    "label": 0
                },
                {
                    "sent": "The chromatic number of a graph is the minimum number of colors that I can paint all the vertices with such that no two adjacent vertices have the same color OK, and so perfect graph is a graph where every induced subgraph H which is inside G satisfies this property.",
                    "label": 1
                },
                {
                    "sent": "So if I delete a node in its edges.",
                    "label": 0
                },
                {
                    "sent": "That remaining sub graph also has to be perfect and also has to satisfy clique number equals coloring number.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is an example of a perfect graph.",
                    "label": 0
                },
                {
                    "sent": "The fully connected graph over 5 nodes.",
                    "label": 0
                },
                {
                    "sent": "If I delete any one of these nodes and all its edges, I still have a fully connected graph.",
                    "label": 0
                },
                {
                    "sent": "So here I need five colors to color this and the maximum clique sizes 5.",
                    "label": 0
                },
                {
                    "sent": "This is not a perfect graph because the maximum clique size is 2.",
                    "label": 0
                },
                {
                    "sent": "An I need more than two colors to color this thing.",
                    "label": 0
                },
                {
                    "sent": "I need three colors over here.",
                    "label": 0
                },
                {
                    "sent": "The maximum size is 2 and I only need two colors color this thing just alternate between red, blue, red, blue, red, blue because it's an even cycle, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's giving us more detail about perfect graphs.",
                    "label": 0
                },
                {
                    "sent": "And then now let's see how this relates back to Berge graph.",
                    "label": 0
                },
                {
                    "sent": "So the strong perfect graph Theorem says a graph is perfect if and only if it is brush.",
                    "label": 1
                },
                {
                    "sent": "So what is bersch iburst graph is not the same definition of the perfect graph.",
                    "label": 0
                },
                {
                    "sent": "Otherwise this theorem would be trivial.",
                    "label": 0
                },
                {
                    "sent": "The Burst Graph is a graph that contains no on whole and whose complement also has no odd hole.",
                    "label": 1
                },
                {
                    "sent": "OK, so the theorem was basically proving that if that's the property then you have to have a perfect graph and vice versa.",
                    "label": 1
                },
                {
                    "sent": "And so a whole is an induced sub graph.",
                    "label": 0
                },
                {
                    "sent": "Which is a cordless cycle of length at least 5.",
                    "label": 0
                },
                {
                    "sent": "OK, so cordless cycle, least length 5 and BYOD holy mean that the cycle length is odd, so 5, seven, 911 and so forth, but three in one or fine.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "So the graph has to have no odd whole an it's compliments also has to have no idea what's the graph complement graph complement is just G bar where you take the same vertices as G and for all pairs of vertices if they're adjacent in G then they become non adjacent in G bar and vice versa.",
                    "label": 1
                },
                {
                    "sent": "So whoever was not connected connects and whoever it was connected disconnects in G bar.",
                    "label": 0
                },
                {
                    "sent": "So if there are no holes in G and there are no holes in G bar then it's a burst graph.",
                    "label": 0
                },
                {
                    "sent": "So here is an odd hole.",
                    "label": 0
                },
                {
                    "sent": "Here's an even whole.",
                    "label": 0
                },
                {
                    "sent": "Here's a knothole and again, you know you can keep trying to recognize these structures in your birth graph and say, oh, this is not a birth graph because they found one of these five holes, or seven holes, nine holes and so on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nope.",
                    "label": 0
                },
                {
                    "sent": "Once again, we could just run the order to the 9th algorithm, but you not ski, or we could use some of the lessons learned about Berge graphs and perfect graphs from the strong perfect graph theorem.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that they.",
                    "label": 0
                },
                {
                    "sent": "In developing a strong perfect graph theorem, an algorithm popped out and a whole bunch of other theoretical tools popped out.",
                    "label": 0
                },
                {
                    "sent": "So let's just review the algorithm very quickly before we look at some of the other theoretical tools.",
                    "label": 0
                },
                {
                    "sent": "So if you give me a graph GI run tradeoff since algorithm in order to add to the 9 and that says.",
                    "label": 0
                },
                {
                    "sent": "Version operation and then I run it on the compliment version, not version.",
                    "label": 0
                },
                {
                    "sent": "If they both say first then I know it's a verse graph.",
                    "label": 0
                },
                {
                    "sent": "And so here's the actual four steps of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "You first detect if the graph contains a pyramid structure.",
                    "label": 1
                },
                {
                    "sent": "I don't want to spend too much time on this, but that's that.",
                    "label": 0
                },
                {
                    "sent": "Basically, looks like this this pyramid in the graph.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a geometric analogy, and you do that by running all shortest paths on your graph.",
                    "label": 0
                },
                {
                    "sent": "It's inefficient algorithm, and then you look at all new pools of vertices, so all subsets of nine vertices in a graph.",
                    "label": 0
                },
                {
                    "sent": "That's where the order enter the knife comes in.",
                    "label": 0
                },
                {
                    "sent": "That's the killer part.",
                    "label": 0
                },
                {
                    "sent": "You have to look at all order into the night.",
                    "label": 0
                },
                {
                    "sent": "So that's one step of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "We did try to detect other structures like a jewel structure and a few other easy to detect structures in the graph.",
                    "label": 1
                },
                {
                    "sent": "And if you don't find those and keep going and then we perform a cleaning procedure which basically vertex in the graph is C major.",
                    "label": 0
                },
                {
                    "sent": "If it's set of neighbors is not a subset of vertex set of any three vertex path.",
                    "label": 1
                },
                {
                    "sent": "So there's this cleaning algorithm that corner way holes and a few other graph theorists developed.",
                    "label": 0
                },
                {
                    "sent": "So you run the cleaning algorithm by corningware holes.",
                    "label": 0
                },
                {
                    "sent": "And then there's a few other things you do with shortest odd holes, and you compute shortest paths between triples vertices, But that's much faster than the enano pools of vertices.",
                    "label": 0
                },
                {
                    "sent": "And then you can decide if it's a perfect graph or not.",
                    "label": 1
                },
                {
                    "sent": "Of course this is slow.",
                    "label": 0
                },
                {
                    "sent": "It's order into ninth.",
                    "label": 0
                },
                {
                    "sent": "There are faster methods that find all holes.",
                    "label": 0
                },
                {
                    "sent": "The problem with this is all odd and even holes, and so the graph might still be perfect and this thing will tell you oh, it's got a hole, but it's OK if it's got a 6 hole or an 8 hole or a 10 hole, as long as it's not whole.",
                    "label": 0
                },
                {
                    "sent": "But you can use this as a faster algorithm, which is roughly cubic time instead of an to the 9th.",
                    "label": 0
                },
                {
                    "sent": "We've run this algorithm on 300 nodes.",
                    "label": 0
                },
                {
                    "sent": "This thing is a good kind of quick check before you go to the full.",
                    "label": 0
                },
                {
                    "sent": "Definitive algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's how you run the algorithm, But it turns out the strong perfect graph theorem gives you a lot of machinery to do stuff with pencil and paper.",
                    "label": 0
                },
                {
                    "sent": "Instead of running an algorithm, the first thing it tells you is a burst graph has to be one of these five graphs, which are these primitive Berge graphs has to be either a bipartite graph, 2 chunks compliments of a bipartite graph, line, graphs of bipartite graphs, compliments of line graphs are bipartite graphs, and double split graphs are the simplest types of birds, graphs, or.",
                    "label": 1
                },
                {
                    "sent": "It's a combination of simple burst graphs where these four gluing procedures have been used to glue together many pieces of birth graphs to create a larger burst graph.",
                    "label": 0
                },
                {
                    "sent": "So these are called graph primitives or decomposition, so there's ways of gluing two graphs together with the two join or two during the compliment and joined a balanced view partition, so these are four techniques for gluing perfect graphs together.",
                    "label": 0
                },
                {
                    "sent": "We're not going to detail on that, but if you recognize these things in your grass then you say Oh well, now I can break it up and see if the pieces are still.",
                    "label": 1
                },
                {
                    "sent": "Primitives themselves and so just for definitions, line graph is just a graph where you connect the vertex for each edge.",
                    "label": 0
                },
                {
                    "sent": "If the two vertex vertices of the line graph adjacent only if the two edges of G had it common vertex.",
                    "label": 0
                },
                {
                    "sent": "So you place you replace the edges in your graph with nodes in the line graph and you connect it up that way.",
                    "label": 0
                },
                {
                    "sent": "So that's the line graph, the standard construction.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here are some nice, so here's a little more detail about some of these nice tools that the The Commodores community uses to investigate.",
                    "label": 0
                },
                {
                    "sent": "Perfect graph so.",
                    "label": 0
                },
                {
                    "sent": "You can decompose the graph by trying to find 2 joins and joins.",
                    "label": 0
                },
                {
                    "sent": "Q partitions replication in the graph and that helps you diagnose if it's perfect or not without running this giant algorithm.",
                    "label": 0
                },
                {
                    "sent": "So one really nice lemma going back to 1972 Lavash again if you have a perfect graph and you take and you know, do you try to stick it into that perfect graph by connecting it to one of the vertices.",
                    "label": 1
                },
                {
                    "sent": "If you connected to vertex V Prime and all its neighbors, then the resulting graph is perfect.",
                    "label": 0
                },
                {
                    "sent": "So if I have this graph here and I bring it, and you know it and I want to connect it to this guy, if I connect it to him and all his neighbors.",
                    "label": 0
                },
                {
                    "sent": "This graph also has to be perfect.",
                    "label": 0
                },
                {
                    "sent": "So I've connected X7 to X4, but I also have to connect to X3 and X5 because their neighbors, so that's the replication lemma.",
                    "label": 0
                },
                {
                    "sent": "That's a tool you can use to make proofs about your graphs and say it is perfect or not.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's another one.",
                    "label": 0
                },
                {
                    "sent": "It's called the skew partition lemma, but the simpler way of thinking of this is gluing on cliques.",
                    "label": 1
                },
                {
                    "sent": "So if I have two perfect graphs graph, G&G, prime.",
                    "label": 0
                },
                {
                    "sent": "And if their intersection where I'm going to include them on top of each other forms of fully connected click or click cut set, then the resulting merge graph is also perfect.",
                    "label": 0
                },
                {
                    "sent": "So here's one graph.",
                    "label": 0
                },
                {
                    "sent": "Here's another if I glue them on top of each other.",
                    "label": 0
                },
                {
                    "sent": "On top of this fully connected clique, this is fully connected X 3X Four that also has to be perfect so I can grow these really complicated perfect graphs using these lemmas.",
                    "label": 0
                },
                {
                    "sent": "These four or five lemmas.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And using these we can now prove and I won't go through the detail of this proof that trees form perfect MRF's.",
                    "label": 0
                },
                {
                    "sent": "And the LP has to be integral, so we know this from Judea Pearl in the 80s.",
                    "label": 0
                },
                {
                    "sent": "But let's just let's just verify it.",
                    "label": 0
                },
                {
                    "sent": "So let's say G is a tree.",
                    "label": 1
                },
                {
                    "sent": "You give me a tree graph and I convert it into an and mark of random field which is curly G. That curly G has to have a perfect graph connectivity.",
                    "label": 1
                },
                {
                    "sent": "So here's the proof.",
                    "label": 0
                },
                {
                    "sent": "You start off by just working with stars instead of trees, and then you only look at one of the configurations before you look at all possible configurations.",
                    "label": 0
                },
                {
                    "sent": "And you recognize that you're going to be forming AV.",
                    "label": 1
                },
                {
                    "sent": "Partite graph.",
                    "label": 0
                },
                {
                    "sent": "Once you realize if you formed the party graph that is perfect, then he used the replication lemma and you start connecting all the configurations that your V partite graph that keeps it perfect.",
                    "label": 1
                },
                {
                    "sent": "So then I've proven that G for a star is perfect.",
                    "label": 1
                },
                {
                    "sent": "Then to connect up a tree, just keep gluing these stars together until you form your tree so you can always construct a tree with all these little star graphs, and that's by using the Cricut set or the gluing on cliques lemma.",
                    "label": 0
                },
                {
                    "sent": "So this proves that.",
                    "label": 0
                },
                {
                    "sent": "Trees have to give you perfect graphs for your Nan Makarena field.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Similarly, here's the bipartite matching graphical model that was proven in in our previous papers.",
                    "label": 1
                },
                {
                    "sent": "This is what it looks like.",
                    "label": 0
                },
                {
                    "sent": "That's the decomposition of the graph the the the formula for it, but the graph it turns out when I convert it into MRF form creates this type of structure for bipartite matching.",
                    "label": 0
                },
                {
                    "sent": "This is called the Rooks graph.",
                    "label": 0
                },
                {
                    "sent": "It's basically all the movements the Rook can do on the chess board, and so a rooks graph is basically the line graph of a complete bipartite graph, so we know that's one of the basic types of primitive first graph, so this also has to be perfect.",
                    "label": 0
                },
                {
                    "sent": "So therefore this also has to be.",
                    "label": 1
                },
                {
                    "sent": "Integral, and that's why that that proof was true.",
                    "label": 0
                },
                {
                    "sent": "For, for bipartite matchings from the previous papers.",
                    "label": 0
                },
                {
                    "sent": "OK, and then here is the unit.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Type version of the problem.",
                    "label": 0
                },
                {
                    "sent": "We're now we're just maximizing weights, but it's not two parts, it's just an arbitrary set of points, and we're trying to do matching.",
                    "label": 0
                },
                {
                    "sent": "There aren't males or females, or, let's say, advertisers and search words.",
                    "label": 0
                },
                {
                    "sent": "This is the formula for the likelihood.",
                    "label": 0
                },
                {
                    "sent": "The most likely setting now is just maximizing this, and it turns out here it's a little more subtle.",
                    "label": 0
                },
                {
                    "sent": "You have to now investigate the actual graph that you're being given and see if it's a perfect rap or not.",
                    "label": 1
                },
                {
                    "sent": "So that's why Sangavi's 2008 paper said.",
                    "label": 0
                },
                {
                    "sent": "If and only if the LP's integral, because you can always say it's integral, you have to check the graph topology here.",
                    "label": 0
                },
                {
                    "sent": "So this is only if the G graph happens to be a perfect graph.",
                    "label": 1
                },
                {
                    "sent": "OK, so some.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For extensions, there are ways to further prove your landmark of random field.",
                    "label": 0
                },
                {
                    "sent": "To search for perfection and efficiency.",
                    "label": 1
                },
                {
                    "sent": "By just removing some of the nodes that aren't going to affect your LP.",
                    "label": 1
                },
                {
                    "sent": "OK, so here are two procedures I don't want to spend too much time on, but you can run this procedure called disconnect and Merge.",
                    "label": 0
                },
                {
                    "sent": "They're both efficient for disconnect, we just look at each fully connected clique and we disconnect the weakest member of that clique.",
                    "label": 0
                },
                {
                    "sent": "You're allowed to do that, and then you can still recover the map problem from this disconnected man Markov random field, but you might have something that's either more efficient or now looks perfect when the other one wasn't perfect.",
                    "label": 0
                },
                {
                    "sent": "And so you can do some disconnections in your landmark around the field if you like.",
                    "label": 1
                },
                {
                    "sent": "You can also do merging, so if a pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "Have the same neighborhoods.",
                    "label": 0
                },
                {
                    "sent": "You can merge them together and say I'm going to just since they have the same neighborhoods.",
                    "label": 0
                },
                {
                    "sent": "If one is on the other, one has to be on.",
                    "label": 0
                },
                {
                    "sent": "If one is off, the other one has to be off.",
                    "label": 1
                },
                {
                    "sent": "And so you can do this merging and then solve for a single variable instead of these two variables.",
                    "label": 0
                },
                {
                    "sent": "You can solve for a single SDK and you replace its weight with the sum of the two.",
                    "label": 0
                },
                {
                    "sent": "The two separate nodes weights.",
                    "label": 0
                },
                {
                    "sent": "So these are two procedures you can run on the graph than an Markov random field that will speed things up.",
                    "label": 0
                },
                {
                    "sent": "And then finally, instead of.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually solving the LP, you can use these faster solvers based on Max product and this variant of it that was proposed in 2007 called Convergent Message passing and what's nice about convergent message passing is it's always guaranteed to solve the LP if the LP's integral and it's a binary relaxation.",
                    "label": 1
                },
                {
                    "sent": "So that's the theorem by Globerson Yakola.",
                    "label": 0
                },
                {
                    "sent": "Here's the algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's a slight variation of Max product.",
                    "label": 0
                },
                {
                    "sent": "It's a little more work, but nothing major, and it will always solve the LP for you.",
                    "label": 0
                },
                {
                    "sent": "Whereas match product might have some other problems and not converge, sometimes it'll get stuck and not not update.",
                    "label": 0
                },
                {
                    "sent": "And so they.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The theorem from global sinicola is if you have binary variables, then the fixed points of convergent convergent message passing recover the optimum of the LP, so you won't stop at a local sub optimal solution and so similarly as a nice corollary convergent message passing on an MRF with a perfect graph will find the map estimate.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just want to close for some.",
                    "label": 0
                },
                {
                    "sent": "Very quick experiments just to investigate if this really works.",
                    "label": 0
                },
                {
                    "sent": "We implemented this and instead of looking at the LP, we actually ran message passing and we ran message passing on this unique partite matching problem.",
                    "label": 0
                },
                {
                    "sent": "And so the theory tells you if the graph is perfect, you're going to get the right answer.",
                    "label": 0
                },
                {
                    "sent": "If it's not perfect, you're going to get the wrong answer.",
                    "label": 0
                },
                {
                    "sent": "OK, or possibly you could get lucky and still get the right answer and we can get the exact estimate by running Edmonds Blossom algorithm that will always give you the right answer.",
                    "label": 0
                },
                {
                    "sent": "That's the common tutorial solution and we can compare the two.",
                    "label": 0
                },
                {
                    "sent": "And so here's a graphical model.",
                    "label": 1
                },
                {
                    "sent": "Again, this is the unit partite matching.",
                    "label": 0
                },
                {
                    "sent": "These are the weights between all the pairs of points and then each point can Only Connect to one other neighbor.",
                    "label": 0
                },
                {
                    "sent": "That's all this is saying these constraints so.",
                    "label": 1
                },
                {
                    "sent": "Only pick one of your neighbors out of all your potential neighbors in the grass, so we compare the solution found by message passing on the MRF to Edmonds algorithm and we try different topologies.",
                    "label": 1
                },
                {
                    "sent": "Try perfect graphs and non perfect graphs and so here are the results.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here if we fed the algorithm perfect graphs, the solution that the message passing algorithm gives is the same as the Edmonds algorithm.",
                    "label": 1
                },
                {
                    "sent": "If we give it non perfect graphs, just random graphs afal Shorten doesn't find the best solution, so this kind of agrees with the LP integrality arguments, but now we can actually throw perfect graphs in there and see because we went out and actually generate perfect graphs.",
                    "label": 0
                },
                {
                    "sent": "We basically did the four types of basic purge graph.",
                    "label": 1
                },
                {
                    "sent": "So bipartite, complemented, bipartite.",
                    "label": 0
                },
                {
                    "sent": "Line graph and component of line graph.",
                    "label": 1
                },
                {
                    "sent": "When we set up those types of graphs, we've got the exact map estimate, otherwise we didn't get it.",
                    "label": 1
                },
                {
                    "sent": "If we had random graphs.",
                    "label": 1
                },
                {
                    "sent": "For for this matching problem it has to be it has to be perfect, yeah?",
                    "label": 0
                },
                {
                    "sent": "And there are some slight issues with numerical and early stopping.",
                    "label": 0
                },
                {
                    "sent": "That's why there's a couple of circles below the exact solution.",
                    "label": 0
                },
                {
                    "sent": "But just to wrap up.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, perfect graph theory is fascinating.",
                    "label": 1
                },
                {
                    "sent": "There's a lot of great work, very recent development in this area.",
                    "label": 0
                },
                {
                    "sent": "It's a crucial tool for exploring LP integrality LP relaxations.",
                    "label": 1
                },
                {
                    "sent": "There's many great algorithms and theoretical breakthroughs, and we know that this is important for graphical modeling because the LP Integrality's is a central question when you're trying to find the map estimate for graphical models and inference and so now we can say for any graphical model, if the MRF's perfect map is going to be exact and it's going to be.",
                    "label": 1
                },
                {
                    "sent": "Efficient and we can also test for perfection efficiently.",
                    "label": 0
                },
                {
                    "sent": "Maximum clique and LP can be solved all efficiently.",
                    "label": 0
                },
                {
                    "sent": "You can also use Max product or message passing instead of LP's and so now this extends the results for map beyond trees.",
                    "label": 1
                },
                {
                    "sent": "Single link graphs, single loop wraps, matchings, and generalized matchings to this big family which really just contains these various crafts called the.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For graph family, so there's some additional work.",
                    "label": 0
                },
                {
                    "sent": "This paper will appear next week at the uncertainty in AI conference.",
                    "label": 0
                },
                {
                    "sent": "There's some very nice survey paper by Martin Wainwright and Michael Jordan.",
                    "label": 0
                },
                {
                    "sent": "This is our previous paper on the generalized matchings, and I'd like to thank Maria Trynowski, Delbert Deck and Bert Huang for collaborating on this work.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Take into account.",
                    "label": 0
                },
                {
                    "sent": "So that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "So in the first part of the talk it doesn't matter what your click potential functions are, you construct an and mark of random field.",
                    "label": 0
                },
                {
                    "sent": "But when you want to run the disconnect and merge algorithms, then it matters what the potential functions are.",
                    "label": 0
                },
                {
                    "sent": "And then it starts to give you a different topology because it's looking at what is the weakest configuration in your click function.",
                    "label": 0
                },
                {
                    "sent": "Remember question such comment is so I would be surprised if you can so you can believe it for specifically for that process we can have one dresser abridgement for others.",
                    "label": 0
                },
                {
                    "sent": "But other than that, I would be surprised if we come into that.",
                    "label": 0
                },
                {
                    "sent": "If there are graphs that are not low huge graphs for which there is opening that graph without thinking 'cause people petrol, which resulting number is a perfect growth in recent ask?",
                    "label": 0
                },
                {
                    "sent": "That is because.",
                    "label": 0
                },
                {
                    "sent": "Actually, last we are showing for.",
                    "label": 0
                },
                {
                    "sent": "Graduation is only easily on local corruption.",
                    "label": 0
                },
                {
                    "sent": "You can't exactly position of grass in which vaccination is easy is valuable credits.",
                    "label": 0
                },
                {
                    "sent": "So I think this is relying on similar both.",
                    "label": 0
                },
                {
                    "sent": "Both people graphic Pen Supergirl conjectures, but this was not the case then that would be extremely interesting.",
                    "label": 0
                },
                {
                    "sent": "So that's a very good point.",
                    "label": 0
                },
                {
                    "sent": "So I'm not saying that what we've said here actually disagrees with your paper, and in fact I'm familiar with that work, because we haven't been able to identify situation in which it was perfect yet.",
                    "label": 0
                },
                {
                    "sent": "So beyond those three known results, although we've explored were graphs where we also had to do some deletion to get perfect graphs, so maybe there are some settings that we just haven't explored it yet where we can say no deletion for any any click functions on this potential loopy graph, there's still a perfect graph in there.",
                    "label": 0
                },
                {
                    "sent": "So we haven't found the counterexample.",
                    "label": 0
                },
                {
                    "sent": "But we've explored those three families, matchings and trees, and then things with delete and disconnected merge running with them.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I don't have a concrete answer, and to say that there's an actual counterexample to two.",
                    "label": 0
                },
                {
                    "sent": "You know the hardness claim in your paper.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "We haven't really looked at at any particular scaling behavior with different types of perfect graphs.",
                    "label": 0
                },
                {
                    "sent": "My hunch is if you're solving the LP and you have a really large clique incidence matrix, that's going to slow things down.",
                    "label": 0
                },
                {
                    "sent": "So if you it's going to depend on the number of clicks, but also on this clique incidence matrix.",
                    "label": 0
                },
                {
                    "sent": "But again, we haven't really pushed the envelope and saying can we characterize how things speed up or slow down depending on the different types of perfect graphs?",
                    "label": 0
                },
                {
                    "sent": "One thing we did do though, is we looked at the effect of introducing some.",
                    "label": 0
                },
                {
                    "sent": "Odd holes and it says current work with with Albert do ekanite does so.",
                    "label": 0
                },
                {
                    "sent": "Some types of bottles are still not too damaging.",
                    "label": 0
                },
                {
                    "sent": "You still get very good inference, but there is no theorem there yet.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright, thank you.",
                    "label": 0
                }
            ]
        }
    }
}