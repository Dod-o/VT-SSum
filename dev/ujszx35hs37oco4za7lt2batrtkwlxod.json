{
    "id": "ujszx35hs37oco4za7lt2batrtkwlxod",
    "title": "Large-scale and larger-scale image search",
    "info": {
        "author": [
            "Herv\u00e9 J\u00e9gou, INRIA Rennes"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_jegou_image_search/",
    "segmentation": [
        [
            "Before starting, I would like to give you some special arrangements to some people who helped me to make this tutorial by providing me some multi or actually on particular from perona from Xerox.",
            "Ashley from in here, but repairs from technical are on Andrea Chen from CIT.",
            "So this is the outline of the talk."
        ],
        [
            "Tutorial and 1st I will present some typical applications and some that I set with which are used in the academic area.",
            "Then I will speak about very briefly actually about Image description on matching to be very short so that they can put more focus on large scale on larger scale image search will present the bag of representation that probably many a few nodes on the few extensions that in my opinion are very important.",
            "And finally, I will finish with a larger scale image search.",
            "That is, what should we do if we want to scale to significantly more amount of images?",
            "Let's say up to 1 billion images.",
            "OK, so the scenarios that we can see."
        ],
        [
            "There is query by example where we might want to find given a query image, some relevant image in the database based on the visual content solely so it is not about metadata uncertainties about the content of the image itself.",
            "So the first typical case is a single condition.",
            "There you have an image of the pyramid Cheops and then you want to retrieve all the images from the test set that correspond to the same.",
            "Location so it is about location or condition or object recognition.",
            "If you think of things, but it is also very useful for copy detection or near duplicate detection.",
            "In this case I have printed an image on scan it and so this gives this horrible images with many reflection.",
            "We want to treat the original image on.",
            "This is important to know is there some copyrighted images.",
            "I have been used without.",
            "And paying any fee.",
            "So we want to do it interactive interactively.",
            "That is, with a short response time.",
            "So shortly can means from a few minutes ago, onto several sedans and two under millions to billions of images.",
            "So in this talk we will focus on million sized data set in what they call large scale image search on.",
            "Then we will go to missile which are able to scale to billions of images on the single server.",
            "That is, we do not want to put 1000 server in parallel.",
            "I want to do it with limited resources.",
            "So just a few sample of existing search engine, so you might take a look."
        ],
        [
            "After this big imbas online images of server which index 10,000,000 images, it is active since 2008.",
            "So you can input some images of yours, like the full tower and then you get some result order by accuracy.",
            "Of course, you probably knows that I need a search."
        ],
        [
            "Engine which actually index sees a lot of images and billions of images on the web on the provide some service.",
            "So this is a company to detect the images which might be the same as same content as a query image.",
            "It is limited to near duplicate mostly, but as you can see we can absorb some variation of intensity.",
            "On event some landscape against.",
            "Against this format of image.",
            "On there is also very impactful Google Google's search system which works."
        ],
        [
            "On Android, on the mobile device, we are given a query.",
            "You can submit it on.",
            "Actually this search engine implements many technique in parallel, so in particular we dedicated search engine for QR codes.",
            "But also you can make more general image search on for instance that is able to find some paint art.",
            "OK, so about the scalability of image search.",
            "We can differentiate."
        ],
        [
            "Distinguish two different kind of system.",
            "The first set of system works with global descriptors, while the 2nd works with local descriptors.",
            "Basically to make sure global descriptors there able to find images as image level that is the same scene with little deformation, little.",
            "Transformation like rotation or scaling on the usually organized image as a wall, not specific area, while local descriptor or able to find instances that is part of the objects that may be in the image.",
            "So the most gullible ones or the global descriptors starting with CU in 1995 which was able to index about 8000 images.",
            "So it might not be.",
            "That's very big today, but at the time it was very, very big.",
            "There could be assistant today on the speaker machine, could be used to index millions of images with no problem.",
            "They also Cotner search engine by quack.",
            "From it is a gauge which in 2004 was able to index also 3 million images.",
            "Images of the word on a very impactful, impactful work was one of Two Harbors.",
            "CPR, 2008, with small short memory codes on the large databases where they actually indexed 30,000,000 images and it has been standard 280 millions.",
            "10 image data set with very few bit per image, so this works really.",
            "Care about the memory usage stating that if you want to index large databases you need to have compact signature and I think this give give us insight on what is what should be done to go to larger data set on regular machine.",
            "The concurrent work afterward was indexing more than 100 million images with Curry Temps, which are very fast.",
            "So a few lessons.",
            "Once again on one curl.",
            "So now if you look at local descriptor, of course capabilities significantly lower because you have two under, not one descriptor preimage, but underrated thousands of descriptors on the similar work of Silicon on this.",
            "So man, if you Google on which I'm going to spend a lot of time.",
            "At this fall, under this tension was originally able only 205 thousand images, which is not that big, but they really gave the principles that could be used can be used to extend to more bigger datasets.",
            "Works was quite an artist is a work by Julie, which I see I hear presented some work indexing 6 million images represented by more than 100 million descriptors.",
            "So at the time it was.",
            "Racing record on the well using some specific indexing techniques and not back off for presentation, but I think this work was visionary work so we have also this very impactful work by Eunice Terrance.",
            "TV news in CPR six.",
            "That really shown what House video Google System should be extended to under larger sets by proposing large vocabularies.",
            "So initially the proposal it on 50,000 images, but it has been extended to.",
            "Continue after after one and then can.",
            "'cause the work which I will do after afterward.",
            "My work at Cpl where we indexed 10 images and then one credit union images based on local descriptors on operable at the time to show you a demo to assist of the system working on this laptop at the other tutorial.",
            "So what was the test that we used to evaluate?"
        ],
        [
            "This image search system.",
            "So basically we use small data set of ground truth merge with bigger data set.",
            "The reason this is it is very difficult to annotate very large scale data set.",
            "So the way that people do that is that user smaller sets the 5000 images on.",
            "Then you merge them with the destructor set, which is much bigger on for which you hope that you will not have some false positive.",
            "So Oxford 5 case probably the most used one.",
            "It is a system where the objective is given some query of some building that you might select on your mobile device.",
            "For instance, you want to retrieve all the images of the set that contains this particular building on this operating from Oxford.",
            "On the merge it with this set of distracting images also retrieves the keyword Oxford to make the valuation on a larger scale.",
            "Loser, that asset is Holidays in real data set and which is."
        ],
        [
            "Smaller than the Oxford asset, but which contain more queries.",
            "You have 500 queries, which is in some sense better for the statistics on the small number of results between 1:11, so this is quite unlike the previous data set of Oxford when you can have very many results or very furiously depending on the query on there are 1 million distracting images to make the variation on the large scale.",
            "But in this case we know that there are several false false positive.",
            "That is, for some particle query.",
            "Which correspond 2 famous places in the world?",
            "Is this random set of 1 images?",
            "You have some corresponding images which should be labeled as true positive, but which are not labeled as true positive.",
            "In practice, this has a little effect on the evaluation, but we have two noses which is possible to have perfect result on this data set.",
            "On the images are not there for some reasons, so there is 1 popular there."
        ],
        [
            "Set which has been introduced before the other ones, which is a bit artificial but still is very used and it was proposed by instance to.",
            "The news is in the city of contain key object recognition benchmark.",
            "You have more than 2000 objects, each of which is represented by 4 images on the average curve is given.",
            "The number of image wrong in the first four position, so the perfect score is 4.",
            "OK, that's fine.",
            "OK, and I want to also present this."
        ],
        [
            "The set which is, I think less used, but which is very interesting, because it also correspond to a very important application case where you want to retrieve with your mobile phones and image and submit to a system containing some reference images on is that I set the reference images or high quality images while the queries are true images shot by mobile phones of different marks different so.",
            "Might as Nokia on different phones, and this is very important because on this data set allows to focus on a symmetric quality of images on query side we have poor quality on database size.",
            "You have a good quality and this is I think a challenge for the community to be able to under this asymmetric quality."
        ],
        [
            "So now I go to the brief introduction of image description on matching.",
            "This is not specifically specifically the focus of the tutorial."
        ],
        [
            "But I have to introduce it because we rely on this part."
        ],
        [
            "So image description is actually an analysis step, so this we want to convert the image into mathematical representation.",
            "Search that cinema images.",
            "Respect to some application or two human interpretation are presented by similar mathematical representation, typically vectors or set of vectors.",
            "On the difficulty of this analysis step is that we have to understand possible transformation of object in natural images.",
            "So for instance we have scale there plus some critter.",
            "Change of viewpoint in the store that I set.",
            "Lighting, which is in this case very strong, as you can see on occlusion.",
            "So we have to be a variant enough to."
        ],
        [
            "Much is a mathematical object representing these images, but in the same time we want to be discriminate if we should not have two much invariants, so I take this particular example of this query for which the results of this one on which is based on the color descriptors.",
            "Is it good result or not?",
            "Well, it depends.",
            "If you want to make some artwork, it might be considered as good because you want images that have the same color.",
            "So from the article.",
            "Chart it may be interesting, but from any application is not interesting.",
            "So for locational conditions for instance, it is basically not usable.",
            "So we have some tradeoff between discrimination.",
            "And variance to transformation on this description should be tailored to the task that we want to address.",
            "So some global descriptors.",
            "Here the idea is to present an image."
        ],
        [
            "One single descriptor, possibly of a dimension.",
            "So the Chrysler Graham.",
            "We have a very used at the beginning, in particular the one proposed by base when 91 on this provide, I invariants too many transformation, as we have seen in the previous slide, but limited discriminative power.",
            "When very popular descriptor global descriptor is a gist descriptor by Olivia and to Alba, which incurred several frequency bands on rotation for each medication.",
            "Try to capture the layout of the scene based on this description.",
            "For instance, it takes device images in several part.",
            "On different convolution and capture, so grading the rotations.",
            "It is very useful single condition.",
            "But most of the applications that we want to address, like locational condition."
        ],
        [
            "Object recognition cannot rely on such descriptors.",
            "Basically, most of the recent work on instant search or rely on local descriptors such as the one produced by the video in force.",
            "Victor said quality.",
            "Most of you know.",
            "In this case, the image content is represented by port Cities.",
            "We're going to describe several patches, actually 2000 of patches in the image, each individual patches including into a vector, and then the image representation is a set of vectors.",
            "To say if two images are.",
            "Should be matched with rely on the individual matching of the local descriptors.",
            "So in order to extract its descriptors, we first needed."
        ],
        [
            "Victor Sow detector tried to find reputable regions.",
            "That is, some regions that could be fine consistently, even under different information such as change of viewpoint and so on.",
            "So the most popular one I would say, or the Mercier.",
            "So for wide baseline matching.",
            "So difference of Goshen by the video just introduced with the descriptor on the Sienna fine descriptor.",
            "Baby killer chicks.",
            "On those days in your new interest for don't descriptor, that is, we are not going to detect some specific regions which are repeatable.",
            "We just sample many patches.",
            "You don't sway from an image.",
            "It said 10,000 and more patches from an image in classification.",
            "This is actually what gives the best results and I will also mention easy and that is also the case if you consider very large scale image retrieval.",
            "It is also very good to use don't descriptor given that we consider some specific image search system that will detail in this tutorial, just to say that.",
            "You can work.",
            "You can rely on description without any detector and get very good result.",
            "Event for image search.",
            "So once we have extra."
        ],
        [
            "Some patches who either in the dance way as are using regions of interest you have to describe it, of course normalization.",
            "So basically what is done usually is orientation normalization, aurify normalization, photometric normalization, which is actually done usually by some normalization on the descriptor.",
            "In the case of the sea descriptor, the most popular ones shift.",
            "I'm not going to detail it just to say that it is specialized on coding of the energy.",
            "Of the graduates.",
            "In a Patch.",
            "Is only thing I will set you mention on the seat because I guess that most of you know this descriptor is that there are some very simple improvement to get like Componentwise Pirollo proposal currently this year by Jane on Hun, Jellick from Oxford on just by Apley, applying square rooting on the component you get some sleep improvement, both specification, but also for image search.",
            "On the wheel.",
            "Speak about this problem also in user context, just to say that I believe that this is a general principle that should be applied using this power normalization because we have some strong first evidence is that it is good for the benchmark, but also because we have some indirect dialing underlying process that explained why we should do the power law.",
            "On there is many derivative from these descriptors, so more efficient, more compact or integrating color which is not the case of of the sifter.",
            "Two to propose a different trade off with respect to efficiency, capacity and so on.",
            "I won't mention one thing about the work of window on Brown, which is learning local descriptors.",
            "I think this work is really insightful about the fact that we should use learning stage event for unsupervised or technique like image search.",
            "At least people mostly think that made search by content is unsupervised scenario.",
            "But in many cases.",
            "On this work was one of the first to show it, but now it is also more and more attractive, with seven said buzzword, we should use learning to supervised learning to improve task which is not supervised.",
            "Now this is a general tone I think in the image search now.",
            "So once we have local descriptor instructed, we have the position we can."
        ],
        [
            "Super from geometrical verification to find some consistent way of mapping so descriptor match basins.",
            "Mathematical representation with another set of descriptor.",
            "Off another image on social media, we can filter out this.",
            "Matches which are not consistent with the global transformation.",
            "This is very precise.",
            "This is usually used as the last step of image matching, but this is not scalable at all.",
            "I shouldn't say that because in next see there's a paper by Stephen News from Google that perform large scale geometrical matching on the millions of images even more.",
            "Actually using some specific optimization, but it is usually so that this symmetrical verification is very costly.",
            "So just invite you to look at the papers to the news that SV to see where the.",
            "OK, on the tool for."
        ],
        [
            "So image description.",
            "Now I mostly assume that we have some local descriptors extracted from the images of the data set and I'm going to work on what we do is local descriptors that we have extracted."
        ],
        [
            "So first the 1st."
        ],
        [
            "We suggest matching, which is also required by the geometrical verification.",
            "But even without that this is a problem by itself is that we have a big complexity issue.",
            "So let's assume that we have an image described by, let's say 1000 descriptors.",
            "Probably more would be better, but we this is used for the sake of analysis and we consider.",
            "Large Kayla.",
            "Data set of women images for me.",
            "Large scale is about 1,000,000 to 10,000,000.",
            "On larger is bigger than 100 millions.",
            "So we have to index to put memory or to store out to find some way or focus on thing 1 billion descriptors.",
            "N * M If you consider regular see descriptors representing each by 128 dimension on coded with one diaper component, you have to store 128 gigabyte of descriptors, which might fit in the big server.",
            "But if you go to a bit more images, it will not fit or you are very rich.",
            "Two very big servers.",
            "On the problem is that the search requires M square and the elementary operation.",
            "So M Square is a number of descriptor preimage.",
            "On the square comes of that you have to match everybody with everybody.",
            "So every descriptor allows 1000 against every descriptor among the 1000.",
            "For the database side for each image times dimensionality of the descriptors.",
            "So this is computationally computationally not tractable.",
            "Actually, because of the quadratic term and square.",
            "So I will come on this matching patterns problem associated with this matching part and also is a solution in a specific section of this tutorial.",
            "But first I want to say that this problem with the direct matching has been.",
            "Partially served with a bag of word back.",
            "Visual world representation.",
            "So it was first introduced actually."
        ],
        [
            "In the context of textural classification by Malikan.",
            "But the most impactful paper was probably the view Google Paper by civic and so man, because they really show shown that it is possible to mimic complete mimic text retrieval system which were already very efficient at the time to get reasonable result.",
            "Actually very good result at the time.",
            "Une image search system.",
            "On the obtain efficiency.",
            "An accident recognition performance.",
            "Concurrent concurrently dance on our proposal visualization with bag of key points, which actually is the same ID but more focused on classification.",
            "So if we want to compare them to paper, both of them are based on the same ID.",
            "That is, we're going to represent a set of local descriptors and by only one vector.",
            "But this one is more focused on how you put it into a system.",
            "For efficiency using inverted file structure while the second one was proposing this to get vector representation that can be fitted to SCM super sector machine for instance because it is very convenient to have only one vector per image.",
            "On the good thing with this bag of words representation is that it inherits completely the invariants of the descriptors, not does not enter, it's completely.",
            "The discriminative power, but at least it generates the invariants.",
            "How it is?",
            "I know it works, so the idea."
        ],
        [
            "Put the images into words, namely visual words, so I'll descriptors can assume that they lie in dimensional space.",
            "Let's say 138 dimensions for the sift on this space is continuous, which is more or less true.",
            "But let's assume this.",
            "So we need to define what is a visual world.",
            "And she's done, but you can't iser container, which is a function that Maps a continuous.",
            "Victor 2 contest index.",
            "If you need infinite set.",
            "It may be also infinite, but this script.",
            "So in this case, in the case of video, Google accuser contains are this.",
            "Mapping function.",
            "Is a chemist container which actually is also like contest which is very good.",
            "We know that this container is very good with respect to minimizing the squared error or construction.",
            "So the set of visual words define visual vocabulary.",
            "Each user word correspond to our production values container.",
            "On your sign descriptor based on nearest neighbor based on the nearest neighbor rules.",
            "In this case finding the one which means the equation distance in the code book.",
            "So I want to mention that conversation is glossy, we cannot go back from this finished space.",
            "Axis of O2 to descriptor we have.",
            "We have lost something and actually we have lost a lot.",
            "But it's very compact.",
            "Typically we just have to represent the regarding of two of the number of possible indexes, which is typically 2 to 4 bytes for descriptor.",
            "So now if you look at the complete processing chain."
        ],
        [
            "If you Google.",
            "We first have this image from which which we extract some local descriptors so we have detector or this menu option and we can use detector as well and we describe this Patch then we can test all the descriptors, only compute vector of frequencies.",
            "They are usually waited by inverse document frequency just to give more importance to the visual words, which are rare.",
            "And this gives us the idea vectors.",
            "When you have a query, we have to search for similar vectors and this is done using inverted file and I will come back on this just after which is an efficient indexing structure for sparse vectors.",
            "Optionally, we can use some ranking, so thinking now is very used with Jean metrical verification, but actually even in the old cubic paper it was proposed as secondary stage to filter out some images which are not correct based on a better representation, but at the time it was without geometry.",
            "So it's."
        ],
        [
            "Go to the injected file.",
            "Then justified is a set of list.",
            "Which purpose is to store the sparse vector components?",
            "On this used to compute the cosine similarity typically between one vector and input on the set of vector on output.",
            "So actually correspond to the implementation of a sparse matrix times plus Victor multiplication.",
            "Another University file implements in application.",
            "The fact is that it can be extended to other measures.",
            "It is not restricted to L2 cosine similarity.",
            "It can be used for any LP norm on actually even a wider class of function like a square for instance.",
            "On this was shown by Mr instead in use because the preferred to use L1 norm for comparison around distance for comparison of Lego Foot, because in that case it was providing better results.",
            "Mutation of injected furniture possible maybe more, but this one are very popular.",
            "So the most popular one probably is just to store given a set of words.",
            "So that is a different component of the vector to be indexed.",
            "This will work now OK, and we're going to store in for the database images all the ID of the images identifier on the frequency.",
            "Of the visual world in this image.",
            "An interactive presentation is just too only stores IDs on order to know how many occurrences of the work we have, we just toss the ID several times.",
            "This may appear as inefficient.",
            "In practice, the most implementation or almost equivalent with respect to the memory usage.",
            "There's a big advantage in this.",
            "Implementation, which is that you have one ID per descriptor, which means that you can actually store some additional information per descriptor, and this is very convenient to go to some extension of the presentation in this representation when you have a frequency, it is already emerged.",
            "We've already performing aggregation."
        ],
        [
            "On this is very difficult to go back to the individual descriptors."
        ],
        [
            "OK, and the complexity is approximated by the number of items and I will come back on this point after so.",
            "OK, I'm going to skip this slide.",
            "Which was only there to say you should use the implementation of the injected files that store one ID per descriptor.",
            "It is much more convenient for many extensions, so if we go ahead to the complexity of inverted file first, we can model the probability to assign a descriptor.",
            "Given visual world I on.",
            "IPI.",
            "N is the number of images in database on M is let's say the average number of descriptor per image.",
            "So the expected length of list I is basically N * N time P. So M already includes expectation.",
            "So expected curse is quadratic in the number of.",
            "This contemporary imagine average, so we have the kill completely kills them square factor I mentioned before, but the fact is that it is compensated by the fact that we have a very low constant.",
            "And then you can see that we have this pie squares to Pierce.",
            "Which is very important to consider, because if you have a cluster of very different sizes, it will have a big impact.",
            "The big values of Pi will negatively impact the cost of this was first mentioned by mistranslated Newsome unformalized afterward and as the balance factor.",
            "On this measure, this measure measures divergent from the optimal uniform distribution, which is the one that gives you the best possible cost for a given number of descriptor on a given vocabulary size.",
            "I have to mention that some strategy have been tested and I have tested the few ones to balance the cluster, but I really have to say that this balancing trying to get more uniform distribution for PII, usually impacts negatively the quality of the search.",
            "So you gain in efficiency, but you losing quality a bit.",
            "Just one thing I didn't say well.",
            "One thing when I presented this complexity, but this complexity is under the assumption that the Pi.",
            "Is the same for the database images and for the query images.",
            "Before I presented the study for the test set for which we know that there is a different quality between the database of reference images on the queries showed by mobile devices.",
            "So in this case it may not be true that Pi is equal on query on database side, so you just have to take this formula we scare.",
            "OK, injustice file is not sub linear.",
            "It is very efficient but it is not Sabrina."
        ],
        [
            "It is linear in the number of images.",
            "With this constant is very small because it is sparse multiplication.",
            "So typically 001 is a constant.",
            "The memory usage for let's say 1,000,000 images is about four to 8 bytes per descriptors.",
            "Let's say 8 gigabytes.",
            "So you can store only 1,000,000 images on one regular server.",
            "Is this can be compressed using ingested file compression, so this one was first proposed in text retrieval, but only to some extent because in the compression is lossless compression on you, you're bounded by the lower limit of entropy of the indexes or difference of index.",
            "Usually it is implemented using Delta Kodera followed by some entropic code like off man.",
            "Some user optimized codes.",
            "So how to boost efficiency?"
        ],
        [
            "So first the first Mr that you might choose is to use consistent using stop words that is.",
            "Try to remove what in text would be informative words.",
            "So in text level, if you have words like the a very short words, there are quite informative.",
            "The provide some description of the content itself, so they usually remove it in text retrieval to 1st get better results, but also because it has a big impact on efficiency.",
            "If you present web page.",
            "Can you stop all the web pages that contain the you you're going to store all the webpages the world of the Internet, so you cannot do that.",
            "You're going to discard this words.",
            "In image search, this amounts to removing the most frequent ones because we do not have exactly the equivalent of informative words.",
            "In practice, most frequently or less informative, as shown by the IDF weighting, but they're not completely informative on.",
            "From my experience, you always lose a bit.",
            "Not that much, but a bit if you filter some.",
            "Some of the most frequent, if you're well.",
            "So it doesn't seem interested in the summation there.",
            "When you send the Pi from one to care, we are cases.",
            "The number of Visual World Cookbook size you're going to start to serve the pie.",
            "Starting with X + 1.",
            "Excel, word, and assuming that the first one or the other most frequent, so you're going to remove the tail of the distribution which contain most of the visual world.",
            "So you have a very good impact and efficiency filter menus words.",
            "So in other ways too.",
            "Great to on."
        ],
        [
            "So to get more efficiency with injected files consist in using large vocabularies, so a link in text in text read it as a choice.",
            "We have the alphabet of the of fixed by the language, English language, French language, whatever you have to use this word, because these are the.",
            "This is a language you cannot decide.",
            "In image search there was an artificial operation to convert some features into an alphabet of visual elements.",
            "Which means that we can decide the size of the alphabet.",
            "We just have to change the value of K. So you can.",
            "You can use it to optimize some different tradeoff between search quality.",
            "On efficiency.",
            "Which we know is that at query time owns the descriptor quantized and the complexity is linear in 1 / K, where K is a size.",
            "So you should use larger Cabri to get less matching results on.",
            "This can be efficiently done using a very large dictionary like the one proposed by instance TV news.",
            "So lots of people prefer for this because of evil efficient."
        ],
        [
            "But in the same time you should not forget that you have increased assignment costs, that is the quantization operation for the query does not depend on the.",
            "The size of the test set.",
            "It is for the query only, but has to be done.",
            "On a query term, if you look at the complexity.",
            "Of quantization of descriptor plus query into exotic file you have something of the Form C1 Timescape received 2 / K. This part is a quantization cost, assuming a flat Kamins quantizer, this one is query is the cost associated with querying into inverted file.",
            "So you have some kind of optimum that you could fix two optimizer costs.",
            "But in practice, we can use some better contessa to reduce this cost.",
            "So the first thing you could do is just to use like it is on compression.",
            "For instance, structure contains a supercontainer.",
            "You have some algebraic operation to perform assignment to the visual world, the quantization.",
            "So you can use a grid.",
            "Lattice contains are, but it was shown later bye Phil Burns that in the context of image searches gives a pretty poor results.",
            "Also you get some inverted list which are very unbalanced if user structure contains are you have something like this.",
            "So I'm going to explain.",
            "There you have the cell population, that is the amount of descriptor contains 2 given visual world and I ordered the cell population by decreasing number.",
            "Of cell population.",
            "So there I have Visual World won the most frequent too and so on.",
            "So this is for K means you have relatively balanced.",
            "Distribution so completely.",
            "So this can be measured by the imbalance factor, but if use structure contains are, you can do whatever you want.",
            "You always sorry you will always have this kind of distribution of the cell population, which means that you will have some very big pie on.",
            "For many visual words.",
            "On then very is small, some cells with some inverted list with very small population and she's not very good for efficiency, obviously.",
            "So you're you cannot.",
            "It's not possible to adjust a compromise are using.",
            "This structure contains a.",
            "So."
        ],
        [
            "When the very good way to learn a very large vocabulary is also to have a very low assignment.",
            "Cursed quantization cost is to use a radical campaigns like the one proposed by instance even use basically what you do is you make a tree of commands you have a first year, you're going to contest your descriptor by assigning it to the closest.",
            "Century is the first year, so this is a limited set.",
            "In this case it is only three on the second layer you're going to use a cabins which is dedicated to this first region of the space, and then you're going to sign into this particular world you have made in total 3 + 3 comparison.",
            "So Jason complexity is greatly reduced because of this power 1 / H, which actually kill the complexity of the assignment, so this is very fast, but we lose.",
            "You have shown these people from Oxford that it is better to use an approximate Cummins instead of your actual Cummins.",
            "So the ones they used and we come back and eat afterwards amounts to using parallel structure and to make the search on just to replace in the ascendant step of the cabins on at the same time also.",
            "As I said, known by approximate search technique.",
            "OK, come back to the front.",
            "There is another interpretation of."
        ],
        [
            "They go through the representation which is actually or dimension is in the 1st paper by civic and some man which amount to say that these are words or just view of mine.",
            "There is no trivial word.",
            "This is a continuous space and we have just artificially cut it into parts.",
            "So bigger fraud can be seen as approximate nearest neighbor search matching voting scheme.",
            "On this amounts to defining the neighborhood of descriptor.",
            "He's a future space, as Victor Witcher Cook on ties in the same cell.",
            "So basically, if you have a descriptor there of an image, so the red image, we say that all this green descriptor of the green image or matching descriptors.",
            "The problem with this interpretation.",
            "So first we can cast completely the bag of representation into this voting system, getting something which is equivalent given that the bag of words are compared with cosine similarity.",
            "But supremacy as we can see an artifact of the bag of fruit comparison, which is that if you assume two descriptor on query side for the, for instance red image onscreen descriptor on the database side, then you're going to count 6 votes 12333.",
            "456 in the matrix vector multiplication.",
            "This is because we have 3 * 2 in the frequency multiplied by some based on constant.",
            "The contribution to the cosine similarity is too big because it is not linear in the number of true matches physical matches.",
            "On to get.",
            "So impossible solution if you could do that would be to say we're not going to count more than the minimum of the two.",
            "So let's say you are going to count 2 because on one side we have only two, so this strategy was called multiple match removal, so you're going to count the minimums that you can physically have in reality.",
            "But a better strategy simply amounts to take the square root of the frequency, right?",
            "OK, you take componentwise square rooting of the bag of pre order.",
            "So if you have two descriptor you take sqrt 2, which means that if you have three on three descriptor for database on query sqrt 3 * sqrt 3 would be 3 on is linear in the number of matches.",
            "So this strategy is a way to compensate for the artifact of the voting system that does not be greater than the different matches."
        ],
        [
            "So this slide is just to show compromise between.",
            "Vocabulary of let's say small size 20,000 so 20,000 would be a lot actually for classification, but make sure it is smaller."
        ],
        [
            "On this is a larger vocabulary vocabulary so that you can see that in the 1st.",
            "In the first case, for the smaller vocabulary, you have many incorrect matches like this.",
            "Which are generated because this.",
            "Descriptor is simply cool.",
            "Contains with this one, but visually they are not that close actually but still can't eyes because vocabulary is not fine enough.",
            "But now if you go to those are you do not have any incorrect match, but at the same time you lose a lot of correct match.",
            "So if you look at this area for instance, this match is correct.",
            "How is miss there?",
            "And you have many miss like this in the boat also."
        ],
        [
            "On the reason is that for me, the intrinsic matching method, which is performed by bag of fraud is week is week on.",
            "There is no good compromise between small vocabulary on large vocabulary, it is just because the definition of the neighborhood is not good enough.",
            "Defining neighborhood as a set of contais descriptor.",
            "Whatever size, you cannot attain the best tradeoff.",
            "So for small visual dictionary small too small, you will have too many fast matches on.",
            "For large ones you will have true matches which will be will be missed.",
            "So there I have collected some patches.",
            "Assigned to the same user word for vocabulary of size 1000, so small vocabulary or may have done the same thing for a large vocabulary, so each time correspond to the same visual world.",
            "So in the case of the larger vocabulary, we can see that we match pretty close patches.",
            "There is not so much variation, but which in some sense means that OK, you matching is precise, but in the same time you cannot absorb alteration.",
            "Otherwise you will become Tyson assigned to another visual world on here.",
            "In contrast we can match very different patches like these two words.",
            "For instance, in my opinion are quite different on should be matched on their match because of context.",
            "So partial solution to this announced to performing multiple or soft assignment.",
            "In Samsung amounts to re centering the assignment of the descriptor to create structure around which is more features dependent, and so you're going to assign descriptor not too is closer.",
            "Some trade between several ones, optionally with some weights.",
            "But these are some impacts of the complexity of memory because you have to store multiple times the same feature, so that's why it's better to do it only on query side as advocated by 100, which to save some memory.",
            "OK, just to mention one thing, to prepare a support and matching efficient matching, this is what you get with a small vocabulary and this is what you get with a better matching method.",
            "So in this case you can see that you can just remove the outliers on there."
        ],
        [
            "Metal Fication is purely based on the matching the descriptor.",
            "This is to compare with the."
        ],
        [
            "Roger, who?"
        ],
        [
            "He as you can see.",
            "It is possible to."
        ],
        [
            "Trash without introducing."
        ],
        [
            "OK, yes, which is the case in this larger vocabulary."
        ],
        [
            "OK, now it's good to geometrical verification.",
            "As I mention, this is a very strong way to match images, especially for rigid objects.",
            "So we have some models on the we know that zooming through the point should be transformed, so we perfectly know automatch.",
            "Sometimes we can take some approximation, but basically it is the last step which is performed after bag over system.",
            "So you typically go for system.",
            "You first order that says one year images based on their score for the back of the presentation on the short list you're going to perform some geometrical verification, which is going to remove some.",
            "Outliers.",
            "This is very costly and it's typically applied to 100 to 1000 pages, so I mentioned that now apparently it is possible to be significantly more efficient, but let's say that it is still very inefficient.",
            "If you go to very large data set, the problem is that.",
            "The probability that your image your correct image is wrong in the shortlist becomes smaller on smaller.",
            "If you assume that the size of shortlist is fixed, let's say 100 and you increase the test set, you're going to get lower and lower probability, shortlist the correct images on this show in there.",
            "So there I increase the data set size.",
            "When I consider the probability to rank the images, the correct ones in the short list.",
            "Considering a short list of 20 images, one unread on 1000 images.",
            "So for the typical shortest of 100 images, you can see the performance drop.",
            "In this case.",
            "You're able to run OK almost 80% of images out of 10,000 is the first 100.",
            "This is the first person, but wrong them in the human.",
            "Only consider one person of one person.",
            "So this case where you have shortness of wonder images on Wendy images, you're going to lose Alpha, you're correct images, so medical verification as a post processing stage is not the solution for large scale image search.",
            "If you are going to consider.",
            "Very large data set.",
            "So this is a typical example, particular one I use."
        ],
        [
            "Undergo photo presentation.",
            "I have a query there on a consider images matching images annotated basic truth by order of increasing difficulty.",
            "So this one is very close.",
            "You do agree that this images we can recognize the this is the same place even easier on there we consider an image which is.",
            "Also the same place there you might recognize this area.",
            "It's the same as this.",
            "But you have a very strong change of viewpoint.",
            "On that is even more difficult.",
            "On the back of a full presentation, of course, for that real image it is wrong in second position, and I think the first was also correct.",
            "It was a false positive, but this images or so this one is wrong in position 6006 thousand is very good.",
            "Actually it is the first person the first person is until 10,000 images out of 1 union.",
            "But this is not enough to be verified by the special verification.",
            "On this is even worse.",
            "This is wrong in the first two 5%, but of course it will not be checked by the medical filter.",
            "So my message is basically you need to improve the first system, the one which is going to create a short list before applying geometrical verification.",
            "You cannot rely on your simple verification on expect it to be able to verify.",
            "10,000 images.",
            "So about Jimmy classification large."
        ],
        [
            "There is a lot of activity.",
            "Actually, so the people that tried to incorporate the geometry in the very first retrieval stage.",
            "So we present briefly after the geometry consistency that we introduced in 2008.",
            "I want to mention but will not have the time to detail the hemoglobin ash, which I think is a very interesting."
        ],
        [
            "Because it really scale to extremely large data set on is able to find some very small object.",
            "Of course it has a lot of problem as well.",
            "That is, you lose you have not a very good recall are but the same time for some queries difficult queries with few descriptor but specific ones.",
            "It works pretty well.",
            "There's also this paper bending features which actually uncovered some information of neighborhood.",
            "Jointly with descriptor.",
            "So I mentioned before that I like the implementation of the inverted file that store and ID for each individual descriptor.",
            "And basically you do that.",
            "You can have any kind of information on.",
            "In particular you can add some information about the neighborhood over the descriptor, which is also.",
            "We also incorporate some additional information in the week geometry consistently filter filter as well.",
            "Snicket's ocation this kind of technique that try to integrate the geometry are not really useful because they do not correspond to vector model that could be used to feed regime.",
            "That is why why is the most popular technique remains specialty and matching by lesbian Dick which simply amounts in dividing the images in several predefined regions, which of course that does not give a lot of invariants too.",
            "Just scaling on on on station and so on.",
            "But in practice it is very good on benchmarks and classification benchmark so.",
            "It is not an image search benchmark where you are more focused on Critter creeping on this kind of transformation depends on the task actually.",
            "So we geometry consistently see what it is.",
            "Basically it is off transform, so this tries."
        ],
        [
            "To estimate in a reliable manner some transformation, some quantities, the key WGC is that it is going to separately estimate the different quantities associated with magical transformation.",
            "In this case rotation, lock, scale, or estimated separately, we want to find a vector model which would correspond to a true geometrical transformation.",
            "We do not want.",
            "Estimate social conservation as a whole.",
            "We just want to estimate some specific quantities WHI, because objective is not to find the transformation is objective is just to detect some outliers based.",
            "So typically what is done is that we have to store jointly, which each descriptor some information about the dominant orientation.",
            "So for instance, when you extract a Patch.",
            "We detected that detector.",
            "You have the value of the dominant rotation, which which is determined by the detector.",
            "You may have another full affine local affine ellipse actually on.",
            "You also have some scale log scale, so this one of stored in the file in the context manner.",
            "So typically you're going to take 1112 bits per descriptor, so it is additional storage, but it is a relatively smaller compared to storing the rest.",
            "For instance, the idea of the descriptor on.",
            "Then for each image you're going to.",
            "Store some small office program to collect the vote.",
            "OK, so this is illustrated there.",
            "We have an image.",
            "We have another image."
        ],
        [
            "Which is rotated on the left image query image.",
            "We're going to estimate to use actually because it is already collected, we're going to use the dominant rotation associated with each Patch on the same is in the database image the computer difference.",
            "On the issue of a troop rotation, you should find a picture.",
            "You should make a histogram of the difference of rotation on this.",
            "Actually, what appears there you have this peak.",
            "Which correspond to all the rotation, which are consistent.",
            "On there you have inconsistent rotation that might appear there on.",
            "Once you have Instagram stories in memory at query time, you can just filter out this one because they are not around the peak.",
            "This is a basic idea, so you're using rotation to filter out some descriptors.",
            "Is this about outlier removal?",
            "The same here.",
            "Obviously the patches and the girl are not consistent with others, so you can remove."
        ],
        [
            "This matches."
        ],
        [
            "So compare if you look at the inner product computed between two bag of words.",
            "Ideas there is continued the voter to pull the votes are in this histogram.",
            "So if you think about it will just be collecting your single dinner.",
            "All the votes there you're going to dilute the vote based on prior you have about the matches, which in this case is different foundation."
        ],
        [
            "On which can also be change in scale I."
        ],
        [
            "To mention this worker variation, which is an answer we geometry consistency proposed by zero.",
            "Which is also known as these are phrases, so I still don't know what is the difference between these two.",
            "Actually from it is almost the same.",
            "So basically there the idea is to not choose to use angle rotation, but simply translation to filter out the incorrect matches.",
            "And you should do that if you incorporate this week geometry.",
            "So there it is.",
            "Mix with some other improve."
        ],
        [
            "Which I will discuss after, but this is just to show that if you integrate some geometry on better matching schema then you can other system which is very good.",
            "Not skate.",
            "I mean this is very fast, so trivial before some clarification is already quite good, not perfect.",
            "You still have to use geometrical verification afterward, but much better on good enough to have all the relevant images shortlisted."
        ],
        [
            "OK.",
            "So another I think very important work is it is quite expansion in visual search.",
            "So expansion is also a technique which is borrowed from text.",
            "Whatever it is, not new by itself, but image search.",
            "It was first proposed by Charm in 2007 at ACV Yes.",
            "Ideas to say I'm going to have a system which is not good enough to find all the all the queries because we might have some cases where you have this.",
            "Statue there, which appears only partially on another image which contains only the statue.",
            "Obviously you cannot match directly to images because they have no overlap.",
            "But they correspond to the same location approximately on you have some images that can link one to the user.",
            "So the idea for expansion as proposed by Chen is to process the list of results.",
            "The first one returned by the 1st original bag of word scoring.",
            "Performs a special verification in on the short list.",
            "Up to now everything is standard, but now from this shortlist process and augmented queries on the good thing is that general filter is very strong so you can identify some images for which you're sure that they are correct, because the number of inliers is about.",
            "10 or one hundreds so you can augment the query.",
            "With this descriptor, retrieve home the images which are trustable.",
            "These doing so you can create your several variants, but you can basically augmented query which will be less parcel.",
            "The query cost will be increased but still which is much better respect to the representation of the physical object, image query image itself to retrieve some new results and then the second stage.",
            "For instance you get 41 results while the first was only 12 and you can iterate.",
            "Is this using some transitive closure?",
            "Until you have no more results than when you get in the produce stage and I want to mention very interesting variant by 100 logics on this or manner.",
            "Would you say OK in creeks pension?",
            "The basic idea is that we have some true positive.",
            "We are pretty sure of because I've been specially verified so we can mark them as being true positive for classifier and then you can take some random images which are completely irrelevant that we can note as negative on.",
            "We can not the math negative because they have.",
            "They had a very low score with respect to the TF IDF scoring.",
            "With respect to the bag of representation, so we have this positive example on negative example.",
            "So this is machine learning, right?",
            "So what they do is that they apply classifier on the fly.",
            "They learning on the fly.",
            "To perform the second query so it turns out that they introduce some some discriminative selection rule in the process of image search, which has a big inning was not a classification task, but which become Christian classification task because they have created some labels on the fly.",
            "I think this is one of the trends that I mentioned before, which is that we can incorporate more and more machine learning in a task which are supposedly.",
            "Or not supervised task because we have the possibility to incorporate so annotation external annotation in this case based on metrical verification.",
            "So now I would like to know if you completed commands and go further."
        ],
        [
            "This is a very practical solution in the sense that we can reuse many ingredients introduced in in text with trivial.",
            "So basically, all those things that really worked in Texas River, I've been reusing image search, the ones that can be applied for instance, in classification we can use Suppository machine that has done by 10, so we can apply cracks, pension and we can also under some statistical phenomenon like burstiness or currencies.",
            "On all this technique actually.",
            "Have been shown effective inmate search but we have previously introduced in the text travel on.",
            "I believe that bag of word with appropriate extension is still state of the art we expect to image search or instant search or localization tasks.",
            "For instance, given that you incorporate the good extension so first some better matching technique.",
            "That is, you have to improve the neighborhoods matching induced by bag of word like.",
            "Using shift assignment about assignment or Hamming embedding as I will show after he honking specification you have to use gematria of images.",
            "Obviously incorrect pension when can be applied.",
            "So I have to mention the expansion can be useful only if you have many images of the same object in the database.",
            "If you have only one reference image.",
            "It is not possible to apply to expansion.",
            "It will not work because the best you can obtain is 1 image.",
            "So if it is not shortlisted you lose it and you cannot augment the query using this single query.",
            "So expansion is especially useful for that asset like Oxford where you can have many images to be returned.",
            "But for the test set like Holidays or benchmark the this technique is not effective because you do not have enough images too.",
            "Once a query.",
            "Any question and going to make just."
        ],
        [
            "Stop now for questions.",
            "OK, I go on.",
            "So now we have."
        ],
        [
            "We've discussed a lot about go further, which as I said, can scale to let's say one.",
            "Images Maybe 10 big server.",
            "But this is a limitation which is strong because you don't have enough memory to store the data required by bag of raw, so you cannot go beyond this scale.",
            "Scale more you may use global descriptors, for instance on use cutting technique to have them more compact.",
            "So now we assume that we want to index 100 million when billion images and you have one server.",
            "So obviously you are limited by your memory, so you have to take into account this constraint on.",
            "I think this is specially the message that rubber on this course.",
            "Said that in this paper, small code on large data base for condition, they used very, very compact codes on coding Jesus crypto rebadges descriptor.",
            "On their able to scale to very large, this exists as mentioned in the title, but clearly the rela is relied on the GIST descriptor, which is not very invariant.",
            "It is a structural layout structure layout.",
            "It is not invariant or not proper for object recognition.",
            "Instance recognition.",
            "So what I propose there is to say, OK, we're going to keep the last part.",
            "That is, you have this."
        ],
        [
            "Dimension to reduction of a global descriptor and then some encoding scheme.",
            "The only thing that is different there is that you're going to 1st extract sift.",
            "On, then use aggregation operator to have a single vector lacking the growth rate actually, but this one is going to be reduced by dimensionality reduction, so that in final you fulfill constraint on the number of bytes per image.",
            "So there is a constraint.",
            "The code is a constraint.",
            "This size is the size of the code is a constraint on.",
            "You have to optimize all these chain join fee to get the best performance as possible given a budget of memory.",
            "We don't want to make global description because we want to go beyond what you can do with suggested script.",
            "Also we rely on safe descriptor.",
            "So what you want to optimize is basically quality, speed and memory.",
            "We have three stages to optimize the aggregation step.",
            "The dimensionality reduction unsound Excel algorithm.",
            "That is why."
        ],
        [
            "So to next section will be dedicated to 1st."
        ],
        [
            "Location of the descriptor.",
            "Since descriptors in two single vector.",
            "So back off word was negation procedure.",
            "I will present some other one.",
            "Then we spent some time on the efficient indexing you're going to efficiently search, but also anchored this descriptor so that they do not take too much memory."
        ],
        [
            "So first motivation for new aggregation algorithm mechanism was about improving the quality of the representation, not about the scale.",
            "But I have to mention that what I'm going to present was first proposed in classification, whereas people are less.",
            "Actually, we're less interested by scaling now.",
            "It's not the case anymore with image net concern, but historically image search is.",
            "More scalable than classification, and I think there's a gap now tends to to be reduced.",
            "So the code is just about counting the number of local descriptors.",
            "So why not including some other statistics?",
            "So for instance, the mean of local descriptors in a given region of the space.",
            "Only this occurrence of Luke."
        ],
        [
            "Descriptors."
        ],
        [
            "The first example of how to include more information that then adjusts accounting is of lab.",
            "So there we still have a cookbook chemist, quantizer defining some visual words.",
            "We still have this assignment procedure which is going to assign each descriptor to its closest entries.",
            "So for instance, this country this computers or assigned to this country and so on.",
            "But instead of sampling counting them.",
            "You're going to incur the difference between the descriptor on its entry, so this difference is vector difference actually can be shown there, so you have their three vector of difference on just some of them.",
            "Which means that per cell you obtain a vector not account like indigo fraud within your vector, which is the cumulative some of the descriptor which have been assigned to the same trade.",
            "And finally you normalize this vector so demonstrates descriptor in this case is bigger than for both ran for the same vocabulary size.",
            "That is, if you have some trees on the dimensionality of the vector, which is do you have cat times D vector of?",
            "Times D sorry.",
            "So instead of K. So the good thing is that it is a marginal switch shift.",
            "It is a difference of."
        ],
        [
            "So you can do it like.",
            "We do for safety and see if we have this 4 * 4 grid.",
            "The only difference is that we might have some negative values represented there in red and you can observe hopefully that if you have similar images you will have similar representation.",
            "So there on there, I think is quite clear.",
            "OK."
        ],
        [
            "Vlad, as we will see is it was introduced after the feature vector but is very close actually in effect.",
            "So the feature vector you might know that this is a state of the art for image classification today.",
            "It has been used successfully by exact, in particular in the last image net Challenge, last year on the unit.",
            "Actually it has been shown last year.",
            "Again we see that it was better than all other new coding technique in cutting technique in the paper.",
            "So the devil is in the details.",
            "What is a Fisher vector?",
            "So it was introduced by Perona Xerox in 2007.",
            "For images, just first introduce 98, but I will come back and spine.",
            "So given likelihood function with parameter Lambda we can define the score function forgiven.",
            "Simple as a derivative of the log likelihood and we expect this parameters of the observation.",
            "So this gives us vector fixed dimensionality, which only depends on the number of parameters.",
            "So for each parameter you have a dimension.",
            "So the intuition is, given some observation on given a generative model, you try to explain how to modify the model.",
            "So that better fits the particular observations that you have.",
            "This is basic intuition, so have your model when you try to start it using this.",
            "This kind of graduate in the log in the space of likelihood two better explains observation.",
            "So the Fisher information matrix can be."
        ],
        [
            "Writing like this so it can be used as proposed by Akula two measures.",
            "The similarity between two observation using official kernel.",
            "So first channel is a kernel.",
            "Chance to compare two representation of produce as a derivative is likely woulda by using these metrics in the middle, which is in versus Fisher information matrix on.",
            "This can be interpreted as some widening of this course actually.",
            "The good thing is that it can be decomposed explicitly, this showing to measure metrics like this so.",
            "So that then you can incorporate directly.",
            "One part who's left part in the descriptor you have generated before in the user terms you can have directly this.",
            "Viktorov score.",
            "Process such that you can compute the Fisher kernel inefficient manner simply by making your inner product.",
            "So now images.",
            "Bill Nye proposed to present a set of."
        ],
        [
            "The script also and to compare set of descriptors using this feature kernel.",
            "So let's assume that you have some, for instance, descriptors which are supposed to be independent vector generated by some distribution.",
            "Then you can simply add the.",
            "This individual.",
            "Derivative of the log likelihood function respect with parameters and to make some average pooling, which amounts to make the independence assumption to obtain.",
            "Victor on if you consider in particular the case where your model is a Gaussian mixture model.",
            "You tell a set of vector which is actually promised some kind of probabilistic visual vocabulary in which you can incorporate many quantities, such as first counter the descriptor, the mean of the distribution you observe in particular respect to the parameters on the covariance term.",
            "So there in the feature vector you basically have the graduates of the derivative locally."
        ],
        [
            "Spec to the counter give you some soft bag off road."
        ],
        [
            "Liking the assignment in value in the burger photo presentation."
        ],
        [
            "But you can add more parameters to your gym model so you can stall so the derivative with respect to the meaner, which give you this formula which is actually very close to summation in a given vocabulary of descriptor minus a centroid.",
            "So there you can already see the relationship with Lab, except that we have you have this white.",
            "Operation, which is performed intrinsically.",
            "You can also uncovered some temp related to the Ryans so in practice.",
            "The proposed to use the general model for the mixture of Goshen on this will be explained of a respectful way of term.",
            "So now if you compare big off road with the Fisher Vector, we have a much higher dimensional vector instead of having.",
            "So should we care case onto it?",
            "So vector dimension K we have two DK dimension.",
            "So you have 2D instead of.",
            "Q factor.",
            "But it is very efficient to compute because the assignment cause."
        ],
        [
            "Which is one of the most quality question bag of word is the same actually as is a bag of Fern.",
            "Assuming that software segment is not more costly than art hasn't.",
            "So first."
        ],
        [
            "When you use the feature vector, it is very important to make some PCA principal component analysis on the local descriptor first on.",
            "The reason is that as I mentioned, the proposed to use additional model for the reason of complexity actually to get not so big model of parameters because for the feature you have one dimension parameters with the covariance matrix it will begin.",
            "Uon's and to have better to have this assumption of diagonal dignity of the matrix better satisfy, it's better to perform PCA first on the local descriptor.",
            "So actually this can be shown there on this graph, where we show the performance of the feature."
        ],
        [
            "With a regular descriptor as input on, then we PCA perform on the local script before applying the feature vector.",
            "And as you can see, the best consumer obtain when applying the dimensionality reduction of the features on input.",
            "For two reasons.",
            "So the first is when I mention the generality assumption of the model is better satisfied, but also the feature perform some lightening.",
            "Which turns to.",
            "To increase the noisy dimensions or the lower energy dimension in the PCA may introduce some new noise.",
            "It should make some turning on them, so you should avoid to use this dimensionality these components.",
            "Another very important step in the feature vector to be done is the parallel component wise."
        ],
        [
            "Normalization?",
            "So let me go forward.",
            "The feature vector representations refer from overcounting of similar pattern, so I mentioned before that when you make the inner product between two regular histogram, you're going to overcount the matches when you have several matches.",
            "Person, if you have three on 3, you get 9 votes on.",
            "For this reason, you apply.",
            "Some square rooting so that the behavior is the number score is linear in the number of matches, which are possible.",
            "So we have this effect of accounting similar patterns that also appear in the Fisher kernel, but it is even more important, in particular when you consider done set up because you have some bursty visual elements that is in natural images, you might know that you have many burst visual burst that is repeated patterns, visual patterns when you look at them closer almost the same.",
            "On the there not so frequent in the world database, but they appear in the same image at the same time.",
            "Which means that when you compute similarity between bag of word or feature vector, you're going to give almost most of the energy in the vote to this repetitive patterns.",
            "This is actually in for sizing the magnifying.",
            "The problem of overcounted pattern on it has been shown that it is very effective solution to apply some power law component wise on this representation.",
            "So if you just want to take into account without counting, you might consider this crouching below 0.5 by default on if you want in addition to reduce impact of bursty pattern you might even consider.",
            "Smaller value of Alpha, typically 0.3 or 0.4.",
            "There is a strong correlation sheet between."
        ],
        [
            "As of late in the future, as I mentioned, the red can carry viewed as non probabilistic version of the Fisher Vector where the Gaussian mixture model is replaced simply by Cummins.",
            "So it must transforming this into this.",
            "The main difference is if you want to focus on that is that Fisher performance soft assignment or the descriptors.",
            "So this may be interesting with interest point I have to mention that my experiments assignment is not very important in the done set up because they have done set up.",
            "You already have implicitly some kind of assignment performed by the sampling.",
            "It also implicitly white turns a component.",
            "So introduce impact.",
            "The components which are more energetic naturally in the database.",
            "On my opinion, this as.",
            "Some kind of similar effect with squelching perform component twice in the same descriptors to reach you perform some square rooting on the CD script or jointly with opinions of Lad.",
            "You get almost the same as feature, even better in some cases.",
            "But the future is imaginary setter because you can use any model representative parameters on give.",
            "You say you out wrong code and compare 8, which means that you can extend it to consider someone order statistic on, you can consider a something different from GM for the encoding, so it is more generic.",
            "But in this way you can also say OK, we can extend the Vlad to include some 2nd order statistic, and it was a, for instance, turning the flat paper which is of ladder but which also consider 2nd order statistics.",
            "And I want to mention that the supervector so this is V 2011 was shown relatively effective.",
            "On it is approximately some combination, some weighted combination of a bag of fraud on Vlad Vector.",
            "Almost the same on the question.",
            "Actually that it was not as good as Fisher in this paper from BBC by Sheffield last year.",
            "So how does this new aggregation representation compare with bag of Worm?"
        ],
        [
            "First, there we only displayed.",
            "The fish are using the derivative respect to the mean because in retrieval for some reasons the 2nd order static do not help.",
            "It's very important classification classification but not for image search."
        ],
        [
            "So for the same dimensionality that is significantly smaller vocabulary because you have person three forgiven vocabulary size feature on Vlad or dimensionality which is larger.",
            "But even for the same dimensionality on this data set, early days Zulte of the feature of lead are much better than the one of the group with the same vocabulary size.",
            "Soft."
        ],
        [
            "Segment on the waiting is a feature vector help, so the result or better than the there.",
            "But when you do some damage."
        ],
        [
            "Introduction of the vector, then those are almost the same."
        ],
        [
            "Finally, to conclude this part, yes to mention that there are some public implementation of the feature vector and also Vlad and this web page, so I think this one is implementation that was used by the people from Oxford for the evaluation last year."
        ],
        [
            "Question 4.",
            "I don't like that.",
            "I'd like to get maybe some comments because we use GMM in 28 dimensions.",
            "It's a very high dimensional space, so what's your personal view on our chances?",
            "First of all, whether you think there's descriptors really density is can be well estimated by GMM.",
            "Based on your research.",
            "And Secondly, even if it was with our chances of finding it.",
            "Model.",
            "Given the dimensions and.",
            "Not so much data, it doesn't work.",
            "It doesn't work very well, but just more insight.",
            "I personally think that the model is not good and completely artificial.",
            "This is Jean and mixture model for Steve.",
            "Descriptor is very bad for sure on there are some is also evidence of this actually because there's this paper by less burning.",
            "For instance that tried to estimate the local dimensionality of the self descriptors and it occurs at the dimensionality.",
            "First is not fixed, depends on where you're in space and is why it's more compared to the overall space.",
            "So the model.",
            "Of course very bad.",
            "Are we going to find some way to better model it?",
            "I don't know, but I'm not sure that it is that important that the model is very, very good.",
            "I'm OK, this is a contradiction with what I say.",
            "Things that you should make your local PCA before to better satisfies the fact that your matrix is the owner.",
            "But actually quite interesting if it showed the table that you just displayed comparing lot to GMM.",
            "And actually, as you notice to commenters, when you go down with them and show it to you.",
            "The results are very comparable.",
            "So, so we had to 2000 dimensions.",
            "It's 62.6 versus 62.1, so it's almost the same, yes.",
            "So so it seems that.",
            "Blood is still extracting as much as.",
            "Fisher, but perhaps in so, so very big, noisy in the input language ability.",
            "Yeah, OK, I do agree that that is is appealing because it is simple, but feature was first introduced before write an for large scale image search.",
            "I would suggest to use Vlad because this employer on also maybe a bit faster, but very slightly to be honest, but in classification it is really shown that feature is superior.",
            "So on the fact that the.",
            "Performance or not, that different, especially after the machine reduction is maybe because there are some effects that we do not take into account on which anyway or the bottleneck on this.",
            "So it may be the case that they are closed because they actually explore the same thing on the awesome statistical effects that neither of these two representation exploit on this might be the bottleneck.",
            "So maybe work on the bottleneck before."
        ],
        [
            "Open these.",
            "Words.",
            "But it sort of matters how many bytes used or each other.",
            "Yeah so.",
            "About the fact that we need to store all the here, understand the question you mentioned.",
            "The fact that we still need to store the components right?",
            "Is the question.",
            "Yes.",
            "Yes.",
            "Let's go to an exception directly.",
            "Ask you perform.",
            "Scriptures to type of allies dimension.",
            "So basically you can comparison how about performance if we don't perform this type?",
            "OK so for Vlad the dimension reduction of the local descriptor has no effect basically.",
            "OK.",
            "Exactly exactly.",
            "Right, right?",
            "So the white whitening is not implemented in the flood where it isn't Fisher on the widening, of course, is rotation dependent invite.",
            "There is no such step which is quotation dependence, so you can take any basis.",
            "It's the same and that is why it has almost no effect.",
            "PC has no effect on Vlad on awesome effect on Fisher vectors.",
            "Thoughts?",
            "How to make these recently visited implemented off?",
            "Because you are half cadence, which now since basically they would try to achieve the same compliance with the cluster.",
            "So, So what you mean?",
            "So basically lawsuits police it's white and because it uses K means OK, listen tried to basically compose clusters that have the same violence, yeah, But chemistry is not going to modify isometrics.",
            "L2 distance remains a metric under some rotation.",
            "When Vlad, you have this expansion, which is performed by the Sigma I, which is going to magnify certain axis on reducing mothers, the most synergistic one so.",
            "Disrespect the flag is OK. You have to come in that is going to put more.",
            "It's actually where you have more energy but it is not going to compensate for the fact that you have some some ellipsoid.",
            "Some distribution which is more important on certain access at some others, so you do not have any expansion.",
            "It doesn't modify the metric.",
            "Yeah, so it's the same issue.",
            "It should make PCA before Vlad chemist is rotation invariant, so except you if you're going to really reduce the large dimensionality, in which case we have some effect.",
            "Of course the Vlad without office PC is the same.",
            "Basically.",
            "I think I have to go to next because otherwise I will be late and on.",
            "I think this part will answer the previous question.",
            "So now as a notice by one question we have still some whole descriptors on.",
            "If you want to go to very large K, we need to."
        ],
        [
            "Have some efficient indexing technique for this one."
        ],
        [
            "So I have a voicemail outline I want to present."
        ],
        [
            "So I'm going to be a bit fast.",
            "So basically we want to find neighbors on the fast efficient way, also using very few memory.",
            "Basically the exhaustive search, the complexity of searching query vector of the size D in the data set of size N is N * D and four identical Victor.",
            "We know that indexing strategy or difficult to find the cause of this dimensional curves.",
            "But before I want to make a poll quick poll and how exact matching is respect to efficiency.",
            "Because sometimes I."
        ],
        [
            "This is some paper saying OK, it's very slow to make this comparison of this amount of Victor with this dimensionality.",
            "So just take a good package on the computer exact exact timings for some query for Victor compared to data set of, let's say one vector.",
            "So there I say OK I have 10 tenors, neighbor of 101 thousand queries in one detective formula vectors I assume.",
            "See descriptor, for instance, which means that I have to compute 1 billion distances in dimension 128 on a user 8 core machine.",
            "So make a polar who thinks that it takes more than one minute.",
            "OK, we think that it takes more than 10 seconds.",
            "OK, more than one second.",
            "Unless and once again.",
            "OK."
        ],
        [
            "Five types of guns.",
            "So OK, it is not that slow.",
            "It means that you can assign 2052 cabaret of size 100K in one or two seconds.",
            "Not that inefficient."
        ],
        [
            "OK, but of course you cannot match all the descriptor of million size database with the one of a query image.",
            "Unreal time to possible, because in this case it is 1 billion distance per local descriptors.",
            "So in total you have 2014 elementary operation.",
            "This is too big.",
            "One hour on 30 minutes.",
            "So you need approximate nearest neighbor search.",
            "On this A and then search has optimize jointly three kittiya, on which fine again the same tires.",
            "One that I wanted to optimize for the larger scale image search problem.",
            "That is such quality.",
            "We want the Rotary vector to be the actual nearest neighbor when you consider about indexing with approximately number search.",
            "When good goal is to try to reproduce, the result is obtained by the exhaustive search.",
            "Exact one.",
            "This speed it is why we go to approximate strategies on the memory and the memory is very important and I think as it received enough focus until recently.",
            "And I'm going to make a personal presentation."
        ],
        [
            "Locality sensitive hashing.",
            "Just to present our I see the things.",
            "It is very known."
        ],
        [
            "It is known in two different contexts and treatment ways of using it.",
            "It is the same underlying social framework, but basically it is not used in the same way.",
            "Depending on which community you are.",
            "So, LSH is usually associated with two distinct search algorithm.",
            "One is about.",
            "Partitioning techniques, which is called hashing, but let's say partitioning to be sure that the distinction is clear where you have several hash function.",
            "So there I have some.",
            "This is a hash function, which is actually a partition of the space.",
            "It just says I have 7 dash function on there, so dash function.",
            "Each hash function partition the space.",
            "What you have is that you have this.",
            "Set when you have a query or going to ash it for each of the hash function on to retrieve Colocalized neighbors to get a list of potential candidates for being nearest neighbors.",
            "After vision, it is more used.",
            "I would say as winners in technique where you have a feature space in which is Euclidean.",
            "Typically we want to cast the search for the equation distance into a search for the binary distance, Hamming distance in the binary space.",
            "OK, so LSH, jediism PDF."
        ],
        [
            "Italian, each vector in databases associated with hash keys stored in inverted list on the query time you compute the hash key for the query and consistent manner on your retrieve.",
            "Also database vectors which are assigned to the same key and then you compute.",
            "On this set of candidates, the exact distance is, so this is square LSH, typically.",
            "You can use any kind of hash function, so most popular."
        ],
        [
            "Honda projections that you can use anyone so underneath, for instance, proposal each quantizer strictly contains surfaces.",
            "It can be a structure.",
            "Either learn came in, so can be used as a hash function.",
            "Yashica means gadgetry.",
            "So what?"
        ],
        [
            "Do we use as hash function?",
            "Super showing that it is much better to use learn hash function.",
            "Like I mean, for instance which adapts to the data that I chose, a compromise between the selectivity on the recall.",
            "Selectivity means the rate of neighbors in the short list, so the amount of neighbors identified as potential neighbors.",
            "Unusually, you have some booty instant parameters to find, to say I want this selectivity.",
            "So there for instance for Cummins I consider a bag of word of this Cummins.",
            "A 400 the words which give you selectivity, which is approximately of 1% and you can increase the vocabulary size exists for each of this structure.",
            "Contains are there.",
            "You can also adjust the size of the elementary hash function in the case of lattices it is just a scale factor for instance.",
            "On that you can see that learndash function or much better than this random projection.",
            "That are very often used actually.",
            "If you use a bitter container, we expect to for uniform distribution like lettuce, quantizer, so is a lattice or each lattice.",
            "You get some improvement, but it's not that it's the data.",
            "So finally you don't have good results.",
            "You should look at the usual cabins.",
            "You can see that you lose respect to the regular flat chemist confessor, but finally in this scale of loss, not that much.",
            "OK, the problem with locality sensitive rushing in user partitioning technique is that you have to."
        ],
        [
            "Store for ejector and ID, at least in each table.",
            "So this take a lot of memory.",
            "So for systems descriptor where you have to use about the 10 assumption, it means 40 bytes is a lot.",
            "In addition to that we have to store the vector though vector for the final verification.",
            "So for the sake of reducing the memory usage of the hash function, you can just use what is called the problem and it was actually proposed before multiple assignment.",
            "But this is basically the same ID, so there.",
            "Instead of using multiple hash function, you are going to use one.",
            "But instead of assigning your descriptor Azure database as a query to hash function, you're going to assign it to several hash function.",
            "So usually it is done only on query side.",
            "On doing that, you just have went from 1 hash function on your sign to you.",
            "at Test time.",
            "You're going to look at several cells to create the list of potential candidates.",
            "So there is of course correction sheet with multiple as a non bag of word and I want to mention that this was done in 2007 before.",
            "Flam flam"
        ],
        [
            "I think is very important package everyone should know about it is.",
            "Goes by Jack Charlie on the choose several action Polynome, multiplicative three or multiple chemistry, so is actually used learndash function, which is the best because they have multiple hash function.",
            "They get very good result.",
            "To retrieve approximate neighbors.",
            "So this is the two things which are important.",
            "Good good hash function.",
            "Hash function, or at least multi problem.",
            "On the other, good thing is that it is auto tune.",
            "The teaser gozum is going to select automatically the best set of parameters, so it is well implemented.",
            "They have to mention that it is not the first time that some search to tune LSH as proposed was first proposed by Dong in 2007 on the size of paper.",
            "So this year by Slender that say also to fix the parameters of LSH.",
            "But it is a good package and actually very often used to perform the assignment of descriptors.",
            "Two visual words, especially for large vocabularies because for my test for relatively small vocabularies it is better to use the efficient exhaustive search.",
            "OK, but still we have this."
        ],
        [
            "Package, including fans that are going to preselect a set of candidates on then they have to perform.",
            "After achieving potential neighbors some exact distance calculation to find the true list of neighbors among the one which have been selected.",
            "So basically, if your vector has been selected as a protection labels.",
            "After this exact same speculation, you're sure to rank.",
            "It is a list of nearest neighbor in the correct order is only a risk you have is if you are not able to retrieve it from the first stage, which is, which is not going to consider all the vectors.",
            "So if it is missing, the 1st place will not be able to find it in the second stage.",
            "For the second stage we need."
        ],
        [
            "The whole descriptor, which is too much.",
            "As an insurance, so you have to go to the discount, but this of course impacts the efficiency quite severely.",
            "So not only large scale.",
            "OK, and now this is the second mode for LSH."
        ],
        [
            "Which say, OK, we're going to map Oakland descriptor to binary space, ongoing space.",
            "It is very interesting, because one so descriptor, very compact.",
            "Xorb, it's Victor of bits, so if you have 60 four dimension, it fits in one machine world.",
            "Unless you have a very fast comparison because you have just to make a popcount operation, which is a single instruction.",
            "Now in a new Inter processor.",
            "So observe compare exhaust.",
            "Sorry on the to make the difference.",
            "To find this picture different on the pop count operation.",
            "So two operation only can be very fast.",
            "It is very fast."
        ],
        [
            "So probably one of the most known algorithm is Petra lashing, which is a nice article framework for finding a solution, but which in practice is just a PCA followed by some urbanization on the different axis based on variance.",
            "So."
        ],
        [
            "So the two modes of LSH or the following year.",
            "User partitioning technique.",
            "LSHS sub linear.",
            "On this and perform exhaustive search so you're not going to compare to everybody because based simply on the vector which or crashed, you're going to only focus on the subset of candidates.",
            "But you have a large memory overhead.",
            "First hashtable overhead and also you need the original vectors for the ranking stage.",
            "So it is interesting, in my opinion when.",
            "You have demonstrated which is not too big, because if the dimension is too big and the fact that you use a partitioning approach is not good, you're going to be impacted by the curse of dimensionality.",
            "You cannot do that.",
            "Also, it's interesting with the user.",
            "Data set is not too small.",
            "1,000,000 is OK, one billion is not OK because of this memory.",
            "So those are some very good variance in software.",
            "In particular, plan users administration technique.",
            "From linear search, but if your individual search is extremely faster on this is a compact comparison.",
            "So for me it is interesting for very high dimensional vectors.",
            "Unmet memory is critical.",
            "On this, calculated to larger scale image search in our case.",
            "OK so I would advise to use this partitioning murder.",
            "So for instance using."
        ],
        [
            "Plan for searching local descriptor or assigning on.",
            "This one is for.",
            "Indexing very large vector on is of particular interest in the case of very large scale inmate search.",
            "When you want to index directly the global descriptors as produced by the Fisher kernel of Lab."
        ],
        [
            "OK, hang on building.",
            "We have two more for less edge.",
            "Can we try to use the best of both actually?"
        ],
        [
            "Two, we wanted to do is having a building which is a combination of a partitioning technique.",
            "Wish.",
            "Urbanizacion technique.",
            "Victory is represented by.",
            "First quantization index on the binary code in the cell.",
            "On the matching rule is 2 descriptor match if and only if and only if they are contais.",
            "Therefore in the same.",
            "Version of the space according to the hash function.",
            "If in addition, the Beanery vector as determined by your local local caching function is similar, so we have partitioning on the local measurement.",
            "On this give very good results, I'm going straight to show the visual impact."
        ],
        [
            "For this, having a building step this."
        ],
        [
            "Is 20 K vocabulary."
        ],
        [
            "It should be 4.",
            "If we take a larger vocabulary, losing a lot of matches."
        ],
        [
            "I miss having a building.",
            "We are going to preserve most of the correct matches.",
            "We're moving many first positive, so this in this case the image of a lot of matches.",
            "The future so extent with a larger vocabulary.",
            "But we sending first have more correct matches unless incorrect matches."
        ],
        [
            "OK, and now I go to the final technique that I want to present which is product."
        ],
        [
            "Physician basically, which is about approximate search using compression technique such that our feature Vector of Lado bag of words can be compacting very few bites.",
            "So this is a typical source coding system I have as I have done doing my PhD quite a lot because I did my PhD in source coding on joints.",
            "Which encoding you have basically a vector which is decorated.",
            "First step, so this PCA Kevin Love you can density for JPEG wavelet transform for GP2000 then it is followed by a contagious and step which is only last step there.",
            "You lose some information is only place where you lose some information on.",
            "Then you have some entropy coder which is lossless coding.",
            "That is from here we can go back there.",
            "So I'm going just to focus on the quantization step which is the one which given the descriptor find the.",
            "Is the best for production value?",
            "Forgiven contessa?",
            "So we can show that if you estimate the distance between the query."
        ],
        [
            "On the Pacific, by the distance between query on the contest.",
            "Version of Victor.",
            "You have some statistical bound saying use that the square or between the distance is bounded by the quantization error.",
            "So the batteries are contains are the better is your distance estimation on your some boundary for the perfect perfect container is young.",
            "You have a perfect distance estimation.",
            "So the idea of this work is to say it is to use a product container.",
            "2.",
            "As a contest."
        ],
        [
            "To perform this kind of estimation on, we see the search as a distance estimation approximation problem, where the distances will be computed in the compressed domain directly.",
            "Such that the quantization is fast and precise enough so for the conversation to be precise, we need a lot of production values.",
            "We need a lot of possible some trees on, not letting that go through, we need significantly more.",
            "We need about two power, 64% rates even more so you cannot fast learner regular comes with that on the incursus primitive.",
            "So instead what you can use is just a protocol Kaiser where you're simply going to split.",
            "Your victim."
        ],
        [
            "Into several parts.",
            "On each side, Victor is Contessa partly.",
            "So for instance, if I take this 16 dimensional vector on, spit it into eight vector, I have 8 contains are applied to component or two components.",
            "On the right produce me.",
            "I have ate some trade person quantizer 3 bits.",
            "So in total I have a 24 bits quantization index, which means that you have to power 24 possible values, which is a lot on typical settings.",
            "We would have a big person container.",
            "On about four to 16 sub container for serious cryptos, for instance, if we take 8 second Acer, you will have two pair of 64 possible positions values, so this is very much more precise than what you can achieve with chemist container and you can do it on.",
            "Vectors are very high dimensional ET which relatively small assignment cost.",
            "So the item cost is equal.",
            "To 2% in the number of bits.",
            "So if you have for instance.",
            "Like this 256 position value person contains are the complexity that complexity of financial index is simply curtains D where D the dimensionality of descriptor on where K is this number of possible.",
            "So it's plastic container.",
            "The good thing is that."
        ],
        [
            "Issues Republican taiser you actually you're going to too concise.",
            "Inaugural space is the signal, which means that if you want to estimate the distance between X&Y.",
            "You can approximate it by summation.",
            "Between of the distance between square distance between each vector on the contest.",
            "So Victor associated with that are basic to ryi.",
            "So at this stage you might think, OK, I've not won anything because I have to make this summation instead of the.",
            "Regular distance computation, but it's the same number of operation.",
            "Even more.",
            "The fact is that it is true if you only consider two vectors, but if you consider that you have one query on many database vectors.",
            "Who is this quantity there?",
            "Actually shared by all the vectors of the database.",
            "So basically when you want to compute all the distances between your query vector on a set of data, basic terms what you have to do is first to compute a set of lookup tables that are going to store all these possible possible terms there in the summation.",
            "The precomputed at this stage you have not looked at the database of vectors, you've just precomputed tables.",
            "The look up tables, and now when you have a particular database vector, you just look at the IDs to retrieve this Emon Tori term associated with this vector.",
            "You just have to send the different components, which in practice that if we have 8 quantizer, you just have to make 8 addition from this group tables.",
            "So yeah, this cursed created tables that appears in this summation on the second stage, which is only one which is linear in the number of database vectors.",
            "Amounts to make this small underestimation for each vector to compute estimated distances.",
            "This is just to show."
        ],
        [
            "Is the estimated distance against the true distance and there you can see that we have some bias we can prove.",
            "Actually you can compute the buyers that the estimated distance are, underestimate the true distances.",
            "Unlike in having a busy."
        ],
        [
            "We can combine this technique, which is a measurement based technique, so it's a competitor actually have the generation technique.",
            "We can combine this measurement based technique jointly with across container so it is a partitioning technique so at the cost level you separate the feature space using across container partition technique like Nilles Edge.",
            "Then instead of going back to the original vectors you simply rely on this.",
            "Product contains a distance estimation.",
            "To find the nearest neighbors.",
            "The typical timings is to query the data set of two billion vectors forgiven query vector.",
            "It takes 3 to 5 minutes ago.",
            "OK, this is a much better than the spectral Sheen of narration technique.",
            "You can trust me."
        ],
        [
            "For this, the author application of product Azatian also context that they will detail."
        ],
        [
            "Because I'm going out of time, just saying one thing which is very important, I believe is that product authorization is actually a way to compute an approximate inner product.",
            "So it can be used in any context where you want to compute the inner product between one vector on big set of vectors.",
            "Every matrix vector multiplication can be used on the metrics is compressed actually, so it has been used.",
            "That's been used six 6:30, for instance, for learning in the compressed domain on their work, concurrent rules that actually use the same ID to improve the.",
            "So this is a different products, different way of using it.",
            "But both use public quantization to approximate matrix vector manipulation."
        ],
        [
            "OK, on this has been so the message of this part is just that.",
            "It's very important to consider.",
            "Indexing jointly with image representation because it shouldn't make large scale image search on even larger.",
            "You need efficient technique which are memory aware like product azatian we have tested it on many many set up text scripter or descriptor.",
            "Any kind of descriptor which is compared with the equivalent distance on which actually is interesting.",
            "Because now that we have this specific embedding technique that try to cast any kernel.",
            "Into space where you can simply using your product, it means that you can basically use product integration event for.",
            "Collapse."
        ],
        [
            "OK, and now I'm going to be sending you plates, but I will come."
        ],
        [
            "Should.",
            "And.",
            "So I mentioned my talk back off road and some extension on how we can make larger image search with one level aggregation mechanism on efficient indexing.",
            "Basically I have presented the part separately but very efficient indexing system on very large scale is the only thing that you have to do is to you is to use.",
            "Jointly, this novel aggregation mechanism with efficient indexing technique which is going to impact your descriptor or descriptor into a few number of bytes.",
            "So."
        ],
        [
            "So you have this large scale setup which seems to state of the art, which should still represent each individual descriptors on exploit, some matching some extension for better matching, reconquer expansion on a larger scale.",
            "This is not possible because of the memory constraint is also strong limitation, but you can still a very good result by using surface structure follow as usual, but I would suggest you use dense because.",
            "In this setup, you not explore this positives injected file, so you should use dense something because it's better as well basically.",
            "Some improve aggregation algorithm, so cannot import a program on an efficient Dixon technique that is going to compress your descriptor on allows you to perform the search in the compressed domain.",
            "The shoes payments are on up to 10,000,000 images.",
            "With some descriptor of."
        ],
        [
            "Is represented by only 16 bytes byproduct quantization on top of feature.",
            "You can have some of which are relatively good compared to, which is obtained by biographer representation.",
            "So there they go through on.",
            "Unless you increase number of bytes have more budget, you can early reach the performance as a whole representation.",
            "There's a continuum between the descriptor on the compressed version of the descriptor, and you can use any intermediate approaching point actually.",
            "Just to mention exists, sure search is not that slow.",
            "7 sagon in this case for a set of vectors until noon images.",
            "So you can set up is the dimension key of the vector is not too big.",
            "You can still use exhaustive search on now I will just mention that we have done some experiment on up to 100 million descriptors.",
            "On that using.",
            "I get in this crypto compresses much better than using some descriptor."
        ],
        [
            "Compressed"
        ],
        [
            "OK, I love you.",
            "Already mentioned that I think that the future of image search and supervisor is to use supervised technique to improve it.",
            "So is awesome recent paper for instance that tried to.",
            "Bring some annotation from image.",
            "Net learning supervised way onto playita.",
            "For general image search on.",
            "Actually this gives good.",
            "This gives some very good results.",
            "On this is I will finish with.",
            "This slide on the free demo if given time.",
            "Free, I have given some tools to under very large scale data set in this tutorial mentioned about some extension of the back."
        ],
        [
            "Refer them on why we should also increase Biostatistics.",
            "To improve the results on also to get some descriptor which can be compressed efficiently using dimensional reduction on the compressed domain.",
            "Indexing on the message that very large limit search.",
            "You can do it and we limited resources do not need a cluster to participate to image net you do not need to have very strong machine.",
            "I think that today we have the tools to have state of the art results with regular machines.",
            "Evan's University.",
            "So basically, this promotion you have done searching 100 images takes only two 5.",
            "It is about 200 minutes ago and of course you have to 1st struggle descriptor, which is maybe the bottleneck in this setup, but the rest is quite quite fast.",
            "On to show that these are not only words, but also that it works really in practice.",
            "If it works because the demo is maybe idle, no, it's OK.",
            "So this is my image search server, so there I have my indexing algorithm which is implemented on my laptop.",
            "In my Mac it is not even an I5 occurrences order one and I have 10 images which are stored on the disk because they cannot fit on the hard drive of the machine.",
            "I can perform search in here times there the only thing which is already done there is extraction of descriptors which is already done before the demo.",
            "But there's a search in the United File is performed on the fly.",
            "So what you can see is that first it is very fast.",
            "They.",
            "You know, it's the invariants.",
            "Of the local descriptor.",
            "So in this case we use send final descriptor to describe the images.",
            "You can under strong change.",
            "If you knew points.",
            "OK, this is a regular image search technique, you will think probably, but as you can see.",
            "OK, sorry.",
            "It's gonna be fast.",
            "OK the timing is.",
            "Sorry.",
            "The timing is about 20 minutes ago on the regular machine 1 core on so it is linear and the number of image.",
            "On the thing you have to know about this is that each image there is represented in memory by 21 bytes, 21 bytes per memory.",
            "So it means that the full index used to make present this result.",
            "It takes about 200 megabytes, so I could even go to 100 millions images on this laptop because I have 4 gigabytes of memory.",
            "The things that I cannot find final disk where I could fit 100 million images.",
            "But you can.",
            "You can already scheduled.",
            "Of course it is the extreme point.",
            "If you want better result, you should use more memory.",
            "But still I want just to show one example that does not work, otherwise it is not fair, right?",
            "This does not work.",
            "In this 21 bytes support and taken by the Apple logo is of course too small.",
            "You have this results show return which or not correct, but in the same time compared to regular matching you have some better results and queries like OK like this ones baby.",
            "You have some babies and will return on his back off road.",
            "You get very crappy results with this query even if user very strong matching system because it is more semantic and is able to absorb more ability.",
            "So there you have an outlier, but these are baby cats so I would say that it may be considered correct.",
            "OK, thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before starting, I would like to give you some special arrangements to some people who helped me to make this tutorial by providing me some multi or actually on particular from perona from Xerox.",
                    "label": 0
                },
                {
                    "sent": "Ashley from in here, but repairs from technical are on Andrea Chen from CIT.",
                    "label": 0
                },
                {
                    "sent": "So this is the outline of the talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tutorial and 1st I will present some typical applications and some that I set with which are used in the academic area.",
                    "label": 1
                },
                {
                    "sent": "Then I will speak about very briefly actually about Image description on matching to be very short so that they can put more focus on large scale on larger scale image search will present the bag of representation that probably many a few nodes on the few extensions that in my opinion are very important.",
                    "label": 1
                },
                {
                    "sent": "And finally, I will finish with a larger scale image search.",
                    "label": 0
                },
                {
                    "sent": "That is, what should we do if we want to scale to significantly more amount of images?",
                    "label": 0
                },
                {
                    "sent": "Let's say up to 1 billion images.",
                    "label": 0
                },
                {
                    "sent": "OK, so the scenarios that we can see.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is query by example where we might want to find given a query image, some relevant image in the database based on the visual content solely so it is not about metadata uncertainties about the content of the image itself.",
                    "label": 0
                },
                {
                    "sent": "So the first typical case is a single condition.",
                    "label": 0
                },
                {
                    "sent": "There you have an image of the pyramid Cheops and then you want to retrieve all the images from the test set that correspond to the same.",
                    "label": 0
                },
                {
                    "sent": "Location so it is about location or condition or object recognition.",
                    "label": 0
                },
                {
                    "sent": "If you think of things, but it is also very useful for copy detection or near duplicate detection.",
                    "label": 0
                },
                {
                    "sent": "In this case I have printed an image on scan it and so this gives this horrible images with many reflection.",
                    "label": 0
                },
                {
                    "sent": "We want to treat the original image on.",
                    "label": 0
                },
                {
                    "sent": "This is important to know is there some copyrighted images.",
                    "label": 0
                },
                {
                    "sent": "I have been used without.",
                    "label": 0
                },
                {
                    "sent": "And paying any fee.",
                    "label": 0
                },
                {
                    "sent": "So we want to do it interactive interactively.",
                    "label": 0
                },
                {
                    "sent": "That is, with a short response time.",
                    "label": 1
                },
                {
                    "sent": "So shortly can means from a few minutes ago, onto several sedans and two under millions to billions of images.",
                    "label": 1
                },
                {
                    "sent": "So in this talk we will focus on million sized data set in what they call large scale image search on.",
                    "label": 0
                },
                {
                    "sent": "Then we will go to missile which are able to scale to billions of images on the single server.",
                    "label": 0
                },
                {
                    "sent": "That is, we do not want to put 1000 server in parallel.",
                    "label": 0
                },
                {
                    "sent": "I want to do it with limited resources.",
                    "label": 0
                },
                {
                    "sent": "So just a few sample of existing search engine, so you might take a look.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After this big imbas online images of server which index 10,000,000 images, it is active since 2008.",
                    "label": 0
                },
                {
                    "sent": "So you can input some images of yours, like the full tower and then you get some result order by accuracy.",
                    "label": 0
                },
                {
                    "sent": "Of course, you probably knows that I need a search.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Engine which actually index sees a lot of images and billions of images on the web on the provide some service.",
                    "label": 0
                },
                {
                    "sent": "So this is a company to detect the images which might be the same as same content as a query image.",
                    "label": 0
                },
                {
                    "sent": "It is limited to near duplicate mostly, but as you can see we can absorb some variation of intensity.",
                    "label": 0
                },
                {
                    "sent": "On event some landscape against.",
                    "label": 0
                },
                {
                    "sent": "Against this format of image.",
                    "label": 0
                },
                {
                    "sent": "On there is also very impactful Google Google's search system which works.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On Android, on the mobile device, we are given a query.",
                    "label": 1
                },
                {
                    "sent": "You can submit it on.",
                    "label": 0
                },
                {
                    "sent": "Actually this search engine implements many technique in parallel, so in particular we dedicated search engine for QR codes.",
                    "label": 0
                },
                {
                    "sent": "But also you can make more general image search on for instance that is able to find some paint art.",
                    "label": 0
                },
                {
                    "sent": "OK, so about the scalability of image search.",
                    "label": 0
                },
                {
                    "sent": "We can differentiate.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distinguish two different kind of system.",
                    "label": 0
                },
                {
                    "sent": "The first set of system works with global descriptors, while the 2nd works with local descriptors.",
                    "label": 1
                },
                {
                    "sent": "Basically to make sure global descriptors there able to find images as image level that is the same scene with little deformation, little.",
                    "label": 0
                },
                {
                    "sent": "Transformation like rotation or scaling on the usually organized image as a wall, not specific area, while local descriptor or able to find instances that is part of the objects that may be in the image.",
                    "label": 0
                },
                {
                    "sent": "So the most gullible ones or the global descriptors starting with CU in 1995 which was able to index about 8000 images.",
                    "label": 0
                },
                {
                    "sent": "So it might not be.",
                    "label": 0
                },
                {
                    "sent": "That's very big today, but at the time it was very, very big.",
                    "label": 0
                },
                {
                    "sent": "There could be assistant today on the speaker machine, could be used to index millions of images with no problem.",
                    "label": 0
                },
                {
                    "sent": "They also Cotner search engine by quack.",
                    "label": 1
                },
                {
                    "sent": "From it is a gauge which in 2004 was able to index also 3 million images.",
                    "label": 0
                },
                {
                    "sent": "Images of the word on a very impactful, impactful work was one of Two Harbors.",
                    "label": 0
                },
                {
                    "sent": "CPR, 2008, with small short memory codes on the large databases where they actually indexed 30,000,000 images and it has been standard 280 millions.",
                    "label": 0
                },
                {
                    "sent": "10 image data set with very few bit per image, so this works really.",
                    "label": 1
                },
                {
                    "sent": "Care about the memory usage stating that if you want to index large databases you need to have compact signature and I think this give give us insight on what is what should be done to go to larger data set on regular machine.",
                    "label": 0
                },
                {
                    "sent": "The concurrent work afterward was indexing more than 100 million images with Curry Temps, which are very fast.",
                    "label": 0
                },
                {
                    "sent": "So a few lessons.",
                    "label": 0
                },
                {
                    "sent": "Once again on one curl.",
                    "label": 0
                },
                {
                    "sent": "So now if you look at local descriptor, of course capabilities significantly lower because you have two under, not one descriptor preimage, but underrated thousands of descriptors on the similar work of Silicon on this.",
                    "label": 0
                },
                {
                    "sent": "So man, if you Google on which I'm going to spend a lot of time.",
                    "label": 0
                },
                {
                    "sent": "At this fall, under this tension was originally able only 205 thousand images, which is not that big, but they really gave the principles that could be used can be used to extend to more bigger datasets.",
                    "label": 0
                },
                {
                    "sent": "Works was quite an artist is a work by Julie, which I see I hear presented some work indexing 6 million images represented by more than 100 million descriptors.",
                    "label": 0
                },
                {
                    "sent": "So at the time it was.",
                    "label": 0
                },
                {
                    "sent": "Racing record on the well using some specific indexing techniques and not back off for presentation, but I think this work was visionary work so we have also this very impactful work by Eunice Terrance.",
                    "label": 0
                },
                {
                    "sent": "TV news in CPR six.",
                    "label": 0
                },
                {
                    "sent": "That really shown what House video Google System should be extended to under larger sets by proposing large vocabularies.",
                    "label": 0
                },
                {
                    "sent": "So initially the proposal it on 50,000 images, but it has been extended to.",
                    "label": 0
                },
                {
                    "sent": "Continue after after one and then can.",
                    "label": 0
                },
                {
                    "sent": "'cause the work which I will do after afterward.",
                    "label": 0
                },
                {
                    "sent": "My work at Cpl where we indexed 10 images and then one credit union images based on local descriptors on operable at the time to show you a demo to assist of the system working on this laptop at the other tutorial.",
                    "label": 0
                },
                {
                    "sent": "So what was the test that we used to evaluate?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This image search system.",
                    "label": 0
                },
                {
                    "sent": "So basically we use small data set of ground truth merge with bigger data set.",
                    "label": 1
                },
                {
                    "sent": "The reason this is it is very difficult to annotate very large scale data set.",
                    "label": 0
                },
                {
                    "sent": "So the way that people do that is that user smaller sets the 5000 images on.",
                    "label": 0
                },
                {
                    "sent": "Then you merge them with the destructor set, which is much bigger on for which you hope that you will not have some false positive.",
                    "label": 0
                },
                {
                    "sent": "So Oxford 5 case probably the most used one.",
                    "label": 0
                },
                {
                    "sent": "It is a system where the objective is given some query of some building that you might select on your mobile device.",
                    "label": 0
                },
                {
                    "sent": "For instance, you want to retrieve all the images of the set that contains this particular building on this operating from Oxford.",
                    "label": 1
                },
                {
                    "sent": "On the merge it with this set of distracting images also retrieves the keyword Oxford to make the valuation on a larger scale.",
                    "label": 0
                },
                {
                    "sent": "Loser, that asset is Holidays in real data set and which is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Smaller than the Oxford asset, but which contain more queries.",
                    "label": 0
                },
                {
                    "sent": "You have 500 queries, which is in some sense better for the statistics on the small number of results between 1:11, so this is quite unlike the previous data set of Oxford when you can have very many results or very furiously depending on the query on there are 1 million distracting images to make the variation on the large scale.",
                    "label": 1
                },
                {
                    "sent": "But in this case we know that there are several false false positive.",
                    "label": 0
                },
                {
                    "sent": "That is, for some particle query.",
                    "label": 0
                },
                {
                    "sent": "Which correspond 2 famous places in the world?",
                    "label": 0
                },
                {
                    "sent": "Is this random set of 1 images?",
                    "label": 0
                },
                {
                    "sent": "You have some corresponding images which should be labeled as true positive, but which are not labeled as true positive.",
                    "label": 0
                },
                {
                    "sent": "In practice, this has a little effect on the evaluation, but we have two noses which is possible to have perfect result on this data set.",
                    "label": 0
                },
                {
                    "sent": "On the images are not there for some reasons, so there is 1 popular there.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set which has been introduced before the other ones, which is a bit artificial but still is very used and it was proposed by instance to.",
                    "label": 0
                },
                {
                    "sent": "The news is in the city of contain key object recognition benchmark.",
                    "label": 1
                },
                {
                    "sent": "You have more than 2000 objects, each of which is represented by 4 images on the average curve is given.",
                    "label": 0
                },
                {
                    "sent": "The number of image wrong in the first four position, so the perfect score is 4.",
                    "label": 0
                },
                {
                    "sent": "OK, that's fine.",
                    "label": 0
                },
                {
                    "sent": "OK, and I want to also present this.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The set which is, I think less used, but which is very interesting, because it also correspond to a very important application case where you want to retrieve with your mobile phones and image and submit to a system containing some reference images on is that I set the reference images or high quality images while the queries are true images shot by mobile phones of different marks different so.",
                    "label": 1
                },
                {
                    "sent": "Might as Nokia on different phones, and this is very important because on this data set allows to focus on a symmetric quality of images on query side we have poor quality on database size.",
                    "label": 0
                },
                {
                    "sent": "You have a good quality and this is I think a challenge for the community to be able to under this asymmetric quality.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I go to the brief introduction of image description on matching.",
                    "label": 0
                },
                {
                    "sent": "This is not specifically specifically the focus of the tutorial.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I have to introduce it because we rely on this part.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So image description is actually an analysis step, so this we want to convert the image into mathematical representation.",
                    "label": 1
                },
                {
                    "sent": "Search that cinema images.",
                    "label": 0
                },
                {
                    "sent": "Respect to some application or two human interpretation are presented by similar mathematical representation, typically vectors or set of vectors.",
                    "label": 0
                },
                {
                    "sent": "On the difficulty of this analysis step is that we have to understand possible transformation of object in natural images.",
                    "label": 0
                },
                {
                    "sent": "So for instance we have scale there plus some critter.",
                    "label": 0
                },
                {
                    "sent": "Change of viewpoint in the store that I set.",
                    "label": 0
                },
                {
                    "sent": "Lighting, which is in this case very strong, as you can see on occlusion.",
                    "label": 0
                },
                {
                    "sent": "So we have to be a variant enough to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much is a mathematical object representing these images, but in the same time we want to be discriminate if we should not have two much invariants, so I take this particular example of this query for which the results of this one on which is based on the color descriptors.",
                    "label": 0
                },
                {
                    "sent": "Is it good result or not?",
                    "label": 0
                },
                {
                    "sent": "Well, it depends.",
                    "label": 0
                },
                {
                    "sent": "If you want to make some artwork, it might be considered as good because you want images that have the same color.",
                    "label": 1
                },
                {
                    "sent": "So from the article.",
                    "label": 0
                },
                {
                    "sent": "Chart it may be interesting, but from any application is not interesting.",
                    "label": 0
                },
                {
                    "sent": "So for locational conditions for instance, it is basically not usable.",
                    "label": 0
                },
                {
                    "sent": "So we have some tradeoff between discrimination.",
                    "label": 0
                },
                {
                    "sent": "And variance to transformation on this description should be tailored to the task that we want to address.",
                    "label": 1
                },
                {
                    "sent": "So some global descriptors.",
                    "label": 0
                },
                {
                    "sent": "Here the idea is to present an image.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One single descriptor, possibly of a dimension.",
                    "label": 1
                },
                {
                    "sent": "So the Chrysler Graham.",
                    "label": 1
                },
                {
                    "sent": "We have a very used at the beginning, in particular the one proposed by base when 91 on this provide, I invariants too many transformation, as we have seen in the previous slide, but limited discriminative power.",
                    "label": 1
                },
                {
                    "sent": "When very popular descriptor global descriptor is a gist descriptor by Olivia and to Alba, which incurred several frequency bands on rotation for each medication.",
                    "label": 0
                },
                {
                    "sent": "Try to capture the layout of the scene based on this description.",
                    "label": 0
                },
                {
                    "sent": "For instance, it takes device images in several part.",
                    "label": 0
                },
                {
                    "sent": "On different convolution and capture, so grading the rotations.",
                    "label": 0
                },
                {
                    "sent": "It is very useful single condition.",
                    "label": 0
                },
                {
                    "sent": "But most of the applications that we want to address, like locational condition.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Object recognition cannot rely on such descriptors.",
                    "label": 0
                },
                {
                    "sent": "Basically, most of the recent work on instant search or rely on local descriptors such as the one produced by the video in force.",
                    "label": 0
                },
                {
                    "sent": "Victor said quality.",
                    "label": 0
                },
                {
                    "sent": "Most of you know.",
                    "label": 0
                },
                {
                    "sent": "In this case, the image content is represented by port Cities.",
                    "label": 1
                },
                {
                    "sent": "We're going to describe several patches, actually 2000 of patches in the image, each individual patches including into a vector, and then the image representation is a set of vectors.",
                    "label": 0
                },
                {
                    "sent": "To say if two images are.",
                    "label": 1
                },
                {
                    "sent": "Should be matched with rely on the individual matching of the local descriptors.",
                    "label": 0
                },
                {
                    "sent": "So in order to extract its descriptors, we first needed.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Victor Sow detector tried to find reputable regions.",
                    "label": 0
                },
                {
                    "sent": "That is, some regions that could be fine consistently, even under different information such as change of viewpoint and so on.",
                    "label": 0
                },
                {
                    "sent": "So the most popular one I would say, or the Mercier.",
                    "label": 0
                },
                {
                    "sent": "So for wide baseline matching.",
                    "label": 0
                },
                {
                    "sent": "So difference of Goshen by the video just introduced with the descriptor on the Sienna fine descriptor.",
                    "label": 0
                },
                {
                    "sent": "Baby killer chicks.",
                    "label": 0
                },
                {
                    "sent": "On those days in your new interest for don't descriptor, that is, we are not going to detect some specific regions which are repeatable.",
                    "label": 0
                },
                {
                    "sent": "We just sample many patches.",
                    "label": 0
                },
                {
                    "sent": "You don't sway from an image.",
                    "label": 0
                },
                {
                    "sent": "It said 10,000 and more patches from an image in classification.",
                    "label": 0
                },
                {
                    "sent": "This is actually what gives the best results and I will also mention easy and that is also the case if you consider very large scale image retrieval.",
                    "label": 0
                },
                {
                    "sent": "It is also very good to use don't descriptor given that we consider some specific image search system that will detail in this tutorial, just to say that.",
                    "label": 0
                },
                {
                    "sent": "You can work.",
                    "label": 0
                },
                {
                    "sent": "You can rely on description without any detector and get very good result.",
                    "label": 0
                },
                {
                    "sent": "Event for image search.",
                    "label": 0
                },
                {
                    "sent": "So once we have extra.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some patches who either in the dance way as are using regions of interest you have to describe it, of course normalization.",
                    "label": 0
                },
                {
                    "sent": "So basically what is done usually is orientation normalization, aurify normalization, photometric normalization, which is actually done usually by some normalization on the descriptor.",
                    "label": 0
                },
                {
                    "sent": "In the case of the sea descriptor, the most popular ones shift.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to detail it just to say that it is specialized on coding of the energy.",
                    "label": 0
                },
                {
                    "sent": "Of the graduates.",
                    "label": 0
                },
                {
                    "sent": "In a Patch.",
                    "label": 0
                },
                {
                    "sent": "Is only thing I will set you mention on the seat because I guess that most of you know this descriptor is that there are some very simple improvement to get like Componentwise Pirollo proposal currently this year by Jane on Hun, Jellick from Oxford on just by Apley, applying square rooting on the component you get some sleep improvement, both specification, but also for image search.",
                    "label": 0
                },
                {
                    "sent": "On the wheel.",
                    "label": 0
                },
                {
                    "sent": "Speak about this problem also in user context, just to say that I believe that this is a general principle that should be applied using this power normalization because we have some strong first evidence is that it is good for the benchmark, but also because we have some indirect dialing underlying process that explained why we should do the power law.",
                    "label": 0
                },
                {
                    "sent": "On there is many derivative from these descriptors, so more efficient, more compact or integrating color which is not the case of of the sifter.",
                    "label": 1
                },
                {
                    "sent": "Two to propose a different trade off with respect to efficiency, capacity and so on.",
                    "label": 0
                },
                {
                    "sent": "I won't mention one thing about the work of window on Brown, which is learning local descriptors.",
                    "label": 0
                },
                {
                    "sent": "I think this work is really insightful about the fact that we should use learning stage event for unsupervised or technique like image search.",
                    "label": 0
                },
                {
                    "sent": "At least people mostly think that made search by content is unsupervised scenario.",
                    "label": 0
                },
                {
                    "sent": "But in many cases.",
                    "label": 0
                },
                {
                    "sent": "On this work was one of the first to show it, but now it is also more and more attractive, with seven said buzzword, we should use learning to supervised learning to improve task which is not supervised.",
                    "label": 0
                },
                {
                    "sent": "Now this is a general tone I think in the image search now.",
                    "label": 0
                },
                {
                    "sent": "So once we have local descriptor instructed, we have the position we can.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Super from geometrical verification to find some consistent way of mapping so descriptor match basins.",
                    "label": 0
                },
                {
                    "sent": "Mathematical representation with another set of descriptor.",
                    "label": 0
                },
                {
                    "sent": "Off another image on social media, we can filter out this.",
                    "label": 1
                },
                {
                    "sent": "Matches which are not consistent with the global transformation.",
                    "label": 0
                },
                {
                    "sent": "This is very precise.",
                    "label": 0
                },
                {
                    "sent": "This is usually used as the last step of image matching, but this is not scalable at all.",
                    "label": 1
                },
                {
                    "sent": "I shouldn't say that because in next see there's a paper by Stephen News from Google that perform large scale geometrical matching on the millions of images even more.",
                    "label": 0
                },
                {
                    "sent": "Actually using some specific optimization, but it is usually so that this symmetrical verification is very costly.",
                    "label": 0
                },
                {
                    "sent": "So just invite you to look at the papers to the news that SV to see where the.",
                    "label": 0
                },
                {
                    "sent": "OK, on the tool for.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So image description.",
                    "label": 0
                },
                {
                    "sent": "Now I mostly assume that we have some local descriptors extracted from the images of the data set and I'm going to work on what we do is local descriptors that we have extracted.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We suggest matching, which is also required by the geometrical verification.",
                    "label": 0
                },
                {
                    "sent": "But even without that this is a problem by itself is that we have a big complexity issue.",
                    "label": 0
                },
                {
                    "sent": "So let's assume that we have an image described by, let's say 1000 descriptors.",
                    "label": 1
                },
                {
                    "sent": "Probably more would be better, but we this is used for the sake of analysis and we consider.",
                    "label": 0
                },
                {
                    "sent": "Large Kayla.",
                    "label": 0
                },
                {
                    "sent": "Data set of women images for me.",
                    "label": 0
                },
                {
                    "sent": "Large scale is about 1,000,000 to 10,000,000.",
                    "label": 0
                },
                {
                    "sent": "On larger is bigger than 100 millions.",
                    "label": 1
                },
                {
                    "sent": "So we have to index to put memory or to store out to find some way or focus on thing 1 billion descriptors.",
                    "label": 0
                },
                {
                    "sent": "N * M If you consider regular see descriptors representing each by 128 dimension on coded with one diaper component, you have to store 128 gigabyte of descriptors, which might fit in the big server.",
                    "label": 0
                },
                {
                    "sent": "But if you go to a bit more images, it will not fit or you are very rich.",
                    "label": 0
                },
                {
                    "sent": "Two very big servers.",
                    "label": 0
                },
                {
                    "sent": "On the problem is that the search requires M square and the elementary operation.",
                    "label": 0
                },
                {
                    "sent": "So M Square is a number of descriptor preimage.",
                    "label": 0
                },
                {
                    "sent": "On the square comes of that you have to match everybody with everybody.",
                    "label": 0
                },
                {
                    "sent": "So every descriptor allows 1000 against every descriptor among the 1000.",
                    "label": 0
                },
                {
                    "sent": "For the database side for each image times dimensionality of the descriptors.",
                    "label": 1
                },
                {
                    "sent": "So this is computationally computationally not tractable.",
                    "label": 0
                },
                {
                    "sent": "Actually, because of the quadratic term and square.",
                    "label": 0
                },
                {
                    "sent": "So I will come on this matching patterns problem associated with this matching part and also is a solution in a specific section of this tutorial.",
                    "label": 0
                },
                {
                    "sent": "But first I want to say that this problem with the direct matching has been.",
                    "label": 0
                },
                {
                    "sent": "Partially served with a bag of word back.",
                    "label": 0
                },
                {
                    "sent": "Visual world representation.",
                    "label": 0
                },
                {
                    "sent": "So it was first introduced actually.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the context of textural classification by Malikan.",
                    "label": 0
                },
                {
                    "sent": "But the most impactful paper was probably the view Google Paper by civic and so man, because they really show shown that it is possible to mimic complete mimic text retrieval system which were already very efficient at the time to get reasonable result.",
                    "label": 1
                },
                {
                    "sent": "Actually very good result at the time.",
                    "label": 0
                },
                {
                    "sent": "Une image search system.",
                    "label": 0
                },
                {
                    "sent": "On the obtain efficiency.",
                    "label": 0
                },
                {
                    "sent": "An accident recognition performance.",
                    "label": 0
                },
                {
                    "sent": "Concurrent concurrently dance on our proposal visualization with bag of key points, which actually is the same ID but more focused on classification.",
                    "label": 1
                },
                {
                    "sent": "So if we want to compare them to paper, both of them are based on the same ID.",
                    "label": 0
                },
                {
                    "sent": "That is, we're going to represent a set of local descriptors and by only one vector.",
                    "label": 1
                },
                {
                    "sent": "But this one is more focused on how you put it into a system.",
                    "label": 0
                },
                {
                    "sent": "For efficiency using inverted file structure while the second one was proposing this to get vector representation that can be fitted to SCM super sector machine for instance because it is very convenient to have only one vector per image.",
                    "label": 0
                },
                {
                    "sent": "On the good thing with this bag of words representation is that it inherits completely the invariants of the descriptors, not does not enter, it's completely.",
                    "label": 0
                },
                {
                    "sent": "The discriminative power, but at least it generates the invariants.",
                    "label": 0
                },
                {
                    "sent": "How it is?",
                    "label": 0
                },
                {
                    "sent": "I know it works, so the idea.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Put the images into words, namely visual words, so I'll descriptors can assume that they lie in dimensional space.",
                    "label": 1
                },
                {
                    "sent": "Let's say 138 dimensions for the sift on this space is continuous, which is more or less true.",
                    "label": 0
                },
                {
                    "sent": "But let's assume this.",
                    "label": 1
                },
                {
                    "sent": "So we need to define what is a visual world.",
                    "label": 0
                },
                {
                    "sent": "And she's done, but you can't iser container, which is a function that Maps a continuous.",
                    "label": 0
                },
                {
                    "sent": "Victor 2 contest index.",
                    "label": 0
                },
                {
                    "sent": "If you need infinite set.",
                    "label": 0
                },
                {
                    "sent": "It may be also infinite, but this script.",
                    "label": 0
                },
                {
                    "sent": "So in this case, in the case of video, Google accuser contains are this.",
                    "label": 0
                },
                {
                    "sent": "Mapping function.",
                    "label": 0
                },
                {
                    "sent": "Is a chemist container which actually is also like contest which is very good.",
                    "label": 0
                },
                {
                    "sent": "We know that this container is very good with respect to minimizing the squared error or construction.",
                    "label": 0
                },
                {
                    "sent": "So the set of visual words define visual vocabulary.",
                    "label": 0
                },
                {
                    "sent": "Each user word correspond to our production values container.",
                    "label": 0
                },
                {
                    "sent": "On your sign descriptor based on nearest neighbor based on the nearest neighbor rules.",
                    "label": 0
                },
                {
                    "sent": "In this case finding the one which means the equation distance in the code book.",
                    "label": 0
                },
                {
                    "sent": "So I want to mention that conversation is glossy, we cannot go back from this finished space.",
                    "label": 0
                },
                {
                    "sent": "Axis of O2 to descriptor we have.",
                    "label": 0
                },
                {
                    "sent": "We have lost something and actually we have lost a lot.",
                    "label": 0
                },
                {
                    "sent": "But it's very compact.",
                    "label": 0
                },
                {
                    "sent": "Typically we just have to represent the regarding of two of the number of possible indexes, which is typically 2 to 4 bytes for descriptor.",
                    "label": 0
                },
                {
                    "sent": "So now if you look at the complete processing chain.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you Google.",
                    "label": 0
                },
                {
                    "sent": "We first have this image from which which we extract some local descriptors so we have detector or this menu option and we can use detector as well and we describe this Patch then we can test all the descriptors, only compute vector of frequencies.",
                    "label": 1
                },
                {
                    "sent": "They are usually waited by inverse document frequency just to give more importance to the visual words, which are rare.",
                    "label": 0
                },
                {
                    "sent": "And this gives us the idea vectors.",
                    "label": 0
                },
                {
                    "sent": "When you have a query, we have to search for similar vectors and this is done using inverted file and I will come back on this just after which is an efficient indexing structure for sparse vectors.",
                    "label": 1
                },
                {
                    "sent": "Optionally, we can use some ranking, so thinking now is very used with Jean metrical verification, but actually even in the old cubic paper it was proposed as secondary stage to filter out some images which are not correct based on a better representation, but at the time it was without geometry.",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go to the injected file.",
                    "label": 0
                },
                {
                    "sent": "Then justified is a set of list.",
                    "label": 0
                },
                {
                    "sent": "Which purpose is to store the sparse vector components?",
                    "label": 1
                },
                {
                    "sent": "On this used to compute the cosine similarity typically between one vector and input on the set of vector on output.",
                    "label": 1
                },
                {
                    "sent": "So actually correspond to the implementation of a sparse matrix times plus Victor multiplication.",
                    "label": 0
                },
                {
                    "sent": "Another University file implements in application.",
                    "label": 0
                },
                {
                    "sent": "The fact is that it can be extended to other measures.",
                    "label": 0
                },
                {
                    "sent": "It is not restricted to L2 cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "It can be used for any LP norm on actually even a wider class of function like a square for instance.",
                    "label": 0
                },
                {
                    "sent": "On this was shown by Mr instead in use because the preferred to use L1 norm for comparison around distance for comparison of Lego Foot, because in that case it was providing better results.",
                    "label": 0
                },
                {
                    "sent": "Mutation of injected furniture possible maybe more, but this one are very popular.",
                    "label": 0
                },
                {
                    "sent": "So the most popular one probably is just to store given a set of words.",
                    "label": 0
                },
                {
                    "sent": "So that is a different component of the vector to be indexed.",
                    "label": 0
                },
                {
                    "sent": "This will work now OK, and we're going to store in for the database images all the ID of the images identifier on the frequency.",
                    "label": 0
                },
                {
                    "sent": "Of the visual world in this image.",
                    "label": 0
                },
                {
                    "sent": "An interactive presentation is just too only stores IDs on order to know how many occurrences of the work we have, we just toss the ID several times.",
                    "label": 0
                },
                {
                    "sent": "This may appear as inefficient.",
                    "label": 0
                },
                {
                    "sent": "In practice, the most implementation or almost equivalent with respect to the memory usage.",
                    "label": 1
                },
                {
                    "sent": "There's a big advantage in this.",
                    "label": 0
                },
                {
                    "sent": "Implementation, which is that you have one ID per descriptor, which means that you can actually store some additional information per descriptor, and this is very convenient to go to some extension of the presentation in this representation when you have a frequency, it is already emerged.",
                    "label": 0
                },
                {
                    "sent": "We've already performing aggregation.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On this is very difficult to go back to the individual descriptors.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and the complexity is approximated by the number of items and I will come back on this point after so.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to skip this slide.",
                    "label": 0
                },
                {
                    "sent": "Which was only there to say you should use the implementation of the injected files that store one ID per descriptor.",
                    "label": 0
                },
                {
                    "sent": "It is much more convenient for many extensions, so if we go ahead to the complexity of inverted file first, we can model the probability to assign a descriptor.",
                    "label": 0
                },
                {
                    "sent": "Given visual world I on.",
                    "label": 0
                },
                {
                    "sent": "IPI.",
                    "label": 0
                },
                {
                    "sent": "N is the number of images in database on M is let's say the average number of descriptor per image.",
                    "label": 0
                },
                {
                    "sent": "So the expected length of list I is basically N * N time P. So M already includes expectation.",
                    "label": 1
                },
                {
                    "sent": "So expected curse is quadratic in the number of.",
                    "label": 0
                },
                {
                    "sent": "This contemporary imagine average, so we have the kill completely kills them square factor I mentioned before, but the fact is that it is compensated by the fact that we have a very low constant.",
                    "label": 0
                },
                {
                    "sent": "And then you can see that we have this pie squares to Pierce.",
                    "label": 0
                },
                {
                    "sent": "Which is very important to consider, because if you have a cluster of very different sizes, it will have a big impact.",
                    "label": 0
                },
                {
                    "sent": "The big values of Pi will negatively impact the cost of this was first mentioned by mistranslated Newsome unformalized afterward and as the balance factor.",
                    "label": 0
                },
                {
                    "sent": "On this measure, this measure measures divergent from the optimal uniform distribution, which is the one that gives you the best possible cost for a given number of descriptor on a given vocabulary size.",
                    "label": 0
                },
                {
                    "sent": "I have to mention that some strategy have been tested and I have tested the few ones to balance the cluster, but I really have to say that this balancing trying to get more uniform distribution for PII, usually impacts negatively the quality of the search.",
                    "label": 0
                },
                {
                    "sent": "So you gain in efficiency, but you losing quality a bit.",
                    "label": 0
                },
                {
                    "sent": "Just one thing I didn't say well.",
                    "label": 0
                },
                {
                    "sent": "One thing when I presented this complexity, but this complexity is under the assumption that the Pi.",
                    "label": 0
                },
                {
                    "sent": "Is the same for the database images and for the query images.",
                    "label": 0
                },
                {
                    "sent": "Before I presented the study for the test set for which we know that there is a different quality between the database of reference images on the queries showed by mobile devices.",
                    "label": 0
                },
                {
                    "sent": "So in this case it may not be true that Pi is equal on query on database side, so you just have to take this formula we scare.",
                    "label": 0
                },
                {
                    "sent": "OK, injustice file is not sub linear.",
                    "label": 0
                },
                {
                    "sent": "It is very efficient but it is not Sabrina.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is linear in the number of images.",
                    "label": 1
                },
                {
                    "sent": "With this constant is very small because it is sparse multiplication.",
                    "label": 0
                },
                {
                    "sent": "So typically 001 is a constant.",
                    "label": 0
                },
                {
                    "sent": "The memory usage for let's say 1,000,000 images is about four to 8 bytes per descriptors.",
                    "label": 0
                },
                {
                    "sent": "Let's say 8 gigabytes.",
                    "label": 0
                },
                {
                    "sent": "So you can store only 1,000,000 images on one regular server.",
                    "label": 0
                },
                {
                    "sent": "Is this can be compressed using ingested file compression, so this one was first proposed in text retrieval, but only to some extent because in the compression is lossless compression on you, you're bounded by the lower limit of entropy of the indexes or difference of index.",
                    "label": 0
                },
                {
                    "sent": "Usually it is implemented using Delta Kodera followed by some entropic code like off man.",
                    "label": 0
                },
                {
                    "sent": "Some user optimized codes.",
                    "label": 0
                },
                {
                    "sent": "So how to boost efficiency?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first the first Mr that you might choose is to use consistent using stop words that is.",
                    "label": 0
                },
                {
                    "sent": "Try to remove what in text would be informative words.",
                    "label": 0
                },
                {
                    "sent": "So in text level, if you have words like the a very short words, there are quite informative.",
                    "label": 0
                },
                {
                    "sent": "The provide some description of the content itself, so they usually remove it in text retrieval to 1st get better results, but also because it has a big impact on efficiency.",
                    "label": 1
                },
                {
                    "sent": "If you present web page.",
                    "label": 0
                },
                {
                    "sent": "Can you stop all the web pages that contain the you you're going to store all the webpages the world of the Internet, so you cannot do that.",
                    "label": 0
                },
                {
                    "sent": "You're going to discard this words.",
                    "label": 1
                },
                {
                    "sent": "In image search, this amounts to removing the most frequent ones because we do not have exactly the equivalent of informative words.",
                    "label": 0
                },
                {
                    "sent": "In practice, most frequently or less informative, as shown by the IDF weighting, but they're not completely informative on.",
                    "label": 0
                },
                {
                    "sent": "From my experience, you always lose a bit.",
                    "label": 0
                },
                {
                    "sent": "Not that much, but a bit if you filter some.",
                    "label": 0
                },
                {
                    "sent": "Some of the most frequent, if you're well.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't seem interested in the summation there.",
                    "label": 0
                },
                {
                    "sent": "When you send the Pi from one to care, we are cases.",
                    "label": 0
                },
                {
                    "sent": "The number of Visual World Cookbook size you're going to start to serve the pie.",
                    "label": 0
                },
                {
                    "sent": "Starting with X + 1.",
                    "label": 0
                },
                {
                    "sent": "Excel, word, and assuming that the first one or the other most frequent, so you're going to remove the tail of the distribution which contain most of the visual world.",
                    "label": 0
                },
                {
                    "sent": "So you have a very good impact and efficiency filter menus words.",
                    "label": 0
                },
                {
                    "sent": "So in other ways too.",
                    "label": 0
                },
                {
                    "sent": "Great to on.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to get more efficiency with injected files consist in using large vocabularies, so a link in text in text read it as a choice.",
                    "label": 1
                },
                {
                    "sent": "We have the alphabet of the of fixed by the language, English language, French language, whatever you have to use this word, because these are the.",
                    "label": 0
                },
                {
                    "sent": "This is a language you cannot decide.",
                    "label": 0
                },
                {
                    "sent": "In image search there was an artificial operation to convert some features into an alphabet of visual elements.",
                    "label": 0
                },
                {
                    "sent": "Which means that we can decide the size of the alphabet.",
                    "label": 1
                },
                {
                    "sent": "We just have to change the value of K. So you can.",
                    "label": 1
                },
                {
                    "sent": "You can use it to optimize some different tradeoff between search quality.",
                    "label": 0
                },
                {
                    "sent": "On efficiency.",
                    "label": 0
                },
                {
                    "sent": "Which we know is that at query time owns the descriptor quantized and the complexity is linear in 1 / K, where K is a size.",
                    "label": 0
                },
                {
                    "sent": "So you should use larger Cabri to get less matching results on.",
                    "label": 0
                },
                {
                    "sent": "This can be efficiently done using a very large dictionary like the one proposed by instance TV news.",
                    "label": 1
                },
                {
                    "sent": "So lots of people prefer for this because of evil efficient.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in the same time you should not forget that you have increased assignment costs, that is the quantization operation for the query does not depend on the.",
                    "label": 0
                },
                {
                    "sent": "The size of the test set.",
                    "label": 0
                },
                {
                    "sent": "It is for the query only, but has to be done.",
                    "label": 0
                },
                {
                    "sent": "On a query term, if you look at the complexity.",
                    "label": 0
                },
                {
                    "sent": "Of quantization of descriptor plus query into exotic file you have something of the Form C1 Timescape received 2 / K. This part is a quantization cost, assuming a flat Kamins quantizer, this one is query is the cost associated with querying into inverted file.",
                    "label": 0
                },
                {
                    "sent": "So you have some kind of optimum that you could fix two optimizer costs.",
                    "label": 0
                },
                {
                    "sent": "But in practice, we can use some better contessa to reduce this cost.",
                    "label": 0
                },
                {
                    "sent": "So the first thing you could do is just to use like it is on compression.",
                    "label": 0
                },
                {
                    "sent": "For instance, structure contains a supercontainer.",
                    "label": 0
                },
                {
                    "sent": "You have some algebraic operation to perform assignment to the visual world, the quantization.",
                    "label": 0
                },
                {
                    "sent": "So you can use a grid.",
                    "label": 0
                },
                {
                    "sent": "Lattice contains are, but it was shown later bye Phil Burns that in the context of image searches gives a pretty poor results.",
                    "label": 0
                },
                {
                    "sent": "Also you get some inverted list which are very unbalanced if user structure contains are you have something like this.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to explain.",
                    "label": 0
                },
                {
                    "sent": "There you have the cell population, that is the amount of descriptor contains 2 given visual world and I ordered the cell population by decreasing number.",
                    "label": 0
                },
                {
                    "sent": "Of cell population.",
                    "label": 0
                },
                {
                    "sent": "So there I have Visual World won the most frequent too and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is for K means you have relatively balanced.",
                    "label": 0
                },
                {
                    "sent": "Distribution so completely.",
                    "label": 0
                },
                {
                    "sent": "So this can be measured by the imbalance factor, but if use structure contains are, you can do whatever you want.",
                    "label": 0
                },
                {
                    "sent": "You always sorry you will always have this kind of distribution of the cell population, which means that you will have some very big pie on.",
                    "label": 0
                },
                {
                    "sent": "For many visual words.",
                    "label": 0
                },
                {
                    "sent": "On then very is small, some cells with some inverted list with very small population and she's not very good for efficiency, obviously.",
                    "label": 0
                },
                {
                    "sent": "So you're you cannot.",
                    "label": 0
                },
                {
                    "sent": "It's not possible to adjust a compromise are using.",
                    "label": 0
                },
                {
                    "sent": "This structure contains a.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When the very good way to learn a very large vocabulary is also to have a very low assignment.",
                    "label": 0
                },
                {
                    "sent": "Cursed quantization cost is to use a radical campaigns like the one proposed by instance even use basically what you do is you make a tree of commands you have a first year, you're going to contest your descriptor by assigning it to the closest.",
                    "label": 0
                },
                {
                    "sent": "Century is the first year, so this is a limited set.",
                    "label": 0
                },
                {
                    "sent": "In this case it is only three on the second layer you're going to use a cabins which is dedicated to this first region of the space, and then you're going to sign into this particular world you have made in total 3 + 3 comparison.",
                    "label": 0
                },
                {
                    "sent": "So Jason complexity is greatly reduced because of this power 1 / H, which actually kill the complexity of the assignment, so this is very fast, but we lose.",
                    "label": 0
                },
                {
                    "sent": "You have shown these people from Oxford that it is better to use an approximate Cummins instead of your actual Cummins.",
                    "label": 0
                },
                {
                    "sent": "So the ones they used and we come back and eat afterwards amounts to using parallel structure and to make the search on just to replace in the ascendant step of the cabins on at the same time also.",
                    "label": 0
                },
                {
                    "sent": "As I said, known by approximate search technique.",
                    "label": 0
                },
                {
                    "sent": "OK, come back to the front.",
                    "label": 0
                },
                {
                    "sent": "There is another interpretation of.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They go through the representation which is actually or dimension is in the 1st paper by civic and some man which amount to say that these are words or just view of mine.",
                    "label": 0
                },
                {
                    "sent": "There is no trivial word.",
                    "label": 0
                },
                {
                    "sent": "This is a continuous space and we have just artificially cut it into parts.",
                    "label": 0
                },
                {
                    "sent": "So bigger fraud can be seen as approximate nearest neighbor search matching voting scheme.",
                    "label": 0
                },
                {
                    "sent": "On this amounts to defining the neighborhood of descriptor.",
                    "label": 1
                },
                {
                    "sent": "He's a future space, as Victor Witcher Cook on ties in the same cell.",
                    "label": 0
                },
                {
                    "sent": "So basically, if you have a descriptor there of an image, so the red image, we say that all this green descriptor of the green image or matching descriptors.",
                    "label": 0
                },
                {
                    "sent": "The problem with this interpretation.",
                    "label": 0
                },
                {
                    "sent": "So first we can cast completely the bag of representation into this voting system, getting something which is equivalent given that the bag of words are compared with cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "But supremacy as we can see an artifact of the bag of fruit comparison, which is that if you assume two descriptor on query side for the, for instance red image onscreen descriptor on the database side, then you're going to count 6 votes 12333.",
                    "label": 0
                },
                {
                    "sent": "456 in the matrix vector multiplication.",
                    "label": 0
                },
                {
                    "sent": "This is because we have 3 * 2 in the frequency multiplied by some based on constant.",
                    "label": 0
                },
                {
                    "sent": "The contribution to the cosine similarity is too big because it is not linear in the number of true matches physical matches.",
                    "label": 1
                },
                {
                    "sent": "On to get.",
                    "label": 0
                },
                {
                    "sent": "So impossible solution if you could do that would be to say we're not going to count more than the minimum of the two.",
                    "label": 0
                },
                {
                    "sent": "So let's say you are going to count 2 because on one side we have only two, so this strategy was called multiple match removal, so you're going to count the minimums that you can physically have in reality.",
                    "label": 0
                },
                {
                    "sent": "But a better strategy simply amounts to take the square root of the frequency, right?",
                    "label": 1
                },
                {
                    "sent": "OK, you take componentwise square rooting of the bag of pre order.",
                    "label": 0
                },
                {
                    "sent": "So if you have two descriptor you take sqrt 2, which means that if you have three on three descriptor for database on query sqrt 3 * sqrt 3 would be 3 on is linear in the number of matches.",
                    "label": 0
                },
                {
                    "sent": "So this strategy is a way to compensate for the artifact of the voting system that does not be greater than the different matches.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this slide is just to show compromise between.",
                    "label": 0
                },
                {
                    "sent": "Vocabulary of let's say small size 20,000 so 20,000 would be a lot actually for classification, but make sure it is smaller.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On this is a larger vocabulary vocabulary so that you can see that in the 1st.",
                    "label": 0
                },
                {
                    "sent": "In the first case, for the smaller vocabulary, you have many incorrect matches like this.",
                    "label": 0
                },
                {
                    "sent": "Which are generated because this.",
                    "label": 0
                },
                {
                    "sent": "Descriptor is simply cool.",
                    "label": 0
                },
                {
                    "sent": "Contains with this one, but visually they are not that close actually but still can't eyes because vocabulary is not fine enough.",
                    "label": 0
                },
                {
                    "sent": "But now if you go to those are you do not have any incorrect match, but at the same time you lose a lot of correct match.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this area for instance, this match is correct.",
                    "label": 0
                },
                {
                    "sent": "How is miss there?",
                    "label": 0
                },
                {
                    "sent": "And you have many miss like this in the boat also.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the reason is that for me, the intrinsic matching method, which is performed by bag of fraud is week is week on.",
                    "label": 1
                },
                {
                    "sent": "There is no good compromise between small vocabulary on large vocabulary, it is just because the definition of the neighborhood is not good enough.",
                    "label": 0
                },
                {
                    "sent": "Defining neighborhood as a set of contais descriptor.",
                    "label": 0
                },
                {
                    "sent": "Whatever size, you cannot attain the best tradeoff.",
                    "label": 1
                },
                {
                    "sent": "So for small visual dictionary small too small, you will have too many fast matches on.",
                    "label": 0
                },
                {
                    "sent": "For large ones you will have true matches which will be will be missed.",
                    "label": 0
                },
                {
                    "sent": "So there I have collected some patches.",
                    "label": 0
                },
                {
                    "sent": "Assigned to the same user word for vocabulary of size 1000, so small vocabulary or may have done the same thing for a large vocabulary, so each time correspond to the same visual world.",
                    "label": 0
                },
                {
                    "sent": "So in the case of the larger vocabulary, we can see that we match pretty close patches.",
                    "label": 0
                },
                {
                    "sent": "There is not so much variation, but which in some sense means that OK, you matching is precise, but in the same time you cannot absorb alteration.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you will become Tyson assigned to another visual world on here.",
                    "label": 1
                },
                {
                    "sent": "In contrast we can match very different patches like these two words.",
                    "label": 0
                },
                {
                    "sent": "For instance, in my opinion are quite different on should be matched on their match because of context.",
                    "label": 0
                },
                {
                    "sent": "So partial solution to this announced to performing multiple or soft assignment.",
                    "label": 0
                },
                {
                    "sent": "In Samsung amounts to re centering the assignment of the descriptor to create structure around which is more features dependent, and so you're going to assign descriptor not too is closer.",
                    "label": 0
                },
                {
                    "sent": "Some trade between several ones, optionally with some weights.",
                    "label": 0
                },
                {
                    "sent": "But these are some impacts of the complexity of memory because you have to store multiple times the same feature, so that's why it's better to do it only on query side as advocated by 100, which to save some memory.",
                    "label": 0
                },
                {
                    "sent": "OK, just to mention one thing, to prepare a support and matching efficient matching, this is what you get with a small vocabulary and this is what you get with a better matching method.",
                    "label": 0
                },
                {
                    "sent": "So in this case you can see that you can just remove the outliers on there.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Metal Fication is purely based on the matching the descriptor.",
                    "label": 0
                },
                {
                    "sent": "This is to compare with the.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Roger, who?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He as you can see.",
                    "label": 0
                },
                {
                    "sent": "It is possible to.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trash without introducing.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, yes, which is the case in this larger vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now it's good to geometrical verification.",
                    "label": 0
                },
                {
                    "sent": "As I mention, this is a very strong way to match images, especially for rigid objects.",
                    "label": 0
                },
                {
                    "sent": "So we have some models on the we know that zooming through the point should be transformed, so we perfectly know automatch.",
                    "label": 0
                },
                {
                    "sent": "Sometimes we can take some approximation, but basically it is the last step which is performed after bag over system.",
                    "label": 0
                },
                {
                    "sent": "So you typically go for system.",
                    "label": 0
                },
                {
                    "sent": "You first order that says one year images based on their score for the back of the presentation on the short list you're going to perform some geometrical verification, which is going to remove some.",
                    "label": 1
                },
                {
                    "sent": "Outliers.",
                    "label": 1
                },
                {
                    "sent": "This is very costly and it's typically applied to 100 to 1000 pages, so I mentioned that now apparently it is possible to be significantly more efficient, but let's say that it is still very inefficient.",
                    "label": 0
                },
                {
                    "sent": "If you go to very large data set, the problem is that.",
                    "label": 0
                },
                {
                    "sent": "The probability that your image your correct image is wrong in the shortlist becomes smaller on smaller.",
                    "label": 0
                },
                {
                    "sent": "If you assume that the size of shortlist is fixed, let's say 100 and you increase the test set, you're going to get lower and lower probability, shortlist the correct images on this show in there.",
                    "label": 1
                },
                {
                    "sent": "So there I increase the data set size.",
                    "label": 0
                },
                {
                    "sent": "When I consider the probability to rank the images, the correct ones in the short list.",
                    "label": 0
                },
                {
                    "sent": "Considering a short list of 20 images, one unread on 1000 images.",
                    "label": 1
                },
                {
                    "sent": "So for the typical shortest of 100 images, you can see the performance drop.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "You're able to run OK almost 80% of images out of 10,000 is the first 100.",
                    "label": 0
                },
                {
                    "sent": "This is the first person, but wrong them in the human.",
                    "label": 0
                },
                {
                    "sent": "Only consider one person of one person.",
                    "label": 0
                },
                {
                    "sent": "So this case where you have shortness of wonder images on Wendy images, you're going to lose Alpha, you're correct images, so medical verification as a post processing stage is not the solution for large scale image search.",
                    "label": 0
                },
                {
                    "sent": "If you are going to consider.",
                    "label": 0
                },
                {
                    "sent": "Very large data set.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical example, particular one I use.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Undergo photo presentation.",
                    "label": 0
                },
                {
                    "sent": "I have a query there on a consider images matching images annotated basic truth by order of increasing difficulty.",
                    "label": 0
                },
                {
                    "sent": "So this one is very close.",
                    "label": 0
                },
                {
                    "sent": "You do agree that this images we can recognize the this is the same place even easier on there we consider an image which is.",
                    "label": 0
                },
                {
                    "sent": "Also the same place there you might recognize this area.",
                    "label": 0
                },
                {
                    "sent": "It's the same as this.",
                    "label": 0
                },
                {
                    "sent": "But you have a very strong change of viewpoint.",
                    "label": 0
                },
                {
                    "sent": "On that is even more difficult.",
                    "label": 0
                },
                {
                    "sent": "On the back of a full presentation, of course, for that real image it is wrong in second position, and I think the first was also correct.",
                    "label": 0
                },
                {
                    "sent": "It was a false positive, but this images or so this one is wrong in position 6006 thousand is very good.",
                    "label": 0
                },
                {
                    "sent": "Actually it is the first person the first person is until 10,000 images out of 1 union.",
                    "label": 0
                },
                {
                    "sent": "But this is not enough to be verified by the special verification.",
                    "label": 0
                },
                {
                    "sent": "On this is even worse.",
                    "label": 0
                },
                {
                    "sent": "This is wrong in the first two 5%, but of course it will not be checked by the medical filter.",
                    "label": 0
                },
                {
                    "sent": "So my message is basically you need to improve the first system, the one which is going to create a short list before applying geometrical verification.",
                    "label": 0
                },
                {
                    "sent": "You cannot rely on your simple verification on expect it to be able to verify.",
                    "label": 0
                },
                {
                    "sent": "10,000 images.",
                    "label": 0
                },
                {
                    "sent": "So about Jimmy classification large.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a lot of activity.",
                    "label": 0
                },
                {
                    "sent": "Actually, so the people that tried to incorporate the geometry in the very first retrieval stage.",
                    "label": 0
                },
                {
                    "sent": "So we present briefly after the geometry consistency that we introduced in 2008.",
                    "label": 0
                },
                {
                    "sent": "I want to mention but will not have the time to detail the hemoglobin ash, which I think is a very interesting.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because it really scale to extremely large data set on is able to find some very small object.",
                    "label": 0
                },
                {
                    "sent": "Of course it has a lot of problem as well.",
                    "label": 0
                },
                {
                    "sent": "That is, you lose you have not a very good recall are but the same time for some queries difficult queries with few descriptor but specific ones.",
                    "label": 0
                },
                {
                    "sent": "It works pretty well.",
                    "label": 0
                },
                {
                    "sent": "There's also this paper bending features which actually uncovered some information of neighborhood.",
                    "label": 0
                },
                {
                    "sent": "Jointly with descriptor.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned before that I like the implementation of the inverted file that store and ID for each individual descriptor.",
                    "label": 1
                },
                {
                    "sent": "And basically you do that.",
                    "label": 0
                },
                {
                    "sent": "You can have any kind of information on.",
                    "label": 0
                },
                {
                    "sent": "In particular you can add some information about the neighborhood over the descriptor, which is also.",
                    "label": 0
                },
                {
                    "sent": "We also incorporate some additional information in the week geometry consistently filter filter as well.",
                    "label": 0
                },
                {
                    "sent": "Snicket's ocation this kind of technique that try to integrate the geometry are not really useful because they do not correspond to vector model that could be used to feed regime.",
                    "label": 1
                },
                {
                    "sent": "That is why why is the most popular technique remains specialty and matching by lesbian Dick which simply amounts in dividing the images in several predefined regions, which of course that does not give a lot of invariants too.",
                    "label": 0
                },
                {
                    "sent": "Just scaling on on on station and so on.",
                    "label": 1
                },
                {
                    "sent": "But in practice it is very good on benchmarks and classification benchmark so.",
                    "label": 0
                },
                {
                    "sent": "It is not an image search benchmark where you are more focused on Critter creeping on this kind of transformation depends on the task actually.",
                    "label": 0
                },
                {
                    "sent": "So we geometry consistently see what it is.",
                    "label": 0
                },
                {
                    "sent": "Basically it is off transform, so this tries.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To estimate in a reliable manner some transformation, some quantities, the key WGC is that it is going to separately estimate the different quantities associated with magical transformation.",
                    "label": 1
                },
                {
                    "sent": "In this case rotation, lock, scale, or estimated separately, we want to find a vector model which would correspond to a true geometrical transformation.",
                    "label": 0
                },
                {
                    "sent": "We do not want.",
                    "label": 0
                },
                {
                    "sent": "Estimate social conservation as a whole.",
                    "label": 0
                },
                {
                    "sent": "We just want to estimate some specific quantities WHI, because objective is not to find the transformation is objective is just to detect some outliers based.",
                    "label": 0
                },
                {
                    "sent": "So typically what is done is that we have to store jointly, which each descriptor some information about the dominant orientation.",
                    "label": 0
                },
                {
                    "sent": "So for instance, when you extract a Patch.",
                    "label": 0
                },
                {
                    "sent": "We detected that detector.",
                    "label": 0
                },
                {
                    "sent": "You have the value of the dominant rotation, which which is determined by the detector.",
                    "label": 0
                },
                {
                    "sent": "You may have another full affine local affine ellipse actually on.",
                    "label": 0
                },
                {
                    "sent": "You also have some scale log scale, so this one of stored in the file in the context manner.",
                    "label": 0
                },
                {
                    "sent": "So typically you're going to take 1112 bits per descriptor, so it is additional storage, but it is a relatively smaller compared to storing the rest.",
                    "label": 0
                },
                {
                    "sent": "For instance, the idea of the descriptor on.",
                    "label": 0
                },
                {
                    "sent": "Then for each image you're going to.",
                    "label": 0
                },
                {
                    "sent": "Store some small office program to collect the vote.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is illustrated there.",
                    "label": 0
                },
                {
                    "sent": "We have an image.",
                    "label": 0
                },
                {
                    "sent": "We have another image.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is rotated on the left image query image.",
                    "label": 0
                },
                {
                    "sent": "We're going to estimate to use actually because it is already collected, we're going to use the dominant rotation associated with each Patch on the same is in the database image the computer difference.",
                    "label": 0
                },
                {
                    "sent": "On the issue of a troop rotation, you should find a picture.",
                    "label": 0
                },
                {
                    "sent": "You should make a histogram of the difference of rotation on this.",
                    "label": 0
                },
                {
                    "sent": "Actually, what appears there you have this peak.",
                    "label": 0
                },
                {
                    "sent": "Which correspond to all the rotation, which are consistent.",
                    "label": 0
                },
                {
                    "sent": "On there you have inconsistent rotation that might appear there on.",
                    "label": 0
                },
                {
                    "sent": "Once you have Instagram stories in memory at query time, you can just filter out this one because they are not around the peak.",
                    "label": 0
                },
                {
                    "sent": "This is a basic idea, so you're using rotation to filter out some descriptors.",
                    "label": 0
                },
                {
                    "sent": "Is this about outlier removal?",
                    "label": 0
                },
                {
                    "sent": "The same here.",
                    "label": 0
                },
                {
                    "sent": "Obviously the patches and the girl are not consistent with others, so you can remove.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This matches.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So compare if you look at the inner product computed between two bag of words.",
                    "label": 0
                },
                {
                    "sent": "Ideas there is continued the voter to pull the votes are in this histogram.",
                    "label": 0
                },
                {
                    "sent": "So if you think about it will just be collecting your single dinner.",
                    "label": 0
                },
                {
                    "sent": "All the votes there you're going to dilute the vote based on prior you have about the matches, which in this case is different foundation.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On which can also be change in scale I.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To mention this worker variation, which is an answer we geometry consistency proposed by zero.",
                    "label": 1
                },
                {
                    "sent": "Which is also known as these are phrases, so I still don't know what is the difference between these two.",
                    "label": 0
                },
                {
                    "sent": "Actually from it is almost the same.",
                    "label": 0
                },
                {
                    "sent": "So basically there the idea is to not choose to use angle rotation, but simply translation to filter out the incorrect matches.",
                    "label": 1
                },
                {
                    "sent": "And you should do that if you incorporate this week geometry.",
                    "label": 0
                },
                {
                    "sent": "So there it is.",
                    "label": 0
                },
                {
                    "sent": "Mix with some other improve.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which I will discuss after, but this is just to show that if you integrate some geometry on better matching schema then you can other system which is very good.",
                    "label": 0
                },
                {
                    "sent": "Not skate.",
                    "label": 0
                },
                {
                    "sent": "I mean this is very fast, so trivial before some clarification is already quite good, not perfect.",
                    "label": 0
                },
                {
                    "sent": "You still have to use geometrical verification afterward, but much better on good enough to have all the relevant images shortlisted.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So another I think very important work is it is quite expansion in visual search.",
                    "label": 1
                },
                {
                    "sent": "So expansion is also a technique which is borrowed from text.",
                    "label": 0
                },
                {
                    "sent": "Whatever it is, not new by itself, but image search.",
                    "label": 0
                },
                {
                    "sent": "It was first proposed by Charm in 2007 at ACV Yes.",
                    "label": 0
                },
                {
                    "sent": "Ideas to say I'm going to have a system which is not good enough to find all the all the queries because we might have some cases where you have this.",
                    "label": 0
                },
                {
                    "sent": "Statue there, which appears only partially on another image which contains only the statue.",
                    "label": 0
                },
                {
                    "sent": "Obviously you cannot match directly to images because they have no overlap.",
                    "label": 0
                },
                {
                    "sent": "But they correspond to the same location approximately on you have some images that can link one to the user.",
                    "label": 0
                },
                {
                    "sent": "So the idea for expansion as proposed by Chen is to process the list of results.",
                    "label": 1
                },
                {
                    "sent": "The first one returned by the 1st original bag of word scoring.",
                    "label": 0
                },
                {
                    "sent": "Performs a special verification in on the short list.",
                    "label": 0
                },
                {
                    "sent": "Up to now everything is standard, but now from this shortlist process and augmented queries on the good thing is that general filter is very strong so you can identify some images for which you're sure that they are correct, because the number of inliers is about.",
                    "label": 0
                },
                {
                    "sent": "10 or one hundreds so you can augment the query.",
                    "label": 0
                },
                {
                    "sent": "With this descriptor, retrieve home the images which are trustable.",
                    "label": 0
                },
                {
                    "sent": "These doing so you can create your several variants, but you can basically augmented query which will be less parcel.",
                    "label": 0
                },
                {
                    "sent": "The query cost will be increased but still which is much better respect to the representation of the physical object, image query image itself to retrieve some new results and then the second stage.",
                    "label": 0
                },
                {
                    "sent": "For instance you get 41 results while the first was only 12 and you can iterate.",
                    "label": 0
                },
                {
                    "sent": "Is this using some transitive closure?",
                    "label": 0
                },
                {
                    "sent": "Until you have no more results than when you get in the produce stage and I want to mention very interesting variant by 100 logics on this or manner.",
                    "label": 0
                },
                {
                    "sent": "Would you say OK in creeks pension?",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that we have some true positive.",
                    "label": 0
                },
                {
                    "sent": "We are pretty sure of because I've been specially verified so we can mark them as being true positive for classifier and then you can take some random images which are completely irrelevant that we can note as negative on.",
                    "label": 0
                },
                {
                    "sent": "We can not the math negative because they have.",
                    "label": 0
                },
                {
                    "sent": "They had a very low score with respect to the TF IDF scoring.",
                    "label": 0
                },
                {
                    "sent": "With respect to the bag of representation, so we have this positive example on negative example.",
                    "label": 0
                },
                {
                    "sent": "So this is machine learning, right?",
                    "label": 0
                },
                {
                    "sent": "So what they do is that they apply classifier on the fly.",
                    "label": 0
                },
                {
                    "sent": "They learning on the fly.",
                    "label": 0
                },
                {
                    "sent": "To perform the second query so it turns out that they introduce some some discriminative selection rule in the process of image search, which has a big inning was not a classification task, but which become Christian classification task because they have created some labels on the fly.",
                    "label": 0
                },
                {
                    "sent": "I think this is one of the trends that I mentioned before, which is that we can incorporate more and more machine learning in a task which are supposedly.",
                    "label": 0
                },
                {
                    "sent": "Or not supervised task because we have the possibility to incorporate so annotation external annotation in this case based on metrical verification.",
                    "label": 0
                },
                {
                    "sent": "So now I would like to know if you completed commands and go further.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is a very practical solution in the sense that we can reuse many ingredients introduced in in text with trivial.",
                    "label": 1
                },
                {
                    "sent": "So basically, all those things that really worked in Texas River, I've been reusing image search, the ones that can be applied for instance, in classification we can use Suppository machine that has done by 10, so we can apply cracks, pension and we can also under some statistical phenomenon like burstiness or currencies.",
                    "label": 0
                },
                {
                    "sent": "On all this technique actually.",
                    "label": 0
                },
                {
                    "sent": "Have been shown effective inmate search but we have previously introduced in the text travel on.",
                    "label": 1
                },
                {
                    "sent": "I believe that bag of word with appropriate extension is still state of the art we expect to image search or instant search or localization tasks.",
                    "label": 0
                },
                {
                    "sent": "For instance, given that you incorporate the good extension so first some better matching technique.",
                    "label": 0
                },
                {
                    "sent": "That is, you have to improve the neighborhoods matching induced by bag of word like.",
                    "label": 1
                },
                {
                    "sent": "Using shift assignment about assignment or Hamming embedding as I will show after he honking specification you have to use gematria of images.",
                    "label": 0
                },
                {
                    "sent": "Obviously incorrect pension when can be applied.",
                    "label": 0
                },
                {
                    "sent": "So I have to mention the expansion can be useful only if you have many images of the same object in the database.",
                    "label": 0
                },
                {
                    "sent": "If you have only one reference image.",
                    "label": 0
                },
                {
                    "sent": "It is not possible to apply to expansion.",
                    "label": 0
                },
                {
                    "sent": "It will not work because the best you can obtain is 1 image.",
                    "label": 0
                },
                {
                    "sent": "So if it is not shortlisted you lose it and you cannot augment the query using this single query.",
                    "label": 0
                },
                {
                    "sent": "So expansion is especially useful for that asset like Oxford where you can have many images to be returned.",
                    "label": 0
                },
                {
                    "sent": "But for the test set like Holidays or benchmark the this technique is not effective because you do not have enough images too.",
                    "label": 0
                },
                {
                    "sent": "Once a query.",
                    "label": 0
                },
                {
                    "sent": "Any question and going to make just.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stop now for questions.",
                    "label": 0
                },
                {
                    "sent": "OK, I go on.",
                    "label": 0
                },
                {
                    "sent": "So now we have.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We've discussed a lot about go further, which as I said, can scale to let's say one.",
                    "label": 0
                },
                {
                    "sent": "Images Maybe 10 big server.",
                    "label": 0
                },
                {
                    "sent": "But this is a limitation which is strong because you don't have enough memory to store the data required by bag of raw, so you cannot go beyond this scale.",
                    "label": 0
                },
                {
                    "sent": "Scale more you may use global descriptors, for instance on use cutting technique to have them more compact.",
                    "label": 1
                },
                {
                    "sent": "So now we assume that we want to index 100 million when billion images and you have one server.",
                    "label": 0
                },
                {
                    "sent": "So obviously you are limited by your memory, so you have to take into account this constraint on.",
                    "label": 0
                },
                {
                    "sent": "I think this is specially the message that rubber on this course.",
                    "label": 0
                },
                {
                    "sent": "Said that in this paper, small code on large data base for condition, they used very, very compact codes on coding Jesus crypto rebadges descriptor.",
                    "label": 0
                },
                {
                    "sent": "On their able to scale to very large, this exists as mentioned in the title, but clearly the rela is relied on the GIST descriptor, which is not very invariant.",
                    "label": 0
                },
                {
                    "sent": "It is a structural layout structure layout.",
                    "label": 0
                },
                {
                    "sent": "It is not invariant or not proper for object recognition.",
                    "label": 0
                },
                {
                    "sent": "Instance recognition.",
                    "label": 0
                },
                {
                    "sent": "So what I propose there is to say, OK, we're going to keep the last part.",
                    "label": 0
                },
                {
                    "sent": "That is, you have this.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dimension to reduction of a global descriptor and then some encoding scheme.",
                    "label": 0
                },
                {
                    "sent": "The only thing that is different there is that you're going to 1st extract sift.",
                    "label": 1
                },
                {
                    "sent": "On, then use aggregation operator to have a single vector lacking the growth rate actually, but this one is going to be reduced by dimensionality reduction, so that in final you fulfill constraint on the number of bytes per image.",
                    "label": 0
                },
                {
                    "sent": "So there is a constraint.",
                    "label": 0
                },
                {
                    "sent": "The code is a constraint.",
                    "label": 0
                },
                {
                    "sent": "This size is the size of the code is a constraint on.",
                    "label": 0
                },
                {
                    "sent": "You have to optimize all these chain join fee to get the best performance as possible given a budget of memory.",
                    "label": 0
                },
                {
                    "sent": "We don't want to make global description because we want to go beyond what you can do with suggested script.",
                    "label": 0
                },
                {
                    "sent": "Also we rely on safe descriptor.",
                    "label": 0
                },
                {
                    "sent": "So what you want to optimize is basically quality, speed and memory.",
                    "label": 1
                },
                {
                    "sent": "We have three stages to optimize the aggregation step.",
                    "label": 1
                },
                {
                    "sent": "The dimensionality reduction unsound Excel algorithm.",
                    "label": 0
                },
                {
                    "sent": "That is why.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to next section will be dedicated to 1st.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Location of the descriptor.",
                    "label": 0
                },
                {
                    "sent": "Since descriptors in two single vector.",
                    "label": 0
                },
                {
                    "sent": "So back off word was negation procedure.",
                    "label": 0
                },
                {
                    "sent": "I will present some other one.",
                    "label": 0
                },
                {
                    "sent": "Then we spent some time on the efficient indexing you're going to efficiently search, but also anchored this descriptor so that they do not take too much memory.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first motivation for new aggregation algorithm mechanism was about improving the quality of the representation, not about the scale.",
                    "label": 0
                },
                {
                    "sent": "But I have to mention that what I'm going to present was first proposed in classification, whereas people are less.",
                    "label": 0
                },
                {
                    "sent": "Actually, we're less interested by scaling now.",
                    "label": 0
                },
                {
                    "sent": "It's not the case anymore with image net concern, but historically image search is.",
                    "label": 0
                },
                {
                    "sent": "More scalable than classification, and I think there's a gap now tends to to be reduced.",
                    "label": 0
                },
                {
                    "sent": "So the code is just about counting the number of local descriptors.",
                    "label": 1
                },
                {
                    "sent": "So why not including some other statistics?",
                    "label": 0
                },
                {
                    "sent": "So for instance, the mean of local descriptors in a given region of the space.",
                    "label": 0
                },
                {
                    "sent": "Only this occurrence of Luke.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Descriptors.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first example of how to include more information that then adjusts accounting is of lab.",
                    "label": 0
                },
                {
                    "sent": "So there we still have a cookbook chemist, quantizer defining some visual words.",
                    "label": 0
                },
                {
                    "sent": "We still have this assignment procedure which is going to assign each descriptor to its closest entries.",
                    "label": 0
                },
                {
                    "sent": "So for instance, this country this computers or assigned to this country and so on.",
                    "label": 0
                },
                {
                    "sent": "But instead of sampling counting them.",
                    "label": 0
                },
                {
                    "sent": "You're going to incur the difference between the descriptor on its entry, so this difference is vector difference actually can be shown there, so you have their three vector of difference on just some of them.",
                    "label": 0
                },
                {
                    "sent": "Which means that per cell you obtain a vector not account like indigo fraud within your vector, which is the cumulative some of the descriptor which have been assigned to the same trade.",
                    "label": 0
                },
                {
                    "sent": "And finally you normalize this vector so demonstrates descriptor in this case is bigger than for both ran for the same vocabulary size.",
                    "label": 0
                },
                {
                    "sent": "That is, if you have some trees on the dimensionality of the vector, which is do you have cat times D vector of?",
                    "label": 0
                },
                {
                    "sent": "Times D sorry.",
                    "label": 0
                },
                {
                    "sent": "So instead of K. So the good thing is that it is a marginal switch shift.",
                    "label": 0
                },
                {
                    "sent": "It is a difference of.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can do it like.",
                    "label": 0
                },
                {
                    "sent": "We do for safety and see if we have this 4 * 4 grid.",
                    "label": 0
                },
                {
                    "sent": "The only difference is that we might have some negative values represented there in red and you can observe hopefully that if you have similar images you will have similar representation.",
                    "label": 0
                },
                {
                    "sent": "So there on there, I think is quite clear.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vlad, as we will see is it was introduced after the feature vector but is very close actually in effect.",
                    "label": 0
                },
                {
                    "sent": "So the feature vector you might know that this is a state of the art for image classification today.",
                    "label": 0
                },
                {
                    "sent": "It has been used successfully by exact, in particular in the last image net Challenge, last year on the unit.",
                    "label": 0
                },
                {
                    "sent": "Actually it has been shown last year.",
                    "label": 0
                },
                {
                    "sent": "Again we see that it was better than all other new coding technique in cutting technique in the paper.",
                    "label": 0
                },
                {
                    "sent": "So the devil is in the details.",
                    "label": 0
                },
                {
                    "sent": "What is a Fisher vector?",
                    "label": 1
                },
                {
                    "sent": "So it was introduced by Perona Xerox in 2007.",
                    "label": 0
                },
                {
                    "sent": "For images, just first introduce 98, but I will come back and spine.",
                    "label": 0
                },
                {
                    "sent": "So given likelihood function with parameter Lambda we can define the score function forgiven.",
                    "label": 1
                },
                {
                    "sent": "Simple as a derivative of the log likelihood and we expect this parameters of the observation.",
                    "label": 0
                },
                {
                    "sent": "So this gives us vector fixed dimensionality, which only depends on the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "So for each parameter you have a dimension.",
                    "label": 1
                },
                {
                    "sent": "So the intuition is, given some observation on given a generative model, you try to explain how to modify the model.",
                    "label": 0
                },
                {
                    "sent": "So that better fits the particular observations that you have.",
                    "label": 0
                },
                {
                    "sent": "This is basic intuition, so have your model when you try to start it using this.",
                    "label": 0
                },
                {
                    "sent": "This kind of graduate in the log in the space of likelihood two better explains observation.",
                    "label": 0
                },
                {
                    "sent": "So the Fisher information matrix can be.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Writing like this so it can be used as proposed by Akula two measures.",
                    "label": 0
                },
                {
                    "sent": "The similarity between two observation using official kernel.",
                    "label": 0
                },
                {
                    "sent": "So first channel is a kernel.",
                    "label": 0
                },
                {
                    "sent": "Chance to compare two representation of produce as a derivative is likely woulda by using these metrics in the middle, which is in versus Fisher information matrix on.",
                    "label": 1
                },
                {
                    "sent": "This can be interpreted as some widening of this course actually.",
                    "label": 1
                },
                {
                    "sent": "The good thing is that it can be decomposed explicitly, this showing to measure metrics like this so.",
                    "label": 0
                },
                {
                    "sent": "So that then you can incorporate directly.",
                    "label": 0
                },
                {
                    "sent": "One part who's left part in the descriptor you have generated before in the user terms you can have directly this.",
                    "label": 0
                },
                {
                    "sent": "Viktorov score.",
                    "label": 0
                },
                {
                    "sent": "Process such that you can compute the Fisher kernel inefficient manner simply by making your inner product.",
                    "label": 0
                },
                {
                    "sent": "So now images.",
                    "label": 0
                },
                {
                    "sent": "Bill Nye proposed to present a set of.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The script also and to compare set of descriptors using this feature kernel.",
                    "label": 0
                },
                {
                    "sent": "So let's assume that you have some, for instance, descriptors which are supposed to be independent vector generated by some distribution.",
                    "label": 0
                },
                {
                    "sent": "Then you can simply add the.",
                    "label": 0
                },
                {
                    "sent": "This individual.",
                    "label": 0
                },
                {
                    "sent": "Derivative of the log likelihood function respect with parameters and to make some average pooling, which amounts to make the independence assumption to obtain.",
                    "label": 0
                },
                {
                    "sent": "Victor on if you consider in particular the case where your model is a Gaussian mixture model.",
                    "label": 1
                },
                {
                    "sent": "You tell a set of vector which is actually promised some kind of probabilistic visual vocabulary in which you can incorporate many quantities, such as first counter the descriptor, the mean of the distribution you observe in particular respect to the parameters on the covariance term.",
                    "label": 0
                },
                {
                    "sent": "So there in the feature vector you basically have the graduates of the derivative locally.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spec to the counter give you some soft bag off road.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Liking the assignment in value in the burger photo presentation.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But you can add more parameters to your gym model so you can stall so the derivative with respect to the meaner, which give you this formula which is actually very close to summation in a given vocabulary of descriptor minus a centroid.",
                    "label": 0
                },
                {
                    "sent": "So there you can already see the relationship with Lab, except that we have you have this white.",
                    "label": 0
                },
                {
                    "sent": "Operation, which is performed intrinsically.",
                    "label": 0
                },
                {
                    "sent": "You can also uncovered some temp related to the Ryans so in practice.",
                    "label": 0
                },
                {
                    "sent": "The proposed to use the general model for the mixture of Goshen on this will be explained of a respectful way of term.",
                    "label": 0
                },
                {
                    "sent": "So now if you compare big off road with the Fisher Vector, we have a much higher dimensional vector instead of having.",
                    "label": 1
                },
                {
                    "sent": "So should we care case onto it?",
                    "label": 0
                },
                {
                    "sent": "So vector dimension K we have two DK dimension.",
                    "label": 0
                },
                {
                    "sent": "So you have 2D instead of.",
                    "label": 0
                },
                {
                    "sent": "Q factor.",
                    "label": 0
                },
                {
                    "sent": "But it is very efficient to compute because the assignment cause.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is one of the most quality question bag of word is the same actually as is a bag of Fern.",
                    "label": 0
                },
                {
                    "sent": "Assuming that software segment is not more costly than art hasn't.",
                    "label": 0
                },
                {
                    "sent": "So first.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When you use the feature vector, it is very important to make some PCA principal component analysis on the local descriptor first on.",
                    "label": 0
                },
                {
                    "sent": "The reason is that as I mentioned, the proposed to use additional model for the reason of complexity actually to get not so big model of parameters because for the feature you have one dimension parameters with the covariance matrix it will begin.",
                    "label": 0
                },
                {
                    "sent": "Uon's and to have better to have this assumption of diagonal dignity of the matrix better satisfy, it's better to perform PCA first on the local descriptor.",
                    "label": 1
                },
                {
                    "sent": "So actually this can be shown there on this graph, where we show the performance of the feature.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With a regular descriptor as input on, then we PCA perform on the local script before applying the feature vector.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, the best consumer obtain when applying the dimensionality reduction of the features on input.",
                    "label": 1
                },
                {
                    "sent": "For two reasons.",
                    "label": 1
                },
                {
                    "sent": "So the first is when I mention the generality assumption of the model is better satisfied, but also the feature perform some lightening.",
                    "label": 0
                },
                {
                    "sent": "Which turns to.",
                    "label": 0
                },
                {
                    "sent": "To increase the noisy dimensions or the lower energy dimension in the PCA may introduce some new noise.",
                    "label": 1
                },
                {
                    "sent": "It should make some turning on them, so you should avoid to use this dimensionality these components.",
                    "label": 0
                },
                {
                    "sent": "Another very important step in the feature vector to be done is the parallel component wise.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Normalization?",
                    "label": 0
                },
                {
                    "sent": "So let me go forward.",
                    "label": 0
                },
                {
                    "sent": "The feature vector representations refer from overcounting of similar pattern, so I mentioned before that when you make the inner product between two regular histogram, you're going to overcount the matches when you have several matches.",
                    "label": 0
                },
                {
                    "sent": "Person, if you have three on 3, you get 9 votes on.",
                    "label": 0
                },
                {
                    "sent": "For this reason, you apply.",
                    "label": 0
                },
                {
                    "sent": "Some square rooting so that the behavior is the number score is linear in the number of matches, which are possible.",
                    "label": 0
                },
                {
                    "sent": "So we have this effect of accounting similar patterns that also appear in the Fisher kernel, but it is even more important, in particular when you consider done set up because you have some bursty visual elements that is in natural images, you might know that you have many burst visual burst that is repeated patterns, visual patterns when you look at them closer almost the same.",
                    "label": 1
                },
                {
                    "sent": "On the there not so frequent in the world database, but they appear in the same image at the same time.",
                    "label": 0
                },
                {
                    "sent": "Which means that when you compute similarity between bag of word or feature vector, you're going to give almost most of the energy in the vote to this repetitive patterns.",
                    "label": 0
                },
                {
                    "sent": "This is actually in for sizing the magnifying.",
                    "label": 0
                },
                {
                    "sent": "The problem of overcounted pattern on it has been shown that it is very effective solution to apply some power law component wise on this representation.",
                    "label": 0
                },
                {
                    "sent": "So if you just want to take into account without counting, you might consider this crouching below 0.5 by default on if you want in addition to reduce impact of bursty pattern you might even consider.",
                    "label": 0
                },
                {
                    "sent": "Smaller value of Alpha, typically 0.3 or 0.4.",
                    "label": 0
                },
                {
                    "sent": "There is a strong correlation sheet between.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As of late in the future, as I mentioned, the red can carry viewed as non probabilistic version of the Fisher Vector where the Gaussian mixture model is replaced simply by Cummins.",
                    "label": 0
                },
                {
                    "sent": "So it must transforming this into this.",
                    "label": 0
                },
                {
                    "sent": "The main difference is if you want to focus on that is that Fisher performance soft assignment or the descriptors.",
                    "label": 0
                },
                {
                    "sent": "So this may be interesting with interest point I have to mention that my experiments assignment is not very important in the done set up because they have done set up.",
                    "label": 0
                },
                {
                    "sent": "You already have implicitly some kind of assignment performed by the sampling.",
                    "label": 0
                },
                {
                    "sent": "It also implicitly white turns a component.",
                    "label": 0
                },
                {
                    "sent": "So introduce impact.",
                    "label": 0
                },
                {
                    "sent": "The components which are more energetic naturally in the database.",
                    "label": 0
                },
                {
                    "sent": "On my opinion, this as.",
                    "label": 0
                },
                {
                    "sent": "Some kind of similar effect with squelching perform component twice in the same descriptors to reach you perform some square rooting on the CD script or jointly with opinions of Lad.",
                    "label": 0
                },
                {
                    "sent": "You get almost the same as feature, even better in some cases.",
                    "label": 0
                },
                {
                    "sent": "But the future is imaginary setter because you can use any model representative parameters on give.",
                    "label": 0
                },
                {
                    "sent": "You say you out wrong code and compare 8, which means that you can extend it to consider someone order statistic on, you can consider a something different from GM for the encoding, so it is more generic.",
                    "label": 0
                },
                {
                    "sent": "But in this way you can also say OK, we can extend the Vlad to include some 2nd order statistic, and it was a, for instance, turning the flat paper which is of ladder but which also consider 2nd order statistics.",
                    "label": 1
                },
                {
                    "sent": "And I want to mention that the supervector so this is V 2011 was shown relatively effective.",
                    "label": 0
                },
                {
                    "sent": "On it is approximately some combination, some weighted combination of a bag of fraud on Vlad Vector.",
                    "label": 0
                },
                {
                    "sent": "Almost the same on the question.",
                    "label": 0
                },
                {
                    "sent": "Actually that it was not as good as Fisher in this paper from BBC by Sheffield last year.",
                    "label": 0
                },
                {
                    "sent": "So how does this new aggregation representation compare with bag of Worm?",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, there we only displayed.",
                    "label": 0
                },
                {
                    "sent": "The fish are using the derivative respect to the mean because in retrieval for some reasons the 2nd order static do not help.",
                    "label": 0
                },
                {
                    "sent": "It's very important classification classification but not for image search.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the same dimensionality that is significantly smaller vocabulary because you have person three forgiven vocabulary size feature on Vlad or dimensionality which is larger.",
                    "label": 0
                },
                {
                    "sent": "But even for the same dimensionality on this data set, early days Zulte of the feature of lead are much better than the one of the group with the same vocabulary size.",
                    "label": 1
                },
                {
                    "sent": "Soft.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Segment on the waiting is a feature vector help, so the result or better than the there.",
                    "label": 0
                },
                {
                    "sent": "But when you do some damage.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Introduction of the vector, then those are almost the same.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, to conclude this part, yes to mention that there are some public implementation of the feature vector and also Vlad and this web page, so I think this one is implementation that was used by the people from Oxford for the evaluation last year.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question 4.",
                    "label": 0
                },
                {
                    "sent": "I don't like that.",
                    "label": 0
                },
                {
                    "sent": "I'd like to get maybe some comments because we use GMM in 28 dimensions.",
                    "label": 0
                },
                {
                    "sent": "It's a very high dimensional space, so what's your personal view on our chances?",
                    "label": 0
                },
                {
                    "sent": "First of all, whether you think there's descriptors really density is can be well estimated by GMM.",
                    "label": 0
                },
                {
                    "sent": "Based on your research.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, even if it was with our chances of finding it.",
                    "label": 0
                },
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "Given the dimensions and.",
                    "label": 0
                },
                {
                    "sent": "Not so much data, it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "It doesn't work very well, but just more insight.",
                    "label": 0
                },
                {
                    "sent": "I personally think that the model is not good and completely artificial.",
                    "label": 0
                },
                {
                    "sent": "This is Jean and mixture model for Steve.",
                    "label": 0
                },
                {
                    "sent": "Descriptor is very bad for sure on there are some is also evidence of this actually because there's this paper by less burning.",
                    "label": 0
                },
                {
                    "sent": "For instance that tried to estimate the local dimensionality of the self descriptors and it occurs at the dimensionality.",
                    "label": 0
                },
                {
                    "sent": "First is not fixed, depends on where you're in space and is why it's more compared to the overall space.",
                    "label": 0
                },
                {
                    "sent": "So the model.",
                    "label": 0
                },
                {
                    "sent": "Of course very bad.",
                    "label": 0
                },
                {
                    "sent": "Are we going to find some way to better model it?",
                    "label": 0
                },
                {
                    "sent": "I don't know, but I'm not sure that it is that important that the model is very, very good.",
                    "label": 0
                },
                {
                    "sent": "I'm OK, this is a contradiction with what I say.",
                    "label": 0
                },
                {
                    "sent": "Things that you should make your local PCA before to better satisfies the fact that your matrix is the owner.",
                    "label": 0
                },
                {
                    "sent": "But actually quite interesting if it showed the table that you just displayed comparing lot to GMM.",
                    "label": 0
                },
                {
                    "sent": "And actually, as you notice to commenters, when you go down with them and show it to you.",
                    "label": 0
                },
                {
                    "sent": "The results are very comparable.",
                    "label": 0
                },
                {
                    "sent": "So, so we had to 2000 dimensions.",
                    "label": 0
                },
                {
                    "sent": "It's 62.6 versus 62.1, so it's almost the same, yes.",
                    "label": 0
                },
                {
                    "sent": "So so it seems that.",
                    "label": 0
                },
                {
                    "sent": "Blood is still extracting as much as.",
                    "label": 0
                },
                {
                    "sent": "Fisher, but perhaps in so, so very big, noisy in the input language ability.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, I do agree that that is is appealing because it is simple, but feature was first introduced before write an for large scale image search.",
                    "label": 0
                },
                {
                    "sent": "I would suggest to use Vlad because this employer on also maybe a bit faster, but very slightly to be honest, but in classification it is really shown that feature is superior.",
                    "label": 0
                },
                {
                    "sent": "So on the fact that the.",
                    "label": 0
                },
                {
                    "sent": "Performance or not, that different, especially after the machine reduction is maybe because there are some effects that we do not take into account on which anyway or the bottleneck on this.",
                    "label": 0
                },
                {
                    "sent": "So it may be the case that they are closed because they actually explore the same thing on the awesome statistical effects that neither of these two representation exploit on this might be the bottleneck.",
                    "label": 0
                },
                {
                    "sent": "So maybe work on the bottleneck before.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Open these.",
                    "label": 0
                },
                {
                    "sent": "Words.",
                    "label": 0
                },
                {
                    "sent": "But it sort of matters how many bytes used or each other.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "About the fact that we need to store all the here, understand the question you mentioned.",
                    "label": 0
                },
                {
                    "sent": "The fact that we still need to store the components right?",
                    "label": 0
                },
                {
                    "sent": "Is the question.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Let's go to an exception directly.",
                    "label": 0
                },
                {
                    "sent": "Ask you perform.",
                    "label": 0
                },
                {
                    "sent": "Scriptures to type of allies dimension.",
                    "label": 0
                },
                {
                    "sent": "So basically you can comparison how about performance if we don't perform this type?",
                    "label": 0
                },
                {
                    "sent": "OK so for Vlad the dimension reduction of the local descriptor has no effect basically.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "Right, right?",
                    "label": 0
                },
                {
                    "sent": "So the white whitening is not implemented in the flood where it isn't Fisher on the widening, of course, is rotation dependent invite.",
                    "label": 0
                },
                {
                    "sent": "There is no such step which is quotation dependence, so you can take any basis.",
                    "label": 0
                },
                {
                    "sent": "It's the same and that is why it has almost no effect.",
                    "label": 0
                },
                {
                    "sent": "PC has no effect on Vlad on awesome effect on Fisher vectors.",
                    "label": 0
                },
                {
                    "sent": "Thoughts?",
                    "label": 0
                },
                {
                    "sent": "How to make these recently visited implemented off?",
                    "label": 0
                },
                {
                    "sent": "Because you are half cadence, which now since basically they would try to achieve the same compliance with the cluster.",
                    "label": 0
                },
                {
                    "sent": "So, So what you mean?",
                    "label": 0
                },
                {
                    "sent": "So basically lawsuits police it's white and because it uses K means OK, listen tried to basically compose clusters that have the same violence, yeah, But chemistry is not going to modify isometrics.",
                    "label": 0
                },
                {
                    "sent": "L2 distance remains a metric under some rotation.",
                    "label": 0
                },
                {
                    "sent": "When Vlad, you have this expansion, which is performed by the Sigma I, which is going to magnify certain axis on reducing mothers, the most synergistic one so.",
                    "label": 0
                },
                {
                    "sent": "Disrespect the flag is OK. You have to come in that is going to put more.",
                    "label": 0
                },
                {
                    "sent": "It's actually where you have more energy but it is not going to compensate for the fact that you have some some ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "Some distribution which is more important on certain access at some others, so you do not have any expansion.",
                    "label": 0
                },
                {
                    "sent": "It doesn't modify the metric.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's the same issue.",
                    "label": 0
                },
                {
                    "sent": "It should make PCA before Vlad chemist is rotation invariant, so except you if you're going to really reduce the large dimensionality, in which case we have some effect.",
                    "label": 0
                },
                {
                    "sent": "Of course the Vlad without office PC is the same.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "I think I have to go to next because otherwise I will be late and on.",
                    "label": 0
                },
                {
                    "sent": "I think this part will answer the previous question.",
                    "label": 0
                },
                {
                    "sent": "So now as a notice by one question we have still some whole descriptors on.",
                    "label": 0
                },
                {
                    "sent": "If you want to go to very large K, we need to.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have some efficient indexing technique for this one.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I have a voicemail outline I want to present.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to be a bit fast.",
                    "label": 0
                },
                {
                    "sent": "So basically we want to find neighbors on the fast efficient way, also using very few memory.",
                    "label": 0
                },
                {
                    "sent": "Basically the exhaustive search, the complexity of searching query vector of the size D in the data set of size N is N * D and four identical Victor.",
                    "label": 1
                },
                {
                    "sent": "We know that indexing strategy or difficult to find the cause of this dimensional curves.",
                    "label": 1
                },
                {
                    "sent": "But before I want to make a poll quick poll and how exact matching is respect to efficiency.",
                    "label": 0
                },
                {
                    "sent": "Because sometimes I.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is some paper saying OK, it's very slow to make this comparison of this amount of Victor with this dimensionality.",
                    "label": 0
                },
                {
                    "sent": "So just take a good package on the computer exact exact timings for some query for Victor compared to data set of, let's say one vector.",
                    "label": 0
                },
                {
                    "sent": "So there I say OK I have 10 tenors, neighbor of 101 thousand queries in one detective formula vectors I assume.",
                    "label": 1
                },
                {
                    "sent": "See descriptor, for instance, which means that I have to compute 1 billion distances in dimension 128 on a user 8 core machine.",
                    "label": 1
                },
                {
                    "sent": "So make a polar who thinks that it takes more than one minute.",
                    "label": 0
                },
                {
                    "sent": "OK, we think that it takes more than 10 seconds.",
                    "label": 0
                },
                {
                    "sent": "OK, more than one second.",
                    "label": 0
                },
                {
                    "sent": "Unless and once again.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Five types of guns.",
                    "label": 0
                },
                {
                    "sent": "So OK, it is not that slow.",
                    "label": 0
                },
                {
                    "sent": "It means that you can assign 2052 cabaret of size 100K in one or two seconds.",
                    "label": 0
                },
                {
                    "sent": "Not that inefficient.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but of course you cannot match all the descriptor of million size database with the one of a query image.",
                    "label": 0
                },
                {
                    "sent": "Unreal time to possible, because in this case it is 1 billion distance per local descriptors.",
                    "label": 1
                },
                {
                    "sent": "So in total you have 2014 elementary operation.",
                    "label": 0
                },
                {
                    "sent": "This is too big.",
                    "label": 1
                },
                {
                    "sent": "One hour on 30 minutes.",
                    "label": 0
                },
                {
                    "sent": "So you need approximate nearest neighbor search.",
                    "label": 1
                },
                {
                    "sent": "On this A and then search has optimize jointly three kittiya, on which fine again the same tires.",
                    "label": 0
                },
                {
                    "sent": "One that I wanted to optimize for the larger scale image search problem.",
                    "label": 0
                },
                {
                    "sent": "That is such quality.",
                    "label": 0
                },
                {
                    "sent": "We want the Rotary vector to be the actual nearest neighbor when you consider about indexing with approximately number search.",
                    "label": 0
                },
                {
                    "sent": "When good goal is to try to reproduce, the result is obtained by the exhaustive search.",
                    "label": 0
                },
                {
                    "sent": "Exact one.",
                    "label": 0
                },
                {
                    "sent": "This speed it is why we go to approximate strategies on the memory and the memory is very important and I think as it received enough focus until recently.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to make a personal presentation.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Locality sensitive hashing.",
                    "label": 0
                },
                {
                    "sent": "Just to present our I see the things.",
                    "label": 0
                },
                {
                    "sent": "It is very known.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is known in two different contexts and treatment ways of using it.",
                    "label": 0
                },
                {
                    "sent": "It is the same underlying social framework, but basically it is not used in the same way.",
                    "label": 0
                },
                {
                    "sent": "Depending on which community you are.",
                    "label": 0
                },
                {
                    "sent": "So, LSH is usually associated with two distinct search algorithm.",
                    "label": 1
                },
                {
                    "sent": "One is about.",
                    "label": 0
                },
                {
                    "sent": "Partitioning techniques, which is called hashing, but let's say partitioning to be sure that the distinction is clear where you have several hash function.",
                    "label": 0
                },
                {
                    "sent": "So there I have some.",
                    "label": 0
                },
                {
                    "sent": "This is a hash function, which is actually a partition of the space.",
                    "label": 0
                },
                {
                    "sent": "It just says I have 7 dash function on there, so dash function.",
                    "label": 0
                },
                {
                    "sent": "Each hash function partition the space.",
                    "label": 0
                },
                {
                    "sent": "What you have is that you have this.",
                    "label": 0
                },
                {
                    "sent": "Set when you have a query or going to ash it for each of the hash function on to retrieve Colocalized neighbors to get a list of potential candidates for being nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "After vision, it is more used.",
                    "label": 0
                },
                {
                    "sent": "I would say as winners in technique where you have a feature space in which is Euclidean.",
                    "label": 0
                },
                {
                    "sent": "Typically we want to cast the search for the equation distance into a search for the binary distance, Hamming distance in the binary space.",
                    "label": 0
                },
                {
                    "sent": "OK, so LSH, jediism PDF.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Italian, each vector in databases associated with hash keys stored in inverted list on the query time you compute the hash key for the query and consistent manner on your retrieve.",
                    "label": 1
                },
                {
                    "sent": "Also database vectors which are assigned to the same key and then you compute.",
                    "label": 0
                },
                {
                    "sent": "On this set of candidates, the exact distance is, so this is square LSH, typically.",
                    "label": 0
                },
                {
                    "sent": "You can use any kind of hash function, so most popular.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Honda projections that you can use anyone so underneath, for instance, proposal each quantizer strictly contains surfaces.",
                    "label": 0
                },
                {
                    "sent": "It can be a structure.",
                    "label": 0
                },
                {
                    "sent": "Either learn came in, so can be used as a hash function.",
                    "label": 1
                },
                {
                    "sent": "Yashica means gadgetry.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do we use as hash function?",
                    "label": 1
                },
                {
                    "sent": "Super showing that it is much better to use learn hash function.",
                    "label": 0
                },
                {
                    "sent": "Like I mean, for instance which adapts to the data that I chose, a compromise between the selectivity on the recall.",
                    "label": 0
                },
                {
                    "sent": "Selectivity means the rate of neighbors in the short list, so the amount of neighbors identified as potential neighbors.",
                    "label": 0
                },
                {
                    "sent": "Unusually, you have some booty instant parameters to find, to say I want this selectivity.",
                    "label": 0
                },
                {
                    "sent": "So there for instance for Cummins I consider a bag of word of this Cummins.",
                    "label": 0
                },
                {
                    "sent": "A 400 the words which give you selectivity, which is approximately of 1% and you can increase the vocabulary size exists for each of this structure.",
                    "label": 0
                },
                {
                    "sent": "Contains are there.",
                    "label": 0
                },
                {
                    "sent": "You can also adjust the size of the elementary hash function in the case of lattices it is just a scale factor for instance.",
                    "label": 1
                },
                {
                    "sent": "On that you can see that learndash function or much better than this random projection.",
                    "label": 0
                },
                {
                    "sent": "That are very often used actually.",
                    "label": 0
                },
                {
                    "sent": "If you use a bitter container, we expect to for uniform distribution like lettuce, quantizer, so is a lattice or each lattice.",
                    "label": 0
                },
                {
                    "sent": "You get some improvement, but it's not that it's the data.",
                    "label": 0
                },
                {
                    "sent": "So finally you don't have good results.",
                    "label": 0
                },
                {
                    "sent": "You should look at the usual cabins.",
                    "label": 0
                },
                {
                    "sent": "You can see that you lose respect to the regular flat chemist confessor, but finally in this scale of loss, not that much.",
                    "label": 0
                },
                {
                    "sent": "OK, the problem with locality sensitive rushing in user partitioning technique is that you have to.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Store for ejector and ID, at least in each table.",
                    "label": 1
                },
                {
                    "sent": "So this take a lot of memory.",
                    "label": 1
                },
                {
                    "sent": "So for systems descriptor where you have to use about the 10 assumption, it means 40 bytes is a lot.",
                    "label": 0
                },
                {
                    "sent": "In addition to that we have to store the vector though vector for the final verification.",
                    "label": 0
                },
                {
                    "sent": "So for the sake of reducing the memory usage of the hash function, you can just use what is called the problem and it was actually proposed before multiple assignment.",
                    "label": 0
                },
                {
                    "sent": "But this is basically the same ID, so there.",
                    "label": 1
                },
                {
                    "sent": "Instead of using multiple hash function, you are going to use one.",
                    "label": 0
                },
                {
                    "sent": "But instead of assigning your descriptor Azure database as a query to hash function, you're going to assign it to several hash function.",
                    "label": 0
                },
                {
                    "sent": "So usually it is done only on query side.",
                    "label": 0
                },
                {
                    "sent": "On doing that, you just have went from 1 hash function on your sign to you.",
                    "label": 0
                },
                {
                    "sent": "at Test time.",
                    "label": 0
                },
                {
                    "sent": "You're going to look at several cells to create the list of potential candidates.",
                    "label": 0
                },
                {
                    "sent": "So there is of course correction sheet with multiple as a non bag of word and I want to mention that this was done in 2007 before.",
                    "label": 0
                },
                {
                    "sent": "Flam flam",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think is very important package everyone should know about it is.",
                    "label": 0
                },
                {
                    "sent": "Goes by Jack Charlie on the choose several action Polynome, multiplicative three or multiple chemistry, so is actually used learndash function, which is the best because they have multiple hash function.",
                    "label": 0
                },
                {
                    "sent": "They get very good result.",
                    "label": 0
                },
                {
                    "sent": "To retrieve approximate neighbors.",
                    "label": 0
                },
                {
                    "sent": "So this is the two things which are important.",
                    "label": 0
                },
                {
                    "sent": "Good good hash function.",
                    "label": 0
                },
                {
                    "sent": "Hash function, or at least multi problem.",
                    "label": 0
                },
                {
                    "sent": "On the other, good thing is that it is auto tune.",
                    "label": 0
                },
                {
                    "sent": "The teaser gozum is going to select automatically the best set of parameters, so it is well implemented.",
                    "label": 0
                },
                {
                    "sent": "They have to mention that it is not the first time that some search to tune LSH as proposed was first proposed by Dong in 2007 on the size of paper.",
                    "label": 0
                },
                {
                    "sent": "So this year by Slender that say also to fix the parameters of LSH.",
                    "label": 0
                },
                {
                    "sent": "But it is a good package and actually very often used to perform the assignment of descriptors.",
                    "label": 0
                },
                {
                    "sent": "Two visual words, especially for large vocabularies because for my test for relatively small vocabularies it is better to use the efficient exhaustive search.",
                    "label": 0
                },
                {
                    "sent": "OK, but still we have this.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Package, including fans that are going to preselect a set of candidates on then they have to perform.",
                    "label": 1
                },
                {
                    "sent": "After achieving potential neighbors some exact distance calculation to find the true list of neighbors among the one which have been selected.",
                    "label": 0
                },
                {
                    "sent": "So basically, if your vector has been selected as a protection labels.",
                    "label": 0
                },
                {
                    "sent": "After this exact same speculation, you're sure to rank.",
                    "label": 0
                },
                {
                    "sent": "It is a list of nearest neighbor in the correct order is only a risk you have is if you are not able to retrieve it from the first stage, which is, which is not going to consider all the vectors.",
                    "label": 0
                },
                {
                    "sent": "So if it is missing, the 1st place will not be able to find it in the second stage.",
                    "label": 0
                },
                {
                    "sent": "For the second stage we need.",
                    "label": 1
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The whole descriptor, which is too much.",
                    "label": 0
                },
                {
                    "sent": "As an insurance, so you have to go to the discount, but this of course impacts the efficiency quite severely.",
                    "label": 0
                },
                {
                    "sent": "So not only large scale.",
                    "label": 1
                },
                {
                    "sent": "OK, and now this is the second mode for LSH.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which say, OK, we're going to map Oakland descriptor to binary space, ongoing space.",
                    "label": 0
                },
                {
                    "sent": "It is very interesting, because one so descriptor, very compact.",
                    "label": 0
                },
                {
                    "sent": "Xorb, it's Victor of bits, so if you have 60 four dimension, it fits in one machine world.",
                    "label": 0
                },
                {
                    "sent": "Unless you have a very fast comparison because you have just to make a popcount operation, which is a single instruction.",
                    "label": 0
                },
                {
                    "sent": "Now in a new Inter processor.",
                    "label": 0
                },
                {
                    "sent": "So observe compare exhaust.",
                    "label": 0
                },
                {
                    "sent": "Sorry on the to make the difference.",
                    "label": 0
                },
                {
                    "sent": "To find this picture different on the pop count operation.",
                    "label": 0
                },
                {
                    "sent": "So two operation only can be very fast.",
                    "label": 0
                },
                {
                    "sent": "It is very fast.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So probably one of the most known algorithm is Petra lashing, which is a nice article framework for finding a solution, but which in practice is just a PCA followed by some urbanization on the different axis based on variance.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the two modes of LSH or the following year.",
                    "label": 1
                },
                {
                    "sent": "User partitioning technique.",
                    "label": 0
                },
                {
                    "sent": "LSHS sub linear.",
                    "label": 0
                },
                {
                    "sent": "On this and perform exhaustive search so you're not going to compare to everybody because based simply on the vector which or crashed, you're going to only focus on the subset of candidates.",
                    "label": 1
                },
                {
                    "sent": "But you have a large memory overhead.",
                    "label": 1
                },
                {
                    "sent": "First hashtable overhead and also you need the original vectors for the ranking stage.",
                    "label": 0
                },
                {
                    "sent": "So it is interesting, in my opinion when.",
                    "label": 0
                },
                {
                    "sent": "You have demonstrated which is not too big, because if the dimension is too big and the fact that you use a partitioning approach is not good, you're going to be impacted by the curse of dimensionality.",
                    "label": 1
                },
                {
                    "sent": "You cannot do that.",
                    "label": 1
                },
                {
                    "sent": "Also, it's interesting with the user.",
                    "label": 0
                },
                {
                    "sent": "Data set is not too small.",
                    "label": 0
                },
                {
                    "sent": "1,000,000 is OK, one billion is not OK because of this memory.",
                    "label": 0
                },
                {
                    "sent": "So those are some very good variance in software.",
                    "label": 0
                },
                {
                    "sent": "In particular, plan users administration technique.",
                    "label": 1
                },
                {
                    "sent": "From linear search, but if your individual search is extremely faster on this is a compact comparison.",
                    "label": 0
                },
                {
                    "sent": "So for me it is interesting for very high dimensional vectors.",
                    "label": 0
                },
                {
                    "sent": "Unmet memory is critical.",
                    "label": 0
                },
                {
                    "sent": "On this, calculated to larger scale image search in our case.",
                    "label": 0
                },
                {
                    "sent": "OK so I would advise to use this partitioning murder.",
                    "label": 0
                },
                {
                    "sent": "So for instance using.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plan for searching local descriptor or assigning on.",
                    "label": 0
                },
                {
                    "sent": "This one is for.",
                    "label": 0
                },
                {
                    "sent": "Indexing very large vector on is of particular interest in the case of very large scale inmate search.",
                    "label": 0
                },
                {
                    "sent": "When you want to index directly the global descriptors as produced by the Fisher kernel of Lab.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, hang on building.",
                    "label": 0
                },
                {
                    "sent": "We have two more for less edge.",
                    "label": 0
                },
                {
                    "sent": "Can we try to use the best of both actually?",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two, we wanted to do is having a building which is a combination of a partitioning technique.",
                    "label": 1
                },
                {
                    "sent": "Wish.",
                    "label": 0
                },
                {
                    "sent": "Urbanizacion technique.",
                    "label": 0
                },
                {
                    "sent": "Victory is represented by.",
                    "label": 1
                },
                {
                    "sent": "First quantization index on the binary code in the cell.",
                    "label": 0
                },
                {
                    "sent": "On the matching rule is 2 descriptor match if and only if and only if they are contais.",
                    "label": 0
                },
                {
                    "sent": "Therefore in the same.",
                    "label": 0
                },
                {
                    "sent": "Version of the space according to the hash function.",
                    "label": 0
                },
                {
                    "sent": "If in addition, the Beanery vector as determined by your local local caching function is similar, so we have partitioning on the local measurement.",
                    "label": 0
                },
                {
                    "sent": "On this give very good results, I'm going straight to show the visual impact.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this, having a building step this.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is 20 K vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It should be 4.",
                    "label": 0
                },
                {
                    "sent": "If we take a larger vocabulary, losing a lot of matches.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I miss having a building.",
                    "label": 0
                },
                {
                    "sent": "We are going to preserve most of the correct matches.",
                    "label": 0
                },
                {
                    "sent": "We're moving many first positive, so this in this case the image of a lot of matches.",
                    "label": 0
                },
                {
                    "sent": "The future so extent with a larger vocabulary.",
                    "label": 0
                },
                {
                    "sent": "But we sending first have more correct matches unless incorrect matches.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and now I go to the final technique that I want to present which is product.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Physician basically, which is about approximate search using compression technique such that our feature Vector of Lado bag of words can be compacting very few bites.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical source coding system I have as I have done doing my PhD quite a lot because I did my PhD in source coding on joints.",
                    "label": 1
                },
                {
                    "sent": "Which encoding you have basically a vector which is decorated.",
                    "label": 0
                },
                {
                    "sent": "First step, so this PCA Kevin Love you can density for JPEG wavelet transform for GP2000 then it is followed by a contagious and step which is only last step there.",
                    "label": 0
                },
                {
                    "sent": "You lose some information is only place where you lose some information on.",
                    "label": 0
                },
                {
                    "sent": "Then you have some entropy coder which is lossless coding.",
                    "label": 0
                },
                {
                    "sent": "That is from here we can go back there.",
                    "label": 0
                },
                {
                    "sent": "So I'm going just to focus on the quantization step which is the one which given the descriptor find the.",
                    "label": 0
                },
                {
                    "sent": "Is the best for production value?",
                    "label": 0
                },
                {
                    "sent": "Forgiven contessa?",
                    "label": 0
                },
                {
                    "sent": "So we can show that if you estimate the distance between the query.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the Pacific, by the distance between query on the contest.",
                    "label": 1
                },
                {
                    "sent": "Version of Victor.",
                    "label": 0
                },
                {
                    "sent": "You have some statistical bound saying use that the square or between the distance is bounded by the quantization error.",
                    "label": 1
                },
                {
                    "sent": "So the batteries are contains are the better is your distance estimation on your some boundary for the perfect perfect container is young.",
                    "label": 0
                },
                {
                    "sent": "You have a perfect distance estimation.",
                    "label": 0
                },
                {
                    "sent": "So the idea of this work is to say it is to use a product container.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "As a contest.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To perform this kind of estimation on, we see the search as a distance estimation approximation problem, where the distances will be computed in the compressed domain directly.",
                    "label": 1
                },
                {
                    "sent": "Such that the quantization is fast and precise enough so for the conversation to be precise, we need a lot of production values.",
                    "label": 0
                },
                {
                    "sent": "We need a lot of possible some trees on, not letting that go through, we need significantly more.",
                    "label": 0
                },
                {
                    "sent": "We need about two power, 64% rates even more so you cannot fast learner regular comes with that on the incursus primitive.",
                    "label": 0
                },
                {
                    "sent": "So instead what you can use is just a protocol Kaiser where you're simply going to split.",
                    "label": 0
                },
                {
                    "sent": "Your victim.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into several parts.",
                    "label": 0
                },
                {
                    "sent": "On each side, Victor is Contessa partly.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if I take this 16 dimensional vector on, spit it into eight vector, I have 8 contains are applied to component or two components.",
                    "label": 0
                },
                {
                    "sent": "On the right produce me.",
                    "label": 0
                },
                {
                    "sent": "I have ate some trade person quantizer 3 bits.",
                    "label": 0
                },
                {
                    "sent": "So in total I have a 24 bits quantization index, which means that you have to power 24 possible values, which is a lot on typical settings.",
                    "label": 0
                },
                {
                    "sent": "We would have a big person container.",
                    "label": 0
                },
                {
                    "sent": "On about four to 16 sub container for serious cryptos, for instance, if we take 8 second Acer, you will have two pair of 64 possible positions values, so this is very much more precise than what you can achieve with chemist container and you can do it on.",
                    "label": 0
                },
                {
                    "sent": "Vectors are very high dimensional ET which relatively small assignment cost.",
                    "label": 0
                },
                {
                    "sent": "So the item cost is equal.",
                    "label": 0
                },
                {
                    "sent": "To 2% in the number of bits.",
                    "label": 0
                },
                {
                    "sent": "So if you have for instance.",
                    "label": 0
                },
                {
                    "sent": "Like this 256 position value person contains are the complexity that complexity of financial index is simply curtains D where D the dimensionality of descriptor on where K is this number of possible.",
                    "label": 0
                },
                {
                    "sent": "So it's plastic container.",
                    "label": 0
                },
                {
                    "sent": "The good thing is that.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Issues Republican taiser you actually you're going to too concise.",
                    "label": 0
                },
                {
                    "sent": "Inaugural space is the signal, which means that if you want to estimate the distance between X&Y.",
                    "label": 0
                },
                {
                    "sent": "You can approximate it by summation.",
                    "label": 0
                },
                {
                    "sent": "Between of the distance between square distance between each vector on the contest.",
                    "label": 1
                },
                {
                    "sent": "So Victor associated with that are basic to ryi.",
                    "label": 0
                },
                {
                    "sent": "So at this stage you might think, OK, I've not won anything because I have to make this summation instead of the.",
                    "label": 1
                },
                {
                    "sent": "Regular distance computation, but it's the same number of operation.",
                    "label": 0
                },
                {
                    "sent": "Even more.",
                    "label": 0
                },
                {
                    "sent": "The fact is that it is true if you only consider two vectors, but if you consider that you have one query on many database vectors.",
                    "label": 0
                },
                {
                    "sent": "Who is this quantity there?",
                    "label": 0
                },
                {
                    "sent": "Actually shared by all the vectors of the database.",
                    "label": 0
                },
                {
                    "sent": "So basically when you want to compute all the distances between your query vector on a set of data, basic terms what you have to do is first to compute a set of lookup tables that are going to store all these possible possible terms there in the summation.",
                    "label": 1
                },
                {
                    "sent": "The precomputed at this stage you have not looked at the database of vectors, you've just precomputed tables.",
                    "label": 0
                },
                {
                    "sent": "The look up tables, and now when you have a particular database vector, you just look at the IDs to retrieve this Emon Tori term associated with this vector.",
                    "label": 1
                },
                {
                    "sent": "You just have to send the different components, which in practice that if we have 8 quantizer, you just have to make 8 addition from this group tables.",
                    "label": 0
                },
                {
                    "sent": "So yeah, this cursed created tables that appears in this summation on the second stage, which is only one which is linear in the number of database vectors.",
                    "label": 0
                },
                {
                    "sent": "Amounts to make this small underestimation for each vector to compute estimated distances.",
                    "label": 0
                },
                {
                    "sent": "This is just to show.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the estimated distance against the true distance and there you can see that we have some bias we can prove.",
                    "label": 0
                },
                {
                    "sent": "Actually you can compute the buyers that the estimated distance are, underestimate the true distances.",
                    "label": 1
                },
                {
                    "sent": "Unlike in having a busy.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can combine this technique, which is a measurement based technique, so it's a competitor actually have the generation technique.",
                    "label": 0
                },
                {
                    "sent": "We can combine this measurement based technique jointly with across container so it is a partitioning technique so at the cost level you separate the feature space using across container partition technique like Nilles Edge.",
                    "label": 0
                },
                {
                    "sent": "Then instead of going back to the original vectors you simply rely on this.",
                    "label": 0
                },
                {
                    "sent": "Product contains a distance estimation.",
                    "label": 0
                },
                {
                    "sent": "To find the nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "The typical timings is to query the data set of two billion vectors forgiven query vector.",
                    "label": 1
                },
                {
                    "sent": "It takes 3 to 5 minutes ago.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a much better than the spectral Sheen of narration technique.",
                    "label": 0
                },
                {
                    "sent": "You can trust me.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this, the author application of product Azatian also context that they will detail.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because I'm going out of time, just saying one thing which is very important, I believe is that product authorization is actually a way to compute an approximate inner product.",
                    "label": 0
                },
                {
                    "sent": "So it can be used in any context where you want to compute the inner product between one vector on big set of vectors.",
                    "label": 1
                },
                {
                    "sent": "Every matrix vector multiplication can be used on the metrics is compressed actually, so it has been used.",
                    "label": 1
                },
                {
                    "sent": "That's been used six 6:30, for instance, for learning in the compressed domain on their work, concurrent rules that actually use the same ID to improve the.",
                    "label": 0
                },
                {
                    "sent": "So this is a different products, different way of using it.",
                    "label": 0
                },
                {
                    "sent": "But both use public quantization to approximate matrix vector manipulation.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, on this has been so the message of this part is just that.",
                    "label": 0
                },
                {
                    "sent": "It's very important to consider.",
                    "label": 0
                },
                {
                    "sent": "Indexing jointly with image representation because it shouldn't make large scale image search on even larger.",
                    "label": 1
                },
                {
                    "sent": "You need efficient technique which are memory aware like product azatian we have tested it on many many set up text scripter or descriptor.",
                    "label": 1
                },
                {
                    "sent": "Any kind of descriptor which is compared with the equivalent distance on which actually is interesting.",
                    "label": 0
                },
                {
                    "sent": "Because now that we have this specific embedding technique that try to cast any kernel.",
                    "label": 0
                },
                {
                    "sent": "Into space where you can simply using your product, it means that you can basically use product integration event for.",
                    "label": 0
                },
                {
                    "sent": "Collapse.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and now I'm going to be sending you plates, but I will come.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Should.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned my talk back off road and some extension on how we can make larger image search with one level aggregation mechanism on efficient indexing.",
                    "label": 1
                },
                {
                    "sent": "Basically I have presented the part separately but very efficient indexing system on very large scale is the only thing that you have to do is to you is to use.",
                    "label": 0
                },
                {
                    "sent": "Jointly, this novel aggregation mechanism with efficient indexing technique which is going to impact your descriptor or descriptor into a few number of bytes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you have this large scale setup which seems to state of the art, which should still represent each individual descriptors on exploit, some matching some extension for better matching, reconquer expansion on a larger scale.",
                    "label": 0
                },
                {
                    "sent": "This is not possible because of the memory constraint is also strong limitation, but you can still a very good result by using surface structure follow as usual, but I would suggest you use dense because.",
                    "label": 0
                },
                {
                    "sent": "In this setup, you not explore this positives injected file, so you should use dense something because it's better as well basically.",
                    "label": 0
                },
                {
                    "sent": "Some improve aggregation algorithm, so cannot import a program on an efficient Dixon technique that is going to compress your descriptor on allows you to perform the search in the compressed domain.",
                    "label": 0
                },
                {
                    "sent": "The shoes payments are on up to 10,000,000 images.",
                    "label": 0
                },
                {
                    "sent": "With some descriptor of.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is represented by only 16 bytes byproduct quantization on top of feature.",
                    "label": 0
                },
                {
                    "sent": "You can have some of which are relatively good compared to, which is obtained by biographer representation.",
                    "label": 0
                },
                {
                    "sent": "So there they go through on.",
                    "label": 0
                },
                {
                    "sent": "Unless you increase number of bytes have more budget, you can early reach the performance as a whole representation.",
                    "label": 0
                },
                {
                    "sent": "There's a continuum between the descriptor on the compressed version of the descriptor, and you can use any intermediate approaching point actually.",
                    "label": 0
                },
                {
                    "sent": "Just to mention exists, sure search is not that slow.",
                    "label": 0
                },
                {
                    "sent": "7 sagon in this case for a set of vectors until noon images.",
                    "label": 0
                },
                {
                    "sent": "So you can set up is the dimension key of the vector is not too big.",
                    "label": 0
                },
                {
                    "sent": "You can still use exhaustive search on now I will just mention that we have done some experiment on up to 100 million descriptors.",
                    "label": 1
                },
                {
                    "sent": "On that using.",
                    "label": 0
                },
                {
                    "sent": "I get in this crypto compresses much better than using some descriptor.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compressed",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I love you.",
                    "label": 0
                },
                {
                    "sent": "Already mentioned that I think that the future of image search and supervisor is to use supervised technique to improve it.",
                    "label": 0
                },
                {
                    "sent": "So is awesome recent paper for instance that tried to.",
                    "label": 0
                },
                {
                    "sent": "Bring some annotation from image.",
                    "label": 0
                },
                {
                    "sent": "Net learning supervised way onto playita.",
                    "label": 0
                },
                {
                    "sent": "For general image search on.",
                    "label": 0
                },
                {
                    "sent": "Actually this gives good.",
                    "label": 0
                },
                {
                    "sent": "This gives some very good results.",
                    "label": 0
                },
                {
                    "sent": "On this is I will finish with.",
                    "label": 0
                },
                {
                    "sent": "This slide on the free demo if given time.",
                    "label": 0
                },
                {
                    "sent": "Free, I have given some tools to under very large scale data set in this tutorial mentioned about some extension of the back.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Refer them on why we should also increase Biostatistics.",
                    "label": 0
                },
                {
                    "sent": "To improve the results on also to get some descriptor which can be compressed efficiently using dimensional reduction on the compressed domain.",
                    "label": 0
                },
                {
                    "sent": "Indexing on the message that very large limit search.",
                    "label": 0
                },
                {
                    "sent": "You can do it and we limited resources do not need a cluster to participate to image net you do not need to have very strong machine.",
                    "label": 0
                },
                {
                    "sent": "I think that today we have the tools to have state of the art results with regular machines.",
                    "label": 1
                },
                {
                    "sent": "Evan's University.",
                    "label": 0
                },
                {
                    "sent": "So basically, this promotion you have done searching 100 images takes only two 5.",
                    "label": 0
                },
                {
                    "sent": "It is about 200 minutes ago and of course you have to 1st struggle descriptor, which is maybe the bottleneck in this setup, but the rest is quite quite fast.",
                    "label": 0
                },
                {
                    "sent": "On to show that these are not only words, but also that it works really in practice.",
                    "label": 0
                },
                {
                    "sent": "If it works because the demo is maybe idle, no, it's OK.",
                    "label": 0
                },
                {
                    "sent": "So this is my image search server, so there I have my indexing algorithm which is implemented on my laptop.",
                    "label": 0
                },
                {
                    "sent": "In my Mac it is not even an I5 occurrences order one and I have 10 images which are stored on the disk because they cannot fit on the hard drive of the machine.",
                    "label": 0
                },
                {
                    "sent": "I can perform search in here times there the only thing which is already done there is extraction of descriptors which is already done before the demo.",
                    "label": 0
                },
                {
                    "sent": "But there's a search in the United File is performed on the fly.",
                    "label": 0
                },
                {
                    "sent": "So what you can see is that first it is very fast.",
                    "label": 0
                },
                {
                    "sent": "They.",
                    "label": 0
                },
                {
                    "sent": "You know, it's the invariants.",
                    "label": 0
                },
                {
                    "sent": "Of the local descriptor.",
                    "label": 0
                },
                {
                    "sent": "So in this case we use send final descriptor to describe the images.",
                    "label": 0
                },
                {
                    "sent": "You can under strong change.",
                    "label": 0
                },
                {
                    "sent": "If you knew points.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a regular image search technique, you will think probably, but as you can see.",
                    "label": 1
                },
                {
                    "sent": "OK, sorry.",
                    "label": 0
                },
                {
                    "sent": "It's gonna be fast.",
                    "label": 0
                },
                {
                    "sent": "OK the timing is.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "The timing is about 20 minutes ago on the regular machine 1 core on so it is linear and the number of image.",
                    "label": 0
                },
                {
                    "sent": "On the thing you have to know about this is that each image there is represented in memory by 21 bytes, 21 bytes per memory.",
                    "label": 0
                },
                {
                    "sent": "So it means that the full index used to make present this result.",
                    "label": 0
                },
                {
                    "sent": "It takes about 200 megabytes, so I could even go to 100 millions images on this laptop because I have 4 gigabytes of memory.",
                    "label": 0
                },
                {
                    "sent": "The things that I cannot find final disk where I could fit 100 million images.",
                    "label": 0
                },
                {
                    "sent": "But you can.",
                    "label": 0
                },
                {
                    "sent": "You can already scheduled.",
                    "label": 0
                },
                {
                    "sent": "Of course it is the extreme point.",
                    "label": 1
                },
                {
                    "sent": "If you want better result, you should use more memory.",
                    "label": 0
                },
                {
                    "sent": "But still I want just to show one example that does not work, otherwise it is not fair, right?",
                    "label": 0
                },
                {
                    "sent": "This does not work.",
                    "label": 0
                },
                {
                    "sent": "In this 21 bytes support and taken by the Apple logo is of course too small.",
                    "label": 0
                },
                {
                    "sent": "You have this results show return which or not correct, but in the same time compared to regular matching you have some better results and queries like OK like this ones baby.",
                    "label": 0
                },
                {
                    "sent": "You have some babies and will return on his back off road.",
                    "label": 0
                },
                {
                    "sent": "You get very crappy results with this query even if user very strong matching system because it is more semantic and is able to absorb more ability.",
                    "label": 0
                },
                {
                    "sent": "So there you have an outlier, but these are baby cats so I would say that it may be considered correct.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}