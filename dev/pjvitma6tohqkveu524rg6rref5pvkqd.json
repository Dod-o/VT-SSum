{
    "id": "pjvitma6tohqkveu524rg6rref5pvkqd",
    "title": "A Session-based Approach for Aligning Large Ontologies",
    "info": {
        "author": [
            "Patrick Lambrix, Department of Computer and Information Science, Link\u00f6ping University"
        ],
        "published": "July 8, 2013",
        "recorded": "May 2013",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2013_lambrix_large_ontologies/",
    "segmentation": [
        [
            "I'm going to talk about work together with Rajaram, Caliope, Omar."
        ],
        [
            "Um?",
            "By now everybody knows that their ontologies that there's always with overlapping information and for various reasons it's important to know the intern teologie relationships.",
            "So."
        ],
        [
            "Or given to ontologies."
        ],
        [
            "Defining these relationships.",
            "Will be ontology alignment.",
            "For the remainder of the talk, I will say a little bit about the state of the art.",
            "Do not reduce our new framework.",
            "Discuss and implement the system and some experience that we have done."
        ],
        [
            "So most of the current systems can be seen as an instantiation of this alignment framework.",
            "As input, we have a number of ontologies.",
            "Output is an alignment, a set of correspondences or mappings.",
            "There are a number of components.",
            "The preprocessing component may select features that are interesting for alignment, or they may try to reduce the search space instead of looking at all pairs of terms that want that you want to compare, you may reduce the search space.",
            "We have matters which compute similarity values between different terms in the different ontologies, and this may be the results of these matches may be combined and filtered in different ways to get mapping suggestions.",
            "Very common way to combine is a weighted sum combination or a maximum based approach.",
            "Most common way to filter is a single threshold filtering approach where.",
            "Pairs of terms with a similarity value higher or equal than a given threshold or retained as mapping suggestions.",
            "And up to now, this is what ontology evaluation, alignment, initiative have been evaluating.",
            "Then there is also a second part where the mapping suggestions can be validated by a user.",
            "There may also be some kind of conflict checking and then the accepted and rejected suggestions can also be used for the next iteration step for alignment process.",
            "And there are a number of auxiliary sources that can be used."
        ],
        [
            "Larger Roman powerful have given us some challenges for aligning large ontologies.",
            "One of the challenges is scalability.",
            "What to do when the apologies get large?",
            "How to create systems that can deal with these and solutions can?",
            "Be based on, for instance, optimizing the matter matters.",
            "Or it could be by reducing the search space.",
            "Another problem is support for metric selection combination and tuning.",
            "It still not very clear which kind of algorithms are good for which kind of ontologies.",
            "We can use.",
            "We should choose background information, not just the auxiliary sources, but this could also include reusing partial results.",
            "And there is a need for user involvement in maybe more of the steps of the ontology alignment process."
        ],
        [
            "So we are proposing a session based framework to tackle some of these sessions these challenges.",
            "Our sessions on its own doesn't sound very innovative, but by introducing sessions and by introducing the kinds of sessions that we propose, we will be able to tackle these challenges and we will be able to do things that we haven't seen in ontology alignment systems up to now."
        ],
        [
            "So will introduce three kinds of sessions.",
            "We have computation sessions, validation sessions, and recommendation sessions.",
            "And one of the.",
            "Characteristics of these stations is that they are interruptible as inputs for a system, we still have the ontologies and output is still in alignment.",
            "So if we look at the computation sessions there, we're doing what almost all the systems are doing.",
            "Nowadays we do the preprocessing, the matching, the combining and the filtering and result of a computation session is a set of mapping suggestions.",
            "Now, these computation sessions are interruptible, so we actually don't have to wait until the complete computation is available.",
            "Later on we can restart the computation where we.",
            "Ended the last time.",
            "Or we can actually do new computations.",
            "In the validation session, the domain expert is going to validate the mapping suggestions.",
            "The ones that will be validated as correct will be part of the alignment and the ones that are valid to be wrong will not be, but they may be used invalid in computation sessions.",
            "An recommendation sessions.",
            "So validation sessions can also be interrupted or domain expert will not have to go through all the lists of possible suggestions.",
            "But you can interrupt and restart at that point.",
            "Or maybe new computation has appeared and will look at a new list of mapping suggestions.",
            "Further, we have the recommendation sessions where the idea is that this component will recommend settings for the computation sessions, so settings for which preprocessing, matching combination of filtering algorithms to use."
        ],
        [
            "And this will help us in these five challenges.",
            "We have scalability where we have the interruptible session so you don't have to do all the work at the same time.",
            "We will have partial computations and partial validations, and we will also see that by using partial validations we will be able to reduce the search space.",
            "Commendation Sessions will give us support for Metro selection, combination and tuning.",
            "We are going to use background information by using partial results in the computation and recommendation.",
            "And the user will be involved directly in the setting process and the validation, but by using validation decisions also in the computation and recommendation sessions.",
            "I will give examples of all of these."
        ],
        [
            "By showing our implemented system."
        ],
        [
            "We are using a number of databases.",
            "We have the session management database where we store information about the sessions and therefore the user ontologies to validated mappings to non validated mappings and it can be multiple sessions for one alignment process.",
            "We also have a similarity values database where for each pair of terms and for each matcher we will store the similarity value computed by that measure and this can be done during the computation sessions, but also during the recommendation sessions are one such a similarity value has been computed.",
            "We will never have to recompute it.",
            "We also have a database about the mapping decisions, which one of the mapping suggested were validated to be correct and which ones were validated be wrong and also a database with information about the recommendation strategies."
        ],
        [
            "So if you look at the computation."
        ],
        [
            "Ponente when a computation start, the user can decide whether to want to use pre process data.",
            "I'm going to decide which matches to use, and we have two different ways to combine them.",
            "The way that some combination and in this case the ways can be added there, or the maximum based combination.",
            "We also have a number of filtering approach is the most common one is the single threshold, but we have also something called the double threshold filtering approach.",
            "The computation sessions can be interrupted, and it could be.",
            "Before hand said that after how many similarity values that are computed?",
            "For instance, do you want to interrupt the session and is also possible to use recommendations from previous runs?"
        ],
        [
            "So if you look at the preprocessing stage."
        ],
        [
            "We have implemented.",
            "An approach where we use a partial alignment.",
            "So this means mapping suggestions that were validated to be correct.",
            "We use a partial alignment preprocessing step and the idea is that we're going to use these mappings in the partial alignment to partition the ontology into mappable groups."
        ],
        [
            "So here's an example.",
            "We have these two ontologies.",
            "Here we have a partial alignment.",
            "Within this partial alignment, we're going to look for something that we call a consistent group, an inconsistent group.",
            "In this case, for each pairs in this consistent group this property holds.",
            "So if A and a prime an BMB primary equivalence mappings, and you know that a is a B in the first ontology, then you would like that as a B is a prime is a big problem in the second ontology.",
            "I.",
            "So what we're going to do is.",
            "Yeah, compute a consistent group within this partial alignment and we can check that the property holds for 6D and 2B.",
            "We see that six is a subconcept of two in the first ontology too is mapped to B6, is mapped to D and here we also have the subconcept relation, so the property holds in this case."
        ],
        [
            "Now for each of the mappings in this consistent group, we partition the ontology in two parts.",
            "First, the concepts which are sub concepts of the.",
            "Concept in the mapping and the rest.",
            "When you do this for each of the mappings in the in the consistent group.",
            "You will retrieve partition of the ontologies and here we get unmappable groups.",
            "So for instance if we want to find mappings for 11, we only should look into.",
            "This part of the ontology.",
            "And in this example, five could only be mapped to E."
        ],
        [
            "For the matches, we used some matches from our previous sample system.",
            "We have an angram matcher.",
            "We have term basic which includes a few string matching algorithms.",
            "Term WN is termed basic, but we also look into word.",
            "Net for subsumption relationships.",
            "Human less asked the unified medical language system for suggestions.",
            "A naive Bayes is an instance based approach where we use documents from pub med's instances for a concept in our ontology and we define a similarity between the concepts based on the instances of the documents that talk about this.",
            "Concepts."
        ],
        [
            "We use the tool."
        ],
        [
            "Who?",
            "Very common combination strategies.",
            "The weighted sum and the maximum based approach."
        ],
        [
            "For the film."
        ],
        [
            "We have a single threshold filtering.",
            "The most common one and the double threshold filtering."
        ],
        [
            "And the idea of the double threshold filtering is is following.",
            "When we use single threshold, when you have a high threshold, usually you get very good precision but maybe not so good recall.",
            "When you load thresholds, usually you get good recall, but maybe not so good precision.",
            "So this approach tries to combine the advantages of both low threshold and high thresholds.",
            "So concept pairs with the similarity value above the upper threshold are retained as suggestions.",
            "Council pairs with similar value below the lower threshold are discarded, and for the ones in between we check whether that makes sense with respect to the structure of the ontologies and the ones with the high similarity value.",
            "So for instance, if we look at 5E.",
            "What we see is that five is a subconcept of two.",
            "Two is suggested to be mapped to be and then we see that E is a sub counts of B, so this makes sense with respect to the structure.",
            "However, if we look at 5C, we see that five is a subconcept of two, but C is not a subconcept of B05C does not make sense with respect to structure and would be discarded.",
            "We also have a strategy that removes mapping suggestions that conflict with already validated to be correct mappings, and we have a version of the double threshold filtering approach where instead of.",
            "Finding a consistent group here we would use a partial alignment."
        ],
        [
            "The domain expert will validate the mapping suggestions and they can accept it as equivalence relation as subconcept relations or just reject the mappings."
        ],
        [
            "We"
        ],
        [
            "Lamented three different recommendation strategies.",
            "The first one was proposed before the idea here is that I'm going to graph."
        ],
        [
            "Cool.",
            "Sleights, the idea is that we have the two ontologies and now we select small pieces of these ontologies.",
            "Then we generate.",
            "The correct alignments and here you would need a domain expert or an Oracle.",
            "Then we run all the strategies that I have, only small.",
            "Segments and check how well they're doing.",
            "On the small segments and based on that, we're going to suggest which strategies to use."
        ],
        [
            "A second approach is to evaluate the alignment algorithms on previous validation decisions.",
            "An recommend based on this."
        ],
        [
            "And the third approach combines these two.",
            "We're going to select small segments of Donatella, Geez.",
            "Evaluate the algorithms on the segments.",
            "But based on what we already validated before?",
            "And then recommend based on this."
        ],
        [
            "So approach one is based on full knowledge of the mappings in small pieces of the ontologies.",
            "The disadvantage may be that you need a domain expert on Oracle.",
            "And a worry could be that good performance for segments does not necessarily lead to good performance for the whole ontologies.",
            "In approaches two and three, you don't have full knowledge of the mappings or not necessarily.",
            "But you don't need a domain expert on Oracle and Vantage.",
            "Maybe that the validation decisions can come from different pieces of the ontology."
        ],
        [
            "So I will show you some experiment result."
        ],
        [
            "And this will be both as an ontology alignment system like.",
            "Yes, it's feasible to have such a system.",
            "And then for some of them we also used the system as an evaluation system for strategies."
        ],
        [
            "As a data, we used anatomy track of the AI.",
            "Where two anthologies about 3000 concepts reference alignment is given a 15116 equivalence mappings.",
            "We used the five matches that I've shown you.",
            "The two most common combination strategies, the single double threshold filter approach, different threshold for those, and this would leave to 4872 strategies."
        ],
        [
            "For each of the strategies, we know which matches are used.",
            "If it's a combination strategy strategy, then wait contamination strategy.",
            "Do you know waits for the different metrics?",
            "And here we used only one and two, but it could also be the maximum based approach.",
            "Then we have the thresholds for the single and double threshold filtering approach.",
            "So if it's two thresholds, that means it was the double threshold filtering approach.",
            "We check the correct suggestion, wrong suggestions.",
            "Computed F measure and jakarr similarity.",
            "There was a good correlation between these two, but the car similarity in this case was a bit more sensitive.",
            "And what we see is of these over 4000 strategies.",
            "The top ten strategies were actually all weighted combination and double threshold filtering strategies."
        ],
        [
            "The actual tests were done on three strategies, AS one is the top ranked strategy overall, a S2 is a reasonable strategy and AS 3 is a pretty bad strategy."
        ],
        [
            "So the first time we did was is Sessions going to help in reducing timing.",
            "And here in this case we have stored about 10% of the total available pairs.",
            "So in total there are over 9 million pairs.",
            "So we have calculated the ngram similarities and it takes 2.59.",
            "And then in this case this would be if you start from scratch and here it is if you have already started these 10% and now do an additional 10%.",
            "So you see you will get performance gains an for the more complex strategies.",
            "This would be up to 25%."
        ],
        [
            "Here we looked at the filtering using validated correct mappings, so you remove all the mapping suggestions that conflict with the ones that you've already validated to be correct.",
            "So if you've already processed 500.",
            "Then for a S 156 of the remaining mapping suggestions would be removed.",
            "Now, this is actually a strategy that we think you should always do so when we implemented it every time we have validated mapping suggestion as being correct, we will remove those so we don't wait 500 suggestions and this will then reduce unnecessary user interaction."
        ],
        [
            "In this case, we look at the double threshold filtering approach using validated mappings.",
            "So the idea here is to remove suggestions.",
            "Using this double threshold filtering approach and we look both at the original technologies andsome repair technologies during the first talk, you heard that we did find incorrect mappings, and missing is relations in the reference in the reference alignment and ontologies.",
            "So what we did here is that we just added the ones that were missing to the ontologies.",
            "That's why we have two values into cells here.",
            "So if you look at a S3 for instance, after having processed 500 mapping suggestions.",
            "And then we run the double threshold filtering approach.",
            "We will actually remove 279 in the repaired ontologies of which one was actually correct.",
            "So we remove.",
            "278 wrong mapping suggestions, but we also removed one correctly."
        ],
        [
            "Regarding the recommendations, this is not really an evaluation of the system, but this is more an evaluation of the actual strategies because we had a session based approach, we could now do this kind of evaluation.",
            "So the first recommendation approach is actually session independent.",
            "You use these segment pairs and use an Oracle.",
            "And of course there's no change during the process done.",
            "And the quality of this recommendation is heavily dependent on the original segments that you used."
        ],
        [
            "For the two session based approaches, approach two and three.",
            "In the first one, we did use the validation decisions only, so no segments.",
            "And what we found was that the recommendation is actually not good for AES one, which is the top ranked strategy.",
            "And the problem that we found was that during the recommendation it was re running the double threshold filtering approach and picked segments that didn't work very well for as one.",
            "However for the worst approach the best approach was actually suggested as a recommendation.",
            "In the third approach, we use the segments and then validate based on the validation decisions for the mappings in the segments.",
            "And here again, for the best strategy.",
            "The recommendation was not very good and the reason is that this best strategy is doing so well that you almost don't get any bad suggestions for this strategy.",
            "So we lack negative examples.",
            "For all the strategies, however, the more.",
            "Validations have done the better.",
            "The recommendation will be in the end."
        ],
        [
            "So in conclusion, I.",
            "Showed you a session based framework where we have computation validation recommendation sessions which are interruptible.",
            "We were able to address several of the challenges for.",
            "Aligning large ontologies.",
            "We have implemented system.",
            "We have some lessons learned from the experiments.",
            "And."
        ],
        [
            "For the future work, we will focus mainly on these two parts.",
            "The first is the use of the validation results in the computation and recommendation.",
            "At the moment we have mainly used.",
            "Validation decisions where the mapping suggestion was correct.",
            "But we will.",
            "We have already done some experiments where we can introduce also negative.",
            "Locations and these help actually in the performance of the algorithms and we also saw that the current strategies for recommendation.",
            "They are quite good if you start with a not so good strategy, but if you're lucky and already had the best strategy, then.",
            "Exactly very difficult to to keep that strategy in the recommendation.",
            "I have a very short question which is a.",
            "So now in the previous talk we had the presentation of benchmark for interactive matters.",
            "Here you seems to have quite some tools for building interactive matters, and so do you have a tool ready to enter this competition?",
            "Oh yes or no.",
            "The problem is I don't have my programmer anymore.",
            "OK, too bad.",
            "I had another question you.",
            "Presented a panel of result and you mentioned that I don't know which correlation you used was more sensible than if measure and indeed F measure was not sensible at all.",
            "That will.",
            "Basically, if you reduce to 2 digits, it's always the same value on all your table.",
            "But if measure is for me it is closer than what the user expects.",
            "Not so.",
            "So this means that, well, maybe you make can make this is also related to the first presentation before but or the second one that you can indeed in depth identify some difference in the system.",
            "But if in the end what is presented to the user in the end is the same, it doesn't matter much, so it's not exactly one of the problems is that when these measures are quite similar and specially in the recommendation part.",
            "Then you may actually have quite bad matches which perform equally well.",
            "Then the very good matches on small pieces and so for recommendation is actually very important to be able to distinguish both.",
            "And did you look into precision and recall to see if there were?",
            "Yes, we actually differences, or if there were the same as well, there were we had five or six different measures that we have, which is which are in the paper.",
            "But these were the most relevant and I show it easier.",
            "Other questions.",
            "Nobody else, well, I can ask question then when looking at this system and the session ID and everything, it leads me to think about more collaborative work at the moment as I understand that the system is more or less one person does this work.",
            "So have you any idea of extending to to collaboratively?",
            "Like that would be one idea.",
            "I think the first step we're going to look at is paralyzing.",
            "Some of these computations so that these things are go faster, but yes.",
            "OK, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about work together with Rajaram, Caliope, Omar.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "By now everybody knows that their ontologies that there's always with overlapping information and for various reasons it's important to know the intern teologie relationships.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or given to ontologies.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Defining these relationships.",
                    "label": 0
                },
                {
                    "sent": "Will be ontology alignment.",
                    "label": 0
                },
                {
                    "sent": "For the remainder of the talk, I will say a little bit about the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Do not reduce our new framework.",
                    "label": 0
                },
                {
                    "sent": "Discuss and implement the system and some experience that we have done.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So most of the current systems can be seen as an instantiation of this alignment framework.",
                    "label": 0
                },
                {
                    "sent": "As input, we have a number of ontologies.",
                    "label": 0
                },
                {
                    "sent": "Output is an alignment, a set of correspondences or mappings.",
                    "label": 0
                },
                {
                    "sent": "There are a number of components.",
                    "label": 0
                },
                {
                    "sent": "The preprocessing component may select features that are interesting for alignment, or they may try to reduce the search space instead of looking at all pairs of terms that want that you want to compare, you may reduce the search space.",
                    "label": 0
                },
                {
                    "sent": "We have matters which compute similarity values between different terms in the different ontologies, and this may be the results of these matches may be combined and filtered in different ways to get mapping suggestions.",
                    "label": 0
                },
                {
                    "sent": "Very common way to combine is a weighted sum combination or a maximum based approach.",
                    "label": 0
                },
                {
                    "sent": "Most common way to filter is a single threshold filtering approach where.",
                    "label": 0
                },
                {
                    "sent": "Pairs of terms with a similarity value higher or equal than a given threshold or retained as mapping suggestions.",
                    "label": 0
                },
                {
                    "sent": "And up to now, this is what ontology evaluation, alignment, initiative have been evaluating.",
                    "label": 0
                },
                {
                    "sent": "Then there is also a second part where the mapping suggestions can be validated by a user.",
                    "label": 0
                },
                {
                    "sent": "There may also be some kind of conflict checking and then the accepted and rejected suggestions can also be used for the next iteration step for alignment process.",
                    "label": 0
                },
                {
                    "sent": "And there are a number of auxiliary sources that can be used.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Larger Roman powerful have given us some challenges for aligning large ontologies.",
                    "label": 1
                },
                {
                    "sent": "One of the challenges is scalability.",
                    "label": 0
                },
                {
                    "sent": "What to do when the apologies get large?",
                    "label": 0
                },
                {
                    "sent": "How to create systems that can deal with these and solutions can?",
                    "label": 0
                },
                {
                    "sent": "Be based on, for instance, optimizing the matter matters.",
                    "label": 0
                },
                {
                    "sent": "Or it could be by reducing the search space.",
                    "label": 0
                },
                {
                    "sent": "Another problem is support for metric selection combination and tuning.",
                    "label": 1
                },
                {
                    "sent": "It still not very clear which kind of algorithms are good for which kind of ontologies.",
                    "label": 0
                },
                {
                    "sent": "We can use.",
                    "label": 0
                },
                {
                    "sent": "We should choose background information, not just the auxiliary sources, but this could also include reusing partial results.",
                    "label": 0
                },
                {
                    "sent": "And there is a need for user involvement in maybe more of the steps of the ontology alignment process.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we are proposing a session based framework to tackle some of these sessions these challenges.",
                    "label": 0
                },
                {
                    "sent": "Our sessions on its own doesn't sound very innovative, but by introducing sessions and by introducing the kinds of sessions that we propose, we will be able to tackle these challenges and we will be able to do things that we haven't seen in ontology alignment systems up to now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So will introduce three kinds of sessions.",
                    "label": 0
                },
                {
                    "sent": "We have computation sessions, validation sessions, and recommendation sessions.",
                    "label": 0
                },
                {
                    "sent": "And one of the.",
                    "label": 0
                },
                {
                    "sent": "Characteristics of these stations is that they are interruptible as inputs for a system, we still have the ontologies and output is still in alignment.",
                    "label": 0
                },
                {
                    "sent": "So if we look at the computation sessions there, we're doing what almost all the systems are doing.",
                    "label": 0
                },
                {
                    "sent": "Nowadays we do the preprocessing, the matching, the combining and the filtering and result of a computation session is a set of mapping suggestions.",
                    "label": 0
                },
                {
                    "sent": "Now, these computation sessions are interruptible, so we actually don't have to wait until the complete computation is available.",
                    "label": 0
                },
                {
                    "sent": "Later on we can restart the computation where we.",
                    "label": 0
                },
                {
                    "sent": "Ended the last time.",
                    "label": 0
                },
                {
                    "sent": "Or we can actually do new computations.",
                    "label": 0
                },
                {
                    "sent": "In the validation session, the domain expert is going to validate the mapping suggestions.",
                    "label": 0
                },
                {
                    "sent": "The ones that will be validated as correct will be part of the alignment and the ones that are valid to be wrong will not be, but they may be used invalid in computation sessions.",
                    "label": 0
                },
                {
                    "sent": "An recommendation sessions.",
                    "label": 0
                },
                {
                    "sent": "So validation sessions can also be interrupted or domain expert will not have to go through all the lists of possible suggestions.",
                    "label": 0
                },
                {
                    "sent": "But you can interrupt and restart at that point.",
                    "label": 0
                },
                {
                    "sent": "Or maybe new computation has appeared and will look at a new list of mapping suggestions.",
                    "label": 0
                },
                {
                    "sent": "Further, we have the recommendation sessions where the idea is that this component will recommend settings for the computation sessions, so settings for which preprocessing, matching combination of filtering algorithms to use.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this will help us in these five challenges.",
                    "label": 0
                },
                {
                    "sent": "We have scalability where we have the interruptible session so you don't have to do all the work at the same time.",
                    "label": 0
                },
                {
                    "sent": "We will have partial computations and partial validations, and we will also see that by using partial validations we will be able to reduce the search space.",
                    "label": 0
                },
                {
                    "sent": "Commendation Sessions will give us support for Metro selection, combination and tuning.",
                    "label": 1
                },
                {
                    "sent": "We are going to use background information by using partial results in the computation and recommendation.",
                    "label": 1
                },
                {
                    "sent": "And the user will be involved directly in the setting process and the validation, but by using validation decisions also in the computation and recommendation sessions.",
                    "label": 0
                },
                {
                    "sent": "I will give examples of all of these.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By showing our implemented system.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are using a number of databases.",
                    "label": 0
                },
                {
                    "sent": "We have the session management database where we store information about the sessions and therefore the user ontologies to validated mappings to non validated mappings and it can be multiple sessions for one alignment process.",
                    "label": 1
                },
                {
                    "sent": "We also have a similarity values database where for each pair of terms and for each matcher we will store the similarity value computed by that measure and this can be done during the computation sessions, but also during the recommendation sessions are one such a similarity value has been computed.",
                    "label": 0
                },
                {
                    "sent": "We will never have to recompute it.",
                    "label": 0
                },
                {
                    "sent": "We also have a database about the mapping decisions, which one of the mapping suggested were validated to be correct and which ones were validated be wrong and also a database with information about the recommendation strategies.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you look at the computation.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ponente when a computation start, the user can decide whether to want to use pre process data.",
                    "label": 0
                },
                {
                    "sent": "I'm going to decide which matches to use, and we have two different ways to combine them.",
                    "label": 0
                },
                {
                    "sent": "The way that some combination and in this case the ways can be added there, or the maximum based combination.",
                    "label": 0
                },
                {
                    "sent": "We also have a number of filtering approach is the most common one is the single threshold, but we have also something called the double threshold filtering approach.",
                    "label": 0
                },
                {
                    "sent": "The computation sessions can be interrupted, and it could be.",
                    "label": 0
                },
                {
                    "sent": "Before hand said that after how many similarity values that are computed?",
                    "label": 0
                },
                {
                    "sent": "For instance, do you want to interrupt the session and is also possible to use recommendations from previous runs?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you look at the preprocessing stage.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have implemented.",
                    "label": 0
                },
                {
                    "sent": "An approach where we use a partial alignment.",
                    "label": 0
                },
                {
                    "sent": "So this means mapping suggestions that were validated to be correct.",
                    "label": 0
                },
                {
                    "sent": "We use a partial alignment preprocessing step and the idea is that we're going to use these mappings in the partial alignment to partition the ontology into mappable groups.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "We have these two ontologies.",
                    "label": 0
                },
                {
                    "sent": "Here we have a partial alignment.",
                    "label": 0
                },
                {
                    "sent": "Within this partial alignment, we're going to look for something that we call a consistent group, an inconsistent group.",
                    "label": 0
                },
                {
                    "sent": "In this case, for each pairs in this consistent group this property holds.",
                    "label": 1
                },
                {
                    "sent": "So if A and a prime an BMB primary equivalence mappings, and you know that a is a B in the first ontology, then you would like that as a B is a prime is a big problem in the second ontology.",
                    "label": 1
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, compute a consistent group within this partial alignment and we can check that the property holds for 6D and 2B.",
                    "label": 0
                },
                {
                    "sent": "We see that six is a subconcept of two in the first ontology too is mapped to B6, is mapped to D and here we also have the subconcept relation, so the property holds in this case.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now for each of the mappings in this consistent group, we partition the ontology in two parts.",
                    "label": 0
                },
                {
                    "sent": "First, the concepts which are sub concepts of the.",
                    "label": 0
                },
                {
                    "sent": "Concept in the mapping and the rest.",
                    "label": 1
                },
                {
                    "sent": "When you do this for each of the mappings in the in the consistent group.",
                    "label": 0
                },
                {
                    "sent": "You will retrieve partition of the ontologies and here we get unmappable groups.",
                    "label": 0
                },
                {
                    "sent": "So for instance if we want to find mappings for 11, we only should look into.",
                    "label": 0
                },
                {
                    "sent": "This part of the ontology.",
                    "label": 0
                },
                {
                    "sent": "And in this example, five could only be mapped to E.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the matches, we used some matches from our previous sample system.",
                    "label": 0
                },
                {
                    "sent": "We have an angram matcher.",
                    "label": 0
                },
                {
                    "sent": "We have term basic which includes a few string matching algorithms.",
                    "label": 0
                },
                {
                    "sent": "Term WN is termed basic, but we also look into word.",
                    "label": 0
                },
                {
                    "sent": "Net for subsumption relationships.",
                    "label": 0
                },
                {
                    "sent": "Human less asked the unified medical language system for suggestions.",
                    "label": 0
                },
                {
                    "sent": "A naive Bayes is an instance based approach where we use documents from pub med's instances for a concept in our ontology and we define a similarity between the concepts based on the instances of the documents that talk about this.",
                    "label": 0
                },
                {
                    "sent": "Concepts.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use the tool.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who?",
                    "label": 0
                },
                {
                    "sent": "Very common combination strategies.",
                    "label": 0
                },
                {
                    "sent": "The weighted sum and the maximum based approach.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the film.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a single threshold filtering.",
                    "label": 0
                },
                {
                    "sent": "The most common one and the double threshold filtering.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the idea of the double threshold filtering is is following.",
                    "label": 1
                },
                {
                    "sent": "When we use single threshold, when you have a high threshold, usually you get very good precision but maybe not so good recall.",
                    "label": 0
                },
                {
                    "sent": "When you load thresholds, usually you get good recall, but maybe not so good precision.",
                    "label": 0
                },
                {
                    "sent": "So this approach tries to combine the advantages of both low threshold and high thresholds.",
                    "label": 0
                },
                {
                    "sent": "So concept pairs with the similarity value above the upper threshold are retained as suggestions.",
                    "label": 0
                },
                {
                    "sent": "Council pairs with similar value below the lower threshold are discarded, and for the ones in between we check whether that makes sense with respect to the structure of the ontologies and the ones with the high similarity value.",
                    "label": 1
                },
                {
                    "sent": "So for instance, if we look at 5E.",
                    "label": 0
                },
                {
                    "sent": "What we see is that five is a subconcept of two.",
                    "label": 0
                },
                {
                    "sent": "Two is suggested to be mapped to be and then we see that E is a sub counts of B, so this makes sense with respect to the structure.",
                    "label": 0
                },
                {
                    "sent": "However, if we look at 5C, we see that five is a subconcept of two, but C is not a subconcept of B05C does not make sense with respect to structure and would be discarded.",
                    "label": 0
                },
                {
                    "sent": "We also have a strategy that removes mapping suggestions that conflict with already validated to be correct mappings, and we have a version of the double threshold filtering approach where instead of.",
                    "label": 0
                },
                {
                    "sent": "Finding a consistent group here we would use a partial alignment.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The domain expert will validate the mapping suggestions and they can accept it as equivalence relation as subconcept relations or just reject the mappings.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lamented three different recommendation strategies.",
                    "label": 0
                },
                {
                    "sent": "The first one was proposed before the idea here is that I'm going to graph.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cool.",
                    "label": 0
                },
                {
                    "sent": "Sleights, the idea is that we have the two ontologies and now we select small pieces of these ontologies.",
                    "label": 0
                },
                {
                    "sent": "Then we generate.",
                    "label": 0
                },
                {
                    "sent": "The correct alignments and here you would need a domain expert or an Oracle.",
                    "label": 0
                },
                {
                    "sent": "Then we run all the strategies that I have, only small.",
                    "label": 0
                },
                {
                    "sent": "Segments and check how well they're doing.",
                    "label": 0
                },
                {
                    "sent": "On the small segments and based on that, we're going to suggest which strategies to use.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A second approach is to evaluate the alignment algorithms on previous validation decisions.",
                    "label": 0
                },
                {
                    "sent": "An recommend based on this.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the third approach combines these two.",
                    "label": 0
                },
                {
                    "sent": "We're going to select small segments of Donatella, Geez.",
                    "label": 1
                },
                {
                    "sent": "Evaluate the algorithms on the segments.",
                    "label": 1
                },
                {
                    "sent": "But based on what we already validated before?",
                    "label": 0
                },
                {
                    "sent": "And then recommend based on this.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So approach one is based on full knowledge of the mappings in small pieces of the ontologies.",
                    "label": 1
                },
                {
                    "sent": "The disadvantage may be that you need a domain expert on Oracle.",
                    "label": 0
                },
                {
                    "sent": "And a worry could be that good performance for segments does not necessarily lead to good performance for the whole ontologies.",
                    "label": 1
                },
                {
                    "sent": "In approaches two and three, you don't have full knowledge of the mappings or not necessarily.",
                    "label": 1
                },
                {
                    "sent": "But you don't need a domain expert on Oracle and Vantage.",
                    "label": 0
                },
                {
                    "sent": "Maybe that the validation decisions can come from different pieces of the ontology.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will show you some experiment result.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this will be both as an ontology alignment system like.",
                    "label": 1
                },
                {
                    "sent": "Yes, it's feasible to have such a system.",
                    "label": 0
                },
                {
                    "sent": "And then for some of them we also used the system as an evaluation system for strategies.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a data, we used anatomy track of the AI.",
                    "label": 1
                },
                {
                    "sent": "Where two anthologies about 3000 concepts reference alignment is given a 15116 equivalence mappings.",
                    "label": 1
                },
                {
                    "sent": "We used the five matches that I've shown you.",
                    "label": 0
                },
                {
                    "sent": "The two most common combination strategies, the single double threshold filter approach, different threshold for those, and this would leave to 4872 strategies.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For each of the strategies, we know which matches are used.",
                    "label": 0
                },
                {
                    "sent": "If it's a combination strategy strategy, then wait contamination strategy.",
                    "label": 0
                },
                {
                    "sent": "Do you know waits for the different metrics?",
                    "label": 0
                },
                {
                    "sent": "And here we used only one and two, but it could also be the maximum based approach.",
                    "label": 0
                },
                {
                    "sent": "Then we have the thresholds for the single and double threshold filtering approach.",
                    "label": 0
                },
                {
                    "sent": "So if it's two thresholds, that means it was the double threshold filtering approach.",
                    "label": 0
                },
                {
                    "sent": "We check the correct suggestion, wrong suggestions.",
                    "label": 0
                },
                {
                    "sent": "Computed F measure and jakarr similarity.",
                    "label": 0
                },
                {
                    "sent": "There was a good correlation between these two, but the car similarity in this case was a bit more sensitive.",
                    "label": 0
                },
                {
                    "sent": "And what we see is of these over 4000 strategies.",
                    "label": 0
                },
                {
                    "sent": "The top ten strategies were actually all weighted combination and double threshold filtering strategies.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The actual tests were done on three strategies, AS one is the top ranked strategy overall, a S2 is a reasonable strategy and AS 3 is a pretty bad strategy.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first time we did was is Sessions going to help in reducing timing.",
                    "label": 0
                },
                {
                    "sent": "And here in this case we have stored about 10% of the total available pairs.",
                    "label": 0
                },
                {
                    "sent": "So in total there are over 9 million pairs.",
                    "label": 0
                },
                {
                    "sent": "So we have calculated the ngram similarities and it takes 2.59.",
                    "label": 0
                },
                {
                    "sent": "And then in this case this would be if you start from scratch and here it is if you have already started these 10% and now do an additional 10%.",
                    "label": 0
                },
                {
                    "sent": "So you see you will get performance gains an for the more complex strategies.",
                    "label": 0
                },
                {
                    "sent": "This would be up to 25%.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we looked at the filtering using validated correct mappings, so you remove all the mapping suggestions that conflict with the ones that you've already validated to be correct.",
                    "label": 1
                },
                {
                    "sent": "So if you've already processed 500.",
                    "label": 0
                },
                {
                    "sent": "Then for a S 156 of the remaining mapping suggestions would be removed.",
                    "label": 0
                },
                {
                    "sent": "Now, this is actually a strategy that we think you should always do so when we implemented it every time we have validated mapping suggestion as being correct, we will remove those so we don't wait 500 suggestions and this will then reduce unnecessary user interaction.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, we look at the double threshold filtering approach using validated mappings.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is to remove suggestions.",
                    "label": 0
                },
                {
                    "sent": "Using this double threshold filtering approach and we look both at the original technologies andsome repair technologies during the first talk, you heard that we did find incorrect mappings, and missing is relations in the reference in the reference alignment and ontologies.",
                    "label": 0
                },
                {
                    "sent": "So what we did here is that we just added the ones that were missing to the ontologies.",
                    "label": 0
                },
                {
                    "sent": "That's why we have two values into cells here.",
                    "label": 0
                },
                {
                    "sent": "So if you look at a S3 for instance, after having processed 500 mapping suggestions.",
                    "label": 1
                },
                {
                    "sent": "And then we run the double threshold filtering approach.",
                    "label": 0
                },
                {
                    "sent": "We will actually remove 279 in the repaired ontologies of which one was actually correct.",
                    "label": 0
                },
                {
                    "sent": "So we remove.",
                    "label": 0
                },
                {
                    "sent": "278 wrong mapping suggestions, but we also removed one correctly.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regarding the recommendations, this is not really an evaluation of the system, but this is more an evaluation of the actual strategies because we had a session based approach, we could now do this kind of evaluation.",
                    "label": 0
                },
                {
                    "sent": "So the first recommendation approach is actually session independent.",
                    "label": 0
                },
                {
                    "sent": "You use these segment pairs and use an Oracle.",
                    "label": 1
                },
                {
                    "sent": "And of course there's no change during the process done.",
                    "label": 1
                },
                {
                    "sent": "And the quality of this recommendation is heavily dependent on the original segments that you used.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the two session based approaches, approach two and three.",
                    "label": 0
                },
                {
                    "sent": "In the first one, we did use the validation decisions only, so no segments.",
                    "label": 1
                },
                {
                    "sent": "And what we found was that the recommendation is actually not good for AES one, which is the top ranked strategy.",
                    "label": 1
                },
                {
                    "sent": "And the problem that we found was that during the recommendation it was re running the double threshold filtering approach and picked segments that didn't work very well for as one.",
                    "label": 0
                },
                {
                    "sent": "However for the worst approach the best approach was actually suggested as a recommendation.",
                    "label": 0
                },
                {
                    "sent": "In the third approach, we use the segments and then validate based on the validation decisions for the mappings in the segments.",
                    "label": 0
                },
                {
                    "sent": "And here again, for the best strategy.",
                    "label": 0
                },
                {
                    "sent": "The recommendation was not very good and the reason is that this best strategy is doing so well that you almost don't get any bad suggestions for this strategy.",
                    "label": 0
                },
                {
                    "sent": "So we lack negative examples.",
                    "label": 0
                },
                {
                    "sent": "For all the strategies, however, the more.",
                    "label": 0
                },
                {
                    "sent": "Validations have done the better.",
                    "label": 0
                },
                {
                    "sent": "The recommendation will be in the end.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, I.",
                    "label": 0
                },
                {
                    "sent": "Showed you a session based framework where we have computation validation recommendation sessions which are interruptible.",
                    "label": 1
                },
                {
                    "sent": "We were able to address several of the challenges for.",
                    "label": 0
                },
                {
                    "sent": "Aligning large ontologies.",
                    "label": 0
                },
                {
                    "sent": "We have implemented system.",
                    "label": 0
                },
                {
                    "sent": "We have some lessons learned from the experiments.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the future work, we will focus mainly on these two parts.",
                    "label": 0
                },
                {
                    "sent": "The first is the use of the validation results in the computation and recommendation.",
                    "label": 1
                },
                {
                    "sent": "At the moment we have mainly used.",
                    "label": 0
                },
                {
                    "sent": "Validation decisions where the mapping suggestion was correct.",
                    "label": 0
                },
                {
                    "sent": "But we will.",
                    "label": 0
                },
                {
                    "sent": "We have already done some experiments where we can introduce also negative.",
                    "label": 0
                },
                {
                    "sent": "Locations and these help actually in the performance of the algorithms and we also saw that the current strategies for recommendation.",
                    "label": 0
                },
                {
                    "sent": "They are quite good if you start with a not so good strategy, but if you're lucky and already had the best strategy, then.",
                    "label": 0
                },
                {
                    "sent": "Exactly very difficult to to keep that strategy in the recommendation.",
                    "label": 0
                },
                {
                    "sent": "I have a very short question which is a.",
                    "label": 0
                },
                {
                    "sent": "So now in the previous talk we had the presentation of benchmark for interactive matters.",
                    "label": 0
                },
                {
                    "sent": "Here you seems to have quite some tools for building interactive matters, and so do you have a tool ready to enter this competition?",
                    "label": 0
                },
                {
                    "sent": "Oh yes or no.",
                    "label": 0
                },
                {
                    "sent": "The problem is I don't have my programmer anymore.",
                    "label": 0
                },
                {
                    "sent": "OK, too bad.",
                    "label": 0
                },
                {
                    "sent": "I had another question you.",
                    "label": 0
                },
                {
                    "sent": "Presented a panel of result and you mentioned that I don't know which correlation you used was more sensible than if measure and indeed F measure was not sensible at all.",
                    "label": 0
                },
                {
                    "sent": "That will.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you reduce to 2 digits, it's always the same value on all your table.",
                    "label": 0
                },
                {
                    "sent": "But if measure is for me it is closer than what the user expects.",
                    "label": 0
                },
                {
                    "sent": "Not so.",
                    "label": 0
                },
                {
                    "sent": "So this means that, well, maybe you make can make this is also related to the first presentation before but or the second one that you can indeed in depth identify some difference in the system.",
                    "label": 0
                },
                {
                    "sent": "But if in the end what is presented to the user in the end is the same, it doesn't matter much, so it's not exactly one of the problems is that when these measures are quite similar and specially in the recommendation part.",
                    "label": 0
                },
                {
                    "sent": "Then you may actually have quite bad matches which perform equally well.",
                    "label": 0
                },
                {
                    "sent": "Then the very good matches on small pieces and so for recommendation is actually very important to be able to distinguish both.",
                    "label": 0
                },
                {
                    "sent": "And did you look into precision and recall to see if there were?",
                    "label": 0
                },
                {
                    "sent": "Yes, we actually differences, or if there were the same as well, there were we had five or six different measures that we have, which is which are in the paper.",
                    "label": 0
                },
                {
                    "sent": "But these were the most relevant and I show it easier.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "Nobody else, well, I can ask question then when looking at this system and the session ID and everything, it leads me to think about more collaborative work at the moment as I understand that the system is more or less one person does this work.",
                    "label": 0
                },
                {
                    "sent": "So have you any idea of extending to to collaboratively?",
                    "label": 0
                },
                {
                    "sent": "Like that would be one idea.",
                    "label": 0
                },
                {
                    "sent": "I think the first step we're going to look at is paralyzing.",
                    "label": 0
                },
                {
                    "sent": "Some of these computations so that these things are go faster, but yes.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}