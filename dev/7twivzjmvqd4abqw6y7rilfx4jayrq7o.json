{
    "id": "7twivzjmvqd4abqw6y7rilfx4jayrq7o",
    "title": "Denoising of Natural Images: Optimality and Fundamental Lower Bounds",
    "info": {
        "author": [
            "Boaz Nadler, Weizmann Institute of Science"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_nadler_dni/",
    "segmentation": [
        [
            "The title of this workshop is machine learning meets computational photography.",
            "You could say that the title of this talk would be nonparametric statistics meets computational photography and.",
            "Joint work with Annette Levine and we had another collaborator that worked very hard with us, which was our computer cluster and you'll see in a minute why and.",
            "This talk is about image denoising, so I'm going to build upon the great talk that they payment gave and we're going to focus on.",
            "Optimality in image denoising how.",
            "Fire can you go?",
            "And maybe are we there yet Sir?"
        ],
        [
            "So.",
            "Uh, the setting that we're going to talk about is natural image denoising, and you should circle the word natural because I'm going to focus on images that I'm assuming have been taken.",
            "Are natural images.",
            "Think about all the collection of images of people have taken with their digital cameras or their phone cameras and you can download from Google Images or something.",
            "So there is an input noisy image why which is X plus noise in your goal is to denies it as best as possible.",
            "Estimate a noise free image.",
            "X hat.",
            "And it's a very intensively studied problem in the last 30 years or so many different algorithms.",
            "And.",
            "Of course, the fact that we assume that the image is a natural image means that you can use additional knowledge on how natural images behaves, and in particular about statistics of natural images.",
            "And the question is, how much can these come in?"
        ],
        [
            "Your help, so here's an example of several recent recent meaning in the last 10 years or so.",
            "Algorithms that, and their performance on a given image.",
            "So typically the measure of quality is PSNR, which is the higher.",
            "The value the better is that the noise in quality and so this is a Gaussian scale mixture and it has a value of 29.",
            "This is K SVD by Miquel ad that uses a sparse representation and also 29 point something.",
            "This is a different algorithm with 29.48.",
            "This is the BM 3D algorithm that payment mentioned, which is slightly better, and this is a yet refined version of a BM 3D.",
            "And what you do see other than the fact that the quality looks very similar is that also the numbers the mean squared error is very close to each other and.",
            "There are also many other algorithms which also give similar performance in such images, and the question is.",
            "How much better can you do or?",
            "We are what are fundamental lower bounds on denoising natural images.",
            "So how much can we improve query in denoising algorithms?",
            "What is optimal denoising?",
            "Can we define it in a rigorous way and?",
            "That also comes into has a more.",
            "A fundamental question of what are limits of natural image statistics for a variety of image processing tasks, deblurring deconvolution and other such problems.",
            "So we're going to use the framework of denoising to study this problem.",
            "Anne."
        ],
        [
            "And.",
            "If you're a PhD students, the question is should your PhD in in."
        ],
        [
            "Denoising so well denoising algorithms there have been a lot of them in terms of lower limits for denoising.",
            "In the signal processing applications that have been some work with the Wiener filter, Gaussian priors, Baker, another had the limit on super resolution.",
            "In the in the in the theoretical statistical literature that are very sharp bounds, but for I would not call them images, I would call them 2D arrays which are perfectly piecewise constant and and with the boundary which is known to be a smooth curve.",
            "So there very very sharp bound and what you can do in such a setting, but it's not necessarily very applicable for actual.",
            "For practically image denoising.",
            "Um?",
            "The non local newspapers by Bodison Morrell.",
            "They claim that if you had an infinitely large image than Uncle means would be a syntactically optimal in some sense and perhaps the most relevant work is the work that recent work by Chatterjee Milan, far that made certain assumptions on on the input image and gave a lower bounds based on the comment I lower bound, so we're going to do a slightly different set of assumptions.",
            "Then get slightly different lower bound and we can maybe if I have time I'll discuss a little bit of differences."
        ],
        [
            "So in order to discuss what is optimal in natural images and we need to introduce a statistical framework, and I'm not going to talk about all possible denoising approaches I'm going to, I'm going to restrict my discussion to denoising algorithms that take a central pixel look at the K by K window around it an denoise.",
            "A central pixel based on this K by K window.",
            "OK, so each pixel in you have your noisy image and you take a central pixel, you look at its K by K window around it and this is the only information you used to the noise you're not using.",
            "So you denies each pixel individually based on its K by K neighborhood, and we're also going to assume that the noise is Gaussian, but it can be a different noise as long as I know its probability density.",
            "And we are so the main.",
            "The key assumption is that.",
            "We are denoising an natural image, so in principle if you gave me the collection of 100 billion natural images or 100 hundred billion natural images, I could.",
            "Constructor there is an implicit generic natural image prior that would be the density of KBK patches of natural images.",
            "And.",
            "The quality of that work and we're going to look at it is the mean squared error.",
            "And of course, someone here mentioned that maybe that's not for visual purposes.",
            "The best quantity, but this is what people have been done, and this is something that is easy to work with.",
            "So that means cordera is the sum of all pixels in the image.",
            "Your estimate, yhat minus the true value.",
            "So C subset subscript C means for the center."
        ],
        [
            "Pixel of a Patch and.",
            "A key issue in their work is that you can view two different.",
            "You can view the mean squared error in two different ways.",
            "One is the L interpretation, so.",
            "You sample a cake, bake a Patch from the density P of X.",
            "You add noise to it, so now you have Y given X and then you try to denoise this Patch wise you get a Whitehead central minus X squared.",
            "You integrate dyd X this is.",
            "The mean squared error.",
            "If you do a change of the order of integration.",
            "You get a different formula which will be very useful for us.",
            "It's the variance interpretation and it goes as follows.",
            "You first sample and noisy Patch.",
            "Why you don't know what was the original underlying Patch X?",
            "Then you look at all possible XSS that could have generated this Y and you look at the variance yhat central minus XYDXDY.",
            "So in this representation as I've said, you start from a noisy Patch X which you know.",
            "Noise free Patch.",
            "Axino you added noise to it.",
            "You get Y and then you get a white hat and you look at this distance and you average over all possible such realizations, but in the variance of presentation.",
            "Given a noisy why there are many X is that could have given rise to this Y and you average over all of them so.",
            "Now.",
            "What's useful in the various interpretation is that you can easily derive from it what is the optimal estimator you just.",
            "The."
        ],
        [
            "Differentiate and you find that the optimistic."
        ],
        [
            "Later is just the mean.",
            "The conditional mean, and this is nothing but the Bayes minimal mean squared error estimator.",
            "So under our setting, if we knew the prior of Kabi can actual images, this is the best thing that one can do.",
            "Anne."
        ],
        [
            "And.",
            "If you plug it in, you get an explicit expression.",
            "What is the optimal minimal mean squared error achievable at each pixel?",
            "So there are several challenges.",
            "One is that this integral is intractable.",
            "It's a it's two integrals, each of which is K squared dimensional, and the second thing is that we don't know the density of natural images anyhow.",
            "So I would like to somehow estimate or lower bound this quantity without even without doing all of these integrations and without knowing P of X."
        ],
        [
            "Can you do it so?",
            "There is a trick, and the trick is that we don't know P, but we can sample from it.",
            "We can sample 100 billion patches and try to nonparametrically give an estimate of P and maybe from it estimate this minimal mean squared error.",
            "So that's what we're going to do and.",
            "What we're going to do is actually.",
            "Use a huge set of natural image patches an give two quantities, which as I will prove in a minute in a in a certain way, give lower and upper bounds on the minimal mean squared error.",
            "And if you're sampling is dense enough, these two quantities will coincide, and that's your optimal minimal achievable mean squared error."
        ],
        [
            "So the data that we used in the experiment that will describe later on is our training data, so to speak, is 10 to the 10 generic clean patches that were taken from the label me data set.",
            "But we don't use the label, just just images.",
            "And we took different images independent set of 2000 clean and noisy pairs of patches."
        ],
        [
            "A.",
            "And.",
            "So remember, this is the exact optimal.",
            "Estimator if I knew the density of X given Y or I can write it as such a fraction and what we're going to do is approximate that that those integrals by finite sums.",
            "So.",
            "This our estimator here Yhat is nothing but yet another valid denoising algorithm is just does it.",
            "Actually that it doesn't use the noisy image at all.",
            "It uses.",
            "I mean it uses the noisy Patch that you're looking at right now, but it uses that whole large set of natural image statistics and production noise.",
            "All of these quantities.",
            "Y given X or nothing.",
            "But the other guy."
        ],
        [
            "Russian Colonel.",
            "So one quantity that you can do using this estimator is computed, it's it's mean squared error over the set of M test patches.",
            "That's one option, and the other option is that we had two representations for the minimum mean squared error.",
            "One was the L presentation and one was the variance, and we can nonparametric we can.",
            "Estimate these two integrals by these two finite sums.",
            "And we'll call this left some MCU because it's an upper bound on the minimal mean squared error and the quantity on the right will call it mercy L. So the main claim of our work is that.",
            "If you average these two sums over many realizations of training data of those 10s of the 10.",
            "Image patches.",
            "The left hand sum, as I've said that that the mean squared error of a valid denoising algorithm that uses huge set that of natural images.",
            "So it's obviously by definition it's mean squared error is larger than the optimal one.",
            "The main claim of our work is that on average.",
            "Uh, the uh.",
            "Expression on the right is a lower bound.",
            "It on the minimal mean squared error.",
            "And therefore if these two.",
            "Of random variables clean side and we have a sharp estimate of the actual minimum mean squared error."
        ],
        [
            "So.",
            "As I've said, the minimum is the upper quantity is the mystery is another.",
            "Not so fast algorithm.",
            "And we claim that the other quantity lower bounds of mean squared error and if they coincide."
        ],
        [
            "Side we got a an estimate so.",
            "Let me try to give you an intuition of why this holds so.",
            "If you have a.",
            "If you have data XI and you compute their sample mean or their exact mean.",
            "Then, uh.",
            "You have you always have this inequality because.",
            "The estimated mean is is chosen to minimize the variance.",
            "And therefore you always have such an inequality, and this is essentially the inequality that.",
            "That that's the reason why RMS CL is a lower bound on the minimum mean squared error.",
            "So you can just take variances.",
            "Now what we have is not a single sum."
        ],
        [
            "We have a ratio.",
            "And what we can prove is that in expectation.",
            "This, uh, we had a Y which is the expected error.",
            "Mean squared error given a noisy Patch, why on average so to leading order it is unbiased.",
            "It gives you the true error at that Patch.",
            "Why?",
            "But the next order term is a quantity C of Y * B of Y and it doesn't matter.",
            "Because why is just a bunch of verse quantities C of Y is 1 / N times something.",
            "The main point is that C of Y is positive and B of Y is negative.",
            "So when you compute the expression MSCL, it's a random variable which has a negative bias.",
            "OK, it's biased downwards, and that's, well, it.",
            "Also, of course fluctuations, but."
        ],
        [
            "Uh, it's biased downwards, so for example, if you started from a Gaussian.",
            "Density or you do Gaussian approximation to the density.",
            "Then we can show mathematically as production distribution the quantity view of why is always less than zero.",
            "So the bias is indeed negative.",
            "And the other thing that you can do."
        ],
        [
            "Is you have this explicit expression for be of white.",
            "It involves various expectations.",
            "With that can be replaced by their plugin estimate, so you can replace these expressions by there.",
            "A nun."
        ],
        [
            "Parametric plugin."
        ],
        [
            "Estimates"
        ],
        [
            "And then what we find is that for our set of 2000 test patches, our estimate of B of Y is always negative.",
            "For some patches the bias is small.",
            "These are the nice smooth patches where we have a lot of data around and we can.",
            "Very sharply also both the noise and also get a lower bound, or this denoising there and for those patches which are very rare, either textures or corners, or you know I don't know.",
            "Maybe corners with not even re angle.",
            "There are not too many neighbors even in that huge 10 to the 10 set of patches and then we have a much higher negative bias.",
            "So."
        ],
        [
            "So.",
            "So that concluded the theoretical part.",
            "And in terms of of the experimental setup, what we did was the following.",
            "We took as I've said 10 to the 10 actual image patches.",
            "We use those to get a nonparametric density estimate.",
            "We used an independent set of 2000 noisy and clean patches.",
            "We looked at adding noise at different levels and with different window sizes and we're going to compare MCL.",
            "MSE you as well as the actual mean squared error.",
            "That's very different.",
            "Algorithms achieve and here is where our cluster data very hard work because.",
            "To the noise each Patch you need to sum over 10 to the 10 distances, exponentiate, etc etc."
        ],
        [
            "So look, so here there is."
        ],
        [
            "Dalton, it's slowly look go over them, so this is the result for relatively, well, let's say small noise.",
            "So here we added Gaussian noise with a standard deviation of 18 and the X axis is the support size you use.",
            "The blue curve is the Wiener filter, so the Wiener filter assumes that the whole set of all natural image patches can be modeled by a single Gaussian.",
            "And then you do shrinkage, Wiener, filtering an.",
            "It does pretty bad.",
            "Not surprisingly, at such relatively low levels of noise, the two curves that I have here.",
            "Are so this isn't PSN are so the higher the piece another better.",
            "Which means that this is our lower bound estimate of the optimal denoising and this is our denoising algorithm that uses 10 to the 10 patches.",
            "And what we see is that this noise level both quantities coincide roughly up to a support size of size 8 or so.",
            "So for such noise levels up to support size 8.",
            "We have a very sharp estimate of what is.",
            "The optimal denoising performance.",
            "And.",
            "Anne.",
            "What we see, for example, is that.",
            "Um?",
            "BM3D which which is these green points.",
            "So for window size 4 it achieves almost as good as what you could do ultimately with a generic natural image prior.",
            "And the the points on the right are our other methods that case videon Gaussian scale mixture which we associate with a very large window size.",
            "Because are based either on wavelet methods or on global optimizations that don't denoise each pixel separately.",
            "If."
        ],
        [
            "We increase the noise level.",
            "Uh.",
            "To 55.",
            "Again, what we see is so actually now we can compute what is the optimal denoising even for larger window sizes, because are 10 to the 10.",
            "Our set of sensor then patches can nonparametrically estimate the actual density much better.",
            "And again, being 3D is very close to optimality here.",
            "Throughout the range, and if we increase."
        ],
        [
            "Noise level to 170.",
            "This is huge noise, right?",
            "Remember that in a natural image, the pixel values are between zero and 2:55, so here you're adding, you're going to get negative values and very large positive values, but for extremely large noise, what you see is that the simple Wiener filter just try to try to explain the data with a single Gaussian is almost optimal at extremely large noise values.",
            "So what can we learn from all of?"
        ],
        [
            "Experiments, so the first observation is that, as predicted by the theory, all algorithms perform below the lower bounds.",
            "OK, the lower bound is this upper curve, which tells you what how best can you go.",
            "Um?"
        ],
        [
            "The second observation is that at certain parameter ranges, like small patches or large noise, we have sufficient our training set of 10 to the 10 patches sufficiently large so that we can have a sharp estimate of the minimal mean squared error.",
            "When I'm not showing you in this picture are confidence intervals, so the quantities MMC, Umm, Sierra, random variables.",
            "So they have a mean and the and the variance and what we did was actually also bootstrap.",
            "We use slightly different variations of the training set and also the test set and therefore so the error bars that we get are smaller than the sizes of of the points that we get OK. 1/3 observatio"
        ],
        [
            "10 is that beam 3D, which is considered one of the state of the art current denoising algorithms.",
            "Is again in those restricted cases of small window sizes, large noise where we have a sharp estimate of the lower bound, it's almost as good as you can get its fractional DB values from optimum.",
            "I would.",
            "So again.",
            "Let me be precise here.",
            "This observation holds for small window sizes.",
            "Or large error in some with larger window sizes.",
            "And in fact.",
            "If you're talking about the small noise.",
            "There is room maybe for improvement if you want to go to larger window."
        ],
        [
            "Outsiders.",
            "Also, if you want that for for, for theoretical issues of the lower bound, if you actually want the denoising algorithm that whose support is going to be 24 by 24 BM 3D nonlocal means type things will not work well because again of this course of dimensionality, even in the noisy image itself, you don't have enough neighbors in a 24 by 24 window and this.",
            "Requires I think maybe different approaches.",
            "For example, if you have a reasonable parametric approach to describe the statistics of natural images for larger window sizes, it need not be exact.",
            "It needs to be sufficiently accurate to beat nonparametric approaches.",
            "This is indeed an open and interesting question, which also has implications to deblurring, denoising, deconvolution and other such stuff.",
            "As well."
        ],
        [
            "So a another observation is that natural image priors are of interest only at certain cases.",
            "At very low noise.",
            "They don't help you.",
            "Because you can just do kind of a local denoising.",
            "If they are of interest at a medium noise level.",
            "At the high noise level, as I've said, just a single Gaussian would be sufficient, so it's very high noise.",
            "The error is solely determined by the 2nd order statistics of the data."
        ],
        [
            "And just to visualize the fact that indeed, current denoising algorithms at certain ranges are are are as good as you can do, here is an original image here is.",
            "This is a setting where our lower bound in their upper bound coincided, so the optimal minimal mean squared error also has an image attached to it, and in this case has a 23.93 DB SNR.",
            "And here are the results of other algorithms and for this specific image the difference was roughly 0.1 DB and also visually it's very difficult to discern what exactly are the differences.",
            "I think if you zoom in there are some regions where this image looks slightly better, but it's really not significa."
        ],
        [
            "From a visual point of view.",
            "So to summarize this talk, what we presented is statistical framework for what does it mean?",
            "Optimal natural image denoising.",
            "The.",
            "What we've shown is that for small windows moderate to large noise, current methods are nearly optimal.",
            "So going back to the question, should you do your PhD on image denoising, you should either go to larger window sizes, think about different representations of natural image patches.",
            "Uh.",
            "As I've said, so larger window sizes may yield better results, but.",
            "Is simple nonparametric approach.",
            "The does not seem to that it will work.",
            "To some extent this is similar.",
            "Maybe to shelkoff's talk that if you restrict your class of possible inputs, you're going to do much better.",
            "And as I've said this framework I think has implications for other low level vision tasks, deconvolution, superresolution.",
            "You can apply the similar machinery to try to get lower bounds in such cases as well and also see how large is the gap with current state of the art methods.",
            "And I think I'm done.",
            "Thank you.",
            "Type of questions.",
            "And so I think the issue maybe isn't Patch size going forward, but the assumption you made that the latent image axis spatially uncorrelated that you don't know anything about the statistics of natural images and how they vary spatially and the big win comes from modeling.",
            "The.",
            "Wait structure via chat and that for that you know that's too complex for this kind of about.",
            "I.",
            "Maybe there's another remark here is that maybe some of that is what you're saying is we use a generic image prior?",
            "Now you could think about.",
            "Here's a noisy image.",
            "I find this image contains buildings, an faces of people in cars.",
            "Maybe I should use a image specific prior.",
            "To try to denoise it.",
            "That's one option that would do better.",
            "We restricted ourselves.",
            "We're trying to be very precise versus ourselves to methods that use only a K by K window around each pixel to denoise it.",
            "So I agree, we're not taking the redundancy inside the image of that Patch actually were taking the redundancy in the whole world of natural images.",
            "When you work on such a large sample, when you want to do is that particular image, the specific questions you want to be noise or not, sampled independently from the whole huge and some of their separate from a very small subset of because there's lots a lot.",
            "Similarity images and that's just.",
            "Similar, not something from the whole huge and several of them by then natural setting for much, much more local area in that region.",
            "Center and using those redundancies in mind that estimates.",
            "But once you.",
            "Once you given given.",
            "No, an independent bitch.",
            "That's probably that that's the best we can do, but once you take into account all image which is not any independent sample of patches.",
            "I was as follows.",
            "Remember that the input images is very noisy, so you don't know the statistics of the underlying noise free image.",
            "So there are two approaches here.",
            "One is, you're going to try from the noisy image.",
            "Infer what were the statistics of that particular image and its redundancies inside.",
            "And another option, which is the one that we went for in this work, is to use a huge well to assume that the each Patch came from the whole images is a natural image and therefore each Patch is a petrol images.",
            "And we're going to take a huge independent data set there.",
            "Are there is work to be done, but we're trying to give some lower bounds in a very specific framework.",
            "We're not saying that.",
            "Nothing can be improved at all.",
            "Is just try actually to maybe to shine.",
            "What are possible different ways to improve current state of the art?",
            "So I I just wanted to say the questions that just came up with consistent with what I said earlier in my presentation, which is.",
            "These nonparametric techniques that we've been using a lot of other people are using implicitly or building priors from the given image.",
            "So they are in fact doing it wasn't suggested here.",
            "There is that interpretation and they have been very successful, so they.",
            "This sort of dictionary based or, or the database approach that you're suggesting is 1 approach, but the one that has been most successful is the one that uses patches from the same image to try to learn those statistics, right?",
            "I guess one other comment I wanted to make was in our work when we computed the bounds.",
            "Our conclusion was sort of counterintuitive.",
            "Namely, it said that.",
            "For images that are really simple, you still have a lot of room for improvements, whereas images that are really complicated.",
            "You pretty much hit the balance, so would you say that's consistent with what you're observing?",
            "Yes, maybe I'll save 2 words about the difference between our works.",
            "So if I understood payments work correctly, you try to construct priors, image specific priors, and we use a generic in which pile, and when the image is sufficiently complex.",
            "Uh, there is not much to gain when the image itself is extremely simple, like a geometric, maybe not an actual image, but more of a geometric type image where you have No 3 three circles and things that are repetitive many many times.",
            "A specific image prior does give you lower, lower lower bounds.",
            "It is so our work is consistent with your conclusions and also with Michaels.",
            "Uh.",
            "Remark as well.",
            "Thank the Speaker again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The title of this workshop is machine learning meets computational photography.",
                    "label": 0
                },
                {
                    "sent": "You could say that the title of this talk would be nonparametric statistics meets computational photography and.",
                    "label": 0
                },
                {
                    "sent": "Joint work with Annette Levine and we had another collaborator that worked very hard with us, which was our computer cluster and you'll see in a minute why and.",
                    "label": 1
                },
                {
                    "sent": "This talk is about image denoising, so I'm going to build upon the great talk that they payment gave and we're going to focus on.",
                    "label": 0
                },
                {
                    "sent": "Optimality in image denoising how.",
                    "label": 0
                },
                {
                    "sent": "Fire can you go?",
                    "label": 0
                },
                {
                    "sent": "And maybe are we there yet Sir?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Uh, the setting that we're going to talk about is natural image denoising, and you should circle the word natural because I'm going to focus on images that I'm assuming have been taken.",
                    "label": 0
                },
                {
                    "sent": "Are natural images.",
                    "label": 0
                },
                {
                    "sent": "Think about all the collection of images of people have taken with their digital cameras or their phone cameras and you can download from Google Images or something.",
                    "label": 0
                },
                {
                    "sent": "So there is an input noisy image why which is X plus noise in your goal is to denies it as best as possible.",
                    "label": 0
                },
                {
                    "sent": "Estimate a noise free image.",
                    "label": 1
                },
                {
                    "sent": "X hat.",
                    "label": 0
                },
                {
                    "sent": "And it's a very intensively studied problem in the last 30 years or so many different algorithms.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Of course, the fact that we assume that the image is a natural image means that you can use additional knowledge on how natural images behaves, and in particular about statistics of natural images.",
                    "label": 1
                },
                {
                    "sent": "And the question is, how much can these come in?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Your help, so here's an example of several recent recent meaning in the last 10 years or so.",
                    "label": 0
                },
                {
                    "sent": "Algorithms that, and their performance on a given image.",
                    "label": 0
                },
                {
                    "sent": "So typically the measure of quality is PSNR, which is the higher.",
                    "label": 0
                },
                {
                    "sent": "The value the better is that the noise in quality and so this is a Gaussian scale mixture and it has a value of 29.",
                    "label": 0
                },
                {
                    "sent": "This is K SVD by Miquel ad that uses a sparse representation and also 29 point something.",
                    "label": 0
                },
                {
                    "sent": "This is a different algorithm with 29.48.",
                    "label": 0
                },
                {
                    "sent": "This is the BM 3D algorithm that payment mentioned, which is slightly better, and this is a yet refined version of a BM 3D.",
                    "label": 0
                },
                {
                    "sent": "And what you do see other than the fact that the quality looks very similar is that also the numbers the mean squared error is very close to each other and.",
                    "label": 0
                },
                {
                    "sent": "There are also many other algorithms which also give similar performance in such images, and the question is.",
                    "label": 0
                },
                {
                    "sent": "How much better can you do or?",
                    "label": 0
                },
                {
                    "sent": "We are what are fundamental lower bounds on denoising natural images.",
                    "label": 0
                },
                {
                    "sent": "So how much can we improve query in denoising algorithms?",
                    "label": 1
                },
                {
                    "sent": "What is optimal denoising?",
                    "label": 0
                },
                {
                    "sent": "Can we define it in a rigorous way and?",
                    "label": 0
                },
                {
                    "sent": "That also comes into has a more.",
                    "label": 1
                },
                {
                    "sent": "A fundamental question of what are limits of natural image statistics for a variety of image processing tasks, deblurring deconvolution and other such problems.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use the framework of denoising to study this problem.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If you're a PhD students, the question is should your PhD in in.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Denoising so well denoising algorithms there have been a lot of them in terms of lower limits for denoising.",
                    "label": 0
                },
                {
                    "sent": "In the signal processing applications that have been some work with the Wiener filter, Gaussian priors, Baker, another had the limit on super resolution.",
                    "label": 1
                },
                {
                    "sent": "In the in the in the theoretical statistical literature that are very sharp bounds, but for I would not call them images, I would call them 2D arrays which are perfectly piecewise constant and and with the boundary which is known to be a smooth curve.",
                    "label": 0
                },
                {
                    "sent": "So there very very sharp bound and what you can do in such a setting, but it's not necessarily very applicable for actual.",
                    "label": 0
                },
                {
                    "sent": "For practically image denoising.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The non local newspapers by Bodison Morrell.",
                    "label": 0
                },
                {
                    "sent": "They claim that if you had an infinitely large image than Uncle means would be a syntactically optimal in some sense and perhaps the most relevant work is the work that recent work by Chatterjee Milan, far that made certain assumptions on on the input image and gave a lower bounds based on the comment I lower bound, so we're going to do a slightly different set of assumptions.",
                    "label": 0
                },
                {
                    "sent": "Then get slightly different lower bound and we can maybe if I have time I'll discuss a little bit of differences.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to discuss what is optimal in natural images and we need to introduce a statistical framework, and I'm not going to talk about all possible denoising approaches I'm going to, I'm going to restrict my discussion to denoising algorithms that take a central pixel look at the K by K window around it an denoise.",
                    "label": 0
                },
                {
                    "sent": "A central pixel based on this K by K window.",
                    "label": 1
                },
                {
                    "sent": "OK, so each pixel in you have your noisy image and you take a central pixel, you look at its K by K window around it and this is the only information you used to the noise you're not using.",
                    "label": 0
                },
                {
                    "sent": "So you denies each pixel individually based on its K by K neighborhood, and we're also going to assume that the noise is Gaussian, but it can be a different noise as long as I know its probability density.",
                    "label": 0
                },
                {
                    "sent": "And we are so the main.",
                    "label": 0
                },
                {
                    "sent": "The key assumption is that.",
                    "label": 0
                },
                {
                    "sent": "We are denoising an natural image, so in principle if you gave me the collection of 100 billion natural images or 100 hundred billion natural images, I could.",
                    "label": 0
                },
                {
                    "sent": "Constructor there is an implicit generic natural image prior that would be the density of KBK patches of natural images.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "The quality of that work and we're going to look at it is the mean squared error.",
                    "label": 0
                },
                {
                    "sent": "And of course, someone here mentioned that maybe that's not for visual purposes.",
                    "label": 0
                },
                {
                    "sent": "The best quantity, but this is what people have been done, and this is something that is easy to work with.",
                    "label": 0
                },
                {
                    "sent": "So that means cordera is the sum of all pixels in the image.",
                    "label": 0
                },
                {
                    "sent": "Your estimate, yhat minus the true value.",
                    "label": 0
                },
                {
                    "sent": "So C subset subscript C means for the center.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pixel of a Patch and.",
                    "label": 0
                },
                {
                    "sent": "A key issue in their work is that you can view two different.",
                    "label": 0
                },
                {
                    "sent": "You can view the mean squared error in two different ways.",
                    "label": 0
                },
                {
                    "sent": "One is the L interpretation, so.",
                    "label": 0
                },
                {
                    "sent": "You sample a cake, bake a Patch from the density P of X.",
                    "label": 0
                },
                {
                    "sent": "You add noise to it, so now you have Y given X and then you try to denoise this Patch wise you get a Whitehead central minus X squared.",
                    "label": 0
                },
                {
                    "sent": "You integrate dyd X this is.",
                    "label": 0
                },
                {
                    "sent": "The mean squared error.",
                    "label": 0
                },
                {
                    "sent": "If you do a change of the order of integration.",
                    "label": 0
                },
                {
                    "sent": "You get a different formula which will be very useful for us.",
                    "label": 0
                },
                {
                    "sent": "It's the variance interpretation and it goes as follows.",
                    "label": 1
                },
                {
                    "sent": "You first sample and noisy Patch.",
                    "label": 0
                },
                {
                    "sent": "Why you don't know what was the original underlying Patch X?",
                    "label": 0
                },
                {
                    "sent": "Then you look at all possible XSS that could have generated this Y and you look at the variance yhat central minus XYDXDY.",
                    "label": 0
                },
                {
                    "sent": "So in this representation as I've said, you start from a noisy Patch X which you know.",
                    "label": 0
                },
                {
                    "sent": "Noise free Patch.",
                    "label": 0
                },
                {
                    "sent": "Axino you added noise to it.",
                    "label": 0
                },
                {
                    "sent": "You get Y and then you get a white hat and you look at this distance and you average over all possible such realizations, but in the variance of presentation.",
                    "label": 0
                },
                {
                    "sent": "Given a noisy why there are many X is that could have given rise to this Y and you average over all of them so.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 1
                },
                {
                    "sent": "What's useful in the various interpretation is that you can easily derive from it what is the optimal estimator you just.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Differentiate and you find that the optimistic.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later is just the mean.",
                    "label": 1
                },
                {
                    "sent": "The conditional mean, and this is nothing but the Bayes minimal mean squared error estimator.",
                    "label": 1
                },
                {
                    "sent": "So under our setting, if we knew the prior of Kabi can actual images, this is the best thing that one can do.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If you plug it in, you get an explicit expression.",
                    "label": 0
                },
                {
                    "sent": "What is the optimal minimal mean squared error achievable at each pixel?",
                    "label": 0
                },
                {
                    "sent": "So there are several challenges.",
                    "label": 0
                },
                {
                    "sent": "One is that this integral is intractable.",
                    "label": 0
                },
                {
                    "sent": "It's a it's two integrals, each of which is K squared dimensional, and the second thing is that we don't know the density of natural images anyhow.",
                    "label": 1
                },
                {
                    "sent": "So I would like to somehow estimate or lower bound this quantity without even without doing all of these integrations and without knowing P of X.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can you do it so?",
                    "label": 0
                },
                {
                    "sent": "There is a trick, and the trick is that we don't know P, but we can sample from it.",
                    "label": 1
                },
                {
                    "sent": "We can sample 100 billion patches and try to nonparametrically give an estimate of P and maybe from it estimate this minimal mean squared error.",
                    "label": 0
                },
                {
                    "sent": "So that's what we're going to do and.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do is actually.",
                    "label": 0
                },
                {
                    "sent": "Use a huge set of natural image patches an give two quantities, which as I will prove in a minute in a in a certain way, give lower and upper bounds on the minimal mean squared error.",
                    "label": 0
                },
                {
                    "sent": "And if you're sampling is dense enough, these two quantities will coincide, and that's your optimal minimal achievable mean squared error.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the data that we used in the experiment that will describe later on is our training data, so to speak, is 10 to the 10 generic clean patches that were taken from the label me data set.",
                    "label": 1
                },
                {
                    "sent": "But we don't use the label, just just images.",
                    "label": 1
                },
                {
                    "sent": "And we took different images independent set of 2000 clean and noisy pairs of patches.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So remember, this is the exact optimal.",
                    "label": 0
                },
                {
                    "sent": "Estimator if I knew the density of X given Y or I can write it as such a fraction and what we're going to do is approximate that that those integrals by finite sums.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This our estimator here Yhat is nothing but yet another valid denoising algorithm is just does it.",
                    "label": 0
                },
                {
                    "sent": "Actually that it doesn't use the noisy image at all.",
                    "label": 0
                },
                {
                    "sent": "It uses.",
                    "label": 0
                },
                {
                    "sent": "I mean it uses the noisy Patch that you're looking at right now, but it uses that whole large set of natural image statistics and production noise.",
                    "label": 0
                },
                {
                    "sent": "All of these quantities.",
                    "label": 0
                },
                {
                    "sent": "Y given X or nothing.",
                    "label": 0
                },
                {
                    "sent": "But the other guy.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Russian Colonel.",
                    "label": 0
                },
                {
                    "sent": "So one quantity that you can do using this estimator is computed, it's it's mean squared error over the set of M test patches.",
                    "label": 0
                },
                {
                    "sent": "That's one option, and the other option is that we had two representations for the minimum mean squared error.",
                    "label": 0
                },
                {
                    "sent": "One was the L presentation and one was the variance, and we can nonparametric we can.",
                    "label": 0
                },
                {
                    "sent": "Estimate these two integrals by these two finite sums.",
                    "label": 0
                },
                {
                    "sent": "And we'll call this left some MCU because it's an upper bound on the minimal mean squared error and the quantity on the right will call it mercy L. So the main claim of our work is that.",
                    "label": 0
                },
                {
                    "sent": "If you average these two sums over many realizations of training data of those 10s of the 10.",
                    "label": 0
                },
                {
                    "sent": "Image patches.",
                    "label": 0
                },
                {
                    "sent": "The left hand sum, as I've said that that the mean squared error of a valid denoising algorithm that uses huge set that of natural images.",
                    "label": 0
                },
                {
                    "sent": "So it's obviously by definition it's mean squared error is larger than the optimal one.",
                    "label": 0
                },
                {
                    "sent": "The main claim of our work is that on average.",
                    "label": 0
                },
                {
                    "sent": "Uh, the uh.",
                    "label": 0
                },
                {
                    "sent": "Expression on the right is a lower bound.",
                    "label": 0
                },
                {
                    "sent": "It on the minimal mean squared error.",
                    "label": 0
                },
                {
                    "sent": "And therefore if these two.",
                    "label": 0
                },
                {
                    "sent": "Of random variables clean side and we have a sharp estimate of the actual minimum mean squared error.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As I've said, the minimum is the upper quantity is the mystery is another.",
                    "label": 0
                },
                {
                    "sent": "Not so fast algorithm.",
                    "label": 0
                },
                {
                    "sent": "And we claim that the other quantity lower bounds of mean squared error and if they coincide.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Side we got a an estimate so.",
                    "label": 0
                },
                {
                    "sent": "Let me try to give you an intuition of why this holds so.",
                    "label": 0
                },
                {
                    "sent": "If you have a.",
                    "label": 0
                },
                {
                    "sent": "If you have data XI and you compute their sample mean or their exact mean.",
                    "label": 1
                },
                {
                    "sent": "Then, uh.",
                    "label": 0
                },
                {
                    "sent": "You have you always have this inequality because.",
                    "label": 0
                },
                {
                    "sent": "The estimated mean is is chosen to minimize the variance.",
                    "label": 1
                },
                {
                    "sent": "And therefore you always have such an inequality, and this is essentially the inequality that.",
                    "label": 0
                },
                {
                    "sent": "That that's the reason why RMS CL is a lower bound on the minimum mean squared error.",
                    "label": 0
                },
                {
                    "sent": "So you can just take variances.",
                    "label": 0
                },
                {
                    "sent": "Now what we have is not a single sum.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a ratio.",
                    "label": 0
                },
                {
                    "sent": "And what we can prove is that in expectation.",
                    "label": 0
                },
                {
                    "sent": "This, uh, we had a Y which is the expected error.",
                    "label": 0
                },
                {
                    "sent": "Mean squared error given a noisy Patch, why on average so to leading order it is unbiased.",
                    "label": 0
                },
                {
                    "sent": "It gives you the true error at that Patch.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "But the next order term is a quantity C of Y * B of Y and it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Because why is just a bunch of verse quantities C of Y is 1 / N times something.",
                    "label": 0
                },
                {
                    "sent": "The main point is that C of Y is positive and B of Y is negative.",
                    "label": 0
                },
                {
                    "sent": "So when you compute the expression MSCL, it's a random variable which has a negative bias.",
                    "label": 0
                },
                {
                    "sent": "OK, it's biased downwards, and that's, well, it.",
                    "label": 0
                },
                {
                    "sent": "Also, of course fluctuations, but.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Uh, it's biased downwards, so for example, if you started from a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Density or you do Gaussian approximation to the density.",
                    "label": 1
                },
                {
                    "sent": "Then we can show mathematically as production distribution the quantity view of why is always less than zero.",
                    "label": 0
                },
                {
                    "sent": "So the bias is indeed negative.",
                    "label": 1
                },
                {
                    "sent": "And the other thing that you can do.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is you have this explicit expression for be of white.",
                    "label": 0
                },
                {
                    "sent": "It involves various expectations.",
                    "label": 0
                },
                {
                    "sent": "With that can be replaced by their plugin estimate, so you can replace these expressions by there.",
                    "label": 0
                },
                {
                    "sent": "A nun.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parametric plugin.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estimates",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then what we find is that for our set of 2000 test patches, our estimate of B of Y is always negative.",
                    "label": 0
                },
                {
                    "sent": "For some patches the bias is small.",
                    "label": 0
                },
                {
                    "sent": "These are the nice smooth patches where we have a lot of data around and we can.",
                    "label": 0
                },
                {
                    "sent": "Very sharply also both the noise and also get a lower bound, or this denoising there and for those patches which are very rare, either textures or corners, or you know I don't know.",
                    "label": 0
                },
                {
                    "sent": "Maybe corners with not even re angle.",
                    "label": 0
                },
                {
                    "sent": "There are not too many neighbors even in that huge 10 to the 10 set of patches and then we have a much higher negative bias.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So that concluded the theoretical part.",
                    "label": 0
                },
                {
                    "sent": "And in terms of of the experimental setup, what we did was the following.",
                    "label": 0
                },
                {
                    "sent": "We took as I've said 10 to the 10 actual image patches.",
                    "label": 0
                },
                {
                    "sent": "We use those to get a nonparametric density estimate.",
                    "label": 0
                },
                {
                    "sent": "We used an independent set of 2000 noisy and clean patches.",
                    "label": 1
                },
                {
                    "sent": "We looked at adding noise at different levels and with different window sizes and we're going to compare MCL.",
                    "label": 1
                },
                {
                    "sent": "MSE you as well as the actual mean squared error.",
                    "label": 0
                },
                {
                    "sent": "That's very different.",
                    "label": 0
                },
                {
                    "sent": "Algorithms achieve and here is where our cluster data very hard work because.",
                    "label": 0
                },
                {
                    "sent": "To the noise each Patch you need to sum over 10 to the 10 distances, exponentiate, etc etc.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So look, so here there is.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dalton, it's slowly look go over them, so this is the result for relatively, well, let's say small noise.",
                    "label": 0
                },
                {
                    "sent": "So here we added Gaussian noise with a standard deviation of 18 and the X axis is the support size you use.",
                    "label": 0
                },
                {
                    "sent": "The blue curve is the Wiener filter, so the Wiener filter assumes that the whole set of all natural image patches can be modeled by a single Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And then you do shrinkage, Wiener, filtering an.",
                    "label": 0
                },
                {
                    "sent": "It does pretty bad.",
                    "label": 0
                },
                {
                    "sent": "Not surprisingly, at such relatively low levels of noise, the two curves that I have here.",
                    "label": 0
                },
                {
                    "sent": "Are so this isn't PSN are so the higher the piece another better.",
                    "label": 0
                },
                {
                    "sent": "Which means that this is our lower bound estimate of the optimal denoising and this is our denoising algorithm that uses 10 to the 10 patches.",
                    "label": 0
                },
                {
                    "sent": "And what we see is that this noise level both quantities coincide roughly up to a support size of size 8 or so.",
                    "label": 0
                },
                {
                    "sent": "So for such noise levels up to support size 8.",
                    "label": 0
                },
                {
                    "sent": "We have a very sharp estimate of what is.",
                    "label": 0
                },
                {
                    "sent": "The optimal denoising performance.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "What we see, for example, is that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "BM3D which which is these green points.",
                    "label": 0
                },
                {
                    "sent": "So for window size 4 it achieves almost as good as what you could do ultimately with a generic natural image prior.",
                    "label": 0
                },
                {
                    "sent": "And the the points on the right are our other methods that case videon Gaussian scale mixture which we associate with a very large window size.",
                    "label": 0
                },
                {
                    "sent": "Because are based either on wavelet methods or on global optimizations that don't denoise each pixel separately.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We increase the noise level.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "To 55.",
                    "label": 0
                },
                {
                    "sent": "Again, what we see is so actually now we can compute what is the optimal denoising even for larger window sizes, because are 10 to the 10.",
                    "label": 0
                },
                {
                    "sent": "Our set of sensor then patches can nonparametrically estimate the actual density much better.",
                    "label": 0
                },
                {
                    "sent": "And again, being 3D is very close to optimality here.",
                    "label": 0
                },
                {
                    "sent": "Throughout the range, and if we increase.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Noise level to 170.",
                    "label": 0
                },
                {
                    "sent": "This is huge noise, right?",
                    "label": 0
                },
                {
                    "sent": "Remember that in a natural image, the pixel values are between zero and 2:55, so here you're adding, you're going to get negative values and very large positive values, but for extremely large noise, what you see is that the simple Wiener filter just try to try to explain the data with a single Gaussian is almost optimal at extremely large noise values.",
                    "label": 0
                },
                {
                    "sent": "So what can we learn from all of?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experiments, so the first observation is that, as predicted by the theory, all algorithms perform below the lower bounds.",
                    "label": 1
                },
                {
                    "sent": "OK, the lower bound is this upper curve, which tells you what how best can you go.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second observation is that at certain parameter ranges, like small patches or large noise, we have sufficient our training set of 10 to the 10 patches sufficiently large so that we can have a sharp estimate of the minimal mean squared error.",
                    "label": 1
                },
                {
                    "sent": "When I'm not showing you in this picture are confidence intervals, so the quantities MMC, Umm, Sierra, random variables.",
                    "label": 0
                },
                {
                    "sent": "So they have a mean and the and the variance and what we did was actually also bootstrap.",
                    "label": 0
                },
                {
                    "sent": "We use slightly different variations of the training set and also the test set and therefore so the error bars that we get are smaller than the sizes of of the points that we get OK. 1/3 observatio",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "10 is that beam 3D, which is considered one of the state of the art current denoising algorithms.",
                    "label": 1
                },
                {
                    "sent": "Is again in those restricted cases of small window sizes, large noise where we have a sharp estimate of the lower bound, it's almost as good as you can get its fractional DB values from optimum.",
                    "label": 0
                },
                {
                    "sent": "I would.",
                    "label": 0
                },
                {
                    "sent": "So again.",
                    "label": 0
                },
                {
                    "sent": "Let me be precise here.",
                    "label": 1
                },
                {
                    "sent": "This observation holds for small window sizes.",
                    "label": 0
                },
                {
                    "sent": "Or large error in some with larger window sizes.",
                    "label": 0
                },
                {
                    "sent": "And in fact.",
                    "label": 0
                },
                {
                    "sent": "If you're talking about the small noise.",
                    "label": 0
                },
                {
                    "sent": "There is room maybe for improvement if you want to go to larger window.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Outsiders.",
                    "label": 0
                },
                {
                    "sent": "Also, if you want that for for, for theoretical issues of the lower bound, if you actually want the denoising algorithm that whose support is going to be 24 by 24 BM 3D nonlocal means type things will not work well because again of this course of dimensionality, even in the noisy image itself, you don't have enough neighbors in a 24 by 24 window and this.",
                    "label": 0
                },
                {
                    "sent": "Requires I think maybe different approaches.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have a reasonable parametric approach to describe the statistics of natural images for larger window sizes, it need not be exact.",
                    "label": 0
                },
                {
                    "sent": "It needs to be sufficiently accurate to beat nonparametric approaches.",
                    "label": 0
                },
                {
                    "sent": "This is indeed an open and interesting question, which also has implications to deblurring, denoising, deconvolution and other such stuff.",
                    "label": 0
                },
                {
                    "sent": "As well.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a another observation is that natural image priors are of interest only at certain cases.",
                    "label": 1
                },
                {
                    "sent": "At very low noise.",
                    "label": 0
                },
                {
                    "sent": "They don't help you.",
                    "label": 0
                },
                {
                    "sent": "Because you can just do kind of a local denoising.",
                    "label": 0
                },
                {
                    "sent": "If they are of interest at a medium noise level.",
                    "label": 1
                },
                {
                    "sent": "At the high noise level, as I've said, just a single Gaussian would be sufficient, so it's very high noise.",
                    "label": 0
                },
                {
                    "sent": "The error is solely determined by the 2nd order statistics of the data.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just to visualize the fact that indeed, current denoising algorithms at certain ranges are are are as good as you can do, here is an original image here is.",
                    "label": 0
                },
                {
                    "sent": "This is a setting where our lower bound in their upper bound coincided, so the optimal minimal mean squared error also has an image attached to it, and in this case has a 23.93 DB SNR.",
                    "label": 0
                },
                {
                    "sent": "And here are the results of other algorithms and for this specific image the difference was roughly 0.1 DB and also visually it's very difficult to discern what exactly are the differences.",
                    "label": 0
                },
                {
                    "sent": "I think if you zoom in there are some regions where this image looks slightly better, but it's really not significa.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From a visual point of view.",
                    "label": 0
                },
                {
                    "sent": "So to summarize this talk, what we presented is statistical framework for what does it mean?",
                    "label": 0
                },
                {
                    "sent": "Optimal natural image denoising.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "What we've shown is that for small windows moderate to large noise, current methods are nearly optimal.",
                    "label": 1
                },
                {
                    "sent": "So going back to the question, should you do your PhD on image denoising, you should either go to larger window sizes, think about different representations of natural image patches.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 1
                },
                {
                    "sent": "As I've said, so larger window sizes may yield better results, but.",
                    "label": 0
                },
                {
                    "sent": "Is simple nonparametric approach.",
                    "label": 0
                },
                {
                    "sent": "The does not seem to that it will work.",
                    "label": 0
                },
                {
                    "sent": "To some extent this is similar.",
                    "label": 1
                },
                {
                    "sent": "Maybe to shelkoff's talk that if you restrict your class of possible inputs, you're going to do much better.",
                    "label": 0
                },
                {
                    "sent": "And as I've said this framework I think has implications for other low level vision tasks, deconvolution, superresolution.",
                    "label": 0
                },
                {
                    "sent": "You can apply the similar machinery to try to get lower bounds in such cases as well and also see how large is the gap with current state of the art methods.",
                    "label": 0
                },
                {
                    "sent": "And I think I'm done.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Type of questions.",
                    "label": 0
                },
                {
                    "sent": "And so I think the issue maybe isn't Patch size going forward, but the assumption you made that the latent image axis spatially uncorrelated that you don't know anything about the statistics of natural images and how they vary spatially and the big win comes from modeling.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Wait structure via chat and that for that you know that's too complex for this kind of about.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's another remark here is that maybe some of that is what you're saying is we use a generic image prior?",
                    "label": 0
                },
                {
                    "sent": "Now you could think about.",
                    "label": 0
                },
                {
                    "sent": "Here's a noisy image.",
                    "label": 0
                },
                {
                    "sent": "I find this image contains buildings, an faces of people in cars.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should use a image specific prior.",
                    "label": 0
                },
                {
                    "sent": "To try to denoise it.",
                    "label": 0
                },
                {
                    "sent": "That's one option that would do better.",
                    "label": 0
                },
                {
                    "sent": "We restricted ourselves.",
                    "label": 0
                },
                {
                    "sent": "We're trying to be very precise versus ourselves to methods that use only a K by K window around each pixel to denoise it.",
                    "label": 0
                },
                {
                    "sent": "So I agree, we're not taking the redundancy inside the image of that Patch actually were taking the redundancy in the whole world of natural images.",
                    "label": 0
                },
                {
                    "sent": "When you work on such a large sample, when you want to do is that particular image, the specific questions you want to be noise or not, sampled independently from the whole huge and some of their separate from a very small subset of because there's lots a lot.",
                    "label": 0
                },
                {
                    "sent": "Similarity images and that's just.",
                    "label": 0
                },
                {
                    "sent": "Similar, not something from the whole huge and several of them by then natural setting for much, much more local area in that region.",
                    "label": 0
                },
                {
                    "sent": "Center and using those redundancies in mind that estimates.",
                    "label": 0
                },
                {
                    "sent": "But once you.",
                    "label": 0
                },
                {
                    "sent": "Once you given given.",
                    "label": 0
                },
                {
                    "sent": "No, an independent bitch.",
                    "label": 0
                },
                {
                    "sent": "That's probably that that's the best we can do, but once you take into account all image which is not any independent sample of patches.",
                    "label": 0
                },
                {
                    "sent": "I was as follows.",
                    "label": 0
                },
                {
                    "sent": "Remember that the input images is very noisy, so you don't know the statistics of the underlying noise free image.",
                    "label": 0
                },
                {
                    "sent": "So there are two approaches here.",
                    "label": 0
                },
                {
                    "sent": "One is, you're going to try from the noisy image.",
                    "label": 0
                },
                {
                    "sent": "Infer what were the statistics of that particular image and its redundancies inside.",
                    "label": 0
                },
                {
                    "sent": "And another option, which is the one that we went for in this work, is to use a huge well to assume that the each Patch came from the whole images is a natural image and therefore each Patch is a petrol images.",
                    "label": 0
                },
                {
                    "sent": "And we're going to take a huge independent data set there.",
                    "label": 0
                },
                {
                    "sent": "Are there is work to be done, but we're trying to give some lower bounds in a very specific framework.",
                    "label": 0
                },
                {
                    "sent": "We're not saying that.",
                    "label": 0
                },
                {
                    "sent": "Nothing can be improved at all.",
                    "label": 0
                },
                {
                    "sent": "Is just try actually to maybe to shine.",
                    "label": 0
                },
                {
                    "sent": "What are possible different ways to improve current state of the art?",
                    "label": 0
                },
                {
                    "sent": "So I I just wanted to say the questions that just came up with consistent with what I said earlier in my presentation, which is.",
                    "label": 0
                },
                {
                    "sent": "These nonparametric techniques that we've been using a lot of other people are using implicitly or building priors from the given image.",
                    "label": 0
                },
                {
                    "sent": "So they are in fact doing it wasn't suggested here.",
                    "label": 0
                },
                {
                    "sent": "There is that interpretation and they have been very successful, so they.",
                    "label": 0
                },
                {
                    "sent": "This sort of dictionary based or, or the database approach that you're suggesting is 1 approach, but the one that has been most successful is the one that uses patches from the same image to try to learn those statistics, right?",
                    "label": 0
                },
                {
                    "sent": "I guess one other comment I wanted to make was in our work when we computed the bounds.",
                    "label": 0
                },
                {
                    "sent": "Our conclusion was sort of counterintuitive.",
                    "label": 0
                },
                {
                    "sent": "Namely, it said that.",
                    "label": 0
                },
                {
                    "sent": "For images that are really simple, you still have a lot of room for improvements, whereas images that are really complicated.",
                    "label": 0
                },
                {
                    "sent": "You pretty much hit the balance, so would you say that's consistent with what you're observing?",
                    "label": 0
                },
                {
                    "sent": "Yes, maybe I'll save 2 words about the difference between our works.",
                    "label": 0
                },
                {
                    "sent": "So if I understood payments work correctly, you try to construct priors, image specific priors, and we use a generic in which pile, and when the image is sufficiently complex.",
                    "label": 0
                },
                {
                    "sent": "Uh, there is not much to gain when the image itself is extremely simple, like a geometric, maybe not an actual image, but more of a geometric type image where you have No 3 three circles and things that are repetitive many many times.",
                    "label": 0
                },
                {
                    "sent": "A specific image prior does give you lower, lower lower bounds.",
                    "label": 0
                },
                {
                    "sent": "It is so our work is consistent with your conclusions and also with Michaels.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Remark as well.",
                    "label": 0
                },
                {
                    "sent": "Thank the Speaker again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}