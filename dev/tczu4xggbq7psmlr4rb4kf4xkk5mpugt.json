{
    "id": "tczu4xggbq7psmlr4rb4kf4xkk5mpugt",
    "title": "The chains model for detecting parts by their context",
    "info": {
        "author": [
            "Leonid Karlinsky, Weizmann Institute of Science"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_karlinsky_cmdp/",
    "segmentation": [
        [
            "My name is Leonard.",
            "My name is Dan Carlin scanner.",
            "Welcome to my talk the called the Chains model for detecting parts.",
            "By the context, this is joint work with Michael Dinnerstein Danielian Schuneman always menace of science."
        ],
        [
            "So our approach is about detecting difficult parts of flexible objects, such as detecting human hands for example, and in fact we will use this example throughout the talk in order to illustrate our approach.",
            "So this way images free convince you that detecting hands is independent objects and not as part of the human body is not such a good idea.",
            "Hands are usually appear small in the image.",
            "They suffer from occlusions and have a large variability in appearance.",
            "In addition, if you do manage to take the hand as a separate object, will probably have a problem of knowing whether we detected the the left or the right hand, or if there are several people.",
            "Image will not know which.",
            "Nelson, the hand belongs to.",
            "However, there are some other parts of the human body which are much easier to detect.",
            "For instance, the face or trunk.",
            "So first idea is to use the."
        ],
        [
            "Defections of these select pilots.",
            "In order to detect and disambiguate the more difficult parts.",
            "So how would we find the hand, given that we know where the face is?",
            "Well, it's quite simple.",
            "You just fold down, for example, like this.",
            "Of course, there are many ways to do that, and in our approach we detect the hand by marginalizing over different.",
            "Baffle change how we call them from the face of the hand which are likely to get there.",
            "So that's an overview, and here are some examples of our approach applied to images of various datasets that we have tested on and in these examples we showed the detection of the right hand with style with green outline and detection of the left hand with the style of with the yellow outline, and notice the high variability in appearance and poses that are successfully handled by our Model 1 important thing to note about our approach is that it doesn't assume in any upper or knowledge of the object structure.",
            "For instance, we do not use the body skeleton commonly used in many part detection approaches.",
            "So that will apply to human parts and then that way we can actually use the same approach out of the box without changing the model of the parameters.",
            "Another train detectors for other objects in other parts.",
            "For instance here we show some results in detecting the frontal leftover horse exactly with the same approach.",
            "But with the."
        ],
        [
            "Post training course, so I'll briefly cover the the model that we proposed.",
            "It is called the chains model.",
            "This is a generative probabilistic nonparametric model.",
            "It goes like this will save an input image either for training or testing.",
            "We first preprocessing by first detecting the reference part in the face in detection example, denoted here by LF, and then we extract features on the image in various interest points.",
            "So you use Sift descriptor for features and subsample edges for interest points.",
            "Quite simple and standard.",
            "Now our goal is to detect the hand.",
            "So what we want to do is given some candidate hand location denoted here by LH, we want to estimate the posterior probability of that location containing the hand given all the features and the reference part location.",
            "So now that we define the following generative model, the formal definitions below, but I'll quickly go over the notations so we add two additional Latin variables.",
            "M&TT is another subset of the features, and then it's the size of the subset and the features that belong to this ordered subset are genetic sequentially one after another, while the first feature is being generated by the face in the last feature, generates the candidate and location.",
            "This is the expression in the red box in the following definition, and we assume that the rest of the features are generated independently out of some world distribution of the parameters are estimated from the training data now by the way, the generations are features of the expression in the blue books.",
            "In the phone definition, so there may be different such assignments to T and corresponding to different chains going from the face of the hand, and we define the feature graph as a union of all these chains.",
            "This is a graph in which features are in the nodes and every two features which have and that you have a non zero probability of being following one another on a chain connected by directed.",
            "Edge.",
            "So the influence our model is the marginalization of all possible assignments to M&T, and this corresponds to summing up over simple paths on this feature graph going from the face of hand over the computation involving the exact inference.",
            "In order to compute the posterior is difficult and inefficient due to the restriction that the path has to be simple.",
            "And in order to handle that, we propose an approximate inference approach in which we remove the requirement of singleness and some overall chains going from the face of the hand, by limiting the maximum length of the chain, we limit it by using three intermediate features in our experiments, so this approximation is much easier to computer, will see in a moment.",
            "But still it doesn't hinder the performance.",
            "As we discovered experimentally in the Australian results section how it works."
        ],
        [
            "So 2 words on the influence if we sum over all the chains, the simple the influence becomes quite simple.",
            "It's just a simple matrix product or the Form D * C Time S were where D is a vector of voting probabilities, where each feature vote for the candidate hand location just in like in the Star S is the column vector of object versus background language ratios, in which.",
            "We checked the estimates for each feature, its affinity to the object, and finally see is a matrix of marginals in which entry IJ is marginal over all the chains going from the feature J to feature I, and it can be simply computed by summing up powers of the weighted adjacency matrix of the feature graph just discussed."
        ],
        [
            "So the final details let me provide about our model is how do we do training and how do we estimate the different probabilities needed in order to compute the inference.",
            "So the training is done by providing the model a set of examples in which on each image would we have the reference file detected and the target part the hand for instance is marked by a single point in order to handle scale variations we normalized by the scale of the detected reference part in the hand detection examples, the weeds of the face.",
            "So in order to estimate the different probabilities needed by the inference, we use the nonparametric approach.",
            "In a nutshell, what it does is first store all the features selected from the training images by feature selection approach.",
            "I will not cover here, but please refer to the paper for that in some efficient search structures in where we can fast and efficiently search for nearest neighbors and then.",
            "In all of the computer different probabilities we use can density estimation, Gaussian distance estimation, and I'll illustrated by example.",
            "For instance, if we need to compute the probability of if I&J on chain, then we search for K nearest neighbors of role vector, sift ice if J and excitement so J, which is an offset between the two features.",
            "The that we get from the image and then we compute the probability by standard KD as.",
            "Shown here in this formula.",
            "So for more details, please refer to the paper."
        ],
        [
            "And finally I wanted to mention that style model, which is a popular model for object detection and many tasks in the computer vision can be seen useful variant of it can be seen as a special case of the chain mode chains model, in which the chains are off limits.",
            "One we've pulled it in our paper and.",
            "In addition, we have provide we have we in the paper will provide a lot of experiments showing that there is significant advantage in power detection of the chains model over the star model."
        ],
        [
            "So before we skip the results, I would just.",
            "I just wanted to show you some examples of the feature graphs we obtained for the task of right hand detection in a couple of examples.",
            "So here you see the feature graphs plotted using their edges.",
            "The we plot only the some portion of the top scoring edges on each image.",
            "The edges are colored in the jet colormap.",
            "The red is more probable and blue is less probable.",
            "And you can see why using this feature graphs the influence of the chains models had successfully detected the correct hand by searching for path leading from the face location to the candidate head locations and notice the interesting example below where the chains model successfully disambiguates between the crossed right and left hands, or the person which is evident from the future graph."
        ],
        [
            "So I'll just briefly go."
        ],
        [
            "Well, some results here is some example results obtained on the sign language data set proposed by Patrick Bueler in 2008.",
            "Again, the right hand detections are marked by green style and the left and attractions are marked by yellow Star.",
            "And here we obtain a performance of about 85%, which is better than than previously reported in the literature.",
            "Here we see examples and I just wanted to stress that in this and in all other experiments we apply our Model 2 separate images.",
            "We do not use any motion formation.",
            "And we also do not use call information.",
            "So this is for this data set."
        ],
        [
            "Here are some more examples on the other public datasets proposed by Vittorio Ferrari and 2008.",
            "This is a Buffy data set.",
            "And here we obtain results compareable to the state of the art.",
            "Please appreciate the large variability in appearance and poses.",
            "Again, the notation of the hands is as I explained before.",
            "OK."
        ],
        [
            "Here are some additional examples on datasets which are actually frames of movie sequences, so I'm plotting the results on a movie on the movies.",
            "Here in these 3 three movies, the task was to detect the right hand for which we had the ground truth, and in this movie we detect both hands and the.",
            "I want to say about it is again that we do not use any motion formation.",
            "All you see here is detection which will be computed for each frame separately and.",
            "Well, floating.",
            "The results, please appreciate.",
            "Large variability in poses and also in this sign language example notice how it handles.",
            "Self occlusions and motion blur.",
            "Yeah.",
            "OK, so."
        ],
        [
            "So we conclude we can also apply our approach to full object detection, not just parts.",
            "Here's some example detections of cars from USC.",
            "Data set was interesting about it.",
            "Is that in order to detect full objects, we actually extend our model to work without any reference part.",
            "So here here we allow the chains to originate not just in the reference part, but in any location on the image.",
            "In the in the US, according to obtain, the comparable is out of state without.",
            "You also have some small improvement over the state of the art in the basement horses data set chain not showing here.",
            "The."
        ],
        [
            "And finally, as we discussed at the beginning of the talk, the same model without changing anything can be trained for detecting other parts and even parts of other objects.",
            "In the left movie The Chains model is used to detect all these three parts.",
            "The face, the elbow in the hand.",
            "And in the right movie, it's detecting the.",
            "Found the left roof over horse.",
            "So now I will conclude.",
            "We have presented the single implemented model that is capable of training a detector for any part of any object without changing the model of the parameters.",
            "The idea is that we detect difficult parts by extending detection, detecting, disambiguate difficult parts for extending detections of easy parts, and in the model the nearby features vote directly for the target.",
            "About well, the following features, both through chains of intermediate features.",
            "This way we exploit the internal context of the object in order to detect the parts.",
            "And finally, the same approach can be used without using without any reference power detection, and in order to detect full objects, thank you.",
            "I see a question back there.",
            "Gentleman in front of the gentleman in the red shirt, tapping on the tap on the shoulder.",
            "They want to drive.",
            "You had a quest.",
            "Could you, yeah, so the question was in the example of the multiple file detection world.",
            "The Palace detection detected independently, or is there some dependence in the detection?",
            "If I got the question correctly, so here in this example we detect the face in the independent detection mode just like for the cars or the horses and then we extend this detection to the elbows on the hands in.",
            "Using the chains model.",
            "Yes question.",
            "I know that.",
            "He reports a float, some results obtained offline.",
            "This is not actually, it does not hardly runs in real time.",
            "I think we have, you know, inefficient MATLAB implementation.",
            "We have something about half a minute or frame running time.",
            "Half a minute 30 seconds.",
            "Currently, but it can be significant.",
            "Can be done significally faster, first transferring some more optimal code and then using the different parameters for the nearest neighbor search.",
            "You can control the level of the approximation of the nearest neighbors you can lose in the in the proximity of the neighbors, but gain in speed.",
            "So actually we buy slight deterioration in the performance we can obtain about a second per frame.",
            "In many examples we've seen this kind of.",
            "Finding thing so and it can be of course made much faster with parallel software.",
            "Hope this answers your question.",
            "So I think that's it for the morning.",
            "Let us thank this speaker and all other speakers."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is Leonard.",
                    "label": 0
                },
                {
                    "sent": "My name is Dan Carlin scanner.",
                    "label": 0
                },
                {
                    "sent": "Welcome to my talk the called the Chains model for detecting parts.",
                    "label": 1
                },
                {
                    "sent": "By the context, this is joint work with Michael Dinnerstein Danielian Schuneman always menace of science.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our approach is about detecting difficult parts of flexible objects, such as detecting human hands for example, and in fact we will use this example throughout the talk in order to illustrate our approach.",
                    "label": 0
                },
                {
                    "sent": "So this way images free convince you that detecting hands is independent objects and not as part of the human body is not such a good idea.",
                    "label": 0
                },
                {
                    "sent": "Hands are usually appear small in the image.",
                    "label": 0
                },
                {
                    "sent": "They suffer from occlusions and have a large variability in appearance.",
                    "label": 0
                },
                {
                    "sent": "In addition, if you do manage to take the hand as a separate object, will probably have a problem of knowing whether we detected the the left or the right hand, or if there are several people.",
                    "label": 0
                },
                {
                    "sent": "Image will not know which.",
                    "label": 0
                },
                {
                    "sent": "Nelson, the hand belongs to.",
                    "label": 1
                },
                {
                    "sent": "However, there are some other parts of the human body which are much easier to detect.",
                    "label": 1
                },
                {
                    "sent": "For instance, the face or trunk.",
                    "label": 0
                },
                {
                    "sent": "So first idea is to use the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Defections of these select pilots.",
                    "label": 0
                },
                {
                    "sent": "In order to detect and disambiguate the more difficult parts.",
                    "label": 0
                },
                {
                    "sent": "So how would we find the hand, given that we know where the face is?",
                    "label": 0
                },
                {
                    "sent": "Well, it's quite simple.",
                    "label": 0
                },
                {
                    "sent": "You just fold down, for example, like this.",
                    "label": 0
                },
                {
                    "sent": "Of course, there are many ways to do that, and in our approach we detect the hand by marginalizing over different.",
                    "label": 0
                },
                {
                    "sent": "Baffle change how we call them from the face of the hand which are likely to get there.",
                    "label": 0
                },
                {
                    "sent": "So that's an overview, and here are some examples of our approach applied to images of various datasets that we have tested on and in these examples we showed the detection of the right hand with style with green outline and detection of the left hand with the style of with the yellow outline, and notice the high variability in appearance and poses that are successfully handled by our Model 1 important thing to note about our approach is that it doesn't assume in any upper or knowledge of the object structure.",
                    "label": 0
                },
                {
                    "sent": "For instance, we do not use the body skeleton commonly used in many part detection approaches.",
                    "label": 1
                },
                {
                    "sent": "So that will apply to human parts and then that way we can actually use the same approach out of the box without changing the model of the parameters.",
                    "label": 0
                },
                {
                    "sent": "Another train detectors for other objects in other parts.",
                    "label": 0
                },
                {
                    "sent": "For instance here we show some results in detecting the frontal leftover horse exactly with the same approach.",
                    "label": 1
                },
                {
                    "sent": "But with the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Post training course, so I'll briefly cover the the model that we proposed.",
                    "label": 0
                },
                {
                    "sent": "It is called the chains model.",
                    "label": 1
                },
                {
                    "sent": "This is a generative probabilistic nonparametric model.",
                    "label": 0
                },
                {
                    "sent": "It goes like this will save an input image either for training or testing.",
                    "label": 0
                },
                {
                    "sent": "We first preprocessing by first detecting the reference part in the face in detection example, denoted here by LF, and then we extract features on the image in various interest points.",
                    "label": 0
                },
                {
                    "sent": "So you use Sift descriptor for features and subsample edges for interest points.",
                    "label": 0
                },
                {
                    "sent": "Quite simple and standard.",
                    "label": 1
                },
                {
                    "sent": "Now our goal is to detect the hand.",
                    "label": 1
                },
                {
                    "sent": "So what we want to do is given some candidate hand location denoted here by LH, we want to estimate the posterior probability of that location containing the hand given all the features and the reference part location.",
                    "label": 0
                },
                {
                    "sent": "So now that we define the following generative model, the formal definitions below, but I'll quickly go over the notations so we add two additional Latin variables.",
                    "label": 0
                },
                {
                    "sent": "M&TT is another subset of the features, and then it's the size of the subset and the features that belong to this ordered subset are genetic sequentially one after another, while the first feature is being generated by the face in the last feature, generates the candidate and location.",
                    "label": 1
                },
                {
                    "sent": "This is the expression in the red box in the following definition, and we assume that the rest of the features are generated independently out of some world distribution of the parameters are estimated from the training data now by the way, the generations are features of the expression in the blue books.",
                    "label": 0
                },
                {
                    "sent": "In the phone definition, so there may be different such assignments to T and corresponding to different chains going from the face of the hand, and we define the feature graph as a union of all these chains.",
                    "label": 0
                },
                {
                    "sent": "This is a graph in which features are in the nodes and every two features which have and that you have a non zero probability of being following one another on a chain connected by directed.",
                    "label": 1
                },
                {
                    "sent": "Edge.",
                    "label": 0
                },
                {
                    "sent": "So the influence our model is the marginalization of all possible assignments to M&T, and this corresponds to summing up over simple paths on this feature graph going from the face of hand over the computation involving the exact inference.",
                    "label": 0
                },
                {
                    "sent": "In order to compute the posterior is difficult and inefficient due to the restriction that the path has to be simple.",
                    "label": 0
                },
                {
                    "sent": "And in order to handle that, we propose an approximate inference approach in which we remove the requirement of singleness and some overall chains going from the face of the hand, by limiting the maximum length of the chain, we limit it by using three intermediate features in our experiments, so this approximation is much easier to computer, will see in a moment.",
                    "label": 0
                },
                {
                    "sent": "But still it doesn't hinder the performance.",
                    "label": 0
                },
                {
                    "sent": "As we discovered experimentally in the Australian results section how it works.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So 2 words on the influence if we sum over all the chains, the simple the influence becomes quite simple.",
                    "label": 0
                },
                {
                    "sent": "It's just a simple matrix product or the Form D * C Time S were where D is a vector of voting probabilities, where each feature vote for the candidate hand location just in like in the Star S is the column vector of object versus background language ratios, in which.",
                    "label": 0
                },
                {
                    "sent": "We checked the estimates for each feature, its affinity to the object, and finally see is a matrix of marginals in which entry IJ is marginal over all the chains going from the feature J to feature I, and it can be simply computed by summing up powers of the weighted adjacency matrix of the feature graph just discussed.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the final details let me provide about our model is how do we do training and how do we estimate the different probabilities needed in order to compute the inference.",
                    "label": 0
                },
                {
                    "sent": "So the training is done by providing the model a set of examples in which on each image would we have the reference file detected and the target part the hand for instance is marked by a single point in order to handle scale variations we normalized by the scale of the detected reference part in the hand detection examples, the weeds of the face.",
                    "label": 0
                },
                {
                    "sent": "So in order to estimate the different probabilities needed by the inference, we use the nonparametric approach.",
                    "label": 0
                },
                {
                    "sent": "In a nutshell, what it does is first store all the features selected from the training images by feature selection approach.",
                    "label": 1
                },
                {
                    "sent": "I will not cover here, but please refer to the paper for that in some efficient search structures in where we can fast and efficiently search for nearest neighbors and then.",
                    "label": 0
                },
                {
                    "sent": "In all of the computer different probabilities we use can density estimation, Gaussian distance estimation, and I'll illustrated by example.",
                    "label": 0
                },
                {
                    "sent": "For instance, if we need to compute the probability of if I&J on chain, then we search for K nearest neighbors of role vector, sift ice if J and excitement so J, which is an offset between the two features.",
                    "label": 1
                },
                {
                    "sent": "The that we get from the image and then we compute the probability by standard KD as.",
                    "label": 0
                },
                {
                    "sent": "Shown here in this formula.",
                    "label": 0
                },
                {
                    "sent": "So for more details, please refer to the paper.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally I wanted to mention that style model, which is a popular model for object detection and many tasks in the computer vision can be seen useful variant of it can be seen as a special case of the chain mode chains model, in which the chains are off limits.",
                    "label": 1
                },
                {
                    "sent": "One we've pulled it in our paper and.",
                    "label": 1
                },
                {
                    "sent": "In addition, we have provide we have we in the paper will provide a lot of experiments showing that there is significant advantage in power detection of the chains model over the star model.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So before we skip the results, I would just.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to show you some examples of the feature graphs we obtained for the task of right hand detection in a couple of examples.",
                    "label": 0
                },
                {
                    "sent": "So here you see the feature graphs plotted using their edges.",
                    "label": 0
                },
                {
                    "sent": "The we plot only the some portion of the top scoring edges on each image.",
                    "label": 0
                },
                {
                    "sent": "The edges are colored in the jet colormap.",
                    "label": 0
                },
                {
                    "sent": "The red is more probable and blue is less probable.",
                    "label": 0
                },
                {
                    "sent": "And you can see why using this feature graphs the influence of the chains models had successfully detected the correct hand by searching for path leading from the face location to the candidate head locations and notice the interesting example below where the chains model successfully disambiguates between the crossed right and left hands, or the person which is evident from the future graph.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll just briefly go.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, some results here is some example results obtained on the sign language data set proposed by Patrick Bueler in 2008.",
                    "label": 1
                },
                {
                    "sent": "Again, the right hand detections are marked by green style and the left and attractions are marked by yellow Star.",
                    "label": 0
                },
                {
                    "sent": "And here we obtain a performance of about 85%, which is better than than previously reported in the literature.",
                    "label": 1
                },
                {
                    "sent": "Here we see examples and I just wanted to stress that in this and in all other experiments we apply our Model 2 separate images.",
                    "label": 0
                },
                {
                    "sent": "We do not use any motion formation.",
                    "label": 0
                },
                {
                    "sent": "And we also do not use call information.",
                    "label": 0
                },
                {
                    "sent": "So this is for this data set.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are some more examples on the other public datasets proposed by Vittorio Ferrari and 2008.",
                    "label": 0
                },
                {
                    "sent": "This is a Buffy data set.",
                    "label": 0
                },
                {
                    "sent": "And here we obtain results compareable to the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Please appreciate the large variability in appearance and poses.",
                    "label": 0
                },
                {
                    "sent": "Again, the notation of the hands is as I explained before.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are some additional examples on datasets which are actually frames of movie sequences, so I'm plotting the results on a movie on the movies.",
                    "label": 0
                },
                {
                    "sent": "Here in these 3 three movies, the task was to detect the right hand for which we had the ground truth, and in this movie we detect both hands and the.",
                    "label": 0
                },
                {
                    "sent": "I want to say about it is again that we do not use any motion formation.",
                    "label": 0
                },
                {
                    "sent": "All you see here is detection which will be computed for each frame separately and.",
                    "label": 0
                },
                {
                    "sent": "Well, floating.",
                    "label": 0
                },
                {
                    "sent": "The results, please appreciate.",
                    "label": 0
                },
                {
                    "sent": "Large variability in poses and also in this sign language example notice how it handles.",
                    "label": 0
                },
                {
                    "sent": "Self occlusions and motion blur.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we conclude we can also apply our approach to full object detection, not just parts.",
                    "label": 0
                },
                {
                    "sent": "Here's some example detections of cars from USC.",
                    "label": 0
                },
                {
                    "sent": "Data set was interesting about it.",
                    "label": 0
                },
                {
                    "sent": "Is that in order to detect full objects, we actually extend our model to work without any reference part.",
                    "label": 0
                },
                {
                    "sent": "So here here we allow the chains to originate not just in the reference part, but in any location on the image.",
                    "label": 0
                },
                {
                    "sent": "In the in the US, according to obtain, the comparable is out of state without.",
                    "label": 1
                },
                {
                    "sent": "You also have some small improvement over the state of the art in the basement horses data set chain not showing here.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, as we discussed at the beginning of the talk, the same model without changing anything can be trained for detecting other parts and even parts of other objects.",
                    "label": 0
                },
                {
                    "sent": "In the left movie The Chains model is used to detect all these three parts.",
                    "label": 0
                },
                {
                    "sent": "The face, the elbow in the hand.",
                    "label": 0
                },
                {
                    "sent": "And in the right movie, it's detecting the.",
                    "label": 0
                },
                {
                    "sent": "Found the left roof over horse.",
                    "label": 0
                },
                {
                    "sent": "So now I will conclude.",
                    "label": 0
                },
                {
                    "sent": "We have presented the single implemented model that is capable of training a detector for any part of any object without changing the model of the parameters.",
                    "label": 1
                },
                {
                    "sent": "The idea is that we detect difficult parts by extending detection, detecting, disambiguate difficult parts for extending detections of easy parts, and in the model the nearby features vote directly for the target.",
                    "label": 1
                },
                {
                    "sent": "About well, the following features, both through chains of intermediate features.",
                    "label": 0
                },
                {
                    "sent": "This way we exploit the internal context of the object in order to detect the parts.",
                    "label": 0
                },
                {
                    "sent": "And finally, the same approach can be used without using without any reference power detection, and in order to detect full objects, thank you.",
                    "label": 1
                },
                {
                    "sent": "I see a question back there.",
                    "label": 0
                },
                {
                    "sent": "Gentleman in front of the gentleman in the red shirt, tapping on the tap on the shoulder.",
                    "label": 0
                },
                {
                    "sent": "They want to drive.",
                    "label": 0
                },
                {
                    "sent": "You had a quest.",
                    "label": 0
                },
                {
                    "sent": "Could you, yeah, so the question was in the example of the multiple file detection world.",
                    "label": 0
                },
                {
                    "sent": "The Palace detection detected independently, or is there some dependence in the detection?",
                    "label": 0
                },
                {
                    "sent": "If I got the question correctly, so here in this example we detect the face in the independent detection mode just like for the cars or the horses and then we extend this detection to the elbows on the hands in.",
                    "label": 0
                },
                {
                    "sent": "Using the chains model.",
                    "label": 0
                },
                {
                    "sent": "Yes question.",
                    "label": 0
                },
                {
                    "sent": "I know that.",
                    "label": 0
                },
                {
                    "sent": "He reports a float, some results obtained offline.",
                    "label": 0
                },
                {
                    "sent": "This is not actually, it does not hardly runs in real time.",
                    "label": 0
                },
                {
                    "sent": "I think we have, you know, inefficient MATLAB implementation.",
                    "label": 0
                },
                {
                    "sent": "We have something about half a minute or frame running time.",
                    "label": 0
                },
                {
                    "sent": "Half a minute 30 seconds.",
                    "label": 0
                },
                {
                    "sent": "Currently, but it can be significant.",
                    "label": 0
                },
                {
                    "sent": "Can be done significally faster, first transferring some more optimal code and then using the different parameters for the nearest neighbor search.",
                    "label": 0
                },
                {
                    "sent": "You can control the level of the approximation of the nearest neighbors you can lose in the in the proximity of the neighbors, but gain in speed.",
                    "label": 0
                },
                {
                    "sent": "So actually we buy slight deterioration in the performance we can obtain about a second per frame.",
                    "label": 0
                },
                {
                    "sent": "In many examples we've seen this kind of.",
                    "label": 0
                },
                {
                    "sent": "Finding thing so and it can be of course made much faster with parallel software.",
                    "label": 0
                },
                {
                    "sent": "Hope this answers your question.",
                    "label": 0
                },
                {
                    "sent": "So I think that's it for the morning.",
                    "label": 0
                },
                {
                    "sent": "Let us thank this speaker and all other speakers.",
                    "label": 0
                }
            ]
        }
    }
}