{
    "id": "juwcnywtidh7sihu646wzwjjlrc4fqh6",
    "title": "Semi-supervised multi-target prediction for analysis of screening data",
    "info": {
        "author": [
            "Dragi Kocev, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "June 28, 2019",
        "recorded": "May 2019",
        "category": [
            "Top->Data Science",
            "Top->Computer Science->Big Data",
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/icgeb_kocev_screening_data/",
    "segmentation": [
        [
            "I will be presenting our work on semi supervised multi target prediction in various domains.",
            "And before continuing, I would like to say that most of the work was done within the PhD thesis Ifurita who is currently.",
            "Doing his postdoc in in Barcelona, so I would like to start so this will be more data science centered.",
            "Kind of talk.",
            "So I would like to start."
        ],
        [
            "Explaining what is semi supervised learning.",
            "In supervised learning, you have an amount of labeled data which is used to obtain a predictive model.",
            "In Semi supervised learning.",
            "On top of the labeled data, you have unlabeled data.",
            "Hoping that would lead to better predictive models.",
            "Where where can be where such cases are present well?",
            "Chem informatics.",
            "It's one of the areas where this is.",
            "Heavily present becausw.",
            "For instance, evaluating the toxicity of a compound in lab.",
            "It can take time.",
            "It's a tedious job and it you need resources to do it for a large amount of compounds.",
            "While on the other hand, there are freely available, the descriptions of compounds in public databases.",
            "For instance, Campbell has nearly two millions of compounds that were not tested.",
            "So on one hand we have labeled data which are hard to get and scars.",
            "On the other hand, we have unlabeled examples that are easy to get in there.",
            "Plenty of them.",
            "Semi supervised learning focuses.",
            "On exploiting both labeled and unlabeled data to get better to learn better predictive models.",
            "And to convince you that this is really needed, that this is."
        ],
        [
            "Indeed, the case I'm considering the datasets that Larissa presented her previous talk.",
            "Oh, so we have more than 3000 biological targets and each one of them is described with with.",
            "Some amount of compounds.",
            "This graph at least that on the X axis we have the number of commits.",
            "A histogram that says on the X axis we have the number of compounds and on the Y axis we have the count by how many.",
            "How many protein targets are targeted with this amount of compounds and we can see that a vast majority of the compounds has less than 100 annotations face the 100 labels.",
            "So.",
            "We we will show how we can exploit the amounts of unlabeled data to learn better models."
        ],
        [
            "The outline of my talk is as follows.",
            "I will introduce the problem.",
            "Then I will present the solution that we proposed, namely the same supervised predictive clustering trees.",
            "Then I'll show the evaluation that without that we did across various domains and illustrate this on an example of several qsar datasets.",
            "And finally I will provide some conclusions."
        ],
        [
            "Let me start by formally describing the task of semi supervised learning.",
            "So we assume that we are given an input space or a descriptive space that is a space where each of the example is described.",
            "For instance, if we consider compounds that can be a space of fingerprints of compound fingerprints.",
            "And then we have an output or target space which can be considered as a bioactivity profile, the bioactivity, the activity of a given compound on a given target.",
            "Then we have given a set of labeled examples that are examples that have both input and output spaces defined, and another set of examples for for who we have for which we have only the descriptive part, which is called unlabeled set of examples.",
            "Then also, we have given a quality criterion that guides the selection of best model.",
            "Then our goal.",
            "The task here is to find a model of function that will make predictions by maximizing the quality criterion that we have defined.",
            "The goal in semi supervised learning is to achieve to be better.",
            "Then learning supervised models.",
            "In essence, that means we want to exploit the information from the unlabeled part compared to using the labeled part.",
            "So let me illustrate this.",
            "On a real toy really toy example how it works.",
            "So."
        ],
        [
            "Assume that we have the task to predict.",
            "Persons gender based on a height and weight.",
            "So we have male and female male.",
            "Female are the circles malar.",
            "The access on the X axis we have the weight on the Y axis.",
            "We have the height.",
            "And we consider 10.",
            "These are a small amount of labeled data that we have.",
            "And if we consider only the label portion of the data, we can easily find that this is a very good predictive model.",
            "To this to discern between male or female.",
            "What happens if we plot now all the unlabeled data for which we don't know the gender?",
            "Then the graph is like that.",
            "Here on the on the histogram we showed this to the distribution of of the of the examples that we have.",
            "We can see that maybe the the decision boundary found by the supervised method it's not optimal, and if we try to run a semi supervised.",
            "Method then we get a slightly different tree that shifts the decision boundary towards the right.",
            "In this case, if we evaluate the performance of these two trees.",
            "If we include the gender information.",
            "We can see that the three that was learned only on the soup on the labeled examples had accuracy 82%, while the other that considers, also the unlabeled examples, has.",
            "90% so there is some information in the unlabeled portion of the data that can lead to better predictive models.",
            "So.",
            "Yes.",
            "Base.",
            "Because the information of the unlabeled data distribution is taken into account when learning the model, the model shift because he's seeing the the unlabeled data.",
            "Also, the space of the unlabeled data.",
            "Yes.",
            "Yeah.",
            "And this these are indeed real examples.",
            "We had, the trees are learned by a tree learner, so it's not."
        ],
        [
            "So the next issue that I want to to show it's why multi target prediction and why?",
            "What do we think when we say multi target prediction?",
            "Typically, in vast majority of the studies.",
            "When people talk about machine learning, they usually consider tasks that have primitive outputs as targets.",
            "For instance, typically the most typical tasks are classification and regression where.",
            "In the first, the task is to predict the value of a discrete variable, while in the second the task is to predict the value of a continuous variable.",
            "In many real life examples, especially in life Sciences.",
            "The output phase that the the the variables.",
            "There are multiple variables that we want to predict in the same time.",
            "The systems that you observe are more complex.",
            "For instance, in gene function prediction, gene can be annotated with multiple functions.",
            "In gene disease associations, 1 gene can be associated with multiple diseases.",
            "In drug gene interactions.",
            "So these representations are more complex than lead to the task of multi target prediction.",
            "There the task is to predict the values not on a single, not of a single variable, but on a couple of multiple variables.",
            "And now if this multiple variables are binary, then the task is multi label classification.",
            "If this multiple variables are continuous, the task is multi target regression.",
            "Here.",
            "There are two main types of methods that learn from such data.",
            "And they belong to the groups of the group.",
            "Either they are grouped into either global or local models.",
            "Now local models mean that I can essentially build.",
            "I can essentially learn a predictive model for each of the target variables in the in the tuple.",
            "This can be A and this is typically known as the binary relevance approach.",
            "This seems like a reasonable thing to do, but what to do in domains when the output sizes are in thousands?",
            "That that would mean that you would need to learn thousands of models towns.",
            "Really soon very fast becomes.",
            "Computationally expensive, expensive on the other hand, these local models are not able to exploit the commonalities that dependencies that might be present between the different target variables.",
            "So.",
            "Based on.",
            "Relatively large amount of experiments that we performed.",
            "We show that global models that consider the structure of the output space usually yield better results than local models.",
            "Now how we combine the task of semi supervised learning with multi target prediction.",
            "Let me start by you."
        ],
        [
            "Stating how semi supervised learning for simple classification look like looks like you have a descriptive space.",
            "If you have a let's say for instance, if this is a compound and to predict whether it is active for a given target or not.",
            "Then you have some compound descriptions and whether you have yes or no, depending whether it was found active or not, but or not all of the compounds were tested for all of the targets.",
            "So we have some question marks in the target space.",
            "For."
        ],
        [
            "Aggression if we consider the same example.",
            "Maybe we are predicting the activity and then the activity is is evaluated for handful of the compounds, but not for all of them.",
            "So we have question marks in the target space for the task of semi supervised learning for Multi label classification and semi supervised learning for multi target regression."
        ],
        [
            "The story line is a bit more complex, so we have missing values across the whole.",
            "The complete target space.",
            "This is illustrated for the task of multi label classification."
        ],
        [
            "This is for the task of multi label of multi target regression.",
            "So.",
            "That's how people usually deal with such with such data that when they encounter which methods have been proposed."
        ],
        [
            "So there are plethora of methods that are aimed at some specific tasks and their aim.",
            "They use some specific methods.",
            "There are lots of kernel based methods.",
            "There are graph based methods, scanners for all of this.",
            "Here we are proposing to use one method to resolve all of these tasks.",
            "So what are the limitations of the ones that we that are available in the literature?"
        ],
        [
            "These methods are tailored for specific types of prediction task.",
            "Most of them are for simple classification.",
            "Usually they they have high computational cost, so as you include lots of lots of unlabeled examples, the cost of Calculator calculation increases.",
            "They are difficult to use.",
            "By experts by non experts.",
            "So if you give some kernel based model or other complex model.",
            "Domain experts would find difficulty would find it difficult to understand why this model gives such predictions and how this model.",
            "What this model tells us.",
            "And then.",
            "All of the methods that were proposed are limited in terms of how they were and to the extent of their evaluation.",
            "In real life scenarios.",
            "So let me."
        ],
        [
            "Briefly.",
            "Illustrate what semi supervised predictive clustering trees are and how how did we.",
            "How did we design them?"
        ],
        [
            "So, predictive clustering trees are generalization of Decision tree stores.",
            "The task of.",
            "Predicting multiple targets, predicting complex targets.",
            "They inherit all the properties of decision trees so they are interpretable.",
            "There is there computationally efficient.",
            "And this figure illustrates one such predictive clustering 3, where the goal is to predict multiple numeric variables simultaneously.",
            "In the so if I use rated."
        ],
        [
            "In different ways.",
            "So this is a supervised tree where we can differentiate between internal notes and leaves, so the leaves.",
            "Contain the predictions which are calculated using prototype function.",
            "While the internal notes.",
            "Contain the splits which are selected based on the variance reduction.",
            "Supervised trees consider only the variance reduction in the output space.",
            "That is there, trying to learn to group examples that are close to each other in the output space.",
            "P cities have been instantiated for several tasks by."
        ],
        [
            "By defining a appropriate prototype and variance functions for multi target regression, the prototype is average and the various is simple average of the variances per target.",
            "Of course, all of the variances are normalized, so each of the targets contributes equally to the overall score.",
            "For multi target classification or Multi label classification we have Jeannie average Gini index across all targets or entropy are close.",
            "Prosol targets and for hierarchical multi label classification.",
            "We have weighted Euclidean distance that considers the hierarchical structure in the output space.",
            "What is different?",
            "But between supervised and semi supervised trees."
        ],
        [
            "Is the definition of the variance function.",
            "Here, the formula that we're using it's.",
            "Much more complex than the one that I'm showing.",
            "The point is that here instead of considering only the output space, we are at the same time considering the variance in the input space, and we we join these two together.",
            "Via A de W parameter.",
            "the W parameter controls the amount of supervision in the process.",
            "If we set W to 0.",
            "That means that the the the P city is learned completely in an honest unsupervised way.",
            "If we set it to one, that means that the the predictive clustering trees three is learned in completely supervised way.",
            "So setting W to one.",
            "That means that we are using only the variances for the for the output space.",
            "Setting it to zero, we are using only the variances in the input space, all in between.",
            "When we set W or something in between, it uses both spaces.",
            "Both both spaces.",
            "So this this combination is not that trivial.",
            "We need to resolve some issues that that come from combination of variances from different variables to making predictions with leaves of with four leaves with lots of missing values and so forth and so on.",
            "Basically this idea.",
            "Is inspired by the."
        ],
        [
            "General idea from the predictive clustering framework.",
            "Here in the predictive clustering framework, the aim is to look for clusters that are compact both in the input and the output space.",
            "So in these three graphs I'm showing different.",
            "Learning tasks that we can consider in the leftmost one considers illustrates the task of predictive modeling.",
            "Here, the goal is that the examples are close to each other in the target space.",
            "Hence the two class the system will find these two clusters.",
            "In the middle picture middle finger.",
            "The task of clustering is illustrated here.",
            "We are only interested in the input space in the descriptive space and other two clusters will be discovered, while in predictive clustering where we consider both the input in the output space.",
            "Three different clusters will be found, so this is.",
            "This is in essence the what we want to achieve.",
            "With with our with the semi supervised predictive clustering trees.",
            "So one."
        ],
        [
            "We have the same supervised predictive clustering trees.",
            "Whilst we have developed them, we can easily extend this into the ensemble learning framework, so instead of so we can learn various kind of semi supervised and samples.",
            "In we have implemented.",
            "Semi supervised random forest, semi supervised begging semi supervised.",
            "Random subspaces so forth and so on.",
            "So how did we if?"
        ],
        [
            "Valuated, the performance of the models that we learn."
        ],
        [
            "We consider several questions of interest, so first.",
            "We were in.",
            "We are interested in the predictive performance that we get with our models.",
            "The main question is, can we improve over supervised predictive clustering trees?",
            "How much?",
            "How much the amount of label data influences the performance?",
            "Next, we are interested in the influence on the W parameter.",
            "How much shifting the bar between unsupervised and supervised learning.",
            "Affects the performance.",
            "Then how much unlabeled data is enough?",
            "Whether whether we need tons of it or it's enough sum?",
            "Some smaller amount.",
            "Then we show how our models are interpretable in terms of in terms of model sizes.",
            "And then we show how these predictive models behave in simple prediction tasks like classification and regression."
        ],
        [
            "The experimental setup is shown here.",
            "We evaluated predictive clustering trees and random forests.",
            "We have benchmark datasets from various domains to show the generality of our approach.",
            "We consider various amounts of labeled data starting from 50, then up to 500.",
            "They will devaluation is that we are using the unlabeled data test set and then we optimize the W parameter using internal three fold cross validation.",
            "I will not go into details showing all the possible results that we got.",
            "But I'm illustrating some some of the."
        ],
        [
            "A performance is that that that you observed.",
            "For instance, these are three datasets, the first one, the left one is from multi label classification.",
            "The middle one is from hierarchical multi label classification.",
            "In the right one is from multi target regression.",
            "The Black line is single piece City, the Red one is same as supervised P City and then for the Violet is random forest.",
            "The yellow one is same supervised random forest.",
            "For the multi label classification hierarchy, Multi label classification more is better for the regression, less is better.",
            "So for regression is relative root mean squared error for the other two is area under the average precision recall curve.",
            "We can see that.",
            "Semi supervised predictive clustering trees.",
            "Again, achieve.",
            "Significantly better performance of supervised trees and that can be across all the amount of labeled examples that we have.",
            "We performed a statistical analysis of."
        ],
        [
            "The results, of course, and this the red ones are the results that showed to be statistically significant.",
            "We can see that for most of the cases.",
            "Semi supervised predictive clustering trees are winning and for there are lots of cases where this these wins are statistically significant for the ensembles.",
            "This does not carry over that easy.",
            "Our hypothesis there is that once you have a relatively powerful learning model learning method, then you cannot match improve.",
            "There are improvements, but they are not as big As for the cases with single trees.",
            "Then"
        ],
        [
            "There are some studies that show that only using unlabeled data can hurt.",
            "Can even hurt the performance because they are shifting the distributions.",
            "And we evaluate it.",
            "The influence of the W parameter to investigate how this relates.",
            "And we show that.",
            "If you consider all the 180 experiments, the amount of wins of semi supervised predictive clustering thesis.",
            "Words.",
            "Which shows that the W parameter profile provides a safety mechanism.",
            "How this mechanism is provided by the Internal Cross validation setting W2 closer to one or closer to 0 avoids hurting the performance by using improper amounts of unlabeled data.",
            "If we consider how much the unlabeled data bring."
        ],
        [
            "To the table.",
            "In terms of predictive potential for the for the models for the methods.",
            "We performed experiments that use the same.",
            "The same variances as semi supervised cities, but without adding unlabeled data.",
            "We observed that the win.",
            "In this case of semi supervised over this type of of the cities which are marked ethnicity double D plasty.",
            "Semi supervised win in 41%.",
            "That means that unlabeled data indeed are the ones that are responsible for the predictive performance improvement in semi supervised predictive clustering trees."
        ],
        [
            "Next, let let's observe the model sizes that we obtained.",
            "So this is.",
            "For the task of multi target regression on the X axis, we have the relative root mean squared error 4.",
            "The on the both axis we have Rd relative root mean squared errors and then the X is marked.",
            "The supervised predictive clustering trees.",
            "The circles Mark Semi supervised projective clustering trees all.",
            "All the if we see.",
            "Sorry on the X axis is the unpruned on the Y axis is the print we see that.",
            "Same is supervised.",
            "Models are less affected by pruning than supervised.",
            "Which means that these are overfitting less.",
            "To the data."
        ],
        [
            "Now let's let's see how how semi supervised predictive clustering trees behave in simple tasks like binary classification, multiclass classification, and regression.",
            "So we conducted serious experiments across several benchmark datasets and we see that we are able still able.",
            "To achieve statistically significant improvements, the difference here is that these improvements are also we can notice such statistically significant improvements also for the ensambles.",
            "So for the semi supervised random forests.",
            "So to further illustrate this with."
        ],
        [
            "Performed the illustrative study on four qsar datasets that.",
            "Relate to this four proteins in NK1, GSK, GSK, 38, Rock Two and HIV one?",
            "So these four datasets are described with the best fingerprints from the meta Qsar study FCFP and the NC.",
            "The notes.",
            "The amount of labeled data that is available for this for approach."
        ],
        [
            "The results that we obtained are shown on these graphs.",
            "We see that for the lower amounts of labeled data, semi supervised predictive clustering trees and examples are able to achieve semi supervised random forests are able to achieve better predictive performance as compared to their supervised counterparts.",
            "Now I talked about interpretability, but up until now I didn't show how how this comes to effect.",
            "So to further illustrate this."
        ],
        [
            "We did an experiment focusing on farnesyl transferase F test, so this is cancer related protein.",
            "We found 57 compounds that inhibit FPS in sacrament sister Visa.",
            "And extracted 70 four other compounds that have unknown inhibitory property.",
            "And have their Tanimoto similarity at least zero point 8 to the compounds that we already have.",
            "We used Max structural key fingerprints which are interpretable.",
            "Their length is 166.",
            "So this in essence are binary vectors that specify whether some.",
            "Part of a compound is present in the given compound.",
            "I will show figures later.",
            "How did how this how this look?",
            "In essence, the three that we obtain."
        ],
        [
            "Look like this.",
            "They are quite similar to each other.",
            "The only difference is is in.",
            "In these two notes, so in this one and this one, the same is supervised preferred.",
            "This structure, the supervised preferred this one.",
            "The performance, so here we can.",
            "We can observe that same is supervised have.",
            "Lower root mean squared error than the supervised counterpart.",
            "Now what do this?",
            "Cryptic symbols mean.",
            "So."
        ],
        [
            "This one refers to having.",
            "This kind of structure in the compound."
        ],
        [
            "This is on the top.",
            "One is with this annotations."
        ],
        [
            "This is this structure."
        ],
        [
            "And finally, this is the simple one with all plus."
        ],
        [
            "So the conclusions?"
        ],
        [
            "In the predictive clustering, trees are versatile in terms of the task that they can handle in, and this refers both to primitive outputs like classification and regression.",
            "And.",
            "Multi target prediction tasks such as multi label classification, multi target regression and hierarchical multi label classification.",
            "We show that these the same is supervised models improve the perf can improve the performance over their supervised counterparts and they overfit less on the training data.",
            "They are highly useful in practice, so we have this safety mechanism that prevents that.",
            "I think unlabeled data deteriorates the predicted performance.",
            "For some of the cases, the performance improvement in the sample case was not translated, as in the cases of single models.",
            "And finally, they are interpretable models that can.",
            "That can be easily understand by when showing them to a domain expert and seeing what these models tell us and with that.",
            "I'll conclude."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will be presenting our work on semi supervised multi target prediction in various domains.",
                    "label": 0
                },
                {
                    "sent": "And before continuing, I would like to say that most of the work was done within the PhD thesis Ifurita who is currently.",
                    "label": 0
                },
                {
                    "sent": "Doing his postdoc in in Barcelona, so I would like to start so this will be more data science centered.",
                    "label": 0
                },
                {
                    "sent": "Kind of talk.",
                    "label": 0
                },
                {
                    "sent": "So I would like to start.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Explaining what is semi supervised learning.",
                    "label": 1
                },
                {
                    "sent": "In supervised learning, you have an amount of labeled data which is used to obtain a predictive model.",
                    "label": 0
                },
                {
                    "sent": "In Semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "On top of the labeled data, you have unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "Hoping that would lead to better predictive models.",
                    "label": 0
                },
                {
                    "sent": "Where where can be where such cases are present well?",
                    "label": 0
                },
                {
                    "sent": "Chem informatics.",
                    "label": 0
                },
                {
                    "sent": "It's one of the areas where this is.",
                    "label": 0
                },
                {
                    "sent": "Heavily present becausw.",
                    "label": 0
                },
                {
                    "sent": "For instance, evaluating the toxicity of a compound in lab.",
                    "label": 0
                },
                {
                    "sent": "It can take time.",
                    "label": 0
                },
                {
                    "sent": "It's a tedious job and it you need resources to do it for a large amount of compounds.",
                    "label": 0
                },
                {
                    "sent": "While on the other hand, there are freely available, the descriptions of compounds in public databases.",
                    "label": 0
                },
                {
                    "sent": "For instance, Campbell has nearly two millions of compounds that were not tested.",
                    "label": 0
                },
                {
                    "sent": "So on one hand we have labeled data which are hard to get and scars.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, we have unlabeled examples that are easy to get in there.",
                    "label": 1
                },
                {
                    "sent": "Plenty of them.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised learning focuses.",
                    "label": 0
                },
                {
                    "sent": "On exploiting both labeled and unlabeled data to get better to learn better predictive models.",
                    "label": 0
                },
                {
                    "sent": "And to convince you that this is really needed, that this is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Indeed, the case I'm considering the datasets that Larissa presented her previous talk.",
                    "label": 0
                },
                {
                    "sent": "Oh, so we have more than 3000 biological targets and each one of them is described with with.",
                    "label": 1
                },
                {
                    "sent": "Some amount of compounds.",
                    "label": 0
                },
                {
                    "sent": "This graph at least that on the X axis we have the number of commits.",
                    "label": 1
                },
                {
                    "sent": "A histogram that says on the X axis we have the number of compounds and on the Y axis we have the count by how many.",
                    "label": 0
                },
                {
                    "sent": "How many protein targets are targeted with this amount of compounds and we can see that a vast majority of the compounds has less than 100 annotations face the 100 labels.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We we will show how we can exploit the amounts of unlabeled data to learn better models.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The outline of my talk is as follows.",
                    "label": 0
                },
                {
                    "sent": "I will introduce the problem.",
                    "label": 0
                },
                {
                    "sent": "Then I will present the solution that we proposed, namely the same supervised predictive clustering trees.",
                    "label": 1
                },
                {
                    "sent": "Then I'll show the evaluation that without that we did across various domains and illustrate this on an example of several qsar datasets.",
                    "label": 0
                },
                {
                    "sent": "And finally I will provide some conclusions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me start by formally describing the task of semi supervised learning.",
                    "label": 1
                },
                {
                    "sent": "So we assume that we are given an input space or a descriptive space that is a space where each of the example is described.",
                    "label": 1
                },
                {
                    "sent": "For instance, if we consider compounds that can be a space of fingerprints of compound fingerprints.",
                    "label": 0
                },
                {
                    "sent": "And then we have an output or target space which can be considered as a bioactivity profile, the bioactivity, the activity of a given compound on a given target.",
                    "label": 0
                },
                {
                    "sent": "Then we have given a set of labeled examples that are examples that have both input and output spaces defined, and another set of examples for for who we have for which we have only the descriptive part, which is called unlabeled set of examples.",
                    "label": 1
                },
                {
                    "sent": "Then also, we have given a quality criterion that guides the selection of best model.",
                    "label": 0
                },
                {
                    "sent": "Then our goal.",
                    "label": 1
                },
                {
                    "sent": "The task here is to find a model of function that will make predictions by maximizing the quality criterion that we have defined.",
                    "label": 0
                },
                {
                    "sent": "The goal in semi supervised learning is to achieve to be better.",
                    "label": 0
                },
                {
                    "sent": "Then learning supervised models.",
                    "label": 0
                },
                {
                    "sent": "In essence, that means we want to exploit the information from the unlabeled part compared to using the labeled part.",
                    "label": 0
                },
                {
                    "sent": "So let me illustrate this.",
                    "label": 0
                },
                {
                    "sent": "On a real toy really toy example how it works.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assume that we have the task to predict.",
                    "label": 0
                },
                {
                    "sent": "Persons gender based on a height and weight.",
                    "label": 0
                },
                {
                    "sent": "So we have male and female male.",
                    "label": 0
                },
                {
                    "sent": "Female are the circles malar.",
                    "label": 0
                },
                {
                    "sent": "The access on the X axis we have the weight on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "We have the height.",
                    "label": 0
                },
                {
                    "sent": "And we consider 10.",
                    "label": 0
                },
                {
                    "sent": "These are a small amount of labeled data that we have.",
                    "label": 0
                },
                {
                    "sent": "And if we consider only the label portion of the data, we can easily find that this is a very good predictive model.",
                    "label": 0
                },
                {
                    "sent": "To this to discern between male or female.",
                    "label": 0
                },
                {
                    "sent": "What happens if we plot now all the unlabeled data for which we don't know the gender?",
                    "label": 0
                },
                {
                    "sent": "Then the graph is like that.",
                    "label": 0
                },
                {
                    "sent": "Here on the on the histogram we showed this to the distribution of of the of the examples that we have.",
                    "label": 1
                },
                {
                    "sent": "We can see that maybe the the decision boundary found by the supervised method it's not optimal, and if we try to run a semi supervised.",
                    "label": 0
                },
                {
                    "sent": "Method then we get a slightly different tree that shifts the decision boundary towards the right.",
                    "label": 0
                },
                {
                    "sent": "In this case, if we evaluate the performance of these two trees.",
                    "label": 0
                },
                {
                    "sent": "If we include the gender information.",
                    "label": 1
                },
                {
                    "sent": "We can see that the three that was learned only on the soup on the labeled examples had accuracy 82%, while the other that considers, also the unlabeled examples, has.",
                    "label": 0
                },
                {
                    "sent": "90% so there is some information in the unlabeled portion of the data that can lead to better predictive models.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Base.",
                    "label": 0
                },
                {
                    "sent": "Because the information of the unlabeled data distribution is taken into account when learning the model, the model shift because he's seeing the the unlabeled data.",
                    "label": 1
                },
                {
                    "sent": "Also, the space of the unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And this these are indeed real examples.",
                    "label": 0
                },
                {
                    "sent": "We had, the trees are learned by a tree learner, so it's not.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the next issue that I want to to show it's why multi target prediction and why?",
                    "label": 0
                },
                {
                    "sent": "What do we think when we say multi target prediction?",
                    "label": 0
                },
                {
                    "sent": "Typically, in vast majority of the studies.",
                    "label": 1
                },
                {
                    "sent": "When people talk about machine learning, they usually consider tasks that have primitive outputs as targets.",
                    "label": 0
                },
                {
                    "sent": "For instance, typically the most typical tasks are classification and regression where.",
                    "label": 0
                },
                {
                    "sent": "In the first, the task is to predict the value of a discrete variable, while in the second the task is to predict the value of a continuous variable.",
                    "label": 0
                },
                {
                    "sent": "In many real life examples, especially in life Sciences.",
                    "label": 0
                },
                {
                    "sent": "The output phase that the the the variables.",
                    "label": 0
                },
                {
                    "sent": "There are multiple variables that we want to predict in the same time.",
                    "label": 0
                },
                {
                    "sent": "The systems that you observe are more complex.",
                    "label": 0
                },
                {
                    "sent": "For instance, in gene function prediction, gene can be annotated with multiple functions.",
                    "label": 1
                },
                {
                    "sent": "In gene disease associations, 1 gene can be associated with multiple diseases.",
                    "label": 0
                },
                {
                    "sent": "In drug gene interactions.",
                    "label": 0
                },
                {
                    "sent": "So these representations are more complex than lead to the task of multi target prediction.",
                    "label": 0
                },
                {
                    "sent": "There the task is to predict the values not on a single, not of a single variable, but on a couple of multiple variables.",
                    "label": 0
                },
                {
                    "sent": "And now if this multiple variables are binary, then the task is multi label classification.",
                    "label": 0
                },
                {
                    "sent": "If this multiple variables are continuous, the task is multi target regression.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "There are two main types of methods that learn from such data.",
                    "label": 0
                },
                {
                    "sent": "And they belong to the groups of the group.",
                    "label": 0
                },
                {
                    "sent": "Either they are grouped into either global or local models.",
                    "label": 1
                },
                {
                    "sent": "Now local models mean that I can essentially build.",
                    "label": 0
                },
                {
                    "sent": "I can essentially learn a predictive model for each of the target variables in the in the tuple.",
                    "label": 0
                },
                {
                    "sent": "This can be A and this is typically known as the binary relevance approach.",
                    "label": 0
                },
                {
                    "sent": "This seems like a reasonable thing to do, but what to do in domains when the output sizes are in thousands?",
                    "label": 0
                },
                {
                    "sent": "That that would mean that you would need to learn thousands of models towns.",
                    "label": 0
                },
                {
                    "sent": "Really soon very fast becomes.",
                    "label": 0
                },
                {
                    "sent": "Computationally expensive, expensive on the other hand, these local models are not able to exploit the commonalities that dependencies that might be present between the different target variables.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Based on.",
                    "label": 0
                },
                {
                    "sent": "Relatively large amount of experiments that we performed.",
                    "label": 0
                },
                {
                    "sent": "We show that global models that consider the structure of the output space usually yield better results than local models.",
                    "label": 0
                },
                {
                    "sent": "Now how we combine the task of semi supervised learning with multi target prediction.",
                    "label": 0
                },
                {
                    "sent": "Let me start by you.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stating how semi supervised learning for simple classification look like looks like you have a descriptive space.",
                    "label": 1
                },
                {
                    "sent": "If you have a let's say for instance, if this is a compound and to predict whether it is active for a given target or not.",
                    "label": 0
                },
                {
                    "sent": "Then you have some compound descriptions and whether you have yes or no, depending whether it was found active or not, but or not all of the compounds were tested for all of the targets.",
                    "label": 0
                },
                {
                    "sent": "So we have some question marks in the target space.",
                    "label": 1
                },
                {
                    "sent": "For.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Aggression if we consider the same example.",
                    "label": 0
                },
                {
                    "sent": "Maybe we are predicting the activity and then the activity is is evaluated for handful of the compounds, but not for all of them.",
                    "label": 0
                },
                {
                    "sent": "So we have question marks in the target space for the task of semi supervised learning for Multi label classification and semi supervised learning for multi target regression.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The story line is a bit more complex, so we have missing values across the whole.",
                    "label": 0
                },
                {
                    "sent": "The complete target space.",
                    "label": 0
                },
                {
                    "sent": "This is illustrated for the task of multi label classification.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is for the task of multi label of multi target regression.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's how people usually deal with such with such data that when they encounter which methods have been proposed.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are plethora of methods that are aimed at some specific tasks and their aim.",
                    "label": 0
                },
                {
                    "sent": "They use some specific methods.",
                    "label": 0
                },
                {
                    "sent": "There are lots of kernel based methods.",
                    "label": 0
                },
                {
                    "sent": "There are graph based methods, scanners for all of this.",
                    "label": 0
                },
                {
                    "sent": "Here we are proposing to use one method to resolve all of these tasks.",
                    "label": 0
                },
                {
                    "sent": "So what are the limitations of the ones that we that are available in the literature?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These methods are tailored for specific types of prediction task.",
                    "label": 1
                },
                {
                    "sent": "Most of them are for simple classification.",
                    "label": 0
                },
                {
                    "sent": "Usually they they have high computational cost, so as you include lots of lots of unlabeled examples, the cost of Calculator calculation increases.",
                    "label": 1
                },
                {
                    "sent": "They are difficult to use.",
                    "label": 1
                },
                {
                    "sent": "By experts by non experts.",
                    "label": 0
                },
                {
                    "sent": "So if you give some kernel based model or other complex model.",
                    "label": 0
                },
                {
                    "sent": "Domain experts would find difficulty would find it difficult to understand why this model gives such predictions and how this model.",
                    "label": 0
                },
                {
                    "sent": "What this model tells us.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "All of the methods that were proposed are limited in terms of how they were and to the extent of their evaluation.",
                    "label": 0
                },
                {
                    "sent": "In real life scenarios.",
                    "label": 0
                },
                {
                    "sent": "So let me.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Briefly.",
                    "label": 0
                },
                {
                    "sent": "Illustrate what semi supervised predictive clustering trees are and how how did we.",
                    "label": 1
                },
                {
                    "sent": "How did we design them?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, predictive clustering trees are generalization of Decision tree stores.",
                    "label": 1
                },
                {
                    "sent": "The task of.",
                    "label": 0
                },
                {
                    "sent": "Predicting multiple targets, predicting complex targets.",
                    "label": 0
                },
                {
                    "sent": "They inherit all the properties of decision trees so they are interpretable.",
                    "label": 0
                },
                {
                    "sent": "There is there computationally efficient.",
                    "label": 0
                },
                {
                    "sent": "And this figure illustrates one such predictive clustering 3, where the goal is to predict multiple numeric variables simultaneously.",
                    "label": 0
                },
                {
                    "sent": "In the so if I use rated.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In different ways.",
                    "label": 0
                },
                {
                    "sent": "So this is a supervised tree where we can differentiate between internal notes and leaves, so the leaves.",
                    "label": 0
                },
                {
                    "sent": "Contain the predictions which are calculated using prototype function.",
                    "label": 1
                },
                {
                    "sent": "While the internal notes.",
                    "label": 0
                },
                {
                    "sent": "Contain the splits which are selected based on the variance reduction.",
                    "label": 1
                },
                {
                    "sent": "Supervised trees consider only the variance reduction in the output space.",
                    "label": 0
                },
                {
                    "sent": "That is there, trying to learn to group examples that are close to each other in the output space.",
                    "label": 0
                },
                {
                    "sent": "P cities have been instantiated for several tasks by.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By defining a appropriate prototype and variance functions for multi target regression, the prototype is average and the various is simple average of the variances per target.",
                    "label": 0
                },
                {
                    "sent": "Of course, all of the variances are normalized, so each of the targets contributes equally to the overall score.",
                    "label": 0
                },
                {
                    "sent": "For multi target classification or Multi label classification we have Jeannie average Gini index across all targets or entropy are close.",
                    "label": 0
                },
                {
                    "sent": "Prosol targets and for hierarchical multi label classification.",
                    "label": 0
                },
                {
                    "sent": "We have weighted Euclidean distance that considers the hierarchical structure in the output space.",
                    "label": 0
                },
                {
                    "sent": "What is different?",
                    "label": 0
                },
                {
                    "sent": "But between supervised and semi supervised trees.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the definition of the variance function.",
                    "label": 1
                },
                {
                    "sent": "Here, the formula that we're using it's.",
                    "label": 0
                },
                {
                    "sent": "Much more complex than the one that I'm showing.",
                    "label": 0
                },
                {
                    "sent": "The point is that here instead of considering only the output space, we are at the same time considering the variance in the input space, and we we join these two together.",
                    "label": 0
                },
                {
                    "sent": "Via A de W parameter.",
                    "label": 0
                },
                {
                    "sent": "the W parameter controls the amount of supervision in the process.",
                    "label": 1
                },
                {
                    "sent": "If we set W to 0.",
                    "label": 0
                },
                {
                    "sent": "That means that the the the P city is learned completely in an honest unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "If we set it to one, that means that the the predictive clustering trees three is learned in completely supervised way.",
                    "label": 0
                },
                {
                    "sent": "So setting W to one.",
                    "label": 0
                },
                {
                    "sent": "That means that we are using only the variances for the for the output space.",
                    "label": 0
                },
                {
                    "sent": "Setting it to zero, we are using only the variances in the input space, all in between.",
                    "label": 0
                },
                {
                    "sent": "When we set W or something in between, it uses both spaces.",
                    "label": 0
                },
                {
                    "sent": "Both both spaces.",
                    "label": 0
                },
                {
                    "sent": "So this this combination is not that trivial.",
                    "label": 0
                },
                {
                    "sent": "We need to resolve some issues that that come from combination of variances from different variables to making predictions with leaves of with four leaves with lots of missing values and so forth and so on.",
                    "label": 0
                },
                {
                    "sent": "Basically this idea.",
                    "label": 0
                },
                {
                    "sent": "Is inspired by the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "General idea from the predictive clustering framework.",
                    "label": 1
                },
                {
                    "sent": "Here in the predictive clustering framework, the aim is to look for clusters that are compact both in the input and the output space.",
                    "label": 1
                },
                {
                    "sent": "So in these three graphs I'm showing different.",
                    "label": 0
                },
                {
                    "sent": "Learning tasks that we can consider in the leftmost one considers illustrates the task of predictive modeling.",
                    "label": 0
                },
                {
                    "sent": "Here, the goal is that the examples are close to each other in the target space.",
                    "label": 0
                },
                {
                    "sent": "Hence the two class the system will find these two clusters.",
                    "label": 0
                },
                {
                    "sent": "In the middle picture middle finger.",
                    "label": 0
                },
                {
                    "sent": "The task of clustering is illustrated here.",
                    "label": 0
                },
                {
                    "sent": "We are only interested in the input space in the descriptive space and other two clusters will be discovered, while in predictive clustering where we consider both the input in the output space.",
                    "label": 0
                },
                {
                    "sent": "Three different clusters will be found, so this is.",
                    "label": 0
                },
                {
                    "sent": "This is in essence the what we want to achieve.",
                    "label": 0
                },
                {
                    "sent": "With with our with the semi supervised predictive clustering trees.",
                    "label": 0
                },
                {
                    "sent": "So one.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have the same supervised predictive clustering trees.",
                    "label": 0
                },
                {
                    "sent": "Whilst we have developed them, we can easily extend this into the ensemble learning framework, so instead of so we can learn various kind of semi supervised and samples.",
                    "label": 1
                },
                {
                    "sent": "In we have implemented.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised random forest, semi supervised begging semi supervised.",
                    "label": 0
                },
                {
                    "sent": "Random subspaces so forth and so on.",
                    "label": 0
                },
                {
                    "sent": "So how did we if?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Valuated, the performance of the models that we learn.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We consider several questions of interest, so first.",
                    "label": 0
                },
                {
                    "sent": "We were in.",
                    "label": 0
                },
                {
                    "sent": "We are interested in the predictive performance that we get with our models.",
                    "label": 0
                },
                {
                    "sent": "The main question is, can we improve over supervised predictive clustering trees?",
                    "label": 1
                },
                {
                    "sent": "How much?",
                    "label": 1
                },
                {
                    "sent": "How much the amount of label data influences the performance?",
                    "label": 0
                },
                {
                    "sent": "Next, we are interested in the influence on the W parameter.",
                    "label": 0
                },
                {
                    "sent": "How much shifting the bar between unsupervised and supervised learning.",
                    "label": 1
                },
                {
                    "sent": "Affects the performance.",
                    "label": 0
                },
                {
                    "sent": "Then how much unlabeled data is enough?",
                    "label": 0
                },
                {
                    "sent": "Whether whether we need tons of it or it's enough sum?",
                    "label": 0
                },
                {
                    "sent": "Some smaller amount.",
                    "label": 0
                },
                {
                    "sent": "Then we show how our models are interpretable in terms of in terms of model sizes.",
                    "label": 0
                },
                {
                    "sent": "And then we show how these predictive models behave in simple prediction tasks like classification and regression.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The experimental setup is shown here.",
                    "label": 1
                },
                {
                    "sent": "We evaluated predictive clustering trees and random forests.",
                    "label": 1
                },
                {
                    "sent": "We have benchmark datasets from various domains to show the generality of our approach.",
                    "label": 0
                },
                {
                    "sent": "We consider various amounts of labeled data starting from 50, then up to 500.",
                    "label": 0
                },
                {
                    "sent": "They will devaluation is that we are using the unlabeled data test set and then we optimize the W parameter using internal three fold cross validation.",
                    "label": 1
                },
                {
                    "sent": "I will not go into details showing all the possible results that we got.",
                    "label": 0
                },
                {
                    "sent": "But I'm illustrating some some of the.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A performance is that that that you observed.",
                    "label": 0
                },
                {
                    "sent": "For instance, these are three datasets, the first one, the left one is from multi label classification.",
                    "label": 0
                },
                {
                    "sent": "The middle one is from hierarchical multi label classification.",
                    "label": 0
                },
                {
                    "sent": "In the right one is from multi target regression.",
                    "label": 0
                },
                {
                    "sent": "The Black line is single piece City, the Red one is same as supervised P City and then for the Violet is random forest.",
                    "label": 0
                },
                {
                    "sent": "The yellow one is same supervised random forest.",
                    "label": 0
                },
                {
                    "sent": "For the multi label classification hierarchy, Multi label classification more is better for the regression, less is better.",
                    "label": 0
                },
                {
                    "sent": "So for regression is relative root mean squared error for the other two is area under the average precision recall curve.",
                    "label": 0
                },
                {
                    "sent": "We can see that.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised predictive clustering trees.",
                    "label": 0
                },
                {
                    "sent": "Again, achieve.",
                    "label": 0
                },
                {
                    "sent": "Significantly better performance of supervised trees and that can be across all the amount of labeled examples that we have.",
                    "label": 0
                },
                {
                    "sent": "We performed a statistical analysis of.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The results, of course, and this the red ones are the results that showed to be statistically significant.",
                    "label": 0
                },
                {
                    "sent": "We can see that for most of the cases.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised predictive clustering trees are winning and for there are lots of cases where this these wins are statistically significant for the ensembles.",
                    "label": 0
                },
                {
                    "sent": "This does not carry over that easy.",
                    "label": 0
                },
                {
                    "sent": "Our hypothesis there is that once you have a relatively powerful learning model learning method, then you cannot match improve.",
                    "label": 0
                },
                {
                    "sent": "There are improvements, but they are not as big As for the cases with single trees.",
                    "label": 0
                },
                {
                    "sent": "Then",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some studies that show that only using unlabeled data can hurt.",
                    "label": 1
                },
                {
                    "sent": "Can even hurt the performance because they are shifting the distributions.",
                    "label": 0
                },
                {
                    "sent": "And we evaluate it.",
                    "label": 1
                },
                {
                    "sent": "The influence of the W parameter to investigate how this relates.",
                    "label": 0
                },
                {
                    "sent": "And we show that.",
                    "label": 1
                },
                {
                    "sent": "If you consider all the 180 experiments, the amount of wins of semi supervised predictive clustering thesis.",
                    "label": 0
                },
                {
                    "sent": "Words.",
                    "label": 0
                },
                {
                    "sent": "Which shows that the W parameter profile provides a safety mechanism.",
                    "label": 0
                },
                {
                    "sent": "How this mechanism is provided by the Internal Cross validation setting W2 closer to one or closer to 0 avoids hurting the performance by using improper amounts of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "If we consider how much the unlabeled data bring.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the table.",
                    "label": 0
                },
                {
                    "sent": "In terms of predictive potential for the for the models for the methods.",
                    "label": 0
                },
                {
                    "sent": "We performed experiments that use the same.",
                    "label": 0
                },
                {
                    "sent": "The same variances as semi supervised cities, but without adding unlabeled data.",
                    "label": 1
                },
                {
                    "sent": "We observed that the win.",
                    "label": 1
                },
                {
                    "sent": "In this case of semi supervised over this type of of the cities which are marked ethnicity double D plasty.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised win in 41%.",
                    "label": 0
                },
                {
                    "sent": "That means that unlabeled data indeed are the ones that are responsible for the predictive performance improvement in semi supervised predictive clustering trees.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next, let let's observe the model sizes that we obtained.",
                    "label": 1
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "For the task of multi target regression on the X axis, we have the relative root mean squared error 4.",
                    "label": 0
                },
                {
                    "sent": "The on the both axis we have Rd relative root mean squared errors and then the X is marked.",
                    "label": 0
                },
                {
                    "sent": "The supervised predictive clustering trees.",
                    "label": 0
                },
                {
                    "sent": "The circles Mark Semi supervised projective clustering trees all.",
                    "label": 0
                },
                {
                    "sent": "All the if we see.",
                    "label": 0
                },
                {
                    "sent": "Sorry on the X axis is the unpruned on the Y axis is the print we see that.",
                    "label": 0
                },
                {
                    "sent": "Same is supervised.",
                    "label": 0
                },
                {
                    "sent": "Models are less affected by pruning than supervised.",
                    "label": 1
                },
                {
                    "sent": "Which means that these are overfitting less.",
                    "label": 0
                },
                {
                    "sent": "To the data.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's let's see how how semi supervised predictive clustering trees behave in simple tasks like binary classification, multiclass classification, and regression.",
                    "label": 0
                },
                {
                    "sent": "So we conducted serious experiments across several benchmark datasets and we see that we are able still able.",
                    "label": 0
                },
                {
                    "sent": "To achieve statistically significant improvements, the difference here is that these improvements are also we can notice such statistically significant improvements also for the ensambles.",
                    "label": 0
                },
                {
                    "sent": "So for the semi supervised random forests.",
                    "label": 0
                },
                {
                    "sent": "So to further illustrate this with.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Performed the illustrative study on four qsar datasets that.",
                    "label": 1
                },
                {
                    "sent": "Relate to this four proteins in NK1, GSK, GSK, 38, Rock Two and HIV one?",
                    "label": 0
                },
                {
                    "sent": "So these four datasets are described with the best fingerprints from the meta Qsar study FCFP and the NC.",
                    "label": 0
                },
                {
                    "sent": "The notes.",
                    "label": 0
                },
                {
                    "sent": "The amount of labeled data that is available for this for approach.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The results that we obtained are shown on these graphs.",
                    "label": 0
                },
                {
                    "sent": "We see that for the lower amounts of labeled data, semi supervised predictive clustering trees and examples are able to achieve semi supervised random forests are able to achieve better predictive performance as compared to their supervised counterparts.",
                    "label": 0
                },
                {
                    "sent": "Now I talked about interpretability, but up until now I didn't show how how this comes to effect.",
                    "label": 0
                },
                {
                    "sent": "So to further illustrate this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We did an experiment focusing on farnesyl transferase F test, so this is cancer related protein.",
                    "label": 0
                },
                {
                    "sent": "We found 57 compounds that inhibit FPS in sacrament sister Visa.",
                    "label": 1
                },
                {
                    "sent": "And extracted 70 four other compounds that have unknown inhibitory property.",
                    "label": 1
                },
                {
                    "sent": "And have their Tanimoto similarity at least zero point 8 to the compounds that we already have.",
                    "label": 0
                },
                {
                    "sent": "We used Max structural key fingerprints which are interpretable.",
                    "label": 1
                },
                {
                    "sent": "Their length is 166.",
                    "label": 0
                },
                {
                    "sent": "So this in essence are binary vectors that specify whether some.",
                    "label": 0
                },
                {
                    "sent": "Part of a compound is present in the given compound.",
                    "label": 0
                },
                {
                    "sent": "I will show figures later.",
                    "label": 0
                },
                {
                    "sent": "How did how this how this look?",
                    "label": 0
                },
                {
                    "sent": "In essence, the three that we obtain.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look like this.",
                    "label": 0
                },
                {
                    "sent": "They are quite similar to each other.",
                    "label": 0
                },
                {
                    "sent": "The only difference is is in.",
                    "label": 0
                },
                {
                    "sent": "In these two notes, so in this one and this one, the same is supervised preferred.",
                    "label": 0
                },
                {
                    "sent": "This structure, the supervised preferred this one.",
                    "label": 0
                },
                {
                    "sent": "The performance, so here we can.",
                    "label": 0
                },
                {
                    "sent": "We can observe that same is supervised have.",
                    "label": 0
                },
                {
                    "sent": "Lower root mean squared error than the supervised counterpart.",
                    "label": 0
                },
                {
                    "sent": "Now what do this?",
                    "label": 0
                },
                {
                    "sent": "Cryptic symbols mean.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one refers to having.",
                    "label": 0
                },
                {
                    "sent": "This kind of structure in the compound.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is on the top.",
                    "label": 0
                },
                {
                    "sent": "One is with this annotations.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is this structure.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, this is the simple one with all plus.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the conclusions?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the predictive clustering, trees are versatile in terms of the task that they can handle in, and this refers both to primitive outputs like classification and regression.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Multi target prediction tasks such as multi label classification, multi target regression and hierarchical multi label classification.",
                    "label": 0
                },
                {
                    "sent": "We show that these the same is supervised models improve the perf can improve the performance over their supervised counterparts and they overfit less on the training data.",
                    "label": 0
                },
                {
                    "sent": "They are highly useful in practice, so we have this safety mechanism that prevents that.",
                    "label": 1
                },
                {
                    "sent": "I think unlabeled data deteriorates the predicted performance.",
                    "label": 1
                },
                {
                    "sent": "For some of the cases, the performance improvement in the sample case was not translated, as in the cases of single models.",
                    "label": 0
                },
                {
                    "sent": "And finally, they are interpretable models that can.",
                    "label": 0
                },
                {
                    "sent": "That can be easily understand by when showing them to a domain expert and seeing what these models tell us and with that.",
                    "label": 0
                },
                {
                    "sent": "I'll conclude.",
                    "label": 0
                }
            ]
        }
    }
}