{
    "id": "xvurtzbp3g7ywx5d7u7jasw3kqwmcwah",
    "title": "The Interplay of Machine Learning and Mechanism Design",
    "info": {
        "author": [
            "David C. Parkes, Harvard School of Engineering and Applied Sciences, Harvard University"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Social Sciences->Economics"
        ]
    },
    "url": "http://videolectures.net/nips2010_parkes_iml/",
    "segmentation": [
        [
            "I'd like to talk today about a interesting interface between machine learning and mechanism design.",
            "We can think about the goal of machine learning in a certain sense as."
        ],
        [
            "Learning a hypothesis with the input, providing a.",
            "Given distribution over inputs, you can think about mechanism design as designing a decision role that will use on inputs that are held privately.",
            "And I think there are some interesting similarities, and we'll see differences between these agendas.",
            "You can think about one of the goals of machine learning is identifying a hypothesis and in mechanism design we often think about designing a decision rule G that is taking inputs from multiple agents.",
            "So X raised to the power N and producing an output.",
            "And the key distinction in mechanism design is the inputs will be held by agents.",
            "They will be privately held, and the agents will be self interested.",
            "Now a key concept."
        ],
        [
            "It's in mechanism.",
            "Design is incentive compatibility.",
            "Let me illustrate that.",
            "Let's"
        ],
        [
            "Take a very simple setting where we're trying to position a fire station on a 01 line.",
            "The preferences of the agents here are single peaked, so here is some example."
        ],
        [
            "Where the peak represents the location of the fire station that the agent most prefers.",
            "So here this agent most prefers the fire station would be located here.",
            "What Milam proposed as a mechanism.",
            "If to locate the fire station at the median of the peaks."
        ],
        [
            "Interesting because as you move the."
        ],
        [
            "Peak here, the median doesn't move."
        ],
        [
            "Until."
        ],
        [
            "She pulls the median away from.",
            "The position that she."
        ],
        [
            "Most prefers so the agent would like the fire station to be here as she pushes her preference the Pico.",
            "The decision we make only gets worse.",
            "Notice the mean rule would not have this property in the mean rule.",
            "She'd over report all the way over here."
        ],
        [
            "We give you another simple example.",
            "This is an example of an auction for a single item.",
            "Suppose I have some wine to sell and the bidders are all around here.",
            "Now the question you might ask.",
            "Let's say that we suppose that we're going to sell the item to Mr Green here question you might ask, is what price?",
            "And some prices that seem reasonable.",
            "The price is between 8:00 and 10:00.",
            "Yeah, so the second highest today, the highest is 10.",
            "So maybe will charge in this range somewhere.",
            "And indeed a competitive equilibrium price would be any price in that range.",
            "Well, Vickrey proposed was to charge the second price, which is the minimal of these prices, and this has some nice properties, which is now the Mr Green can just be truthful now.",
            "We've decoupled his bid price and the price he pays is not the same as his bid.",
            "Another way to think about this is that the allocation rule is monotone an for all bids higher than 8.",
            "Then he would win, and so we should charge the smallest amount.",
            "OK, so again this is a example of a very simple mechanism where the inputs are privately held.",
            "In this case, they're just individual numbers.",
            "And the social decision that we wanted to make was to allocate the item for the agent with the highest value.",
            "Received the item and we provided incentive compatibility."
        ],
        [
            "So abstractly, then you can think about a mechanism as receiving N inputs X one through XN.",
            "And then determining a choice.",
            "We have a choice Roar GX which determines the choice instead in some abstract space Y.",
            "And potentially determining payments.",
            "One of the mechanisms I described had payments, the other one didn't have payments.",
            "OK, now what is X1 through XNXI defines the value of Agent I for all possible choices Y.",
            "So what this says here?",
            "So this is the value of Agent I on choice Y."
        ],
        [
            "And the key property of incentive compatibility that I've described informally so far is that the value the agent gets when it reports its true input XI minus the price it pays."
        ],
        [
            "Should be at least of much of the value it would get minus the price it pays for all other reports XI prime that it might submit, and this should hold for all agents for all inputs.",
            "OK, so this just says whatever the inputs of the other agents, your best input is to provide your best strategy as a self interested agent is that you should report your input truthfully and not then miss report.",
            "OK."
        ],
        [
            "What I want to talk about in my talk is different connections between Emelin, MD.",
            "I've provided in my introduction alittle bit about MD 'cause I think we're all more knowledgeable about ML here and I want to break down what I talk about in two ML4MD and MD4ML.",
            "So on the left hand side we're going to see problems that are intrinsically problems of social choice and on the right hand side will see problems that are intrinsically learning problems.",
            "One thing you might use machine learning for is to operationalize mechanisms or interested in elicitation in clearing.",
            "You might use it to design mechanisms.",
            "You might use it to learn the distribution on inputs.",
            "How might we use mechanism design when solving machine learning problems?",
            "We might have a stopping problem.",
            "Where the inputs are privately held.",
            "We might have an online learning problem where the rewards that are revealed overtime are privately held.",
            "Well, we might have a supervised learning problem where the data is privately held.",
            "And in each of these cases, we'd like to make the learning algorithms incentive compatible.",
            "So I'm not going to talk about all of these, but I don't have enough time, but I'm going to spend a little time talking about the ones in gold and then a tiny amount of time talking about the ones in blue and one of them white.",
            "I'll skip."
        ],
        [
            "Let me first of all talk about elicitation and how we can use learning to provide illicite."
        ],
        [
            "Ocean.",
            "And for this I want to situate what I tell you in the context of auctions on multiple items.",
            "A combinatorial auction is an auction with M goods, M distinct goods.",
            "N agents and then the the inputs is quite complex.",
            "The valuation function of an agent X of I is its value for all subsets of goods, so it's value for each subset of good of goods.",
            "This can represent complements and substitutes and so forth.",
            "So you can say that you only want a left shoe if you get a right shoe.",
            "You can say you only want one hotel room.",
            "You can represent this all in the valuation function."
        ],
        [
            "Now.",
            "We'd like to design auctions where the agents don't report that information in one step, so we'd like to query the agents.",
            "And we'd like to query the agents until we have a proof that we know what the outcome of the mechanism is."
        ],
        [
            "In order to talk about this, let me introduce the notion of a language, so bidding language will be a way to represent, hopefully, in a way that's quite compact.",
            "The evaluation function.",
            "Let me describe for this purpose this set B as an example, which is a set of atoms.",
            "It's it's a set of pairs of a package of goods and a value.",
            "And then, given this we can think."
        ],
        [
            "About different languages that will define the semantics of the valuation.",
            "One language that we might think of is the X or language where the value on a bundle, say AB, would be the maximum on the value of the subsets included in AB.",
            "So the value of a B is 12 because 12 is a maximum of these two values value and ABC again would be the value of the Max value of all of the subsets."
        ],
        [
            "In the old language you would basically look for the maximum weighted set packing, so you would you would take the atoms and you would try to fit them into the package and you can think about various languages for each of these languages you can ask whether it's expressive and you can ask whether it's compact language for a particular valuation distribution."
        ],
        [
            "OK, now given this, we can make a connection with learning theory, an exact query learning.",
            "So if I now describe.",
            "The minimal representation size in a language.",
            "OK, is the size of the valuation in that language.",
            "That we can think about different goals that we might take in terms of using learning theory to elicit one goal that you might think of is to essentially do exact query learning.",
            "Where you going to insist the number of queries you use our polynomial in the size of the minimal representation, the number of goods from the number of agents and where, rather than the membership and equivalence queries that we used to in learning theory will have value queries and demand queries.",
            "Demand query is where I show you prices and I ask you which bundle you prefer at those prices.",
            "Now another goal you might think of because after all, we don't really want to learn all the valuation functions is to determine the outcome of the mechanism quickly.",
            "And this is the goal that I want to talk about.",
            "So we're going to try to design A protocol that will query the bidders such that we can efficiently determine the outcome of the mechanism.",
            "OK, so in learning theory we think about equivalence queries.",
            "Is a hypothesis correct on a particular input?",
            "And then the answer is either no, it should be Y prime and we can think of or yes and we can think about membership queries.",
            "Say what is FX4 for auctions it's natural to think about demand queries.",
            "I say does this bundle Y maximize your utility at the prices?",
            "I've a yes or no.",
            "I prefer this other bundle and I might ask what is your value?",
            "Now given this, what we did in this work was we."
        ],
        [
            "We considered adopting different representation languages for different agents.",
            "We simulate the membership queries as value queries.",
            "So we use learning algorithms here and here and here.",
            "When every learning algorithm is stalled, waiting on an equivalent query, what we're going to do."
        ],
        [
            "Do.",
            "Is.",
            "We're going to take the current manifest so the current hypothesis of the valuations we're going to optimistically solve the winner determination problem in the pricing problem.",
            "We're going to compute a competitive equilibrium outcome, which I alluded to earlier.",
            "This is something that would provide us with a proof that the allocation is efficient, and then we're going to use this equilibrium as a demand query.",
            "We're going to say OK. Are you happy with this equilibrium?",
            "And then if the agent for say yes, we stop.",
            "We haven't learned exactly, but we know enough to prove that we have the efficient outcome if at least one agent serves no.",
            "I prefer why prime then I can simulate the equivalent query.",
            "And I can keep going.",
            "OK, so you can show that for that if you can do polynomial query learning you can do polynomial query elicitation.",
            "And one interesting thing about this framework is it's nice and modular.",
            "You can use different representation classes for different agents.",
            "Now he didn't mention self interest.",
            "Let me join."
        ],
        [
            "Make a comment about that.",
            "In this context, go back to the single item auction example where I said that the price you should charge his aides and they said that the competitive equilibrium prices were between 8:00 and 10:00 by charge more than 10.",
            "The fellow doesn't sell a good if I ask for less than 8, then Mr Green and Mr. Red would like the good.",
            "I asked between 8:00 and 10:00, then I'm good.",
            "Now I can also ask what do the competitive equilibrium prices look like when I take each agent out of the system 1 by 1, so I'm going to take out Agent Green on colibria prices would be between 8:00 and 6:00.",
            "Take out Mr Red between Ted and fix.",
            "Take out Mr Blue between 10 and eight, take out most pink between 10:00 and 8:00.",
            "And now I can say give me one price that in the support of all of these and that would be 8.",
            "And we call that the universal competitive equilibrium price.",
            "And it turns out that you can show that any communication protocol that determines the outcome of the generalization of the Vickrey auction necessarily determines you see prices, and vice versa, and therefore what we can do is we can extend the framework I showed you.",
            "We can compute universal competitive equilibrium, and we have incentive compatibility as well.",
            "OK."
        ],
        [
            "The second thing I wanted to chat about is clearing."
        ],
        [
            "And for this I'd like to describe some recent ideas in using kernel methods.",
            "Normally when you clear a combinatorial auction.",
            "And you care about incentive compatibility.",
            "You might appeal to the Vickrey auction.",
            "In this context, which would involve you solving M + 1 optimization problems when you're solving things on the Internet scale, this is not acceptable."
        ],
        [
            "And so the hey has been working on using kernel methods.",
            "Now, the advantages of the kernel methods here, which I'll explain all that you can compute the allocation and pain."
        ],
        [
            "In one step.",
            "You can represent nonlinear prices as linear prices in a high dimensional space, and we use the kernel trick there.",
            "OK, so I'm essentially going to project a package.",
            "Which is a 01 bit vector into a high dimensional space and then my prices will be a weight vector.",
            "And then we can use.",
            "We can use different kernels for different price bases."
        ],
        [
            "I think one of the most interesting things is a very nice connection between stability in the fiscal learning sense and UCE and therefore incentives."
        ],
        [
            "Let me mention this.",
            "Well the hey shows is that you can first of all think about how you might formulate the winner determination problem as an optimization problem.",
            "This is for the single minded setting, so the agents input.",
            "It's just a single value and a package of goods, so your each interest is in one unique package of goods.",
            "The package might be different over the agents.",
            "OK, so.",
            "First idea is well, that's just.",
            "That's that's just fines alphas that maximize value.",
            "Well, this would be infeasible 'cause I would."
        ],
        [
            "Over allocate, so I'm going to penalize my allocation.",
            "Not going to spend a lot of time explaining this term, but you can think about this term as essentially where penalising the amount by which we're overselling.",
            "Case for beta K is going to be available on entire allocations, and this is basically this will do something like looking across all allocations and making sure each allocation is feasible.",
            "Now.",
            "For those of you familiar with SVM, so this looks like the SVM dual problem for auctions.",
            "This is like the.",
            "Primal problem when we go into our dual space, we're now computing prices.",
            "So I've got a convex optimization problem here.",
            "I'm going to go into my dual space and this is going to look like the primal problem in Efms, where now Pi is the profit for Agent I in my dual and \u03c0 zero is the revenue and this is something like the best response constraints.",
            "This says that agent I is happy at the prices.",
            "And then the final term you need in the dual is a regularization term.",
            "And W will represent the vector that will capture prices.",
            "So the interesting thing is that this very natural framework makes leads to a connection between regularization, which provides stability and getting closer to you the prices.",
            "So as you increase Lambda.",
            "The prices will be selected such that they become less sensitive to the individual input of anyone agent.",
            "And what you can show is you can show that if if W is the optimal."
        ],
        [
            "Door solution and W -- I is optimal without a.",
            "Then you can actually bound the difference between these vectors and it will depend on on capper which is.",
            "Parameterising the complexity of the kernel, lower kapper is higher complexity and Lambda and then you can obtain a resort for incentive compatibility.",
            "And eventually what we see if we see this nice connection between regularization, the complexity of a kernel and incentive properties."
        ],
        [
            "OK.",
            "So the next thing I wanted to talk about was using learning for the design of mechanisms.",
            "Now I'm going to talk about its use for the design of voting rules, but I will talk about its use in the design of auction rules."
        ],
        [
            "When we're solving the combinatorial auction problem.",
            "If you think that each of these dots is a distinct item.",
            "And the.",
            "The sections here represents the demand of an individual agent and if it's helpful here that these have become separators.",
            "This means that we have a feasible solution.",
            "What we're trying to do to get strategy proofness so to get incentive compatibility is to find prices that separate in this sense.",
            "And where the prices don't depend at all on the input of the agent that we're pricing, if we can find such prices, then we have incentive compatibility."
        ],
        [
            "OK, so the problem statement that I'd like to describe a solution to here is if I give you an allocation algorithm.",
            "Which is characterized by a function that Maps inputs into a allocation of goods.",
            "I'd like to find a payment rule that is in a formal sense maximally incentive compatible.",
            "And I'd like to use support vector machines.",
            "In achieving the."
        ],
        [
            "Essentially what you can do.",
            "Is you can generate data so you sample from an underlying distribution on valuation functions for each of those samples you run the allocation algorithm that you're given.",
            "And you get a new data point.",
            "And then we're going to look to train a classifier.",
            "It will be a multi classifier.",
            "Essentially, we're going to use the discriminative function of the classifier to perform pricing.",
            "Kasota"
        ],
        [
            "Your very simple example.",
            "Go back to the single item allocation problem.",
            "Where for a single item the input X is just a vector of reals, just the value of each agent.",
            "And the output just going to focus on agent one and this will hold for all agent from the same way.",
            "The output of the allocation algorithm is plus one.",
            "If you're allocated a -- 1 if you're not allocated, so the input data might look like 10, eight, 7.",
            "There were three agents.",
            "Their bids are ten, 8, seven and one.",
            "This means that agent one is allocated 'cause its value is higher than the other values 587 its value is lower and minus 1925.",
            "And plus one.",
            "This is what the training data might look like, and we're going to try to learn a discriminative function F. Well, then the hypothesis are classified.",
            "We just depends on the sign of F."
        ],
        [
            "When notice that an exact classifier.",
            "Probably see this an exact classifier here would use FX equal to the value of Agent 1 minus the Max of the other values.",
            "If this is is positive, the agent should be allocated.",
            "If this is negative, the agent should not be allocated."
        ],
        [
            "And the particular thing we're going to require is we're going to impose some structure on the discriminative function.",
            "We're going to impose the discriminative function is linear in the value of agent one and potentially nonlinear in the values of the other agents.",
            "And then I'm going to pick up this term as the payment.",
            "Actually minus the payment and by doing so, the discriminant function gives me exactly the payoff of an agent.",
            "OK, this is the value of the agent minus the price it has to pay.",
            "If it's allocated so by insisting on this particular structure I get a nice correspondence between the discriminative function and the utility of an A."
        ],
        [
            "Now for strategy proofness you need the following thing you needed to the beat to be the case if whenever your value.",
            "Is greater than the amount I'm charging you?",
            "You're allocated the good and whenever your value is less than that of that amount, you're not allocated the good.",
            "This is the case.",
            "You'll have incentive compatibility and notice that this is exactly true when we have an exact classifier.",
            "Because of this connection between the discriminative function and the value minus the price."
        ],
        [
            "I should say this work is unpublished.",
            "I wanted to talk about it because I think it's it's an interesting direction.",
            "There's a working paper on my web page.",
            "The general problem here then for the combinatorial auction problem is that the input is a vector in.",
            "Kind of the concatenated vectors defining the valuation function of each agent and the classification problem is a multi classification problem where now it's not minus 1 + 1.",
            "It's which package is the agent allocated for those inputs in the underlying allocation algorithm, sorta.",
            "Why is and then our goal is to learn a hypothesis in the same way and will take the structural SVM approach, where will say that the hypothesis should be computed as the argmax.",
            "Oven underlying discriminative function."
        ],
        [
            "And again, I'm going to stipulate the special structure, which makes things nicely separable.",
            "This will become the payment function in the same way."
        ],
        [
            "Hey.",
            "I have a structural SVM problem where the nice correspondence between the training problem of minimum which you see in the literature and in our setting becomes minimizing a regularize upper bounds on empirical regret."
        ],
        [
            "And we have the same kind of theorem I showed you before, which is again if you have an exact classifier, you have identified prices that make the allocation rule coupled with these prices incentive compatible."
        ],
        [
            "So I'm going to switch gears now and I'm going to talk about mechanism design for machine learning problems.",
            "So we're going to move over to this side.",
            "In doing that, then we just briefly mentioned that there is also work on learning distributions both in the context of dynamic auctions and in the context of auctions for digital goods.",
            "So moving to this other side, now I want to talk about first the secretary problem."
        ],
        [
            "Very briefly.",
            "So in the normal secretary problem.",
            "You imagine that you're online.",
            "You're given a a rival sequence of choices you might make, and when each new choice arrives.",
            "You're given the information as to whether this choice is better than all the previous choices.",
            "And you're told how many choices you should expect and you're seeking to compete with the offline algorithm that would pick the choice that for best.",
            "And the asymptotically optimal thing to do in the worst case is to sample for around 1 / E of the inputs, so observe.",
            "And then, given that you now know the best you've seen so far, forward from that, you'll acccept and you'll accept the best input that you see after that.",
            "Now you can make an interesting analogue now to a dynamic auction problem where the arriving objects are now bidders with private information about their value.",
            "And I'd like to do the same kind of thing.",
            "I'd essentially like to be able to learn something about the underlying distribution.",
            "Even though the inputs are privately held and I need incentive compatibility."
        ],
        [
            "OK, So what we showed in this paper is that as long as you're careful about handling the transition from the learning phase into the accepting phase and the particular concern is that there might be an agent who arrived just before the transition but is patient, the transition occurs during his patience and therefore could, if you're not careful, manipulate the auction to his advantage by delaying his arrival into the system.",
            "We have to be careful about things like that, but as long as we are.",
            "Then we can get incentive compatibility and we can get essentially the same competitive analysis as you get in the standard problem."
        ],
        [
            "The second example I wanted to briefly talk about along the same lines.",
            "Is an exploration exploitation problem modeled as the band?"
        ],
        [
            "It's problem.",
            "OK, so now I want you to imagine that behind each arm is an agent.",
            "And the agent when you activate her arm, which you can think about, is giving her a good or giving her a resource that lets her be able to sample her value for that resource in the environment.",
            "I want you to think that she gets that information privately.",
            "OK, so every every time you activate the process behind the agent, she gets a private observation about whether the value behind the scenes is low or high.",
            "And I'd like to be able to do something like Bayesian optimal learning, despite the fact that the agents are privately observing this information.",
            "So assume a prior on the underlying distribution.",
            "And assume that I would like to maximize expected discounted value with respect to that prior.",
            "And in fact, you can do this.",
            "You can take the Vickrey auction that we've seen a few Times Now, and you can generalize it.",
            "You can make it work in a dynamic setting where the equivalent of winner determination becomes the efficient policy that makes the right tradeoff between exploration and exploitation, and you essentially make agents play make agents pay.",
            "Excuse me, the expected.",
            "Marginal externality they impose on the other agents.",
            "So in this setting where the agents are assumed to be basean, meaning that they are happy to maximize expected utility.",
            "You can achieve essentially first best you can do the same algorithm you would use if you could observe the information."
        ],
        [
            "Second comments I make on the bandits problem with inputs that are coming from self interested agents.",
            "Is about a variation now where and this variation was motivated by sponsored Ferge, where you're seeing uncertain clicks on an advert and you're going to ask an advertiser to describe his willingness to pay for every click.",
            "But as a mechanism you don't understand yet, the click through rate on different adverts.",
            "So then the setting is a little bit different than before.",
            "Now the mechanism does get to observe a click.",
            "But the only private information now is the value per click.",
            "So at the start of time I'm going to ask Agent one and Agent 2 to report their value.",
            "And then what I'd like is I'd like incentive compatibility in the strong dominant strategy sense I had at the start of my talk, so I'd like it to be the case, or whatever the uncertain realization of clicks, whatever the reports of other agents, you should be truthful.",
            "Anne."
        ],
        [
            "And in a nice paper anythi 09.",
            "Essentially, this problem was discussed and hear this bad news.",
            "Essentially for this bandits problem where you insist on this very strong form of incentive compatibility, you have to separate exploration and exploitation an the intuition for the difficulty.",
            "Is that?",
            "In order to compute prices that would make the algorithm incentive compatible.",
            "I would need to know the information the click that would have a curd if I had activated the bandwidth in a different way.",
            "So I need this counter factual information off the learning path, and without that information I can't get incentive compatibility in this strong sense, and therefore you have new constraints on the algorithm and therefore you have new regret bounds.",
            "Essentially, that's what goes wrong here.",
            "So if you switch from this basean incentive compatible.",
            "Way of solving the problem till this worst case.",
            "You get.",
            "Worse results."
        ],
        [
            "So the last thing that I wanted to chat about now was.",
            "Incentive compatible supervised learning and I'm going to describe in particular work on incentive compatible regression."
        ],
        [
            "OK, so in the framing of this problem, let us suppose that the mechanism is interested in learning hypothesis F, which is a mapping from inputs into a real.",
            "And that is, suppose that each agent.",
            "Has a private distribution.",
            "So piece of eye is the distribution from which agent I samples.",
            "It's examples and is the distribution it cares about in terms of error, and that is also suppose that each agent has its own target function in mind.",
            "So suppose let's say that.",
            "Each agent represents the store and the stores are reporting data to the center about the sales that they've been achieving on their inventory.",
            "So take yourself back to a world without information technology systems so the sensor is not able to actually observe that, and then based on this information that is, suppose that the sensor representing the Corporation is going to try to learn a function to try to understand what's selling well and what is not selling well and then based on that.",
            "It's going to offend knew shipments.",
            "There's a setting where the training examples are distributed is reasonable to expect.",
            "There would be self interest in misreporting that data, and that is suppose that each agent cares about the risk with respect to its own distribution.",
            "Pizza by.",
            "Anne has an error function that depends on the on the divergent between the prediction and the target that it holds, and that is suppose that the social goal is to pick an F the maximizes or minimizes the total expected risk in this sense."
        ],
        [
            "Like I said, the twist on the standard problem is the data is privately held.",
            "And that agent might then miss report."
        ],
        [
            "Satan.",
            "So Dekle ET al.",
            "In working on this incentive compatible machine learning framework, then insisted that there were no payments and thought about the problem in the following way.",
            "The mechanism will request endpoints from each agent.",
            "So these are the points from Agent I.",
            "And then based on these reported points, will train and determine a function F."
        ],
        [
            "And the question is which kinds of learning ideas will provide incentive compatibility?",
            "And then it's suppose first of all just to focus ourselves that we select a function F prime.",
            "That's the empirical risk minimizer, and we want to know when will that be incentive compatible."
        ],
        [
            "OK, so the warm up let's suppose that each agent actually only cares about one point, so the distribution is a degenerate distribution on that point.",
            "And the agent will report its own label."
        ],
        [
            "There.",
            "A theorem is that if you have.",
            "Linear.",
            "Loss functions, absolute loss functions, and a convex hypothesis class.",
            "Then, the ERM, is incentive compatible."
        ],
        [
            "Let me show you an example of this that suppose that the hypothesis class is the constant hypothesis.",
            "Then because of this loss function, if these are the three points owned by different agents, the way to minimize absolute loss is the median rule which we saw at the thoughts of my talk.",
            "Yeah, so by by choosing this as the hypothesis, you minimize the sum absolute error.",
            "And we already saw that median gives you incentive compatibility.",
            "Flats"
        ],
        [
            "Ice.",
            "But this fails for other loss functions.",
            "So for example, if you care about the squareds error and let's say there are two agents with Y values, 2 and 0.",
            "Then the right thing to do would be to put the hypothesis right in the middle and then I have the same problem with the mean I described earlier.",
            "So what these authors have done in their work?"
        ],
        [
            "Is then to try to generalize this they've considered then more than one point and still sticking with this absolute loss function.",
            "And the question is, what can you do when the input now is that each agent owns more than one point?"
        ],
        [
            "OK, let's consider a simple example with two agents.",
            "Again, where the hypothesis class is the constant hypothesis and agent one has three points and agent two has these other three points and you can ignore the X values and just focus on the Y values.",
            "OK, so in this case the there are lots of different things that would minimize the empirical absolute loss.",
            "One thing you might do is pick the constant function 0.",
            "So let's say that we do that.",
            "Let's say that we break ties in favor of the minimum function.",
            "In this case, the empirical risk to agent one is 2/3 because the prediction is wrong on two of its points, an right or one of its points.",
            "But this is not incentive compatible.",
            "Well, that agent can do is to pretend that the third data points actually had the Y value of 1.",
            "In this case, the ERM solution.",
            "Now there are four 120 that be to pick one, and now the agents risk is improved."
        ],
        [
            "OK, so the solution that's described in the paper is to project.",
            "This high dimensional data down to a lower dimension where you eventually do if you take the median solution for each agent individually, and then you combine those medians into one median.",
            "This is the project and fit idea that these are."
        ],
        [
            "As described, and they show, this gives you a three competitive worst case learning algorithm and they also show that if now the agents don't just have these endpoints, but the points are being sampled from underlying distribution, you get approximate incentive compatibility.",
            "So I described this here as an example of some of the initial work that's been done on incentive compatible supervised learning."
        ],
        [
            "So I'm moving towards wrapping up.",
            "Let me just make a quick comment about what I think.",
            "Is an interesting challenge problem that the community here is, I think, likely interested in.",
            "And maybe one of the reasons why I was asked to give this talk, but I I don't have anything deep to say about this at this point, which is that?",
            "If you think that mechanism design is essentially at least within the setting with money is about trying to find good designs of transfer payments between agents.",
            "And if you think that from an AI perspective, we're interested in modular intelligent systems.",
            "Then can we now take the decade of development with we see in on computational mechanism design and can we use that to bring back into computer science into AI and machine learning?",
            "Especially for the design of intrinsic rewards for the transfer of reward between different modules using payments and so forth.",
            "So essentially this would not be an appeal to self interest because each of these modules is.",
            "Somehow working on a different team.",
            "Let's say this appeal to self interest because that's a useful way to modular eyes and architecture and then how can we use transfer payments and prices and things like this in order to mediate between these different modules?",
            "You think about this, perhaps as a market of minds.",
            "I think this is an interesting direction.",
            "So I've talked about."
        ],
        [
            "10 pieces I wanted to emphasize that the interface between machine learning and mechanism design is quite rich and I think quite surprising when you see it for the first time.",
            "The different ways in which the fields are finding ways to use each other.",
            "I've emphasized this distinction between.",
            "Using machine learning methods for operationalizing designing or learning distributions in the context of MD and then using MD in the context of ML problems, where now you might imagine the inputs are self interested be held.",
            "So I think I'll stop and take questions that may end by thanking you all.",
            "And if you have any questions we have time, thanks.",
            "Question."
        ],
        [
            "So is there any work done on modeling where the protocol between the bidders and the center?",
            "I guess where the bidders don't understand exactly there's some possibility of miscommunication where the bidders think they're bidding on 2001 Toyota, but they're really bidding on a 2000 field or something, so there's some noise or error in the process.",
            "OK, so the so the question is, has it been work in the maximum design context where the agents have intrinsic uncertainty about the valuations they have, for example well or about the items they are bidding on right?",
            "And therefore about the values?",
            "There's there's different kinds of work on that one, I think well known problem is the lemons problem where the seller is not able to credibly describe the quality of the underlying good, and therefore you get this bad equilibrium where everybody assumes the good is bad and the high quality sellers leave the market.",
            "So there's a lot of classic work on that.",
            "The the solution so that, for example, is to use reputation to fold reputation algorithms on top of this.",
            "So you learn something about the long term credibility of the seller.",
            "The other strand of literature that might be helpful to know about is this work where my value depends on information that you have.",
            "So I didn't emphasize this, but everything I talked about here was private values where the inputs are privately held and is sufficient to describe your utility function.",
            "And then there's the literature in maximum design theory on interdependant values where now.",
            "My value depends on your private information as well.",
            "You can think about we're drilling for oil.",
            "I'm buying a antique picture etc.",
            "And there is work on that as well.",
            "The vanilla expected utility problem doesn't pose much of a difficult if the agents are risk neutral.",
            "So I'd like to add something to talk, which is, I think there's a shared foundation between mechanism design machine learning, which is generalized notion of proper scoring rules from proper scoring rule, you can derive a mechanism from proper scoring rule.",
            "You can also derive a learning algorithm, and I guess the generalized notion of this lets you capture much marching properties and just probability of things.",
            "Right, that's great.",
            "Thank you so, so there's quite a lot of extremely interesting work using scoring rules.",
            "Scoring rules are.",
            "Proper when it's in the best interest of an agent to report information it has about an uncertain event.",
            "OK, and.",
            "I have been working in recent years both in economics and in computer science.",
            "On trying to understand what statistics of distributions you can elicit in that approach and also connecting scoring rules with information markets, I didn't talk about information markets, I totally could have done and I maybe should have done information markets are extremely interesting there designed to aggregate information that's held by lots of people to predict something about an uncertain event.",
            "And this work.",
            "Bringing proper scoring rules into their design.",
            "So so if I think about agents on the Internet, or if I think about it, bidders on eBay, there are lots of cases in which the agents are too stupid to realize that the mechanism is incentive compatible.",
            "Is there any way of getting at that?",
            "Right, OK, yeah so.",
            "This is a difficult problem, I agree.",
            "Let me say a couple of things.",
            "One thing is that.",
            "You might think that bid is for advertising or also.",
            "Maybe not super sophisticated and it was the case there that search engine switched away from first price into something that's not incentive compatible, but it's nicely stable.",
            "And essentially I think if you believe that there are learning dynamics where people are learning how to play, then if you have something that's stable, at least the learning dynamics may be more stable, so you don't need to believe that people necessarily our reasoning about the mechanism, but they're exploring and trying to learn how to bid.",
            "And even there you can get benefits.",
            "But generally you point to an interesting direction.",
            "One challenge is how can we describe mechanisms that are simple enough and make them understandable enough?",
            "We'd like incentive compatible things because we can provide normative advice, but somehow people have to believe that there's a trust issue.",
            "Maybe people don't believe you're collecting the second price.",
            "This is a problem for, again, search engine's that are on both sides of the market, often times, and then the third thing is, can we develop a mechanism design that explicitly handles?",
            "This bounded rationality of agents, little bit of work on that, but I think there should be much more.",
            "So I kind of want to answer Charles.",
            "So there's a sense in which for some mechanism designs, if you have wealth getting transferred and the agent you have agents were playing well, another one agent or not, you can prove that the overall online regrettable system is is like online learning against an adversary type regrets, which says that the overall, even though some agents are performing badly and other ones are doing well, the ones that perform badly will end up with very little money and then and then you just have the ones with the money will be the ones that are performing well.",
            "I'm not sure I quite got the question.",
            "Was it about bidders with budget constraints?",
            "It wasn't a question, it was really comment on Charles over the comments, OK?",
            "Is the covenant?",
            "I'll say it's a great comment and I'll take leave now to answer the question.",
            "OK, so let's thank our speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'd like to talk today about a interesting interface between machine learning and mechanism design.",
                    "label": 0
                },
                {
                    "sent": "We can think about the goal of machine learning in a certain sense as.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning a hypothesis with the input, providing a.",
                    "label": 1
                },
                {
                    "sent": "Given distribution over inputs, you can think about mechanism design as designing a decision role that will use on inputs that are held privately.",
                    "label": 1
                },
                {
                    "sent": "And I think there are some interesting similarities, and we'll see differences between these agendas.",
                    "label": 0
                },
                {
                    "sent": "You can think about one of the goals of machine learning is identifying a hypothesis and in mechanism design we often think about designing a decision rule G that is taking inputs from multiple agents.",
                    "label": 0
                },
                {
                    "sent": "So X raised to the power N and producing an output.",
                    "label": 0
                },
                {
                    "sent": "And the key distinction in mechanism design is the inputs will be held by agents.",
                    "label": 0
                },
                {
                    "sent": "They will be privately held, and the agents will be self interested.",
                    "label": 0
                },
                {
                    "sent": "Now a key concept.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's in mechanism.",
                    "label": 0
                },
                {
                    "sent": "Design is incentive compatibility.",
                    "label": 0
                },
                {
                    "sent": "Let me illustrate that.",
                    "label": 0
                },
                {
                    "sent": "Let's",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take a very simple setting where we're trying to position a fire station on a 01 line.",
                    "label": 0
                },
                {
                    "sent": "The preferences of the agents here are single peaked, so here is some example.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where the peak represents the location of the fire station that the agent most prefers.",
                    "label": 0
                },
                {
                    "sent": "So here this agent most prefers the fire station would be located here.",
                    "label": 0
                },
                {
                    "sent": "What Milam proposed as a mechanism.",
                    "label": 0
                },
                {
                    "sent": "If to locate the fire station at the median of the peaks.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting because as you move the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Peak here, the median doesn't move.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Until.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She pulls the median away from.",
                    "label": 0
                },
                {
                    "sent": "The position that she.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most prefers so the agent would like the fire station to be here as she pushes her preference the Pico.",
                    "label": 0
                },
                {
                    "sent": "The decision we make only gets worse.",
                    "label": 0
                },
                {
                    "sent": "Notice the mean rule would not have this property in the mean rule.",
                    "label": 0
                },
                {
                    "sent": "She'd over report all the way over here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We give you another simple example.",
                    "label": 0
                },
                {
                    "sent": "This is an example of an auction for a single item.",
                    "label": 0
                },
                {
                    "sent": "Suppose I have some wine to sell and the bidders are all around here.",
                    "label": 0
                },
                {
                    "sent": "Now the question you might ask.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we suppose that we're going to sell the item to Mr Green here question you might ask, is what price?",
                    "label": 0
                },
                {
                    "sent": "And some prices that seem reasonable.",
                    "label": 0
                },
                {
                    "sent": "The price is between 8:00 and 10:00.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the second highest today, the highest is 10.",
                    "label": 0
                },
                {
                    "sent": "So maybe will charge in this range somewhere.",
                    "label": 0
                },
                {
                    "sent": "And indeed a competitive equilibrium price would be any price in that range.",
                    "label": 0
                },
                {
                    "sent": "Well, Vickrey proposed was to charge the second price, which is the minimal of these prices, and this has some nice properties, which is now the Mr Green can just be truthful now.",
                    "label": 0
                },
                {
                    "sent": "We've decoupled his bid price and the price he pays is not the same as his bid.",
                    "label": 0
                },
                {
                    "sent": "Another way to think about this is that the allocation rule is monotone an for all bids higher than 8.",
                    "label": 0
                },
                {
                    "sent": "Then he would win, and so we should charge the smallest amount.",
                    "label": 0
                },
                {
                    "sent": "OK, so again this is a example of a very simple mechanism where the inputs are privately held.",
                    "label": 0
                },
                {
                    "sent": "In this case, they're just individual numbers.",
                    "label": 0
                },
                {
                    "sent": "And the social decision that we wanted to make was to allocate the item for the agent with the highest value.",
                    "label": 0
                },
                {
                    "sent": "Received the item and we provided incentive compatibility.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So abstractly, then you can think about a mechanism as receiving N inputs X one through XN.",
                    "label": 1
                },
                {
                    "sent": "And then determining a choice.",
                    "label": 0
                },
                {
                    "sent": "We have a choice Roar GX which determines the choice instead in some abstract space Y.",
                    "label": 0
                },
                {
                    "sent": "And potentially determining payments.",
                    "label": 0
                },
                {
                    "sent": "One of the mechanisms I described had payments, the other one didn't have payments.",
                    "label": 0
                },
                {
                    "sent": "OK, now what is X1 through XNXI defines the value of Agent I for all possible choices Y.",
                    "label": 0
                },
                {
                    "sent": "So what this says here?",
                    "label": 0
                },
                {
                    "sent": "So this is the value of Agent I on choice Y.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the key property of incentive compatibility that I've described informally so far is that the value the agent gets when it reports its true input XI minus the price it pays.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should be at least of much of the value it would get minus the price it pays for all other reports XI prime that it might submit, and this should hold for all agents for all inputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so this just says whatever the inputs of the other agents, your best input is to provide your best strategy as a self interested agent is that you should report your input truthfully and not then miss report.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What I want to talk about in my talk is different connections between Emelin, MD.",
                    "label": 0
                },
                {
                    "sent": "I've provided in my introduction alittle bit about MD 'cause I think we're all more knowledgeable about ML here and I want to break down what I talk about in two ML4MD and MD4ML.",
                    "label": 0
                },
                {
                    "sent": "So on the left hand side we're going to see problems that are intrinsically problems of social choice and on the right hand side will see problems that are intrinsically learning problems.",
                    "label": 1
                },
                {
                    "sent": "One thing you might use machine learning for is to operationalize mechanisms or interested in elicitation in clearing.",
                    "label": 0
                },
                {
                    "sent": "You might use it to design mechanisms.",
                    "label": 0
                },
                {
                    "sent": "You might use it to learn the distribution on inputs.",
                    "label": 0
                },
                {
                    "sent": "How might we use mechanism design when solving machine learning problems?",
                    "label": 0
                },
                {
                    "sent": "We might have a stopping problem.",
                    "label": 0
                },
                {
                    "sent": "Where the inputs are privately held.",
                    "label": 1
                },
                {
                    "sent": "We might have an online learning problem where the rewards that are revealed overtime are privately held.",
                    "label": 1
                },
                {
                    "sent": "Well, we might have a supervised learning problem where the data is privately held.",
                    "label": 0
                },
                {
                    "sent": "And in each of these cases, we'd like to make the learning algorithms incentive compatible.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to talk about all of these, but I don't have enough time, but I'm going to spend a little time talking about the ones in gold and then a tiny amount of time talking about the ones in blue and one of them white.",
                    "label": 0
                },
                {
                    "sent": "I'll skip.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me first of all talk about elicitation and how we can use learning to provide illicite.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ocean.",
                    "label": 0
                },
                {
                    "sent": "And for this I want to situate what I tell you in the context of auctions on multiple items.",
                    "label": 0
                },
                {
                    "sent": "A combinatorial auction is an auction with M goods, M distinct goods.",
                    "label": 0
                },
                {
                    "sent": "N agents and then the the inputs is quite complex.",
                    "label": 1
                },
                {
                    "sent": "The valuation function of an agent X of I is its value for all subsets of goods, so it's value for each subset of good of goods.",
                    "label": 0
                },
                {
                    "sent": "This can represent complements and substitutes and so forth.",
                    "label": 0
                },
                {
                    "sent": "So you can say that you only want a left shoe if you get a right shoe.",
                    "label": 0
                },
                {
                    "sent": "You can say you only want one hotel room.",
                    "label": 0
                },
                {
                    "sent": "You can represent this all in the valuation function.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "We'd like to design auctions where the agents don't report that information in one step, so we'd like to query the agents.",
                    "label": 0
                },
                {
                    "sent": "And we'd like to query the agents until we have a proof that we know what the outcome of the mechanism is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to talk about this, let me introduce the notion of a language, so bidding language will be a way to represent, hopefully, in a way that's quite compact.",
                    "label": 0
                },
                {
                    "sent": "The evaluation function.",
                    "label": 0
                },
                {
                    "sent": "Let me describe for this purpose this set B as an example, which is a set of atoms.",
                    "label": 0
                },
                {
                    "sent": "It's it's a set of pairs of a package of goods and a value.",
                    "label": 1
                },
                {
                    "sent": "And then, given this we can think.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About different languages that will define the semantics of the valuation.",
                    "label": 0
                },
                {
                    "sent": "One language that we might think of is the X or language where the value on a bundle, say AB, would be the maximum on the value of the subsets included in AB.",
                    "label": 0
                },
                {
                    "sent": "So the value of a B is 12 because 12 is a maximum of these two values value and ABC again would be the value of the Max value of all of the subsets.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the old language you would basically look for the maximum weighted set packing, so you would you would take the atoms and you would try to fit them into the package and you can think about various languages for each of these languages you can ask whether it's expressive and you can ask whether it's compact language for a particular valuation distribution.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now given this, we can make a connection with learning theory, an exact query learning.",
                    "label": 1
                },
                {
                    "sent": "So if I now describe.",
                    "label": 0
                },
                {
                    "sent": "The minimal representation size in a language.",
                    "label": 0
                },
                {
                    "sent": "OK, is the size of the valuation in that language.",
                    "label": 0
                },
                {
                    "sent": "That we can think about different goals that we might take in terms of using learning theory to elicit one goal that you might think of is to essentially do exact query learning.",
                    "label": 1
                },
                {
                    "sent": "Where you going to insist the number of queries you use our polynomial in the size of the minimal representation, the number of goods from the number of agents and where, rather than the membership and equivalence queries that we used to in learning theory will have value queries and demand queries.",
                    "label": 0
                },
                {
                    "sent": "Demand query is where I show you prices and I ask you which bundle you prefer at those prices.",
                    "label": 0
                },
                {
                    "sent": "Now another goal you might think of because after all, we don't really want to learn all the valuation functions is to determine the outcome of the mechanism quickly.",
                    "label": 0
                },
                {
                    "sent": "And this is the goal that I want to talk about.",
                    "label": 0
                },
                {
                    "sent": "So we're going to try to design A protocol that will query the bidders such that we can efficiently determine the outcome of the mechanism.",
                    "label": 0
                },
                {
                    "sent": "OK, so in learning theory we think about equivalence queries.",
                    "label": 0
                },
                {
                    "sent": "Is a hypothesis correct on a particular input?",
                    "label": 0
                },
                {
                    "sent": "And then the answer is either no, it should be Y prime and we can think of or yes and we can think about membership queries.",
                    "label": 1
                },
                {
                    "sent": "Say what is FX4 for auctions it's natural to think about demand queries.",
                    "label": 0
                },
                {
                    "sent": "I say does this bundle Y maximize your utility at the prices?",
                    "label": 0
                },
                {
                    "sent": "I've a yes or no.",
                    "label": 0
                },
                {
                    "sent": "I prefer this other bundle and I might ask what is your value?",
                    "label": 0
                },
                {
                    "sent": "Now given this, what we did in this work was we.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We considered adopting different representation languages for different agents.",
                    "label": 0
                },
                {
                    "sent": "We simulate the membership queries as value queries.",
                    "label": 0
                },
                {
                    "sent": "So we use learning algorithms here and here and here.",
                    "label": 0
                },
                {
                    "sent": "When every learning algorithm is stalled, waiting on an equivalent query, what we're going to do.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "We're going to take the current manifest so the current hypothesis of the valuations we're going to optimistically solve the winner determination problem in the pricing problem.",
                    "label": 0
                },
                {
                    "sent": "We're going to compute a competitive equilibrium outcome, which I alluded to earlier.",
                    "label": 0
                },
                {
                    "sent": "This is something that would provide us with a proof that the allocation is efficient, and then we're going to use this equilibrium as a demand query.",
                    "label": 0
                },
                {
                    "sent": "We're going to say OK. Are you happy with this equilibrium?",
                    "label": 0
                },
                {
                    "sent": "And then if the agent for say yes, we stop.",
                    "label": 0
                },
                {
                    "sent": "We haven't learned exactly, but we know enough to prove that we have the efficient outcome if at least one agent serves no.",
                    "label": 0
                },
                {
                    "sent": "I prefer why prime then I can simulate the equivalent query.",
                    "label": 0
                },
                {
                    "sent": "And I can keep going.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can show that for that if you can do polynomial query learning you can do polynomial query elicitation.",
                    "label": 0
                },
                {
                    "sent": "And one interesting thing about this framework is it's nice and modular.",
                    "label": 0
                },
                {
                    "sent": "You can use different representation classes for different agents.",
                    "label": 0
                },
                {
                    "sent": "Now he didn't mention self interest.",
                    "label": 0
                },
                {
                    "sent": "Let me join.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Make a comment about that.",
                    "label": 0
                },
                {
                    "sent": "In this context, go back to the single item auction example where I said that the price you should charge his aides and they said that the competitive equilibrium prices were between 8:00 and 10:00 by charge more than 10.",
                    "label": 0
                },
                {
                    "sent": "The fellow doesn't sell a good if I ask for less than 8, then Mr Green and Mr. Red would like the good.",
                    "label": 0
                },
                {
                    "sent": "I asked between 8:00 and 10:00, then I'm good.",
                    "label": 0
                },
                {
                    "sent": "Now I can also ask what do the competitive equilibrium prices look like when I take each agent out of the system 1 by 1, so I'm going to take out Agent Green on colibria prices would be between 8:00 and 6:00.",
                    "label": 0
                },
                {
                    "sent": "Take out Mr Red between Ted and fix.",
                    "label": 0
                },
                {
                    "sent": "Take out Mr Blue between 10 and eight, take out most pink between 10:00 and 8:00.",
                    "label": 0
                },
                {
                    "sent": "And now I can say give me one price that in the support of all of these and that would be 8.",
                    "label": 0
                },
                {
                    "sent": "And we call that the universal competitive equilibrium price.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that you can show that any communication protocol that determines the outcome of the generalization of the Vickrey auction necessarily determines you see prices, and vice versa, and therefore what we can do is we can extend the framework I showed you.",
                    "label": 0
                },
                {
                    "sent": "We can compute universal competitive equilibrium, and we have incentive compatibility as well.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second thing I wanted to chat about is clearing.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for this I'd like to describe some recent ideas in using kernel methods.",
                    "label": 1
                },
                {
                    "sent": "Normally when you clear a combinatorial auction.",
                    "label": 0
                },
                {
                    "sent": "And you care about incentive compatibility.",
                    "label": 0
                },
                {
                    "sent": "You might appeal to the Vickrey auction.",
                    "label": 0
                },
                {
                    "sent": "In this context, which would involve you solving M + 1 optimization problems when you're solving things on the Internet scale, this is not acceptable.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the hey has been working on using kernel methods.",
                    "label": 0
                },
                {
                    "sent": "Now, the advantages of the kernel methods here, which I'll explain all that you can compute the allocation and pain.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In one step.",
                    "label": 0
                },
                {
                    "sent": "You can represent nonlinear prices as linear prices in a high dimensional space, and we use the kernel trick there.",
                    "label": 1
                },
                {
                    "sent": "OK, so I'm essentially going to project a package.",
                    "label": 0
                },
                {
                    "sent": "Which is a 01 bit vector into a high dimensional space and then my prices will be a weight vector.",
                    "label": 0
                },
                {
                    "sent": "And then we can use.",
                    "label": 1
                },
                {
                    "sent": "We can use different kernels for different price bases.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think one of the most interesting things is a very nice connection between stability in the fiscal learning sense and UCE and therefore incentives.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me mention this.",
                    "label": 0
                },
                {
                    "sent": "Well the hey shows is that you can first of all think about how you might formulate the winner determination problem as an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "This is for the single minded setting, so the agents input.",
                    "label": 0
                },
                {
                    "sent": "It's just a single value and a package of goods, so your each interest is in one unique package of goods.",
                    "label": 0
                },
                {
                    "sent": "The package might be different over the agents.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "First idea is well, that's just.",
                    "label": 0
                },
                {
                    "sent": "That's that's just fines alphas that maximize value.",
                    "label": 0
                },
                {
                    "sent": "Well, this would be infeasible 'cause I would.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over allocate, so I'm going to penalize my allocation.",
                    "label": 0
                },
                {
                    "sent": "Not going to spend a lot of time explaining this term, but you can think about this term as essentially where penalising the amount by which we're overselling.",
                    "label": 0
                },
                {
                    "sent": "Case for beta K is going to be available on entire allocations, and this is basically this will do something like looking across all allocations and making sure each allocation is feasible.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "For those of you familiar with SVM, so this looks like the SVM dual problem for auctions.",
                    "label": 0
                },
                {
                    "sent": "This is like the.",
                    "label": 0
                },
                {
                    "sent": "Primal problem when we go into our dual space, we're now computing prices.",
                    "label": 0
                },
                {
                    "sent": "So I've got a convex optimization problem here.",
                    "label": 0
                },
                {
                    "sent": "I'm going to go into my dual space and this is going to look like the primal problem in Efms, where now Pi is the profit for Agent I in my dual and \u03c0 zero is the revenue and this is something like the best response constraints.",
                    "label": 0
                },
                {
                    "sent": "This says that agent I is happy at the prices.",
                    "label": 0
                },
                {
                    "sent": "And then the final term you need in the dual is a regularization term.",
                    "label": 0
                },
                {
                    "sent": "And W will represent the vector that will capture prices.",
                    "label": 0
                },
                {
                    "sent": "So the interesting thing is that this very natural framework makes leads to a connection between regularization, which provides stability and getting closer to you the prices.",
                    "label": 0
                },
                {
                    "sent": "So as you increase Lambda.",
                    "label": 0
                },
                {
                    "sent": "The prices will be selected such that they become less sensitive to the individual input of anyone agent.",
                    "label": 0
                },
                {
                    "sent": "And what you can show is you can show that if if W is the optimal.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Door solution and W -- I is optimal without a.",
                    "label": 1
                },
                {
                    "sent": "Then you can actually bound the difference between these vectors and it will depend on on capper which is.",
                    "label": 0
                },
                {
                    "sent": "Parameterising the complexity of the kernel, lower kapper is higher complexity and Lambda and then you can obtain a resort for incentive compatibility.",
                    "label": 0
                },
                {
                    "sent": "And eventually what we see if we see this nice connection between regularization, the complexity of a kernel and incentive properties.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the next thing I wanted to talk about was using learning for the design of mechanisms.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about its use for the design of voting rules, but I will talk about its use in the design of auction rules.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we're solving the combinatorial auction problem.",
                    "label": 0
                },
                {
                    "sent": "If you think that each of these dots is a distinct item.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "The sections here represents the demand of an individual agent and if it's helpful here that these have become separators.",
                    "label": 0
                },
                {
                    "sent": "This means that we have a feasible solution.",
                    "label": 0
                },
                {
                    "sent": "What we're trying to do to get strategy proofness so to get incentive compatibility is to find prices that separate in this sense.",
                    "label": 0
                },
                {
                    "sent": "And where the prices don't depend at all on the input of the agent that we're pricing, if we can find such prices, then we have incentive compatibility.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the problem statement that I'd like to describe a solution to here is if I give you an allocation algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which is characterized by a function that Maps inputs into a allocation of goods.",
                    "label": 0
                },
                {
                    "sent": "I'd like to find a payment rule that is in a formal sense maximally incentive compatible.",
                    "label": 1
                },
                {
                    "sent": "And I'd like to use support vector machines.",
                    "label": 0
                },
                {
                    "sent": "In achieving the.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Essentially what you can do.",
                    "label": 0
                },
                {
                    "sent": "Is you can generate data so you sample from an underlying distribution on valuation functions for each of those samples you run the allocation algorithm that you're given.",
                    "label": 0
                },
                {
                    "sent": "And you get a new data point.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to look to train a classifier.",
                    "label": 1
                },
                {
                    "sent": "It will be a multi classifier.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we're going to use the discriminative function of the classifier to perform pricing.",
                    "label": 0
                },
                {
                    "sent": "Kasota",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your very simple example.",
                    "label": 0
                },
                {
                    "sent": "Go back to the single item allocation problem.",
                    "label": 0
                },
                {
                    "sent": "Where for a single item the input X is just a vector of reals, just the value of each agent.",
                    "label": 0
                },
                {
                    "sent": "And the output just going to focus on agent one and this will hold for all agent from the same way.",
                    "label": 0
                },
                {
                    "sent": "The output of the allocation algorithm is plus one.",
                    "label": 0
                },
                {
                    "sent": "If you're allocated a -- 1 if you're not allocated, so the input data might look like 10, eight, 7.",
                    "label": 0
                },
                {
                    "sent": "There were three agents.",
                    "label": 0
                },
                {
                    "sent": "Their bids are ten, 8, seven and one.",
                    "label": 0
                },
                {
                    "sent": "This means that agent one is allocated 'cause its value is higher than the other values 587 its value is lower and minus 1925.",
                    "label": 0
                },
                {
                    "sent": "And plus one.",
                    "label": 0
                },
                {
                    "sent": "This is what the training data might look like, and we're going to try to learn a discriminative function F. Well, then the hypothesis are classified.",
                    "label": 0
                },
                {
                    "sent": "We just depends on the sign of F.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When notice that an exact classifier.",
                    "label": 1
                },
                {
                    "sent": "Probably see this an exact classifier here would use FX equal to the value of Agent 1 minus the Max of the other values.",
                    "label": 0
                },
                {
                    "sent": "If this is is positive, the agent should be allocated.",
                    "label": 0
                },
                {
                    "sent": "If this is negative, the agent should not be allocated.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the particular thing we're going to require is we're going to impose some structure on the discriminative function.",
                    "label": 0
                },
                {
                    "sent": "We're going to impose the discriminative function is linear in the value of agent one and potentially nonlinear in the values of the other agents.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to pick up this term as the payment.",
                    "label": 0
                },
                {
                    "sent": "Actually minus the payment and by doing so, the discriminant function gives me exactly the payoff of an agent.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the value of the agent minus the price it has to pay.",
                    "label": 0
                },
                {
                    "sent": "If it's allocated so by insisting on this particular structure I get a nice correspondence between the discriminative function and the utility of an A.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now for strategy proofness you need the following thing you needed to the beat to be the case if whenever your value.",
                    "label": 0
                },
                {
                    "sent": "Is greater than the amount I'm charging you?",
                    "label": 0
                },
                {
                    "sent": "You're allocated the good and whenever your value is less than that of that amount, you're not allocated the good.",
                    "label": 0
                },
                {
                    "sent": "This is the case.",
                    "label": 0
                },
                {
                    "sent": "You'll have incentive compatibility and notice that this is exactly true when we have an exact classifier.",
                    "label": 0
                },
                {
                    "sent": "Because of this connection between the discriminative function and the value minus the price.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I should say this work is unpublished.",
                    "label": 0
                },
                {
                    "sent": "I wanted to talk about it because I think it's it's an interesting direction.",
                    "label": 0
                },
                {
                    "sent": "There's a working paper on my web page.",
                    "label": 0
                },
                {
                    "sent": "The general problem here then for the combinatorial auction problem is that the input is a vector in.",
                    "label": 0
                },
                {
                    "sent": "Kind of the concatenated vectors defining the valuation function of each agent and the classification problem is a multi classification problem where now it's not minus 1 + 1.",
                    "label": 0
                },
                {
                    "sent": "It's which package is the agent allocated for those inputs in the underlying allocation algorithm, sorta.",
                    "label": 0
                },
                {
                    "sent": "Why is and then our goal is to learn a hypothesis in the same way and will take the structural SVM approach, where will say that the hypothesis should be computed as the argmax.",
                    "label": 0
                },
                {
                    "sent": "Oven underlying discriminative function.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, I'm going to stipulate the special structure, which makes things nicely separable.",
                    "label": 0
                },
                {
                    "sent": "This will become the payment function in the same way.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "I have a structural SVM problem where the nice correspondence between the training problem of minimum which you see in the literature and in our setting becomes minimizing a regularize upper bounds on empirical regret.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have the same kind of theorem I showed you before, which is again if you have an exact classifier, you have identified prices that make the allocation rule coupled with these prices incentive compatible.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to switch gears now and I'm going to talk about mechanism design for machine learning problems.",
                    "label": 1
                },
                {
                    "sent": "So we're going to move over to this side.",
                    "label": 0
                },
                {
                    "sent": "In doing that, then we just briefly mentioned that there is also work on learning distributions both in the context of dynamic auctions and in the context of auctions for digital goods.",
                    "label": 1
                },
                {
                    "sent": "So moving to this other side, now I want to talk about first the secretary problem.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very briefly.",
                    "label": 0
                },
                {
                    "sent": "So in the normal secretary problem.",
                    "label": 1
                },
                {
                    "sent": "You imagine that you're online.",
                    "label": 0
                },
                {
                    "sent": "You're given a a rival sequence of choices you might make, and when each new choice arrives.",
                    "label": 0
                },
                {
                    "sent": "You're given the information as to whether this choice is better than all the previous choices.",
                    "label": 0
                },
                {
                    "sent": "And you're told how many choices you should expect and you're seeking to compete with the offline algorithm that would pick the choice that for best.",
                    "label": 0
                },
                {
                    "sent": "And the asymptotically optimal thing to do in the worst case is to sample for around 1 / E of the inputs, so observe.",
                    "label": 0
                },
                {
                    "sent": "And then, given that you now know the best you've seen so far, forward from that, you'll acccept and you'll accept the best input that you see after that.",
                    "label": 0
                },
                {
                    "sent": "Now you can make an interesting analogue now to a dynamic auction problem where the arriving objects are now bidders with private information about their value.",
                    "label": 0
                },
                {
                    "sent": "And I'd like to do the same kind of thing.",
                    "label": 0
                },
                {
                    "sent": "I'd essentially like to be able to learn something about the underlying distribution.",
                    "label": 0
                },
                {
                    "sent": "Even though the inputs are privately held and I need incentive compatibility.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we showed in this paper is that as long as you're careful about handling the transition from the learning phase into the accepting phase and the particular concern is that there might be an agent who arrived just before the transition but is patient, the transition occurs during his patience and therefore could, if you're not careful, manipulate the auction to his advantage by delaying his arrival into the system.",
                    "label": 0
                },
                {
                    "sent": "We have to be careful about things like that, but as long as we are.",
                    "label": 0
                },
                {
                    "sent": "Then we can get incentive compatibility and we can get essentially the same competitive analysis as you get in the standard problem.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second example I wanted to briefly talk about along the same lines.",
                    "label": 0
                },
                {
                    "sent": "Is an exploration exploitation problem modeled as the band?",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I want you to imagine that behind each arm is an agent.",
                    "label": 0
                },
                {
                    "sent": "And the agent when you activate her arm, which you can think about, is giving her a good or giving her a resource that lets her be able to sample her value for that resource in the environment.",
                    "label": 0
                },
                {
                    "sent": "I want you to think that she gets that information privately.",
                    "label": 0
                },
                {
                    "sent": "OK, so every every time you activate the process behind the agent, she gets a private observation about whether the value behind the scenes is low or high.",
                    "label": 0
                },
                {
                    "sent": "And I'd like to be able to do something like Bayesian optimal learning, despite the fact that the agents are privately observing this information.",
                    "label": 0
                },
                {
                    "sent": "So assume a prior on the underlying distribution.",
                    "label": 0
                },
                {
                    "sent": "And assume that I would like to maximize expected discounted value with respect to that prior.",
                    "label": 0
                },
                {
                    "sent": "And in fact, you can do this.",
                    "label": 0
                },
                {
                    "sent": "You can take the Vickrey auction that we've seen a few Times Now, and you can generalize it.",
                    "label": 0
                },
                {
                    "sent": "You can make it work in a dynamic setting where the equivalent of winner determination becomes the efficient policy that makes the right tradeoff between exploration and exploitation, and you essentially make agents play make agents pay.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, the expected.",
                    "label": 0
                },
                {
                    "sent": "Marginal externality they impose on the other agents.",
                    "label": 0
                },
                {
                    "sent": "So in this setting where the agents are assumed to be basean, meaning that they are happy to maximize expected utility.",
                    "label": 0
                },
                {
                    "sent": "You can achieve essentially first best you can do the same algorithm you would use if you could observe the information.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second comments I make on the bandits problem with inputs that are coming from self interested agents.",
                    "label": 0
                },
                {
                    "sent": "Is about a variation now where and this variation was motivated by sponsored Ferge, where you're seeing uncertain clicks on an advert and you're going to ask an advertiser to describe his willingness to pay for every click.",
                    "label": 0
                },
                {
                    "sent": "But as a mechanism you don't understand yet, the click through rate on different adverts.",
                    "label": 0
                },
                {
                    "sent": "So then the setting is a little bit different than before.",
                    "label": 0
                },
                {
                    "sent": "Now the mechanism does get to observe a click.",
                    "label": 0
                },
                {
                    "sent": "But the only private information now is the value per click.",
                    "label": 0
                },
                {
                    "sent": "So at the start of time I'm going to ask Agent one and Agent 2 to report their value.",
                    "label": 0
                },
                {
                    "sent": "And then what I'd like is I'd like incentive compatibility in the strong dominant strategy sense I had at the start of my talk, so I'd like it to be the case, or whatever the uncertain realization of clicks, whatever the reports of other agents, you should be truthful.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in a nice paper anythi 09.",
                    "label": 0
                },
                {
                    "sent": "Essentially, this problem was discussed and hear this bad news.",
                    "label": 0
                },
                {
                    "sent": "Essentially for this bandits problem where you insist on this very strong form of incentive compatibility, you have to separate exploration and exploitation an the intuition for the difficulty.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "In order to compute prices that would make the algorithm incentive compatible.",
                    "label": 0
                },
                {
                    "sent": "I would need to know the information the click that would have a curd if I had activated the bandwidth in a different way.",
                    "label": 0
                },
                {
                    "sent": "So I need this counter factual information off the learning path, and without that information I can't get incentive compatibility in this strong sense, and therefore you have new constraints on the algorithm and therefore you have new regret bounds.",
                    "label": 0
                },
                {
                    "sent": "Essentially, that's what goes wrong here.",
                    "label": 0
                },
                {
                    "sent": "So if you switch from this basean incentive compatible.",
                    "label": 0
                },
                {
                    "sent": "Way of solving the problem till this worst case.",
                    "label": 0
                },
                {
                    "sent": "You get.",
                    "label": 0
                },
                {
                    "sent": "Worse results.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the last thing that I wanted to chat about now was.",
                    "label": 0
                },
                {
                    "sent": "Incentive compatible supervised learning and I'm going to describe in particular work on incentive compatible regression.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in the framing of this problem, let us suppose that the mechanism is interested in learning hypothesis F, which is a mapping from inputs into a real.",
                    "label": 0
                },
                {
                    "sent": "And that is, suppose that each agent.",
                    "label": 0
                },
                {
                    "sent": "Has a private distribution.",
                    "label": 0
                },
                {
                    "sent": "So piece of eye is the distribution from which agent I samples.",
                    "label": 1
                },
                {
                    "sent": "It's examples and is the distribution it cares about in terms of error, and that is also suppose that each agent has its own target function in mind.",
                    "label": 1
                },
                {
                    "sent": "So suppose let's say that.",
                    "label": 0
                },
                {
                    "sent": "Each agent represents the store and the stores are reporting data to the center about the sales that they've been achieving on their inventory.",
                    "label": 0
                },
                {
                    "sent": "So take yourself back to a world without information technology systems so the sensor is not able to actually observe that, and then based on this information that is, suppose that the sensor representing the Corporation is going to try to learn a function to try to understand what's selling well and what is not selling well and then based on that.",
                    "label": 0
                },
                {
                    "sent": "It's going to offend knew shipments.",
                    "label": 0
                },
                {
                    "sent": "There's a setting where the training examples are distributed is reasonable to expect.",
                    "label": 0
                },
                {
                    "sent": "There would be self interest in misreporting that data, and that is suppose that each agent cares about the risk with respect to its own distribution.",
                    "label": 0
                },
                {
                    "sent": "Pizza by.",
                    "label": 0
                },
                {
                    "sent": "Anne has an error function that depends on the on the divergent between the prediction and the target that it holds, and that is suppose that the social goal is to pick an F the maximizes or minimizes the total expected risk in this sense.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like I said, the twist on the standard problem is the data is privately held.",
                    "label": 0
                },
                {
                    "sent": "And that agent might then miss report.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Satan.",
                    "label": 0
                },
                {
                    "sent": "So Dekle ET al.",
                    "label": 0
                },
                {
                    "sent": "In working on this incentive compatible machine learning framework, then insisted that there were no payments and thought about the problem in the following way.",
                    "label": 0
                },
                {
                    "sent": "The mechanism will request endpoints from each agent.",
                    "label": 0
                },
                {
                    "sent": "So these are the points from Agent I.",
                    "label": 0
                },
                {
                    "sent": "And then based on these reported points, will train and determine a function F.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the question is which kinds of learning ideas will provide incentive compatibility?",
                    "label": 0
                },
                {
                    "sent": "And then it's suppose first of all just to focus ourselves that we select a function F prime.",
                    "label": 0
                },
                {
                    "sent": "That's the empirical risk minimizer, and we want to know when will that be incentive compatible.",
                    "label": 1
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the warm up let's suppose that each agent actually only cares about one point, so the distribution is a degenerate distribution on that point.",
                    "label": 0
                },
                {
                    "sent": "And the agent will report its own label.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "A theorem is that if you have.",
                    "label": 0
                },
                {
                    "sent": "Linear.",
                    "label": 0
                },
                {
                    "sent": "Loss functions, absolute loss functions, and a convex hypothesis class.",
                    "label": 1
                },
                {
                    "sent": "Then, the ERM, is incentive compatible.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me show you an example of this that suppose that the hypothesis class is the constant hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Then because of this loss function, if these are the three points owned by different agents, the way to minimize absolute loss is the median rule which we saw at the thoughts of my talk.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so by by choosing this as the hypothesis, you minimize the sum absolute error.",
                    "label": 0
                },
                {
                    "sent": "And we already saw that median gives you incentive compatibility.",
                    "label": 0
                },
                {
                    "sent": "Flats",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ice.",
                    "label": 0
                },
                {
                    "sent": "But this fails for other loss functions.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you care about the squareds error and let's say there are two agents with Y values, 2 and 0.",
                    "label": 0
                },
                {
                    "sent": "Then the right thing to do would be to put the hypothesis right in the middle and then I have the same problem with the mean I described earlier.",
                    "label": 0
                },
                {
                    "sent": "So what these authors have done in their work?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is then to try to generalize this they've considered then more than one point and still sticking with this absolute loss function.",
                    "label": 0
                },
                {
                    "sent": "And the question is, what can you do when the input now is that each agent owns more than one point?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's consider a simple example with two agents.",
                    "label": 0
                },
                {
                    "sent": "Again, where the hypothesis class is the constant hypothesis and agent one has three points and agent two has these other three points and you can ignore the X values and just focus on the Y values.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case the there are lots of different things that would minimize the empirical absolute loss.",
                    "label": 0
                },
                {
                    "sent": "One thing you might do is pick the constant function 0.",
                    "label": 0
                },
                {
                    "sent": "So let's say that we do that.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we break ties in favor of the minimum function.",
                    "label": 0
                },
                {
                    "sent": "In this case, the empirical risk to agent one is 2/3 because the prediction is wrong on two of its points, an right or one of its points.",
                    "label": 0
                },
                {
                    "sent": "But this is not incentive compatible.",
                    "label": 0
                },
                {
                    "sent": "Well, that agent can do is to pretend that the third data points actually had the Y value of 1.",
                    "label": 0
                },
                {
                    "sent": "In this case, the ERM solution.",
                    "label": 0
                },
                {
                    "sent": "Now there are four 120 that be to pick one, and now the agents risk is improved.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the solution that's described in the paper is to project.",
                    "label": 0
                },
                {
                    "sent": "This high dimensional data down to a lower dimension where you eventually do if you take the median solution for each agent individually, and then you combine those medians into one median.",
                    "label": 0
                },
                {
                    "sent": "This is the project and fit idea that these are.",
                    "label": 1
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As described, and they show, this gives you a three competitive worst case learning algorithm and they also show that if now the agents don't just have these endpoints, but the points are being sampled from underlying distribution, you get approximate incentive compatibility.",
                    "label": 0
                },
                {
                    "sent": "So I described this here as an example of some of the initial work that's been done on incentive compatible supervised learning.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm moving towards wrapping up.",
                    "label": 0
                },
                {
                    "sent": "Let me just make a quick comment about what I think.",
                    "label": 0
                },
                {
                    "sent": "Is an interesting challenge problem that the community here is, I think, likely interested in.",
                    "label": 0
                },
                {
                    "sent": "And maybe one of the reasons why I was asked to give this talk, but I I don't have anything deep to say about this at this point, which is that?",
                    "label": 0
                },
                {
                    "sent": "If you think that mechanism design is essentially at least within the setting with money is about trying to find good designs of transfer payments between agents.",
                    "label": 1
                },
                {
                    "sent": "And if you think that from an AI perspective, we're interested in modular intelligent systems.",
                    "label": 0
                },
                {
                    "sent": "Then can we now take the decade of development with we see in on computational mechanism design and can we use that to bring back into computer science into AI and machine learning?",
                    "label": 0
                },
                {
                    "sent": "Especially for the design of intrinsic rewards for the transfer of reward between different modules using payments and so forth.",
                    "label": 1
                },
                {
                    "sent": "So essentially this would not be an appeal to self interest because each of these modules is.",
                    "label": 0
                },
                {
                    "sent": "Somehow working on a different team.",
                    "label": 0
                },
                {
                    "sent": "Let's say this appeal to self interest because that's a useful way to modular eyes and architecture and then how can we use transfer payments and prices and things like this in order to mediate between these different modules?",
                    "label": 1
                },
                {
                    "sent": "You think about this, perhaps as a market of minds.",
                    "label": 0
                },
                {
                    "sent": "I think this is an interesting direction.",
                    "label": 0
                },
                {
                    "sent": "So I've talked about.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 pieces I wanted to emphasize that the interface between machine learning and mechanism design is quite rich and I think quite surprising when you see it for the first time.",
                    "label": 0
                },
                {
                    "sent": "The different ways in which the fields are finding ways to use each other.",
                    "label": 0
                },
                {
                    "sent": "I've emphasized this distinction between.",
                    "label": 0
                },
                {
                    "sent": "Using machine learning methods for operationalizing designing or learning distributions in the context of MD and then using MD in the context of ML problems, where now you might imagine the inputs are self interested be held.",
                    "label": 0
                },
                {
                    "sent": "So I think I'll stop and take questions that may end by thanking you all.",
                    "label": 0
                },
                {
                    "sent": "And if you have any questions we have time, thanks.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So is there any work done on modeling where the protocol between the bidders and the center?",
                    "label": 0
                },
                {
                    "sent": "I guess where the bidders don't understand exactly there's some possibility of miscommunication where the bidders think they're bidding on 2001 Toyota, but they're really bidding on a 2000 field or something, so there's some noise or error in the process.",
                    "label": 0
                },
                {
                    "sent": "OK, so the so the question is, has it been work in the maximum design context where the agents have intrinsic uncertainty about the valuations they have, for example well or about the items they are bidding on right?",
                    "label": 0
                },
                {
                    "sent": "And therefore about the values?",
                    "label": 0
                },
                {
                    "sent": "There's there's different kinds of work on that one, I think well known problem is the lemons problem where the seller is not able to credibly describe the quality of the underlying good, and therefore you get this bad equilibrium where everybody assumes the good is bad and the high quality sellers leave the market.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of classic work on that.",
                    "label": 0
                },
                {
                    "sent": "The the solution so that, for example, is to use reputation to fold reputation algorithms on top of this.",
                    "label": 0
                },
                {
                    "sent": "So you learn something about the long term credibility of the seller.",
                    "label": 0
                },
                {
                    "sent": "The other strand of literature that might be helpful to know about is this work where my value depends on information that you have.",
                    "label": 0
                },
                {
                    "sent": "So I didn't emphasize this, but everything I talked about here was private values where the inputs are privately held and is sufficient to describe your utility function.",
                    "label": 0
                },
                {
                    "sent": "And then there's the literature in maximum design theory on interdependant values where now.",
                    "label": 0
                },
                {
                    "sent": "My value depends on your private information as well.",
                    "label": 0
                },
                {
                    "sent": "You can think about we're drilling for oil.",
                    "label": 0
                },
                {
                    "sent": "I'm buying a antique picture etc.",
                    "label": 0
                },
                {
                    "sent": "And there is work on that as well.",
                    "label": 0
                },
                {
                    "sent": "The vanilla expected utility problem doesn't pose much of a difficult if the agents are risk neutral.",
                    "label": 0
                },
                {
                    "sent": "So I'd like to add something to talk, which is, I think there's a shared foundation between mechanism design machine learning, which is generalized notion of proper scoring rules from proper scoring rule, you can derive a mechanism from proper scoring rule.",
                    "label": 1
                },
                {
                    "sent": "You can also derive a learning algorithm, and I guess the generalized notion of this lets you capture much marching properties and just probability of things.",
                    "label": 0
                },
                {
                    "sent": "Right, that's great.",
                    "label": 0
                },
                {
                    "sent": "Thank you so, so there's quite a lot of extremely interesting work using scoring rules.",
                    "label": 0
                },
                {
                    "sent": "Scoring rules are.",
                    "label": 0
                },
                {
                    "sent": "Proper when it's in the best interest of an agent to report information it has about an uncertain event.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "I have been working in recent years both in economics and in computer science.",
                    "label": 0
                },
                {
                    "sent": "On trying to understand what statistics of distributions you can elicit in that approach and also connecting scoring rules with information markets, I didn't talk about information markets, I totally could have done and I maybe should have done information markets are extremely interesting there designed to aggregate information that's held by lots of people to predict something about an uncertain event.",
                    "label": 0
                },
                {
                    "sent": "And this work.",
                    "label": 0
                },
                {
                    "sent": "Bringing proper scoring rules into their design.",
                    "label": 0
                },
                {
                    "sent": "So so if I think about agents on the Internet, or if I think about it, bidders on eBay, there are lots of cases in which the agents are too stupid to realize that the mechanism is incentive compatible.",
                    "label": 0
                },
                {
                    "sent": "Is there any way of getting at that?",
                    "label": 0
                },
                {
                    "sent": "Right, OK, yeah so.",
                    "label": 0
                },
                {
                    "sent": "This is a difficult problem, I agree.",
                    "label": 0
                },
                {
                    "sent": "Let me say a couple of things.",
                    "label": 0
                },
                {
                    "sent": "One thing is that.",
                    "label": 0
                },
                {
                    "sent": "You might think that bid is for advertising or also.",
                    "label": 0
                },
                {
                    "sent": "Maybe not super sophisticated and it was the case there that search engine switched away from first price into something that's not incentive compatible, but it's nicely stable.",
                    "label": 0
                },
                {
                    "sent": "And essentially I think if you believe that there are learning dynamics where people are learning how to play, then if you have something that's stable, at least the learning dynamics may be more stable, so you don't need to believe that people necessarily our reasoning about the mechanism, but they're exploring and trying to learn how to bid.",
                    "label": 0
                },
                {
                    "sent": "And even there you can get benefits.",
                    "label": 0
                },
                {
                    "sent": "But generally you point to an interesting direction.",
                    "label": 0
                },
                {
                    "sent": "One challenge is how can we describe mechanisms that are simple enough and make them understandable enough?",
                    "label": 0
                },
                {
                    "sent": "We'd like incentive compatible things because we can provide normative advice, but somehow people have to believe that there's a trust issue.",
                    "label": 0
                },
                {
                    "sent": "Maybe people don't believe you're collecting the second price.",
                    "label": 0
                },
                {
                    "sent": "This is a problem for, again, search engine's that are on both sides of the market, often times, and then the third thing is, can we develop a mechanism design that explicitly handles?",
                    "label": 0
                },
                {
                    "sent": "This bounded rationality of agents, little bit of work on that, but I think there should be much more.",
                    "label": 0
                },
                {
                    "sent": "So I kind of want to answer Charles.",
                    "label": 0
                },
                {
                    "sent": "So there's a sense in which for some mechanism designs, if you have wealth getting transferred and the agent you have agents were playing well, another one agent or not, you can prove that the overall online regrettable system is is like online learning against an adversary type regrets, which says that the overall, even though some agents are performing badly and other ones are doing well, the ones that perform badly will end up with very little money and then and then you just have the ones with the money will be the ones that are performing well.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure I quite got the question.",
                    "label": 0
                },
                {
                    "sent": "Was it about bidders with budget constraints?",
                    "label": 0
                },
                {
                    "sent": "It wasn't a question, it was really comment on Charles over the comments, OK?",
                    "label": 0
                },
                {
                    "sent": "Is the covenant?",
                    "label": 0
                },
                {
                    "sent": "I'll say it's a great comment and I'll take leave now to answer the question.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's thank our speaker again.",
                    "label": 0
                }
            ]
        }
    }
}