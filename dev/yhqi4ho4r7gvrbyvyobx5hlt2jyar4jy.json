{
    "id": "yhqi4ho4r7gvrbyvyobx5hlt2jyar4jy",
    "title": "Probabilistic Models for Preference Learning",
    "info": {
        "author": [
            "Zoubin Ghahramani, Department of Engineering, University of Cambridge"
        ],
        "published": "Jan. 24, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_ghahramani_probalistic/",
    "segmentation": [
        [
            "Great thanks, he only takes to the organizers so.",
            "I'm going to talk about probabilistic approaches to preference learning, and in particular looking at both supervised and unsupervised models for preference learning, and I apologize if I I'll cover some material which I think maybe a bunch of you are aware of because I've seen it sort of extended in interesting ways in some of the posters here."
        ],
        [
            "So first of all, what's preference learning well?",
            "At a very simple level, it's learning where the data is in the form of some sort of inequality relationships.",
            "And surprisingly, many machine learning problems fall into this class.",
            "There all sorts of places where either explicitly or implicitly we can get preference information out of, usually people, and then we want to model them in various different ways."
        ],
        [
            "So.",
            "We can distinguish between various different kinds of preference learning problems, and I'll.",
            "Kind of broadly distinguish between instance preference, learning and label preference, learning or label ranking.",
            "So in instance.",
            "Preference learning your data is a set of preference relations measured on items or instances, so your data set might be.",
            "Set of the source of preference relations, where each of these items comes from some set of items X you know, like.",
            "You prefer Coke to Pepsi or something like that.",
            "And you know, to make this a bit more interesting, usually we have, we know some features of these sorts of objects when we're trying to model the preferences.",
            "In label preference learning or label ranking, you have some items X subset of items X and a set of labels L. And for any item X.",
            "You he might have preference relations in terms of which labels go with that item X. OK, so we could actually cast various problems in machine learning in terms of these sorts of label preference graphs.",
            "So for example in a multi class classification problem.",
            "You say that for some item X. Label three is the correct label that information can be cast as a bunch of preferences, label preferences saying the three is preferred to 2.",
            "Three is preferred to 1.",
            "Three is preferred for threes before to five.",
            "In ordinal regression, where there is an actual ordering in these labels, then the similar thing here would also imply that.",
            "If you prefer 3, then you should prefer 2 to one as well, because these things are labeled are ordered, and similarly in the other direction.",
            "So I'm going to focus on instance preference learning.",
            "And."
        ],
        [
            "So imagine if the user exhibits some sort of preference.",
            "Prefer X to X prime.",
            "Way we're going to approach this is to imagine that there is some preference function or utility function, let's call it F, such that F of X is greater than F of X prime.",
            "Perhaps corrupted by noise and this is, you know, it's a very classical way of doing things, and I know there are other ways of doing things, but this goes back to some of the stuff that you heard about before.",
            "It's very similar to some aspects of what Torah talked about as well.",
            "And.",
            "So then the problem of preference learning boils down to the problem of learning about these underlying hidden functions.",
            "And so we need to think how do we learn about these functions?"
        ],
        [
            "So how do we learn about preference functions from data of this kind?",
            "Imagine we now have N data points, each of which is some kind of preference relation like this between a pair of items.",
            "And broadly speaking, when we have approaches based on learning about unknown functions.",
            "There are sort of large number of very elegant optimization based approaches which say.",
            "Minimize over some suitable space of functions loss function.",
            "Loss for each data point evaluated on that function plus some regularizer.",
            "This is a rather closely related to probabilistic approach, which is the one that I'm going to take where instead of thinking about a minimization over functions, we're going to think about an inference problem over hidden functions.",
            "We have our observed data.",
            "We want to infer the function from the data the way we do that is, first of all, we have to put in some prior assumptions about the space of functions.",
            "That we're going to use.",
            "And then we have our likelihood function which roughly corresponds.",
            "I mean, this prior roughly corresponds to the regularizer here, and the likelihood function roughly corresponds to the loss function that we use there.",
            "And then we do posterior inference over functions given the data in this framework.",
            "So basically we're now going from preference learning to preference functions.",
            "We need a prior on functions.",
            "What do we use as a prior on functions?"
        ],
        [
            "So I'm going to very briefly do a Gaussian process tutorial.",
            "Raise your hand if you are very familiar with Gaussian processes, OK. Raise your hand if you're very unfamiliar with Gaussian processes.",
            "OK, and then there are people in between.",
            "OK, so I'm going to do this blindingly fast then.",
            "Alright, so Gaussian process defines a distribution over functions, functions that map from some space to the reels, and it has the property that if you evaluate the functions in a finite number of points, then the multivariate distribution over that vector evaluated this finite number of points is a multivariate Gaussian distribution.",
            "So if that holds for any any subset of this SpaceX and all those Gaussians are coherent with each other, then there is such a thing as a Gaussian process, and you've characterized it through its marginals."
        ],
        [
            "So it's parameterized in terms of his mean function and its covariance function, which correspond to the mean vector and covariance matrix of a multivariate Gaussian, and they also correspond to something that people don't usually use, and the kernel in a kernel machine.",
            "And essentially, all inferences about Gaussian process are, although the Gaussian process itself is an infinite dimensional object, all inferences can be done on the finite dimensional marginals of the function evaluated at your end data points.",
            "So you end up doing operations that are on N by N matrices an end dimensional Gaussians."
        ],
        [
            "OK, so.",
            "Generally, we think of guessing processes being used for regression, but they've been used for classification, and here we're going to use him for preference learning."
        ],
        [
            "This is the hopefully blindingly fast part, a Gaussian process, kernel or covariance function captures the properties of the functions that you might be interested in, and you generally define parameterized families of such kernels.",
            "For example, this is a particular parametrized family of kernels, and you have a bunch of parameters which are interpretable.",
            "That's the nice thing about it.",
            "You can call these things different things like signal variance, length, scale, roughness, variance of the bias, etc.",
            "Once you play with these, you can really understand what they're doing, which is great, and you can learn them automatically from the data using very standard methods.",
            "OK."
        ],
        [
            "So here's some samples from Gaussian processes with different covariance functions, and they characterize different kinds of assumptions about distributions over data."
        ],
        [
            "And learning the kernel.",
            "Involves taking those hyperparameters of the kernel that I was talking about.",
            "Here is a different slightly different kernel with a bunch of hyperparameters, a very standard one as well, and then you can write down the marginal likelihood as a function of those hyperparameters.",
            "That's the probability of the regression cases, the probability of the output labels for preference learning, it would be the probability of those observed preference relations given the features of the inputs.",
            "As in instance preference learning, let's say.",
            "That marginal likelihood for for regression with Gaussian noise is just the multivariate Gaussian density.",
            "So you can write it out in this form and optimize it with respect to the thetas, or do Bayesian inference over the thetas if you really want to avoid any any risk of overfitting.",
            "In the preference learning case, which will get to in a minute.",
            "The subtlety is that this marginal likelihood can't be computed exactly because of all those inequality relationships, so we need to make approximations."
        ],
        [
            "So here is Gaussian process for classification.",
            "I will talk about."
        ],
        [
            "Them very much.",
            "Who wants me to talk about the relationship between Gaussian processes and SVM's?",
            "Raise your hand.",
            "Not too many people.",
            "OK.",
            "The longer I wait, the less it cost you to say yes, I guess, so I'm not going to re derive the SVM, but here is a soft margin support vector machine cost function using this is in the kind of finite dimensional version where you have a vector here and you minimize the regular, the sort of regularizer here plus some constant C times.",
            "This hinge losses for classification.",
            "Then when you kernelized this whole thing, you can write it in terms of the.",
            "You can map from the W2 the function space.",
            "And the equivalent thing can be written like this.",
            "You minimize over a vector of function values.",
            "A quadratic form in the function values plus C times all those hinge loss functions."
        ],
        [
            "And.",
            "It looks incredibly similar to an object inside the Gaussian process, so.",
            "In the SVM we generally minimize this thing which I had on the previous slide.",
            "In the Gaussian process, the negative of the log of the Gaussian process likelihood is exactly the same thing with the same kernel.",
            "You could plug in and then here instead of this bit, we have the log probability of the label given FI for each item I plus some irrelevant constant here.",
            "This is an important and relevant constant is the regularization parameter and.",
            "These look incredibly similar, but they're sort of philosophically very different.",
            "In the SVM you do minimization in the Gaussian process you actually integrate over the functions here, so you're doing averaging over all the possible solutions in this sort of version space, you could think of.",
            "And so we measure innocence in the Gaussian process.",
            "We measure the uncertainty in the function as I described before.",
            "We can learn the kernel parameters in a straightforward way because we have a proper likelihood, so we can do Bayesian inference or maximum likely on the kernel parameters.",
            "We can combine 10 different kernels with different weighting coefficients and learn them with nothing to worry about.",
            "The other funny thing which people might consider weird is we can learn the regularization parameter C without cross validation.",
            "Y well, see here is just overall constant which I could wrap it into.",
            "If I divide everything by CI could wrap into the kernel so it's just a scaling on the kernel matrix is another.",
            "Other kernel hyperparameter no different than the other 10 or 15 kernel hyperparameters I could have.",
            "There's no notion of 1 parameter controlling complexity that just seems silly to me.",
            "OK, so and other various things, but you know in terms of performance there are often quite similar and they're you know sisters or brothers or so."
        ],
        [
            "Things like that.",
            "So maybe they don't always get along well, but they're related, right?",
            "So here is just a picture of where these methods fall.",
            "We can start from linear regression and turn it into classification method.",
            "For example using something like logistic function, we get logistic regression.",
            "We can start from linear regression and kernelized it.",
            "Just by mapping into some high dimensional feature space, we can start from linear regression and do Bayesian inference over the parameters rather than optimization.",
            "So this is these blue edges of this cube are base ifying methods, and then if you if you travel you know any of these many paths from linear regression through a blue edge magenta edge and an orange edge, you get to Gaussian process classification.",
            "OK. And support vector machines would be here.",
            "We could, you know, relate them.",
            "It's not exactly a logistic loss, function is a hinge.",
            "Loss function is pretty close.",
            "These are just these are indicative labels here we can have many variants of different methods in each of these cubes.",
            "And I think this is a very useful kind of diagram.",
            "It certainly helps me understand things.",
            "And.",
            "I dare say I didn't do it, but if we replace this with a different colored edge for preference ifying or something like that, we could build preference models out of regression models through these inequality relations.",
            "It's actually very closely related.",
            "This is related to this poster by parents whose are.",
            "Over."
        ],
        [
            "OK, so I'm not going to."
        ],
        [
            "Do that, I'm not going to talk about the comparison of SVM's and Gaussian process classifiers, but this is something interesting to think about.",
            "OK, so."
        ],
        [
            "So let's get back to preference learning.",
            "You see how I'm doing on time.",
            "OK.",
            "So this is now slightly old work, don't despair.",
            "I think a lot of you have seen this.",
            "Judging by the posters, I'll talk about some newer stuff as well.",
            "OK, so for Gaussian processing preference learning, I just spent the last 10 minutes or so talking about the prior over functions.",
            "Let's quickly talk about this likelihood.",
            "The preference function likelihood can be written in the following way.",
            "Just imagine a noise free or perfect sort of preference function which says that the probability that you prefer item V to you.",
            "Given the function at.",
            "V and the function value it U is 1 if.",
            "The preference function at V is greater than the preference function at you.",
            "In other words, you observe a preference data point saying that you prefer V to you if and only if your preference function is greater at V than it is at you.",
            "Clearly this is this is a idealistic or noise free model and we want to be able to allow for noise in preference judgments so we can easily do that by imagining that these preference functions are corrupted by, say, Gaussian noise.",
            "When you threshold it like this in a very similar way to what you saw in tourist talk, what you get is a probe it function.",
            "So this is the actual kind of preference function that we use.",
            "It's a pro bit of the difference it.",
            "Sorry I didn't shouldn't have said preference function.",
            "This is the actual likelihood function that we use.",
            "It's a probate of the difference in the preference functions.",
            "Sigma is the noise level of your corruption of the preference function and this is sort of the shape of the pro, but it's sort of sigmoid function and then this likelihood in red is just assuming IID given these functions.",
            "OK.",
            "So and then this is the pointer to Ference Hussars, recent work mapping this simply onto a classification.",
            "And then also talking about active learning in this context.",
            "And there's see code for this, which makes it easier hopefully to compare."
        ],
        [
            "OK, now to do inference.",
            "In this I said, oh I'm going to do integration.",
            "I'm not going to do optimization.",
            "OK, you know, one of the ways of doing integration is you do optimization.",
            "OK, then you get to the top of the Hill.",
            "You measure the curvature at the top of the Hill and then you fit a Gaussian around the top of the Hill with that curvature.",
            "And that's called Laplace's approximation.",
            "So in this paper what we did was we optimized that posterior, which essentially ends up being an optimization of.",
            "A function that looks like this.",
            "It's a bunch of logs of probits and quadratic form and F. And the nice thing about this objective function as a function of F. OK, remember F is infinite dimensional.",
            "We're not actually optimizing over the whole fit dimensional space.",
            "Equivalently, we can simply optimize over the vector F which is evaluated at our end items S of F is convex, which is nice, so.",
            "We can easily optimize it using one of many standard methods, and then at the.",
            "Map value of F. We can compute the.",
            "This is the kernel matrix which is known, but we can compute additional second derivative terms.",
            "This is a diagonal matrix here and evaluate a marginal likelihood for this model.",
            "And this marginal likely it is nice because it can be used for hyperparameter learning, like learning the kernel or model selection, etc.",
            "K Any questions about this?",
            "Alright."
        ],
        [
            "OK, what about prediction?",
            "Well, once you learn about the latent preference function prediction is straightforward.",
            "Given the data.",
            "If you want to evaluate whether you prefer R to S, then you have to compute this integral is a double integral over F of R&F of S of the distribution of F of R&F of X.",
            "Given the data which we've approximated as a Gaussian.",
            "So this is a bivariate Gaussian and then this is going to be simply a probate function.",
            "Of that bivariate Gaussian, which is very easy to write, it's just the probate of the mean of F of R minus the mean of F of S / a variance term that's easy to compute.",
            "OK."
        ],
        [
            "So here is now rather dated results.",
            "I'm sure you know there are probably many better comparisons by now.",
            "Showing that, at least at the time, this Gaussian process approach to preference learning.",
            "Was doing better than a constraint based support vector machine approached preference learning that had been proposed also in terms of CPU time?",
            "In this case, this is the Gaussian process method versus the SVM method, because in this particular case at least, this SVM formulation was based on which scale with the number of preference observations that you had, not with the number of items, whereas the Gaussian process.",
            "Although it's cubic is cubic in the number of items.",
            "Not in the number of preference relations that you observe, and usually you're going to have, you know.",
            "Well depends if you have sparse observations, then roughly you'll observe some constant number of preference relations.",
            "That's a factor of the number of items, but.",
            "OK. Now we extended this too, so I think this work is actually now reasonably well known and probably dated, so I apologize to all the people who've done really excellent work since then.",
            "I particularly want to point out there's some really nice work by Bonilla ET al.",
            "Over the intervening years that really extend."
        ],
        [
            "This extends in interesting ways.",
            "I do want to talk about some work that I I sort of feel like maybe people haven't seen much.",
            "Which was kind of maybe at a.",
            "An older version of this workshop, so this was a nips workshop on learning to rank.",
            "So I'm sure that some of the people at that workshop in 2005.",
            "Are either the same as here topics and here what we did was we looked at combining this Gaussian process preference learning framework with semi supervised learning and active learning.",
            "So in particular, at the time, and I think still there is a great deal of interest in graph based, semi supervised learning and graph based semi supervised learning.",
            "The idea is illustrated here for the classification case.",
            "Imagine we have a bunch of data for which most of the data points we don't observe the labels and a few of the data points we observe some labels.",
            "But based on the raw data, we can form a graph connecting similar data points to each other.",
            "So the way graph based semi supervised learning works is you form a graph G connecting nearby points based on whatever metric you want.",
            "You compute the graph combinatorial Laplacian and then which I'll talk about in a minute.",
            "And now we're actually going to use this.",
            "Almost as a likelihood for our Gaussian process, it's not clear whether it's really should be called a likelihood or a prior, but it's a term that we're going to use to multiply in with our original Gaussian process prior, and the likelihood from the observed preference relations and this term here.",
            "Is just E to the minus 1/2 F, transpose graph, Laplacian F. So obviously it's another quadratic term in F which which very naturally combines with the Gaussian process prior.",
            "And the intuition for the graph Laplacian is.",
            "Imagine the unweighted case.",
            "Of course, we can make a weighted graph version, but the unweighted is very easy to get into it.",
            "In the unweighted graph, this term encourages the function values to be similar at connected nodes, so I can write down this term.",
            "By doing just a little bit of linear algebra, I can write it as this term here.",
            "For the unweighted graph which simply says I have an additional term.",
            "Which.",
            "Sums over all pairs of connected nodes in the graph.",
            "A quadratic term F I -- F J squared.",
            "Alright, so this obviously penalizes the function value at I in the function value at J being very different from each other.",
            "Smoothness on the graph.",
            "That's what the graph Laplacian captures.",
            "And of course there's been huge literature on this over the over many years now.",
            "So that's the idea of the graph Laplacian, and we can straightforwardly included into our Gaussian process preference learning model and Moreover, in this paper we looked at active learning where we evaluated the expected information gain or entropy reduction from querying a particular pair.",
            "Of items.",
            "So.",
            "So you imagine.",
            "OK, imagine you query this pair of items, UK versus VK.",
            "Like you know, do you like Coke versus Sprite?",
            "OK, this is obviously related to things we've been talking about today.",
            "And now you can imagine the two possible answers that you get out of that.",
            "And for each of those two answers, you compute the change in entropy, which is hard to compute exactly.",
            "But remember, we've made a Gaussian approximation to the posterior over F, so we can simply entropies of Gaussians are rather easy to compute.",
            "Especially if we add a small term to the Gaussian, then computing the difference in entropy is a little easier because it depends on the change in the determinant of the covariance matrix of Gaussian.",
            "And now too, because we don't know what the outcome is going to be, whether you like Coke versus Sprite, yes or no, we have to do an expectation over the possible two possible answers.",
            "But we can sort of predict what those two answers are going to be OK, because we have a model of the whole thing.",
            "So essentially, think of it as a pool based active learning.",
            "We have a whole set of items or pairs.",
            "We can pick items and.",
            "And figure out which is going to give us the most information now.",
            "Active learning and semi supervised learning go really well together actually because in both cases the assumption is that labeling is hard to get.",
            "But we might have a lot of unlabeled data.",
            "In particular here, it could be that.",
            "Eliciting preference judgments is expensive, but we might have a lot of items and features of those items.",
            "For example, OK."
        ],
        [
            "So here are some results.",
            "I mean, this was.",
            "You know this was.",
            "I wouldn't say these are the best results in the world.",
            "This was just a workshop paper.",
            "I don't think we really followed up on it in terms of writing of.",
            "A full paper on this.",
            "But there are several comparisons here.",
            "This is the fully supervised learning case.",
            "You can compare active learning versus random OK random Query versus active querying for a number of query points on on a log scale here.",
            "And the blue one is the active one, and so these error bars are standard deviations over 20 runs of this method.",
            "And here we you know.",
            "Again, I apologize a little bit.",
            "We cheated.",
            "We took a metric regression problem.",
            "Boston Housing is sort of regression problem and we turned it into a preference learning problem.",
            "Basically we said OK.",
            "The preference relation is implicit in the value that we're trying to predict in a regression problem.",
            "We're only going to observe Inequality's in that value.",
            "Real-world preference problems are probably not that well behaved OK.",
            "So active learning is better than random, which isn't surprising.",
            "Here is the semi supervised case.",
            "Again, active learning is better than random in the semi supervised case.",
            "You know you could see if you draw horizontal lines along here you can actually see a cost gain.",
            "By being active versus random, which could be measured in terms of the number of preference pairs that you need to achieve a certain performance.",
            "And here is semi supervised versus supervised for the active case and we don't seem to get much difference actually on this particular data set, so I'm not really sure why.",
            "OK, any questions about this?",
            "Yes.",
            "I see the point that reduces the SP process on the latent function in the most, and you see this sort of thing when people do active learning or Gaussian process classification and stuff as well, where they're trying to reduce the entropy.",
            "The latent function.",
            "But if you think about what you actually care about, it's sort of like you have an unlabeled points.",
            "So there's like any missing preferences, but your nonlinear transform.",
            "Other GPU that induces a different non Gaussian distribution on those.",
            "My query, something that gives you a lot of information about the the Gaussian, but you don't care about the Gaussian function, but maybe it's really, really yes.",
            "I totally agree with you.",
            "I totally agree with you.",
            "The entropy on the Gaussian is sort of cheap poor man surrogate for what you might ultimately be really interested in, which is the.",
            "The information gained about the labels, or actually maybe ultimately what you're interested in is the.",
            "The query point that minimizes my expected generalization error as measured by classification error OK or preference error, let's say and.",
            "Although in this work we didn't, we didn't do that.",
            "I have done some work along those lines with Jerry Zhu and John Lafferty in a semi supervised learning case where we actually for that graph based semi supervised learning procedure that we had.",
            "We can compute the.",
            "Expected change in classification labels.",
            "And it's actually not.",
            "It's actually rather cheap in that model as well, but it's not always the case.",
            "Most of the time it's very expensive to compute that, so there's a paper on active semi supervised learning, which I think does much more the correct thing than what we did here.",
            "OK. Alright."
        ],
        [
            "So any other questions about this?",
            "Alright, I wanted to point out.",
            "I want to change gears the last few minutes and talk about kind of unsupervised preference learning.",
            "And here I'm going to talk about some work by Dylan Gore and colleagues.",
            "On a choice model with infinitely many latent features, which I thought was very interesting.",
            "And this is based on the illumination by aspects model.",
            "Where are you look at the probability of choosing item XI?",
            "Versus item XJ.",
            "Let's call that PJ and we're going to model this.",
            "This is, uh, I don't know whether you want to call it.",
            "I think the distinction between supervised and unsupervised is maybe a bit fuzzy here anyway, but we could almost call this unsupervised because.",
            "Essentially, what we're going to do is we're going to learn a bunch of latent features of these items.",
            "So if we had observed features of these items, like, let's say, Costan way, tan color, etc, then the elimination by aspects model would say something like.",
            "Let's take each of our features, we have a weight on each feature.",
            "And then.",
            "We're going to choose I / J.",
            "Using these feature indicators so this says item I has feature K versus item J does not have feature K. Alright, so if two items have the same feature.",
            "Then there is no term in this sum in the numerator, but if two items differ in the feature.",
            "Then there's a weight that gets added up, and then there is a normalizing constant here which basically ensures that you get a sensible probability of choosing I versus J.",
            "Now, if you had observed features, you could just simply learn these W's from the data.",
            "But now what we're going to assume is or not.",
            "When I say we, I mean they really 'cause I was not involved in this at all.",
            "What they assumed is that these hidden binary features have to be learned or inferred from the data.",
            "So these are latent features, and Moreover, I mean this is too stringent a model, so you can again add some noise in the likelihood function and say you prefer item I to item J.",
            "With a probability that's a function of these parameters shall talk about in a minute and essentially you take this PIJ value an you shrink it down from from the extreme zero and one by epsilon on each end.",
            "So you have one minus epsilon Pi J plus.",
            "Epsilon, PG.",
            "Is that right?",
            "No, that's not right.",
            "Then these cancel.",
            "And you get one.",
            "No, you get PIJ.",
            "All right, there is a bug in this equation, but essentially what you can imagine is corrupt.",
            "The decisions at the top and the bottom by epsilon, and that's the likelihood function that you have.",
            "OK.",
            "I'll have either I transcribed it wrong or there was a bug in the paper.",
            "Sorry, PJI yeah.",
            "Or one minus PJ.",
            "OK, thank you now.",
            "Now we have a bunch of binary hidden features here and this is the I think the interesting aspect of this paper is that they wanted to infer those binary hidden features from the data and they use a nonparametric Bayesian approach for doing that.",
            "Saying that we don't know how many of these binary latent features there are, so we're going to assume that this feature matrix F is drawn from an Indian buffet process.",
            "The Indian buffet process is just a sparse way for each item to define binary features.",
            "Where you don't have a bound on the possible number of binary features, a priority, so the model can learn automatically how many binary features it needs to model the data, and then these weights they have to be positive.",
            "So these were given a gamma prior, but obviously that's a other choices could be done there and the model that learns how many latent features are needed to model the preference data.",
            "Which I think is kind of neat actually.",
            "OK."
        ],
        [
            "So the last thing I want to talk about is a very simple idea.",
            "And you know, I swear, this must have been done by somebody.",
            "So the reason I'm talking about it here is because I'm just curious whether somebody's done this.",
            "So I'm hoping the answer is yes, somebody has done it.",
            "If the answer is no, then I'll really quickly get a student to write a paper on it.",
            "Or if the answer is not interesting, then I'll forget about it again.",
            "OK, so this is a very simple thing.",
            "Imagine you have data where users you.",
            "Express preferences for items.",
            "And we're going to denote PUIJ being one as user U prefers item I to item J and our goal is going to be super simple.",
            "We're just going to cluster users on the basis of such preference data.",
            "So if we use now, this notation says, call it XX UI to note the utility or value or preference sort of.",
            "Yeah, let's just say utility or value of item I to user U.",
            "Then preferences can be expressed as inequality relations.",
            "Between these latent things here.",
            "I mean, this maybe looks a lot like the Matchbox type models.",
            "And now the utility.",
            "The point is the utility.",
            "Of item I to user U is going to be expressed through a kind of matrix factorization form.",
            "Where you have a vector in some M dimensional space representing the user and a vector in that same dimensional space representing the item.",
            "If the dot product is high, then there is high utility.",
            "Otherwise there's low utility.",
            "In fact, actually, you know if we made this infinite dimensional we could think of these as functions in some space, but you know, kernelized it.",
            "Make it functions, blah blah blah.",
            "Let's talk about this simple form first.",
            "OK, without obfuscating everything.",
            "So now if we want to cluster users, essentially all we have to do is cluster these W vectors in this M dimensional space and so for that we can use a rather straightforward model, for example a. Dearsley process.",
            "Mixture of normals.",
            "So this is just a mixture of Gaussians in the M dimensional space where you can allow as many clusters as you want and you can allow it to grow.",
            "So has this been?",
            "Has this been done before?",
            "Super.",
            "It's in a sense we're clustering the users.",
            "Just based on what stuff they like.",
            "OK, the preferences that we observe on the users.",
            "Sushi daughter said at a paper on this kind of thing.",
            "I don't know if it's really worth it.",
            "Would be very interesting to think about it.",
            "I mean, you know this is just this sort of another unsupervised way of modeling preference data.",
            "I mean, I'm I don't know whether college supervisor unsupervised, but essentially you're learning something about your users by clustering them.",
            "You could do much fancier things as well, like by not clustering these vectors, you're doing and low dimensional embedding of your users, and that maybe is more standard.",
            "But clustering is sometimes interpretable and nice.",
            "So in case."
        ],
        [
            "You're curious, here's the graphical model for it and actually got with a have to admit a great deal of help from one of my students who's an expert on Internet.",
            "We actually managed to code this thing up infer.net.",
            "To play around with it so."
        ],
        [
            "So it could be interesting to explore this.",
            "Alright, so I'm just going to wrap up now.",
            "Many problems in preference learning can be viewed as problems of inferring latent preference or utility functions.",
            "Obviously, you know we can apply probabilistic modeling approaches to these problems.",
            "For the supervised preference, learning problems where essentially you observe features of items and then preference judgments of some kind, then this preference function, it seems natural, at least from probabilistic point of view, to use something like Gaussian process.",
            "For unsupervised preference modeling, then you can learn latent features using things like the Indian buffet process or the Chinese restaurant profit process.",
            "And all of these are actually, I would say, reasonably simple and usable models.",
            "OK, you know people are often scared of nonparametrics, can get really nasty and horrible but I think in all these cases these are actually quite deal aghbal and perhaps even scalable models.",
            "OK, I'll end there.",
            "Great thanks.",
            "When you say in your in the model that you just presented."
        ],
        [
            "You assume abiding out form W * * V. You have some ways to canonize the dot product.",
            "If you multiply to Goshen process, for example, assume that.",
            "Space, how would you do that?",
            "Because in the performance learning it's quite easy when you have just yeah.",
            "As soon as you multiply 2 version processes, you don't obtain admission process.",
            "So how would you do that?",
            "It's a very interesting question.",
            "I don't know standing here.",
            "It's gonna be one of these things like it's either trivial or impossible.",
            "You know, I'm not willing to say which one yet.",
            "But you know, anytime you see some, you know linear spaces and all products you could think of.",
            "A joint function.",
            "Of you and I right in this space.",
            "But OK. Perhaps I should look at that?",
            "Yeah, so I mean, you know there are interesting ways.",
            "Activate it, yeah.",
            "Thanks for the distraction.",
            "Yes, it might be interesting to simply have just a function representing this dot product in high dimensional space.",
            "You're thinking of a function here.",
            "Anna function here and then doing that sort of dot product.",
            "I'm not exactly sure whether that can be done easily.",
            "Yeah.",
            "Yeah, I'm not sure.",
            "I mean the other characteristic of this is maybe for that, for interpretability.",
            "Might be nice to cluster users or something like that, or cluster items, yeah?",
            "You could have gotten process prior all user right now, yeah.",
            "For example, what you saying one thing?",
            "Yeah, if you do block structure on the covariance here, then yeah, then you get essentially the kernelized infinite dimensional version of this.",
            "Now one thing that I think is nice is you know when you map stuff into high enough dimensional space, you can get away with all sorts of things like that's a pretty rich representation of your items and.",
            "You know basically dot products in high dimensional spaces can allow you to capture all sorts of interesting complicated interactions, I think.",
            "OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Great thanks, he only takes to the organizers so.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about probabilistic approaches to preference learning, and in particular looking at both supervised and unsupervised models for preference learning, and I apologize if I I'll cover some material which I think maybe a bunch of you are aware of because I've seen it sort of extended in interesting ways in some of the posters here.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first of all, what's preference learning well?",
                    "label": 0
                },
                {
                    "sent": "At a very simple level, it's learning where the data is in the form of some sort of inequality relationships.",
                    "label": 1
                },
                {
                    "sent": "And surprisingly, many machine learning problems fall into this class.",
                    "label": 1
                },
                {
                    "sent": "There all sorts of places where either explicitly or implicitly we can get preference information out of, usually people, and then we want to model them in various different ways.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can distinguish between various different kinds of preference learning problems, and I'll.",
                    "label": 0
                },
                {
                    "sent": "Kind of broadly distinguish between instance preference, learning and label preference, learning or label ranking.",
                    "label": 1
                },
                {
                    "sent": "So in instance.",
                    "label": 0
                },
                {
                    "sent": "Preference learning your data is a set of preference relations measured on items or instances, so your data set might be.",
                    "label": 1
                },
                {
                    "sent": "Set of the source of preference relations, where each of these items comes from some set of items X you know, like.",
                    "label": 0
                },
                {
                    "sent": "You prefer Coke to Pepsi or something like that.",
                    "label": 0
                },
                {
                    "sent": "And you know, to make this a bit more interesting, usually we have, we know some features of these sorts of objects when we're trying to model the preferences.",
                    "label": 0
                },
                {
                    "sent": "In label preference learning or label ranking, you have some items X subset of items X and a set of labels L. And for any item X.",
                    "label": 0
                },
                {
                    "sent": "You he might have preference relations in terms of which labels go with that item X. OK, so we could actually cast various problems in machine learning in terms of these sorts of label preference graphs.",
                    "label": 0
                },
                {
                    "sent": "So for example in a multi class classification problem.",
                    "label": 0
                },
                {
                    "sent": "You say that for some item X. Label three is the correct label that information can be cast as a bunch of preferences, label preferences saying the three is preferred to 2.",
                    "label": 0
                },
                {
                    "sent": "Three is preferred to 1.",
                    "label": 0
                },
                {
                    "sent": "Three is preferred for threes before to five.",
                    "label": 0
                },
                {
                    "sent": "In ordinal regression, where there is an actual ordering in these labels, then the similar thing here would also imply that.",
                    "label": 0
                },
                {
                    "sent": "If you prefer 3, then you should prefer 2 to one as well, because these things are labeled are ordered, and similarly in the other direction.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to focus on instance preference learning.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So imagine if the user exhibits some sort of preference.",
                    "label": 1
                },
                {
                    "sent": "Prefer X to X prime.",
                    "label": 0
                },
                {
                    "sent": "Way we're going to approach this is to imagine that there is some preference function or utility function, let's call it F, such that F of X is greater than F of X prime.",
                    "label": 1
                },
                {
                    "sent": "Perhaps corrupted by noise and this is, you know, it's a very classical way of doing things, and I know there are other ways of doing things, but this goes back to some of the stuff that you heard about before.",
                    "label": 0
                },
                {
                    "sent": "It's very similar to some aspects of what Torah talked about as well.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So then the problem of preference learning boils down to the problem of learning about these underlying hidden functions.",
                    "label": 0
                },
                {
                    "sent": "And so we need to think how do we learn about these functions?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we learn about preference functions from data of this kind?",
                    "label": 1
                },
                {
                    "sent": "Imagine we now have N data points, each of which is some kind of preference relation like this between a pair of items.",
                    "label": 0
                },
                {
                    "sent": "And broadly speaking, when we have approaches based on learning about unknown functions.",
                    "label": 0
                },
                {
                    "sent": "There are sort of large number of very elegant optimization based approaches which say.",
                    "label": 0
                },
                {
                    "sent": "Minimize over some suitable space of functions loss function.",
                    "label": 0
                },
                {
                    "sent": "Loss for each data point evaluated on that function plus some regularizer.",
                    "label": 0
                },
                {
                    "sent": "This is a rather closely related to probabilistic approach, which is the one that I'm going to take where instead of thinking about a minimization over functions, we're going to think about an inference problem over hidden functions.",
                    "label": 0
                },
                {
                    "sent": "We have our observed data.",
                    "label": 0
                },
                {
                    "sent": "We want to infer the function from the data the way we do that is, first of all, we have to put in some prior assumptions about the space of functions.",
                    "label": 0
                },
                {
                    "sent": "That we're going to use.",
                    "label": 0
                },
                {
                    "sent": "And then we have our likelihood function which roughly corresponds.",
                    "label": 0
                },
                {
                    "sent": "I mean, this prior roughly corresponds to the regularizer here, and the likelihood function roughly corresponds to the loss function that we use there.",
                    "label": 0
                },
                {
                    "sent": "And then we do posterior inference over functions given the data in this framework.",
                    "label": 0
                },
                {
                    "sent": "So basically we're now going from preference learning to preference functions.",
                    "label": 0
                },
                {
                    "sent": "We need a prior on functions.",
                    "label": 0
                },
                {
                    "sent": "What do we use as a prior on functions?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to very briefly do a Gaussian process tutorial.",
                    "label": 0
                },
                {
                    "sent": "Raise your hand if you are very familiar with Gaussian processes, OK. Raise your hand if you're very unfamiliar with Gaussian processes.",
                    "label": 0
                },
                {
                    "sent": "OK, and then there are people in between.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to do this blindingly fast then.",
                    "label": 0
                },
                {
                    "sent": "Alright, so Gaussian process defines a distribution over functions, functions that map from some space to the reels, and it has the property that if you evaluate the functions in a finite number of points, then the multivariate distribution over that vector evaluated this finite number of points is a multivariate Gaussian distribution.",
                    "label": 1
                },
                {
                    "sent": "So if that holds for any any subset of this SpaceX and all those Gaussians are coherent with each other, then there is such a thing as a Gaussian process, and you've characterized it through its marginals.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's parameterized in terms of his mean function and its covariance function, which correspond to the mean vector and covariance matrix of a multivariate Gaussian, and they also correspond to something that people don't usually use, and the kernel in a kernel machine.",
                    "label": 1
                },
                {
                    "sent": "And essentially, all inferences about Gaussian process are, although the Gaussian process itself is an infinite dimensional object, all inferences can be done on the finite dimensional marginals of the function evaluated at your end data points.",
                    "label": 0
                },
                {
                    "sent": "So you end up doing operations that are on N by N matrices an end dimensional Gaussians.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Generally, we think of guessing processes being used for regression, but they've been used for classification, and here we're going to use him for preference learning.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the hopefully blindingly fast part, a Gaussian process, kernel or covariance function captures the properties of the functions that you might be interested in, and you generally define parameterized families of such kernels.",
                    "label": 1
                },
                {
                    "sent": "For example, this is a particular parametrized family of kernels, and you have a bunch of parameters which are interpretable.",
                    "label": 0
                },
                {
                    "sent": "That's the nice thing about it.",
                    "label": 0
                },
                {
                    "sent": "You can call these things different things like signal variance, length, scale, roughness, variance of the bias, etc.",
                    "label": 1
                },
                {
                    "sent": "Once you play with these, you can really understand what they're doing, which is great, and you can learn them automatically from the data using very standard methods.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's some samples from Gaussian processes with different covariance functions, and they characterize different kinds of assumptions about distributions over data.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And learning the kernel.",
                    "label": 0
                },
                {
                    "sent": "Involves taking those hyperparameters of the kernel that I was talking about.",
                    "label": 1
                },
                {
                    "sent": "Here is a different slightly different kernel with a bunch of hyperparameters, a very standard one as well, and then you can write down the marginal likelihood as a function of those hyperparameters.",
                    "label": 1
                },
                {
                    "sent": "That's the probability of the regression cases, the probability of the output labels for preference learning, it would be the probability of those observed preference relations given the features of the inputs.",
                    "label": 0
                },
                {
                    "sent": "As in instance preference learning, let's say.",
                    "label": 0
                },
                {
                    "sent": "That marginal likelihood for for regression with Gaussian noise is just the multivariate Gaussian density.",
                    "label": 0
                },
                {
                    "sent": "So you can write it out in this form and optimize it with respect to the thetas, or do Bayesian inference over the thetas if you really want to avoid any any risk of overfitting.",
                    "label": 0
                },
                {
                    "sent": "In the preference learning case, which will get to in a minute.",
                    "label": 0
                },
                {
                    "sent": "The subtlety is that this marginal likelihood can't be computed exactly because of all those inequality relationships, so we need to make approximations.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is Gaussian process for classification.",
                    "label": 0
                },
                {
                    "sent": "I will talk about.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Them very much.",
                    "label": 0
                },
                {
                    "sent": "Who wants me to talk about the relationship between Gaussian processes and SVM's?",
                    "label": 0
                },
                {
                    "sent": "Raise your hand.",
                    "label": 0
                },
                {
                    "sent": "Not too many people.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The longer I wait, the less it cost you to say yes, I guess, so I'm not going to re derive the SVM, but here is a soft margin support vector machine cost function using this is in the kind of finite dimensional version where you have a vector here and you minimize the regular, the sort of regularizer here plus some constant C times.",
                    "label": 0
                },
                {
                    "sent": "This hinge losses for classification.",
                    "label": 0
                },
                {
                    "sent": "Then when you kernelized this whole thing, you can write it in terms of the.",
                    "label": 0
                },
                {
                    "sent": "You can map from the W2 the function space.",
                    "label": 0
                },
                {
                    "sent": "And the equivalent thing can be written like this.",
                    "label": 0
                },
                {
                    "sent": "You minimize over a vector of function values.",
                    "label": 0
                },
                {
                    "sent": "A quadratic form in the function values plus C times all those hinge loss functions.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It looks incredibly similar to an object inside the Gaussian process, so.",
                    "label": 0
                },
                {
                    "sent": "In the SVM we generally minimize this thing which I had on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "In the Gaussian process, the negative of the log of the Gaussian process likelihood is exactly the same thing with the same kernel.",
                    "label": 0
                },
                {
                    "sent": "You could plug in and then here instead of this bit, we have the log probability of the label given FI for each item I plus some irrelevant constant here.",
                    "label": 0
                },
                {
                    "sent": "This is an important and relevant constant is the regularization parameter and.",
                    "label": 0
                },
                {
                    "sent": "These look incredibly similar, but they're sort of philosophically very different.",
                    "label": 0
                },
                {
                    "sent": "In the SVM you do minimization in the Gaussian process you actually integrate over the functions here, so you're doing averaging over all the possible solutions in this sort of version space, you could think of.",
                    "label": 0
                },
                {
                    "sent": "And so we measure innocence in the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "We measure the uncertainty in the function as I described before.",
                    "label": 0
                },
                {
                    "sent": "We can learn the kernel parameters in a straightforward way because we have a proper likelihood, so we can do Bayesian inference or maximum likely on the kernel parameters.",
                    "label": 1
                },
                {
                    "sent": "We can combine 10 different kernels with different weighting coefficients and learn them with nothing to worry about.",
                    "label": 0
                },
                {
                    "sent": "The other funny thing which people might consider weird is we can learn the regularization parameter C without cross validation.",
                    "label": 1
                },
                {
                    "sent": "Y well, see here is just overall constant which I could wrap it into.",
                    "label": 0
                },
                {
                    "sent": "If I divide everything by CI could wrap into the kernel so it's just a scaling on the kernel matrix is another.",
                    "label": 0
                },
                {
                    "sent": "Other kernel hyperparameter no different than the other 10 or 15 kernel hyperparameters I could have.",
                    "label": 0
                },
                {
                    "sent": "There's no notion of 1 parameter controlling complexity that just seems silly to me.",
                    "label": 0
                },
                {
                    "sent": "OK, so and other various things, but you know in terms of performance there are often quite similar and they're you know sisters or brothers or so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things like that.",
                    "label": 0
                },
                {
                    "sent": "So maybe they don't always get along well, but they're related, right?",
                    "label": 0
                },
                {
                    "sent": "So here is just a picture of where these methods fall.",
                    "label": 1
                },
                {
                    "sent": "We can start from linear regression and turn it into classification method.",
                    "label": 1
                },
                {
                    "sent": "For example using something like logistic function, we get logistic regression.",
                    "label": 0
                },
                {
                    "sent": "We can start from linear regression and kernelized it.",
                    "label": 1
                },
                {
                    "sent": "Just by mapping into some high dimensional feature space, we can start from linear regression and do Bayesian inference over the parameters rather than optimization.",
                    "label": 0
                },
                {
                    "sent": "So this is these blue edges of this cube are base ifying methods, and then if you if you travel you know any of these many paths from linear regression through a blue edge magenta edge and an orange edge, you get to Gaussian process classification.",
                    "label": 0
                },
                {
                    "sent": "OK. And support vector machines would be here.",
                    "label": 0
                },
                {
                    "sent": "We could, you know, relate them.",
                    "label": 0
                },
                {
                    "sent": "It's not exactly a logistic loss, function is a hinge.",
                    "label": 0
                },
                {
                    "sent": "Loss function is pretty close.",
                    "label": 0
                },
                {
                    "sent": "These are just these are indicative labels here we can have many variants of different methods in each of these cubes.",
                    "label": 0
                },
                {
                    "sent": "And I think this is a very useful kind of diagram.",
                    "label": 0
                },
                {
                    "sent": "It certainly helps me understand things.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I dare say I didn't do it, but if we replace this with a different colored edge for preference ifying or something like that, we could build preference models out of regression models through these inequality relations.",
                    "label": 0
                },
                {
                    "sent": "It's actually very closely related.",
                    "label": 0
                },
                {
                    "sent": "This is related to this poster by parents whose are.",
                    "label": 0
                },
                {
                    "sent": "Over.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm not going to.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do that, I'm not going to talk about the comparison of SVM's and Gaussian process classifiers, but this is something interesting to think about.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's get back to preference learning.",
                    "label": 0
                },
                {
                    "sent": "You see how I'm doing on time.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is now slightly old work, don't despair.",
                    "label": 0
                },
                {
                    "sent": "I think a lot of you have seen this.",
                    "label": 0
                },
                {
                    "sent": "Judging by the posters, I'll talk about some newer stuff as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so for Gaussian processing preference learning, I just spent the last 10 minutes or so talking about the prior over functions.",
                    "label": 0
                },
                {
                    "sent": "Let's quickly talk about this likelihood.",
                    "label": 0
                },
                {
                    "sent": "The preference function likelihood can be written in the following way.",
                    "label": 1
                },
                {
                    "sent": "Just imagine a noise free or perfect sort of preference function which says that the probability that you prefer item V to you.",
                    "label": 0
                },
                {
                    "sent": "Given the function at.",
                    "label": 0
                },
                {
                    "sent": "V and the function value it U is 1 if.",
                    "label": 0
                },
                {
                    "sent": "The preference function at V is greater than the preference function at you.",
                    "label": 0
                },
                {
                    "sent": "In other words, you observe a preference data point saying that you prefer V to you if and only if your preference function is greater at V than it is at you.",
                    "label": 0
                },
                {
                    "sent": "Clearly this is this is a idealistic or noise free model and we want to be able to allow for noise in preference judgments so we can easily do that by imagining that these preference functions are corrupted by, say, Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "When you threshold it like this in a very similar way to what you saw in tourist talk, what you get is a probe it function.",
                    "label": 0
                },
                {
                    "sent": "So this is the actual kind of preference function that we use.",
                    "label": 0
                },
                {
                    "sent": "It's a pro bit of the difference it.",
                    "label": 0
                },
                {
                    "sent": "Sorry I didn't shouldn't have said preference function.",
                    "label": 0
                },
                {
                    "sent": "This is the actual likelihood function that we use.",
                    "label": 0
                },
                {
                    "sent": "It's a probate of the difference in the preference functions.",
                    "label": 0
                },
                {
                    "sent": "Sigma is the noise level of your corruption of the preference function and this is sort of the shape of the pro, but it's sort of sigmoid function and then this likelihood in red is just assuming IID given these functions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So and then this is the pointer to Ference Hussars, recent work mapping this simply onto a classification.",
                    "label": 0
                },
                {
                    "sent": "And then also talking about active learning in this context.",
                    "label": 0
                },
                {
                    "sent": "And there's see code for this, which makes it easier hopefully to compare.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now to do inference.",
                    "label": 0
                },
                {
                    "sent": "In this I said, oh I'm going to do integration.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to do optimization.",
                    "label": 0
                },
                {
                    "sent": "OK, you know, one of the ways of doing integration is you do optimization.",
                    "label": 0
                },
                {
                    "sent": "OK, then you get to the top of the Hill.",
                    "label": 0
                },
                {
                    "sent": "You measure the curvature at the top of the Hill and then you fit a Gaussian around the top of the Hill with that curvature.",
                    "label": 0
                },
                {
                    "sent": "And that's called Laplace's approximation.",
                    "label": 0
                },
                {
                    "sent": "So in this paper what we did was we optimized that posterior, which essentially ends up being an optimization of.",
                    "label": 0
                },
                {
                    "sent": "A function that looks like this.",
                    "label": 0
                },
                {
                    "sent": "It's a bunch of logs of probits and quadratic form and F. And the nice thing about this objective function as a function of F. OK, remember F is infinite dimensional.",
                    "label": 0
                },
                {
                    "sent": "We're not actually optimizing over the whole fit dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Equivalently, we can simply optimize over the vector F which is evaluated at our end items S of F is convex, which is nice, so.",
                    "label": 1
                },
                {
                    "sent": "We can easily optimize it using one of many standard methods, and then at the.",
                    "label": 0
                },
                {
                    "sent": "Map value of F. We can compute the.",
                    "label": 0
                },
                {
                    "sent": "This is the kernel matrix which is known, but we can compute additional second derivative terms.",
                    "label": 0
                },
                {
                    "sent": "This is a diagonal matrix here and evaluate a marginal likelihood for this model.",
                    "label": 1
                },
                {
                    "sent": "And this marginal likely it is nice because it can be used for hyperparameter learning, like learning the kernel or model selection, etc.",
                    "label": 1
                },
                {
                    "sent": "K Any questions about this?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, what about prediction?",
                    "label": 0
                },
                {
                    "sent": "Well, once you learn about the latent preference function prediction is straightforward.",
                    "label": 1
                },
                {
                    "sent": "Given the data.",
                    "label": 0
                },
                {
                    "sent": "If you want to evaluate whether you prefer R to S, then you have to compute this integral is a double integral over F of R&F of S of the distribution of F of R&F of X.",
                    "label": 0
                },
                {
                    "sent": "Given the data which we've approximated as a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So this is a bivariate Gaussian and then this is going to be simply a probate function.",
                    "label": 0
                },
                {
                    "sent": "Of that bivariate Gaussian, which is very easy to write, it's just the probate of the mean of F of R minus the mean of F of S / a variance term that's easy to compute.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is now rather dated results.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you know there are probably many better comparisons by now.",
                    "label": 0
                },
                {
                    "sent": "Showing that, at least at the time, this Gaussian process approach to preference learning.",
                    "label": 0
                },
                {
                    "sent": "Was doing better than a constraint based support vector machine approached preference learning that had been proposed also in terms of CPU time?",
                    "label": 0
                },
                {
                    "sent": "In this case, this is the Gaussian process method versus the SVM method, because in this particular case at least, this SVM formulation was based on which scale with the number of preference observations that you had, not with the number of items, whereas the Gaussian process.",
                    "label": 1
                },
                {
                    "sent": "Although it's cubic is cubic in the number of items.",
                    "label": 0
                },
                {
                    "sent": "Not in the number of preference relations that you observe, and usually you're going to have, you know.",
                    "label": 0
                },
                {
                    "sent": "Well depends if you have sparse observations, then roughly you'll observe some constant number of preference relations.",
                    "label": 0
                },
                {
                    "sent": "That's a factor of the number of items, but.",
                    "label": 0
                },
                {
                    "sent": "OK. Now we extended this too, so I think this work is actually now reasonably well known and probably dated, so I apologize to all the people who've done really excellent work since then.",
                    "label": 1
                },
                {
                    "sent": "I particularly want to point out there's some really nice work by Bonilla ET al.",
                    "label": 0
                },
                {
                    "sent": "Over the intervening years that really extend.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This extends in interesting ways.",
                    "label": 0
                },
                {
                    "sent": "I do want to talk about some work that I I sort of feel like maybe people haven't seen much.",
                    "label": 0
                },
                {
                    "sent": "Which was kind of maybe at a.",
                    "label": 0
                },
                {
                    "sent": "An older version of this workshop, so this was a nips workshop on learning to rank.",
                    "label": 1
                },
                {
                    "sent": "So I'm sure that some of the people at that workshop in 2005.",
                    "label": 0
                },
                {
                    "sent": "Are either the same as here topics and here what we did was we looked at combining this Gaussian process preference learning framework with semi supervised learning and active learning.",
                    "label": 0
                },
                {
                    "sent": "So in particular, at the time, and I think still there is a great deal of interest in graph based, semi supervised learning and graph based semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "The idea is illustrated here for the classification case.",
                    "label": 0
                },
                {
                    "sent": "Imagine we have a bunch of data for which most of the data points we don't observe the labels and a few of the data points we observe some labels.",
                    "label": 0
                },
                {
                    "sent": "But based on the raw data, we can form a graph connecting similar data points to each other.",
                    "label": 1
                },
                {
                    "sent": "So the way graph based semi supervised learning works is you form a graph G connecting nearby points based on whatever metric you want.",
                    "label": 0
                },
                {
                    "sent": "You compute the graph combinatorial Laplacian and then which I'll talk about in a minute.",
                    "label": 0
                },
                {
                    "sent": "And now we're actually going to use this.",
                    "label": 0
                },
                {
                    "sent": "Almost as a likelihood for our Gaussian process, it's not clear whether it's really should be called a likelihood or a prior, but it's a term that we're going to use to multiply in with our original Gaussian process prior, and the likelihood from the observed preference relations and this term here.",
                    "label": 0
                },
                {
                    "sent": "Is just E to the minus 1/2 F, transpose graph, Laplacian F. So obviously it's another quadratic term in F which which very naturally combines with the Gaussian process prior.",
                    "label": 0
                },
                {
                    "sent": "And the intuition for the graph Laplacian is.",
                    "label": 0
                },
                {
                    "sent": "Imagine the unweighted case.",
                    "label": 0
                },
                {
                    "sent": "Of course, we can make a weighted graph version, but the unweighted is very easy to get into it.",
                    "label": 0
                },
                {
                    "sent": "In the unweighted graph, this term encourages the function values to be similar at connected nodes, so I can write down this term.",
                    "label": 1
                },
                {
                    "sent": "By doing just a little bit of linear algebra, I can write it as this term here.",
                    "label": 0
                },
                {
                    "sent": "For the unweighted graph which simply says I have an additional term.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Sums over all pairs of connected nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "A quadratic term F I -- F J squared.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this obviously penalizes the function value at I in the function value at J being very different from each other.",
                    "label": 0
                },
                {
                    "sent": "Smoothness on the graph.",
                    "label": 0
                },
                {
                    "sent": "That's what the graph Laplacian captures.",
                    "label": 0
                },
                {
                    "sent": "And of course there's been huge literature on this over the over many years now.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea of the graph Laplacian, and we can straightforwardly included into our Gaussian process preference learning model and Moreover, in this paper we looked at active learning where we evaluated the expected information gain or entropy reduction from querying a particular pair.",
                    "label": 0
                },
                {
                    "sent": "Of items.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So you imagine.",
                    "label": 0
                },
                {
                    "sent": "OK, imagine you query this pair of items, UK versus VK.",
                    "label": 0
                },
                {
                    "sent": "Like you know, do you like Coke versus Sprite?",
                    "label": 0
                },
                {
                    "sent": "OK, this is obviously related to things we've been talking about today.",
                    "label": 0
                },
                {
                    "sent": "And now you can imagine the two possible answers that you get out of that.",
                    "label": 0
                },
                {
                    "sent": "And for each of those two answers, you compute the change in entropy, which is hard to compute exactly.",
                    "label": 0
                },
                {
                    "sent": "But remember, we've made a Gaussian approximation to the posterior over F, so we can simply entropies of Gaussians are rather easy to compute.",
                    "label": 0
                },
                {
                    "sent": "Especially if we add a small term to the Gaussian, then computing the difference in entropy is a little easier because it depends on the change in the determinant of the covariance matrix of Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And now too, because we don't know what the outcome is going to be, whether you like Coke versus Sprite, yes or no, we have to do an expectation over the possible two possible answers.",
                    "label": 0
                },
                {
                    "sent": "But we can sort of predict what those two answers are going to be OK, because we have a model of the whole thing.",
                    "label": 0
                },
                {
                    "sent": "So essentially, think of it as a pool based active learning.",
                    "label": 0
                },
                {
                    "sent": "We have a whole set of items or pairs.",
                    "label": 0
                },
                {
                    "sent": "We can pick items and.",
                    "label": 0
                },
                {
                    "sent": "And figure out which is going to give us the most information now.",
                    "label": 0
                },
                {
                    "sent": "Active learning and semi supervised learning go really well together actually because in both cases the assumption is that labeling is hard to get.",
                    "label": 0
                },
                {
                    "sent": "But we might have a lot of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "In particular here, it could be that.",
                    "label": 0
                },
                {
                    "sent": "Eliciting preference judgments is expensive, but we might have a lot of items and features of those items.",
                    "label": 0
                },
                {
                    "sent": "For example, OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are some results.",
                    "label": 0
                },
                {
                    "sent": "I mean, this was.",
                    "label": 0
                },
                {
                    "sent": "You know this was.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't say these are the best results in the world.",
                    "label": 0
                },
                {
                    "sent": "This was just a workshop paper.",
                    "label": 0
                },
                {
                    "sent": "I don't think we really followed up on it in terms of writing of.",
                    "label": 0
                },
                {
                    "sent": "A full paper on this.",
                    "label": 0
                },
                {
                    "sent": "But there are several comparisons here.",
                    "label": 0
                },
                {
                    "sent": "This is the fully supervised learning case.",
                    "label": 0
                },
                {
                    "sent": "You can compare active learning versus random OK random Query versus active querying for a number of query points on on a log scale here.",
                    "label": 1
                },
                {
                    "sent": "And the blue one is the active one, and so these error bars are standard deviations over 20 runs of this method.",
                    "label": 1
                },
                {
                    "sent": "And here we you know.",
                    "label": 0
                },
                {
                    "sent": "Again, I apologize a little bit.",
                    "label": 0
                },
                {
                    "sent": "We cheated.",
                    "label": 1
                },
                {
                    "sent": "We took a metric regression problem.",
                    "label": 0
                },
                {
                    "sent": "Boston Housing is sort of regression problem and we turned it into a preference learning problem.",
                    "label": 0
                },
                {
                    "sent": "Basically we said OK.",
                    "label": 0
                },
                {
                    "sent": "The preference relation is implicit in the value that we're trying to predict in a regression problem.",
                    "label": 0
                },
                {
                    "sent": "We're only going to observe Inequality's in that value.",
                    "label": 0
                },
                {
                    "sent": "Real-world preference problems are probably not that well behaved OK.",
                    "label": 0
                },
                {
                    "sent": "So active learning is better than random, which isn't surprising.",
                    "label": 1
                },
                {
                    "sent": "Here is the semi supervised case.",
                    "label": 1
                },
                {
                    "sent": "Again, active learning is better than random in the semi supervised case.",
                    "label": 0
                },
                {
                    "sent": "You know you could see if you draw horizontal lines along here you can actually see a cost gain.",
                    "label": 0
                },
                {
                    "sent": "By being active versus random, which could be measured in terms of the number of preference pairs that you need to achieve a certain performance.",
                    "label": 0
                },
                {
                    "sent": "And here is semi supervised versus supervised for the active case and we don't seem to get much difference actually on this particular data set, so I'm not really sure why.",
                    "label": 0
                },
                {
                    "sent": "OK, any questions about this?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I see the point that reduces the SP process on the latent function in the most, and you see this sort of thing when people do active learning or Gaussian process classification and stuff as well, where they're trying to reduce the entropy.",
                    "label": 0
                },
                {
                    "sent": "The latent function.",
                    "label": 0
                },
                {
                    "sent": "But if you think about what you actually care about, it's sort of like you have an unlabeled points.",
                    "label": 0
                },
                {
                    "sent": "So there's like any missing preferences, but your nonlinear transform.",
                    "label": 1
                },
                {
                    "sent": "Other GPU that induces a different non Gaussian distribution on those.",
                    "label": 0
                },
                {
                    "sent": "My query, something that gives you a lot of information about the the Gaussian, but you don't care about the Gaussian function, but maybe it's really, really yes.",
                    "label": 0
                },
                {
                    "sent": "I totally agree with you.",
                    "label": 0
                },
                {
                    "sent": "I totally agree with you.",
                    "label": 1
                },
                {
                    "sent": "The entropy on the Gaussian is sort of cheap poor man surrogate for what you might ultimately be really interested in, which is the.",
                    "label": 0
                },
                {
                    "sent": "The information gained about the labels, or actually maybe ultimately what you're interested in is the.",
                    "label": 0
                },
                {
                    "sent": "The query point that minimizes my expected generalization error as measured by classification error OK or preference error, let's say and.",
                    "label": 0
                },
                {
                    "sent": "Although in this work we didn't, we didn't do that.",
                    "label": 0
                },
                {
                    "sent": "I have done some work along those lines with Jerry Zhu and John Lafferty in a semi supervised learning case where we actually for that graph based semi supervised learning procedure that we had.",
                    "label": 0
                },
                {
                    "sent": "We can compute the.",
                    "label": 0
                },
                {
                    "sent": "Expected change in classification labels.",
                    "label": 0
                },
                {
                    "sent": "And it's actually not.",
                    "label": 0
                },
                {
                    "sent": "It's actually rather cheap in that model as well, but it's not always the case.",
                    "label": 0
                },
                {
                    "sent": "Most of the time it's very expensive to compute that, so there's a paper on active semi supervised learning, which I think does much more the correct thing than what we did here.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So any other questions about this?",
                    "label": 0
                },
                {
                    "sent": "Alright, I wanted to point out.",
                    "label": 0
                },
                {
                    "sent": "I want to change gears the last few minutes and talk about kind of unsupervised preference learning.",
                    "label": 0
                },
                {
                    "sent": "And here I'm going to talk about some work by Dylan Gore and colleagues.",
                    "label": 0
                },
                {
                    "sent": "On a choice model with infinitely many latent features, which I thought was very interesting.",
                    "label": 1
                },
                {
                    "sent": "And this is based on the illumination by aspects model.",
                    "label": 0
                },
                {
                    "sent": "Where are you look at the probability of choosing item XI?",
                    "label": 0
                },
                {
                    "sent": "Versus item XJ.",
                    "label": 0
                },
                {
                    "sent": "Let's call that PJ and we're going to model this.",
                    "label": 0
                },
                {
                    "sent": "This is, uh, I don't know whether you want to call it.",
                    "label": 0
                },
                {
                    "sent": "I think the distinction between supervised and unsupervised is maybe a bit fuzzy here anyway, but we could almost call this unsupervised because.",
                    "label": 0
                },
                {
                    "sent": "Essentially, what we're going to do is we're going to learn a bunch of latent features of these items.",
                    "label": 0
                },
                {
                    "sent": "So if we had observed features of these items, like, let's say, Costan way, tan color, etc, then the elimination by aspects model would say something like.",
                    "label": 0
                },
                {
                    "sent": "Let's take each of our features, we have a weight on each feature.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We're going to choose I / J.",
                    "label": 0
                },
                {
                    "sent": "Using these feature indicators so this says item I has feature K versus item J does not have feature K. Alright, so if two items have the same feature.",
                    "label": 0
                },
                {
                    "sent": "Then there is no term in this sum in the numerator, but if two items differ in the feature.",
                    "label": 0
                },
                {
                    "sent": "Then there's a weight that gets added up, and then there is a normalizing constant here which basically ensures that you get a sensible probability of choosing I versus J.",
                    "label": 0
                },
                {
                    "sent": "Now, if you had observed features, you could just simply learn these W's from the data.",
                    "label": 0
                },
                {
                    "sent": "But now what we're going to assume is or not.",
                    "label": 0
                },
                {
                    "sent": "When I say we, I mean they really 'cause I was not involved in this at all.",
                    "label": 0
                },
                {
                    "sent": "What they assumed is that these hidden binary features have to be learned or inferred from the data.",
                    "label": 0
                },
                {
                    "sent": "So these are latent features, and Moreover, I mean this is too stringent a model, so you can again add some noise in the likelihood function and say you prefer item I to item J.",
                    "label": 0
                },
                {
                    "sent": "With a probability that's a function of these parameters shall talk about in a minute and essentially you take this PIJ value an you shrink it down from from the extreme zero and one by epsilon on each end.",
                    "label": 0
                },
                {
                    "sent": "So you have one minus epsilon Pi J plus.",
                    "label": 0
                },
                {
                    "sent": "Epsilon, PG.",
                    "label": 0
                },
                {
                    "sent": "Is that right?",
                    "label": 0
                },
                {
                    "sent": "No, that's not right.",
                    "label": 0
                },
                {
                    "sent": "Then these cancel.",
                    "label": 0
                },
                {
                    "sent": "And you get one.",
                    "label": 0
                },
                {
                    "sent": "No, you get PIJ.",
                    "label": 0
                },
                {
                    "sent": "All right, there is a bug in this equation, but essentially what you can imagine is corrupt.",
                    "label": 0
                },
                {
                    "sent": "The decisions at the top and the bottom by epsilon, and that's the likelihood function that you have.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I'll have either I transcribed it wrong or there was a bug in the paper.",
                    "label": 0
                },
                {
                    "sent": "Sorry, PJI yeah.",
                    "label": 0
                },
                {
                    "sent": "Or one minus PJ.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you now.",
                    "label": 0
                },
                {
                    "sent": "Now we have a bunch of binary hidden features here and this is the I think the interesting aspect of this paper is that they wanted to infer those binary hidden features from the data and they use a nonparametric Bayesian approach for doing that.",
                    "label": 1
                },
                {
                    "sent": "Saying that we don't know how many of these binary latent features there are, so we're going to assume that this feature matrix F is drawn from an Indian buffet process.",
                    "label": 0
                },
                {
                    "sent": "The Indian buffet process is just a sparse way for each item to define binary features.",
                    "label": 0
                },
                {
                    "sent": "Where you don't have a bound on the possible number of binary features, a priority, so the model can learn automatically how many binary features it needs to model the data, and then these weights they have to be positive.",
                    "label": 0
                },
                {
                    "sent": "So these were given a gamma prior, but obviously that's a other choices could be done there and the model that learns how many latent features are needed to model the preference data.",
                    "label": 1
                },
                {
                    "sent": "Which I think is kind of neat actually.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last thing I want to talk about is a very simple idea.",
                    "label": 0
                },
                {
                    "sent": "And you know, I swear, this must have been done by somebody.",
                    "label": 0
                },
                {
                    "sent": "So the reason I'm talking about it here is because I'm just curious whether somebody's done this.",
                    "label": 0
                },
                {
                    "sent": "So I'm hoping the answer is yes, somebody has done it.",
                    "label": 0
                },
                {
                    "sent": "If the answer is no, then I'll really quickly get a student to write a paper on it.",
                    "label": 0
                },
                {
                    "sent": "Or if the answer is not interesting, then I'll forget about it again.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very simple thing.",
                    "label": 0
                },
                {
                    "sent": "Imagine you have data where users you.",
                    "label": 1
                },
                {
                    "sent": "Express preferences for items.",
                    "label": 0
                },
                {
                    "sent": "And we're going to denote PUIJ being one as user U prefers item I to item J and our goal is going to be super simple.",
                    "label": 1
                },
                {
                    "sent": "We're just going to cluster users on the basis of such preference data.",
                    "label": 1
                },
                {
                    "sent": "So if we use now, this notation says, call it XX UI to note the utility or value or preference sort of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, let's just say utility or value of item I to user U.",
                    "label": 0
                },
                {
                    "sent": "Then preferences can be expressed as inequality relations.",
                    "label": 0
                },
                {
                    "sent": "Between these latent things here.",
                    "label": 1
                },
                {
                    "sent": "I mean, this maybe looks a lot like the Matchbox type models.",
                    "label": 0
                },
                {
                    "sent": "And now the utility.",
                    "label": 0
                },
                {
                    "sent": "The point is the utility.",
                    "label": 0
                },
                {
                    "sent": "Of item I to user U is going to be expressed through a kind of matrix factorization form.",
                    "label": 0
                },
                {
                    "sent": "Where you have a vector in some M dimensional space representing the user and a vector in that same dimensional space representing the item.",
                    "label": 0
                },
                {
                    "sent": "If the dot product is high, then there is high utility.",
                    "label": 0
                },
                {
                    "sent": "Otherwise there's low utility.",
                    "label": 0
                },
                {
                    "sent": "In fact, actually, you know if we made this infinite dimensional we could think of these as functions in some space, but you know, kernelized it.",
                    "label": 0
                },
                {
                    "sent": "Make it functions, blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about this simple form first.",
                    "label": 0
                },
                {
                    "sent": "OK, without obfuscating everything.",
                    "label": 0
                },
                {
                    "sent": "So now if we want to cluster users, essentially all we have to do is cluster these W vectors in this M dimensional space and so for that we can use a rather straightforward model, for example a. Dearsley process.",
                    "label": 0
                },
                {
                    "sent": "Mixture of normals.",
                    "label": 1
                },
                {
                    "sent": "So this is just a mixture of Gaussians in the M dimensional space where you can allow as many clusters as you want and you can allow it to grow.",
                    "label": 0
                },
                {
                    "sent": "So has this been?",
                    "label": 0
                },
                {
                    "sent": "Has this been done before?",
                    "label": 0
                },
                {
                    "sent": "Super.",
                    "label": 0
                },
                {
                    "sent": "It's in a sense we're clustering the users.",
                    "label": 0
                },
                {
                    "sent": "Just based on what stuff they like.",
                    "label": 0
                },
                {
                    "sent": "OK, the preferences that we observe on the users.",
                    "label": 0
                },
                {
                    "sent": "Sushi daughter said at a paper on this kind of thing.",
                    "label": 0
                },
                {
                    "sent": "I don't know if it's really worth it.",
                    "label": 0
                },
                {
                    "sent": "Would be very interesting to think about it.",
                    "label": 0
                },
                {
                    "sent": "I mean, you know this is just this sort of another unsupervised way of modeling preference data.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm I don't know whether college supervisor unsupervised, but essentially you're learning something about your users by clustering them.",
                    "label": 0
                },
                {
                    "sent": "You could do much fancier things as well, like by not clustering these vectors, you're doing and low dimensional embedding of your users, and that maybe is more standard.",
                    "label": 0
                },
                {
                    "sent": "But clustering is sometimes interpretable and nice.",
                    "label": 0
                },
                {
                    "sent": "So in case.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're curious, here's the graphical model for it and actually got with a have to admit a great deal of help from one of my students who's an expert on Internet.",
                    "label": 0
                },
                {
                    "sent": "We actually managed to code this thing up infer.net.",
                    "label": 0
                },
                {
                    "sent": "To play around with it so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it could be interesting to explore this.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'm just going to wrap up now.",
                    "label": 0
                },
                {
                    "sent": "Many problems in preference learning can be viewed as problems of inferring latent preference or utility functions.",
                    "label": 1
                },
                {
                    "sent": "Obviously, you know we can apply probabilistic modeling approaches to these problems.",
                    "label": 0
                },
                {
                    "sent": "For the supervised preference, learning problems where essentially you observe features of items and then preference judgments of some kind, then this preference function, it seems natural, at least from probabilistic point of view, to use something like Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "For unsupervised preference modeling, then you can learn latent features using things like the Indian buffet process or the Chinese restaurant profit process.",
                    "label": 0
                },
                {
                    "sent": "And all of these are actually, I would say, reasonably simple and usable models.",
                    "label": 0
                },
                {
                    "sent": "OK, you know people are often scared of nonparametrics, can get really nasty and horrible but I think in all these cases these are actually quite deal aghbal and perhaps even scalable models.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll end there.",
                    "label": 0
                },
                {
                    "sent": "Great thanks.",
                    "label": 0
                },
                {
                    "sent": "When you say in your in the model that you just presented.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You assume abiding out form W * * V. You have some ways to canonize the dot product.",
                    "label": 0
                },
                {
                    "sent": "If you multiply to Goshen process, for example, assume that.",
                    "label": 0
                },
                {
                    "sent": "Space, how would you do that?",
                    "label": 0
                },
                {
                    "sent": "Because in the performance learning it's quite easy when you have just yeah.",
                    "label": 0
                },
                {
                    "sent": "As soon as you multiply 2 version processes, you don't obtain admission process.",
                    "label": 0
                },
                {
                    "sent": "So how would you do that?",
                    "label": 0
                },
                {
                    "sent": "It's a very interesting question.",
                    "label": 0
                },
                {
                    "sent": "I don't know standing here.",
                    "label": 0
                },
                {
                    "sent": "It's gonna be one of these things like it's either trivial or impossible.",
                    "label": 0
                },
                {
                    "sent": "You know, I'm not willing to say which one yet.",
                    "label": 0
                },
                {
                    "sent": "But you know, anytime you see some, you know linear spaces and all products you could think of.",
                    "label": 0
                },
                {
                    "sent": "A joint function.",
                    "label": 0
                },
                {
                    "sent": "Of you and I right in this space.",
                    "label": 0
                },
                {
                    "sent": "But OK. Perhaps I should look at that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I mean, you know there are interesting ways.",
                    "label": 0
                },
                {
                    "sent": "Activate it, yeah.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the distraction.",
                    "label": 0
                },
                {
                    "sent": "Yes, it might be interesting to simply have just a function representing this dot product in high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "You're thinking of a function here.",
                    "label": 1
                },
                {
                    "sent": "Anna function here and then doing that sort of dot product.",
                    "label": 0
                },
                {
                    "sent": "I'm not exactly sure whether that can be done easily.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "I mean the other characteristic of this is maybe for that, for interpretability.",
                    "label": 0
                },
                {
                    "sent": "Might be nice to cluster users or something like that, or cluster items, yeah?",
                    "label": 1
                },
                {
                    "sent": "You could have gotten process prior all user right now, yeah.",
                    "label": 1
                },
                {
                    "sent": "For example, what you saying one thing?",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you do block structure on the covariance here, then yeah, then you get essentially the kernelized infinite dimensional version of this.",
                    "label": 1
                },
                {
                    "sent": "Now one thing that I think is nice is you know when you map stuff into high enough dimensional space, you can get away with all sorts of things like that's a pretty rich representation of your items and.",
                    "label": 0
                },
                {
                    "sent": "You know basically dot products in high dimensional spaces can allow you to capture all sorts of interesting complicated interactions, I think.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                }
            ]
        }
    }
}