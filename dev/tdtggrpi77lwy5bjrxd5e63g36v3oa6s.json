{
    "id": "tdtggrpi77lwy5bjrxd5e63g36v3oa6s",
    "title": "On Subgroup Discovery in Numerical Domains",
    "info": {
        "author": [
            "Henrik Grosskreutz, Fraunhofer IAIS"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_grosskreutz_sdnd/",
    "segmentation": [
        [
            "OK so hello everybody.",
            "My talk is about subgroup discovery in the miracle domains and this is joint work with."
        ],
        [
            "Ungrouping.",
            "Um?",
            "Is a brief overview over the talk.",
            "First, I briefly describe the task of subgroup discovery.",
            "Then I will talk about problems that arise if subgroup discovery is done in numerical domains.",
            "The raft I will present new pruning scheme to improve the performance of subgroup discovery in such domains and present an algorithm based on this routing scheme and present some impact."
        ],
        [
            "Empirical results.",
            "So first subgroup discovering what is this task?",
            "It's a local pattern discovery task and the idea is to find in a population some parts of the populations or.",
            "I better say to find a description of parts of the population which differ from the overall population and are as large as possible.",
            "So here's an example.",
            "I have a data set or here's a data set with some employee data.",
            "And there is one attribute.",
            "The so called class attribute which describes the stress level of the employees.",
            "And the employees are also described by two other attributes which say what profession do they have and what is their gender.",
            "And so subgroup discovery would look for example for employees or group of people with a high stress level.",
            "And that could be for example, a description like the professionals feature and the general sexes male.",
            "So this description would select the 1st and the last row.",
            "They both have a high stress level and sense they are they differ from the overall.",
            "Population so formally subgroup description is a conjunction of attribute value pairs.",
            "Like profession, this teacher and there's a relation between subgroups discovery and other tasks.",
            "In particular rule discovery tasks, because this can be interpreted as a kind of.",
            "Rule which says that under certain conditions the.",
            "Target attribute of the class has a particular value, so subgroup discovery is closely related with other tasks, like also contrast set mining and.",
            "Correlated itemset mining."
        ],
        [
            "One thing which is really important subgroup discovery or probably general in local pattern discovery is what is the quality of a subgroup or the pattern in general, and in this work we consider quality functions of the following structure.",
            "So basically you take the size of the subgroup extension to the power of constant A.",
            "And multiply it with the difference between the share in the subgroup and the share and the overall population.",
            "So in the case of this example description, here we have.",
            "2 examples in this data set.",
            "The 1st and the last one, so the size is 2 and is multiplied with the target share in the subgroup, which is 100% because in the first and last row we have a high stress level minus the overall share of high stress level which is.",
            "4 out of 6.",
            "And as I just said, A is constant and defending depending on the value of that constant, this quality function is all equivalent to.",
            "A few very well known quality functions like the Jeffrey Schapiro or weighted relative currency.",
            "Quality function alter the normal test."
        ],
        [
            "Quality function so that was about subgroup discovery in general.",
            "Now in many domains, the attributes which described.",
            "Records all the entities of interests are not nominal, but instead numerical or ordinal.",
            "So for example, if we have a medical data set and we are looking for.",
            "Persons which have sudden vascular disease then the attributes are likely to be something like the blood pressure which is in the miracle value on the body mass index or the age and so on and so.",
            "In this case, we probably don't want to have attributes, value pairs or conjunction of attribute value pairs, because these would select only very small subset of the population.",
            "But instead we would prefer to have attribute interval tests.",
            "So we would like to have more defined subgroups like.",
            "Maybe the body mass index if it is large between 26 and 30 and we have these three rows and Additionally the.",
            "Blood blood pressure is high.",
            "Then we have a very high risk for the disease, first and last.",
            "Record again.",
            "Now that."
        ],
        [
            "How can we deal with subgroup discovery in numerical domains and 1st?",
            "I want to present.",
            "Or to describe some problems which arise if one simply uses or simply, if one uses the standard approach, nominal, subgroup, discovery and 1st use the discretization step.",
            "Typically we would probably use entropy discretization and replace every numerical attribute by a nominal attribute.",
            "And to illustrate the problem here, well, graphical representation of the data set which has two describing attributes, the X value and the Y value, and these values of these attributes takes.",
            "Values between one and six in this example for both X&Y and the points here, shall describe different records and the records with a kind of a plus positive records and the points are simply negative records.",
            "So what we are looking for here is a description of a subgroup which has a lot of pluses.",
            "I know this is an artificial intelligent.",
            "Example, but still it should probably help to lose traits.",
            "The task we want to solve.",
            "The problems will arise.",
            "So what we want to have is for example this subgroup here, which only includes positive examples or this subgroup here and we don't have 1/2 of the subgroups.",
            "But if we would use entropy discretization then every.",
            "Attribute basically would be replaced by a new nominal attribute.",
            "And the set of split points in case of entropy discretization would be the green lines and the blue lines.",
            "So we would have a new domain, say for the.",
            "Replacement for this attribute.",
            "New attributes prime with values 1234 and five, 6 and the problem now is that.",
            "If we stick to the standard.",
            "Definitional approach which finds conjunction of attribute value pairs.",
            "Then we cannot find description of this subgroup here simply because.",
            "The values for the new discretized X IS123 four or five 6, so it's possible to express a subgroup like X as in 1, two and wise and 1 two.",
            "But it's not possible to say X as in 124.",
            "Simply because we have new non overlapping intervals as.",
            "Normal values for the new attribute.",
            "So well, you have a problem here.",
            "And of course it might be or is a good idea.",
            "And a solution to.",
            "In some way use overlapping intervals.",
            "So to have the possibility to express it, something ranges between."
        ],
        [
            "Four and one way to do this technically is to use a set of binary two valued attributes.",
            "But at least if this is combined with entropy discretization, there are still many cases where we will not find the optimal solution.",
            "Here's another data set, and again, I think you can see that this up we want to find this one.",
            "But if we apply entropy discretization, then attribute Y is divided into 3 intervals, which is nice, but the interval X if we use entropy discretization will simply result in.",
            "Well would be removed basically.",
            "Because there are no obvious split points because the distribution on this X is on the X axis is uniformly in every.",
            "In every column you can see that there is exactly 1/3 of the examples are positive, so there is no obvious split point.",
            "And well, it's.",
            "The problem which occurs will find something like that a subgroup description, but this is not what we intended to."
        ],
        [
            "Define well.",
            "Cause an obvious question is, is this purely artificial this example or can it also can this kind of problems also occur in real world datasets and to well, get an idea if this is the case, not we?",
            "Use different strategies for discretization on datasets from the UCI repository and for example here on the right we have used data set.",
            "And the red curve is the quality of the best subgroup that one can find if one uses arbitrary intervals overlapping intervals.",
            "And the different other lines show the quality.",
            "Further have set this X axis shows the maximum length of the subgroup descriptions.",
            "But what I want to say is that if one users, for example frequency discretization and one gets really bad subgroups if one uses entropy, the subgroup descriptions have a higher quality, but they are still far away from the best solution that we would like to find and the blue line here is again overlapping intervals, but using frequency discretization to avoid the problem illustrated in this image that entropy discretization will simply find.",
            "Note spit point when considering a single.",
            "Now."
        ],
        [
            "Under Merrick attribute so.",
            "All this motivation was to show you that in general, if we want to find optimal solutions, we first have to look at overlapping intervals, and it's not possible to.",
            "So in general it's not possible to use something like entropy discretization because the quality of the subgroups.",
            "Will not be optimal, so we have to well look at a lot of different attribute interval.",
            "Constraints and the question is, is it possible to somehow speed up the computation then?",
            "Because of course the search space becomes real."
        ],
        [
            "Large in this case.",
            "So.",
            "We haven't.",
            "I would present a new pruning approach in this case, and the first thing I'd like to do is to show how subgroup discovery is realized in practice or in most algorithms it's realized as a kind of search.",
            "Many algorithms kind of search in the space of subgroup descriptions, so we have different levels in the sense that we start with subgroup descriptions with length 0, so empty description.",
            "Then we have descriptions of length one, length two, and so on and on this.",
            "First level there are subscriptions which involve a test or constraint on the X.",
            "Attribute this is just an example with two attributes.",
            "Then we have constraints based on 2nd attribute Y and then next level.",
            "We have constraints which range over both.",
            "Attributes and this is meant to be to be read like that.",
            "For example, here we have a constraint Y is in Y1Y2.",
            "And Additionally, it's constrained to be an X one X3, so this is a conjunction of two.",
            "Constraints.",
            "And the question now is, can we somehow search this space without having to explicitly consider every node to do?"
        ],
        [
            "Much pruning as possible.",
            "And.",
            "First, I'd like to show you what standard approaches exist to speed up the computation or to speed up the discovery of subgroups once then approaches to use optimistic estimates.",
            "I'm too optimistic estimate pruning and the idea is basically if I consider a certain node during for example depth or search.",
            "I calculate an optimistic estimate which is a bound on the value of all subgroup descriptions below that node.",
            "So it's a bound on the quality of all descriptions in the branch below that node.",
            "And if this optimistic estimated I obtain is below a certain threshold.",
            "Maybe I should say something with the threshold there are different ways to state the exact problem.",
            "If for example, I'm looking for the best subgroup description, then I would during the search adaptive threshold because I would only be interested in subgroups which are better than the subgroup I already considered.",
            "So optimistic estimate pruning can allow to prune some parts of the search space and, well, it's fine that reduces the search space, but."
        ],
        [
            "In numerical domains, we can do more and the idea is the following.",
            "We can do some kind of well, maybe it's could be called something like horizontal pruning.",
            "The idea is to if I have.",
            "Considered all subgroups below condition, like X as in X one X2 is 1 and thanks to our thresholds here.",
            "So I have looked at all subgroups in this branch and calculates the maximum quality for these subgroups and I've also done the same for X and X2X3.",
            "Flip found another maximum quality for the subgroups in this branch.",
            "Then they can use these two values and one M2 to calculate and you bound.",
            "On the quality of all subgroups below the.",
            "Constraint X in X one X3.",
            "And the reason is that XX.",
            "One X3 is.",
            "Obviously related to XX1X2 and X and X2X3 because it's the union of these two intervals and.",
            "Actually, it is possible to calculate a new bound and this bound can be titled in the Bound.",
            "Then I can obtain if I use optimistic estimates at this node.",
            "So it's possible to prune a larger number of branches using this new estimate based on the best qualities in the two different.",
            "Branches."
        ],
        [
            "And this bound is simply the sum of the two.",
            "Maximum value so.",
            "Here's a lemma which makes it a bit more precise, but here I have an image which cell which I hope can illustrate the bound if I have a.",
            "Condition X is in.",
            "This time I have used threshold left threshold rides, then the best quality below this or in this branch is bound by the some of the best quality below the branch X&T left T. And X&TG right for arbitrary tease between the left and the right.",
            "And this gives me the possibility to find a new tighter bound.",
            "Ends well.",
            "It's interesting to note that this is also possible if I use depth limit, so I don't search the whole space of possible subgroup descriptions, but only to a fixed maximum level.",
            "And it also holds if I don't consider arbitrary tests.",
            "But if I consider, let's say, a particular set of split points, which could be determined by frequency discretization or something like that."
        ],
        [
            "OK, and then what's interesting also is that this can very well be combined with standard optimistic estimates.",
            "So for example, if I find the maximum quality in this branch.",
            "And I find or I use an optimistic estimate for everything below this branch.",
            "Then I can also take the maximum of.",
            "Some of this bound and the value I found here to calculate a new bound for all the subgroups below that node.",
            "So I don't have to explicitly search this whole space and this whole space to maybe find a new bound for this branch.",
            "But instead it's can be sufficient to exhaustively search 1 branch using optimistic estimate for another branch.",
            "OK, and.",
            "This can allow me to find a new bound which would will allow me to prune the branch which would not be possible if I would use standard optimistic estim."
        ],
        [
            "It's.",
            "So well, this pruning ideas still foundational basis for a new subgroup Discovery algorithm, which we have developed and the idea is roughly the following.",
            "We do depth first search in the space of subgroup descriptions as just illustrated.",
            "Use optimistic estimates to get the first bound for different refinements or for different branches, and then later on whenever I find a new found using exhaustive search or something like that, I update.",
            "The bounds of all intervals, super intervals of the interval.",
            "I consider it might sound a bit complicated, but for example, if I find exhaustively search everything below X one X2, then I can update X1 extreme X1 X 4X1X.",
            "And."
        ],
        [
            "OK, and that was the idea of the algorithm.",
            "Just like to present a bit of well experimental results.",
            "Here we have two datasets where we did not use exhaustively every possible.",
            "Intervals, but instead used a discretization with 10 bins.",
            "And consider the number of nodes which have to be considered.",
            "It cannot be proved for different depth limits, so if we use no problem at all, we get some kind of exponential increase in number of nodes.",
            "This is a scale.",
            "Then if we use standard optimistic estimates, we don't have to consider that much.",
            "We get the red line.",
            "So we can pull in large numbers of nodes be considered, but if we Additionally use this new pooling scheme, we can prove much more.",
            "And what's really interesting here is that while optimistic estimate starts to have an effect at depth level 2, this new pruning has already in effect at step Level 1."
        ],
        [
            "Well.",
            "Here also a few runtime results.",
            "It always depends on the number of spit points that one considers if one exhaust and scores on the data set.",
            "If one considers exhaustive search, then one can get speedups of thousands or more and.",
            "If the number of split points decreases, of course the performance gain becomes smaller."
        ],
        [
            "Well, so basically that's it.",
            "The summary is I wanted to explain where why in numerical domains there might be problems or there are problems sometimes with standard approaches.",
            "In the present new pruning scheme which.",
            "Allows to speed up the computation in many cases.",
            "Of course, there are a lot of open issues.",
            "Which we may be or which we plan to address in future work.",
            "So thank you very much.",
            "For this charge, yeah.",
            "To Georgia.",
            "Interesting subgroups as well.",
            "Yeah, yeah exactly right.",
            "Hi.",
            "Lightly used intervals over your American means.",
            "Basically, that's actually my view to refinements here.",
            "Yeah, good.",
            "At this point, whether you can still use your trade, I think you should still be able to use it, but.",
            "You would probably use it in two different steps.",
            "First, you would have a bound from above and then from below and then East of these two search levels.",
            "Also you could do the same thing, but it's more efficient, I think to do it in one step, but you're right, you could instead of using intervals, use inequality constraints.",
            "But still you could use the same pruning trick.",
            "So here you have evaluated your system in terms of efficiency.",
            "Yeah, but what about the quality of subgroups?",
            "Yeah, you're right.",
            "At the beginning I had a few.",
            "Figures about that.",
            "That's the quality of the best subgroups, and we discover in this way, and the gain is not very impressive in quality.",
            "But still we get a better quality for the best subgroup.",
            "Then, if we would use, for example, entropy discretization, I know it's would probably you have to look at the individual pattern to say how bad or how.",
            "Good it is to have this increase, but in any case the quality increases of the subgroups.",
            "Individual subgroups, yes yes, actually at the best subgroup.",
            "Do this kind of evaluation over several domains.",
            "Yeah, I completed.",
            "We have a few model means.",
            "I just have two.",
            "Images here and now.",
            "You are working with bins, combining them together into intervals.",
            "Yes, maybe some other set up.",
            "Well, there are a lot of possibilities.",
            "I mean you can do it exhaustively.",
            "If the number of the data set is not too large to find the optimal solution, but sometimes that doesn't work because the runtime becomes too high and then we use bins in TTS.",
            "Could also be good idea to use entropy discretization, which often also gets good results, but you're not guaranteed to get the best result that way.",
            "Be interesting to compare.",
            "Yeah, OK, thank you very much, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so hello everybody.",
                    "label": 0
                },
                {
                    "sent": "My talk is about subgroup discovery in the miracle domains and this is joint work with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ungrouping.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Is a brief overview over the talk.",
                    "label": 0
                },
                {
                    "sent": "First, I briefly describe the task of subgroup discovery.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk about problems that arise if subgroup discovery is done in numerical domains.",
                    "label": 1
                },
                {
                    "sent": "The raft I will present new pruning scheme to improve the performance of subgroup discovery in such domains and present an algorithm based on this routing scheme and present some impact.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Empirical results.",
                    "label": 0
                },
                {
                    "sent": "So first subgroup discovering what is this task?",
                    "label": 0
                },
                {
                    "sent": "It's a local pattern discovery task and the idea is to find in a population some parts of the populations or.",
                    "label": 1
                },
                {
                    "sent": "I better say to find a description of parts of the population which differ from the overall population and are as large as possible.",
                    "label": 0
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "I have a data set or here's a data set with some employee data.",
                    "label": 1
                },
                {
                    "sent": "And there is one attribute.",
                    "label": 0
                },
                {
                    "sent": "The so called class attribute which describes the stress level of the employees.",
                    "label": 0
                },
                {
                    "sent": "And the employees are also described by two other attributes which say what profession do they have and what is their gender.",
                    "label": 0
                },
                {
                    "sent": "And so subgroup discovery would look for example for employees or group of people with a high stress level.",
                    "label": 0
                },
                {
                    "sent": "And that could be for example, a description like the professionals feature and the general sexes male.",
                    "label": 0
                },
                {
                    "sent": "So this description would select the 1st and the last row.",
                    "label": 0
                },
                {
                    "sent": "They both have a high stress level and sense they are they differ from the overall.",
                    "label": 1
                },
                {
                    "sent": "Population so formally subgroup description is a conjunction of attribute value pairs.",
                    "label": 0
                },
                {
                    "sent": "Like profession, this teacher and there's a relation between subgroups discovery and other tasks.",
                    "label": 0
                },
                {
                    "sent": "In particular rule discovery tasks, because this can be interpreted as a kind of.",
                    "label": 0
                },
                {
                    "sent": "Rule which says that under certain conditions the.",
                    "label": 0
                },
                {
                    "sent": "Target attribute of the class has a particular value, so subgroup discovery is closely related with other tasks, like also contrast set mining and.",
                    "label": 0
                },
                {
                    "sent": "Correlated itemset mining.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One thing which is really important subgroup discovery or probably general in local pattern discovery is what is the quality of a subgroup or the pattern in general, and in this work we consider quality functions of the following structure.",
                    "label": 1
                },
                {
                    "sent": "So basically you take the size of the subgroup extension to the power of constant A.",
                    "label": 0
                },
                {
                    "sent": "And multiply it with the difference between the share in the subgroup and the share and the overall population.",
                    "label": 0
                },
                {
                    "sent": "So in the case of this example description, here we have.",
                    "label": 0
                },
                {
                    "sent": "2 examples in this data set.",
                    "label": 0
                },
                {
                    "sent": "The 1st and the last one, so the size is 2 and is multiplied with the target share in the subgroup, which is 100% because in the first and last row we have a high stress level minus the overall share of high stress level which is.",
                    "label": 0
                },
                {
                    "sent": "4 out of 6.",
                    "label": 0
                },
                {
                    "sent": "And as I just said, A is constant and defending depending on the value of that constant, this quality function is all equivalent to.",
                    "label": 0
                },
                {
                    "sent": "A few very well known quality functions like the Jeffrey Schapiro or weighted relative currency.",
                    "label": 0
                },
                {
                    "sent": "Quality function alter the normal test.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quality function so that was about subgroup discovery in general.",
                    "label": 1
                },
                {
                    "sent": "Now in many domains, the attributes which described.",
                    "label": 1
                },
                {
                    "sent": "Records all the entities of interests are not nominal, but instead numerical or ordinal.",
                    "label": 1
                },
                {
                    "sent": "So for example, if we have a medical data set and we are looking for.",
                    "label": 0
                },
                {
                    "sent": "Persons which have sudden vascular disease then the attributes are likely to be something like the blood pressure which is in the miracle value on the body mass index or the age and so on and so.",
                    "label": 0
                },
                {
                    "sent": "In this case, we probably don't want to have attributes, value pairs or conjunction of attribute value pairs, because these would select only very small subset of the population.",
                    "label": 0
                },
                {
                    "sent": "But instead we would prefer to have attribute interval tests.",
                    "label": 0
                },
                {
                    "sent": "So we would like to have more defined subgroups like.",
                    "label": 0
                },
                {
                    "sent": "Maybe the body mass index if it is large between 26 and 30 and we have these three rows and Additionally the.",
                    "label": 0
                },
                {
                    "sent": "Blood blood pressure is high.",
                    "label": 0
                },
                {
                    "sent": "Then we have a very high risk for the disease, first and last.",
                    "label": 0
                },
                {
                    "sent": "Record again.",
                    "label": 0
                },
                {
                    "sent": "Now that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can we deal with subgroup discovery in numerical domains and 1st?",
                    "label": 1
                },
                {
                    "sent": "I want to present.",
                    "label": 0
                },
                {
                    "sent": "Or to describe some problems which arise if one simply uses or simply, if one uses the standard approach, nominal, subgroup, discovery and 1st use the discretization step.",
                    "label": 0
                },
                {
                    "sent": "Typically we would probably use entropy discretization and replace every numerical attribute by a nominal attribute.",
                    "label": 1
                },
                {
                    "sent": "And to illustrate the problem here, well, graphical representation of the data set which has two describing attributes, the X value and the Y value, and these values of these attributes takes.",
                    "label": 0
                },
                {
                    "sent": "Values between one and six in this example for both X&Y and the points here, shall describe different records and the records with a kind of a plus positive records and the points are simply negative records.",
                    "label": 0
                },
                {
                    "sent": "So what we are looking for here is a description of a subgroup which has a lot of pluses.",
                    "label": 0
                },
                {
                    "sent": "I know this is an artificial intelligent.",
                    "label": 0
                },
                {
                    "sent": "Example, but still it should probably help to lose traits.",
                    "label": 0
                },
                {
                    "sent": "The task we want to solve.",
                    "label": 0
                },
                {
                    "sent": "The problems will arise.",
                    "label": 0
                },
                {
                    "sent": "So what we want to have is for example this subgroup here, which only includes positive examples or this subgroup here and we don't have 1/2 of the subgroups.",
                    "label": 0
                },
                {
                    "sent": "But if we would use entropy discretization then every.",
                    "label": 0
                },
                {
                    "sent": "Attribute basically would be replaced by a new nominal attribute.",
                    "label": 0
                },
                {
                    "sent": "And the set of split points in case of entropy discretization would be the green lines and the blue lines.",
                    "label": 0
                },
                {
                    "sent": "So we would have a new domain, say for the.",
                    "label": 0
                },
                {
                    "sent": "Replacement for this attribute.",
                    "label": 0
                },
                {
                    "sent": "New attributes prime with values 1234 and five, 6 and the problem now is that.",
                    "label": 0
                },
                {
                    "sent": "If we stick to the standard.",
                    "label": 0
                },
                {
                    "sent": "Definitional approach which finds conjunction of attribute value pairs.",
                    "label": 0
                },
                {
                    "sent": "Then we cannot find description of this subgroup here simply because.",
                    "label": 0
                },
                {
                    "sent": "The values for the new discretized X IS123 four or five 6, so it's possible to express a subgroup like X as in 1, two and wise and 1 two.",
                    "label": 0
                },
                {
                    "sent": "But it's not possible to say X as in 124.",
                    "label": 0
                },
                {
                    "sent": "Simply because we have new non overlapping intervals as.",
                    "label": 0
                },
                {
                    "sent": "Normal values for the new attribute.",
                    "label": 0
                },
                {
                    "sent": "So well, you have a problem here.",
                    "label": 0
                },
                {
                    "sent": "And of course it might be or is a good idea.",
                    "label": 0
                },
                {
                    "sent": "And a solution to.",
                    "label": 0
                },
                {
                    "sent": "In some way use overlapping intervals.",
                    "label": 0
                },
                {
                    "sent": "So to have the possibility to express it, something ranges between.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Four and one way to do this technically is to use a set of binary two valued attributes.",
                    "label": 1
                },
                {
                    "sent": "But at least if this is combined with entropy discretization, there are still many cases where we will not find the optimal solution.",
                    "label": 0
                },
                {
                    "sent": "Here's another data set, and again, I think you can see that this up we want to find this one.",
                    "label": 0
                },
                {
                    "sent": "But if we apply entropy discretization, then attribute Y is divided into 3 intervals, which is nice, but the interval X if we use entropy discretization will simply result in.",
                    "label": 0
                },
                {
                    "sent": "Well would be removed basically.",
                    "label": 0
                },
                {
                    "sent": "Because there are no obvious split points because the distribution on this X is on the X axis is uniformly in every.",
                    "label": 0
                },
                {
                    "sent": "In every column you can see that there is exactly 1/3 of the examples are positive, so there is no obvious split point.",
                    "label": 0
                },
                {
                    "sent": "And well, it's.",
                    "label": 0
                },
                {
                    "sent": "The problem which occurs will find something like that a subgroup description, but this is not what we intended to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Define well.",
                    "label": 0
                },
                {
                    "sent": "Cause an obvious question is, is this purely artificial this example or can it also can this kind of problems also occur in real world datasets and to well, get an idea if this is the case, not we?",
                    "label": 0
                },
                {
                    "sent": "Use different strategies for discretization on datasets from the UCI repository and for example here on the right we have used data set.",
                    "label": 0
                },
                {
                    "sent": "And the red curve is the quality of the best subgroup that one can find if one uses arbitrary intervals overlapping intervals.",
                    "label": 1
                },
                {
                    "sent": "And the different other lines show the quality.",
                    "label": 0
                },
                {
                    "sent": "Further have set this X axis shows the maximum length of the subgroup descriptions.",
                    "label": 0
                },
                {
                    "sent": "But what I want to say is that if one users, for example frequency discretization and one gets really bad subgroups if one uses entropy, the subgroup descriptions have a higher quality, but they are still far away from the best solution that we would like to find and the blue line here is again overlapping intervals, but using frequency discretization to avoid the problem illustrated in this image that entropy discretization will simply find.",
                    "label": 0
                },
                {
                    "sent": "Note spit point when considering a single.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under Merrick attribute so.",
                    "label": 0
                },
                {
                    "sent": "All this motivation was to show you that in general, if we want to find optimal solutions, we first have to look at overlapping intervals, and it's not possible to.",
                    "label": 1
                },
                {
                    "sent": "So in general it's not possible to use something like entropy discretization because the quality of the subgroups.",
                    "label": 0
                },
                {
                    "sent": "Will not be optimal, so we have to well look at a lot of different attribute interval.",
                    "label": 0
                },
                {
                    "sent": "Constraints and the question is, is it possible to somehow speed up the computation then?",
                    "label": 0
                },
                {
                    "sent": "Because of course the search space becomes real.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Large in this case.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We haven't.",
                    "label": 0
                },
                {
                    "sent": "I would present a new pruning approach in this case, and the first thing I'd like to do is to show how subgroup discovery is realized in practice or in most algorithms it's realized as a kind of search.",
                    "label": 0
                },
                {
                    "sent": "Many algorithms kind of search in the space of subgroup descriptions, so we have different levels in the sense that we start with subgroup descriptions with length 0, so empty description.",
                    "label": 1
                },
                {
                    "sent": "Then we have descriptions of length one, length two, and so on and on this.",
                    "label": 0
                },
                {
                    "sent": "First level there are subscriptions which involve a test or constraint on the X.",
                    "label": 0
                },
                {
                    "sent": "Attribute this is just an example with two attributes.",
                    "label": 1
                },
                {
                    "sent": "Then we have constraints based on 2nd attribute Y and then next level.",
                    "label": 0
                },
                {
                    "sent": "We have constraints which range over both.",
                    "label": 0
                },
                {
                    "sent": "Attributes and this is meant to be to be read like that.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have a constraint Y is in Y1Y2.",
                    "label": 0
                },
                {
                    "sent": "And Additionally, it's constrained to be an X one X3, so this is a conjunction of two.",
                    "label": 0
                },
                {
                    "sent": "Constraints.",
                    "label": 0
                },
                {
                    "sent": "And the question now is, can we somehow search this space without having to explicitly consider every node to do?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much pruning as possible.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "First, I'd like to show you what standard approaches exist to speed up the computation or to speed up the discovery of subgroups once then approaches to use optimistic estimates.",
                    "label": 0
                },
                {
                    "sent": "I'm too optimistic estimate pruning and the idea is basically if I consider a certain node during for example depth or search.",
                    "label": 1
                },
                {
                    "sent": "I calculate an optimistic estimate which is a bound on the value of all subgroup descriptions below that node.",
                    "label": 1
                },
                {
                    "sent": "So it's a bound on the quality of all descriptions in the branch below that node.",
                    "label": 0
                },
                {
                    "sent": "And if this optimistic estimated I obtain is below a certain threshold.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should say something with the threshold there are different ways to state the exact problem.",
                    "label": 0
                },
                {
                    "sent": "If for example, I'm looking for the best subgroup description, then I would during the search adaptive threshold because I would only be interested in subgroups which are better than the subgroup I already considered.",
                    "label": 0
                },
                {
                    "sent": "So optimistic estimate pruning can allow to prune some parts of the search space and, well, it's fine that reduces the search space, but.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In numerical domains, we can do more and the idea is the following.",
                    "label": 0
                },
                {
                    "sent": "We can do some kind of well, maybe it's could be called something like horizontal pruning.",
                    "label": 0
                },
                {
                    "sent": "The idea is to if I have.",
                    "label": 0
                },
                {
                    "sent": "Considered all subgroups below condition, like X as in X one X2 is 1 and thanks to our thresholds here.",
                    "label": 0
                },
                {
                    "sent": "So I have looked at all subgroups in this branch and calculates the maximum quality for these subgroups and I've also done the same for X and X2X3.",
                    "label": 0
                },
                {
                    "sent": "Flip found another maximum quality for the subgroups in this branch.",
                    "label": 0
                },
                {
                    "sent": "Then they can use these two values and one M2 to calculate and you bound.",
                    "label": 0
                },
                {
                    "sent": "On the quality of all subgroups below the.",
                    "label": 0
                },
                {
                    "sent": "Constraint X in X one X3.",
                    "label": 0
                },
                {
                    "sent": "And the reason is that XX.",
                    "label": 0
                },
                {
                    "sent": "One X3 is.",
                    "label": 0
                },
                {
                    "sent": "Obviously related to XX1X2 and X and X2X3 because it's the union of these two intervals and.",
                    "label": 0
                },
                {
                    "sent": "Actually, it is possible to calculate a new bound and this bound can be titled in the Bound.",
                    "label": 0
                },
                {
                    "sent": "Then I can obtain if I use optimistic estimates at this node.",
                    "label": 0
                },
                {
                    "sent": "So it's possible to prune a larger number of branches using this new estimate based on the best qualities in the two different.",
                    "label": 0
                },
                {
                    "sent": "Branches.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this bound is simply the sum of the two.",
                    "label": 1
                },
                {
                    "sent": "Maximum value so.",
                    "label": 0
                },
                {
                    "sent": "Here's a lemma which makes it a bit more precise, but here I have an image which cell which I hope can illustrate the bound if I have a.",
                    "label": 0
                },
                {
                    "sent": "Condition X is in.",
                    "label": 0
                },
                {
                    "sent": "This time I have used threshold left threshold rides, then the best quality below this or in this branch is bound by the some of the best quality below the branch X&T left T. And X&TG right for arbitrary tease between the left and the right.",
                    "label": 1
                },
                {
                    "sent": "And this gives me the possibility to find a new tighter bound.",
                    "label": 0
                },
                {
                    "sent": "Ends well.",
                    "label": 1
                },
                {
                    "sent": "It's interesting to note that this is also possible if I use depth limit, so I don't search the whole space of possible subgroup descriptions, but only to a fixed maximum level.",
                    "label": 0
                },
                {
                    "sent": "And it also holds if I don't consider arbitrary tests.",
                    "label": 0
                },
                {
                    "sent": "But if I consider, let's say, a particular set of split points, which could be determined by frequency discretization or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then what's interesting also is that this can very well be combined with standard optimistic estimates.",
                    "label": 0
                },
                {
                    "sent": "So for example, if I find the maximum quality in this branch.",
                    "label": 0
                },
                {
                    "sent": "And I find or I use an optimistic estimate for everything below this branch.",
                    "label": 0
                },
                {
                    "sent": "Then I can also take the maximum of.",
                    "label": 0
                },
                {
                    "sent": "Some of this bound and the value I found here to calculate a new bound for all the subgroups below that node.",
                    "label": 0
                },
                {
                    "sent": "So I don't have to explicitly search this whole space and this whole space to maybe find a new bound for this branch.",
                    "label": 0
                },
                {
                    "sent": "But instead it's can be sufficient to exhaustively search 1 branch using optimistic estimate for another branch.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "This can allow me to find a new bound which would will allow me to prune the branch which would not be possible if I would use standard optimistic estim.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "So well, this pruning ideas still foundational basis for a new subgroup Discovery algorithm, which we have developed and the idea is roughly the following.",
                    "label": 0
                },
                {
                    "sent": "We do depth first search in the space of subgroup descriptions as just illustrated.",
                    "label": 1
                },
                {
                    "sent": "Use optimistic estimates to get the first bound for different refinements or for different branches, and then later on whenever I find a new found using exhaustive search or something like that, I update.",
                    "label": 0
                },
                {
                    "sent": "The bounds of all intervals, super intervals of the interval.",
                    "label": 0
                },
                {
                    "sent": "I consider it might sound a bit complicated, but for example, if I find exhaustively search everything below X one X2, then I can update X1 extreme X1 X 4X1X.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and that was the idea of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Just like to present a bit of well experimental results.",
                    "label": 0
                },
                {
                    "sent": "Here we have two datasets where we did not use exhaustively every possible.",
                    "label": 0
                },
                {
                    "sent": "Intervals, but instead used a discretization with 10 bins.",
                    "label": 1
                },
                {
                    "sent": "And consider the number of nodes which have to be considered.",
                    "label": 0
                },
                {
                    "sent": "It cannot be proved for different depth limits, so if we use no problem at all, we get some kind of exponential increase in number of nodes.",
                    "label": 0
                },
                {
                    "sent": "This is a scale.",
                    "label": 0
                },
                {
                    "sent": "Then if we use standard optimistic estimates, we don't have to consider that much.",
                    "label": 0
                },
                {
                    "sent": "We get the red line.",
                    "label": 0
                },
                {
                    "sent": "So we can pull in large numbers of nodes be considered, but if we Additionally use this new pooling scheme, we can prove much more.",
                    "label": 0
                },
                {
                    "sent": "And what's really interesting here is that while optimistic estimate starts to have an effect at depth level 2, this new pruning has already in effect at step Level 1.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Here also a few runtime results.",
                    "label": 0
                },
                {
                    "sent": "It always depends on the number of spit points that one considers if one exhaust and scores on the data set.",
                    "label": 0
                },
                {
                    "sent": "If one considers exhaustive search, then one can get speedups of thousands or more and.",
                    "label": 0
                },
                {
                    "sent": "If the number of split points decreases, of course the performance gain becomes smaller.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, so basically that's it.",
                    "label": 0
                },
                {
                    "sent": "The summary is I wanted to explain where why in numerical domains there might be problems or there are problems sometimes with standard approaches.",
                    "label": 0
                },
                {
                    "sent": "In the present new pruning scheme which.",
                    "label": 1
                },
                {
                    "sent": "Allows to speed up the computation in many cases.",
                    "label": 1
                },
                {
                    "sent": "Of course, there are a lot of open issues.",
                    "label": 0
                },
                {
                    "sent": "Which we may be or which we plan to address in future work.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much.",
                    "label": 1
                },
                {
                    "sent": "For this charge, yeah.",
                    "label": 0
                },
                {
                    "sent": "To Georgia.",
                    "label": 0
                },
                {
                    "sent": "Interesting subgroups as well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah exactly right.",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "Lightly used intervals over your American means.",
                    "label": 0
                },
                {
                    "sent": "Basically, that's actually my view to refinements here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, good.",
                    "label": 0
                },
                {
                    "sent": "At this point, whether you can still use your trade, I think you should still be able to use it, but.",
                    "label": 0
                },
                {
                    "sent": "You would probably use it in two different steps.",
                    "label": 0
                },
                {
                    "sent": "First, you would have a bound from above and then from below and then East of these two search levels.",
                    "label": 0
                },
                {
                    "sent": "Also you could do the same thing, but it's more efficient, I think to do it in one step, but you're right, you could instead of using intervals, use inequality constraints.",
                    "label": 0
                },
                {
                    "sent": "But still you could use the same pruning trick.",
                    "label": 1
                },
                {
                    "sent": "So here you have evaluated your system in terms of efficiency.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but what about the quality of subgroups?",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're right.",
                    "label": 0
                },
                {
                    "sent": "At the beginning I had a few.",
                    "label": 0
                },
                {
                    "sent": "Figures about that.",
                    "label": 1
                },
                {
                    "sent": "That's the quality of the best subgroups, and we discover in this way, and the gain is not very impressive in quality.",
                    "label": 0
                },
                {
                    "sent": "But still we get a better quality for the best subgroup.",
                    "label": 0
                },
                {
                    "sent": "Then, if we would use, for example, entropy discretization, I know it's would probably you have to look at the individual pattern to say how bad or how.",
                    "label": 0
                },
                {
                    "sent": "Good it is to have this increase, but in any case the quality increases of the subgroups.",
                    "label": 0
                },
                {
                    "sent": "Individual subgroups, yes yes, actually at the best subgroup.",
                    "label": 0
                },
                {
                    "sent": "Do this kind of evaluation over several domains.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I completed.",
                    "label": 0
                },
                {
                    "sent": "We have a few model means.",
                    "label": 0
                },
                {
                    "sent": "I just have two.",
                    "label": 0
                },
                {
                    "sent": "Images here and now.",
                    "label": 0
                },
                {
                    "sent": "You are working with bins, combining them together into intervals.",
                    "label": 0
                },
                {
                    "sent": "Yes, maybe some other set up.",
                    "label": 0
                },
                {
                    "sent": "Well, there are a lot of possibilities.",
                    "label": 0
                },
                {
                    "sent": "I mean you can do it exhaustively.",
                    "label": 0
                },
                {
                    "sent": "If the number of the data set is not too large to find the optimal solution, but sometimes that doesn't work because the runtime becomes too high and then we use bins in TTS.",
                    "label": 0
                },
                {
                    "sent": "Could also be good idea to use entropy discretization, which often also gets good results, but you're not guaranteed to get the best result that way.",
                    "label": 0
                },
                {
                    "sent": "Be interesting to compare.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, thank you very much, thank you.",
                    "label": 0
                }
            ]
        }
    }
}