{
    "id": "6kbwzlb4hvl6vnqsmdqs2nkgctgjlcwh",
    "title": "Fine-grained Evaluation of Rule- and Embedding-based Systems for Knowledge Graph Completion",
    "info": {
        "author": [
            "Manuel Fink, University of Mannheim"
        ],
        "published": "Nov. 22, 2018",
        "recorded": "October 2018",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2018_fink_fine_grained_completion/",
    "segmentation": [
        [
            "Hello everybody and thank you for the kind introduction in this talk.",
            "I will present some of our contributions in the field of knowledge graph completion so."
        ],
        [
            "We will focus only on RDF data datasets, so if you visualize them.",
            "What you would end up is actually something like Knowledge Graph which you can see here on these slides and in that case knowledge graph completion is actually the task of finding missing links which correspond to actual correct knowledge in the world, which is for some reason missing in the graph.",
            "So it might be missing the cause.",
            "The data source from which the graph has been generated was incomplete, or maybe the method we used to generate it was not 100% accurate, and for such a reason there is some information which should be in the graph, but it isn't.",
            "And the goal is in that case to predict and find this knowledge by learning from the patterns which are in the data that we actually have."
        ],
        [
            "So we focused on the two approaches, which I think the most common ones how to tackle this problem, the first one being the symbolic approach, which is making use of explicit knowledge about the entities in the graph which we try to make predictions for.",
            "So a lot of times these mechanisms of making predictions can be formalized as a rule.",
            "So for instance, if you take a look at this example, we can see that producer of Terminator is James Cameron, and we know that the sequel of Terminator.",
            "Two, and so we can say we're pretty confident that again, the produce of Terminator two is going to be changed Cameron.",
            "So that would be one kind of rule you could use."
        ],
        [
            "And on the other hand side, we have latent approaches which actually are a lot of times or what we focus on our geometrical embeddings of the knowledge graph in a lower dimensional vector space.",
            "So in this example I gave an example for the system trancy with dimension 2, and if we try to embed the graph from the previous slides, we might actually end up with something that looks like this.",
            "So we have coordinates for every entity, which is the embedding of the entities and we have vectors which are D embeddings of the relations.",
            "And if we want to make a prediction, for example, who is the producer of Terminator two, what we would do with transients?",
            "We would add this mixture to the coordinates of Terminator two.",
            "We would end up at this blue location an we would look at the distance of the entities to this location in the craft and we would see that James Cameron is actually the best fit because it has the closest distance to this point, and so we would end up with a ranking with the scores being the distances in this case.",
            "And we can use this to make predictions."
        ],
        [
            "Now, what's interesting is if you take a look at the evaluation state of the field over like half decade, and you will find that there's plenty of systems which essentially participated in this race to get better on primarily two datasets, which is the word net 18 data set, and the Freebase 15K data set.",
            "And you see there's plenty of systems beating each other by half and percent by 1%, going better and better, and actually a lot of these systems are embedding based systems.",
            "But what is lacking here is kind of a baseline where you can actually intuitively understand its performance and charge the other systems in relation to it.",
            "And we think a rule based system would actually be a good candidate for this, because you can look at the rules as a human and you can understand these rules and see why is this system coming to its predictions and what kind of stuff can it predict?",
            "What can't it be?",
            "And so we went ahead and we."
        ],
        [
            "Developed a new rule based system specific specifically for this task.",
            "We don't claim that it's the newest, most innovative system.",
            "In fact, it has a lot of similarities to existing rule systems like peer A or me plus, but we called it rule for the fact that we claim it's a bit more naive than these approaches, so the language bias of our system has two templates for rules, the first one being path rules.",
            "You can see the abstract form here.",
            "It's actually.",
            "A closed and connected Horn rule will get to see an example in a second, and it's much more clear and the second template is constant rules.",
            "Which you can also see here.",
            "If we take a look at an example we already."
        ],
        [
            "Side on the previous slide, so a path two rule, which means the body of the rule consists of two predicates.",
            "Could actually look like this, saying that movies producers the same as it's equals producer and constant rule, for example, could be something like if something speaks a language, then it's English.",
            "Now obviously that rule is not true because not everyone speaks English and that's why we."
        ],
        [
            "Some confidence confidence is attached to these rules.",
            "So for example, we could say maybe in six."
        ],
        [
            "4% of the cases.",
            "If someone speaks something, then it's English and likewise for the other rule."
        ],
        [
            "Now our system learns rules by making use of sampling in two different ways.",
            "1st Way we try to discover potential rules which might be interesting and we do this by doing random walks, just as PRA has already done that.",
            "Let me visualize that a bit.",
            "Let's say we're interested in learning a rule to predict links for the relation has actor."
        ],
        [
            "So what we do is we sample some node pairs in the graph which are connected with a relation has actor.",
            "So for instance Terminator two and Arnold Schwarzenegger.",
            "I heard you guys love him, so I picked that example and then we go."
        ],
        [
            "Go ahead and we try to find alternative paths going from the source node to the target node in the graph, so the blue path here would be a potential body for rule and we get this rule from it, but there's more paths.",
            "You can also go with location to California and from California you can go the governor relation to Arnold Schwarzenegger and that would actually give you a second rule, and so we end up with two different rules after."
        ],
        [
            "The sampling process may be an.",
            "Now we need to calculate the confidence of these rules, and again we use sampling because it can be quite costly to calculate the exact confidences and we do this by essentially looking for."
        ],
        [
            "The bodies grounded in the knowledge graph.",
            "So for instance we look for prequel and his actor for this path and we find it's the one again where we found the rule with and we can see in all cases of these paths of these path acquiring the knowledge Graph, the head relation is actually true, so it would get a confidence of 1.0 in this case.",
            "On the other hand, if we go for location governor we can find two of these paths in the Knowledge Graph."
        ],
        [
            "On weakling right now, where we see we actually have a has actor relationship going from source to target, but for the other one weekly.",
            "Now we see that that has actual link is missing, and so it would only have a confidence of 0.5.",
            "And if we actually"
        ],
        [
            "Rendered with a lot of more examples, we would maybe end up with constant confidences like this, which would tell us that the second rule is actually nonsense, but the other one can be used for quite a lot of cases to predict the actor of a movie, maybe.",
            "So."
        ],
        [
            "So the challenge now is not to come up with an algorithm on how to apply these rules.",
            "That's straightforward.",
            "It's absolutely clear if you deal with this stuff, But the problem is, what do you do if you have multiple rules making a prediction for the same candidate?",
            "Because intuitively it should count more if you have two rules predicting a candidate, then you have one, but on the other hand you have this confidence is and that complicates things because it's unclear what you do if you have two rules predicting something each with confidence 0.5.",
            "Is that more powerful than having one rule predicting with zero Point 6 maybe?",
            "And that is the hard problem you have when you do prediction with rule systems.",
            "So what we did in our case, we settled for a very robust and straightforward thing, and that is, we just say the score of a candidate is given by the most confident rule that predicted this candidate, and only when there is a tie we break the tie by looking at the number of rules that predicted a specific candidate.",
            "And so."
        ],
        [
            "Let's see where we end up with this approach.",
            "You can see that in this table, ruhlen is actually think the best performing system, or at least it's in a in an area with its performance where you could say it's competitive to the latest embedding systems.",
            "But that is not true completely, because that's a bit of an older table from 2017, but still nowadays there systems that are even more performing than rule, and so it's not.",
            "In any case the best system, but it's I think interesting how far you can already go.",
            "With the rule system, a system where you can still interpret the result and understand why it came to its conclusions.",
            "So we think that's quite valuable to have it there as a baseline for further references."
        ],
        [
            "But we did another contribution, and in fact we leveraged our rule system with its explanatory features.",
            "What we did is we partitioned the test set because we wanted to understand which kind of test cases are hard to solve, which ones are easy and what do you need to solve them.",
            "So we went ahead and we took the rule and rules which generated on the datasets that had a confidence of at least 0.5 and then we went ahead and we identified for each test case.",
            "The rule with the highest confidence that actually predicts the missing entity.",
            "And so."
        ],
        [
            "What you end up with if you do this for example on Freebase 15 K looks kind of like this.",
            "So you see the three left columns, they're all path one rule, so the most simple rules, so to say.",
            "Well, then we also have path 2 rules and then we have an uncovered category.",
            "So we further split the path 1 rules into three different things, first one being symmetry.",
            "So you can say for example if why is appear of X, then you know that also X is appear.",
            "Why it's just a symmetrical relationship?",
            "Then you have something like equivalence.",
            "You can say that if X is of category Y, then you also know that X is the topic of Y, and I'm not going to read out every rule here, but you see some examples for every category.",
            "What's noteworthy is that only 14% of the test cases require more complicated rules than path tool for freeways 15K, and it's not necessarily the case that you can't solve it with a path one or two rule, but.",
            "They can still be connected with one or two hops in the data set in the training set, but the rules that you would need they would not have a confidence higher than 0.5, so we thought it would be unfair to say you can solve it with this and that's why we said it's uncovered.",
            "Of course, this 0.5 is a bit arbitrary, but we settled for that."
        ],
        [
            "Now, if you look again at the evaluation, you can do it more fingrid cause for every category you can assess the performance of the different models.",
            "So we went ahead and we took another rule system which is Amy on top of Lennon.",
            "We also took three embedding systems, not necessarily the most state of the art ones, but pretty common ones.",
            "Holy Race, Kaylan Trancy, and we did a fine grade evaluation and what's interesting first of all, if you look at the hits at one score, you can see that the rule based systems actually pretty confident.",
            "When they make a prediction on rank one, it's usually the correct one."
        ],
        [
            "But the embedding systems are quite bad at the hips at one, so it's actually most of the cases the wrong, wrong answer, and this is especially surprising on easy task.",
            "For example on symmetrical ones or the equivalent category or the subsumption category for which the rule based systems are actually able with the precision of at least 90 or no."
        ],
        [
            "80 Three point 1% in case of subsumption too.",
            "Only need one guest to get the right candidate.",
            "So I'm not saying here that embedding systems don't work.",
            "In fact they are.",
            "They can do things that rule based systems can't.",
            "And later on we'll see.",
            "We'll see that in the in the results we present, but we thought it would be interesting to not only look at the performance of systems of different methods, but to combine them, and I think this is not something we alone came up with it.",
            "I think that's the more recent trend to combine these systems, but we thought again, let's take a very similar."
        ],
        [
            "Roach and what we do is we do a stacking or sample of five different systems to rule based systems Amy and Roulin and three latent models.",
            "Trancy Holien re scale and what we do is we train them completely independent from each other.",
            "We also do the prediction completely independent of each other.",
            "They don't know that they will be part of Windows or Samba when they do predictions and then we train a log linear regression model to combine the score functions and non functions.",
            "But the scores that are given for.",
            "Candidates by these systems and what you end up."
        ],
        [
            "With is an ensemble that on data set like Freebase 237, which is a much harder Ironton Freebase 15K is actually beating all single systems and it's not only beating them but you can see that the performance gain is a huge jump.",
            "In fact if you look at the individual systems you can see that on hits at 10 which is the most common metric people evaluate on.",
            "Those five individual systems are actually quite in the same range, so you could maybe think that they solve the same kind of tasks well.",
            "But if you look at the assembly approach, you see that it's jumping alot in performance, indicating that it's actually not the case.",
            "They are good at the same easy test cases and that in fact they compliment each other and we think it's the case that some tasks are quite easy.",
            "You can solve them, or maybe some tasks of specific relations.",
            "Are very easy to solve with rule based systems.",
            "For example, if there's a symmetrical rule for the relation.",
            "But rule based systems fail in some cases, for example when the graph is very sparse or when it's tough to find path 2 rules or something and longer rules are very hard to mine computationally, and in those cases you can still make predictions with the latent models, and so that's the reason why they actually complement each other and we see that in the latest contributions to the field.",
            "The trend is actually going towards combining both symbolic features and latent features, which I think is a good way and we hope we can further fortify this.",
            "This way of tackling the problem with our contribution, and with that I thank you for your attention and I'm open for questions."
        ],
        [
            "So thank you, not very interesting talk.",
            "Let's see questions.",
            "You can see any.",
            "Well maybe I can start making a question.",
            "It seems that by looking at the results if if.",
            "If if the link is is is, is can be predicted by the rules.",
            "The rules do a really good job at that and they they created very well.",
            "On the other hand, or there are situations where using the bands can also help, so I'm wondering in what sense?",
            "Does this depend on their specific data set?",
            "An if you have more or less like topology of a different types of data sets that could benefit more from one approach from the other from December.",
            "Yeah, what I can tell you is for example it in fact depends very much so on the data set.",
            "For example, on Wordnet you can see that.",
            "That the rule based systems are actually quite strong because it's a data set where you have a lot of hierarchy in it, so any system that learns rules that can predict these hierarchies, for example, which words are hypernyms of others.",
            "That is very easy for rule based system, while on other datasets like Freebase it's actually a bit harder and I think.",
            "One way you could use the rule systems is to solve the easy tasks and then what's left.",
            "Maybe the latent models could be used for and they would actually be much stronger in that case.",
            "But it also depends on if you can learn very long rules or not on a data set.",
            "So we saw that on word.",
            "Net you can actually go as far as learning rules of length 5 for the body and on Freebase it's much harder to learn longer rules and I think we only got 2 length four and for example Amy which is a much more complete system which tries all different rules in the language bias.",
            "I had, I think length two only on Freebase and length 3 on word net.",
            "So you quickly run into.",
            "Situation where it's tough to learn interesting rules, and if that's the case, then the rule systems fail horribly and the latent ones play the advantage because they can still make predictions in that case.",
            "But I think with a sampling approach like ours, even if the data set grows, you can still find rules with the high confidence because they should be quite common in the data set.",
            "And even if you only do assembling, you should be able to find them so that kind of makes that disadvantage a bit less.",
            "Compared to a complete system search, OK Thanks.",
            "So in the mean time.",
            "So.",
            "Hello, great doc, do you do you have any comparison of the performance like how long it takes to learn the views?",
            "For instance?",
            "I mean there's around there too.",
            "Computing them the embedding so the computational costs.",
            "Yeah, I think the part that takes the longest and embedding systems unfortunately more on the rule side is the hyper primary data search.",
            "So if you have the hyperparameters, then the running times are actually quite compareable.",
            "But if you take into account that the embedding systems need that search and the rule systems do not because we just always take the most.",
            "Liberal settings we can still run in a given time, then the rule based systems are in fact much faster.",
            "For example, in Freebase the learning took around 40 minutes I think, and the application of the rules another 20 minutes.",
            "And for the embedding based systems they were more like on half a day or day.",
            "OK, maybe this time for another quick question over there.",
            "We have Michael and Mike in there in the room.",
            "If you have chain rules like only then you mentioned that this is hard to learn like.",
            "Chains of like 5 atoms, but if you chain like several rules of like with two atoms then it would be the same outcome, right?",
            "Or but you have to take into account that the things you predict with shorter rules is not necessarily knowledge that you're very confident in.",
            "So if you have a rule with like 99 percentage then that's actually possible to 1st apply this and then use another rule on top of what it predicted.",
            "But in often in a lot of cases those rules don't have such high confidence.",
            "So you basically you propagate errors.",
            "The more often you apply your rules to get basically longer rules.",
            "But in theory yes, you can emulate longer rules by applying shorter rules that make up this body of the longer rule.",
            "OK, thank you.",
            "Thank you very much.",
            "I think we don't have more time for questions.",
            "Thanks again.",
            "Once again, the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody and thank you for the kind introduction in this talk.",
                    "label": 0
                },
                {
                    "sent": "I will present some of our contributions in the field of knowledge graph completion so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will focus only on RDF data datasets, so if you visualize them.",
                    "label": 0
                },
                {
                    "sent": "What you would end up is actually something like Knowledge Graph which you can see here on these slides and in that case knowledge graph completion is actually the task of finding missing links which correspond to actual correct knowledge in the world, which is for some reason missing in the graph.",
                    "label": 0
                },
                {
                    "sent": "So it might be missing the cause.",
                    "label": 0
                },
                {
                    "sent": "The data source from which the graph has been generated was incomplete, or maybe the method we used to generate it was not 100% accurate, and for such a reason there is some information which should be in the graph, but it isn't.",
                    "label": 0
                },
                {
                    "sent": "And the goal is in that case to predict and find this knowledge by learning from the patterns which are in the data that we actually have.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we focused on the two approaches, which I think the most common ones how to tackle this problem, the first one being the symbolic approach, which is making use of explicit knowledge about the entities in the graph which we try to make predictions for.",
                    "label": 0
                },
                {
                    "sent": "So a lot of times these mechanisms of making predictions can be formalized as a rule.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you take a look at this example, we can see that producer of Terminator is James Cameron, and we know that the sequel of Terminator.",
                    "label": 0
                },
                {
                    "sent": "Two, and so we can say we're pretty confident that again, the produce of Terminator two is going to be changed Cameron.",
                    "label": 0
                },
                {
                    "sent": "So that would be one kind of rule you could use.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And on the other hand side, we have latent approaches which actually are a lot of times or what we focus on our geometrical embeddings of the knowledge graph in a lower dimensional vector space.",
                    "label": 0
                },
                {
                    "sent": "So in this example I gave an example for the system trancy with dimension 2, and if we try to embed the graph from the previous slides, we might actually end up with something that looks like this.",
                    "label": 0
                },
                {
                    "sent": "So we have coordinates for every entity, which is the embedding of the entities and we have vectors which are D embeddings of the relations.",
                    "label": 0
                },
                {
                    "sent": "And if we want to make a prediction, for example, who is the producer of Terminator two, what we would do with transients?",
                    "label": 1
                },
                {
                    "sent": "We would add this mixture to the coordinates of Terminator two.",
                    "label": 0
                },
                {
                    "sent": "We would end up at this blue location an we would look at the distance of the entities to this location in the craft and we would see that James Cameron is actually the best fit because it has the closest distance to this point, and so we would end up with a ranking with the scores being the distances in this case.",
                    "label": 0
                },
                {
                    "sent": "And we can use this to make predictions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, what's interesting is if you take a look at the evaluation state of the field over like half decade, and you will find that there's plenty of systems which essentially participated in this race to get better on primarily two datasets, which is the word net 18 data set, and the Freebase 15K data set.",
                    "label": 0
                },
                {
                    "sent": "And you see there's plenty of systems beating each other by half and percent by 1%, going better and better, and actually a lot of these systems are embedding based systems.",
                    "label": 0
                },
                {
                    "sent": "But what is lacking here is kind of a baseline where you can actually intuitively understand its performance and charge the other systems in relation to it.",
                    "label": 0
                },
                {
                    "sent": "And we think a rule based system would actually be a good candidate for this, because you can look at the rules as a human and you can understand these rules and see why is this system coming to its predictions and what kind of stuff can it predict?",
                    "label": 0
                },
                {
                    "sent": "What can't it be?",
                    "label": 0
                },
                {
                    "sent": "And so we went ahead and we.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Developed a new rule based system specific specifically for this task.",
                    "label": 0
                },
                {
                    "sent": "We don't claim that it's the newest, most innovative system.",
                    "label": 0
                },
                {
                    "sent": "In fact, it has a lot of similarities to existing rule systems like peer A or me plus, but we called it rule for the fact that we claim it's a bit more naive than these approaches, so the language bias of our system has two templates for rules, the first one being path rules.",
                    "label": 1
                },
                {
                    "sent": "You can see the abstract form here.",
                    "label": 0
                },
                {
                    "sent": "It's actually.",
                    "label": 0
                },
                {
                    "sent": "A closed and connected Horn rule will get to see an example in a second, and it's much more clear and the second template is constant rules.",
                    "label": 0
                },
                {
                    "sent": "Which you can also see here.",
                    "label": 0
                },
                {
                    "sent": "If we take a look at an example we already.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Side on the previous slide, so a path two rule, which means the body of the rule consists of two predicates.",
                    "label": 0
                },
                {
                    "sent": "Could actually look like this, saying that movies producers the same as it's equals producer and constant rule, for example, could be something like if something speaks a language, then it's English.",
                    "label": 1
                },
                {
                    "sent": "Now obviously that rule is not true because not everyone speaks English and that's why we.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some confidence confidence is attached to these rules.",
                    "label": 0
                },
                {
                    "sent": "So for example, we could say maybe in six.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "4% of the cases.",
                    "label": 0
                },
                {
                    "sent": "If someone speaks something, then it's English and likewise for the other rule.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now our system learns rules by making use of sampling in two different ways.",
                    "label": 0
                },
                {
                    "sent": "1st Way we try to discover potential rules which might be interesting and we do this by doing random walks, just as PRA has already done that.",
                    "label": 0
                },
                {
                    "sent": "Let me visualize that a bit.",
                    "label": 0
                },
                {
                    "sent": "Let's say we're interested in learning a rule to predict links for the relation has actor.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we do is we sample some node pairs in the graph which are connected with a relation has actor.",
                    "label": 0
                },
                {
                    "sent": "So for instance Terminator two and Arnold Schwarzenegger.",
                    "label": 1
                },
                {
                    "sent": "I heard you guys love him, so I picked that example and then we go.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go ahead and we try to find alternative paths going from the source node to the target node in the graph, so the blue path here would be a potential body for rule and we get this rule from it, but there's more paths.",
                    "label": 0
                },
                {
                    "sent": "You can also go with location to California and from California you can go the governor relation to Arnold Schwarzenegger and that would actually give you a second rule, and so we end up with two different rules after.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The sampling process may be an.",
                    "label": 0
                },
                {
                    "sent": "Now we need to calculate the confidence of these rules, and again we use sampling because it can be quite costly to calculate the exact confidences and we do this by essentially looking for.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The bodies grounded in the knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So for instance we look for prequel and his actor for this path and we find it's the one again where we found the rule with and we can see in all cases of these paths of these path acquiring the knowledge Graph, the head relation is actually true, so it would get a confidence of 1.0 in this case.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if we go for location governor we can find two of these paths in the Knowledge Graph.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On weakling right now, where we see we actually have a has actor relationship going from source to target, but for the other one weekly.",
                    "label": 0
                },
                {
                    "sent": "Now we see that that has actual link is missing, and so it would only have a confidence of 0.5.",
                    "label": 0
                },
                {
                    "sent": "And if we actually",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rendered with a lot of more examples, we would maybe end up with constant confidences like this, which would tell us that the second rule is actually nonsense, but the other one can be used for quite a lot of cases to predict the actor of a movie, maybe.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the challenge now is not to come up with an algorithm on how to apply these rules.",
                    "label": 1
                },
                {
                    "sent": "That's straightforward.",
                    "label": 0
                },
                {
                    "sent": "It's absolutely clear if you deal with this stuff, But the problem is, what do you do if you have multiple rules making a prediction for the same candidate?",
                    "label": 1
                },
                {
                    "sent": "Because intuitively it should count more if you have two rules predicting a candidate, then you have one, but on the other hand you have this confidence is and that complicates things because it's unclear what you do if you have two rules predicting something each with confidence 0.5.",
                    "label": 0
                },
                {
                    "sent": "Is that more powerful than having one rule predicting with zero Point 6 maybe?",
                    "label": 0
                },
                {
                    "sent": "And that is the hard problem you have when you do prediction with rule systems.",
                    "label": 0
                },
                {
                    "sent": "So what we did in our case, we settled for a very robust and straightforward thing, and that is, we just say the score of a candidate is given by the most confident rule that predicted this candidate, and only when there is a tie we break the tie by looking at the number of rules that predicted a specific candidate.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see where we end up with this approach.",
                    "label": 0
                },
                {
                    "sent": "You can see that in this table, ruhlen is actually think the best performing system, or at least it's in a in an area with its performance where you could say it's competitive to the latest embedding systems.",
                    "label": 0
                },
                {
                    "sent": "But that is not true completely, because that's a bit of an older table from 2017, but still nowadays there systems that are even more performing than rule, and so it's not.",
                    "label": 0
                },
                {
                    "sent": "In any case the best system, but it's I think interesting how far you can already go.",
                    "label": 0
                },
                {
                    "sent": "With the rule system, a system where you can still interpret the result and understand why it came to its conclusions.",
                    "label": 0
                },
                {
                    "sent": "So we think that's quite valuable to have it there as a baseline for further references.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we did another contribution, and in fact we leveraged our rule system with its explanatory features.",
                    "label": 0
                },
                {
                    "sent": "What we did is we partitioned the test set because we wanted to understand which kind of test cases are hard to solve, which ones are easy and what do you need to solve them.",
                    "label": 0
                },
                {
                    "sent": "So we went ahead and we took the rule and rules which generated on the datasets that had a confidence of at least 0.5 and then we went ahead and we identified for each test case.",
                    "label": 0
                },
                {
                    "sent": "The rule with the highest confidence that actually predicts the missing entity.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you end up with if you do this for example on Freebase 15 K looks kind of like this.",
                    "label": 0
                },
                {
                    "sent": "So you see the three left columns, they're all path one rule, so the most simple rules, so to say.",
                    "label": 0
                },
                {
                    "sent": "Well, then we also have path 2 rules and then we have an uncovered category.",
                    "label": 0
                },
                {
                    "sent": "So we further split the path 1 rules into three different things, first one being symmetry.",
                    "label": 0
                },
                {
                    "sent": "So you can say for example if why is appear of X, then you know that also X is appear.",
                    "label": 0
                },
                {
                    "sent": "Why it's just a symmetrical relationship?",
                    "label": 0
                },
                {
                    "sent": "Then you have something like equivalence.",
                    "label": 0
                },
                {
                    "sent": "You can say that if X is of category Y, then you also know that X is the topic of Y, and I'm not going to read out every rule here, but you see some examples for every category.",
                    "label": 0
                },
                {
                    "sent": "What's noteworthy is that only 14% of the test cases require more complicated rules than path tool for freeways 15K, and it's not necessarily the case that you can't solve it with a path one or two rule, but.",
                    "label": 0
                },
                {
                    "sent": "They can still be connected with one or two hops in the data set in the training set, but the rules that you would need they would not have a confidence higher than 0.5, so we thought it would be unfair to say you can solve it with this and that's why we said it's uncovered.",
                    "label": 0
                },
                {
                    "sent": "Of course, this 0.5 is a bit arbitrary, but we settled for that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, if you look again at the evaluation, you can do it more fingrid cause for every category you can assess the performance of the different models.",
                    "label": 0
                },
                {
                    "sent": "So we went ahead and we took another rule system which is Amy on top of Lennon.",
                    "label": 0
                },
                {
                    "sent": "We also took three embedding systems, not necessarily the most state of the art ones, but pretty common ones.",
                    "label": 0
                },
                {
                    "sent": "Holy Race, Kaylan Trancy, and we did a fine grade evaluation and what's interesting first of all, if you look at the hits at one score, you can see that the rule based systems actually pretty confident.",
                    "label": 0
                },
                {
                    "sent": "When they make a prediction on rank one, it's usually the correct one.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the embedding systems are quite bad at the hips at one, so it's actually most of the cases the wrong, wrong answer, and this is especially surprising on easy task.",
                    "label": 0
                },
                {
                    "sent": "For example on symmetrical ones or the equivalent category or the subsumption category for which the rule based systems are actually able with the precision of at least 90 or no.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "80 Three point 1% in case of subsumption too.",
                    "label": 0
                },
                {
                    "sent": "Only need one guest to get the right candidate.",
                    "label": 0
                },
                {
                    "sent": "So I'm not saying here that embedding systems don't work.",
                    "label": 0
                },
                {
                    "sent": "In fact they are.",
                    "label": 0
                },
                {
                    "sent": "They can do things that rule based systems can't.",
                    "label": 0
                },
                {
                    "sent": "And later on we'll see.",
                    "label": 0
                },
                {
                    "sent": "We'll see that in the in the results we present, but we thought it would be interesting to not only look at the performance of systems of different methods, but to combine them, and I think this is not something we alone came up with it.",
                    "label": 0
                },
                {
                    "sent": "I think that's the more recent trend to combine these systems, but we thought again, let's take a very similar.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Roach and what we do is we do a stacking or sample of five different systems to rule based systems Amy and Roulin and three latent models.",
                    "label": 1
                },
                {
                    "sent": "Trancy Holien re scale and what we do is we train them completely independent from each other.",
                    "label": 0
                },
                {
                    "sent": "We also do the prediction completely independent of each other.",
                    "label": 0
                },
                {
                    "sent": "They don't know that they will be part of Windows or Samba when they do predictions and then we train a log linear regression model to combine the score functions and non functions.",
                    "label": 0
                },
                {
                    "sent": "But the scores that are given for.",
                    "label": 0
                },
                {
                    "sent": "Candidates by these systems and what you end up.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With is an ensemble that on data set like Freebase 237, which is a much harder Ironton Freebase 15K is actually beating all single systems and it's not only beating them but you can see that the performance gain is a huge jump.",
                    "label": 0
                },
                {
                    "sent": "In fact if you look at the individual systems you can see that on hits at 10 which is the most common metric people evaluate on.",
                    "label": 0
                },
                {
                    "sent": "Those five individual systems are actually quite in the same range, so you could maybe think that they solve the same kind of tasks well.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the assembly approach, you see that it's jumping alot in performance, indicating that it's actually not the case.",
                    "label": 0
                },
                {
                    "sent": "They are good at the same easy test cases and that in fact they compliment each other and we think it's the case that some tasks are quite easy.",
                    "label": 0
                },
                {
                    "sent": "You can solve them, or maybe some tasks of specific relations.",
                    "label": 0
                },
                {
                    "sent": "Are very easy to solve with rule based systems.",
                    "label": 0
                },
                {
                    "sent": "For example, if there's a symmetrical rule for the relation.",
                    "label": 0
                },
                {
                    "sent": "But rule based systems fail in some cases, for example when the graph is very sparse or when it's tough to find path 2 rules or something and longer rules are very hard to mine computationally, and in those cases you can still make predictions with the latent models, and so that's the reason why they actually complement each other and we see that in the latest contributions to the field.",
                    "label": 0
                },
                {
                    "sent": "The trend is actually going towards combining both symbolic features and latent features, which I think is a good way and we hope we can further fortify this.",
                    "label": 0
                },
                {
                    "sent": "This way of tackling the problem with our contribution, and with that I thank you for your attention and I'm open for questions.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you, not very interesting talk.",
                    "label": 0
                },
                {
                    "sent": "Let's see questions.",
                    "label": 0
                },
                {
                    "sent": "You can see any.",
                    "label": 0
                },
                {
                    "sent": "Well maybe I can start making a question.",
                    "label": 0
                },
                {
                    "sent": "It seems that by looking at the results if if.",
                    "label": 0
                },
                {
                    "sent": "If if the link is is is, is can be predicted by the rules.",
                    "label": 0
                },
                {
                    "sent": "The rules do a really good job at that and they they created very well.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, or there are situations where using the bands can also help, so I'm wondering in what sense?",
                    "label": 0
                },
                {
                    "sent": "Does this depend on their specific data set?",
                    "label": 0
                },
                {
                    "sent": "An if you have more or less like topology of a different types of data sets that could benefit more from one approach from the other from December.",
                    "label": 0
                },
                {
                    "sent": "Yeah, what I can tell you is for example it in fact depends very much so on the data set.",
                    "label": 0
                },
                {
                    "sent": "For example, on Wordnet you can see that.",
                    "label": 0
                },
                {
                    "sent": "That the rule based systems are actually quite strong because it's a data set where you have a lot of hierarchy in it, so any system that learns rules that can predict these hierarchies, for example, which words are hypernyms of others.",
                    "label": 0
                },
                {
                    "sent": "That is very easy for rule based system, while on other datasets like Freebase it's actually a bit harder and I think.",
                    "label": 0
                },
                {
                    "sent": "One way you could use the rule systems is to solve the easy tasks and then what's left.",
                    "label": 0
                },
                {
                    "sent": "Maybe the latent models could be used for and they would actually be much stronger in that case.",
                    "label": 0
                },
                {
                    "sent": "But it also depends on if you can learn very long rules or not on a data set.",
                    "label": 0
                },
                {
                    "sent": "So we saw that on word.",
                    "label": 0
                },
                {
                    "sent": "Net you can actually go as far as learning rules of length 5 for the body and on Freebase it's much harder to learn longer rules and I think we only got 2 length four and for example Amy which is a much more complete system which tries all different rules in the language bias.",
                    "label": 0
                },
                {
                    "sent": "I had, I think length two only on Freebase and length 3 on word net.",
                    "label": 0
                },
                {
                    "sent": "So you quickly run into.",
                    "label": 0
                },
                {
                    "sent": "Situation where it's tough to learn interesting rules, and if that's the case, then the rule systems fail horribly and the latent ones play the advantage because they can still make predictions in that case.",
                    "label": 0
                },
                {
                    "sent": "But I think with a sampling approach like ours, even if the data set grows, you can still find rules with the high confidence because they should be quite common in the data set.",
                    "label": 0
                },
                {
                    "sent": "And even if you only do assembling, you should be able to find them so that kind of makes that disadvantage a bit less.",
                    "label": 0
                },
                {
                    "sent": "Compared to a complete system search, OK Thanks.",
                    "label": 0
                },
                {
                    "sent": "So in the mean time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Hello, great doc, do you do you have any comparison of the performance like how long it takes to learn the views?",
                    "label": 0
                },
                {
                    "sent": "For instance?",
                    "label": 0
                },
                {
                    "sent": "I mean there's around there too.",
                    "label": 0
                },
                {
                    "sent": "Computing them the embedding so the computational costs.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think the part that takes the longest and embedding systems unfortunately more on the rule side is the hyper primary data search.",
                    "label": 0
                },
                {
                    "sent": "So if you have the hyperparameters, then the running times are actually quite compareable.",
                    "label": 0
                },
                {
                    "sent": "But if you take into account that the embedding systems need that search and the rule systems do not because we just always take the most.",
                    "label": 0
                },
                {
                    "sent": "Liberal settings we can still run in a given time, then the rule based systems are in fact much faster.",
                    "label": 0
                },
                {
                    "sent": "For example, in Freebase the learning took around 40 minutes I think, and the application of the rules another 20 minutes.",
                    "label": 0
                },
                {
                    "sent": "And for the embedding based systems they were more like on half a day or day.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe this time for another quick question over there.",
                    "label": 0
                },
                {
                    "sent": "We have Michael and Mike in there in the room.",
                    "label": 0
                },
                {
                    "sent": "If you have chain rules like only then you mentioned that this is hard to learn like.",
                    "label": 0
                },
                {
                    "sent": "Chains of like 5 atoms, but if you chain like several rules of like with two atoms then it would be the same outcome, right?",
                    "label": 0
                },
                {
                    "sent": "Or but you have to take into account that the things you predict with shorter rules is not necessarily knowledge that you're very confident in.",
                    "label": 0
                },
                {
                    "sent": "So if you have a rule with like 99 percentage then that's actually possible to 1st apply this and then use another rule on top of what it predicted.",
                    "label": 0
                },
                {
                    "sent": "But in often in a lot of cases those rules don't have such high confidence.",
                    "label": 0
                },
                {
                    "sent": "So you basically you propagate errors.",
                    "label": 0
                },
                {
                    "sent": "The more often you apply your rules to get basically longer rules.",
                    "label": 0
                },
                {
                    "sent": "But in theory yes, you can emulate longer rules by applying shorter rules that make up this body of the longer rule.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "I think we don't have more time for questions.",
                    "label": 0
                },
                {
                    "sent": "Thanks again.",
                    "label": 0
                },
                {
                    "sent": "Once again, the speaker.",
                    "label": 0
                }
            ]
        }
    }
}