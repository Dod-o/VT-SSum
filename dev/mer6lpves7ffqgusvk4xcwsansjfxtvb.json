{
    "id": "mer6lpves7ffqgusvk4xcwsansjfxtvb",
    "title": "Approximate Bayesian computation (ABC): advances and questions",
    "info": {
        "author": [
            "Christian P. Robert, Paris Dauphine University"
        ],
        "introducer": [
            "Peter Mueller, University of Texas M.D. Anderson Cancer Center, University of Texas at Austin"
        ],
        "recorded by": [
            "Kyoeisha"
        ],
        "published": "Aug. 22, 2012",
        "recorded": "June 2012",
        "category": [
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/isba2012_robert_bayesian_computation/",
    "segmentation": [
        [
            "It's a wonderful honor to introduce our next is my lecture by Chrystia Robbia, who is one of the massive contributors to MCMC, and among many other things, has written a wonderful book deviation choice.",
            "One of the few.",
            "Technical statistics books that are actually really a pleasure to read.",
            "I really enjoyed it.",
            "But somehow off lately he has abandoned the exact and beautiful things and he starts to do things approximately and he's going to tell us about this approximate Bayesian computation.",
            "the ABC advances in questions please Christian.",
            "OK Peter, thank you for this approximative introduction.",
            "First, I want to thank the organizers for giving me this opportunity to talk about ABC.",
            "It's a bit of paradoxical that it comes in a in a beige and foundation.",
            "Session in the sense that it's.",
            "On the approximately beige and so, it cannot be truly foundational, but actually, I mean further, probably this topic, because this is my current area of interest.",
            "But also I think they when I was trying to prepare those slides from previous lectures.",
            "I thought that there could be something slightly deeper than just being approximated.",
            "The sense that.",
            "To link with Mike's talk.",
            "As we are facing harder and harder problems, larger and larger datasets.",
            "It gets it's getting harder and harder to stick with Z traditional model that is completely defined that we know from from A-Z except for the parameter and therefore dealing with approximate models or approximate misses.",
            "Maybe a vision of the future and not only side occupation for earth visions."
        ],
        [
            "The first thing is this happens at like the worst of times in that my principle author George.",
            "Died last week, so I'd like to dedicate this talk to his memory and mention that on Wednesday we're having a memorial session at lunch break too, which of course everyone is welcome.",
            "To participate in an and talk stories about Jordan is is wonderful personality."
        ],
        [
            "Um?",
            "Now.",
            "This.",
            "This talk tries to avoid too much technical stuff about computations, an rather trying to focus on the thing I mentioned at the beginning, namely, said.",
            "This this could be a different perspective on.",
            "A new type of inference machine, so I mean I'm not trying to to be to oversell the method, as is drawbacks and and I mentioned that them doing the top but at the same time it allows to process at a reasonable cost, harder problems than found previously.",
            "I get treated that."
        ],
        [
            "Yeah.",
            "OK, so.",
            "I just give a few words of introductions, then describe what is ABC and then on the last part fully reaching there.",
            "I'll link ABC with inference.",
            "And what I mean by that."
        ],
        [
            "OK, so.",
            "To motivate ABC, let us start with the basics.",
            "We have a vision problem of inference.",
            "In, for instance, we want to compute an integral that is related to the to the posterior, and we can compute this integral.",
            "OK, so there's the usual stuff."
        ],
        [
            "And therefore we process the issue by producing a sample from this posterior an using the basic Monte Carlo approximation that has all the standard properties if.",
            "The function we want to integrate is regular enough so that."
        ],
        [
            "Does the stuff of course.",
            "To do that, we need to prove to provide this sample from the posterior, and this is often impossible or very inefficient if we don't know how to simulate efficiently from."
        ],
        [
            "Dispatcher, and therefore there are many ways of getting around out an one that.",
            "Has been around for as many years as Monte Carlo actually is important.",
            "Sampling where instead of assuming from the posterior, you take a proxy that is density Q and simulating from his density you re Express a problem that's pretty integrals against these."
        ],
        [
            "Density, and therefore if we can produce a sample from this important sampling density.",
            "Given that we are free to choose it.",
            "Then we can provide an approximation to the integral by re expressing this integral as as this expectation."
        ],
        [
            "Again there for exactly the same reason we have the same convergence properties."
        ],
        [
            "Now of course, to do that, we need to be able to compute \u03c0 / Q An in most Asian problems we don't know Pi exactly because we are missing the normalizing constant and this is not such."
        ],
        [
            "A big deal because.",
            "We can estimate the constants for the same price for the same cost and divide this average by the average of the weights and again."
        ],
        [
            "We get the same type of results of low fresh numbers and central limit theorems.",
            "But"
        ],
        [
            "This again imposes some constraints on the problem, namely that pie at least should be known up to a constant.",
            "An when \u03c0 is not available up to a constant, we are suddenly facing a problem of a much higher difficulty and to some extent problem that sounds unfeasible in the most realistic situations.",
            "And so this will lead to the introduction of ABC."
        ],
        [
            "Anne again.",
            "We can see things from different perspectives.",
            "Either we are dealing with a mere computational problem and mirrors to be put between quotes, but because it's a computer problem, the core of our job is not is not affected.",
            "An we can hope that better computer or better method will appear an and solve a problem.",
            "That's the optimistic side as a pessimistic, pessimistic side is that we may have to wait too long for this solution now."
        ],
        [
            "There are other ways of looking at the problem, namely that."
        ],
        [
            "The very nature of of the model, the fact that it is not a tractable model in the sense of providing.",
            "A closed form density or computable density?",
            "Pushes for different inferential approaches.",
            "And to to leave the standard version.",
            "Path for different inferential approach that, if you're optimistic, can be repatriated within the vision.",
            "Real an if you're pessimistic that is incorrect because it's not exactly basean.",
            "An A middle ground is to see that to say that we may still be visions, but we're dealing with different types of estimators and methodologies, and again, the bright side is that because it's still within the Bayesian approach, it's it's valid in an incoherent an if you're not that optimistic, it may lead to cases where it is not clear and because for instance.",
            "It's not convergent.",
            "Now do."
        ],
        [
            "Just.",
            "A side issue that actually relates to to ABC, and that's more like an historical background on the issue.",
            "There are a lot of connections with the introduction of ABC between the intuition of ABC and some solutions that have been developed in econometrics.",
            "Anne.",
            "In a sense, we're not always paying enough attention to what's going on econometrics.",
            "Although I mean the two foods are statistics in a metrics are close enough.",
            "What happened in the in the past 15?",
            "Yours at least.",
            "There have been ways to deal with complex econometric models that prefigured ABC.",
            "An related simulation based techniques, and so I will just mention a few here in case you have not seen them and if you have in case you have seen them to make the link with ABC."
        ],
        [
            "So for his simulated method of moments is.",
            "Such that because you cannot compute a likelihood, for instance, you produce pseudo estimations through observations from your shoe model, reads a given value of the parameter sitter.",
            "Ann, you try to fit the best see to in terms of the simulated data when compared with the original data.",
            "YOT so that's one approach.",
            "Given that it it depends.",
            "A little too much on on the series and so it looks at the difference between each term of the series and not."
        ],
        [
            "It is just to look at one statistic based on the series and for instance to take the average of the observations minus the average of the simulation observations.",
            "And if you know already ABC, you can see that there is a perfect link there."
        ],
        [
            "And then a bit broader and more ambitious is a method of simulated moments to distinguish it from the simulated method of moments.",
            "That goes a bit further and uses first a statistic K for which we can find an unbiased estimator of its expectation and compare what you observe The Cave YT again with a simulated version that may be repeated in order to reduce the Monte Carlo variation.",
            "And this distance is is.",
            "Arbitrary, but we again pick a parameter sitter that tries to bring what we observe.",
            "Through some prism through some change of perspective, because K is only a statistic is not the whole vector an an approximation based on a knowledge of the method?"
        ],
        [
            "And then comes up.",
            "I think the most interesting of the group, which is the indirect inference approach.",
            "That was introduced by Google at all, namely that.",
            "They go even farther from the assumption they have on the model by using estimators.",
            "That rely on a pseudo model that is not necessarily true, but.",
            "Using the model behind the picture behind the scene.",
            "They try to find the parameter seater that brings this estimator of the wrong model as close as possible to an estimator based on absolute data.",
            "Using the true model.",
            "Later it sounds quite convoluted, but it allows for.",
            "Processing situations where the true model is truly a complex thing where all you can do about it.",
            "The knowledge you can use from it is only simulating absolute data now."
        ],
        [
            "There are again many ways of implementing this principle.",
            "There are many choices to calibrate the method.",
            "For instance, our once you'd pick up pseudo model you can use.",
            "Directories are maximum likelihood estimator for subsidy model.",
            "That assume action will actually matter and from there compare your bit ahead as you observations with bit ahead at a sample of pseudo observations."
        ],
        [
            "Or else in the study related where you can use the score vector in the same perspective.",
            "Now."
        ],
        [
            "Does it work well?",
            "If you look at."
        ],
        [
            "The creators of the method grew and more for.",
            "They are rather vague about the cases where it where it works, but there's this interesting sentence that we will find again in ABC, namely that of course beta must contain enough information to recover the perimeter sitter and so in a sense within.",
            "This construct Cedar must be the equivalent of identifiable.",
            "And then they get to this interesting sentence that we will recover later.",
            "Maybe that the best case.",
            "If I interpret their words, the best case is when the parameter.",
            "Sierra is just identify, namely when the pseudo model is parameterized in the sparsest possible way, not to induce extra dimensions that would slow down convergence.",
            "An lead to more inefficiency.",
            "So that's an interesting feature of indirect inference."
        ],
        [
            "Of course, there is a lot of arbitrariness.",
            "The justification in the economic literature is justification of consistency and convergence of those estimators at a given speed.",
            "So we cannot recover much for our problems with a given sample size.",
            "That there is an interesting follow-up to the indirect inference paper biography.",
            "Jesse, an England.",
            "And in Genesis B in 2004, where they try to have a more practical evaluation of the method by comparing choices of pseudo models, an of estimators in.",
            "Variety of situations and they came with the conclusion that Beta had had to be dependent on Cedar.",
            "So in subsequent terms, if you pick an ancillary statistic is not going to help very much, which makes sense.",
            "But at the same time, once you get in formation about see that.",
            "That is when Peter had varies.",
            "When Cedar varies, you must have.",
            "As concentration as possible in the distribution of bit ahead of Cedar, which again makes sense because the more concentrated it is, the easier it is to get in to get the relevant information about the parameter sitter.",
            "There will be a talk.",
            "In one of the ABC sessions about the use of indirect inference in connection with ABC by Chris to Randy."
        ],
        [
            "Now, another approach that I put under the head of econometrics, although its role in that is empirical likelihood, an originally it's not a method that is directly related with simulation, nor is ABC that I will make the link in a minute break likelihood is another way to process complex models where you don't want to make.",
            "All the assumptions you need to to create a complete model.",
            "Instead you introduce a parameter that is your parameter of interest.",
            "An link with this parameter you define expectations that define the parameter.",
            "So essentially you introduce a parameter that either defines moments or behaviors of the data that are of interest to you, and you create a function of the data and of these parameters so that you get a pivotal quantity HY insita.",
            "That was expectation at Cedar is 0, so francita is the mean of the wise.",
            "You just get E of Ybor Majesty to equal to 0 and based on this definition of the model, which is not a mobile, just a collection of features about your problem, you define the empirical likelihood by.",
            "Well, you start from the beginning that puts weight 1 / N to each point in your sample and you start twisting the weights so that the constraint is fulfilled, is satisfied, and so you must get some of the PIHYI see to to be equal 0, which is a translation of this.",
            "Of these constraints, OK, and this is not new.",
            "This is due to Auto Berlin in the late 80s.",
            "Any?"
        ],
        [
            "Has not been very much connected with the Bayesian approach.",
            "Although this is coming, and in particular in this meeting there will be an entire session dedicated to empirical likelihood and Bayesian approach.",
            "So I mean, this is an illustration in the case of other mean, you start picking the weights so that the weighted average of the wise is cheetah an optimize the product of the ways to get the largest possible empirical likelihood.",
            "And the more Cedar Father Theater is from the true seed, as the one that corresponds to the data, the harder it is to fit this constraint, and therefore the smaller.",
            "The product."
        ],
        [
            "Now what do the connection we see?",
            "Well, you can starting from this perspective.",
            "Whether the model is totally provided or you only want to make a few assumptions about your model and you don't care about the whole construct, you could create a simulation approach that rely on that by simulating theorize from the prior or from an alternative importance function and then create regular importance weights except that.",
            "You use the empirical likelihood rather than the original likelihood.",
            "Again, whether you can compute it or not, and we played with this notion in a fairly recent paper to try to compare that with more standard ABC, an in both dynamical models and genetic population genetic examples, we found that this was providing much more stable.",
            "Evaluation to the likelihood than the regular ABC, I mean the state of the art ABC."
        ],
        [
            "So why is it ABC in that case?",
            "Well, it's it's approximate, just like this picture that we've done already.",
            "If it's based or not."
        ],
        [
            "It's beige and this we know it's from base.",
            "This is the picture you get in this paper.",
            "It's vision because, well, you see here from the prior, so more vision could be than that."
        ],
        [
            "And it's computationally because you provide a sample that tries to approximate a certain target, as in this example, where it where it works beautifully.",
            "I don't put a picture of the employee."
        ],
        [
            "Doesn't work.",
            "All right now, is it really beige and well?",
            "The only justification for Bill likely would like the whole collection of those economic method I presented is.",
            "That is validated by the sample size growing to Infinity.",
            "So is it really meaningful for us that's debatable?",
            "The second point that for me is more important is that.",
            "We are.",
            "Giving an approximation to the truth.",
            "Whatever is truth is or means.",
            "And the truth is that this approximation is very hard to assess, very tell, so it's this method are good approximations method.",
            "Sometimes they aren't the only way to provide an approximation, but unless you run extensive simulation of magnitude that is higher than the one you need to produce the approximation, you don't already how far you are from the truth, and that's that's a big drawback.",
            "But again.",
            "Insinuating situations like the one we face in property in population genetics.",
            "This may be the only valuable valid sorry implementation, because otherwise we would have to wait weeks or years or we would have to use alternative models that do not provide the same.",
            "Amount of information."
        ],
        [
            "OK, so this was just the introduction, so now I can reach the the ABC per say the genuine ABC.",
            "And I just have."
        ],
        [
            "2 words about the genetic background.",
            "The main reason is I.",
            "Don't want to make a more of a fool of myself by speaking about genetics, so play safe and don't say anything.",
            "The second thing is that form of the talks we would be listening to an user week are connected with genetics, so they will know where to talk about.",
            "So I mean ABC.",
            "The genuine ABC started in practice in population genetics about 15 years ago to deal with.",
            "Genic scenarios relating populations to two common ancestor where people were interested in the parameters driving the divergance."
        ],
        [
            "Between populations, and so there were a few parameters were not talking of big data about Sera.",
            "Sera could be as small as 2 dimensional or 1 dimensional cannot be smaller.",
            "But these parameters were hard to derive because the likely."
        ],
        [
            "Good.",
            "Add a very funny shape that depended on this population tree towards the most common ancestor that was huge and difficult to integrate."
        ],
        [
            "Then and this, this is a kind of example that the people I worked with.",
            "There were analyzing where you had several tribes of Pygmies in Western Africa, an the equation.",
            "The badges were considering, where was about the origin of those pygmy tribes, namely whether whether related together and they issued from a branch from the non pygmy population earlier or the split was more."
        ],
        [
            "Complex and so there are these kind of scenarios where you just have to look at the colors.",
            "These even scenarios they wanted to compare and again the trees as of political structure was interesting, but the actual tree of going to the most common ancestor was not, and so this made difficult problem because the likelihood was not available.",
            "So that's how it started."
        ],
        [
            "That essentially we were in a kind of missing data problem, but there was so much missing data that this integration was not possible or it was only possible in the simplest of cases, and otherwise it would have taken too long to compute."
        ],
        [
            "So we are going back to the same problem, namely that we have.",
            "A likelihood function that in many cases is completely defined.",
            "You know it entirely.",
            "In other cases, as in pre correctly with just know a few features, but essentially you know it entirely.",
            "An you don't know what to do.",
            "Is it because it's computation is impossible and so therefore you cannot do MCMC?",
            "You kind of do important sampling.",
            "You can do any of the regular simulation trick that we are so used to, and so the question is whether we give up.",
            "Any approach with the extension you?",
            "You have to change the model.",
            "It's not like another method is available or you have to settle for a degree of approximation.",
            "Integration is how much approximation is it."
        ],
        [
            "And so, in a sense we have to do.",
            "ABC stands for almost based.",
            "Can you send that?",
            "Is not based almost can, but it's almost base can."
        ],
        [
            "So just."
        ],
        [
            "After such a long wait, you can see what is ABC.",
            "You have a target that you say Asian targets of the prior and likelihood regularly."
        ],
        [
            "It, but you know to define it as a construct.",
            "You can produce simulations from this likelihood.",
            "An the trick is related to this very basic, although essential properties that if you simulate from the prior seater prime then you seem like super data from this Model Z and you wait until Z is equal to Y the observed data.",
            "The time you get out of this loop.",
            "Produces acetyl prime.",
            "That is exactly from the posterior distribution.",
            "That is, it prove just look at the distribution of the Outcoming CR.",
            "It is prior times approval to accept and the pretty accept is F of Y given Sitter, so it's accept reject 101, but it was no tist.",
            "In 19.",
            "1984 by Don Rubin and also in 1984 by Peter Diego and Greater.",
            "In more in a conceptual way, then for the ruins and in a practical way.",
            "But as a representation of what is Apostle distributions, position uses a prior as a prediction of a population.",
            "An.",
            "In that case it waits this simulation by pseudo datasat must mimic the true data and so that is our spirit is quite interesting because it gives a fairly intuitive approach to Bayesian statistics.",
            "But of course in practice it was until 1997.",
            "That it became a fact."
        ],
        [
            "Now, is it practical?",
            "Well, as I wrote, it is not practical, because waiting for ZQ Y means that this is an event that must occur at a human scale, cannot wait billions of years, force equal to Y, and therefore the A in ABC is drifting away from this exact representation of the posterior by allowing for some tolerance around the data.",
            "And so you don't accept only ones equal to Y.",
            "But when Z is close enough to our, namely, one distance between Y&Z or absolute distance is less than a certain absolom and epsilon is tolerance that you are ready to tolerate.",
            "And actually in practice this is the tolerance that you're forced to tolerate.",
            "If you want to solve your problem before."
        ],
        [
            "Retire?",
            "Now, of course, this produces an approximation, and this approximation means that you're not simulating from the true posterior, but from a convolution of this posterior by this tolerance.",
            "And that's the price you have to pay or should pay for."
        ],
        [
            "Calling approximately the problem.",
            "OK, so."
        ],
        [
            "The algorithm just you can write it in a few lines you see made from the data.",
            "This email from there, sorry, you seem so data conditional on this value of the parameter and you wait until ZNY are close enough.",
            "Now there is another degree of approximation that is found in most cases, namely that you cannot wait for the whole data to be close to the hopes of the data and so you force this proximity.",
            "This closeness to occur in a reduced pace through the use of.",
            "Statistics that are called summary statistics, which doesn't mean anything because there are statistics that these Transformers today to the point that they are usually not sufficient, so they are throwing away some part of the information content of the data.",
            "But paradoxically as I will explain in a minute, this is almost necessary to do anything useful with this method, and so the regular ABC algorithm will pick not only a distance and tolerance, but also a summary of the data.",
            "Through this summary statistic eat."
        ],
        [
            "And again, this leads to an."
        ],
        [
            "Optimation of of the posterior.",
            "Because so we get this convolution of the true posterior with the Z.",
            "An the belief is that if epsilon goes to zero, we should get back to this pile of Cedar given one that if we put enough computational effort, we shouldn't be too far from the."
        ],
        [
            "The troops."
        ],
        [
            "OK."
        ],
        [
            "So I'll just skip this slide out.",
            "There are ways of proving that essentially epsilon goes to zero.",
            "You do recover something that is close to the to the posterior, but you have to make some assumptions.",
            "So there are two ways I had to."
        ],
        [
            "Prove that that's not."
        ],
        [
            "Very important because."
        ],
        [
            "Um?"
        ],
        [
            "Actually, it's not, of course always true Ann.",
            "In most cases, because we are using insufficient statistic, we cannot recover."
        ],
        [
            "The true posterior at best.",
            "What we could recover is this pile of Cedar.",
            "Given each of war now.",
            "This is the best we can hope for, but."
        ],
        [
            "If we get to this extreme and caricature case where Eater is on scenery, then we don't recover anything at all.",
            "The best we can hope is a prior.",
            "Thank you Ann.",
            "I made this a typo.",
            "It's part of seats are not part of heater.",
            "So well."
        ],
        [
            "It's not that funny.",
            "Because it seems so.",
            "It's easy to produce this kind of example where actually by using a very heavy machinery you get it with the sample that at the end has not said anything about the information contains data, so convergence is really an issue and not convergence in the synthetic sense, but convergence in the tolerance sense."
        ],
        [
            "So let me show you just well skip this exam."
        ],
        [
            "People."
        ],
        [
            "Let me show you."
        ],
        [
            "An example that is related with Mike talks, although it's a, it's a baby example in the sense that is an MEQ model, so we know to handle MEQ model, but let's look at the output to see the difference between the ABC outcome an are regular MCMC outcome for instance.",
            "So we have an MEQ model where the connection between the data points in the series is through the noise.",
            "And we make a regular uniform assumption on the perimeter CI so that we get this classical identity conditions."
        ],
        [
            "In the case of an enemy to model, we just have a triangle around 04 C to one and see tattoo.",
            "So let's pick uniform prior over that triangle."
        ],
        [
            "OK, now if we want to apply the ABC example algorithm to this example or we have to do is to pick a value of 0102 over this triangle.",
            "That's easy, and then we generate a new series by during a new ID sequence of noises and constructing the series from the conc tattoo and the noises.",
            "Now here comes.",
            "It."
        ],
        [
            "Mission.",
            "Of importance, once we have this pseudo series and we have the original series, how do we compare book series?",
            "So the question is how do we build the distance between the two series?",
            "Well what we saw already in in the simulated method of moments that we could take the basic row difference between the two series, biting the sum of the XT minus X prime tease square.",
            "That's a distance.",
            "If it is zero, the two series are.",
            "Identical.",
            "There is nothing wrong with that.",
            "But that's using a distance between the series that contain a lot of noise in addition to information about the parameters.",
            "So an alternative is to try to reduce the dimension of the problem by looking for any type of estimator.",
            "Our inefficient it is, it doesn't matter.",
            "But reducing dimension as much as possible for foreigners in MA 2 case, we could take the two first autocorrelations and take the distance between those two autocorrelations.",
            "Here we have a distance in the space of dimension T here ever distant in the space of dimension 2.",
            "The summary statistics are not sufficient, so in a sense we're losing information compared with that.",
            "But we will see that politically we're gaining a lot."
        ],
        [
            "Because if we simulate.",
            "ABC in both cases those are the outcomes we get.",
            "If we use the distance between the autocorrelations, we get a quick concentration of the accepted values of C to one and C2 means the triangle is the area of support of the prior.",
            "That's where the model is identifiable and the colors are blue, red and gold.",
            "Or actually corresponding to tolerances of 10 percent, 1% and zero point 1% of the distances.",
            "So it's an empirical choice of the tolerance that is the usual approach in ABC, and it's shrinking towards a point that you actually the Emily in that case, so it's shrinking in a proper region.",
            "Now, if instead I used the whole data to compute the distance.",
            "I guess it's very different picture picture where you still observe a kind of shrinkage from the prior towards the region of interest, where it's much, much slower and therefore to get to region.",
            "And it doesn't exactly the same, but it means that to get to regions that that would come parable in both cases here we would need many many, many more simulations."
        ],
        [
            "And if you look at the posterior marginal posteriors for both approaches, if we use a distance on the road data regards this kind of behavior again when epsilon is going down to zero, we get these three curves from flat to blue to red to gold.",
            "It is very far from the genuine procedure produced by an MCMC sampler.",
            "Same thing for CD2 and the interesting thing is that epsilon is shrinking, although the theory tells us that if there is exactly 0, we should recover the troopers terror with zero point.",
            "1% of the similar distances were still very very far from the true posterior."
        ],
        [
            "If instead we use a distance on the autocorrelations.",
            "Of course, we don't get exactly the triple stare, but we get the picture that is much, much closer to the true posterior.",
            "Granted, that's fairly basic toys."
        ],
        [
            "But we can get some conclusions out of that that will lead to the following points.",
            "1st.",
            "As we said the.",
            "The role of the distance that you should have said the role of the summary statistic.",
            "So we're just projecting first before committing to distance is completely paramount, and the products of this role of the distance is that while the method is justified for absurd, exactly equal to 0, in practice we never get absurd to be exactly 0.",
            "An the the numerical value of epsilon is actually of little importance compared with the space we're working in, so it's only there is a relative value.",
            "There is no absolute.",
            "Excellent in in the real problem, but when we implement the method it starts playing a role that is connected with the distance and the dimension of the problem and this example is a perfect illustration of what has been called the curse of dimensionality for ABC algorithm, namely that if we try too much by comparing the whole data with the hopes your data.",
            "Although as statisticians we would not want to waste any Atom of information.",
            "In that case, the noise created by the simulation of the Salida is killing by orders of magnitude.",
            "The information containing the whole data, and therefore it makes much more sense to 1st project in in a smaller space, accepting that we're losing information.",
            "But then because we're in a much smaller space, epsilon will be closer to 0 in this sense of bring information so that this product that.",
            "We cannot only sing a statisticians when when dealing with this problem, we have to think as as more advanced traditions.",
            "Away from from the true model."
        ],
        [
            "OK, so let me go.",
            "I don't talk about the simulation methods again because there are several talks doing that in the sessions and also because I'm not that much in terms of time."
        ],
        [
            "But"
        ],
        [
            "Some of these?"
        ],
        [
            "Simulation advances are actually more to say about.",
            "Statistical inference than than mere gains in efficiency."
        ],
        [
            "So.",
            "One of the main points I want to stress before moving to the last part.",
            "Is that?",
            "Well, it's clear that the more legitimate interpretation of ABC is not a computational interpretation, but rather a nonparametric interpretation is like umbraco likelihoods, because we don't access, we don't have access to the to the true likelihood where using XO simulation methods to produce approximation to the true likelihood and those approximations can be interpreted as nonparametric.",
            "Interpretation so from the beginning of ABC they were uses of of nonparametric methods specially in this important paper by Mark Como and courses virtually what's more important."
        ],
        [
            "Is that?",
            "One we are using simulations from.",
            "Simsim transforms of the data through this summary statistics were actually trying to get to an approximation of Pi of Cedar given eater of war and being able to simulate this summary statistics is providing this kind of system."
        ],
        [
            "And that's why that's how I made sense for myself, at least of this curve.",
            "For dimensionality, we are dealing with a nonparametric problem and therefore we cannot hope with a given amount of computational power to get good approximation of the whole question distribution of Cedar given the data.",
            "At best we can get a few dimensions because nonparametric estimation gets quickly terrible as a dimension.",
            "Increases."
        ],
        [
            "OK, and so is there a few papers in the recent literatures that explore this direction.",
            "And including Michael Blum will give one of the talks in the ABC sessions."
        ],
        [
            "I won't say too much."
        ],
        [
            "That, but what ABC is doing is using one kernel or another.",
            "The basic kernel is indicator is providing a similar of Pi of Sita given eater of Y using those simulations and therefore that explain."
        ],
        [
            "All the the error can be evaluated, namely that.",
            "The range of the error is for the bias in terms of of bsquare.",
            "If B is deterrence and the variance is 1 / B, Delta D and so the D is, here is an acting upon the violence and there is not much we can do as the increases.",
            "Except seeing their increasing as well.",
            "OK so these are skipped.",
            "So hard to skip MCMC, but I will."
        ],
        [
            "To move to the to the last part.",
            "And to go it's it's more of a video of literature than than anything new, but I'm trying to replace ABC in the inference word rather than the computing world."
        ],
        [
            "Again.",
            "So.",
            "You may have seen this this this slide a few minutes ago.",
            "I'm just repeating the same thing that so far and we cannot get much further than that.",
            "ABC has been justified as a convergent method, or in some cases has been justified as a convergence method.",
            "Are the simulation approximation method.",
            "It requires further simulations too given given iteration of the approximation except when we start looking at the nonparametric perspective, in which case we don't need to run more simulations.",
            "Now while being pragmatic relies on the lots of calibration issues we have to pick the summary statistics and from there we have to pick the distances and also the tolerance.",
            "And in connection with the nonparametric perspective and as stressed in the in the recent Red Paper by Paul from head and Dennis Prangle.",
            "Pushing epsilon exactly to 0 or as close as possible to zero in that respect may not be the optimal ID because we are losing.",
            "Intuitively, a certain amount of simulations, but you're also increasing violence by trying to reduce the bias."
        ],
        [
            "So if you're using ABC, may be dangerous to your.",
            "Maybe not turn off, but inference.",
            "Without warnings from the general."
        ],
        [
            "Urgent or."
        ],
        [
            "Ever.",
            "OK, so let me go through a few points.",
            "A few papers that that relates to this ID and one important paper in this respect is the PNS paper by early Redmond and courses.",
            "Where, because epsilon is both essential and in a terrible nuisance because it doesn't appear in the original problem.",
            "They included epsilon into the picture by drawing inference not only on theater but also on epsilon.",
            "And so they used.",
            "Particle approach to do that by putting a prior Absolon.",
            "And transforming the.",
            "Likelihood into a function on Epson's website, and became part partly the error on the method and partly the variation of the data around the data.",
            "OK, so because this is not exactly available there is a non parametric approximation involved at this level as well."
        ],
        [
            "And then in the technique, I don't go through the technique.",
            "For lack of time but.",
            "It's it's shooting.",
            "MCMC to move around with this trick, that that's all tricks.",
            "The first one is that the distances do not.",
            "Summarize into a 1 dimensional object any longer and that the strength of the message.",
            "There are many distances altogether, and so epsilon becomes a multi dimensional object.",
            "The distances can be negative, which is interesting for distances, but that's another positive point being negative right?",
            "And the last point is that because there are so many several directions.",
            "The distribution on this directions are summarized into a minimum, which is another unusual object into into the picture."
        ],
        [
            "And from this intuition of new objects, they get a way to compare models as well, because each of the direction.",
            "So this is stolen from the paper with permission.",
            "From each of the directions of the errors, you can build a distribution percent distribution, absolute perspective.",
            "Distribution of these errors and compare what happens in different models to spot the model that is behaving strangely, namely, is avoiding 0 value that relates to our epsilon equals zero justification of ABC."
        ],
        [
            "And I think I will keep that and."
        ],
        [
            "Add a few questions."
        ],
        [
            "Let's keep the questions."
        ],
        [
            "No, another approach that.",
            "Started with Richard Wilkinson in Season 8 but that has been found in in many papers subsequently is the fact that somehow ABC can be Inter turn into what I got an exact BC?",
            "Although it's not exactly an exact PC.",
            "That makes me.",
            "When you look at this pseudo object that is connected with the product of our simulations, we're simulating from pie Cedar from pie.",
            "Then we're seeming to data from the true likelihood, and then because we cannot wait, we have this weight that is 01 in the original ABC, or that is a kernel of any flavor.",
            "In the general case with.",
            "Terms of silent.",
            "So when you get things from that way.",
            "This looks like a true posterior, but from another."
        ],
        [
            "Distribution, then the true distribution.",
            "Namely, there is a combination between the F and the key.",
            "You can look at F of Z given seed at times K of Y -- Z as.",
            "The new distribution.",
            "And that means that.",
            "ABC is exact, but for the wrong problem.",
            "So we're just asking the wrong question, but then we get the right solution.",
            "So if we do that.",
            "It's as if we were getting observations that on noise noisy means that Rob Salvation is why Tilda from F of Y~ given sera, but then.",
            "Because without observe Y2DY will survive is noise.",
            "Aside from keep silent, we do get this convolution.",
            "Term into the posterior.",
            "OK, so in that respect ABC is an exact Bayesian computation, but for noisy model.",
            "And of course this has drawbacks."
        ],
        [
            "As a perspective, because rather than saying that.",
            "It's measurement errors that would be fine, but to make it work you have to say that is it is a model error and then using."
        ],
        [
            "This K as the position of the model error becomes difficult to justify in.",
            "In a conversation, right?"
        ],
        [
            "So.",
            "Yeah, of course.",
            "Pros and cons to dad.",
            "The cons are that.",
            "It's still a fake model inside the case totally artificial.",
            "You cannot start justifying that your normal or whatever kernel has anything to do with the truth and illusion.",
            "You have to modify the algorithm."
        ],
        [
            "OK."
        ],
        [
            "Now let me re exact to yet another paper where where things get closer to the picture.",
            "It's a recent paperback by dinner at all.",
            "Are focusing on on this specific model of hidden Markov models, so it also relates to Mikes talks where you observe a sequence that is indexed by a none observed Markov chain.",
            "An ABC in this setup is built in a way that the simulated data.",
            "Is forced to belong to an intersection of balls around the true data.",
            "So we only accept simulations where why one is close enough to why one not you observed Y one up to YN close enough to Wyandot.",
            "So that makes for a very restrictive distance because that's essentially comparing each simulation with each point in the series, and so it cannot work when N gets very large, but that's the price to pay for us."
        ],
        [
            "Series of interesting results."
        ],
        [
            "That relate to both these aspects that ABC could be exact.",
            "If we look at it from another side of the mirror, an also for its convergence when the length of the series goes to Infinity.",
            "So again, they have this the same remark that if you, for instance defines the ABC, Emily, that is the first outcome of the simulation.",
            "Trying to take these procedures that produce the most.",
            "The highest rate of success in this acceptance.",
            "It is an exact Emily.",
            "If we use a convoluted version, which in that case makes certainly makes a bit more sense because it's like you had the series an you drew.",
            "A tube around the original series and you could shake the series inside the tube so you have tolerance that is transformed into a measurement error of epsilon in that case."
        ],
        [
            "For for the noisy or shaky.",
            "Series you get exact inference, and that's an error in observation type of model that started being rather commendable."
        ],
        [
            "And there are different similar types of results, namely that.",
            "If you look at your model ABC, even when N goes to Infinity, ABC Emily is bust, but if.",
            "You start decreasing epsilon towards a smaller value.",
            "Get this convergence to the information to the converted likelihood as fear and then goes to Infinity."
        ],
        [
            "So.",
            "From this perspective it's like replays are true data.",
            "With this noisy version and then you get regular vision inference and so that's one of the conclusions of the paper, and from there we start seeing where.",
            "The connection between vision inference and this ABC perspective could happen, namely that by accepting to throw away this precision on the data, you do recover an exact type of inference.",
            "Again, that's a bit against the original principles that why should we throw away information?",
            "By roughening up the data, but that's the price to pay that.",
            "If we accept that we cannot get to this ultimate precision that the whole information.",
            "Is not attainable.",
            "Then why not doing that and still being basean?",
            "And throw the egg away."
        ],
        [
            "And so in the paper they do get.",
            "Consistency result for the noisy version.",
            "No, I mean it's not like all nice and rosy.",
            "And things are deteriorating very quickly as an grows because the paper is using.",
            "Problem that is of dimension N. So this kind of transist the increase of N. But as a principle I find I find the paper fairly interesting."
        ],
        [
            "I can see.",
            "There are two five that means 10, right?"
        ],
        [
            "OK, now I'm I just have one oversized left, so I'm almost done.",
            "And I'll skip most of them."
        ],
        [
            "No.",
            "I read the like the final final question.",
            "Which is.",
            "When we try to implement ABC.",
            "There are very few cases where.",
            "We can use the whole data so we have to pick a summary statistics.",
            "Because of the size of the data, there is no way we can produce computable version without reducing the data into a small vector of summary statistics and therefore it's.",
            "It's an interesting problem that we need to find.",
            "The optimal summary statistics for for conducting this approximation to the true posterior.",
            "An there are cases where.",
            "It's so relevant that Mrs.",
            "Choice of summer."
        ],
        [
            "Autistic that depending on the choice we do get consistency or not.",
            "And so we have a series of two papers."
        ],
        [
            "One of which do this would present in a few days where.",
            "Actually, they picking the wrong summary statistics.",
            "The base factor when comparing two models will not be consistent.",
            "We will not pick even when angles to Infinity pick the right model, but we will pick the simplest model, for instance.",
            "And that 4 bit for Model Choice proposes the equivalent for for estimation."
        ],
        [
            "And so in connection with that there is again this Red Paper I just I mentioned a few minutes ago by Profan head and Dennis Prangle.",
            "That studies among all possible choices of summary statistics.",
            "Which one makes the most sense for contacting ABC?",
            "Anne.",
            "I won't discuss the paper.",
            "First cutoff time and second because he's not my paper, but."
        ],
        [
            "The summary of the paper about the summary statistics is that.",
            "The very interesting result in the very beige and result is that the optimal summary statistics is the basic general E of cheetah given one, and it has many.",
            "Interesting features first is vision.",
            "Second one is that it's exactly this dimension of Sita, so you have not.",
            "Any extravagant entry in the summary statistic is just the best.",
            "Possible entry it's the size of soda and nothing, nothing else.",
            "There is just one.",
            "Downside, which is that that's exactly what we try to approximate, so we don't have this summary statistic, and so in fact to be pragmatic and practical, we're first to approximate this summary statistic before conducting the ABC.",
            "And the other."
        ],
        [
            "Part"
        ],
        [
            "Of the paper."
        ],
        [
            "Is that deals with the errors contained in ABC, I mean it's throwing away this idea that we are losing information.",
            "By getting going from Y to this summary statistic, but otherwise it compares the approximation due to the conversation to the approximation due to Monte Carlo and it recovers.",
            "Somewhere.",
            "The.",
            "Nonparametric error I've already mentioned through this kind of variation of of the error somewhere is here.",
            "So we do recover the nonparametric speed that we had previously.",
            "And then there is a side result that all versions should appreciate.",
            "Namely that if you use this.",
            "As a summary statistic, it doesn't have to be sufficient because you don't have to be in an exponential family model, but it is almost sufficient in the sense that the expectation of Sita given S of Y is always the expectation of Sita given one.",
            "And it took me awhile to believe in that, but it's true, and so it's really well, OK. Now.",
            "It's not a perfect message, and I think I'll stop here.",
            "Add more about the discussion, but you can look at the slides on the web.",
            "The point is that through the recent literature.",
            "When's the decisions became?",
            "As interested in the methods as population geneticists.",
            "It became obvious that.",
            "There was more to the message than just a crucial trick.",
            "That look fairly dirty.",
            "It's it's a way to handle complex models.",
            "An to go over either the complexity of the data, the complexity of the parameter.",
            "Or are the partial information about the model an my impression at the moment is that it's it's totally soluble in the Bayesian approach by rewarding the whole thing as as a new model rather than seeing it as an approximation to the exact model, because in a sense.",
            "All mothers are wrong, but some other useful.",
            "Well, some methods are more useful than others.",
            "Thank you.",
            "Any credit whoops.",
            "It's OK, you can do any questions for Christian.",
            "Comments.",
            "We have some minutes time if somebody.",
            "You just believed it all.",
            "So so in theory I guess you owe some questions somewhere.",
            "Oh, can you please go down to the microphone?",
            "Hi, you mentioned that using Bayes factor may lead to picking the simplest model.",
            "Could you please explain it a little?",
            "You mentioned two references in 2012, so there will be a talk on.",
            "On Wednesday on that paper, but essentially if.",
            "Your summary statistic behaves the same.",
            "Or could behave the same in the bus models, then drink inference using only these summary statistics will lead to an agreement of the data with each of the models.",
            "Whether that is true or not, we not matter because you only look at the summary statistic and so you will get an agreement for Model A and for Model B an in that case because there is agreement for both models, the one which wins is the smallest, simplest one.",
            "So that's that's when the caller ID in this paper that to make discriminants separation between models using a summary statistic, it must behave differently under both models, so that you cannot recover the parameter under the wrong model.",
            "Thank you.",
            "Other question on race or.",
            "Somewhere down there.",
            "Any other comments?",
            "Well, uh oh.",
            "Hi Christian, very interesting talk in in the tradition of looking at Bayesian modeling as a model for how rational people think.",
            "Do you think that the ABC that you have been talking about could model how deterministic modelers try to get their models close to the?",
            "The data with noise, so some summary statistic.",
            "Of the data.",
            "I'm not sad at all.",
            "Just to make an objection for the sake of objection.",
            "As usual, is.",
            "Obviously the calibration then of ABC could could get into the way by.",
            "I mean, it's the noise.",
            "Would be a choice of the tradition, not of the modeler, and so it it it.",
            "I mean, the choice of a camel.",
            "Good.",
            "Could just not get things right.",
            "I don't know, just this could be an issue.",
            "But I mean, that's that's an interesting direction.",
            "Left Christian speechless.",
            "Pretty good.",
            "Any other comments?",
            "I'm interested in some of the population genetics examples, so do you have any in the light of your discussion of the different approaches and methods?",
            "Can you sort of?",
            "Just say how good some of those previous results are or or are they sort of cast into question.",
            "Um?",
            "Well, let me answer another question.",
            "Just to link with the model choice issue.",
            "For instance, that.",
            "A lot of the population genetic literature has been comparing scenarios.",
            "And of course they used whatever summary statistics you had there.",
            "At the hands, right?",
            "When we looked at some of the papers, actually it, it happens that there were always a component in this summary statistics that was able to make the difference between the models.",
            "So although there was no formal checking that.",
            "It was leading to the proper discrimination in practice.",
            "In the cases we looked at it wells.",
            "Not really answering your question with.",
            "Anymore.",
            "Urgent questions.",
            "Otherwise we have a bus to catch eventually.",
            "Let's move on.",
            "Also, let's Vanquish are again thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a wonderful honor to introduce our next is my lecture by Chrystia Robbia, who is one of the massive contributors to MCMC, and among many other things, has written a wonderful book deviation choice.",
                    "label": 0
                },
                {
                    "sent": "One of the few.",
                    "label": 0
                },
                {
                    "sent": "Technical statistics books that are actually really a pleasure to read.",
                    "label": 0
                },
                {
                    "sent": "I really enjoyed it.",
                    "label": 0
                },
                {
                    "sent": "But somehow off lately he has abandoned the exact and beautiful things and he starts to do things approximately and he's going to tell us about this approximate Bayesian computation.",
                    "label": 1
                },
                {
                    "sent": "the ABC advances in questions please Christian.",
                    "label": 0
                },
                {
                    "sent": "OK Peter, thank you for this approximative introduction.",
                    "label": 0
                },
                {
                    "sent": "First, I want to thank the organizers for giving me this opportunity to talk about ABC.",
                    "label": 0
                },
                {
                    "sent": "It's a bit of paradoxical that it comes in a in a beige and foundation.",
                    "label": 0
                },
                {
                    "sent": "Session in the sense that it's.",
                    "label": 0
                },
                {
                    "sent": "On the approximately beige and so, it cannot be truly foundational, but actually, I mean further, probably this topic, because this is my current area of interest.",
                    "label": 0
                },
                {
                    "sent": "But also I think they when I was trying to prepare those slides from previous lectures.",
                    "label": 0
                },
                {
                    "sent": "I thought that there could be something slightly deeper than just being approximated.",
                    "label": 0
                },
                {
                    "sent": "The sense that.",
                    "label": 0
                },
                {
                    "sent": "To link with Mike's talk.",
                    "label": 0
                },
                {
                    "sent": "As we are facing harder and harder problems, larger and larger datasets.",
                    "label": 0
                },
                {
                    "sent": "It gets it's getting harder and harder to stick with Z traditional model that is completely defined that we know from from A-Z except for the parameter and therefore dealing with approximate models or approximate misses.",
                    "label": 0
                },
                {
                    "sent": "Maybe a vision of the future and not only side occupation for earth visions.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first thing is this happens at like the worst of times in that my principle author George.",
                    "label": 0
                },
                {
                    "sent": "Died last week, so I'd like to dedicate this talk to his memory and mention that on Wednesday we're having a memorial session at lunch break too, which of course everyone is welcome.",
                    "label": 0
                },
                {
                    "sent": "To participate in an and talk stories about Jordan is is wonderful personality.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "This talk tries to avoid too much technical stuff about computations, an rather trying to focus on the thing I mentioned at the beginning, namely, said.",
                    "label": 0
                },
                {
                    "sent": "This this could be a different perspective on.",
                    "label": 0
                },
                {
                    "sent": "A new type of inference machine, so I mean I'm not trying to to be to oversell the method, as is drawbacks and and I mentioned that them doing the top but at the same time it allows to process at a reasonable cost, harder problems than found previously.",
                    "label": 0
                },
                {
                    "sent": "I get treated that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I just give a few words of introductions, then describe what is ABC and then on the last part fully reaching there.",
                    "label": 0
                },
                {
                    "sent": "I'll link ABC with inference.",
                    "label": 0
                },
                {
                    "sent": "And what I mean by that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "To motivate ABC, let us start with the basics.",
                    "label": 0
                },
                {
                    "sent": "We have a vision problem of inference.",
                    "label": 0
                },
                {
                    "sent": "In, for instance, we want to compute an integral that is related to the to the posterior, and we can compute this integral.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's the usual stuff.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And therefore we process the issue by producing a sample from this posterior an using the basic Monte Carlo approximation that has all the standard properties if.",
                    "label": 0
                },
                {
                    "sent": "The function we want to integrate is regular enough so that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does the stuff of course.",
                    "label": 0
                },
                {
                    "sent": "To do that, we need to prove to provide this sample from the posterior, and this is often impossible or very inefficient if we don't know how to simulate efficiently from.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dispatcher, and therefore there are many ways of getting around out an one that.",
                    "label": 0
                },
                {
                    "sent": "Has been around for as many years as Monte Carlo actually is important.",
                    "label": 0
                },
                {
                    "sent": "Sampling where instead of assuming from the posterior, you take a proxy that is density Q and simulating from his density you re Express a problem that's pretty integrals against these.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Density, and therefore if we can produce a sample from this important sampling density.",
                    "label": 0
                },
                {
                    "sent": "Given that we are free to choose it.",
                    "label": 0
                },
                {
                    "sent": "Then we can provide an approximation to the integral by re expressing this integral as as this expectation.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again there for exactly the same reason we have the same convergence properties.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now of course, to do that, we need to be able to compute \u03c0 / Q An in most Asian problems we don't know Pi exactly because we are missing the normalizing constant and this is not such.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A big deal because.",
                    "label": 0
                },
                {
                    "sent": "We can estimate the constants for the same price for the same cost and divide this average by the average of the weights and again.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We get the same type of results of low fresh numbers and central limit theorems.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This again imposes some constraints on the problem, namely that pie at least should be known up to a constant.",
                    "label": 0
                },
                {
                    "sent": "An when \u03c0 is not available up to a constant, we are suddenly facing a problem of a much higher difficulty and to some extent problem that sounds unfeasible in the most realistic situations.",
                    "label": 0
                },
                {
                    "sent": "And so this will lead to the introduction of ABC.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne again.",
                    "label": 0
                },
                {
                    "sent": "We can see things from different perspectives.",
                    "label": 0
                },
                {
                    "sent": "Either we are dealing with a mere computational problem and mirrors to be put between quotes, but because it's a computer problem, the core of our job is not is not affected.",
                    "label": 0
                },
                {
                    "sent": "An we can hope that better computer or better method will appear an and solve a problem.",
                    "label": 0
                },
                {
                    "sent": "That's the optimistic side as a pessimistic, pessimistic side is that we may have to wait too long for this solution now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are other ways of looking at the problem, namely that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The very nature of of the model, the fact that it is not a tractable model in the sense of providing.",
                    "label": 0
                },
                {
                    "sent": "A closed form density or computable density?",
                    "label": 0
                },
                {
                    "sent": "Pushes for different inferential approaches.",
                    "label": 0
                },
                {
                    "sent": "And to to leave the standard version.",
                    "label": 0
                },
                {
                    "sent": "Path for different inferential approach that, if you're optimistic, can be repatriated within the vision.",
                    "label": 0
                },
                {
                    "sent": "Real an if you're pessimistic that is incorrect because it's not exactly basean.",
                    "label": 0
                },
                {
                    "sent": "An A middle ground is to see that to say that we may still be visions, but we're dealing with different types of estimators and methodologies, and again, the bright side is that because it's still within the Bayesian approach, it's it's valid in an incoherent an if you're not that optimistic, it may lead to cases where it is not clear and because for instance.",
                    "label": 0
                },
                {
                    "sent": "It's not convergent.",
                    "label": 0
                },
                {
                    "sent": "Now do.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just.",
                    "label": 0
                },
                {
                    "sent": "A side issue that actually relates to to ABC, and that's more like an historical background on the issue.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of connections with the introduction of ABC between the intuition of ABC and some solutions that have been developed in econometrics.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "In a sense, we're not always paying enough attention to what's going on econometrics.",
                    "label": 0
                },
                {
                    "sent": "Although I mean the two foods are statistics in a metrics are close enough.",
                    "label": 0
                },
                {
                    "sent": "What happened in the in the past 15?",
                    "label": 0
                },
                {
                    "sent": "Yours at least.",
                    "label": 0
                },
                {
                    "sent": "There have been ways to deal with complex econometric models that prefigured ABC.",
                    "label": 0
                },
                {
                    "sent": "An related simulation based techniques, and so I will just mention a few here in case you have not seen them and if you have in case you have seen them to make the link with ABC.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for his simulated method of moments is.",
                    "label": 0
                },
                {
                    "sent": "Such that because you cannot compute a likelihood, for instance, you produce pseudo estimations through observations from your shoe model, reads a given value of the parameter sitter.",
                    "label": 1
                },
                {
                    "sent": "Ann, you try to fit the best see to in terms of the simulated data when compared with the original data.",
                    "label": 0
                },
                {
                    "sent": "YOT so that's one approach.",
                    "label": 0
                },
                {
                    "sent": "Given that it it depends.",
                    "label": 0
                },
                {
                    "sent": "A little too much on on the series and so it looks at the difference between each term of the series and not.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is just to look at one statistic based on the series and for instance to take the average of the observations minus the average of the simulation observations.",
                    "label": 0
                },
                {
                    "sent": "And if you know already ABC, you can see that there is a perfect link there.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then a bit broader and more ambitious is a method of simulated moments to distinguish it from the simulated method of moments.",
                    "label": 1
                },
                {
                    "sent": "That goes a bit further and uses first a statistic K for which we can find an unbiased estimator of its expectation and compare what you observe The Cave YT again with a simulated version that may be repeated in order to reduce the Monte Carlo variation.",
                    "label": 1
                },
                {
                    "sent": "And this distance is is.",
                    "label": 0
                },
                {
                    "sent": "Arbitrary, but we again pick a parameter sitter that tries to bring what we observe.",
                    "label": 0
                },
                {
                    "sent": "Through some prism through some change of perspective, because K is only a statistic is not the whole vector an an approximation based on a knowledge of the method?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then comes up.",
                    "label": 0
                },
                {
                    "sent": "I think the most interesting of the group, which is the indirect inference approach.",
                    "label": 1
                },
                {
                    "sent": "That was introduced by Google at all, namely that.",
                    "label": 0
                },
                {
                    "sent": "They go even farther from the assumption they have on the model by using estimators.",
                    "label": 0
                },
                {
                    "sent": "That rely on a pseudo model that is not necessarily true, but.",
                    "label": 1
                },
                {
                    "sent": "Using the model behind the picture behind the scene.",
                    "label": 0
                },
                {
                    "sent": "They try to find the parameter seater that brings this estimator of the wrong model as close as possible to an estimator based on absolute data.",
                    "label": 1
                },
                {
                    "sent": "Using the true model.",
                    "label": 0
                },
                {
                    "sent": "Later it sounds quite convoluted, but it allows for.",
                    "label": 0
                },
                {
                    "sent": "Processing situations where the true model is truly a complex thing where all you can do about it.",
                    "label": 1
                },
                {
                    "sent": "The knowledge you can use from it is only simulating absolute data now.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are again many ways of implementing this principle.",
                    "label": 0
                },
                {
                    "sent": "There are many choices to calibrate the method.",
                    "label": 0
                },
                {
                    "sent": "For instance, our once you'd pick up pseudo model you can use.",
                    "label": 0
                },
                {
                    "sent": "Directories are maximum likelihood estimator for subsidy model.",
                    "label": 0
                },
                {
                    "sent": "That assume action will actually matter and from there compare your bit ahead as you observations with bit ahead at a sample of pseudo observations.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or else in the study related where you can use the score vector in the same perspective.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does it work well?",
                    "label": 0
                },
                {
                    "sent": "If you look at.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The creators of the method grew and more for.",
                    "label": 1
                },
                {
                    "sent": "They are rather vague about the cases where it where it works, but there's this interesting sentence that we will find again in ABC, namely that of course beta must contain enough information to recover the perimeter sitter and so in a sense within.",
                    "label": 1
                },
                {
                    "sent": "This construct Cedar must be the equivalent of identifiable.",
                    "label": 0
                },
                {
                    "sent": "And then they get to this interesting sentence that we will recover later.",
                    "label": 0
                },
                {
                    "sent": "Maybe that the best case.",
                    "label": 1
                },
                {
                    "sent": "If I interpret their words, the best case is when the parameter.",
                    "label": 0
                },
                {
                    "sent": "Sierra is just identify, namely when the pseudo model is parameterized in the sparsest possible way, not to induce extra dimensions that would slow down convergence.",
                    "label": 0
                },
                {
                    "sent": "An lead to more inefficiency.",
                    "label": 0
                },
                {
                    "sent": "So that's an interesting feature of indirect inference.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, there is a lot of arbitrariness.",
                    "label": 0
                },
                {
                    "sent": "The justification in the economic literature is justification of consistency and convergence of those estimators at a given speed.",
                    "label": 0
                },
                {
                    "sent": "So we cannot recover much for our problems with a given sample size.",
                    "label": 0
                },
                {
                    "sent": "That there is an interesting follow-up to the indirect inference paper biography.",
                    "label": 0
                },
                {
                    "sent": "Jesse, an England.",
                    "label": 0
                },
                {
                    "sent": "And in Genesis B in 2004, where they try to have a more practical evaluation of the method by comparing choices of pseudo models, an of estimators in.",
                    "label": 0
                },
                {
                    "sent": "Variety of situations and they came with the conclusion that Beta had had to be dependent on Cedar.",
                    "label": 0
                },
                {
                    "sent": "So in subsequent terms, if you pick an ancillary statistic is not going to help very much, which makes sense.",
                    "label": 0
                },
                {
                    "sent": "But at the same time, once you get in formation about see that.",
                    "label": 0
                },
                {
                    "sent": "That is when Peter had varies.",
                    "label": 0
                },
                {
                    "sent": "When Cedar varies, you must have.",
                    "label": 0
                },
                {
                    "sent": "As concentration as possible in the distribution of bit ahead of Cedar, which again makes sense because the more concentrated it is, the easier it is to get in to get the relevant information about the parameter sitter.",
                    "label": 0
                },
                {
                    "sent": "There will be a talk.",
                    "label": 0
                },
                {
                    "sent": "In one of the ABC sessions about the use of indirect inference in connection with ABC by Chris to Randy.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, another approach that I put under the head of econometrics, although its role in that is empirical likelihood, an originally it's not a method that is directly related with simulation, nor is ABC that I will make the link in a minute break likelihood is another way to process complex models where you don't want to make.",
                    "label": 0
                },
                {
                    "sent": "All the assumptions you need to to create a complete model.",
                    "label": 0
                },
                {
                    "sent": "Instead you introduce a parameter that is your parameter of interest.",
                    "label": 1
                },
                {
                    "sent": "An link with this parameter you define expectations that define the parameter.",
                    "label": 0
                },
                {
                    "sent": "So essentially you introduce a parameter that either defines moments or behaviors of the data that are of interest to you, and you create a function of the data and of these parameters so that you get a pivotal quantity HY insita.",
                    "label": 0
                },
                {
                    "sent": "That was expectation at Cedar is 0, so francita is the mean of the wise.",
                    "label": 0
                },
                {
                    "sent": "You just get E of Ybor Majesty to equal to 0 and based on this definition of the model, which is not a mobile, just a collection of features about your problem, you define the empirical likelihood by.",
                    "label": 1
                },
                {
                    "sent": "Well, you start from the beginning that puts weight 1 / N to each point in your sample and you start twisting the weights so that the constraint is fulfilled, is satisfied, and so you must get some of the PIHYI see to to be equal 0, which is a translation of this.",
                    "label": 1
                },
                {
                    "sent": "Of these constraints, OK, and this is not new.",
                    "label": 0
                },
                {
                    "sent": "This is due to Auto Berlin in the late 80s.",
                    "label": 0
                },
                {
                    "sent": "Any?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Has not been very much connected with the Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "Although this is coming, and in particular in this meeting there will be an entire session dedicated to empirical likelihood and Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "So I mean, this is an illustration in the case of other mean, you start picking the weights so that the weighted average of the wise is cheetah an optimize the product of the ways to get the largest possible empirical likelihood.",
                    "label": 1
                },
                {
                    "sent": "And the more Cedar Father Theater is from the true seed, as the one that corresponds to the data, the harder it is to fit this constraint, and therefore the smaller.",
                    "label": 0
                },
                {
                    "sent": "The product.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now what do the connection we see?",
                    "label": 0
                },
                {
                    "sent": "Well, you can starting from this perspective.",
                    "label": 0
                },
                {
                    "sent": "Whether the model is totally provided or you only want to make a few assumptions about your model and you don't care about the whole construct, you could create a simulation approach that rely on that by simulating theorize from the prior or from an alternative importance function and then create regular importance weights except that.",
                    "label": 1
                },
                {
                    "sent": "You use the empirical likelihood rather than the original likelihood.",
                    "label": 0
                },
                {
                    "sent": "Again, whether you can compute it or not, and we played with this notion in a fairly recent paper to try to compare that with more standard ABC, an in both dynamical models and genetic population genetic examples, we found that this was providing much more stable.",
                    "label": 0
                },
                {
                    "sent": "Evaluation to the likelihood than the regular ABC, I mean the state of the art ABC.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So why is it ABC in that case?",
                    "label": 0
                },
                {
                    "sent": "Well, it's it's approximate, just like this picture that we've done already.",
                    "label": 0
                },
                {
                    "sent": "If it's based or not.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's beige and this we know it's from base.",
                    "label": 0
                },
                {
                    "sent": "This is the picture you get in this paper.",
                    "label": 0
                },
                {
                    "sent": "It's vision because, well, you see here from the prior, so more vision could be than that.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's computationally because you provide a sample that tries to approximate a certain target, as in this example, where it where it works beautifully.",
                    "label": 0
                },
                {
                    "sent": "I don't put a picture of the employee.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doesn't work.",
                    "label": 0
                },
                {
                    "sent": "All right now, is it really beige and well?",
                    "label": 0
                },
                {
                    "sent": "The only justification for Bill likely would like the whole collection of those economic method I presented is.",
                    "label": 0
                },
                {
                    "sent": "That is validated by the sample size growing to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So is it really meaningful for us that's debatable?",
                    "label": 0
                },
                {
                    "sent": "The second point that for me is more important is that.",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "Giving an approximation to the truth.",
                    "label": 0
                },
                {
                    "sent": "Whatever is truth is or means.",
                    "label": 0
                },
                {
                    "sent": "And the truth is that this approximation is very hard to assess, very tell, so it's this method are good approximations method.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they aren't the only way to provide an approximation, but unless you run extensive simulation of magnitude that is higher than the one you need to produce the approximation, you don't already how far you are from the truth, and that's that's a big drawback.",
                    "label": 0
                },
                {
                    "sent": "But again.",
                    "label": 0
                },
                {
                    "sent": "Insinuating situations like the one we face in property in population genetics.",
                    "label": 0
                },
                {
                    "sent": "This may be the only valuable valid sorry implementation, because otherwise we would have to wait weeks or years or we would have to use alternative models that do not provide the same.",
                    "label": 0
                },
                {
                    "sent": "Amount of information.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this was just the introduction, so now I can reach the the ABC per say the genuine ABC.",
                    "label": 0
                },
                {
                    "sent": "And I just have.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "2 words about the genetic background.",
                    "label": 1
                },
                {
                    "sent": "The main reason is I.",
                    "label": 0
                },
                {
                    "sent": "Don't want to make a more of a fool of myself by speaking about genetics, so play safe and don't say anything.",
                    "label": 0
                },
                {
                    "sent": "The second thing is that form of the talks we would be listening to an user week are connected with genetics, so they will know where to talk about.",
                    "label": 0
                },
                {
                    "sent": "So I mean ABC.",
                    "label": 0
                },
                {
                    "sent": "The genuine ABC started in practice in population genetics about 15 years ago to deal with.",
                    "label": 1
                },
                {
                    "sent": "Genic scenarios relating populations to two common ancestor where people were interested in the parameters driving the divergance.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Between populations, and so there were a few parameters were not talking of big data about Sera.",
                    "label": 0
                },
                {
                    "sent": "Sera could be as small as 2 dimensional or 1 dimensional cannot be smaller.",
                    "label": 0
                },
                {
                    "sent": "But these parameters were hard to derive because the likely.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good.",
                    "label": 0
                },
                {
                    "sent": "Add a very funny shape that depended on this population tree towards the most common ancestor that was huge and difficult to integrate.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then and this, this is a kind of example that the people I worked with.",
                    "label": 0
                },
                {
                    "sent": "There were analyzing where you had several tribes of Pygmies in Western Africa, an the equation.",
                    "label": 0
                },
                {
                    "sent": "The badges were considering, where was about the origin of those pygmy tribes, namely whether whether related together and they issued from a branch from the non pygmy population earlier or the split was more.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Complex and so there are these kind of scenarios where you just have to look at the colors.",
                    "label": 0
                },
                {
                    "sent": "These even scenarios they wanted to compare and again the trees as of political structure was interesting, but the actual tree of going to the most common ancestor was not, and so this made difficult problem because the likelihood was not available.",
                    "label": 0
                },
                {
                    "sent": "So that's how it started.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That essentially we were in a kind of missing data problem, but there was so much missing data that this integration was not possible or it was only possible in the simplest of cases, and otherwise it would have taken too long to compute.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we are going back to the same problem, namely that we have.",
                    "label": 0
                },
                {
                    "sent": "A likelihood function that in many cases is completely defined.",
                    "label": 1
                },
                {
                    "sent": "You know it entirely.",
                    "label": 0
                },
                {
                    "sent": "In other cases, as in pre correctly with just know a few features, but essentially you know it entirely.",
                    "label": 0
                },
                {
                    "sent": "An you don't know what to do.",
                    "label": 0
                },
                {
                    "sent": "Is it because it's computation is impossible and so therefore you cannot do MCMC?",
                    "label": 0
                },
                {
                    "sent": "You kind of do important sampling.",
                    "label": 0
                },
                {
                    "sent": "You can do any of the regular simulation trick that we are so used to, and so the question is whether we give up.",
                    "label": 1
                },
                {
                    "sent": "Any approach with the extension you?",
                    "label": 1
                },
                {
                    "sent": "You have to change the model.",
                    "label": 0
                },
                {
                    "sent": "It's not like another method is available or you have to settle for a degree of approximation.",
                    "label": 0
                },
                {
                    "sent": "Integration is how much approximation is it.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, in a sense we have to do.",
                    "label": 0
                },
                {
                    "sent": "ABC stands for almost based.",
                    "label": 0
                },
                {
                    "sent": "Can you send that?",
                    "label": 0
                },
                {
                    "sent": "Is not based almost can, but it's almost base can.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After such a long wait, you can see what is ABC.",
                    "label": 0
                },
                {
                    "sent": "You have a target that you say Asian targets of the prior and likelihood regularly.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It, but you know to define it as a construct.",
                    "label": 0
                },
                {
                    "sent": "You can produce simulations from this likelihood.",
                    "label": 0
                },
                {
                    "sent": "An the trick is related to this very basic, although essential properties that if you simulate from the prior seater prime then you seem like super data from this Model Z and you wait until Z is equal to Y the observed data.",
                    "label": 1
                },
                {
                    "sent": "The time you get out of this loop.",
                    "label": 0
                },
                {
                    "sent": "Produces acetyl prime.",
                    "label": 0
                },
                {
                    "sent": "That is exactly from the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "That is, it prove just look at the distribution of the Outcoming CR.",
                    "label": 0
                },
                {
                    "sent": "It is prior times approval to accept and the pretty accept is F of Y given Sitter, so it's accept reject 101, but it was no tist.",
                    "label": 0
                },
                {
                    "sent": "In 19.",
                    "label": 0
                },
                {
                    "sent": "1984 by Don Rubin and also in 1984 by Peter Diego and Greater.",
                    "label": 0
                },
                {
                    "sent": "In more in a conceptual way, then for the ruins and in a practical way.",
                    "label": 0
                },
                {
                    "sent": "But as a representation of what is Apostle distributions, position uses a prior as a prediction of a population.",
                    "label": 0
                },
                {
                    "sent": "An.",
                    "label": 0
                },
                {
                    "sent": "In that case it waits this simulation by pseudo datasat must mimic the true data and so that is our spirit is quite interesting because it gives a fairly intuitive approach to Bayesian statistics.",
                    "label": 0
                },
                {
                    "sent": "But of course in practice it was until 1997.",
                    "label": 0
                },
                {
                    "sent": "That it became a fact.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, is it practical?",
                    "label": 0
                },
                {
                    "sent": "Well, as I wrote, it is not practical, because waiting for ZQ Y means that this is an event that must occur at a human scale, cannot wait billions of years, force equal to Y, and therefore the A in ABC is drifting away from this exact representation of the posterior by allowing for some tolerance around the data.",
                    "label": 0
                },
                {
                    "sent": "And so you don't accept only ones equal to Y.",
                    "label": 0
                },
                {
                    "sent": "But when Z is close enough to our, namely, one distance between Y&Z or absolute distance is less than a certain absolom and epsilon is tolerance that you are ready to tolerate.",
                    "label": 0
                },
                {
                    "sent": "And actually in practice this is the tolerance that you're forced to tolerate.",
                    "label": 0
                },
                {
                    "sent": "If you want to solve your problem before.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Retire?",
                    "label": 0
                },
                {
                    "sent": "Now, of course, this produces an approximation, and this approximation means that you're not simulating from the true posterior, but from a convolution of this posterior by this tolerance.",
                    "label": 0
                },
                {
                    "sent": "And that's the price you have to pay or should pay for.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Calling approximately the problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The algorithm just you can write it in a few lines you see made from the data.",
                    "label": 1
                },
                {
                    "sent": "This email from there, sorry, you seem so data conditional on this value of the parameter and you wait until ZNY are close enough.",
                    "label": 0
                },
                {
                    "sent": "Now there is another degree of approximation that is found in most cases, namely that you cannot wait for the whole data to be close to the hopes of the data and so you force this proximity.",
                    "label": 1
                },
                {
                    "sent": "This closeness to occur in a reduced pace through the use of.",
                    "label": 0
                },
                {
                    "sent": "Statistics that are called summary statistics, which doesn't mean anything because there are statistics that these Transformers today to the point that they are usually not sufficient, so they are throwing away some part of the information content of the data.",
                    "label": 0
                },
                {
                    "sent": "But paradoxically as I will explain in a minute, this is almost necessary to do anything useful with this method, and so the regular ABC algorithm will pick not only a distance and tolerance, but also a summary of the data.",
                    "label": 0
                },
                {
                    "sent": "Through this summary statistic eat.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, this leads to an.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optimation of of the posterior.",
                    "label": 1
                },
                {
                    "sent": "Because so we get this convolution of the true posterior with the Z.",
                    "label": 1
                },
                {
                    "sent": "An the belief is that if epsilon goes to zero, we should get back to this pile of Cedar given one that if we put enough computational effort, we shouldn't be too far from the.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The troops.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll just skip this slide out.",
                    "label": 0
                },
                {
                    "sent": "There are ways of proving that essentially epsilon goes to zero.",
                    "label": 0
                },
                {
                    "sent": "You do recover something that is close to the to the posterior, but you have to make some assumptions.",
                    "label": 0
                },
                {
                    "sent": "So there are two ways I had to.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prove that that's not.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very important because.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, it's not, of course always true Ann.",
                    "label": 0
                },
                {
                    "sent": "In most cases, because we are using insufficient statistic, we cannot recover.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The true posterior at best.",
                    "label": 0
                },
                {
                    "sent": "What we could recover is this pile of Cedar.",
                    "label": 0
                },
                {
                    "sent": "Given each of war now.",
                    "label": 0
                },
                {
                    "sent": "This is the best we can hope for, but.",
                    "label": 1
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we get to this extreme and caricature case where Eater is on scenery, then we don't recover anything at all.",
                    "label": 0
                },
                {
                    "sent": "The best we can hope is a prior.",
                    "label": 1
                },
                {
                    "sent": "Thank you Ann.",
                    "label": 0
                },
                {
                    "sent": "I made this a typo.",
                    "label": 0
                },
                {
                    "sent": "It's part of seats are not part of heater.",
                    "label": 0
                },
                {
                    "sent": "So well.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not that funny.",
                    "label": 0
                },
                {
                    "sent": "Because it seems so.",
                    "label": 0
                },
                {
                    "sent": "It's easy to produce this kind of example where actually by using a very heavy machinery you get it with the sample that at the end has not said anything about the information contains data, so convergence is really an issue and not convergence in the synthetic sense, but convergence in the tolerance sense.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me show you just well skip this exam.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me show you.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An example that is related with Mike talks, although it's a, it's a baby example in the sense that is an MEQ model, so we know to handle MEQ model, but let's look at the output to see the difference between the ABC outcome an are regular MCMC outcome for instance.",
                    "label": 0
                },
                {
                    "sent": "So we have an MEQ model where the connection between the data points in the series is through the noise.",
                    "label": 0
                },
                {
                    "sent": "And we make a regular uniform assumption on the perimeter CI so that we get this classical identity conditions.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the case of an enemy to model, we just have a triangle around 04 C to one and see tattoo.",
                    "label": 0
                },
                {
                    "sent": "So let's pick uniform prior over that triangle.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now if we want to apply the ABC example algorithm to this example or we have to do is to pick a value of 0102 over this triangle.",
                    "label": 0
                },
                {
                    "sent": "That's easy, and then we generate a new series by during a new ID sequence of noises and constructing the series from the conc tattoo and the noises.",
                    "label": 0
                },
                {
                    "sent": "Now here comes.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mission.",
                    "label": 0
                },
                {
                    "sent": "Of importance, once we have this pseudo series and we have the original series, how do we compare book series?",
                    "label": 0
                },
                {
                    "sent": "So the question is how do we build the distance between the two series?",
                    "label": 0
                },
                {
                    "sent": "Well what we saw already in in the simulated method of moments that we could take the basic row difference between the two series, biting the sum of the XT minus X prime tease square.",
                    "label": 0
                },
                {
                    "sent": "That's a distance.",
                    "label": 0
                },
                {
                    "sent": "If it is zero, the two series are.",
                    "label": 0
                },
                {
                    "sent": "Identical.",
                    "label": 0
                },
                {
                    "sent": "There is nothing wrong with that.",
                    "label": 0
                },
                {
                    "sent": "But that's using a distance between the series that contain a lot of noise in addition to information about the parameters.",
                    "label": 0
                },
                {
                    "sent": "So an alternative is to try to reduce the dimension of the problem by looking for any type of estimator.",
                    "label": 0
                },
                {
                    "sent": "Our inefficient it is, it doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "But reducing dimension as much as possible for foreigners in MA 2 case, we could take the two first autocorrelations and take the distance between those two autocorrelations.",
                    "label": 0
                },
                {
                    "sent": "Here we have a distance in the space of dimension T here ever distant in the space of dimension 2.",
                    "label": 0
                },
                {
                    "sent": "The summary statistics are not sufficient, so in a sense we're losing information compared with that.",
                    "label": 0
                },
                {
                    "sent": "But we will see that politically we're gaining a lot.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because if we simulate.",
                    "label": 0
                },
                {
                    "sent": "ABC in both cases those are the outcomes we get.",
                    "label": 0
                },
                {
                    "sent": "If we use the distance between the autocorrelations, we get a quick concentration of the accepted values of C to one and C2 means the triangle is the area of support of the prior.",
                    "label": 1
                },
                {
                    "sent": "That's where the model is identifiable and the colors are blue, red and gold.",
                    "label": 0
                },
                {
                    "sent": "Or actually corresponding to tolerances of 10 percent, 1% and zero point 1% of the distances.",
                    "label": 0
                },
                {
                    "sent": "So it's an empirical choice of the tolerance that is the usual approach in ABC, and it's shrinking towards a point that you actually the Emily in that case, so it's shrinking in a proper region.",
                    "label": 0
                },
                {
                    "sent": "Now, if instead I used the whole data to compute the distance.",
                    "label": 0
                },
                {
                    "sent": "I guess it's very different picture picture where you still observe a kind of shrinkage from the prior towards the region of interest, where it's much, much slower and therefore to get to region.",
                    "label": 0
                },
                {
                    "sent": "And it doesn't exactly the same, but it means that to get to regions that that would come parable in both cases here we would need many many, many more simulations.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you look at the posterior marginal posteriors for both approaches, if we use a distance on the road data regards this kind of behavior again when epsilon is going down to zero, we get these three curves from flat to blue to red to gold.",
                    "label": 0
                },
                {
                    "sent": "It is very far from the genuine procedure produced by an MCMC sampler.",
                    "label": 0
                },
                {
                    "sent": "Same thing for CD2 and the interesting thing is that epsilon is shrinking, although the theory tells us that if there is exactly 0, we should recover the troopers terror with zero point.",
                    "label": 0
                },
                {
                    "sent": "1% of the similar distances were still very very far from the true posterior.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If instead we use a distance on the autocorrelations.",
                    "label": 1
                },
                {
                    "sent": "Of course, we don't get exactly the triple stare, but we get the picture that is much, much closer to the true posterior.",
                    "label": 0
                },
                {
                    "sent": "Granted, that's fairly basic toys.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we can get some conclusions out of that that will lead to the following points.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "As we said the.",
                    "label": 0
                },
                {
                    "sent": "The role of the distance that you should have said the role of the summary statistic.",
                    "label": 0
                },
                {
                    "sent": "So we're just projecting first before committing to distance is completely paramount, and the products of this role of the distance is that while the method is justified for absurd, exactly equal to 0, in practice we never get absurd to be exactly 0.",
                    "label": 0
                },
                {
                    "sent": "An the the numerical value of epsilon is actually of little importance compared with the space we're working in, so it's only there is a relative value.",
                    "label": 0
                },
                {
                    "sent": "There is no absolute.",
                    "label": 0
                },
                {
                    "sent": "Excellent in in the real problem, but when we implement the method it starts playing a role that is connected with the distance and the dimension of the problem and this example is a perfect illustration of what has been called the curse of dimensionality for ABC algorithm, namely that if we try too much by comparing the whole data with the hopes your data.",
                    "label": 0
                },
                {
                    "sent": "Although as statisticians we would not want to waste any Atom of information.",
                    "label": 0
                },
                {
                    "sent": "In that case, the noise created by the simulation of the Salida is killing by orders of magnitude.",
                    "label": 0
                },
                {
                    "sent": "The information containing the whole data, and therefore it makes much more sense to 1st project in in a smaller space, accepting that we're losing information.",
                    "label": 0
                },
                {
                    "sent": "But then because we're in a much smaller space, epsilon will be closer to 0 in this sense of bring information so that this product that.",
                    "label": 0
                },
                {
                    "sent": "We cannot only sing a statisticians when when dealing with this problem, we have to think as as more advanced traditions.",
                    "label": 0
                },
                {
                    "sent": "Away from from the true model.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me go.",
                    "label": 0
                },
                {
                    "sent": "I don't talk about the simulation methods again because there are several talks doing that in the sessions and also because I'm not that much in terms of time.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of these?",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simulation advances are actually more to say about.",
                    "label": 0
                },
                {
                    "sent": "Statistical inference than than mere gains in efficiency.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One of the main points I want to stress before moving to the last part.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Well, it's clear that the more legitimate interpretation of ABC is not a computational interpretation, but rather a nonparametric interpretation is like umbraco likelihoods, because we don't access, we don't have access to the to the true likelihood where using XO simulation methods to produce approximation to the true likelihood and those approximations can be interpreted as nonparametric.",
                    "label": 0
                },
                {
                    "sent": "Interpretation so from the beginning of ABC they were uses of of nonparametric methods specially in this important paper by Mark Como and courses virtually what's more important.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "One we are using simulations from.",
                    "label": 0
                },
                {
                    "sent": "Simsim transforms of the data through this summary statistics were actually trying to get to an approximation of Pi of Cedar given eater of war and being able to simulate this summary statistics is providing this kind of system.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's why that's how I made sense for myself, at least of this curve.",
                    "label": 0
                },
                {
                    "sent": "For dimensionality, we are dealing with a nonparametric problem and therefore we cannot hope with a given amount of computational power to get good approximation of the whole question distribution of Cedar given the data.",
                    "label": 0
                },
                {
                    "sent": "At best we can get a few dimensions because nonparametric estimation gets quickly terrible as a dimension.",
                    "label": 0
                },
                {
                    "sent": "Increases.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and so is there a few papers in the recent literatures that explore this direction.",
                    "label": 0
                },
                {
                    "sent": "And including Michael Blum will give one of the talks in the ABC sessions.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I won't say too much.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That, but what ABC is doing is using one kernel or another.",
                    "label": 0
                },
                {
                    "sent": "The basic kernel is indicator is providing a similar of Pi of Sita given eater of Y using those simulations and therefore that explain.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the the error can be evaluated, namely that.",
                    "label": 0
                },
                {
                    "sent": "The range of the error is for the bias in terms of of bsquare.",
                    "label": 0
                },
                {
                    "sent": "If B is deterrence and the variance is 1 / B, Delta D and so the D is, here is an acting upon the violence and there is not much we can do as the increases.",
                    "label": 0
                },
                {
                    "sent": "Except seeing their increasing as well.",
                    "label": 0
                },
                {
                    "sent": "OK so these are skipped.",
                    "label": 0
                },
                {
                    "sent": "So hard to skip MCMC, but I will.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To move to the to the last part.",
                    "label": 0
                },
                {
                    "sent": "And to go it's it's more of a video of literature than than anything new, but I'm trying to replace ABC in the inference word rather than the computing world.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You may have seen this this this slide a few minutes ago.",
                    "label": 0
                },
                {
                    "sent": "I'm just repeating the same thing that so far and we cannot get much further than that.",
                    "label": 0
                },
                {
                    "sent": "ABC has been justified as a convergent method, or in some cases has been justified as a convergence method.",
                    "label": 0
                },
                {
                    "sent": "Are the simulation approximation method.",
                    "label": 0
                },
                {
                    "sent": "It requires further simulations too given given iteration of the approximation except when we start looking at the nonparametric perspective, in which case we don't need to run more simulations.",
                    "label": 0
                },
                {
                    "sent": "Now while being pragmatic relies on the lots of calibration issues we have to pick the summary statistics and from there we have to pick the distances and also the tolerance.",
                    "label": 0
                },
                {
                    "sent": "And in connection with the nonparametric perspective and as stressed in the in the recent Red Paper by Paul from head and Dennis Prangle.",
                    "label": 0
                },
                {
                    "sent": "Pushing epsilon exactly to 0 or as close as possible to zero in that respect may not be the optimal ID because we are losing.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, a certain amount of simulations, but you're also increasing violence by trying to reduce the bias.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you're using ABC, may be dangerous to your.",
                    "label": 0
                },
                {
                    "sent": "Maybe not turn off, but inference.",
                    "label": 0
                },
                {
                    "sent": "Without warnings from the general.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Urgent or.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ever.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me go through a few points.",
                    "label": 0
                },
                {
                    "sent": "A few papers that that relates to this ID and one important paper in this respect is the PNS paper by early Redmond and courses.",
                    "label": 0
                },
                {
                    "sent": "Where, because epsilon is both essential and in a terrible nuisance because it doesn't appear in the original problem.",
                    "label": 0
                },
                {
                    "sent": "They included epsilon into the picture by drawing inference not only on theater but also on epsilon.",
                    "label": 0
                },
                {
                    "sent": "And so they used.",
                    "label": 0
                },
                {
                    "sent": "Particle approach to do that by putting a prior Absolon.",
                    "label": 0
                },
                {
                    "sent": "And transforming the.",
                    "label": 0
                },
                {
                    "sent": "Likelihood into a function on Epson's website, and became part partly the error on the method and partly the variation of the data around the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so because this is not exactly available there is a non parametric approximation involved at this level as well.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then in the technique, I don't go through the technique.",
                    "label": 0
                },
                {
                    "sent": "For lack of time but.",
                    "label": 0
                },
                {
                    "sent": "It's it's shooting.",
                    "label": 0
                },
                {
                    "sent": "MCMC to move around with this trick, that that's all tricks.",
                    "label": 0
                },
                {
                    "sent": "The first one is that the distances do not.",
                    "label": 0
                },
                {
                    "sent": "Summarize into a 1 dimensional object any longer and that the strength of the message.",
                    "label": 0
                },
                {
                    "sent": "There are many distances altogether, and so epsilon becomes a multi dimensional object.",
                    "label": 0
                },
                {
                    "sent": "The distances can be negative, which is interesting for distances, but that's another positive point being negative right?",
                    "label": 0
                },
                {
                    "sent": "And the last point is that because there are so many several directions.",
                    "label": 0
                },
                {
                    "sent": "The distribution on this directions are summarized into a minimum, which is another unusual object into into the picture.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And from this intuition of new objects, they get a way to compare models as well, because each of the direction.",
                    "label": 0
                },
                {
                    "sent": "So this is stolen from the paper with permission.",
                    "label": 0
                },
                {
                    "sent": "From each of the directions of the errors, you can build a distribution percent distribution, absolute perspective.",
                    "label": 0
                },
                {
                    "sent": "Distribution of these errors and compare what happens in different models to spot the model that is behaving strangely, namely, is avoiding 0 value that relates to our epsilon equals zero justification of ABC.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I think I will keep that and.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add a few questions.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's keep the questions.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, another approach that.",
                    "label": 0
                },
                {
                    "sent": "Started with Richard Wilkinson in Season 8 but that has been found in in many papers subsequently is the fact that somehow ABC can be Inter turn into what I got an exact BC?",
                    "label": 0
                },
                {
                    "sent": "Although it's not exactly an exact PC.",
                    "label": 0
                },
                {
                    "sent": "That makes me.",
                    "label": 0
                },
                {
                    "sent": "When you look at this pseudo object that is connected with the product of our simulations, we're simulating from pie Cedar from pie.",
                    "label": 0
                },
                {
                    "sent": "Then we're seeming to data from the true likelihood, and then because we cannot wait, we have this weight that is 01 in the original ABC, or that is a kernel of any flavor.",
                    "label": 0
                },
                {
                    "sent": "In the general case with.",
                    "label": 0
                },
                {
                    "sent": "Terms of silent.",
                    "label": 0
                },
                {
                    "sent": "So when you get things from that way.",
                    "label": 0
                },
                {
                    "sent": "This looks like a true posterior, but from another.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution, then the true distribution.",
                    "label": 0
                },
                {
                    "sent": "Namely, there is a combination between the F and the key.",
                    "label": 0
                },
                {
                    "sent": "You can look at F of Z given seed at times K of Y -- Z as.",
                    "label": 0
                },
                {
                    "sent": "The new distribution.",
                    "label": 0
                },
                {
                    "sent": "And that means that.",
                    "label": 0
                },
                {
                    "sent": "ABC is exact, but for the wrong problem.",
                    "label": 0
                },
                {
                    "sent": "So we're just asking the wrong question, but then we get the right solution.",
                    "label": 0
                },
                {
                    "sent": "So if we do that.",
                    "label": 0
                },
                {
                    "sent": "It's as if we were getting observations that on noise noisy means that Rob Salvation is why Tilda from F of Y~ given sera, but then.",
                    "label": 0
                },
                {
                    "sent": "Because without observe Y2DY will survive is noise.",
                    "label": 0
                },
                {
                    "sent": "Aside from keep silent, we do get this convolution.",
                    "label": 0
                },
                {
                    "sent": "Term into the posterior.",
                    "label": 0
                },
                {
                    "sent": "OK, so in that respect ABC is an exact Bayesian computation, but for noisy model.",
                    "label": 0
                },
                {
                    "sent": "And of course this has drawbacks.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a perspective, because rather than saying that.",
                    "label": 0
                },
                {
                    "sent": "It's measurement errors that would be fine, but to make it work you have to say that is it is a model error and then using.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This K as the position of the model error becomes difficult to justify in.",
                    "label": 0
                },
                {
                    "sent": "In a conversation, right?",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, of course.",
                    "label": 0
                },
                {
                    "sent": "Pros and cons to dad.",
                    "label": 0
                },
                {
                    "sent": "The cons are that.",
                    "label": 0
                },
                {
                    "sent": "It's still a fake model inside the case totally artificial.",
                    "label": 0
                },
                {
                    "sent": "You cannot start justifying that your normal or whatever kernel has anything to do with the truth and illusion.",
                    "label": 0
                },
                {
                    "sent": "You have to modify the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let me re exact to yet another paper where where things get closer to the picture.",
                    "label": 0
                },
                {
                    "sent": "It's a recent paperback by dinner at all.",
                    "label": 0
                },
                {
                    "sent": "Are focusing on on this specific model of hidden Markov models, so it also relates to Mikes talks where you observe a sequence that is indexed by a none observed Markov chain.",
                    "label": 0
                },
                {
                    "sent": "An ABC in this setup is built in a way that the simulated data.",
                    "label": 0
                },
                {
                    "sent": "Is forced to belong to an intersection of balls around the true data.",
                    "label": 0
                },
                {
                    "sent": "So we only accept simulations where why one is close enough to why one not you observed Y one up to YN close enough to Wyandot.",
                    "label": 0
                },
                {
                    "sent": "So that makes for a very restrictive distance because that's essentially comparing each simulation with each point in the series, and so it cannot work when N gets very large, but that's the price to pay for us.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Series of interesting results.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That relate to both these aspects that ABC could be exact.",
                    "label": 0
                },
                {
                    "sent": "If we look at it from another side of the mirror, an also for its convergence when the length of the series goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So again, they have this the same remark that if you, for instance defines the ABC, Emily, that is the first outcome of the simulation.",
                    "label": 0
                },
                {
                    "sent": "Trying to take these procedures that produce the most.",
                    "label": 0
                },
                {
                    "sent": "The highest rate of success in this acceptance.",
                    "label": 0
                },
                {
                    "sent": "It is an exact Emily.",
                    "label": 0
                },
                {
                    "sent": "If we use a convoluted version, which in that case makes certainly makes a bit more sense because it's like you had the series an you drew.",
                    "label": 0
                },
                {
                    "sent": "A tube around the original series and you could shake the series inside the tube so you have tolerance that is transformed into a measurement error of epsilon in that case.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For for the noisy or shaky.",
                    "label": 0
                },
                {
                    "sent": "Series you get exact inference, and that's an error in observation type of model that started being rather commendable.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there are different similar types of results, namely that.",
                    "label": 0
                },
                {
                    "sent": "If you look at your model ABC, even when N goes to Infinity, ABC Emily is bust, but if.",
                    "label": 0
                },
                {
                    "sent": "You start decreasing epsilon towards a smaller value.",
                    "label": 0
                },
                {
                    "sent": "Get this convergence to the information to the converted likelihood as fear and then goes to Infinity.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "From this perspective it's like replays are true data.",
                    "label": 0
                },
                {
                    "sent": "With this noisy version and then you get regular vision inference and so that's one of the conclusions of the paper, and from there we start seeing where.",
                    "label": 0
                },
                {
                    "sent": "The connection between vision inference and this ABC perspective could happen, namely that by accepting to throw away this precision on the data, you do recover an exact type of inference.",
                    "label": 0
                },
                {
                    "sent": "Again, that's a bit against the original principles that why should we throw away information?",
                    "label": 0
                },
                {
                    "sent": "By roughening up the data, but that's the price to pay that.",
                    "label": 0
                },
                {
                    "sent": "If we accept that we cannot get to this ultimate precision that the whole information.",
                    "label": 0
                },
                {
                    "sent": "Is not attainable.",
                    "label": 0
                },
                {
                    "sent": "Then why not doing that and still being basean?",
                    "label": 0
                },
                {
                    "sent": "And throw the egg away.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so in the paper they do get.",
                    "label": 0
                },
                {
                    "sent": "Consistency result for the noisy version.",
                    "label": 0
                },
                {
                    "sent": "No, I mean it's not like all nice and rosy.",
                    "label": 0
                },
                {
                    "sent": "And things are deteriorating very quickly as an grows because the paper is using.",
                    "label": 0
                },
                {
                    "sent": "Problem that is of dimension N. So this kind of transist the increase of N. But as a principle I find I find the paper fairly interesting.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can see.",
                    "label": 0
                },
                {
                    "sent": "There are two five that means 10, right?",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now I'm I just have one oversized left, so I'm almost done.",
                    "label": 0
                },
                {
                    "sent": "And I'll skip most of them.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "I read the like the final final question.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "When we try to implement ABC.",
                    "label": 0
                },
                {
                    "sent": "There are very few cases where.",
                    "label": 0
                },
                {
                    "sent": "We can use the whole data so we have to pick a summary statistics.",
                    "label": 0
                },
                {
                    "sent": "Because of the size of the data, there is no way we can produce computable version without reducing the data into a small vector of summary statistics and therefore it's.",
                    "label": 1
                },
                {
                    "sent": "It's an interesting problem that we need to find.",
                    "label": 1
                },
                {
                    "sent": "The optimal summary statistics for for conducting this approximation to the true posterior.",
                    "label": 0
                },
                {
                    "sent": "An there are cases where.",
                    "label": 0
                },
                {
                    "sent": "It's so relevant that Mrs.",
                    "label": 0
                },
                {
                    "sent": "Choice of summer.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Autistic that depending on the choice we do get consistency or not.",
                    "label": 0
                },
                {
                    "sent": "And so we have a series of two papers.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of which do this would present in a few days where.",
                    "label": 0
                },
                {
                    "sent": "Actually, they picking the wrong summary statistics.",
                    "label": 0
                },
                {
                    "sent": "The base factor when comparing two models will not be consistent.",
                    "label": 0
                },
                {
                    "sent": "We will not pick even when angles to Infinity pick the right model, but we will pick the simplest model, for instance.",
                    "label": 0
                },
                {
                    "sent": "And that 4 bit for Model Choice proposes the equivalent for for estimation.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so in connection with that there is again this Red Paper I just I mentioned a few minutes ago by Profan head and Dennis Prangle.",
                    "label": 1
                },
                {
                    "sent": "That studies among all possible choices of summary statistics.",
                    "label": 1
                },
                {
                    "sent": "Which one makes the most sense for contacting ABC?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "I won't discuss the paper.",
                    "label": 0
                },
                {
                    "sent": "First cutoff time and second because he's not my paper, but.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The summary of the paper about the summary statistics is that.",
                    "label": 0
                },
                {
                    "sent": "The very interesting result in the very beige and result is that the optimal summary statistics is the basic general E of cheetah given one, and it has many.",
                    "label": 0
                },
                {
                    "sent": "Interesting features first is vision.",
                    "label": 0
                },
                {
                    "sent": "Second one is that it's exactly this dimension of Sita, so you have not.",
                    "label": 0
                },
                {
                    "sent": "Any extravagant entry in the summary statistic is just the best.",
                    "label": 0
                },
                {
                    "sent": "Possible entry it's the size of soda and nothing, nothing else.",
                    "label": 0
                },
                {
                    "sent": "There is just one.",
                    "label": 0
                },
                {
                    "sent": "Downside, which is that that's exactly what we try to approximate, so we don't have this summary statistic, and so in fact to be pragmatic and practical, we're first to approximate this summary statistic before conducting the ABC.",
                    "label": 0
                },
                {
                    "sent": "And the other.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the paper.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that deals with the errors contained in ABC, I mean it's throwing away this idea that we are losing information.",
                    "label": 0
                },
                {
                    "sent": "By getting going from Y to this summary statistic, but otherwise it compares the approximation due to the conversation to the approximation due to Monte Carlo and it recovers.",
                    "label": 0
                },
                {
                    "sent": "Somewhere.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Nonparametric error I've already mentioned through this kind of variation of of the error somewhere is here.",
                    "label": 0
                },
                {
                    "sent": "So we do recover the nonparametric speed that we had previously.",
                    "label": 0
                },
                {
                    "sent": "And then there is a side result that all versions should appreciate.",
                    "label": 0
                },
                {
                    "sent": "Namely that if you use this.",
                    "label": 0
                },
                {
                    "sent": "As a summary statistic, it doesn't have to be sufficient because you don't have to be in an exponential family model, but it is almost sufficient in the sense that the expectation of Sita given S of Y is always the expectation of Sita given one.",
                    "label": 0
                },
                {
                    "sent": "And it took me awhile to believe in that, but it's true, and so it's really well, OK. Now.",
                    "label": 0
                },
                {
                    "sent": "It's not a perfect message, and I think I'll stop here.",
                    "label": 0
                },
                {
                    "sent": "Add more about the discussion, but you can look at the slides on the web.",
                    "label": 0
                },
                {
                    "sent": "The point is that through the recent literature.",
                    "label": 0
                },
                {
                    "sent": "When's the decisions became?",
                    "label": 0
                },
                {
                    "sent": "As interested in the methods as population geneticists.",
                    "label": 0
                },
                {
                    "sent": "It became obvious that.",
                    "label": 0
                },
                {
                    "sent": "There was more to the message than just a crucial trick.",
                    "label": 0
                },
                {
                    "sent": "That look fairly dirty.",
                    "label": 0
                },
                {
                    "sent": "It's it's a way to handle complex models.",
                    "label": 0
                },
                {
                    "sent": "An to go over either the complexity of the data, the complexity of the parameter.",
                    "label": 1
                },
                {
                    "sent": "Or are the partial information about the model an my impression at the moment is that it's it's totally soluble in the Bayesian approach by rewarding the whole thing as as a new model rather than seeing it as an approximation to the exact model, because in a sense.",
                    "label": 0
                },
                {
                    "sent": "All mothers are wrong, but some other useful.",
                    "label": 0
                },
                {
                    "sent": "Well, some methods are more useful than others.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Any credit whoops.",
                    "label": 0
                },
                {
                    "sent": "It's OK, you can do any questions for Christian.",
                    "label": 0
                },
                {
                    "sent": "Comments.",
                    "label": 0
                },
                {
                    "sent": "We have some minutes time if somebody.",
                    "label": 0
                },
                {
                    "sent": "You just believed it all.",
                    "label": 0
                },
                {
                    "sent": "So so in theory I guess you owe some questions somewhere.",
                    "label": 0
                },
                {
                    "sent": "Oh, can you please go down to the microphone?",
                    "label": 0
                },
                {
                    "sent": "Hi, you mentioned that using Bayes factor may lead to picking the simplest model.",
                    "label": 0
                },
                {
                    "sent": "Could you please explain it a little?",
                    "label": 0
                },
                {
                    "sent": "You mentioned two references in 2012, so there will be a talk on.",
                    "label": 0
                },
                {
                    "sent": "On Wednesday on that paper, but essentially if.",
                    "label": 0
                },
                {
                    "sent": "Your summary statistic behaves the same.",
                    "label": 0
                },
                {
                    "sent": "Or could behave the same in the bus models, then drink inference using only these summary statistics will lead to an agreement of the data with each of the models.",
                    "label": 0
                },
                {
                    "sent": "Whether that is true or not, we not matter because you only look at the summary statistic and so you will get an agreement for Model A and for Model B an in that case because there is agreement for both models, the one which wins is the smallest, simplest one.",
                    "label": 0
                },
                {
                    "sent": "So that's that's when the caller ID in this paper that to make discriminants separation between models using a summary statistic, it must behave differently under both models, so that you cannot recover the parameter under the wrong model.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Other question on race or.",
                    "label": 0
                },
                {
                    "sent": "Somewhere down there.",
                    "label": 0
                },
                {
                    "sent": "Any other comments?",
                    "label": 0
                },
                {
                    "sent": "Well, uh oh.",
                    "label": 0
                },
                {
                    "sent": "Hi Christian, very interesting talk in in the tradition of looking at Bayesian modeling as a model for how rational people think.",
                    "label": 0
                },
                {
                    "sent": "Do you think that the ABC that you have been talking about could model how deterministic modelers try to get their models close to the?",
                    "label": 0
                },
                {
                    "sent": "The data with noise, so some summary statistic.",
                    "label": 0
                },
                {
                    "sent": "Of the data.",
                    "label": 0
                },
                {
                    "sent": "I'm not sad at all.",
                    "label": 0
                },
                {
                    "sent": "Just to make an objection for the sake of objection.",
                    "label": 0
                },
                {
                    "sent": "As usual, is.",
                    "label": 0
                },
                {
                    "sent": "Obviously the calibration then of ABC could could get into the way by.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's the noise.",
                    "label": 0
                },
                {
                    "sent": "Would be a choice of the tradition, not of the modeler, and so it it it.",
                    "label": 0
                },
                {
                    "sent": "I mean, the choice of a camel.",
                    "label": 0
                },
                {
                    "sent": "Good.",
                    "label": 0
                },
                {
                    "sent": "Could just not get things right.",
                    "label": 0
                },
                {
                    "sent": "I don't know, just this could be an issue.",
                    "label": 0
                },
                {
                    "sent": "But I mean, that's that's an interesting direction.",
                    "label": 0
                },
                {
                    "sent": "Left Christian speechless.",
                    "label": 0
                },
                {
                    "sent": "Pretty good.",
                    "label": 0
                },
                {
                    "sent": "Any other comments?",
                    "label": 0
                },
                {
                    "sent": "I'm interested in some of the population genetics examples, so do you have any in the light of your discussion of the different approaches and methods?",
                    "label": 0
                },
                {
                    "sent": "Can you sort of?",
                    "label": 0
                },
                {
                    "sent": "Just say how good some of those previous results are or or are they sort of cast into question.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, let me answer another question.",
                    "label": 0
                },
                {
                    "sent": "Just to link with the model choice issue.",
                    "label": 0
                },
                {
                    "sent": "For instance, that.",
                    "label": 1
                },
                {
                    "sent": "A lot of the population genetic literature has been comparing scenarios.",
                    "label": 0
                },
                {
                    "sent": "And of course they used whatever summary statistics you had there.",
                    "label": 0
                },
                {
                    "sent": "At the hands, right?",
                    "label": 0
                },
                {
                    "sent": "When we looked at some of the papers, actually it, it happens that there were always a component in this summary statistics that was able to make the difference between the models.",
                    "label": 0
                },
                {
                    "sent": "So although there was no formal checking that.",
                    "label": 0
                },
                {
                    "sent": "It was leading to the proper discrimination in practice.",
                    "label": 0
                },
                {
                    "sent": "In the cases we looked at it wells.",
                    "label": 0
                },
                {
                    "sent": "Not really answering your question with.",
                    "label": 0
                },
                {
                    "sent": "Anymore.",
                    "label": 0
                },
                {
                    "sent": "Urgent questions.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we have a bus to catch eventually.",
                    "label": 0
                },
                {
                    "sent": "Let's move on.",
                    "label": 0
                },
                {
                    "sent": "Also, let's Vanquish are again thank you.",
                    "label": 0
                }
            ]
        }
    }
}