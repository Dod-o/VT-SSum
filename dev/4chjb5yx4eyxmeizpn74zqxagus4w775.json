{
    "id": "4chjb5yx4eyxmeizpn74zqxagus4w775",
    "title": "A Scalable Framework for Quality Assessment of RDF Datasets",
    "info": {
        "author": [
            "Jens Lehmann, Department of Business Information Systems, University of Leipzig"
        ],
        "published": "Dec. 10, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_lehmann_quality_assessment/",
    "segmentation": [
        [
            "Have thanks a lot and welcome everyone who made it through this session in a slightly remote room here.",
            "So today I'm presenting your work on scalable data quality assessment for RDF datasets.",
            "The original presenter of this presentation could not make it because of visa issues, so I'm jumping in here and the first start with."
        ],
        [
            "The motivations of why are we doing this work?",
            "So there are two factors essentially on the one side, we've seen increase in the size of RDF datasets over the past years.",
            "And."
        ],
        [
            "As measured, for instance by a lot starts, which shows more than 10,000 datasets, some of them very large but also an increasing number of datasets inside of companies.",
            "So that's one factor."
        ],
        [
            "The other factor is the importance of data quality assessment, so we are in the second data quality session here at the conference.",
            "So I think generally people believe this topic is important.",
            "So you need data quality measurements to assess."
        ],
        [
            "Is whether not if data set is fit fit for particular use case?",
            "So in previous work that we're usually 4 dimensions of data quality.",
            "As you can see on the slide here and for each of those different metrics which are defined in those metrics are basically computations which can be carried out over the data set.",
            "Then you get some results which allow you to analyze and assess your data set.",
            "And yeah, this allows to judge data quality."
        ],
        [
            "However, so far all of the existing tools basically do not scale to larger knowledge graphs, and that's exactly the contribution we make here.",
            "So we provide a software framework so it's a resource paper for quality assessment of large RDF datasets."
        ],
        [
            "So to do this, we implement in an approach in sons.",
            "A son says framework which combines distributed in memory computing and the semantic web stack.",
            "So for distributed memory computing, there are frameworks like Apache, Spark and Flink.",
            "So who in the audience knows Apache Spark?",
            "So approximately half of you.",
            "So that's that's a good sign.",
            "So essentially Apache Spark is a framework.",
            "Which allows to work with large datasets.",
            "Those datasets are first read in distributed on several nodes in the cluster, and then they can be processed.",
            "On each cluster, on each node in the cluster, and usually in memory.",
            "That's a big advantage compared to previous frameworks, like a map reduce.",
            "So the Suns, a framework built on top of Apache Spark and Flink in a layer here and then provides various.",
            "Functionality on top of this for clearing inference and machine learning.",
            "And exactly in this part we integrate our data quality assessment techniques.",
            "So how do those?"
        ],
        [
            "Techniques worked, so we first introduced a new notion of quality assessment patterns or QA piece.",
            "Which consist of transformations and actions.",
            "So you can see an example.",
            "Down here, so essentially transformation are either so called rules like checking whether some things and I with us in internal and internal resource in an RDF data set, external and so on.",
            "So there are many.",
            "Different functions which can be used and you can also combine multiple.",
            "Transformations like here you have a union of two transformations.",
            "Yeah, and.",
            "There are some shortcuts here like like SPO, which which retrieve subject predicate object given an RDF triple.",
            "So essentially, those transformations allow you to take an RDF data set as input.",
            "And process it and return another idea of data set as output.",
            "So of course the paper contains all the more formal details of how those transformations work.",
            "Once series of transformations has been performed, you can apply actions on top of this, so those are usually methods which.",
            "Compute numerical values, for instance for instinct account.",
            "Here, the size of the final transformation, count the number of triples in the data set, and then you perform this division.",
            "So essentially, data quality metrics can be expressed via those transformations and actions.",
            "So the details here maybe not the most important thing, but what is actually important is that those QPS as we."
        ],
        [
            "Find them in the paper, cover the data quality metrics defined in previous work.",
            "Now that's a paper on boots, which is a data quality assessment framework.",
            "So all of the metrics which are defined in there can be expressed using those Q APS.",
            "And due to the way we defined QPS, they can be transformed to Apache Spark code for execution.",
            "So once you have.",
            "You find your QA piece and into."
        ],
        [
            "There are a few examples in this table.",
            "They can be transformed and to code which is.",
            "Which can be executed in a distributed manner.",
            "And yeah, that's that's the main.",
            "That's the core of the software framework, which we provide here."
        ],
        [
            "So how does the approach work?",
            "So assume you have an RDF data set.",
            "You first read it into your file system.",
            "That's in this case the Hadoop file system because you want to work on on the cluster."
        ],
        [
            "So then you can define quality, dimensions and metrics.",
            "As I've just shown, at least to some extent on the previous slide.",
            "So once you have defined them, you can start."
        ],
        [
            "Processings as I set everything runs inside of this answer engine, which first reads in the RDF data set.",
            "So Apache Spark performs lazy execution that only.",
            "Performs those steps which are actually needed later on."
        ],
        [
            "Then those QoS are executed on the cluster on multiple nodes and.",
            "The final actions return results of their quality metrics."
        ],
        [
            "And because of the integration inzunza, you can visualize the results in on notebooks.",
            "So I guess many of you are familiar with Jupyter notebooks, separate notebooks and so on, so you can.",
            "I'm analyzing the results here in a similar way.",
            "But we can also store the results in a vocabulary data quality vocabulary which is currently working.",
            "Note by W3C.",
            "So we have some standardized output for the different data quality metrics."
        ],
        [
            "So that's how the approach works in general.",
            "And of course the interesting aspect here is how well does it scale, actually.",
            "So we measured this on a cluster with six worker nodes.",
            "With more or less average hardware nowadays, so 128 gigabytes RAM to have TB disk and 32 cores.",
            "So we use three benchmark datasets being geodata which is an RDF version of Open Street map.",
            "Wendy Peter in different language version.",
            "And PS PM distance for the Berlin sparkle benchmark.",
            "So that's a benchmark data set generator, so we use this because here we can change the size of the data set and scale it up to different volumes in order to evaluate the approach."
        ],
        [
            "So here are some of the results we are getting, so they actually not many frameworks we can compare against.",
            "So at the time of writing the paper.",
            "Only the loot, so framework was available and.",
            "Is a generic idea of data quality assessment framework.",
            "There are other approaches which are more specific for particular metrics, but here we wanted to look at frameworks which allowed to express metrics.",
            "More generally.",
            "And as I said, we rent this over multiple datasets, link share data, view PTR, different size of the PCM benchmark.",
            "And in doing so, there are two different operating modes.",
            "First, you can run all the metrics individually.",
            "And that's this column here and then you can also jointly run all the metrics.",
            "It's a streaming approach.",
            "And each basically when each table is possessed, calculates all the metrics at this particular point.",
            "So we used the same metrics for evaluation which are also in boots or so.",
            "We don't actually contribute any new quality metrics, so it just needs exactly the same ones but implement them by our QA piece.",
            "And those are the performance results we get.",
            "So the runtime here is in minutes.",
            "So we can see that lutsu essentially works on smaller scale datasets.",
            "But it fails for all the larger datasets, so that's what I initially said.",
            "I mean there are.",
            "Currently no at generic RDF data quality assessment frameworks which scale to those larger datasets.",
            "So when we compare against.",
            "Results of our approach.",
            "We can see that we are quite substantially faster.",
            "So this column here is a local execution, so we just use a single node in the cluster and the other one is the execution with six worker nodes and the hardware configuration I've shown on the previous slide.",
            "So what we can also see that there's quite a dramatic improvement in some cases when you move from a single node to multiple nodes.",
            "The main reason is that.",
            "6 broken notes that could happen that the entire data set fits into memory.",
            "And if this is the case then basically Apache Spark works very efficiently because it never has to spill data to disk.",
            "So.",
            "Yeah, I think that's those are the main average."
        ],
        [
            "Results versus Lucy.",
            "Guess other framework.",
            "Then of course we also want to have a look at how it scales when we grow the number of worker nodes and when we grow the datasets.",
            "So for this we used the Berlin Sparkle benchmark where you can change the data set size and we observed.",
            "The runtime.",
            "And for particular data set size with respect to several data quality metrics.",
            "So those are seven matrix which the details of which you can find in the paper.",
            "Which what you can see is.",
            "That you have an roughly exponential scale on the X axis here and.",
            "The runtime of the approach grows approximately linear with the with the size of the input data set.",
            "That's exactly how it should be when you use a distributed computing approach.",
            "So in this case, we can say that in terms of size or performance the approach works and scales to larger datasets.",
            "So we also looked at."
        ],
        [
            "What happens when we work with different number of nodes in the cluster?",
            "So far we checked one up to six.",
            "Broker notes and as you can see, there's a dramatic performance improvement when adding further notes.",
            "So in terms of scalability evaluation, we also didn't observe any major issues, so the matrix which we implemented by our QPS.",
            "Actually also scale well when you increase the cluster size.",
            "OK, as a further evaluation we looked at a few individual metrics."
        ],
        [
            "Other main thing be source that."
        ],
        [
            "We mainly face issues when when the metrics require shuffling data between nodes in the cluster.",
            "This usually happens when the matrix have to use some sort of joints between.",
            "At parts of the input data set.",
            "So that's not not too surprising, I would say."
        ],
        [
            "So this is a set of software framework paper and it's used in three different projects.",
            "At the moment, one is the crowd project, which is an European Union project for crowdsourcing big data.",
            "Twist and then it's and our approach is news for quality assessment within this project.",
            "Then there's another company, Alethia, which analyzed the blockchain data set, which consists of 7 terabytes of data, and I think we're 18 billion triples.",
            "And they used our approach on 100 broker notes and also obtained very quick results.",
            "And the third approach is on spatial data.",
            "So there those checks were used before when used for fusing multiple datasets and analyzing.",
            "The individual data sets before they are fused."
        ],
        [
            "So OK to sum up our contributions, we.",
            "Undefined QA piece for quality metrics.",
            "We provide an open source framework which.",
            "Can perform scalable RDF data quality assessment.",
            "It's integrated into his answer so we also have an active community and it will be maintained for many years to come.",
            "And the approach outperformed and competing approach on three benchmarks.",
            "And it also showed good performance in terms of scaleability with respect to data set size and cluster size.",
            "So you can try out the approach yourself.",
            "Everything is open source, and yeah, that's that's it from my side and I'm happy for any feedback.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have thanks a lot and welcome everyone who made it through this session in a slightly remote room here.",
                    "label": 0
                },
                {
                    "sent": "So today I'm presenting your work on scalable data quality assessment for RDF datasets.",
                    "label": 1
                },
                {
                    "sent": "The original presenter of this presentation could not make it because of visa issues, so I'm jumping in here and the first start with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The motivations of why are we doing this work?",
                    "label": 0
                },
                {
                    "sent": "So there are two factors essentially on the one side, we've seen increase in the size of RDF datasets over the past years.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As measured, for instance by a lot starts, which shows more than 10,000 datasets, some of them very large but also an increasing number of datasets inside of companies.",
                    "label": 0
                },
                {
                    "sent": "So that's one factor.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other factor is the importance of data quality assessment, so we are in the second data quality session here at the conference.",
                    "label": 1
                },
                {
                    "sent": "So I think generally people believe this topic is important.",
                    "label": 0
                },
                {
                    "sent": "So you need data quality measurements to assess.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is whether not if data set is fit fit for particular use case?",
                    "label": 1
                },
                {
                    "sent": "So in previous work that we're usually 4 dimensions of data quality.",
                    "label": 0
                },
                {
                    "sent": "As you can see on the slide here and for each of those different metrics which are defined in those metrics are basically computations which can be carried out over the data set.",
                    "label": 0
                },
                {
                    "sent": "Then you get some results which allow you to analyze and assess your data set.",
                    "label": 1
                },
                {
                    "sent": "And yeah, this allows to judge data quality.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, so far all of the existing tools basically do not scale to larger knowledge graphs, and that's exactly the contribution we make here.",
                    "label": 0
                },
                {
                    "sent": "So we provide a software framework so it's a resource paper for quality assessment of large RDF datasets.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to do this, we implement in an approach in sons.",
                    "label": 0
                },
                {
                    "sent": "A son says framework which combines distributed in memory computing and the semantic web stack.",
                    "label": 0
                },
                {
                    "sent": "So for distributed memory computing, there are frameworks like Apache, Spark and Flink.",
                    "label": 0
                },
                {
                    "sent": "So who in the audience knows Apache Spark?",
                    "label": 0
                },
                {
                    "sent": "So approximately half of you.",
                    "label": 0
                },
                {
                    "sent": "So that's that's a good sign.",
                    "label": 0
                },
                {
                    "sent": "So essentially Apache Spark is a framework.",
                    "label": 0
                },
                {
                    "sent": "Which allows to work with large datasets.",
                    "label": 0
                },
                {
                    "sent": "Those datasets are first read in distributed on several nodes in the cluster, and then they can be processed.",
                    "label": 0
                },
                {
                    "sent": "On each cluster, on each node in the cluster, and usually in memory.",
                    "label": 0
                },
                {
                    "sent": "That's a big advantage compared to previous frameworks, like a map reduce.",
                    "label": 0
                },
                {
                    "sent": "So the Suns, a framework built on top of Apache Spark and Flink in a layer here and then provides various.",
                    "label": 0
                },
                {
                    "sent": "Functionality on top of this for clearing inference and machine learning.",
                    "label": 0
                },
                {
                    "sent": "And exactly in this part we integrate our data quality assessment techniques.",
                    "label": 0
                },
                {
                    "sent": "So how do those?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Techniques worked, so we first introduced a new notion of quality assessment patterns or QA piece.",
                    "label": 1
                },
                {
                    "sent": "Which consist of transformations and actions.",
                    "label": 1
                },
                {
                    "sent": "So you can see an example.",
                    "label": 0
                },
                {
                    "sent": "Down here, so essentially transformation are either so called rules like checking whether some things and I with us in internal and internal resource in an RDF data set, external and so on.",
                    "label": 0
                },
                {
                    "sent": "So there are many.",
                    "label": 0
                },
                {
                    "sent": "Different functions which can be used and you can also combine multiple.",
                    "label": 0
                },
                {
                    "sent": "Transformations like here you have a union of two transformations.",
                    "label": 1
                },
                {
                    "sent": "Yeah, and.",
                    "label": 0
                },
                {
                    "sent": "There are some shortcuts here like like SPO, which which retrieve subject predicate object given an RDF triple.",
                    "label": 0
                },
                {
                    "sent": "So essentially, those transformations allow you to take an RDF data set as input.",
                    "label": 0
                },
                {
                    "sent": "And process it and return another idea of data set as output.",
                    "label": 0
                },
                {
                    "sent": "So of course the paper contains all the more formal details of how those transformations work.",
                    "label": 0
                },
                {
                    "sent": "Once series of transformations has been performed, you can apply actions on top of this, so those are usually methods which.",
                    "label": 0
                },
                {
                    "sent": "Compute numerical values, for instance for instinct account.",
                    "label": 0
                },
                {
                    "sent": "Here, the size of the final transformation, count the number of triples in the data set, and then you perform this division.",
                    "label": 0
                },
                {
                    "sent": "So essentially, data quality metrics can be expressed via those transformations and actions.",
                    "label": 0
                },
                {
                    "sent": "So the details here maybe not the most important thing, but what is actually important is that those QPS as we.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Find them in the paper, cover the data quality metrics defined in previous work.",
                    "label": 1
                },
                {
                    "sent": "Now that's a paper on boots, which is a data quality assessment framework.",
                    "label": 0
                },
                {
                    "sent": "So all of the metrics which are defined in there can be expressed using those Q APS.",
                    "label": 1
                },
                {
                    "sent": "And due to the way we defined QPS, they can be transformed to Apache Spark code for execution.",
                    "label": 0
                },
                {
                    "sent": "So once you have.",
                    "label": 0
                },
                {
                    "sent": "You find your QA piece and into.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are a few examples in this table.",
                    "label": 0
                },
                {
                    "sent": "They can be transformed and to code which is.",
                    "label": 0
                },
                {
                    "sent": "Which can be executed in a distributed manner.",
                    "label": 0
                },
                {
                    "sent": "And yeah, that's that's the main.",
                    "label": 0
                },
                {
                    "sent": "That's the core of the software framework, which we provide here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does the approach work?",
                    "label": 0
                },
                {
                    "sent": "So assume you have an RDF data set.",
                    "label": 1
                },
                {
                    "sent": "You first read it into your file system.",
                    "label": 0
                },
                {
                    "sent": "That's in this case the Hadoop file system because you want to work on on the cluster.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then you can define quality, dimensions and metrics.",
                    "label": 1
                },
                {
                    "sent": "As I've just shown, at least to some extent on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "So once you have defined them, you can start.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Processings as I set everything runs inside of this answer engine, which first reads in the RDF data set.",
                    "label": 0
                },
                {
                    "sent": "So Apache Spark performs lazy execution that only.",
                    "label": 0
                },
                {
                    "sent": "Performs those steps which are actually needed later on.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then those QoS are executed on the cluster on multiple nodes and.",
                    "label": 0
                },
                {
                    "sent": "The final actions return results of their quality metrics.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And because of the integration inzunza, you can visualize the results in on notebooks.",
                    "label": 0
                },
                {
                    "sent": "So I guess many of you are familiar with Jupyter notebooks, separate notebooks and so on, so you can.",
                    "label": 0
                },
                {
                    "sent": "I'm analyzing the results here in a similar way.",
                    "label": 0
                },
                {
                    "sent": "But we can also store the results in a vocabulary data quality vocabulary which is currently working.",
                    "label": 1
                },
                {
                    "sent": "Note by W3C.",
                    "label": 0
                },
                {
                    "sent": "So we have some standardized output for the different data quality metrics.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's how the approach works in general.",
                    "label": 0
                },
                {
                    "sent": "And of course the interesting aspect here is how well does it scale, actually.",
                    "label": 0
                },
                {
                    "sent": "So we measured this on a cluster with six worker nodes.",
                    "label": 0
                },
                {
                    "sent": "With more or less average hardware nowadays, so 128 gigabytes RAM to have TB disk and 32 cores.",
                    "label": 0
                },
                {
                    "sent": "So we use three benchmark datasets being geodata which is an RDF version of Open Street map.",
                    "label": 0
                },
                {
                    "sent": "Wendy Peter in different language version.",
                    "label": 0
                },
                {
                    "sent": "And PS PM distance for the Berlin sparkle benchmark.",
                    "label": 0
                },
                {
                    "sent": "So that's a benchmark data set generator, so we use this because here we can change the size of the data set and scale it up to different volumes in order to evaluate the approach.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some of the results we are getting, so they actually not many frameworks we can compare against.",
                    "label": 0
                },
                {
                    "sent": "So at the time of writing the paper.",
                    "label": 0
                },
                {
                    "sent": "Only the loot, so framework was available and.",
                    "label": 0
                },
                {
                    "sent": "Is a generic idea of data quality assessment framework.",
                    "label": 0
                },
                {
                    "sent": "There are other approaches which are more specific for particular metrics, but here we wanted to look at frameworks which allowed to express metrics.",
                    "label": 0
                },
                {
                    "sent": "More generally.",
                    "label": 0
                },
                {
                    "sent": "And as I said, we rent this over multiple datasets, link share data, view PTR, different size of the PCM benchmark.",
                    "label": 0
                },
                {
                    "sent": "And in doing so, there are two different operating modes.",
                    "label": 0
                },
                {
                    "sent": "First, you can run all the metrics individually.",
                    "label": 0
                },
                {
                    "sent": "And that's this column here and then you can also jointly run all the metrics.",
                    "label": 0
                },
                {
                    "sent": "It's a streaming approach.",
                    "label": 0
                },
                {
                    "sent": "And each basically when each table is possessed, calculates all the metrics at this particular point.",
                    "label": 0
                },
                {
                    "sent": "So we used the same metrics for evaluation which are also in boots or so.",
                    "label": 0
                },
                {
                    "sent": "We don't actually contribute any new quality metrics, so it just needs exactly the same ones but implement them by our QA piece.",
                    "label": 0
                },
                {
                    "sent": "And those are the performance results we get.",
                    "label": 0
                },
                {
                    "sent": "So the runtime here is in minutes.",
                    "label": 0
                },
                {
                    "sent": "So we can see that lutsu essentially works on smaller scale datasets.",
                    "label": 0
                },
                {
                    "sent": "But it fails for all the larger datasets, so that's what I initially said.",
                    "label": 0
                },
                {
                    "sent": "I mean there are.",
                    "label": 0
                },
                {
                    "sent": "Currently no at generic RDF data quality assessment frameworks which scale to those larger datasets.",
                    "label": 0
                },
                {
                    "sent": "So when we compare against.",
                    "label": 0
                },
                {
                    "sent": "Results of our approach.",
                    "label": 0
                },
                {
                    "sent": "We can see that we are quite substantially faster.",
                    "label": 0
                },
                {
                    "sent": "So this column here is a local execution, so we just use a single node in the cluster and the other one is the execution with six worker nodes and the hardware configuration I've shown on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "So what we can also see that there's quite a dramatic improvement in some cases when you move from a single node to multiple nodes.",
                    "label": 0
                },
                {
                    "sent": "The main reason is that.",
                    "label": 0
                },
                {
                    "sent": "6 broken notes that could happen that the entire data set fits into memory.",
                    "label": 0
                },
                {
                    "sent": "And if this is the case then basically Apache Spark works very efficiently because it never has to spill data to disk.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think that's those are the main average.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results versus Lucy.",
                    "label": 0
                },
                {
                    "sent": "Guess other framework.",
                    "label": 0
                },
                {
                    "sent": "Then of course we also want to have a look at how it scales when we grow the number of worker nodes and when we grow the datasets.",
                    "label": 0
                },
                {
                    "sent": "So for this we used the Berlin Sparkle benchmark where you can change the data set size and we observed.",
                    "label": 0
                },
                {
                    "sent": "The runtime.",
                    "label": 0
                },
                {
                    "sent": "And for particular data set size with respect to several data quality metrics.",
                    "label": 0
                },
                {
                    "sent": "So those are seven matrix which the details of which you can find in the paper.",
                    "label": 0
                },
                {
                    "sent": "Which what you can see is.",
                    "label": 0
                },
                {
                    "sent": "That you have an roughly exponential scale on the X axis here and.",
                    "label": 0
                },
                {
                    "sent": "The runtime of the approach grows approximately linear with the with the size of the input data set.",
                    "label": 0
                },
                {
                    "sent": "That's exactly how it should be when you use a distributed computing approach.",
                    "label": 0
                },
                {
                    "sent": "So in this case, we can say that in terms of size or performance the approach works and scales to larger datasets.",
                    "label": 0
                },
                {
                    "sent": "So we also looked at.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens when we work with different number of nodes in the cluster?",
                    "label": 0
                },
                {
                    "sent": "So far we checked one up to six.",
                    "label": 0
                },
                {
                    "sent": "Broker notes and as you can see, there's a dramatic performance improvement when adding further notes.",
                    "label": 0
                },
                {
                    "sent": "So in terms of scalability evaluation, we also didn't observe any major issues, so the matrix which we implemented by our QPS.",
                    "label": 0
                },
                {
                    "sent": "Actually also scale well when you increase the cluster size.",
                    "label": 0
                },
                {
                    "sent": "OK, as a further evaluation we looked at a few individual metrics.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other main thing be source that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We mainly face issues when when the metrics require shuffling data between nodes in the cluster.",
                    "label": 1
                },
                {
                    "sent": "This usually happens when the matrix have to use some sort of joints between.",
                    "label": 0
                },
                {
                    "sent": "At parts of the input data set.",
                    "label": 0
                },
                {
                    "sent": "So that's not not too surprising, I would say.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a set of software framework paper and it's used in three different projects.",
                    "label": 0
                },
                {
                    "sent": "At the moment, one is the crowd project, which is an European Union project for crowdsourcing big data.",
                    "label": 1
                },
                {
                    "sent": "Twist and then it's and our approach is news for quality assessment within this project.",
                    "label": 0
                },
                {
                    "sent": "Then there's another company, Alethia, which analyzed the blockchain data set, which consists of 7 terabytes of data, and I think we're 18 billion triples.",
                    "label": 0
                },
                {
                    "sent": "And they used our approach on 100 broker notes and also obtained very quick results.",
                    "label": 0
                },
                {
                    "sent": "And the third approach is on spatial data.",
                    "label": 0
                },
                {
                    "sent": "So there those checks were used before when used for fusing multiple datasets and analyzing.",
                    "label": 0
                },
                {
                    "sent": "The individual data sets before they are fused.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So OK to sum up our contributions, we.",
                    "label": 0
                },
                {
                    "sent": "Undefined QA piece for quality metrics.",
                    "label": 1
                },
                {
                    "sent": "We provide an open source framework which.",
                    "label": 1
                },
                {
                    "sent": "Can perform scalable RDF data quality assessment.",
                    "label": 1
                },
                {
                    "sent": "It's integrated into his answer so we also have an active community and it will be maintained for many years to come.",
                    "label": 1
                },
                {
                    "sent": "And the approach outperformed and competing approach on three benchmarks.",
                    "label": 0
                },
                {
                    "sent": "And it also showed good performance in terms of scaleability with respect to data set size and cluster size.",
                    "label": 0
                },
                {
                    "sent": "So you can try out the approach yourself.",
                    "label": 0
                },
                {
                    "sent": "Everything is open source, and yeah, that's that's it from my side and I'm happy for any feedback.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}