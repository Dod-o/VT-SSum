{
    "id": "r7toa4edp2jmawbv3pj7oxkxcg7anxci",
    "title": "Data driven vs. hypothesis-driven research in the social sciences",
    "info": {
        "author": [
            "J\u00f6rg Reichardt, Institute for Theoretical Physics - University of W\u00fcrzburg"
        ],
        "published": "Sept. 26, 2008",
        "recorded": "August 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/cvss08_reichardt_ddhd/",
    "segmentation": [
        [
            "Thank you very much for the kind introduction and welcome to this evening talk.",
            "Um?",
            "This is work that I'd like to present at it together with Michaela Leona from the ISI Interino theoretical work Physics methodology, but I still hope that it offers insights for those of you coming from a social science background as well.",
            "So let's get started right away with hypothesis driven research.",
            "That would probably be would."
        ],
        [
            "Professor Dickman would advocate this is a picture.",
            "From the ad health study, this is a friendship network and American High School.",
            "And.",
            "It basically shows individual students, and the links denote friendship relations between them.",
            "And the colors denote race.",
            "I think these are Blacks and these are whites.",
            "Red are Hispanics.",
            "And you see, clear division between race and then there is another division, that which you can see in here which is by age.",
            "So what you would ordinarily do is you would ask these people, how old are you?",
            "What ethnic background do you have?",
            "And then you would do a statistical test and say, OK, friendships are more likely between people of the same age between people of the same race, between people or whatever.",
            "And that statistical test would give you a P value.",
            "And you would say, OK, there is a muffly and it has a P value of let's say 0.01.",
            "Um?",
            "With this technique, a hypothesis driven research.",
            "Essentially, you can confirm to some extent or reject something that you suspect or already know.",
            "OK, you can only do hypothesis driven research if you have some idea about the data and you have to measure additional variables about the nodes in the network.",
            "OK, but then the other advantage of this may be that given enough data, you can essentially show arbitrarily small effect."
        ],
        [
            "Which is really nice.",
            "On the other hand, we have data driven research an I would picture this as basically saying, OK, this is your network, but you do not have the colors, so you cannot ask whether there is preferential linking of people of the same age.",
            "So essentially you have no hypothesis, but you take a computer and the computer tells you hey look there are four dense groups.",
            "Now try to figure out what they are.",
            "So this calls for a post hoc explanation.",
            "The problem here is that you're essentially testing multiple hypothesis, right?",
            "You have a computer that searches for a good layout into cohesive groups, for instance.",
            "So what do you do about statistical significance and what can you say about the effect sizes?",
            "And this is essentially what this talk is going to be about.",
            "I give you an example of a typical setting for data driven analysis, this is.",
            "A competition network of eBay users in Germany.",
            "It's close.",
            "It's like a bidding period of six weeks.",
            "We had about 900,000 users sampled.",
            "And they are in this competition network of pairwise competition.",
            "So every time two people were competing in the same auction."
        ],
        [
            "They would be getting a link here because what they have done is they have expressed common interest in the same article, right?",
            "The average degree in this network is only 16, so the probability that two arbitrarily chosen people meet is practically zero.",
            "OK, so you go and you ask your computer or code.",
            "Can you find cohesive subgroups in here and these subgroups would correspond to communities of user interest if you wish."
        ],
        [
            "And what comes out is something really interesting.",
            "There's a group of people who is interested in at music books, movies, but also cosmetics and baby stuff.",
            "And there is like model building people and there is musical instruments.",
            "There's coins and.",
            "Stamps in this group here, and this is the same matrix.",
            "All I did was reorder the rows and columns according to something that the computer told me.",
            "So you see, there are extremely cohesive subgroups in here.",
            "The difference in link density between within group an from within group to the rest of the network is between 10 and 100, so.",
            "Links aggregate among people who have some sort of common interest, and if you look at the articles that or if you look at the description of the articles that these people have actually met in, then you have some idea of what their common interest would be even with their life situation would be OK. 'cause if you see that people are potentially bidding in content categories and cosmetics and baby stuff, and that's probably young families, you know and so forth, so.",
            "The computer doesn't need to know anything about the categories of eBay articles.",
            "It doesn't need to know anything about the age of these people or anything.",
            "We just take the network nodes which have a number and they are linked, give it to the computer, and the computer comes up with this and then we say, hey, this is the market segmentation of the German eBay market and we can find a sensible post hoc explanation for that.",
            "OK question is, is that feasible?",
            "And so to do that.",
            "What we did was to come up with a model in which we can tune the degree of homophily in the network and then we can study whether computer is able at all to recover this group that we have put in the network as a design.",
            "Group essentially and can ask there's a computer is a computer able to recover that and this?"
        ],
        [
            "Is there a symbol of networks we study?",
            "We say we look at very large network and for theoretical reasons.",
            "It's infinitely large, and I'll talk about the implications it has for finite sized networks later.",
            "We say, well, there are different types of networks, and to make parameterisation simple, we say OK, the degree distribution in the entire network is the same.",
            "It's the same for all clusters that we define an.",
            "We'd like to have a finite average degree, and this is something that you actually find in in all networks that have been studied so far.",
            "If they have power law or close to power law degree distributions in the thermodynamic limit, the average number of neighbors.",
            "You have a network is finite, so that's not a big restriction.",
            "And in this case we have only two groups and we partition our nodes into equal sized.",
            "Groups we call them will type A and type B.",
            "And then we say, OK, the links we have in our network, they are present with probability P in between nodes of the same type.",
            "So you can also interpret that given that I am off type A, what is the probability that my neighbor is of type A?",
            "So that's what we call PN and then there is pee out, which is essentially given that I am of type A, which is the probability that my neighbors of type B OK so very simple.",
            "Now this is the network we set up that gives us a topology.",
            "It's a cluster topology.",
            "OK, links aggregate between nodes of same of the same predefined types and we ask whether a computer can find this structure.",
            "And what is easy to see is there must be a transition, because if the probability for internal links is just one half in the case of two groups, then there is no preference in linking.",
            "OK, professor Hackathon would call it.",
            "There's zero homophily.",
            "OK, so here in France is impossible.",
            "Now here you have complete.",
            "Hopefully you know every link is inside or is between nodes of the same predefined type.",
            "So here in France is trivial OK."
        ],
        [
            "And in between we have all kinds of well.",
            "In between situations, more or less realistic to some setting and what I'd like to ask is, how do you think?",
            "How do you think the transition goes from impossible to trivial?",
            "You have any ideas how that transition looks like?",
            "OK, the network is infinitely large.",
            "OK, you have infinite data.",
            "Any ideas?",
            "OK, you say it's a step function.",
            "More or less other ideas.",
            "OK, I'll show you how it looks like for a network in which everybody has exactly 3 neighbors.",
            "OK, that's like the worst case scenario because it's the maximum sparse, not sure.",
            "Fight.",
            "I'll come to that, yeah.",
            "Gold what do you expect?",
            "Why the computer is broken?",
            "I'll tell you that exactly.",
            "So this is how the transition looks like for worst case scenarios.",
            "I would call it when everybody has only three neighbors or three friends or whatever.",
            "There is a phase where you can only be as good as guessing and that goes on till the value of P in which is 7 / 8.",
            "And then very rapidly your accuracy that you can achieve.",
            "In recovering the.",
            "The planted structure increases very rapidly, so I would say OK, there is a phase of guessing whether it's structure present obviously and you could detect it with any kind of statistical test if you had a hypothesis."
        ],
        [
            "Then there is a phase in which inference is actually possible, where you can actually hope to recover something.",
            "It's in the network OK, but that phase may be rather small depending on the network and I'll speak about how this transition point here moves, possibly to the left of the properties of the network change.",
            "OK now, Professor Anus asked what is the computer doing?",
            "OK, so."
        ],
        [
            "Why do we have this transition and we try to pose this problem so that it would be independent of any algorithm?",
            "That's why we say, OK, we have equal size groups and the whole thing is parameterized only by essentially the probability that links lie between groups versus like within groups.",
            "So.",
            "Well, there could be four.",
            "There could be four, there could be 5.",
            "Bye bye.",
            "Pardon me.",
            "Haha.",
            "That that's very true.",
            "I show you an example for four groups and so forth.",
            "To make it independent of an algorithm, we said OK, what we give to the potential computer is we give the number of groups we give their respective sizes.",
            "So you have to find essentially a partition that corresponds to what you already know is in the network, but we don't tell you the parameters of the partition, so we don't tell you what is the probability for a link to be inside or to be outside, but everything else you're given and what that does is it transforms the problem.",
            "Of the eel defined clustering problem into a well defined partitioning problem, 'cause I tell you what is the size of the partition.",
            "Ann, you're supposed, and the only strategy that you can now have is to look for maximally separated clusters, right?",
            "So I give you the network, I tell you the sizes of the partitions and the only thing you can sensibly do is try to find a partition that minimizes the number of links that run between the different parts, 'cause if you wouldn't do that.",
            "You would miss the trivial cases.",
            "Right?",
            "So.",
            "Then what you optimize is this cost function here, and it's very easy to understand.",
            "You go over all the links.",
            "And you assign a variable of inference.",
            "Now Sigma I to each of the nodes and when a link runs between two nodes which are in the same in the same group that gives you.",
            "What does it do?",
            "Well, this is zero.",
            "Then you count the edge.",
            "Sorry, I should have probably put in the - in front of here so.",
            "No hold on.",
            "What you do is you count all the edges that run between nodes in different groups, right?",
            "So this is the cut size as it's written there, sure.",
            "Can you try to minimize that and the way you minimize it is you change the labels you assign to the nodes you change your inference variables.",
            "So how many possibilities do you have to assign inference variables?",
            "Well, in principle you have to search among all the.",
            "And over two out of N possible assignments into 2 equal sized groups.",
            "For our trivial case here.",
            "And if you find the minimum of that, then this is probably a Bayesian maximum a posteriori optimal estimator.",
            "What you should note is that for a given P in.",
            "The cut size that you.",
            "Expect.",
            "Is linearly dependent on this?",
            "Pienso PN is 1, then you're cut sizes zero and pin is 1/2.",
            "Then your cat size is just one quarter of all the edges essentially.",
            "OK. Um?",
            "So this is the problem as it's defined and the nice thing is that statistical mechanics allows us to give expectation values for these quantities.",
            "Here for this cut size E for this ensemble of networks that we have defined and.",
            "Above that we are actually able to calculate the probability that given that a particular node has an assigned label, has a design cluster label of South.",
            "What is the probability that we will infer it in Group Sigma?",
            "OK, so."
        ],
        [
            "So essentially what we study is what is the overlap of the configuration.",
            "The assignment of labels that minimizes the cut size with the assignment of pre assigned clusters that we put in the network and statistical mechanics allows us to do that rigorously.",
            "And then the accuracy I showed you in the plot is nothing more than the sum over correctly assigned nodes.",
            "OK, so you just go over all nodes and you ask.",
            "OK, let's just count how many get the right.",
            "Assignment OK. Is that is that clear?",
            "But it does OK. Now, why do you have this funny transition?",
            "And the reason is to be solved in this picture.",
            "Here what this shows you is."
        ],
        [
            "A cartoon image, so to say of the landscape of cut sizes versus configurations.",
            "So here you have to imagine all the.",
            "Anhalf out of possible assignments of inferred labels.",
            "And they all have a cut size."
        ],
        [
            "OK, and then one of these configurations, in particular the one here.",
            "That's our design configuration.",
            "That's like the true thing that we want to infer."
        ],
        [
            "If we're down here where there is no structure, well, then obviously this is some configuration which is not an optimum.",
            "There is a different configuration, OK, which has a lower cut size than this random network, very simple.",
            "Now.",
            "We're able to calculate the cut size that we expect in a random network.",
            "OK, so that gives us this expectation value here.",
            "Now let's see what happens with this energy landscape as we go with our AMA fully, so to say to higher values.",
            "So you see, we decrease.",
            "This is the the cut size of the design configuration, but there are still different solutions that have zero overlap, so we're still here, right, no overlap.",
            "Then we go on and on and that is something happens.",
            "Suddenly one of the neighbor."
        ],
        [
            "In configurations."
        ],
        [
            "Of our design configurations gives."
        ],
        [
            "Minimum which is lower than this expectation value here, which you can essentially find in any network.",
            "Which is totally random, and so we are right at this point here.",
            "So now suddenly our design configuration has induced a minimum in this landscape, which is lower than the expectation value for an entirely random networks like lower than all the competing solutions.",
            "And then our inference here starts, and if we go further.",
            "What?"
        ],
        [
            "Happens is that.",
            "This energy landscape here suddenly starts to smooth.",
            "So if you compare that to this, so here is really rugged and now suddenly it starts to smooth out.",
            "And if as we go even further."
        ],
        [
            "Up to here.",
            "There are less and less local minima.",
            "Inference gets easier and easier for other algorithms."
        ],
        [
            "We go up here.",
            "We go up here."
        ],
        [
            "At this point up here where we are the trivial solution, there is only one minimum left.",
            "And greedy search will always go downhill.",
            "Any algorithm is able to find that.",
            "OK, so this is like the simple solution.",
            "Now what I showed you here is essentially what is plotted in this curve.",
            "Here the green line is the cut size or energy for the physicists of the planted partition.",
            "OK, that as I said, goes down linearly with our homophily parameter.",
            "Note that this here starts at 0.8, whereas this year start to 0.5, so this is sort of this range here.",
            "So before this critical point, this point here, that's exactly.",
            "Here.",
            "This is where suddenly we find a cut size which is lower than the expectation value this."
        ],
        [
            "This here starts.",
            "This is where our inference starts to make sense.",
            "So.",
            "We can already say if we find a cut size which is lower than what we would expect in the random case.",
            "Then we're in the phase that inference is possible, so that's the first conclusion that we have.",
            "We need to find something that is better than what we expect from purely random network.",
            "OK, and the second conclusion is what we expect to find in a random network, is also found in a lot of non random networks.",
            "OK, this is like straight line here, simply because the structure we define cannot yet compete.",
            "With what we find by searching in random data essentially and so at this point here we have this and then there is this other critical point right here which is.",
            "This picture and that's where.",
            "The cut size of our design."
        ],
        [
            "And configuration is below.",
            "The expectation value, so this is where this green line crosses essentially the value that this straight line here defines, and that would have been my naive guess where inference starts.",
            "If the cut size of my planted solution.",
            "If it is lower than what I expect to find in a random network, then I would think inference starts.",
            "But it's actually earlier, which is kind of good news, OK?",
            "So this is this point up here.",
            "So at this point when the cut size of the design solution already exceeds the expectation value, already have an accuracy above 90%.",
            "Which is also nice because you can sort of say OK if homophily exceeds a particular value then you can be sure that your accuracy is higher than in particular value.",
            "OK. And then the last thing that I'd like to point out here is that."
        ],
        [
            "Those solutions that are below this critical value here, smooth out the entire energy landscape and that means.",
            "Inference is easier for any algorithm.",
            "OK, because they all have to search in this landscape and the better they cope with local minima, the better they are able to find good solutions.",
            "But if there are less local minima naturally.",
            "More algorithms, sure.",
            "Yes.",
            "I think it's totally universal.",
            "Grab your perimeter of pinion.",
            "Every node, yes, three link.",
            "There is a probability PE.",
            "Each one of those links.",
            "Burn rate.",
            "So for any node, the actual value that your server.",
            "Screaming screaming.",
            "No, no, no, it's not extremely discreet P in that that's probably.",
            "One connection inside Connected Insider connection inside right, yeah, OK.",
            "But this is sort of for a particular node.",
            "P is of course not discrete on the total scale for the entire network, right, right right now.",
            "The average yeah?",
            "Degree.",
            "Do you have an infinite network?",
            "Yeah.",
            "Ah, OK, I yeah, I know what you're alluding to.",
            "Yeah, because of this.",
            "I'm trying to visualize what would happen, what kind.",
            "What happens is that this transitions gets steeper, so this is really rounded here.",
            "Other transitions look steeper if you have higher degree.",
            "Yeah, they they also move.",
            "They also move.",
            "I get to this.",
            "I get to this.",
            "OK very good question.",
            "So this is how it moves.",
            "OK, so now we're."
        ],
        [
            "Trusted how does this transition point here depend on the degree distribution, and there are two interesting things.",
            "Well, one is sort of trivial.",
            "If you have."
        ],
        [
            "A higher degree.",
            "That pin moves to the."
        ],
        [
            "And this is sort of turned around.",
            "Higher degree P in critical goes down, but it also depends on is the shape of the degree distribution, and I was really surprised by this because this is a post sonion degree distribution and these are two different types of scale free degree distribution.",
            "This one here has sort of a barabasi type thing.",
            "It starts at a particular degree and then it goes power law all the way to Infinity.",
            "Whereas this one here starts a degree one.",
            "I get a different average degree by adding a different Delta K to this thing here, so these two scale 3 degrees solutions have the same exponent, but one of them is sort of a straight line all the way, whereas the other is sort of curved at the beginning.",
            "And inference is easier here.",
            "Which is sort of surprising because the abyss rainy, which is.",
            "Sort of homogeneous, is there it's most difficult to do inference if you want to look at it like this.",
            "No, it's Infinity.",
            "It's a thermodynamic limit calculation.",
            "The side effect.",
            "I mean I, I work on on the ensemble essentially, pardon me.",
            "Yeah.",
            "Yeah, yeah.",
            "What this here shows you is.",
            "Maybe going back to this, this is the ratio of this naive estimate of this blue line."
        ],
        [
            "Versus this one here and what you see is that as the average degree gets low."
        ],
        [
            "After they move closer together, so that means and goes back to Professor Amaral's question.",
            "If this line in this line here moves closer together for higher degree, that that means the transition gets steeper, right?",
            "OK, so recognizable structure starts at weaker cluster structures if you increase.",
            "The average degree an it starts at weaker than you would expect naively.",
            "Um?"
        ],
        [
            "Well, what do you do if you maybe have some label, some labeled data?",
            "OK, you could say.",
            "Well, I already know that some.",
            "I know what race.",
            "For instance, some of the nodes in the network are.",
            "Let's say I have information about every thousand person and then that doesn't give you a lot of advantage, and but if you know 1%, that's already a little better.",
            "If you know 10% then you sort of start to get this smooth transition.",
            "Here we're already at the beginning.",
            "You get some sort of inference here.",
            "But what is interesting to note is that the advantage you get over having no labeled data is largest close to this transition point.",
            "So that's very typical for phase transition, thank you.",
            "Yeah, that's that.",
            "And then this is about the finite size effects, so this is."
        ],
        [
            "Typical benchmark that people use for assessing the validity of network clustering algorithms.",
            "So they say OK, we have 4 equal sized groups and we fix the average degree to 16 degrees.",
            "Tribu Shun is parsonian nothing spectacular.",
            "Somebody started this and then everybody picked up on it.",
            "The typical thing that they do with.",
            "In the papers is networks of size 128, and when you compare that those black diamonds here to the theoretical prediction, then you see actually inference is better than you predict.",
            "But if you go to larger networks and fix the average degree still to 16, sorry network gets sparser, then you approach the theoretical curve quite well.",
            "I use simulated annealing also like Professor MRL.",
            "Has worked on.",
            "It's like probably the most sensible thing to do.",
            "Optimizing cut sizes by simulated annealing.",
            "But what I?",
            "Like to point out is that in principle for a very large network, there's no algorithm that can do.",
            "Significantly better than this red curve.",
            "OK, what happens if you have unequal size?"
        ],
        [
            "As clusters, well, nothing particular just looks the same.",
            "This is again for this network with three links per node.",
            "But now we have 2/3 of nodes or RF type A and 1 thirds of no dark type B.",
            "So it's the same phenomenon.",
            "What is interesting is that the transition point for the two classes at the same probability.",
            "Here, but if you look at the table of errors.",
            "For two groups, then it's obvious that it must be like this, you know, because.",
            "What you are doing wrong in one you are also doing wrong.",
            "In the other side, so it must be at the same point.",
            "But what is now more difficult to assess is, well, do you plotted versus the probability that a link lies within the larger cluster or within the smaller cluster?",
            "And what happens is that the transition point for the larger cluster is to the left of the transition point for the equal size cluster.",
            "And if I would plot versus the probability PB given B, then it would be to the right of the case for two equal size clusters, so.",
            "Even the case of equal size clusters sort of gives you an average kind of behavior for differently sized clusters.",
            "So we're already at the conclusions.",
            "Are we seen?"
        ],
        [
            "There is a sharp transition, at least for very large networks between the phase in which inference is absolutely impossible by definition, so to say because.",
            "Other solutions obscure the true structure and a phase where inference is possible with high accuracy.",
            "There are similar observations for multivariate."
        ],
        [
            "Data analysis that have been studied in physics.",
            "So usually the setting there is.",
            "I have a space of dimension D. And I have a number of samples from this space number is N. And then you observe the same kind of transition, but then it's always the ratio of the number of data points you sample from versus the dimension of the space from which you sample.",
            "So if you keep the dimension of the space constant and sample more and more data, you always get across this transition point.",
            "Alright, so essentially, given enough samples from a distribution, you can learn any distribution.",
            "If you have sparse networks."
        ],
        [
            "For the average degrees finite, this is wrong, and the unfortunate thing is that all the networks the majority of networks we have in the real world are sparse.",
            "And what I mean by this, I'd like to emphasize a lot of networks, model network models go.",
            "There is a probability for two nodes being connected.",
            "And they say it has value 0.1 OK. That means if the network doubles in size.",
            "Then every node gets the double number of connections.",
            "So the number of information per node also doubles by doubling the size of the network, but that's not what happens in the majority of networks.",
            "You know if twice the number of people get a mobile phone.",
            "The number of people you call doesn't double.",
            "You know, or if you look, if you think of the Internet, if there are twice as many pages on the Internet, the number of links per page doesn't double either.",
            "OK, so finite degree is something very real, and that's why if you take the thermodynamic limit, you have to assume that the degree is finite, and if you go to the literature and you look up this type of studies for network clustering algorithms, what they will usually do is they will say OK there is a link probability and then they will give you an estimate which says.",
            "If 1 / sqrt N is smaller than some function of the link probability, then you can always infer things.",
            "But the problem is that the link probabilities are of the order of one over North, so comparing that with 1 / sqrt N doesn't make any sense.",
            "OK, so for networks, dimensionality and size of the data set are essentially not."
        ],
        [
            "Independent, that's that's the main problem.",
            "There may exist structure that's principally undetectable by unsupervised methods.",
            "But it is iaccessible to hypothesis.",
            "The serious solutions of this said they obscure true structure."
        ],
        [
            "If you have some labeled data."
        ],
        [
            "And that that helps."
        ],
        [
            "We can."
        ],
        [
            "Analytically formula, or at least algorithms that calculate the transition points and the achievable accuracy.",
            "And sort of as a final conclusion, I'd like to say data driven research will essentially tell."
        ],
        [
            "About the strong effects.",
            "But the good thing is it will tell you about all the strong effects.",
            "OK, so the ones that you might miss if you don't have the right hypothesis.",
            "And the small effects are unfortunately only visible to hypothesis driven research.",
            "So again, you see that the two things are complementary.",
            "And with that I'd like to close and maybe for the.",
            "Questions that point you to some references.",
            "Thank you very much for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for the kind introduction and welcome to this evening talk.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This is work that I'd like to present at it together with Michaela Leona from the ISI Interino theoretical work Physics methodology, but I still hope that it offers insights for those of you coming from a social science background as well.",
                    "label": 0
                },
                {
                    "sent": "So let's get started right away with hypothesis driven research.",
                    "label": 0
                },
                {
                    "sent": "That would probably be would.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Professor Dickman would advocate this is a picture.",
                    "label": 0
                },
                {
                    "sent": "From the ad health study, this is a friendship network and American High School.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It basically shows individual students, and the links denote friendship relations between them.",
                    "label": 0
                },
                {
                    "sent": "And the colors denote race.",
                    "label": 0
                },
                {
                    "sent": "I think these are Blacks and these are whites.",
                    "label": 0
                },
                {
                    "sent": "Red are Hispanics.",
                    "label": 0
                },
                {
                    "sent": "And you see, clear division between race and then there is another division, that which you can see in here which is by age.",
                    "label": 0
                },
                {
                    "sent": "So what you would ordinarily do is you would ask these people, how old are you?",
                    "label": 0
                },
                {
                    "sent": "What ethnic background do you have?",
                    "label": 0
                },
                {
                    "sent": "And then you would do a statistical test and say, OK, friendships are more likely between people of the same age between people of the same race, between people or whatever.",
                    "label": 0
                },
                {
                    "sent": "And that statistical test would give you a P value.",
                    "label": 0
                },
                {
                    "sent": "And you would say, OK, there is a muffly and it has a P value of let's say 0.01.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "With this technique, a hypothesis driven research.",
                    "label": 1
                },
                {
                    "sent": "Essentially, you can confirm to some extent or reject something that you suspect or already know.",
                    "label": 0
                },
                {
                    "sent": "OK, you can only do hypothesis driven research if you have some idea about the data and you have to measure additional variables about the nodes in the network.",
                    "label": 0
                },
                {
                    "sent": "OK, but then the other advantage of this may be that given enough data, you can essentially show arbitrarily small effect.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is really nice.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we have data driven research an I would picture this as basically saying, OK, this is your network, but you do not have the colors, so you cannot ask whether there is preferential linking of people of the same age.",
                    "label": 0
                },
                {
                    "sent": "So essentially you have no hypothesis, but you take a computer and the computer tells you hey look there are four dense groups.",
                    "label": 1
                },
                {
                    "sent": "Now try to figure out what they are.",
                    "label": 0
                },
                {
                    "sent": "So this calls for a post hoc explanation.",
                    "label": 0
                },
                {
                    "sent": "The problem here is that you're essentially testing multiple hypothesis, right?",
                    "label": 0
                },
                {
                    "sent": "You have a computer that searches for a good layout into cohesive groups, for instance.",
                    "label": 0
                },
                {
                    "sent": "So what do you do about statistical significance and what can you say about the effect sizes?",
                    "label": 1
                },
                {
                    "sent": "And this is essentially what this talk is going to be about.",
                    "label": 0
                },
                {
                    "sent": "I give you an example of a typical setting for data driven analysis, this is.",
                    "label": 1
                },
                {
                    "sent": "A competition network of eBay users in Germany.",
                    "label": 0
                },
                {
                    "sent": "It's close.",
                    "label": 0
                },
                {
                    "sent": "It's like a bidding period of six weeks.",
                    "label": 0
                },
                {
                    "sent": "We had about 900,000 users sampled.",
                    "label": 0
                },
                {
                    "sent": "And they are in this competition network of pairwise competition.",
                    "label": 0
                },
                {
                    "sent": "So every time two people were competing in the same auction.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They would be getting a link here because what they have done is they have expressed common interest in the same article, right?",
                    "label": 0
                },
                {
                    "sent": "The average degree in this network is only 16, so the probability that two arbitrarily chosen people meet is practically zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so you go and you ask your computer or code.",
                    "label": 0
                },
                {
                    "sent": "Can you find cohesive subgroups in here and these subgroups would correspond to communities of user interest if you wish.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what comes out is something really interesting.",
                    "label": 0
                },
                {
                    "sent": "There's a group of people who is interested in at music books, movies, but also cosmetics and baby stuff.",
                    "label": 1
                },
                {
                    "sent": "And there is like model building people and there is musical instruments.",
                    "label": 0
                },
                {
                    "sent": "There's coins and.",
                    "label": 0
                },
                {
                    "sent": "Stamps in this group here, and this is the same matrix.",
                    "label": 0
                },
                {
                    "sent": "All I did was reorder the rows and columns according to something that the computer told me.",
                    "label": 0
                },
                {
                    "sent": "So you see, there are extremely cohesive subgroups in here.",
                    "label": 0
                },
                {
                    "sent": "The difference in link density between within group an from within group to the rest of the network is between 10 and 100, so.",
                    "label": 0
                },
                {
                    "sent": "Links aggregate among people who have some sort of common interest, and if you look at the articles that or if you look at the description of the articles that these people have actually met in, then you have some idea of what their common interest would be even with their life situation would be OK. 'cause if you see that people are potentially bidding in content categories and cosmetics and baby stuff, and that's probably young families, you know and so forth, so.",
                    "label": 0
                },
                {
                    "sent": "The computer doesn't need to know anything about the categories of eBay articles.",
                    "label": 0
                },
                {
                    "sent": "It doesn't need to know anything about the age of these people or anything.",
                    "label": 0
                },
                {
                    "sent": "We just take the network nodes which have a number and they are linked, give it to the computer, and the computer comes up with this and then we say, hey, this is the market segmentation of the German eBay market and we can find a sensible post hoc explanation for that.",
                    "label": 0
                },
                {
                    "sent": "OK question is, is that feasible?",
                    "label": 0
                },
                {
                    "sent": "And so to do that.",
                    "label": 0
                },
                {
                    "sent": "What we did was to come up with a model in which we can tune the degree of homophily in the network and then we can study whether computer is able at all to recover this group that we have put in the network as a design.",
                    "label": 0
                },
                {
                    "sent": "Group essentially and can ask there's a computer is a computer able to recover that and this?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is there a symbol of networks we study?",
                    "label": 0
                },
                {
                    "sent": "We say we look at very large network and for theoretical reasons.",
                    "label": 1
                },
                {
                    "sent": "It's infinitely large, and I'll talk about the implications it has for finite sized networks later.",
                    "label": 0
                },
                {
                    "sent": "We say, well, there are different types of networks, and to make parameterisation simple, we say OK, the degree distribution in the entire network is the same.",
                    "label": 0
                },
                {
                    "sent": "It's the same for all clusters that we define an.",
                    "label": 1
                },
                {
                    "sent": "We'd like to have a finite average degree, and this is something that you actually find in in all networks that have been studied so far.",
                    "label": 0
                },
                {
                    "sent": "If they have power law or close to power law degree distributions in the thermodynamic limit, the average number of neighbors.",
                    "label": 1
                },
                {
                    "sent": "You have a network is finite, so that's not a big restriction.",
                    "label": 0
                },
                {
                    "sent": "And in this case we have only two groups and we partition our nodes into equal sized.",
                    "label": 0
                },
                {
                    "sent": "Groups we call them will type A and type B.",
                    "label": 0
                },
                {
                    "sent": "And then we say, OK, the links we have in our network, they are present with probability P in between nodes of the same type.",
                    "label": 0
                },
                {
                    "sent": "So you can also interpret that given that I am off type A, what is the probability that my neighbor is of type A?",
                    "label": 0
                },
                {
                    "sent": "So that's what we call PN and then there is pee out, which is essentially given that I am of type A, which is the probability that my neighbors of type B OK so very simple.",
                    "label": 0
                },
                {
                    "sent": "Now this is the network we set up that gives us a topology.",
                    "label": 0
                },
                {
                    "sent": "It's a cluster topology.",
                    "label": 0
                },
                {
                    "sent": "OK, links aggregate between nodes of same of the same predefined types and we ask whether a computer can find this structure.",
                    "label": 0
                },
                {
                    "sent": "And what is easy to see is there must be a transition, because if the probability for internal links is just one half in the case of two groups, then there is no preference in linking.",
                    "label": 0
                },
                {
                    "sent": "OK, professor Hackathon would call it.",
                    "label": 0
                },
                {
                    "sent": "There's zero homophily.",
                    "label": 0
                },
                {
                    "sent": "OK, so here in France is impossible.",
                    "label": 0
                },
                {
                    "sent": "Now here you have complete.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you know every link is inside or is between nodes of the same predefined type.",
                    "label": 0
                },
                {
                    "sent": "So here in France is trivial OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in between we have all kinds of well.",
                    "label": 0
                },
                {
                    "sent": "In between situations, more or less realistic to some setting and what I'd like to ask is, how do you think?",
                    "label": 0
                },
                {
                    "sent": "How do you think the transition goes from impossible to trivial?",
                    "label": 0
                },
                {
                    "sent": "You have any ideas how that transition looks like?",
                    "label": 0
                },
                {
                    "sent": "OK, the network is infinitely large.",
                    "label": 0
                },
                {
                    "sent": "OK, you have infinite data.",
                    "label": 0
                },
                {
                    "sent": "Any ideas?",
                    "label": 0
                },
                {
                    "sent": "OK, you say it's a step function.",
                    "label": 0
                },
                {
                    "sent": "More or less other ideas.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll show you how it looks like for a network in which everybody has exactly 3 neighbors.",
                    "label": 0
                },
                {
                    "sent": "OK, that's like the worst case scenario because it's the maximum sparse, not sure.",
                    "label": 0
                },
                {
                    "sent": "Fight.",
                    "label": 0
                },
                {
                    "sent": "I'll come to that, yeah.",
                    "label": 0
                },
                {
                    "sent": "Gold what do you expect?",
                    "label": 0
                },
                {
                    "sent": "Why the computer is broken?",
                    "label": 0
                },
                {
                    "sent": "I'll tell you that exactly.",
                    "label": 0
                },
                {
                    "sent": "So this is how the transition looks like for worst case scenarios.",
                    "label": 0
                },
                {
                    "sent": "I would call it when everybody has only three neighbors or three friends or whatever.",
                    "label": 0
                },
                {
                    "sent": "There is a phase where you can only be as good as guessing and that goes on till the value of P in which is 7 / 8.",
                    "label": 0
                },
                {
                    "sent": "And then very rapidly your accuracy that you can achieve.",
                    "label": 0
                },
                {
                    "sent": "In recovering the.",
                    "label": 0
                },
                {
                    "sent": "The planted structure increases very rapidly, so I would say OK, there is a phase of guessing whether it's structure present obviously and you could detect it with any kind of statistical test if you had a hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then there is a phase in which inference is actually possible, where you can actually hope to recover something.",
                    "label": 0
                },
                {
                    "sent": "It's in the network OK, but that phase may be rather small depending on the network and I'll speak about how this transition point here moves, possibly to the left of the properties of the network change.",
                    "label": 0
                },
                {
                    "sent": "OK now, Professor Anus asked what is the computer doing?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why do we have this transition and we try to pose this problem so that it would be independent of any algorithm?",
                    "label": 0
                },
                {
                    "sent": "That's why we say, OK, we have equal size groups and the whole thing is parameterized only by essentially the probability that links lie between groups versus like within groups.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, there could be four.",
                    "label": 0
                },
                {
                    "sent": "There could be four, there could be 5.",
                    "label": 0
                },
                {
                    "sent": "Bye bye.",
                    "label": 0
                },
                {
                    "sent": "Pardon me.",
                    "label": 0
                },
                {
                    "sent": "Haha.",
                    "label": 0
                },
                {
                    "sent": "That that's very true.",
                    "label": 0
                },
                {
                    "sent": "I show you an example for four groups and so forth.",
                    "label": 0
                },
                {
                    "sent": "To make it independent of an algorithm, we said OK, what we give to the potential computer is we give the number of groups we give their respective sizes.",
                    "label": 0
                },
                {
                    "sent": "So you have to find essentially a partition that corresponds to what you already know is in the network, but we don't tell you the parameters of the partition, so we don't tell you what is the probability for a link to be inside or to be outside, but everything else you're given and what that does is it transforms the problem.",
                    "label": 0
                },
                {
                    "sent": "Of the eel defined clustering problem into a well defined partitioning problem, 'cause I tell you what is the size of the partition.",
                    "label": 0
                },
                {
                    "sent": "Ann, you're supposed, and the only strategy that you can now have is to look for maximally separated clusters, right?",
                    "label": 1
                },
                {
                    "sent": "So I give you the network, I tell you the sizes of the partitions and the only thing you can sensibly do is try to find a partition that minimizes the number of links that run between the different parts, 'cause if you wouldn't do that.",
                    "label": 0
                },
                {
                    "sent": "You would miss the trivial cases.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Then what you optimize is this cost function here, and it's very easy to understand.",
                    "label": 0
                },
                {
                    "sent": "You go over all the links.",
                    "label": 0
                },
                {
                    "sent": "And you assign a variable of inference.",
                    "label": 0
                },
                {
                    "sent": "Now Sigma I to each of the nodes and when a link runs between two nodes which are in the same in the same group that gives you.",
                    "label": 0
                },
                {
                    "sent": "What does it do?",
                    "label": 0
                },
                {
                    "sent": "Well, this is zero.",
                    "label": 0
                },
                {
                    "sent": "Then you count the edge.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I should have probably put in the - in front of here so.",
                    "label": 0
                },
                {
                    "sent": "No hold on.",
                    "label": 0
                },
                {
                    "sent": "What you do is you count all the edges that run between nodes in different groups, right?",
                    "label": 0
                },
                {
                    "sent": "So this is the cut size as it's written there, sure.",
                    "label": 0
                },
                {
                    "sent": "Can you try to minimize that and the way you minimize it is you change the labels you assign to the nodes you change your inference variables.",
                    "label": 1
                },
                {
                    "sent": "So how many possibilities do you have to assign inference variables?",
                    "label": 0
                },
                {
                    "sent": "Well, in principle you have to search among all the.",
                    "label": 0
                },
                {
                    "sent": "And over two out of N possible assignments into 2 equal sized groups.",
                    "label": 0
                },
                {
                    "sent": "For our trivial case here.",
                    "label": 1
                },
                {
                    "sent": "And if you find the minimum of that, then this is probably a Bayesian maximum a posteriori optimal estimator.",
                    "label": 0
                },
                {
                    "sent": "What you should note is that for a given P in.",
                    "label": 0
                },
                {
                    "sent": "The cut size that you.",
                    "label": 0
                },
                {
                    "sent": "Expect.",
                    "label": 0
                },
                {
                    "sent": "Is linearly dependent on this?",
                    "label": 0
                },
                {
                    "sent": "Pienso PN is 1, then you're cut sizes zero and pin is 1/2.",
                    "label": 0
                },
                {
                    "sent": "Then your cat size is just one quarter of all the edges essentially.",
                    "label": 0
                },
                {
                    "sent": "OK. Um?",
                    "label": 0
                },
                {
                    "sent": "So this is the problem as it's defined and the nice thing is that statistical mechanics allows us to give expectation values for these quantities.",
                    "label": 0
                },
                {
                    "sent": "Here for this cut size E for this ensemble of networks that we have defined and.",
                    "label": 0
                },
                {
                    "sent": "Above that we are actually able to calculate the probability that given that a particular node has an assigned label, has a design cluster label of South.",
                    "label": 0
                },
                {
                    "sent": "What is the probability that we will infer it in Group Sigma?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So essentially what we study is what is the overlap of the configuration.",
                    "label": 1
                },
                {
                    "sent": "The assignment of labels that minimizes the cut size with the assignment of pre assigned clusters that we put in the network and statistical mechanics allows us to do that rigorously.",
                    "label": 0
                },
                {
                    "sent": "And then the accuracy I showed you in the plot is nothing more than the sum over correctly assigned nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so you just go over all nodes and you ask.",
                    "label": 0
                },
                {
                    "sent": "OK, let's just count how many get the right.",
                    "label": 0
                },
                {
                    "sent": "Assignment OK. Is that is that clear?",
                    "label": 0
                },
                {
                    "sent": "But it does OK. Now, why do you have this funny transition?",
                    "label": 0
                },
                {
                    "sent": "And the reason is to be solved in this picture.",
                    "label": 0
                },
                {
                    "sent": "Here what this shows you is.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A cartoon image, so to say of the landscape of cut sizes versus configurations.",
                    "label": 0
                },
                {
                    "sent": "So here you have to imagine all the.",
                    "label": 0
                },
                {
                    "sent": "Anhalf out of possible assignments of inferred labels.",
                    "label": 0
                },
                {
                    "sent": "And they all have a cut size.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then one of these configurations, in particular the one here.",
                    "label": 0
                },
                {
                    "sent": "That's our design configuration.",
                    "label": 0
                },
                {
                    "sent": "That's like the true thing that we want to infer.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we're down here where there is no structure, well, then obviously this is some configuration which is not an optimum.",
                    "label": 0
                },
                {
                    "sent": "There is a different configuration, OK, which has a lower cut size than this random network, very simple.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "We're able to calculate the cut size that we expect in a random network.",
                    "label": 0
                },
                {
                    "sent": "OK, so that gives us this expectation value here.",
                    "label": 0
                },
                {
                    "sent": "Now let's see what happens with this energy landscape as we go with our AMA fully, so to say to higher values.",
                    "label": 0
                },
                {
                    "sent": "So you see, we decrease.",
                    "label": 0
                },
                {
                    "sent": "This is the the cut size of the design configuration, but there are still different solutions that have zero overlap, so we're still here, right, no overlap.",
                    "label": 0
                },
                {
                    "sent": "Then we go on and on and that is something happens.",
                    "label": 0
                },
                {
                    "sent": "Suddenly one of the neighbor.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In configurations.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of our design configurations gives.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Minimum which is lower than this expectation value here, which you can essentially find in any network.",
                    "label": 0
                },
                {
                    "sent": "Which is totally random, and so we are right at this point here.",
                    "label": 0
                },
                {
                    "sent": "So now suddenly our design configuration has induced a minimum in this landscape, which is lower than the expectation value for an entirely random networks like lower than all the competing solutions.",
                    "label": 0
                },
                {
                    "sent": "And then our inference here starts, and if we go further.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happens is that.",
                    "label": 0
                },
                {
                    "sent": "This energy landscape here suddenly starts to smooth.",
                    "label": 0
                },
                {
                    "sent": "So if you compare that to this, so here is really rugged and now suddenly it starts to smooth out.",
                    "label": 0
                },
                {
                    "sent": "And if as we go even further.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up to here.",
                    "label": 0
                },
                {
                    "sent": "There are less and less local minima.",
                    "label": 0
                },
                {
                    "sent": "Inference gets easier and easier for other algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We go up here.",
                    "label": 0
                },
                {
                    "sent": "We go up here.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At this point up here where we are the trivial solution, there is only one minimum left.",
                    "label": 1
                },
                {
                    "sent": "And greedy search will always go downhill.",
                    "label": 0
                },
                {
                    "sent": "Any algorithm is able to find that.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is like the simple solution.",
                    "label": 0
                },
                {
                    "sent": "Now what I showed you here is essentially what is plotted in this curve.",
                    "label": 0
                },
                {
                    "sent": "Here the green line is the cut size or energy for the physicists of the planted partition.",
                    "label": 0
                },
                {
                    "sent": "OK, that as I said, goes down linearly with our homophily parameter.",
                    "label": 0
                },
                {
                    "sent": "Note that this here starts at 0.8, whereas this year start to 0.5, so this is sort of this range here.",
                    "label": 0
                },
                {
                    "sent": "So before this critical point, this point here, that's exactly.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 1
                },
                {
                    "sent": "This is where suddenly we find a cut size which is lower than the expectation value this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This here starts.",
                    "label": 0
                },
                {
                    "sent": "This is where our inference starts to make sense.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can already say if we find a cut size which is lower than what we would expect in the random case.",
                    "label": 1
                },
                {
                    "sent": "Then we're in the phase that inference is possible, so that's the first conclusion that we have.",
                    "label": 0
                },
                {
                    "sent": "We need to find something that is better than what we expect from purely random network.",
                    "label": 0
                },
                {
                    "sent": "OK, and the second conclusion is what we expect to find in a random network, is also found in a lot of non random networks.",
                    "label": 1
                },
                {
                    "sent": "OK, this is like straight line here, simply because the structure we define cannot yet compete.",
                    "label": 0
                },
                {
                    "sent": "With what we find by searching in random data essentially and so at this point here we have this and then there is this other critical point right here which is.",
                    "label": 0
                },
                {
                    "sent": "This picture and that's where.",
                    "label": 0
                },
                {
                    "sent": "The cut size of our design.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And configuration is below.",
                    "label": 0
                },
                {
                    "sent": "The expectation value, so this is where this green line crosses essentially the value that this straight line here defines, and that would have been my naive guess where inference starts.",
                    "label": 0
                },
                {
                    "sent": "If the cut size of my planted solution.",
                    "label": 0
                },
                {
                    "sent": "If it is lower than what I expect to find in a random network, then I would think inference starts.",
                    "label": 1
                },
                {
                    "sent": "But it's actually earlier, which is kind of good news, OK?",
                    "label": 0
                },
                {
                    "sent": "So this is this point up here.",
                    "label": 1
                },
                {
                    "sent": "So at this point when the cut size of the design solution already exceeds the expectation value, already have an accuracy above 90%.",
                    "label": 0
                },
                {
                    "sent": "Which is also nice because you can sort of say OK if homophily exceeds a particular value then you can be sure that your accuracy is higher than in particular value.",
                    "label": 0
                },
                {
                    "sent": "OK. And then the last thing that I'd like to point out here is that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those solutions that are below this critical value here, smooth out the entire energy landscape and that means.",
                    "label": 0
                },
                {
                    "sent": "Inference is easier for any algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, because they all have to search in this landscape and the better they cope with local minima, the better they are able to find good solutions.",
                    "label": 0
                },
                {
                    "sent": "But if there are less local minima naturally.",
                    "label": 0
                },
                {
                    "sent": "More algorithms, sure.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I think it's totally universal.",
                    "label": 0
                },
                {
                    "sent": "Grab your perimeter of pinion.",
                    "label": 0
                },
                {
                    "sent": "Every node, yes, three link.",
                    "label": 0
                },
                {
                    "sent": "There is a probability PE.",
                    "label": 0
                },
                {
                    "sent": "Each one of those links.",
                    "label": 0
                },
                {
                    "sent": "Burn rate.",
                    "label": 0
                },
                {
                    "sent": "So for any node, the actual value that your server.",
                    "label": 0
                },
                {
                    "sent": "Screaming screaming.",
                    "label": 0
                },
                {
                    "sent": "No, no, no, it's not extremely discreet P in that that's probably.",
                    "label": 0
                },
                {
                    "sent": "One connection inside Connected Insider connection inside right, yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "But this is sort of for a particular node.",
                    "label": 0
                },
                {
                    "sent": "P is of course not discrete on the total scale for the entire network, right, right right now.",
                    "label": 0
                },
                {
                    "sent": "The average yeah?",
                    "label": 0
                },
                {
                    "sent": "Degree.",
                    "label": 0
                },
                {
                    "sent": "Do you have an infinite network?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Ah, OK, I yeah, I know what you're alluding to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because of this.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to visualize what would happen, what kind.",
                    "label": 0
                },
                {
                    "sent": "What happens is that this transitions gets steeper, so this is really rounded here.",
                    "label": 0
                },
                {
                    "sent": "Other transitions look steeper if you have higher degree.",
                    "label": 0
                },
                {
                    "sent": "Yeah, they they also move.",
                    "label": 0
                },
                {
                    "sent": "They also move.",
                    "label": 0
                },
                {
                    "sent": "I get to this.",
                    "label": 0
                },
                {
                    "sent": "I get to this.",
                    "label": 0
                },
                {
                    "sent": "OK very good question.",
                    "label": 0
                },
                {
                    "sent": "So this is how it moves.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trusted how does this transition point here depend on the degree distribution, and there are two interesting things.",
                    "label": 1
                },
                {
                    "sent": "Well, one is sort of trivial.",
                    "label": 0
                },
                {
                    "sent": "If you have.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A higher degree.",
                    "label": 0
                },
                {
                    "sent": "That pin moves to the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is sort of turned around.",
                    "label": 0
                },
                {
                    "sent": "Higher degree P in critical goes down, but it also depends on is the shape of the degree distribution, and I was really surprised by this because this is a post sonion degree distribution and these are two different types of scale free degree distribution.",
                    "label": 0
                },
                {
                    "sent": "This one here has sort of a barabasi type thing.",
                    "label": 0
                },
                {
                    "sent": "It starts at a particular degree and then it goes power law all the way to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Whereas this one here starts a degree one.",
                    "label": 0
                },
                {
                    "sent": "I get a different average degree by adding a different Delta K to this thing here, so these two scale 3 degrees solutions have the same exponent, but one of them is sort of a straight line all the way, whereas the other is sort of curved at the beginning.",
                    "label": 0
                },
                {
                    "sent": "And inference is easier here.",
                    "label": 0
                },
                {
                    "sent": "Which is sort of surprising because the abyss rainy, which is.",
                    "label": 0
                },
                {
                    "sent": "Sort of homogeneous, is there it's most difficult to do inference if you want to look at it like this.",
                    "label": 0
                },
                {
                    "sent": "No, it's Infinity.",
                    "label": 0
                },
                {
                    "sent": "It's a thermodynamic limit calculation.",
                    "label": 0
                },
                {
                    "sent": "The side effect.",
                    "label": 0
                },
                {
                    "sent": "I mean I, I work on on the ensemble essentially, pardon me.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "What this here shows you is.",
                    "label": 0
                },
                {
                    "sent": "Maybe going back to this, this is the ratio of this naive estimate of this blue line.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Versus this one here and what you see is that as the average degree gets low.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After they move closer together, so that means and goes back to Professor Amaral's question.",
                    "label": 0
                },
                {
                    "sent": "If this line in this line here moves closer together for higher degree, that that means the transition gets steeper, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so recognizable structure starts at weaker cluster structures if you increase.",
                    "label": 1
                },
                {
                    "sent": "The average degree an it starts at weaker than you would expect naively.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, what do you do if you maybe have some label, some labeled data?",
                    "label": 0
                },
                {
                    "sent": "OK, you could say.",
                    "label": 0
                },
                {
                    "sent": "Well, I already know that some.",
                    "label": 0
                },
                {
                    "sent": "I know what race.",
                    "label": 0
                },
                {
                    "sent": "For instance, some of the nodes in the network are.",
                    "label": 0
                },
                {
                    "sent": "Let's say I have information about every thousand person and then that doesn't give you a lot of advantage, and but if you know 1%, that's already a little better.",
                    "label": 0
                },
                {
                    "sent": "If you know 10% then you sort of start to get this smooth transition.",
                    "label": 0
                },
                {
                    "sent": "Here we're already at the beginning.",
                    "label": 0
                },
                {
                    "sent": "You get some sort of inference here.",
                    "label": 0
                },
                {
                    "sent": "But what is interesting to note is that the advantage you get over having no labeled data is largest close to this transition point.",
                    "label": 0
                },
                {
                    "sent": "So that's very typical for phase transition, thank you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's that.",
                    "label": 0
                },
                {
                    "sent": "And then this is about the finite size effects, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Typical benchmark that people use for assessing the validity of network clustering algorithms.",
                    "label": 0
                },
                {
                    "sent": "So they say OK, we have 4 equal sized groups and we fix the average degree to 16 degrees.",
                    "label": 1
                },
                {
                    "sent": "Tribu Shun is parsonian nothing spectacular.",
                    "label": 0
                },
                {
                    "sent": "Somebody started this and then everybody picked up on it.",
                    "label": 0
                },
                {
                    "sent": "The typical thing that they do with.",
                    "label": 0
                },
                {
                    "sent": "In the papers is networks of size 128, and when you compare that those black diamonds here to the theoretical prediction, then you see actually inference is better than you predict.",
                    "label": 0
                },
                {
                    "sent": "But if you go to larger networks and fix the average degree still to 16, sorry network gets sparser, then you approach the theoretical curve quite well.",
                    "label": 0
                },
                {
                    "sent": "I use simulated annealing also like Professor MRL.",
                    "label": 0
                },
                {
                    "sent": "Has worked on.",
                    "label": 0
                },
                {
                    "sent": "It's like probably the most sensible thing to do.",
                    "label": 0
                },
                {
                    "sent": "Optimizing cut sizes by simulated annealing.",
                    "label": 0
                },
                {
                    "sent": "But what I?",
                    "label": 0
                },
                {
                    "sent": "Like to point out is that in principle for a very large network, there's no algorithm that can do.",
                    "label": 0
                },
                {
                    "sent": "Significantly better than this red curve.",
                    "label": 0
                },
                {
                    "sent": "OK, what happens if you have unequal size?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As clusters, well, nothing particular just looks the same.",
                    "label": 0
                },
                {
                    "sent": "This is again for this network with three links per node.",
                    "label": 1
                },
                {
                    "sent": "But now we have 2/3 of nodes or RF type A and 1 thirds of no dark type B.",
                    "label": 0
                },
                {
                    "sent": "So it's the same phenomenon.",
                    "label": 1
                },
                {
                    "sent": "What is interesting is that the transition point for the two classes at the same probability.",
                    "label": 0
                },
                {
                    "sent": "Here, but if you look at the table of errors.",
                    "label": 0
                },
                {
                    "sent": "For two groups, then it's obvious that it must be like this, you know, because.",
                    "label": 0
                },
                {
                    "sent": "What you are doing wrong in one you are also doing wrong.",
                    "label": 0
                },
                {
                    "sent": "In the other side, so it must be at the same point.",
                    "label": 0
                },
                {
                    "sent": "But what is now more difficult to assess is, well, do you plotted versus the probability that a link lies within the larger cluster or within the smaller cluster?",
                    "label": 0
                },
                {
                    "sent": "And what happens is that the transition point for the larger cluster is to the left of the transition point for the equal size cluster.",
                    "label": 0
                },
                {
                    "sent": "And if I would plot versus the probability PB given B, then it would be to the right of the case for two equal size clusters, so.",
                    "label": 0
                },
                {
                    "sent": "Even the case of equal size clusters sort of gives you an average kind of behavior for differently sized clusters.",
                    "label": 0
                },
                {
                    "sent": "So we're already at the conclusions.",
                    "label": 0
                },
                {
                    "sent": "Are we seen?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a sharp transition, at least for very large networks between the phase in which inference is absolutely impossible by definition, so to say because.",
                    "label": 0
                },
                {
                    "sent": "Other solutions obscure the true structure and a phase where inference is possible with high accuracy.",
                    "label": 0
                },
                {
                    "sent": "There are similar observations for multivariate.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data analysis that have been studied in physics.",
                    "label": 0
                },
                {
                    "sent": "So usually the setting there is.",
                    "label": 0
                },
                {
                    "sent": "I have a space of dimension D. And I have a number of samples from this space number is N. And then you observe the same kind of transition, but then it's always the ratio of the number of data points you sample from versus the dimension of the space from which you sample.",
                    "label": 1
                },
                {
                    "sent": "So if you keep the dimension of the space constant and sample more and more data, you always get across this transition point.",
                    "label": 0
                },
                {
                    "sent": "Alright, so essentially, given enough samples from a distribution, you can learn any distribution.",
                    "label": 1
                },
                {
                    "sent": "If you have sparse networks.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the average degrees finite, this is wrong, and the unfortunate thing is that all the networks the majority of networks we have in the real world are sparse.",
                    "label": 0
                },
                {
                    "sent": "And what I mean by this, I'd like to emphasize a lot of networks, model network models go.",
                    "label": 0
                },
                {
                    "sent": "There is a probability for two nodes being connected.",
                    "label": 0
                },
                {
                    "sent": "And they say it has value 0.1 OK. That means if the network doubles in size.",
                    "label": 0
                },
                {
                    "sent": "Then every node gets the double number of connections.",
                    "label": 0
                },
                {
                    "sent": "So the number of information per node also doubles by doubling the size of the network, but that's not what happens in the majority of networks.",
                    "label": 0
                },
                {
                    "sent": "You know if twice the number of people get a mobile phone.",
                    "label": 0
                },
                {
                    "sent": "The number of people you call doesn't double.",
                    "label": 0
                },
                {
                    "sent": "You know, or if you look, if you think of the Internet, if there are twice as many pages on the Internet, the number of links per page doesn't double either.",
                    "label": 0
                },
                {
                    "sent": "OK, so finite degree is something very real, and that's why if you take the thermodynamic limit, you have to assume that the degree is finite, and if you go to the literature and you look up this type of studies for network clustering algorithms, what they will usually do is they will say OK there is a link probability and then they will give you an estimate which says.",
                    "label": 0
                },
                {
                    "sent": "If 1 / sqrt N is smaller than some function of the link probability, then you can always infer things.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that the link probabilities are of the order of one over North, so comparing that with 1 / sqrt N doesn't make any sense.",
                    "label": 0
                },
                {
                    "sent": "OK, so for networks, dimensionality and size of the data set are essentially not.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Independent, that's that's the main problem.",
                    "label": 0
                },
                {
                    "sent": "There may exist structure that's principally undetectable by unsupervised methods.",
                    "label": 0
                },
                {
                    "sent": "But it is iaccessible to hypothesis.",
                    "label": 0
                },
                {
                    "sent": "The serious solutions of this said they obscure true structure.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you have some labeled data.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that that helps.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Analytically formula, or at least algorithms that calculate the transition points and the achievable accuracy.",
                    "label": 0
                },
                {
                    "sent": "And sort of as a final conclusion, I'd like to say data driven research will essentially tell.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About the strong effects.",
                    "label": 0
                },
                {
                    "sent": "But the good thing is it will tell you about all the strong effects.",
                    "label": 0
                },
                {
                    "sent": "OK, so the ones that you might miss if you don't have the right hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And the small effects are unfortunately only visible to hypothesis driven research.",
                    "label": 0
                },
                {
                    "sent": "So again, you see that the two things are complementary.",
                    "label": 0
                },
                {
                    "sent": "And with that I'd like to close and maybe for the.",
                    "label": 0
                },
                {
                    "sent": "Questions that point you to some references.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}