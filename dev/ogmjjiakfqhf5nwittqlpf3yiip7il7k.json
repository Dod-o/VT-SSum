{
    "id": "ogmjjiakfqhf5nwittqlpf3yiip7il7k",
    "title": "Neighborhood-based Tag Prediction",
    "info": {
        "author": [
            "Adriana Budura, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne"
        ],
        "published": "July 28, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Semantic Web->Annotation->Tagging"
        ]
    },
    "url": "http://videolectures.net/eswc09_budura_nbtp/",
    "segmentation": [
        [
            "Hello everyone I'm again Abdullah from EP FL and this is joint work with Sebastian Michelen Colaborar from EP FL and Philip could drama who are former colleague of ours from EP FL is now affiliated with MIT."
        ],
        [
            "I will start by giving a motivation for our work on tech prediction and then I will introduce the principles which have guided us in developing our algorithm based on these principles I will show how we derive a scoring model for assessing the relevance of A tag for a certain resource.",
            "Finally, I will present our top kaitag inference algorithm, show you what experimental results we have achieved and."
        ],
        [
            "Draw some conclusions.",
            "Let me start by making the observation that tagging portals supported by so called Web 2.0 technologies are today an integral part of the web.",
            "There are all sorts of platforms out there that offer the users the possibility of uploading and sharing, and also annotating resources with simple free text annotations.",
            "The types of resources that are supported depends on the depends on the.",
            "Portal we have images on Flickr.",
            "We have a web pages on delicieux or scientific publications inside too, like for example for US researchers, tags represent pieces of unstructured textual information that actually reflect the meaning of resources for the users.",
            "As such, they hold the great potential in improving search, for example by by including this user opinions into the ranking task.",
            "But in order to achieve meaningful results we need a lot of tags to reason on.",
            "And here we have a small problem because the users are lazy, they do upload a lot of items, but not often are the items tagged with many tags.",
            "Therefore, we believe that automatic tag inference.",
            "Is a promising direction that we should take and this is what this is the problem we are addressing in this work."
        ],
        [
            "The idea behind the behind our approach is straightforward.",
            "We want to enhance the set of tags attached to a given resource by simply copying text from other resources.",
            "While doing this, we make an important assumption, namely that semantically related resources should share similar or at least related tags.",
            "Now the question is how should we discover such semantically similar resources?",
            "For doing that, we turn to the users for help.",
            "It turns out that in many scenarios we have the resources that the users are sharing are actually connected via links by the users that have created them.",
            "We have web pages that are connected via HTML links or we have scientific publications that are connected by citations.",
            "We believe that the neighborhood of a resource captures its context and.",
            "For a concrete example, we just have to think at the related work section in our public in our papers, where we actually identify other publications that are related to our work and cite them.",
            "So the idea is to propagate tags along such edges of a document of a document graph.",
            "Now we can't simply gather all the tags from the neighborhood of of a document and assume that they are related to this document.",
            "Therefore we need a method of assessing how relevant is A tag that comes from a neighbor actually."
        ],
        [
            "My document.",
            "Now before going into more technical details, let me just briefly highlight the main concepts behind our model, so we look at documents that are the resources for which we infer tags.",
            "They are uniquely uniquely identifiable an.",
            "In our scenario, they represent either scientific publications or web pages.",
            "We have tags that are keywords which users attached to these resources, and we have document neighborhoods which are parts of of this document graphs which I have mentioned before."
        ],
        [
            "Now going back to the question of how do we?",
            "How do we assess the relevance of A tag from the neighborhood of a document to that given document?",
            "And to answer this question, we base ourselves on a couple of observations that are characteristic to our setting.",
            "I have mentioned before that we believe that the neighborhood of a resource defines its context text that appear further away should be less related to our to the paper for which we want to.",
            "In free text.",
            "That's why we want to incorporate a measure of tag distance to assess this.",
            "Exactly this distance from the observation point of attack to the paper for which one to infer that type.",
            "Now we don't believe that all the tags that appear in the immediate.",
            "Neighborhood of a resource are actually relevant for that resource.",
            "We we require text to have a certain support.",
            "In the neighborhood that is, we require them to occur a certain number of times.",
            "In order to to be able to say whether they are relevant or not.",
            "For that document, another observation is that some tags are more likely to occur together.",
            "That this because probably they refer to two similar concepts, and you users simply use them.",
            "Together.",
            "We will introduce therefore a measure of tech Co occurrence and to favor those tags from the neighborhood that occur together with text that have already been assigned to the document which we want to infer tax form.",
            "And finally, since tags are related to the content of the document, we want to capture also the document document similarity.",
            "Between the resources for which we want to infer tax."
        ],
        [
            "Let's look at a concrete example for what I have presented before.",
            "We have here graph of of academic publications that are citing each other and that are annotated with a couple of tags.",
            "Now let's assume that we want to infer more tags for this document, which we call the init that already has two tags assigned.",
            "We want to infer more text by by copying tags from its neighbors.",
            "Now the first observation.",
            "Would be that, for example if we look at all the neighbors, we see that attack IR appears.",
            "Is attached to each.",
            "Each of those papers.",
            "So this might mean that this tag is also relevant for our document.",
            "Second observation is that the tag that is already attached to the initial document occurs together with other two tags.",
            "You can see here IR and peer to peer occur together with distributed.",
            "This could mean that these tags are actually related so that maybe I are in peer to peer, also fit 2 to my document.",
            "However, we see here that peer to peer appears two hops away.",
            "From my document while for example IR appears already twice at a distance of 1, hop of with respect to my document, so it could be that peer to peer is not that much related.",
            "Finally, we can also look at the similarity between these two documents that hold, for example, the tag IR and the document that holds the tag IR in our document.",
            "And conclude that if they are similar, then maybe I are indeed is a very good option to attach to our doc you."
        ],
        [
            "Now I I will I named the principles which we base our algorithm on an.",
            "Now I will show how we derive specific scoring model scoring measures for each of these."
        ],
        [
            "This principles and let's start with the tag cooccurrence measure, which is supposed to assess the relevance of A tag for an initial document based on the tags that have already been assigned to that document.",
            "For that we use a simple conditional probability.",
            "Which equals the number of documents that have been annotated with both tags over the number of documents that have been annotated with attack that belongs to the initial document.",
            "Now, the initial document can have more than one initial tag, so therefore we need to aggregate, and we do this by simply summing up."
        ],
        [
            "The document document similarity looks at how how related the documents are on a content base.",
            "And for that we adopt A vector space model where each document is represented as a vector in a feature space generated from the terms that appear in the documents, and the similarity is then measured as the cosine between the angle of the of the two vectors.",
            "For documents that are several hops away from our initial document, we simply aggregate the similarities on the path by multiplying them."
        ],
        [
            "Finally, the tag distance and the tag occurrence measures for the tag distance.",
            "We simply take the smallest path between the observation point of A tag and our initial document and for the tag Co occurrence, which is supposed to assess them.",
            "The support of A tag in the neighborhood we simply sum up all the partial scores of that observed tag."
        ],
        [
            "Now finally we we put all these measures together into one scoring function that is supposed to assess the relevance of attack T coming from the neighborhood of a document of initial document with respect to that initial document, and for that we, as I mentioned before, we sum up all partial scores of the tag whenever it is observed in that in the neighborhood of the document.",
            "These partial scores are made out of two ingredients, one of them combines the document document similarity andetag distance, the other one, the tech Co occurrence.",
            "Finally the sum.",
            "Of the partial score actually.",
            "And reflect our tag occurrence principle where we count the support of the."
        ],
        [
            "In the neighborhood.",
            "Now that we know how to how to assess the relevance of A tag with respect to the initial document, let's see how we do this on the graph of documents."
        ],
        [
            "The idea here is that we should start from the document for which we want to infer more tags.",
            "We should traverse the graph of documents and gather.",
            "Gather possible tags for this initial document.",
            "Now there are some issues which we would like to consider here.",
            "First of all, we do not like to visit the whole neighborhood because this might be a bit too expensive, so we would like to have a smart, smart way of picking up picking only the most promising path.",
            "The path that would lead to the most promising tags for our document.",
            "The second issue is that in with our model, we can compute the score of any tag which we see for the document, but we wouldn't like to return.",
            "All the tags.",
            "For this document, because we might have simply too many and they might, it might be too noisy, so we would like a method that gives us the top K tags that can be found in the neighborhood of this document.",
            "Now, having said that.",
            "Another question is how do I know when to stop my graph traversal hide?",
            "How do I know if I have reached the top K best tags for this document?",
            "And this is what we will deal with?",
            "In the following couple of slides."
        ],
        [
            "Let's see first how our how our algorithm works, so we.",
            "Given that we want to infer tags for the this initial document, we look at all all its neighbors.",
            "And compute the scores of these neighbors with respect to this initial document and here for each tag the scores of each tag of these documents.",
            "So here we have, for example, document one that has the following tags, and these are the scores with respect to the initial document.",
            "Now when we want to decide which documents will be picked next, we simply pick the document that is the most similar to our."
        ],
        [
            "Initial document.",
            "Let's look at one specific instance in this algorithm, so we have again the initial document and we have the green documents that have already been visited.",
            "We keep we keep their tags in a list that is sorted, sorted in descending order of their score.",
            "We also have a list of neighbors of this document that are sorted by the Doc DOC similarity from this list, we pick the best document and compute the scores of of its tags finally.",
            "We we introduced this discourse into the list which we already have from the visited document and aggregate score when applicable, for example, so the tax social has had a score of zero 25.",
            "Now we observe the text social with a score of 04.",
            "Therefore the new score will be zero 65 because, as I said, we simply sum up all the scores for each observation of attack.",
            "Now, if we if we order this list, we have the top K tags at this point for the initial document.",
            "How?"
        ],
        [
            "But this still doesn't answer our question of when to stop.",
            "When do we know that we have reached all the top K tags that we want to return?",
            "And for that we we adapt faggins no random access algorithm.",
            "The following way for each candidate tag, we compute two different scores, a worst core, which is actually the actual score of the tag when it is observed, and the best score which is supposed to be the best possible score to come for that tag.",
            "Now we compute the best possible score to come, assuming that we will that we will meet the tag on the best path that we have have already visited so far.",
            "In the future.",
            "Then we can.",
            "We can simply disregard attack when it's best score to come is smaller than the score of A tag of the tech currently at rank 8.",
            "This means that in the best best case, this tag has no chance of reaching of entering into the top K list.",
            "We stop when we have seen K tags and when there are no candidate tags left in our list.",
            "However, we still have a problem, namely as I said here we we assume that we observe the tag once on the best possible path so far, but since we are summing up all the all the observation points.",
            "We have to.",
            "We don't know the final score mass for each tag because it can be that I observe it a great big number of times and the best score will be very high in the future.",
            "Therefore we have to limit the number of considered occurrences for each tag.",
            "And we introduce a parameter M. In this way, when I meet a new tag which I have with me to tag, which I have seen already M prime times, it's best score can be only N -- M prime.",
            "The best quarter come because I will not consider more than Emma currencies.",
            "And now let's look at a simple example we have here three different tags with their worst and the best scores.",
            "Assume now that the blue tag is the last tag in the top K list.",
            "The worst tag from top K. In this case, we can already expelled the red tag because it's best for is smaller than the worst score of the of the top K tag, while the green tag we still have to keep because.",
            "It can still reach a best score that is higher than this score."
        ],
        [
            "And now let's see how our method works in."
        ],
        [
            "Practice we have we have run our experiments on two different datasets, one extracted from delicius and one from the side to like portal and the citations we have we have extracted from sites here as measures of interest.",
            "We have precision.",
            "Which represents the number of correctly infer types over the number of all in.",
            "For tags we have two kinds of precision, the absolute precision which we take from a user study and the relative precision which we compute based on already assigned text.",
            "That is, we hide a portion of the tags and then we try to reconstruct it.",
            "And finally we also look at the cost in terms of the number of neighbors that we have visited during our."
        ],
        [
            "Angry.",
            "Now the results for the site like experiment.",
            "We have 30 initial documents.",
            "If for which we infer tags, and as I mentioned before, we have conducted a user study.",
            "We gave each different each document to three different users, and then we took the best best result.",
            "The best opinion, I mean where they wear their opinion coincides.",
            "We see here that procedure we have different values of sorry.",
            "We have different values of M&K.",
            "We see that precision goes down with K, which is to be expected.",
            "Another interesting observation is that the number of neighbors which we explore growth with M. This means this is also to be expected because M actually controls the number of occurrences that I allow for each tag.",
            "So the bigger MI will.",
            "I hope that I find the tag further away.",
            "I allow to have it several times, so I will move further away from the initial paper.",
            "However, we see that the precision, for example for K3M7, OK City and three, the precision doesn't grow.",
            "This somehow supports our intuition that the most interesting tags can be found in the immediate.",
            "Neighborhood of a paper, and the more further we get, the more noise noise we gather, so it doesn't make sense actually to move too much away."
        ],
        [
            "Now the delicious results here we took 120 initial documents and we made a relative precision evaluation.",
            "You will see now that the precision values are slightly lower than in the side too like case and this is due to two different reasons.",
            "On the one hand, since the precision evaluation is relative, we get a lot of false negatives, so we infer text that are correct, but they weren't assigned to that papers by users and we consider is correct.",
            "Only tags that have already that are already been assigned.",
            "Another another reason for that is.",
            "Quite obvious in the neighbors column where we have constant number of neighbors that is really small.",
            "Now this is a sort of unfortunate characteristic of our data set.",
            "Because you see, we require that not only the initial document is present and tagged in delicious, but that all its neighbors are tagged in delicieux.",
            "And sorry that all its neighbors are tagged in delicious and this doesn't happen very often, so you have a magazine or more also authoritative web page that is tagged in delicious.",
            "But then from all these neighbors, only one of them will be will appear in this data set.",
            "So the problem is that we have a very sparse data set there, but still we managed to infer a couple of Korea."
        ],
        [
            "Qtext and now to the conclusions we have.",
            "I have presented A tag inference algorithm over the edges of resource graph.",
            "We have four different principles for which we derive measures and combine these measures in into into one scoring model.",
            "And finally we have a top kaitag inference and traversal graph traversal algorithm that makes modest access to the resource graph.",
            "Thank you for your attention and.",
            "OK, so my question is really regarding the valuation that you are doing.",
            "We are working on a subjective world, so every everybody thinks that the tags that they are assigning probably are the best ones and you are making an evaluation where.",
            "People, I mean you're getting into composition and the position that you are taking into account is basically based on what the value waiters have said that they it's the most important tax.",
            "Is that really the right way too?",
            "I mean, it's like a general question is not only on your on your work, but it's like a general question for all of us.",
            "Is that really the best way to identify that this is, I mean that this is a good worker North and I mean it's it's.",
            "I think there is no no not one answer to your question.",
            "So basically it's true tags are subjective and that's why I mean we did our best.",
            "That's why we wanted to take also the automatic one where we say OK. Users have attached these tags.",
            "They believe that they are important, but I can't judge whether it's whether they are right or wrong.",
            "You see, and we actually had a lot of discussions on this issue because when you submit the paper you want to show like again, the best precision values and then people would ask.",
            "OK, why isn't it 99%?",
            "If your method works, but?",
            "I don't know because some people think that one tag is relevant.",
            "Some people think it's another one.",
            "We also tried when we conducted our user studies we didn't know.",
            "Should we ask users for a binary answer?",
            "Yes, no.",
            "Or should we say relevant kind of relevant, not relevant, But then how do you aggregate these?",
            "What does it mean if if, for example, if you have a tax system, I think it fits too.",
            "I don't know.",
            "70% of all computer science papers, right?",
            "Everyone present, or like I don't know.",
            "Evaluation or experiments.",
            "So yeah, there is no answer.",
            "This is I can only tell you how we conducted the experiment and then let's say it's up to you to judge how meaningful their results are.",
            "Not you see.",
            "Have you actually tried turning it around?",
            "Asking users to to find a document again based on certain search topics?",
            "I mean if you can use the tags for searching element in the body, did they actually find the document they wanted?",
            "So I haven't conducted such a study myself, but people have looked actually at the overlap between queries from web search engines and tags and this might answer your questions and they found that actually the two overlap and I think there are even studies where they showed that.",
            "When you query and then in Google you put a query in Google.",
            "Then you get a top top answer and then you check the tags for that answer.",
            "Actually they overlap with the queries for that so.",
            "But that's not my work, but people have looked at that.",
            "So thanks for the interesting talk.",
            "Just to follow up.",
            "Actually on on his comment.",
            "Do you have any ideas of the tasks that could be enhanced by this?",
            "You know this related tags or what your motivation for doing this work OK, I think.",
            "Well, I would think that search as a primary application for this because you see.",
            "So what is very interesting now?",
            "And that's why actually tags have attracted large interest from the research community.",
            "In the last year I would say it's been like a boom.",
            "It's the fact that until now we were only only relying on the content.",
            "Now the content is created by one person right by the Creator, or OK.",
            "If you want a team of people, but it's sort of 1 sided while the tags offer us an opinion and opinion of large amount of people on this paper or whatever it is, so I think it's very very interesting if we introduce this into the ranking.",
            "Like I don't want a paper that describes.",
            "I don't know if.",
            "That describes inferencing tags.",
            "I want the best paper that describes inferencing and this you can't get from the from the content right?",
            "Google gets this by looking at the links in web pages and they say, OK, they don't look only at the content.",
            "They say, OK, this content wise the page fits the query.",
            "Now let's see whether other people think it's important whether they link to it and how important it is.",
            "Now we can do this not only with the link structure but also with the information which people attached to these.",
            "And then another example is where tags are very useful is for example image retrieval content based image retrieval.",
            "Now you've seen earlier also that feature if you extract features and try to compare images or videos it doesn't really work.",
            "Now imagine how good it is now that you have people actually attaching words which we know how to process differently to images, right?",
            "It's not just the house, it's some cathedral or I don't know and we even know which cathedral and.",
            "So and so in this case.",
            "Again, it's very very.",
            "I think it's very useful to have a lot of tags.",
            "But again, the problem is that it's unstructured, so they're unstructured data.",
            "Yeah we have to work on that.",
            "And actually there are papers that try to infer ontologies from tags.",
            "Another interesting.",
            "Idea?",
            "OK. No more burning questions.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone I'm again Abdullah from EP FL and this is joint work with Sebastian Michelen Colaborar from EP FL and Philip could drama who are former colleague of ours from EP FL is now affiliated with MIT.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will start by giving a motivation for our work on tech prediction and then I will introduce the principles which have guided us in developing our algorithm based on these principles I will show how we derive a scoring model for assessing the relevance of A tag for a certain resource.",
                    "label": 0
                },
                {
                    "sent": "Finally, I will present our top kaitag inference algorithm, show you what experimental results we have achieved and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Draw some conclusions.",
                    "label": 0
                },
                {
                    "sent": "Let me start by making the observation that tagging portals supported by so called Web 2.0 technologies are today an integral part of the web.",
                    "label": 0
                },
                {
                    "sent": "There are all sorts of platforms out there that offer the users the possibility of uploading and sharing, and also annotating resources with simple free text annotations.",
                    "label": 0
                },
                {
                    "sent": "The types of resources that are supported depends on the depends on the.",
                    "label": 0
                },
                {
                    "sent": "Portal we have images on Flickr.",
                    "label": 0
                },
                {
                    "sent": "We have a web pages on delicieux or scientific publications inside too, like for example for US researchers, tags represent pieces of unstructured textual information that actually reflect the meaning of resources for the users.",
                    "label": 1
                },
                {
                    "sent": "As such, they hold the great potential in improving search, for example by by including this user opinions into the ranking task.",
                    "label": 1
                },
                {
                    "sent": "But in order to achieve meaningful results we need a lot of tags to reason on.",
                    "label": 0
                },
                {
                    "sent": "And here we have a small problem because the users are lazy, they do upload a lot of items, but not often are the items tagged with many tags.",
                    "label": 1
                },
                {
                    "sent": "Therefore, we believe that automatic tag inference.",
                    "label": 0
                },
                {
                    "sent": "Is a promising direction that we should take and this is what this is the problem we are addressing in this work.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea behind the behind our approach is straightforward.",
                    "label": 0
                },
                {
                    "sent": "We want to enhance the set of tags attached to a given resource by simply copying text from other resources.",
                    "label": 0
                },
                {
                    "sent": "While doing this, we make an important assumption, namely that semantically related resources should share similar or at least related tags.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how should we discover such semantically similar resources?",
                    "label": 0
                },
                {
                    "sent": "For doing that, we turn to the users for help.",
                    "label": 0
                },
                {
                    "sent": "It turns out that in many scenarios we have the resources that the users are sharing are actually connected via links by the users that have created them.",
                    "label": 0
                },
                {
                    "sent": "We have web pages that are connected via HTML links or we have scientific publications that are connected by citations.",
                    "label": 0
                },
                {
                    "sent": "We believe that the neighborhood of a resource captures its context and.",
                    "label": 1
                },
                {
                    "sent": "For a concrete example, we just have to think at the related work section in our public in our papers, where we actually identify other publications that are related to our work and cite them.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to propagate tags along such edges of a document of a document graph.",
                    "label": 0
                },
                {
                    "sent": "Now we can't simply gather all the tags from the neighborhood of of a document and assume that they are related to this document.",
                    "label": 1
                },
                {
                    "sent": "Therefore we need a method of assessing how relevant is A tag that comes from a neighbor actually.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My document.",
                    "label": 0
                },
                {
                    "sent": "Now before going into more technical details, let me just briefly highlight the main concepts behind our model, so we look at documents that are the resources for which we infer tags.",
                    "label": 1
                },
                {
                    "sent": "They are uniquely uniquely identifiable an.",
                    "label": 1
                },
                {
                    "sent": "In our scenario, they represent either scientific publications or web pages.",
                    "label": 0
                },
                {
                    "sent": "We have tags that are keywords which users attached to these resources, and we have document neighborhoods which are parts of of this document graphs which I have mentioned before.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now going back to the question of how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we assess the relevance of A tag from the neighborhood of a document to that given document?",
                    "label": 0
                },
                {
                    "sent": "And to answer this question, we base ourselves on a couple of observations that are characteristic to our setting.",
                    "label": 0
                },
                {
                    "sent": "I have mentioned before that we believe that the neighborhood of a resource defines its context text that appear further away should be less related to our to the paper for which we want to.",
                    "label": 0
                },
                {
                    "sent": "In free text.",
                    "label": 0
                },
                {
                    "sent": "That's why we want to incorporate a measure of tag distance to assess this.",
                    "label": 0
                },
                {
                    "sent": "Exactly this distance from the observation point of attack to the paper for which one to infer that type.",
                    "label": 0
                },
                {
                    "sent": "Now we don't believe that all the tags that appear in the immediate.",
                    "label": 0
                },
                {
                    "sent": "Neighborhood of a resource are actually relevant for that resource.",
                    "label": 0
                },
                {
                    "sent": "We we require text to have a certain support.",
                    "label": 0
                },
                {
                    "sent": "In the neighborhood that is, we require them to occur a certain number of times.",
                    "label": 1
                },
                {
                    "sent": "In order to to be able to say whether they are relevant or not.",
                    "label": 0
                },
                {
                    "sent": "For that document, another observation is that some tags are more likely to occur together.",
                    "label": 1
                },
                {
                    "sent": "That this because probably they refer to two similar concepts, and you users simply use them.",
                    "label": 0
                },
                {
                    "sent": "Together.",
                    "label": 0
                },
                {
                    "sent": "We will introduce therefore a measure of tech Co occurrence and to favor those tags from the neighborhood that occur together with text that have already been assigned to the document which we want to infer tax form.",
                    "label": 0
                },
                {
                    "sent": "And finally, since tags are related to the content of the document, we want to capture also the document document similarity.",
                    "label": 0
                },
                {
                    "sent": "Between the resources for which we want to infer tax.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look at a concrete example for what I have presented before.",
                    "label": 0
                },
                {
                    "sent": "We have here graph of of academic publications that are citing each other and that are annotated with a couple of tags.",
                    "label": 0
                },
                {
                    "sent": "Now let's assume that we want to infer more tags for this document, which we call the init that already has two tags assigned.",
                    "label": 0
                },
                {
                    "sent": "We want to infer more text by by copying tags from its neighbors.",
                    "label": 0
                },
                {
                    "sent": "Now the first observation.",
                    "label": 0
                },
                {
                    "sent": "Would be that, for example if we look at all the neighbors, we see that attack IR appears.",
                    "label": 0
                },
                {
                    "sent": "Is attached to each.",
                    "label": 0
                },
                {
                    "sent": "Each of those papers.",
                    "label": 0
                },
                {
                    "sent": "So this might mean that this tag is also relevant for our document.",
                    "label": 0
                },
                {
                    "sent": "Second observation is that the tag that is already attached to the initial document occurs together with other two tags.",
                    "label": 0
                },
                {
                    "sent": "You can see here IR and peer to peer occur together with distributed.",
                    "label": 0
                },
                {
                    "sent": "This could mean that these tags are actually related so that maybe I are in peer to peer, also fit 2 to my document.",
                    "label": 0
                },
                {
                    "sent": "However, we see here that peer to peer appears two hops away.",
                    "label": 0
                },
                {
                    "sent": "From my document while for example IR appears already twice at a distance of 1, hop of with respect to my document, so it could be that peer to peer is not that much related.",
                    "label": 0
                },
                {
                    "sent": "Finally, we can also look at the similarity between these two documents that hold, for example, the tag IR and the document that holds the tag IR in our document.",
                    "label": 0
                },
                {
                    "sent": "And conclude that if they are similar, then maybe I are indeed is a very good option to attach to our doc you.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I I will I named the principles which we base our algorithm on an.",
                    "label": 0
                },
                {
                    "sent": "Now I will show how we derive specific scoring model scoring measures for each of these.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This principles and let's start with the tag cooccurrence measure, which is supposed to assess the relevance of A tag for an initial document based on the tags that have already been assigned to that document.",
                    "label": 1
                },
                {
                    "sent": "For that we use a simple conditional probability.",
                    "label": 0
                },
                {
                    "sent": "Which equals the number of documents that have been annotated with both tags over the number of documents that have been annotated with attack that belongs to the initial document.",
                    "label": 1
                },
                {
                    "sent": "Now, the initial document can have more than one initial tag, so therefore we need to aggregate, and we do this by simply summing up.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The document document similarity looks at how how related the documents are on a content base.",
                    "label": 0
                },
                {
                    "sent": "And for that we adopt A vector space model where each document is represented as a vector in a feature space generated from the terms that appear in the documents, and the similarity is then measured as the cosine between the angle of the of the two vectors.",
                    "label": 0
                },
                {
                    "sent": "For documents that are several hops away from our initial document, we simply aggregate the similarities on the path by multiplying them.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, the tag distance and the tag occurrence measures for the tag distance.",
                    "label": 0
                },
                {
                    "sent": "We simply take the smallest path between the observation point of A tag and our initial document and for the tag Co occurrence, which is supposed to assess them.",
                    "label": 0
                },
                {
                    "sent": "The support of A tag in the neighborhood we simply sum up all the partial scores of that observed tag.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now finally we we put all these measures together into one scoring function that is supposed to assess the relevance of attack T coming from the neighborhood of a document of initial document with respect to that initial document, and for that we, as I mentioned before, we sum up all partial scores of the tag whenever it is observed in that in the neighborhood of the document.",
                    "label": 1
                },
                {
                    "sent": "These partial scores are made out of two ingredients, one of them combines the document document similarity andetag distance, the other one, the tech Co occurrence.",
                    "label": 0
                },
                {
                    "sent": "Finally the sum.",
                    "label": 0
                },
                {
                    "sent": "Of the partial score actually.",
                    "label": 0
                },
                {
                    "sent": "And reflect our tag occurrence principle where we count the support of the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the neighborhood.",
                    "label": 0
                },
                {
                    "sent": "Now that we know how to how to assess the relevance of A tag with respect to the initial document, let's see how we do this on the graph of documents.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea here is that we should start from the document for which we want to infer more tags.",
                    "label": 0
                },
                {
                    "sent": "We should traverse the graph of documents and gather.",
                    "label": 1
                },
                {
                    "sent": "Gather possible tags for this initial document.",
                    "label": 0
                },
                {
                    "sent": "Now there are some issues which we would like to consider here.",
                    "label": 0
                },
                {
                    "sent": "First of all, we do not like to visit the whole neighborhood because this might be a bit too expensive, so we would like to have a smart, smart way of picking up picking only the most promising path.",
                    "label": 0
                },
                {
                    "sent": "The path that would lead to the most promising tags for our document.",
                    "label": 0
                },
                {
                    "sent": "The second issue is that in with our model, we can compute the score of any tag which we see for the document, but we wouldn't like to return.",
                    "label": 0
                },
                {
                    "sent": "All the tags.",
                    "label": 0
                },
                {
                    "sent": "For this document, because we might have simply too many and they might, it might be too noisy, so we would like a method that gives us the top K tags that can be found in the neighborhood of this document.",
                    "label": 0
                },
                {
                    "sent": "Now, having said that.",
                    "label": 0
                },
                {
                    "sent": "Another question is how do I know when to stop my graph traversal hide?",
                    "label": 0
                },
                {
                    "sent": "How do I know if I have reached the top K best tags for this document?",
                    "label": 0
                },
                {
                    "sent": "And this is what we will deal with?",
                    "label": 0
                },
                {
                    "sent": "In the following couple of slides.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see first how our how our algorithm works, so we.",
                    "label": 0
                },
                {
                    "sent": "Given that we want to infer tags for the this initial document, we look at all all its neighbors.",
                    "label": 0
                },
                {
                    "sent": "And compute the scores of these neighbors with respect to this initial document and here for each tag the scores of each tag of these documents.",
                    "label": 0
                },
                {
                    "sent": "So here we have, for example, document one that has the following tags, and these are the scores with respect to the initial document.",
                    "label": 0
                },
                {
                    "sent": "Now when we want to decide which documents will be picked next, we simply pick the document that is the most similar to our.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Initial document.",
                    "label": 0
                },
                {
                    "sent": "Let's look at one specific instance in this algorithm, so we have again the initial document and we have the green documents that have already been visited.",
                    "label": 0
                },
                {
                    "sent": "We keep we keep their tags in a list that is sorted, sorted in descending order of their score.",
                    "label": 0
                },
                {
                    "sent": "We also have a list of neighbors of this document that are sorted by the Doc DOC similarity from this list, we pick the best document and compute the scores of of its tags finally.",
                    "label": 1
                },
                {
                    "sent": "We we introduced this discourse into the list which we already have from the visited document and aggregate score when applicable, for example, so the tax social has had a score of zero 25.",
                    "label": 0
                },
                {
                    "sent": "Now we observe the text social with a score of 04.",
                    "label": 0
                },
                {
                    "sent": "Therefore the new score will be zero 65 because, as I said, we simply sum up all the scores for each observation of attack.",
                    "label": 0
                },
                {
                    "sent": "Now, if we if we order this list, we have the top K tags at this point for the initial document.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But this still doesn't answer our question of when to stop.",
                    "label": 0
                },
                {
                    "sent": "When do we know that we have reached all the top K tags that we want to return?",
                    "label": 0
                },
                {
                    "sent": "And for that we we adapt faggins no random access algorithm.",
                    "label": 0
                },
                {
                    "sent": "The following way for each candidate tag, we compute two different scores, a worst core, which is actually the actual score of the tag when it is observed, and the best score which is supposed to be the best possible score to come for that tag.",
                    "label": 1
                },
                {
                    "sent": "Now we compute the best possible score to come, assuming that we will that we will meet the tag on the best path that we have have already visited so far.",
                    "label": 0
                },
                {
                    "sent": "In the future.",
                    "label": 0
                },
                {
                    "sent": "Then we can.",
                    "label": 1
                },
                {
                    "sent": "We can simply disregard attack when it's best score to come is smaller than the score of A tag of the tech currently at rank 8.",
                    "label": 0
                },
                {
                    "sent": "This means that in the best best case, this tag has no chance of reaching of entering into the top K list.",
                    "label": 0
                },
                {
                    "sent": "We stop when we have seen K tags and when there are no candidate tags left in our list.",
                    "label": 1
                },
                {
                    "sent": "However, we still have a problem, namely as I said here we we assume that we observe the tag once on the best possible path so far, but since we are summing up all the all the observation points.",
                    "label": 1
                },
                {
                    "sent": "We have to.",
                    "label": 0
                },
                {
                    "sent": "We don't know the final score mass for each tag because it can be that I observe it a great big number of times and the best score will be very high in the future.",
                    "label": 0
                },
                {
                    "sent": "Therefore we have to limit the number of considered occurrences for each tag.",
                    "label": 0
                },
                {
                    "sent": "And we introduce a parameter M. In this way, when I meet a new tag which I have with me to tag, which I have seen already M prime times, it's best score can be only N -- M prime.",
                    "label": 0
                },
                {
                    "sent": "The best quarter come because I will not consider more than Emma currencies.",
                    "label": 0
                },
                {
                    "sent": "And now let's look at a simple example we have here three different tags with their worst and the best scores.",
                    "label": 0
                },
                {
                    "sent": "Assume now that the blue tag is the last tag in the top K list.",
                    "label": 0
                },
                {
                    "sent": "The worst tag from top K. In this case, we can already expelled the red tag because it's best for is smaller than the worst score of the of the top K tag, while the green tag we still have to keep because.",
                    "label": 0
                },
                {
                    "sent": "It can still reach a best score that is higher than this score.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now let's see how our method works in.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Practice we have we have run our experiments on two different datasets, one extracted from delicius and one from the side to like portal and the citations we have we have extracted from sites here as measures of interest.",
                    "label": 0
                },
                {
                    "sent": "We have precision.",
                    "label": 0
                },
                {
                    "sent": "Which represents the number of correctly infer types over the number of all in.",
                    "label": 0
                },
                {
                    "sent": "For tags we have two kinds of precision, the absolute precision which we take from a user study and the relative precision which we compute based on already assigned text.",
                    "label": 1
                },
                {
                    "sent": "That is, we hide a portion of the tags and then we try to reconstruct it.",
                    "label": 0
                },
                {
                    "sent": "And finally we also look at the cost in terms of the number of neighbors that we have visited during our.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Angry.",
                    "label": 0
                },
                {
                    "sent": "Now the results for the site like experiment.",
                    "label": 0
                },
                {
                    "sent": "We have 30 initial documents.",
                    "label": 1
                },
                {
                    "sent": "If for which we infer tags, and as I mentioned before, we have conducted a user study.",
                    "label": 0
                },
                {
                    "sent": "We gave each different each document to three different users, and then we took the best best result.",
                    "label": 0
                },
                {
                    "sent": "The best opinion, I mean where they wear their opinion coincides.",
                    "label": 0
                },
                {
                    "sent": "We see here that procedure we have different values of sorry.",
                    "label": 0
                },
                {
                    "sent": "We have different values of M&K.",
                    "label": 0
                },
                {
                    "sent": "We see that precision goes down with K, which is to be expected.",
                    "label": 0
                },
                {
                    "sent": "Another interesting observation is that the number of neighbors which we explore growth with M. This means this is also to be expected because M actually controls the number of occurrences that I allow for each tag.",
                    "label": 0
                },
                {
                    "sent": "So the bigger MI will.",
                    "label": 0
                },
                {
                    "sent": "I hope that I find the tag further away.",
                    "label": 0
                },
                {
                    "sent": "I allow to have it several times, so I will move further away from the initial paper.",
                    "label": 0
                },
                {
                    "sent": "However, we see that the precision, for example for K3M7, OK City and three, the precision doesn't grow.",
                    "label": 0
                },
                {
                    "sent": "This somehow supports our intuition that the most interesting tags can be found in the immediate.",
                    "label": 0
                },
                {
                    "sent": "Neighborhood of a paper, and the more further we get, the more noise noise we gather, so it doesn't make sense actually to move too much away.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the delicious results here we took 120 initial documents and we made a relative precision evaluation.",
                    "label": 1
                },
                {
                    "sent": "You will see now that the precision values are slightly lower than in the side too like case and this is due to two different reasons.",
                    "label": 0
                },
                {
                    "sent": "On the one hand, since the precision evaluation is relative, we get a lot of false negatives, so we infer text that are correct, but they weren't assigned to that papers by users and we consider is correct.",
                    "label": 0
                },
                {
                    "sent": "Only tags that have already that are already been assigned.",
                    "label": 0
                },
                {
                    "sent": "Another another reason for that is.",
                    "label": 0
                },
                {
                    "sent": "Quite obvious in the neighbors column where we have constant number of neighbors that is really small.",
                    "label": 0
                },
                {
                    "sent": "Now this is a sort of unfortunate characteristic of our data set.",
                    "label": 0
                },
                {
                    "sent": "Because you see, we require that not only the initial document is present and tagged in delicious, but that all its neighbors are tagged in delicieux.",
                    "label": 0
                },
                {
                    "sent": "And sorry that all its neighbors are tagged in delicious and this doesn't happen very often, so you have a magazine or more also authoritative web page that is tagged in delicious.",
                    "label": 0
                },
                {
                    "sent": "But then from all these neighbors, only one of them will be will appear in this data set.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that we have a very sparse data set there, but still we managed to infer a couple of Korea.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Qtext and now to the conclusions we have.",
                    "label": 0
                },
                {
                    "sent": "I have presented A tag inference algorithm over the edges of resource graph.",
                    "label": 1
                },
                {
                    "sent": "We have four different principles for which we derive measures and combine these measures in into into one scoring model.",
                    "label": 0
                },
                {
                    "sent": "And finally we have a top kaitag inference and traversal graph traversal algorithm that makes modest access to the resource graph.",
                    "label": 1
                },
                {
                    "sent": "Thank you for your attention and.",
                    "label": 0
                },
                {
                    "sent": "OK, so my question is really regarding the valuation that you are doing.",
                    "label": 0
                },
                {
                    "sent": "We are working on a subjective world, so every everybody thinks that the tags that they are assigning probably are the best ones and you are making an evaluation where.",
                    "label": 0
                },
                {
                    "sent": "People, I mean you're getting into composition and the position that you are taking into account is basically based on what the value waiters have said that they it's the most important tax.",
                    "label": 0
                },
                {
                    "sent": "Is that really the right way too?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's like a general question is not only on your on your work, but it's like a general question for all of us.",
                    "label": 0
                },
                {
                    "sent": "Is that really the best way to identify that this is, I mean that this is a good worker North and I mean it's it's.",
                    "label": 0
                },
                {
                    "sent": "I think there is no no not one answer to your question.",
                    "label": 0
                },
                {
                    "sent": "So basically it's true tags are subjective and that's why I mean we did our best.",
                    "label": 0
                },
                {
                    "sent": "That's why we wanted to take also the automatic one where we say OK. Users have attached these tags.",
                    "label": 0
                },
                {
                    "sent": "They believe that they are important, but I can't judge whether it's whether they are right or wrong.",
                    "label": 0
                },
                {
                    "sent": "You see, and we actually had a lot of discussions on this issue because when you submit the paper you want to show like again, the best precision values and then people would ask.",
                    "label": 0
                },
                {
                    "sent": "OK, why isn't it 99%?",
                    "label": 0
                },
                {
                    "sent": "If your method works, but?",
                    "label": 0
                },
                {
                    "sent": "I don't know because some people think that one tag is relevant.",
                    "label": 0
                },
                {
                    "sent": "Some people think it's another one.",
                    "label": 0
                },
                {
                    "sent": "We also tried when we conducted our user studies we didn't know.",
                    "label": 0
                },
                {
                    "sent": "Should we ask users for a binary answer?",
                    "label": 0
                },
                {
                    "sent": "Yes, no.",
                    "label": 0
                },
                {
                    "sent": "Or should we say relevant kind of relevant, not relevant, But then how do you aggregate these?",
                    "label": 0
                },
                {
                    "sent": "What does it mean if if, for example, if you have a tax system, I think it fits too.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "70% of all computer science papers, right?",
                    "label": 0
                },
                {
                    "sent": "Everyone present, or like I don't know.",
                    "label": 0
                },
                {
                    "sent": "Evaluation or experiments.",
                    "label": 0
                },
                {
                    "sent": "So yeah, there is no answer.",
                    "label": 0
                },
                {
                    "sent": "This is I can only tell you how we conducted the experiment and then let's say it's up to you to judge how meaningful their results are.",
                    "label": 0
                },
                {
                    "sent": "Not you see.",
                    "label": 0
                },
                {
                    "sent": "Have you actually tried turning it around?",
                    "label": 0
                },
                {
                    "sent": "Asking users to to find a document again based on certain search topics?",
                    "label": 0
                },
                {
                    "sent": "I mean if you can use the tags for searching element in the body, did they actually find the document they wanted?",
                    "label": 0
                },
                {
                    "sent": "So I haven't conducted such a study myself, but people have looked actually at the overlap between queries from web search engines and tags and this might answer your questions and they found that actually the two overlap and I think there are even studies where they showed that.",
                    "label": 0
                },
                {
                    "sent": "When you query and then in Google you put a query in Google.",
                    "label": 0
                },
                {
                    "sent": "Then you get a top top answer and then you check the tags for that answer.",
                    "label": 0
                },
                {
                    "sent": "Actually they overlap with the queries for that so.",
                    "label": 0
                },
                {
                    "sent": "But that's not my work, but people have looked at that.",
                    "label": 0
                },
                {
                    "sent": "So thanks for the interesting talk.",
                    "label": 0
                },
                {
                    "sent": "Just to follow up.",
                    "label": 0
                },
                {
                    "sent": "Actually on on his comment.",
                    "label": 0
                },
                {
                    "sent": "Do you have any ideas of the tasks that could be enhanced by this?",
                    "label": 0
                },
                {
                    "sent": "You know this related tags or what your motivation for doing this work OK, I think.",
                    "label": 0
                },
                {
                    "sent": "Well, I would think that search as a primary application for this because you see.",
                    "label": 0
                },
                {
                    "sent": "So what is very interesting now?",
                    "label": 0
                },
                {
                    "sent": "And that's why actually tags have attracted large interest from the research community.",
                    "label": 0
                },
                {
                    "sent": "In the last year I would say it's been like a boom.",
                    "label": 0
                },
                {
                    "sent": "It's the fact that until now we were only only relying on the content.",
                    "label": 0
                },
                {
                    "sent": "Now the content is created by one person right by the Creator, or OK.",
                    "label": 0
                },
                {
                    "sent": "If you want a team of people, but it's sort of 1 sided while the tags offer us an opinion and opinion of large amount of people on this paper or whatever it is, so I think it's very very interesting if we introduce this into the ranking.",
                    "label": 0
                },
                {
                    "sent": "Like I don't want a paper that describes.",
                    "label": 0
                },
                {
                    "sent": "I don't know if.",
                    "label": 0
                },
                {
                    "sent": "That describes inferencing tags.",
                    "label": 0
                },
                {
                    "sent": "I want the best paper that describes inferencing and this you can't get from the from the content right?",
                    "label": 0
                },
                {
                    "sent": "Google gets this by looking at the links in web pages and they say, OK, they don't look only at the content.",
                    "label": 0
                },
                {
                    "sent": "They say, OK, this content wise the page fits the query.",
                    "label": 0
                },
                {
                    "sent": "Now let's see whether other people think it's important whether they link to it and how important it is.",
                    "label": 0
                },
                {
                    "sent": "Now we can do this not only with the link structure but also with the information which people attached to these.",
                    "label": 0
                },
                {
                    "sent": "And then another example is where tags are very useful is for example image retrieval content based image retrieval.",
                    "label": 0
                },
                {
                    "sent": "Now you've seen earlier also that feature if you extract features and try to compare images or videos it doesn't really work.",
                    "label": 0
                },
                {
                    "sent": "Now imagine how good it is now that you have people actually attaching words which we know how to process differently to images, right?",
                    "label": 0
                },
                {
                    "sent": "It's not just the house, it's some cathedral or I don't know and we even know which cathedral and.",
                    "label": 0
                },
                {
                    "sent": "So and so in this case.",
                    "label": 0
                },
                {
                    "sent": "Again, it's very very.",
                    "label": 0
                },
                {
                    "sent": "I think it's very useful to have a lot of tags.",
                    "label": 0
                },
                {
                    "sent": "But again, the problem is that it's unstructured, so they're unstructured data.",
                    "label": 0
                },
                {
                    "sent": "Yeah we have to work on that.",
                    "label": 0
                },
                {
                    "sent": "And actually there are papers that try to infer ontologies from tags.",
                    "label": 0
                },
                {
                    "sent": "Another interesting.",
                    "label": 0
                },
                {
                    "sent": "Idea?",
                    "label": 0
                },
                {
                    "sent": "OK. No more burning questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}