{
    "id": "m56w6qjorshrbgano27vdpfwnbg6gotl",
    "title": "A Support Vector Machine Approach to Dutch Part-of-Speech Tagging",
    "info": {
        "author": [
            "Mannes Poel, University of Twente"
        ],
        "published": "Oct. 8, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Speech Analysis",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/ida07_poel_asvma/",
    "segmentation": [
        [
            "Thank you, let me just point out how we have divided to work within this research.",
            "Reach Opener is a member of our group which is expert in natural language processing myself.",
            "I'm more familiar with machine learning and we had a very highly intelligent master student who had to do all the work.",
            "The Dirty work in programming and trying to come up trying to see if our guesses worked or advises if they were really helpful.",
            "So let me."
        ],
        [
            "Give you small town of my talk, will talk a little bit about the corpus spoken Dutch.",
            "That's a large corpus we use in the Netherlands for natural language processing, evaluating methods for natural language processing.",
            "One of the problems we have if you want to model this analyze or.",
            "Mantoux text when you first try to do part of speech tagging saying is this word unknown?",
            "Is it a verb, etc.",
            "And then of course, you want to automatically.",
            "So we designed a support vector machine based part of speech tagger and will tell a little bit how we did it.",
            "Then we have a final evaluation cause in between there are some evaluations on a validation set, how our designs performed.",
            "Of course I will conclude with the conclude."
        ],
        [
            "The couple spoken Dutch qidian Corpus was broken headlines.",
            "It's a very large corpus.",
            "It's about 9 million transcribe words, so it's from speech.",
            "It's not from text, meaning that also typical spoken words in it off words, because somebody wants changed his mind, etc.",
            "And a lot of different categories.",
            "You see, 15.",
            "You see some of them here face to face conversations with two point 6 million words.",
            "Also a very small one.",
            "Masters in ceremonies, with 18,000 words, etc.",
            "Dutch, Why is that?",
            "Interview with teachers in Dutch?",
            "Because they're also Flemish.",
            "Let me say spoken.",
            "Text in it.",
            "And of course people know Flemish.",
            "It's a little bit different from Dutch, but it resembles Dutch.",
            "So you can see of course part commands to use quite different words than if you look at Masters ceremonies.",
            "That's why this whole corpus is annotated with part of speech tags and other linguistic features."
        ],
        [
            "Well, what kind of?",
            "One of the annotations is part of speech stacks.",
            "And if you look at Dutch, if you look at the corpus spoken Dutch 316, part of speed stacks, there's a very fine.",
            "Tuned and only some of these texts on your curfew times so.",
            "In our research and other research would be reduced the speed stacks, the power speed sticks now full of main classes, but they call the reduce part of speech tags that are non verbal let like which is instance of punctuation mark or?",
            "And of course these are the special marks from something which occur only in speech.",
            "But this is far too small if you use this kind of part of speech text, you cannot use it for further analysis of your text.",
            "So.",
            "What we considered is the exit consisting of 72 tags.",
            "Meaning every word in this corpus is must be assigned to one of these 72 texts.",
            "And you want to."
        ],
        [
            "Would automatically.",
            "Yeah, you can see the text said this is came up by Richard the Knocker and other researchers in natural language processing in Dutch.",
            "So these are not my ideas.",
            "So we have now and now you can have of course.",
            "As a plural single, and whatever verbs tense you can, gender, etc to differ between different forms of verbs, etc.",
            "You see the main 27 of the 72 speed stick used.",
            "To give you an idea of what what we used in this research."
        ],
        [
            "And why is this a problem?",
            "If you look at the frequency of words in this?",
            "In this corpus then you see words which occur 100 times.",
            "Then 50% of the words which occur 100 times.",
            "50% of 40% is ambitious meaning of different text depending on the context.",
            "So the context determines the tag of a word, and if you look at highly frequent words.",
            "Almost all of them are ambitious, meaning.",
            "They have different."
        ],
        [
            "Sex.",
            "So what was the challenge?",
            "Could come up with a support vector machine based part of speech tagger.",
            "Huawei support vector Machine based becausw from other researchers.",
            "Other research it is known that support vector machine can do a good job.",
            "Part of speech tagging.",
            "So that's one of the reasons.",
            "But if you look at the literature, most of them are on written text and all the other small corpus and not on the corpus of 9 million words.",
            "So the main challenge where this all can be used support vector machines for such a large corpus."
        ],
        [
            "First, of course, the design first before I tell you how we did it, we just want to focus a little bit on the design and the input coding.",
            "As usual, you sliding window be cause the tag of the word determined is determined by the context and we want to determine attack of W form the middle word.",
            "And of course then you take into account the context and the context, 3 words before the word you want to take in three words.",
            "After the words you want to take.",
            "So this is the window using all the tax W 4.",
            "So then you have to come up with an input code, because if you want to use support vector machines you should make it all numerical.",
            "So here you W1W 2W3 we use the power speed stack is 1 one out of encoding meaning one bit of 72 bits is 1 the other zero.",
            "You can see the relative text.",
            "We can see each of these words which.",
            "In the future, you use the relative tech frequencies based on your training set.",
            "Now you can use it for the capitalization because most of that Mr. Capital word it says something if it's not at the start of the sentence.",
            "Probably it's now set to run.",
            "You can use the length is used the number.",
            "Part of speech tag bigrams, 3 grams etc.",
            "This is all coming from the people working in natural language processing that these are relevant.",
            "Properties of these words.",
            "In order to determine the part of speech stack.",
            "But that means that you more or less can highly dimensional input coding, especially because you use this one out of encoding.",
            "That will blow up the dimensions of your input space, but one of their fans is of course that many.",
            "Let me so many components as Europe because this one out of him.",
            "So this the input coding used in its standard input coding used.",
            "In this kind of."
        ],
        [
            "Natural language processing.",
            "So, but we have a huge amount of data.",
            "So you cannot say well, just pick up a pick, a support vector machine.",
            "And just use the training data.",
            "Let me say one 910 to let me say 8 million sentences of 8 million words and put it in memory and try to come up with support vector machine with tech.",
            "These words it will not work.",
            "We have too much data, So what we did we tried to come up with a committee of support vector machine based.",
            "Or knowledge you have.",
            "So one of the things that W for the work we need to protect the common word mean it's the frequency is more than 50 in the training set.",
            "Then we for each such word.",
            "We train a different support vector machine.",
            "So meaning this would result in 795 support vector machines.",
            "So for this, for each word you have a common word, you have to support vector machine, meaning that.",
            "For W4 to let me set input coding for W4 is constant for the support vector machine, so it can be left out.",
            "Is W follows an uncommon word, meaning it only occurs relative infrequently or just a few times?",
            "Then you based.",
            "Then you construct a support vector machine for each reduced tag.",
            "Of W 3 revert proceeding W 4.",
            "You have 12 reduced X, so meaning that you have to look different support vector machines.",
            "An of course, but the main problem always is you have an unknown word.",
            "What is an unknown word.",
            "An unknown word is a word which doesn't occur in your training set, meaning you don't know anything about it because you didn't see it before.",
            "So you cannot say anything about the relative frequencies of the power, speed, stacks, etc.",
            "So also let me train to a different one.",
            "But we used again the reduced stack of W 3 W 3 and.",
            "The frequency of W4 is set to 0.",
            "And hence you can discard this one from the."
        ],
        [
            "Put coding.",
            "So initial Committee of Support vector machine work as follows.",
            "If WP4 is a common word then you select this specific machine related with this word.",
            "If it's an uncommon word, you select the support vector machine determined by the reduced tech of W 3.",
            "And if it's unknown word, you select the unknown support vector machine learning word support vector machine based again on the reduced deck of W 3.",
            "So meaning you split up.",
            "Immediately when you see your data point most of time on your committee, you fit all the data points to all your classifiers and determine an outcome at the end by combining them based on what we know and knowledge we have about part of speech, tagging, etc.",
            "We can do the decomposition immediately before.",
            "Given it to all the spectrum."
        ],
        [
            "Now, how did we evaluate this approach?",
            "From the corpus we constructed eleven sets.",
            "And to get a more less stratified you conversation, the first sentence of the corpus goes instead zero the second one and set one, etc.",
            "So you get eleven sets, set one up to set and including set.",
            "Then I use for training and validation, meaning that we use set one up to set nine for training and set 10 for validation and set zero.",
            "The box used for the ultimate Performance ultimate test we did on the performance of our approach."
        ],
        [
            "So if you want to use support vector machines, you need to decide what kernel to use.",
            "If you see what you see is given overall performance.",
            "I should remark that overall performance also include the normal basis words, so that's the reason why the overall performance is higher than all the performances here.",
            "You don't see any.",
            "You don't see much difference.",
            "It's not significant difference between the different kernels you can use.",
            "But you see a little bit here.",
            "You see that this one is for the uncommon one.",
            "This one is better, but unknown what this one is.",
            "Not the best one, but the second one.",
            "And that led us to decide to use a third order polynomial.",
            "You can argue that also from also linear one would do.",
            "I don't know.",
            "We have to decide which one to take.",
            "Decided based on performance on uncommon words an unknown words to use the 3rd order polynomial kernel.",
            "But what you see is that the performance on the unknown versus relatively low.",
            "So what can we do to increase this performance?",
            "And what way to do is, is that you compound analysis.",
            "It's very famous in Dutch and us with this."
        ],
        [
            "Interpret that we can just glue words together.",
            "Many Dutch water compounds search, for instance, coonfare databases, shoestring.",
            "Fist bump the tire of a bicycle, and even you have a fix ventile Doppler but yours may explain what it means.",
            "So very, you can even extend this one too much longer one, but we.",
            "Can glue words together still after me, which still has a meeting.",
            "So what you can do if you have an unknown word, try to decompose it in words you know words bits are in the training set.",
            "That's what compound analysis is, and most of the time the last compound determines the part of speech tag.",
            "So what we did is we use the kind of decomposition after word of unknown words determined.",
            "The last compound that should be in the in the training set and based on this last compound you can come up with a relative frequency of the part of speech tax and use that one.",
            "As in."
        ],
        [
            "Vacation.",
            "Now you can do it two ways.",
            "You can do a strict one.",
            "Meaning you divide it in two and both components must be in the training set.",
            "Or you just say, well, I do relax one only the second part, which is the most important part, should be in the lexical knowledge and training set.",
            "You see, if you do.",
            "The only district one you have coverage of 38% on unknown words.",
            "If you relax it recover it becomes higher but overall performance.",
            "On compounds decreases."
        ],
        [
            "So let us do a final, let's say committee of Support Vector machine for that's part of speech tagging.",
            "And this is exactly the same as the previous one.",
            "But if it's unknown what and you can compound this word, then you select the uncommon just the same one As for the uncommon word, but.",
            "And then you started the classification for your part of speed stick.",
            "And now, and if you cannot compound this word, then you use the support vector machine related to unknown."
        ],
        [
            "OK, let that increases the performance on unknown words drastically.",
            "It goes up from 53% to 70%.",
            "And the overall performance of this part of speech tagger is 97 and half percent.",
            "There's also a memory based part of speech tagger for Dutch, but it was not tested on a complete corpus, only part of the corpus.",
            "This is 95 or 96%.",
            "We also looked at the neural network based approach.",
            "Which has higher performance on known words but much less performance on unknown words."
        ],
        [
            "So if you look in more detail to the.",
            "Let me say to the best scoring to the evaluation.",
            "After the testing you see that one of the best scoring categories is is phone dialogues.",
            "'cause there's no, there's almost no month verbal communication involved, so we see all this based on words and then you see that is 98%.",
            "And of course, the worst scoring category, which one you could predict, let me almost predict at.",
            "Before you started at Martin ceremonies Becausw, they used kind of strange words, not typical Dutch words."
        ],
        [
            "OK.",
            "Conclusion We designed support fax machine Buster based battle part of speech stack.",
            "If it could handle this large coopera.",
            "It is a performance of 97 1/2% which is one of the highest.",
            "Low."
        ],
        [
            "Own, at least to us.",
            "And compound analysis.",
            "You can use compound analysis to improve the unknown word performance.",
            "And it also has a reasonable taking speed.",
            "1000 words a second, which is reasonable for part of speech tagger.",
            "In future we want look at other approaches based on the total corpus such as neural network based approach.",
            "Is it a Markov based approach?",
            "Brill Tagger, which is a famous tracker taken to evaluate it on the total corpus.",
            "OK, that concludes my talk.",
            "Question.",
            "I can try again.",
            "Combine because it's usually just compare classification errors more or less.",
            "Expectorants Sombra so yes, you can make a sandwich.",
            "You can maybe 1 one of them is better on unknown words.",
            "You can use that one for now.",
            "If you have an unknown word you can maybe use support vector machine.",
            "You can look at different categories in the Coop as well.",
            "This one is better and amassing ceremony so much knowledge based ways to use some kind of ensemble.",
            "Then just combining them.",
            "Let me say both let me say at the decision level.",
            "So the idea is to use more less knowledge of of the Dutch after pattern of the natural language processing you have.",
            "Also, you say it's impossible to use support vector machines on the full data set.",
            "Brochure.",
            "Very large computer can use the great, that's only in the future.",
            "Maybe 4 infusion would be possible, but.",
            "I don't think it will improve a lot because you use knowledge now from what sport is relevant and what do you shoot you look at, etc.",
            "Don't think if you just.",
            "Do the total data set use a large computer?",
            "Use one support vector machine to classify all.",
            "Don't think it will.",
            "Improve your performance.",
            "Fully understand the idea to use multiple classifiers.",
            "A swarm of classifiers.",
            "On the background, that human being is specially a telephone, dialogues are speaking in full sentences which have semantic background and which of course have some dependency.",
            "Multiple French from my point I didn't catch everything or intensive course may destroy these in the connection all day.",
            "How do you get it back that that you have the idea that the full fitting in.",
            "Sentence which is in some semantical, any reasonable.",
            "I I can't find a dollars for myself.",
            "Didn't completely becausw didn't use the full sentence.",
            "We say, well, the part of speech that is based on the context, but we just use several words of the context only when you're 7.",
            "Together they they should be assembled assets that a readable sentence comes up.",
            "I'm not sure it's a individual, the best classifier his son is picked up, but they absolutely bonkers.",
            "I don't think I agree with that because.",
            "Why should it be rubbish becausw?",
            "You take it when the count more or less the context which is more or less can say that's the semantic meaning of that word.",
            "Well, I give an example.",
            "I never say I enter the park and sit down on the bank.",
            "It can't be.",
            "Don't sit down in the financial institution.",
            "No, but this way if you use it, let me say it's one of the words and before bank then you know.",
            "But that's just an input coding.",
            "If you want to classify bank then you know one of the words before was.",
            "Yes.",
            "It's it's it's.",
            "It's."
        ],
        [
            "Well, less you have to encode, and it's a sliding window which you use certain words in the middle word you want to take.",
            "So meaning that some these words determine can determine the of course the part of speech take of this one.",
            "And then of course, then you use part of speech tags even you know which word it is, because you code the word for W1W2 W 3.",
            "But of course long-term dependencies.",
            "You cannot catch.",
            "The assumption is that you that is determined by.",
            "66 words surrounding W 4.",
            "The part of speech tag.",
            "That's the semantic session.",
            "The same measure uses some.",
            "If you look at the same technique, they say, well if you want to cluster documents on content then the content of the meaning of the word is determined by the words in front and after and we do the same.",
            "The part of speech stack of WFR determined by the words before W 4, three words before in three after.",
            "Instinct speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, let me just point out how we have divided to work within this research.",
                    "label": 0
                },
                {
                    "sent": "Reach Opener is a member of our group which is expert in natural language processing myself.",
                    "label": 0
                },
                {
                    "sent": "I'm more familiar with machine learning and we had a very highly intelligent master student who had to do all the work.",
                    "label": 0
                },
                {
                    "sent": "The Dirty work in programming and trying to come up trying to see if our guesses worked or advises if they were really helpful.",
                    "label": 0
                },
                {
                    "sent": "So let me.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Give you small town of my talk, will talk a little bit about the corpus spoken Dutch.",
                    "label": 0
                },
                {
                    "sent": "That's a large corpus we use in the Netherlands for natural language processing, evaluating methods for natural language processing.",
                    "label": 0
                },
                {
                    "sent": "One of the problems we have if you want to model this analyze or.",
                    "label": 1
                },
                {
                    "sent": "Mantoux text when you first try to do part of speech tagging saying is this word unknown?",
                    "label": 1
                },
                {
                    "sent": "Is it a verb, etc.",
                    "label": 0
                },
                {
                    "sent": "And then of course, you want to automatically.",
                    "label": 1
                },
                {
                    "sent": "So we designed a support vector machine based part of speech tagger and will tell a little bit how we did it.",
                    "label": 0
                },
                {
                    "sent": "Then we have a final evaluation cause in between there are some evaluations on a validation set, how our designs performed.",
                    "label": 0
                },
                {
                    "sent": "Of course I will conclude with the conclude.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The couple spoken Dutch qidian Corpus was broken headlines.",
                    "label": 0
                },
                {
                    "sent": "It's a very large corpus.",
                    "label": 1
                },
                {
                    "sent": "It's about 9 million transcribe words, so it's from speech.",
                    "label": 0
                },
                {
                    "sent": "It's not from text, meaning that also typical spoken words in it off words, because somebody wants changed his mind, etc.",
                    "label": 0
                },
                {
                    "sent": "And a lot of different categories.",
                    "label": 0
                },
                {
                    "sent": "You see, 15.",
                    "label": 0
                },
                {
                    "sent": "You see some of them here face to face conversations with two point 6 million words.",
                    "label": 1
                },
                {
                    "sent": "Also a very small one.",
                    "label": 0
                },
                {
                    "sent": "Masters in ceremonies, with 18,000 words, etc.",
                    "label": 1
                },
                {
                    "sent": "Dutch, Why is that?",
                    "label": 0
                },
                {
                    "sent": "Interview with teachers in Dutch?",
                    "label": 0
                },
                {
                    "sent": "Because they're also Flemish.",
                    "label": 0
                },
                {
                    "sent": "Let me say spoken.",
                    "label": 0
                },
                {
                    "sent": "Text in it.",
                    "label": 0
                },
                {
                    "sent": "And of course people know Flemish.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit different from Dutch, but it resembles Dutch.",
                    "label": 0
                },
                {
                    "sent": "So you can see of course part commands to use quite different words than if you look at Masters ceremonies.",
                    "label": 1
                },
                {
                    "sent": "That's why this whole corpus is annotated with part of speech tags and other linguistic features.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, what kind of?",
                    "label": 0
                },
                {
                    "sent": "One of the annotations is part of speech stacks.",
                    "label": 1
                },
                {
                    "sent": "And if you look at Dutch, if you look at the corpus spoken Dutch 316, part of speed stacks, there's a very fine.",
                    "label": 0
                },
                {
                    "sent": "Tuned and only some of these texts on your curfew times so.",
                    "label": 1
                },
                {
                    "sent": "In our research and other research would be reduced the speed stacks, the power speed sticks now full of main classes, but they call the reduce part of speech tags that are non verbal let like which is instance of punctuation mark or?",
                    "label": 0
                },
                {
                    "sent": "And of course these are the special marks from something which occur only in speech.",
                    "label": 0
                },
                {
                    "sent": "But this is far too small if you use this kind of part of speech text, you cannot use it for further analysis of your text.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What we considered is the exit consisting of 72 tags.",
                    "label": 1
                },
                {
                    "sent": "Meaning every word in this corpus is must be assigned to one of these 72 texts.",
                    "label": 0
                },
                {
                    "sent": "And you want to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would automatically.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can see the text said this is came up by Richard the Knocker and other researchers in natural language processing in Dutch.",
                    "label": 0
                },
                {
                    "sent": "So these are not my ideas.",
                    "label": 0
                },
                {
                    "sent": "So we have now and now you can have of course.",
                    "label": 0
                },
                {
                    "sent": "As a plural single, and whatever verbs tense you can, gender, etc to differ between different forms of verbs, etc.",
                    "label": 0
                },
                {
                    "sent": "You see the main 27 of the 72 speed stick used.",
                    "label": 0
                },
                {
                    "sent": "To give you an idea of what what we used in this research.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And why is this a problem?",
                    "label": 0
                },
                {
                    "sent": "If you look at the frequency of words in this?",
                    "label": 0
                },
                {
                    "sent": "In this corpus then you see words which occur 100 times.",
                    "label": 0
                },
                {
                    "sent": "Then 50% of the words which occur 100 times.",
                    "label": 0
                },
                {
                    "sent": "50% of 40% is ambitious meaning of different text depending on the context.",
                    "label": 0
                },
                {
                    "sent": "So the context determines the tag of a word, and if you look at highly frequent words.",
                    "label": 0
                },
                {
                    "sent": "Almost all of them are ambitious, meaning.",
                    "label": 0
                },
                {
                    "sent": "They have different.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sex.",
                    "label": 0
                },
                {
                    "sent": "So what was the challenge?",
                    "label": 0
                },
                {
                    "sent": "Could come up with a support vector machine based part of speech tagger.",
                    "label": 1
                },
                {
                    "sent": "Huawei support vector Machine based becausw from other researchers.",
                    "label": 0
                },
                {
                    "sent": "Other research it is known that support vector machine can do a good job.",
                    "label": 0
                },
                {
                    "sent": "Part of speech tagging.",
                    "label": 1
                },
                {
                    "sent": "So that's one of the reasons.",
                    "label": 1
                },
                {
                    "sent": "But if you look at the literature, most of them are on written text and all the other small corpus and not on the corpus of 9 million words.",
                    "label": 1
                },
                {
                    "sent": "So the main challenge where this all can be used support vector machines for such a large corpus.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, of course, the design first before I tell you how we did it, we just want to focus a little bit on the design and the input coding.",
                    "label": 0
                },
                {
                    "sent": "As usual, you sliding window be cause the tag of the word determined is determined by the context and we want to determine attack of W form the middle word.",
                    "label": 1
                },
                {
                    "sent": "And of course then you take into account the context and the context, 3 words before the word you want to take in three words.",
                    "label": 0
                },
                {
                    "sent": "After the words you want to take.",
                    "label": 1
                },
                {
                    "sent": "So this is the window using all the tax W 4.",
                    "label": 0
                },
                {
                    "sent": "So then you have to come up with an input code, because if you want to use support vector machines you should make it all numerical.",
                    "label": 0
                },
                {
                    "sent": "So here you W1W 2W3 we use the power speed stack is 1 one out of encoding meaning one bit of 72 bits is 1 the other zero.",
                    "label": 0
                },
                {
                    "sent": "You can see the relative text.",
                    "label": 0
                },
                {
                    "sent": "We can see each of these words which.",
                    "label": 0
                },
                {
                    "sent": "In the future, you use the relative tech frequencies based on your training set.",
                    "label": 1
                },
                {
                    "sent": "Now you can use it for the capitalization because most of that Mr. Capital word it says something if it's not at the start of the sentence.",
                    "label": 0
                },
                {
                    "sent": "Probably it's now set to run.",
                    "label": 0
                },
                {
                    "sent": "You can use the length is used the number.",
                    "label": 1
                },
                {
                    "sent": "Part of speech tag bigrams, 3 grams etc.",
                    "label": 1
                },
                {
                    "sent": "This is all coming from the people working in natural language processing that these are relevant.",
                    "label": 0
                },
                {
                    "sent": "Properties of these words.",
                    "label": 1
                },
                {
                    "sent": "In order to determine the part of speech stack.",
                    "label": 0
                },
                {
                    "sent": "But that means that you more or less can highly dimensional input coding, especially because you use this one out of encoding.",
                    "label": 0
                },
                {
                    "sent": "That will blow up the dimensions of your input space, but one of their fans is of course that many.",
                    "label": 0
                },
                {
                    "sent": "Let me so many components as Europe because this one out of him.",
                    "label": 0
                },
                {
                    "sent": "So this the input coding used in its standard input coding used.",
                    "label": 0
                },
                {
                    "sent": "In this kind of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Natural language processing.",
                    "label": 0
                },
                {
                    "sent": "So, but we have a huge amount of data.",
                    "label": 1
                },
                {
                    "sent": "So you cannot say well, just pick up a pick, a support vector machine.",
                    "label": 0
                },
                {
                    "sent": "And just use the training data.",
                    "label": 0
                },
                {
                    "sent": "Let me say one 910 to let me say 8 million sentences of 8 million words and put it in memory and try to come up with support vector machine with tech.",
                    "label": 0
                },
                {
                    "sent": "These words it will not work.",
                    "label": 0
                },
                {
                    "sent": "We have too much data, So what we did we tried to come up with a committee of support vector machine based.",
                    "label": 0
                },
                {
                    "sent": "Or knowledge you have.",
                    "label": 0
                },
                {
                    "sent": "So one of the things that W for the work we need to protect the common word mean it's the frequency is more than 50 in the training set.",
                    "label": 1
                },
                {
                    "sent": "Then we for each such word.",
                    "label": 0
                },
                {
                    "sent": "We train a different support vector machine.",
                    "label": 0
                },
                {
                    "sent": "So meaning this would result in 795 support vector machines.",
                    "label": 1
                },
                {
                    "sent": "So for this, for each word you have a common word, you have to support vector machine, meaning that.",
                    "label": 0
                },
                {
                    "sent": "For W4 to let me set input coding for W4 is constant for the support vector machine, so it can be left out.",
                    "label": 0
                },
                {
                    "sent": "Is W follows an uncommon word, meaning it only occurs relative infrequently or just a few times?",
                    "label": 0
                },
                {
                    "sent": "Then you based.",
                    "label": 0
                },
                {
                    "sent": "Then you construct a support vector machine for each reduced tag.",
                    "label": 0
                },
                {
                    "sent": "Of W 3 revert proceeding W 4.",
                    "label": 0
                },
                {
                    "sent": "You have 12 reduced X, so meaning that you have to look different support vector machines.",
                    "label": 0
                },
                {
                    "sent": "An of course, but the main problem always is you have an unknown word.",
                    "label": 0
                },
                {
                    "sent": "What is an unknown word.",
                    "label": 0
                },
                {
                    "sent": "An unknown word is a word which doesn't occur in your training set, meaning you don't know anything about it because you didn't see it before.",
                    "label": 0
                },
                {
                    "sent": "So you cannot say anything about the relative frequencies of the power, speed, stacks, etc.",
                    "label": 0
                },
                {
                    "sent": "So also let me train to a different one.",
                    "label": 0
                },
                {
                    "sent": "But we used again the reduced stack of W 3 W 3 and.",
                    "label": 1
                },
                {
                    "sent": "The frequency of W4 is set to 0.",
                    "label": 0
                },
                {
                    "sent": "And hence you can discard this one from the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Put coding.",
                    "label": 0
                },
                {
                    "sent": "So initial Committee of Support vector machine work as follows.",
                    "label": 1
                },
                {
                    "sent": "If WP4 is a common word then you select this specific machine related with this word.",
                    "label": 0
                },
                {
                    "sent": "If it's an uncommon word, you select the support vector machine determined by the reduced tech of W 3.",
                    "label": 0
                },
                {
                    "sent": "And if it's unknown word, you select the unknown support vector machine learning word support vector machine based again on the reduced deck of W 3.",
                    "label": 0
                },
                {
                    "sent": "So meaning you split up.",
                    "label": 0
                },
                {
                    "sent": "Immediately when you see your data point most of time on your committee, you fit all the data points to all your classifiers and determine an outcome at the end by combining them based on what we know and knowledge we have about part of speech, tagging, etc.",
                    "label": 0
                },
                {
                    "sent": "We can do the decomposition immediately before.",
                    "label": 0
                },
                {
                    "sent": "Given it to all the spectrum.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, how did we evaluate this approach?",
                    "label": 0
                },
                {
                    "sent": "From the corpus we constructed eleven sets.",
                    "label": 1
                },
                {
                    "sent": "And to get a more less stratified you conversation, the first sentence of the corpus goes instead zero the second one and set one, etc.",
                    "label": 1
                },
                {
                    "sent": "So you get eleven sets, set one up to set and including set.",
                    "label": 0
                },
                {
                    "sent": "Then I use for training and validation, meaning that we use set one up to set nine for training and set 10 for validation and set zero.",
                    "label": 1
                },
                {
                    "sent": "The box used for the ultimate Performance ultimate test we did on the performance of our approach.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you want to use support vector machines, you need to decide what kernel to use.",
                    "label": 0
                },
                {
                    "sent": "If you see what you see is given overall performance.",
                    "label": 0
                },
                {
                    "sent": "I should remark that overall performance also include the normal basis words, so that's the reason why the overall performance is higher than all the performances here.",
                    "label": 0
                },
                {
                    "sent": "You don't see any.",
                    "label": 0
                },
                {
                    "sent": "You don't see much difference.",
                    "label": 0
                },
                {
                    "sent": "It's not significant difference between the different kernels you can use.",
                    "label": 0
                },
                {
                    "sent": "But you see a little bit here.",
                    "label": 0
                },
                {
                    "sent": "You see that this one is for the uncommon one.",
                    "label": 0
                },
                {
                    "sent": "This one is better, but unknown what this one is.",
                    "label": 0
                },
                {
                    "sent": "Not the best one, but the second one.",
                    "label": 0
                },
                {
                    "sent": "And that led us to decide to use a third order polynomial.",
                    "label": 0
                },
                {
                    "sent": "You can argue that also from also linear one would do.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "We have to decide which one to take.",
                    "label": 0
                },
                {
                    "sent": "Decided based on performance on uncommon words an unknown words to use the 3rd order polynomial kernel.",
                    "label": 1
                },
                {
                    "sent": "But what you see is that the performance on the unknown versus relatively low.",
                    "label": 0
                },
                {
                    "sent": "So what can we do to increase this performance?",
                    "label": 1
                },
                {
                    "sent": "And what way to do is, is that you compound analysis.",
                    "label": 0
                },
                {
                    "sent": "It's very famous in Dutch and us with this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interpret that we can just glue words together.",
                    "label": 0
                },
                {
                    "sent": "Many Dutch water compounds search, for instance, coonfare databases, shoestring.",
                    "label": 1
                },
                {
                    "sent": "Fist bump the tire of a bicycle, and even you have a fix ventile Doppler but yours may explain what it means.",
                    "label": 1
                },
                {
                    "sent": "So very, you can even extend this one too much longer one, but we.",
                    "label": 0
                },
                {
                    "sent": "Can glue words together still after me, which still has a meeting.",
                    "label": 0
                },
                {
                    "sent": "So what you can do if you have an unknown word, try to decompose it in words you know words bits are in the training set.",
                    "label": 0
                },
                {
                    "sent": "That's what compound analysis is, and most of the time the last compound determines the part of speech tag.",
                    "label": 1
                },
                {
                    "sent": "So what we did is we use the kind of decomposition after word of unknown words determined.",
                    "label": 0
                },
                {
                    "sent": "The last compound that should be in the in the training set and based on this last compound you can come up with a relative frequency of the part of speech tax and use that one.",
                    "label": 0
                },
                {
                    "sent": "As in.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Vacation.",
                    "label": 0
                },
                {
                    "sent": "Now you can do it two ways.",
                    "label": 0
                },
                {
                    "sent": "You can do a strict one.",
                    "label": 0
                },
                {
                    "sent": "Meaning you divide it in two and both components must be in the training set.",
                    "label": 1
                },
                {
                    "sent": "Or you just say, well, I do relax one only the second part, which is the most important part, should be in the lexical knowledge and training set.",
                    "label": 0
                },
                {
                    "sent": "You see, if you do.",
                    "label": 0
                },
                {
                    "sent": "The only district one you have coverage of 38% on unknown words.",
                    "label": 0
                },
                {
                    "sent": "If you relax it recover it becomes higher but overall performance.",
                    "label": 0
                },
                {
                    "sent": "On compounds decreases.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let us do a final, let's say committee of Support Vector machine for that's part of speech tagging.",
                    "label": 1
                },
                {
                    "sent": "And this is exactly the same as the previous one.",
                    "label": 0
                },
                {
                    "sent": "But if it's unknown what and you can compound this word, then you select the uncommon just the same one As for the uncommon word, but.",
                    "label": 0
                },
                {
                    "sent": "And then you started the classification for your part of speed stick.",
                    "label": 1
                },
                {
                    "sent": "And now, and if you cannot compound this word, then you use the support vector machine related to unknown.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let that increases the performance on unknown words drastically.",
                    "label": 0
                },
                {
                    "sent": "It goes up from 53% to 70%.",
                    "label": 0
                },
                {
                    "sent": "And the overall performance of this part of speech tagger is 97 and half percent.",
                    "label": 1
                },
                {
                    "sent": "There's also a memory based part of speech tagger for Dutch, but it was not tested on a complete corpus, only part of the corpus.",
                    "label": 0
                },
                {
                    "sent": "This is 95 or 96%.",
                    "label": 1
                },
                {
                    "sent": "We also looked at the neural network based approach.",
                    "label": 0
                },
                {
                    "sent": "Which has higher performance on known words but much less performance on unknown words.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you look in more detail to the.",
                    "label": 0
                },
                {
                    "sent": "Let me say to the best scoring to the evaluation.",
                    "label": 0
                },
                {
                    "sent": "After the testing you see that one of the best scoring categories is is phone dialogues.",
                    "label": 1
                },
                {
                    "sent": "'cause there's no, there's almost no month verbal communication involved, so we see all this based on words and then you see that is 98%.",
                    "label": 1
                },
                {
                    "sent": "And of course, the worst scoring category, which one you could predict, let me almost predict at.",
                    "label": 0
                },
                {
                    "sent": "Before you started at Martin ceremonies Becausw, they used kind of strange words, not typical Dutch words.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Conclusion We designed support fax machine Buster based battle part of speech stack.",
                    "label": 1
                },
                {
                    "sent": "If it could handle this large coopera.",
                    "label": 1
                },
                {
                    "sent": "It is a performance of 97 1/2% which is one of the highest.",
                    "label": 0
                },
                {
                    "sent": "Low.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Own, at least to us.",
                    "label": 0
                },
                {
                    "sent": "And compound analysis.",
                    "label": 0
                },
                {
                    "sent": "You can use compound analysis to improve the unknown word performance.",
                    "label": 1
                },
                {
                    "sent": "And it also has a reasonable taking speed.",
                    "label": 1
                },
                {
                    "sent": "1000 words a second, which is reasonable for part of speech tagger.",
                    "label": 1
                },
                {
                    "sent": "In future we want look at other approaches based on the total corpus such as neural network based approach.",
                    "label": 0
                },
                {
                    "sent": "Is it a Markov based approach?",
                    "label": 0
                },
                {
                    "sent": "Brill Tagger, which is a famous tracker taken to evaluate it on the total corpus.",
                    "label": 0
                },
                {
                    "sent": "OK, that concludes my talk.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "I can try again.",
                    "label": 0
                },
                {
                    "sent": "Combine because it's usually just compare classification errors more or less.",
                    "label": 0
                },
                {
                    "sent": "Expectorants Sombra so yes, you can make a sandwich.",
                    "label": 0
                },
                {
                    "sent": "You can maybe 1 one of them is better on unknown words.",
                    "label": 0
                },
                {
                    "sent": "You can use that one for now.",
                    "label": 0
                },
                {
                    "sent": "If you have an unknown word you can maybe use support vector machine.",
                    "label": 0
                },
                {
                    "sent": "You can look at different categories in the Coop as well.",
                    "label": 0
                },
                {
                    "sent": "This one is better and amassing ceremony so much knowledge based ways to use some kind of ensemble.",
                    "label": 0
                },
                {
                    "sent": "Then just combining them.",
                    "label": 0
                },
                {
                    "sent": "Let me say both let me say at the decision level.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to use more less knowledge of of the Dutch after pattern of the natural language processing you have.",
                    "label": 0
                },
                {
                    "sent": "Also, you say it's impossible to use support vector machines on the full data set.",
                    "label": 0
                },
                {
                    "sent": "Brochure.",
                    "label": 0
                },
                {
                    "sent": "Very large computer can use the great, that's only in the future.",
                    "label": 0
                },
                {
                    "sent": "Maybe 4 infusion would be possible, but.",
                    "label": 0
                },
                {
                    "sent": "I don't think it will improve a lot because you use knowledge now from what sport is relevant and what do you shoot you look at, etc.",
                    "label": 0
                },
                {
                    "sent": "Don't think if you just.",
                    "label": 0
                },
                {
                    "sent": "Do the total data set use a large computer?",
                    "label": 0
                },
                {
                    "sent": "Use one support vector machine to classify all.",
                    "label": 0
                },
                {
                    "sent": "Don't think it will.",
                    "label": 0
                },
                {
                    "sent": "Improve your performance.",
                    "label": 0
                },
                {
                    "sent": "Fully understand the idea to use multiple classifiers.",
                    "label": 0
                },
                {
                    "sent": "A swarm of classifiers.",
                    "label": 0
                },
                {
                    "sent": "On the background, that human being is specially a telephone, dialogues are speaking in full sentences which have semantic background and which of course have some dependency.",
                    "label": 0
                },
                {
                    "sent": "Multiple French from my point I didn't catch everything or intensive course may destroy these in the connection all day.",
                    "label": 0
                },
                {
                    "sent": "How do you get it back that that you have the idea that the full fitting in.",
                    "label": 0
                },
                {
                    "sent": "Sentence which is in some semantical, any reasonable.",
                    "label": 0
                },
                {
                    "sent": "I I can't find a dollars for myself.",
                    "label": 0
                },
                {
                    "sent": "Didn't completely becausw didn't use the full sentence.",
                    "label": 0
                },
                {
                    "sent": "We say, well, the part of speech that is based on the context, but we just use several words of the context only when you're 7.",
                    "label": 0
                },
                {
                    "sent": "Together they they should be assembled assets that a readable sentence comes up.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure it's a individual, the best classifier his son is picked up, but they absolutely bonkers.",
                    "label": 0
                },
                {
                    "sent": "I don't think I agree with that because.",
                    "label": 0
                },
                {
                    "sent": "Why should it be rubbish becausw?",
                    "label": 0
                },
                {
                    "sent": "You take it when the count more or less the context which is more or less can say that's the semantic meaning of that word.",
                    "label": 0
                },
                {
                    "sent": "Well, I give an example.",
                    "label": 0
                },
                {
                    "sent": "I never say I enter the park and sit down on the bank.",
                    "label": 0
                },
                {
                    "sent": "It can't be.",
                    "label": 0
                },
                {
                    "sent": "Don't sit down in the financial institution.",
                    "label": 0
                },
                {
                    "sent": "No, but this way if you use it, let me say it's one of the words and before bank then you know.",
                    "label": 0
                },
                {
                    "sent": "But that's just an input coding.",
                    "label": 0
                },
                {
                    "sent": "If you want to classify bank then you know one of the words before was.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "It's it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, less you have to encode, and it's a sliding window which you use certain words in the middle word you want to take.",
                    "label": 1
                },
                {
                    "sent": "So meaning that some these words determine can determine the of course the part of speech take of this one.",
                    "label": 0
                },
                {
                    "sent": "And then of course, then you use part of speech tags even you know which word it is, because you code the word for W1W2 W 3.",
                    "label": 1
                },
                {
                    "sent": "But of course long-term dependencies.",
                    "label": 0
                },
                {
                    "sent": "You cannot catch.",
                    "label": 0
                },
                {
                    "sent": "The assumption is that you that is determined by.",
                    "label": 0
                },
                {
                    "sent": "66 words surrounding W 4.",
                    "label": 0
                },
                {
                    "sent": "The part of speech tag.",
                    "label": 0
                },
                {
                    "sent": "That's the semantic session.",
                    "label": 0
                },
                {
                    "sent": "The same measure uses some.",
                    "label": 1
                },
                {
                    "sent": "If you look at the same technique, they say, well if you want to cluster documents on content then the content of the meaning of the word is determined by the words in front and after and we do the same.",
                    "label": 0
                },
                {
                    "sent": "The part of speech stack of WFR determined by the words before W 4, three words before in three after.",
                    "label": 0
                },
                {
                    "sent": "Instinct speaker again.",
                    "label": 0
                }
            ]
        }
    }
}