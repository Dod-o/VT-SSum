{
    "id": "dzxpof5d5tpicpc6oqciad2o6xnudgwk",
    "title": "Predicting Long-Term Impact of CQA Posts: A Comprehensive Viewpoint",
    "info": {
        "author": [
            "Yuan Yao, State Key Laboratory for Novel Software Technology, Nanjing University"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_yao_cqa_posts/",
    "segmentation": [
        [
            "Hi everyone, my name is Yuan Yao an I'm from Nanjing University China.",
            "Now I'm going to present our work predicting the long term impact of secret posts and a comprehensive viewpoint and this is joint work with Hong Kong phone engine."
        ],
        [
            "And there are five parts in this talk."
        ],
        [
            "Start from background motivations."
        ],
        [
            "CQA, which stands for Community question answering, has become very popular in recent years and there now exist manage secret sites ranging from those general ones like Yahoo, Yahoo Answers and Baidu nodes to domain specific ones like Stackoverflow and mathematics."
        ],
        [
            "And our General general task of this work is to predict the long term impact of a question or answer post in secret sites.",
            "So what is long term impact?",
            "Let's see two examples from Stackoverflow here.",
            "The number in the red box is the voting score of this post, which indicates the net number of users who find the post beneficial to them.",
            "So in this work we define the voting score as the long term impact."
        ],
        [
            "And at first glance, this seems a standard supervised learning problem, but existing of the shared data mining algorithms are suboptimal here.",
            "Do the following two challenges.",
            "The first isn't very aspect challenge and Secondly efficiency challenge.",
            "Let's take a further look at the multi aspect."
        ],
        [
            "The first aspect is the covenant between question answers, which means that the impact of a question may be correlated with that of its answers, and this has been verified by the previous works and to make use of the correlation voting consistent term is imposed to connect the question prediction answer prediction.",
            "Here, voting consistency means that we can directly minimize the predicted score of a question, and that office answers."
        ],
        [
            "And then we have the method to capture coupling and the first 2 terms are for question prediction announcer prediction.",
            "The third term is for the voting consistency."
        ],
        [
            "OK, and the next aspect is nonlinearity, which means that the input output relationship may be beyond the simple linear relationship, and here a powerful choices the kernel trick which is also used by SVN.",
            "So we skip that.",
            "Skip the details."
        ],
        [
            "And.",
            "The third aspect is dynamics.",
            "Here dynamics means that question answers dynamically arrive in many secret sites, so we need the algorithm to be adaptive to new examples.",
            "For instance, given the existing examples and new and the current model, when new example, new examples arrive, we should be able to update the new model based on the current model and new examples only.",
            "And here are common practices for our regression setting, as the recursive least squares method."
        ],
        [
            "OK, then this slide we give the main questions we aim to answer in this paper.",
            "All the three aspects are potentially useful for the project for our prediction task, and although there are several methods to model these aspects, how to comprehensively capture them into one algorithm, immense problem?",
            "And seconds.",
            "Each of the aspects will add extra complexity in our model, so for example, to capture nonlinearity, we typically require quadratic time, so the second challenge is how can we make the long term impact prediction algorithm efficient and scalable?"
        ],
        [
            "And I will answer the true question in the following two parts.",
            "Let's first go to modeling multi aspect."
        ],
        [
            "And we followed the prior periods work to model cabinets.",
            "So here we first show how we model nonlinearity.",
            "The basic idea is to Colonel eyes, Lip M method and for details we propose LBK, an method which is a kernelized version of the band and we have the closed form solution for this method.",
            "And as we can see there is a matrix inversion term and the solution which makes the time complexity of LBK em CU with respect to the number of pricing analysis."
        ],
        [
            "The next, let's see how we model dynamics here.",
            "The basic idea is to recursively update the lipcan method and for details.",
            "Key step is to apply the matrix inverse lemma so that we can update the new model based on the current model and new examples.",
            "And Additionally, it turns out that Lipkin can reduce the time complexity from cubic quadratic."
        ],
        [
            "OK, steal a quadratic time algorithm is too expensive for secret size, so we next show how we speed up the computations."
        ],
        [
            "The quadratic time actually comes from the kernel matrix, which is of size N by N, where N is the number of question answers.",
            "So the basic idea here is to compress the kernel matrix.",
            "And for details, we proposed lipki method and there are several steps here.",
            "The first step is to decompose this kernel question econometrics, an answer kernel matrix separately, and then we need to further make the decomposition reusable, future updates.",
            "And finally we can apply the reusable decomposition on Lipkin.",
            "Here, since we only need to maintain 2M by our matrices instead of the empire in kernel matrix, where R is usually much smaller than N, so we can reduce the time complexity from quadratic to linear."
        ],
        [
            "In some cases, even an linear algorithm is still expensive, so we further try to reduce the time complexity and by filtering some less informative examples.",
            "And she will propose Lipuma square method and for example, given the existing examples in the current model, we treat the new examples as the test set, and then we only keep those new examples whose prediction error is beyond a certain threshold.",
            "And since lipuma square scales linearly with respect to the number of remaining question analysis, so it scales sublinearly with the number of total number of question analysis."
        ],
        [
            "And he will summarize the solution space for our long-term impact prediction problem and hear each solid error makes the model more comprehensive by adding one more aspect and each dashed arrow makes more and more scalable interior.",
            "Shaded box.",
            "Are the methods proposed in this work and white boxes existing work?",
            "And in this talk we cover the four boxes with a green mark.",
            "And as we can see in the bottom, based on the bottom Ridge regression method, we can have that kernel Ridge regression by capturing nonlinearity.",
            "And we can have recursive Ridge regression by capturing dynamics and moving upwards.",
            "We have the lipki method to capture all the three aspects and we further propose approximation methods to scale up the computations."
        ],
        [
            "OK, let's go to the experiments."
        ],
        [
            "She can now experience with study two data sets, the Stackoverflow and mathematics Stackexchange.",
            "They're popular, secret size for programming and maths, and both of us as a publicly available.",
            "And for features we choose some common content features, an context or features.",
            "And then we divide the questions and their answers into several segmentations based on the chronological order.",
            "And we use the last segmentation as a test set and for the remaining training set we start from the initial set and gradually add the incremental set."
        ],
        [
            "And here are the evaluation objectives.",
            "First, how accurate are the proposed algorithms for our long-term impact prediction problem, and how scalable are the proposed algorithms?"
        ],
        [
            "Let's first see the effect in the results.",
            "And here we compare our methods with two existing methods, the kernel, Ridge regression, an SVR and we report the root mean squared error.",
            "And as we can see, our methods are better than the two compared methods, especially for lip Kemaman and Lipkin.",
            "Follicular square, although it is not as good as lip Kim, it is still better than the two competitors in most of the cases."
        ],
        [
            "Next, let's see the efficiency results.",
            "Here we compare the wall Clock time of different algorithms and the Y axis is in log scale.",
            "And as we can see, live kyma Animal Square are much faster than the other methods.",
            "And we also show the result of Leukemia Square in the top right corner with the Y axis in linear scale.",
            "So there we can observe a sub near scalability."
        ],
        [
            "And we also do a quality speed balance of study of the different algorithms.",
            "And here in Ideal algorithm will sit in the bottom left corner in the figures and as we can see our exams sit in this corner.",
            "So in practice we recommend the Pima Animal Clinic Square."
        ],
        [
            "OK, conclusion."
        ],
        [
            "In this work, we have proposed a family of algorithms to predict the long term impact of CPU posts, and we capture three important aspects by voting consistency, the kernel trick, and recursive updating, and we also propose approximation methods to scale up the computations.",
            "An empirical evaluations on two security data sets show that one of our algorithms can achieve up to 35% I MSE improvement and up to more than 300 times speedup.",
            "And also this algorithm scales enjoys this sub linear scalability."
        ],
        [
            "That's it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, my name is Yuan Yao an I'm from Nanjing University China.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to present our work predicting the long term impact of secret posts and a comprehensive viewpoint and this is joint work with Hong Kong phone engine.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there are five parts in this talk.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start from background motivations.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "CQA, which stands for Community question answering, has become very popular in recent years and there now exist manage secret sites ranging from those general ones like Yahoo, Yahoo Answers and Baidu nodes to domain specific ones like Stackoverflow and mathematics.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our General general task of this work is to predict the long term impact of a question or answer post in secret sites.",
                    "label": 1
                },
                {
                    "sent": "So what is long term impact?",
                    "label": 0
                },
                {
                    "sent": "Let's see two examples from Stackoverflow here.",
                    "label": 0
                },
                {
                    "sent": "The number in the red box is the voting score of this post, which indicates the net number of users who find the post beneficial to them.",
                    "label": 0
                },
                {
                    "sent": "So in this work we define the voting score as the long term impact.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And at first glance, this seems a standard supervised learning problem, but existing of the shared data mining algorithms are suboptimal here.",
                    "label": 1
                },
                {
                    "sent": "Do the following two challenges.",
                    "label": 0
                },
                {
                    "sent": "The first isn't very aspect challenge and Secondly efficiency challenge.",
                    "label": 0
                },
                {
                    "sent": "Let's take a further look at the multi aspect.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first aspect is the covenant between question answers, which means that the impact of a question may be correlated with that of its answers, and this has been verified by the previous works and to make use of the correlation voting consistent term is imposed to connect the question prediction answer prediction.",
                    "label": 0
                },
                {
                    "sent": "Here, voting consistency means that we can directly minimize the predicted score of a question, and that office answers.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we have the method to capture coupling and the first 2 terms are for question prediction announcer prediction.",
                    "label": 0
                },
                {
                    "sent": "The third term is for the voting consistency.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and the next aspect is nonlinearity, which means that the input output relationship may be beyond the simple linear relationship, and here a powerful choices the kernel trick which is also used by SVN.",
                    "label": 1
                },
                {
                    "sent": "So we skip that.",
                    "label": 0
                },
                {
                    "sent": "Skip the details.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The third aspect is dynamics.",
                    "label": 0
                },
                {
                    "sent": "Here dynamics means that question answers dynamically arrive in many secret sites, so we need the algorithm to be adaptive to new examples.",
                    "label": 0
                },
                {
                    "sent": "For instance, given the existing examples and new and the current model, when new example, new examples arrive, we should be able to update the new model based on the current model and new examples only.",
                    "label": 1
                },
                {
                    "sent": "And here are common practices for our regression setting, as the recursive least squares method.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, then this slide we give the main questions we aim to answer in this paper.",
                    "label": 0
                },
                {
                    "sent": "All the three aspects are potentially useful for the project for our prediction task, and although there are several methods to model these aspects, how to comprehensively capture them into one algorithm, immense problem?",
                    "label": 1
                },
                {
                    "sent": "And seconds.",
                    "label": 1
                },
                {
                    "sent": "Each of the aspects will add extra complexity in our model, so for example, to capture nonlinearity, we typically require quadratic time, so the second challenge is how can we make the long term impact prediction algorithm efficient and scalable?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I will answer the true question in the following two parts.",
                    "label": 0
                },
                {
                    "sent": "Let's first go to modeling multi aspect.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we followed the prior periods work to model cabinets.",
                    "label": 0
                },
                {
                    "sent": "So here we first show how we model nonlinearity.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is to Colonel eyes, Lip M method and for details we propose LBK, an method which is a kernelized version of the band and we have the closed form solution for this method.",
                    "label": 0
                },
                {
                    "sent": "And as we can see there is a matrix inversion term and the solution which makes the time complexity of LBK em CU with respect to the number of pricing analysis.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next, let's see how we model dynamics here.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is to recursively update the lipcan method and for details.",
                    "label": 1
                },
                {
                    "sent": "Key step is to apply the matrix inverse lemma so that we can update the new model based on the current model and new examples.",
                    "label": 0
                },
                {
                    "sent": "And Additionally, it turns out that Lipkin can reduce the time complexity from cubic quadratic.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, steal a quadratic time algorithm is too expensive for secret size, so we next show how we speed up the computations.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The quadratic time actually comes from the kernel matrix, which is of size N by N, where N is the number of question answers.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea here is to compress the kernel matrix.",
                    "label": 1
                },
                {
                    "sent": "And for details, we proposed lipki method and there are several steps here.",
                    "label": 0
                },
                {
                    "sent": "The first step is to decompose this kernel question econometrics, an answer kernel matrix separately, and then we need to further make the decomposition reusable, future updates.",
                    "label": 1
                },
                {
                    "sent": "And finally we can apply the reusable decomposition on Lipkin.",
                    "label": 0
                },
                {
                    "sent": "Here, since we only need to maintain 2M by our matrices instead of the empire in kernel matrix, where R is usually much smaller than N, so we can reduce the time complexity from quadratic to linear.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In some cases, even an linear algorithm is still expensive, so we further try to reduce the time complexity and by filtering some less informative examples.",
                    "label": 1
                },
                {
                    "sent": "And she will propose Lipuma square method and for example, given the existing examples in the current model, we treat the new examples as the test set, and then we only keep those new examples whose prediction error is beyond a certain threshold.",
                    "label": 1
                },
                {
                    "sent": "And since lipuma square scales linearly with respect to the number of remaining question analysis, so it scales sublinearly with the number of total number of question analysis.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And he will summarize the solution space for our long-term impact prediction problem and hear each solid error makes the model more comprehensive by adding one more aspect and each dashed arrow makes more and more scalable interior.",
                    "label": 0
                },
                {
                    "sent": "Shaded box.",
                    "label": 0
                },
                {
                    "sent": "Are the methods proposed in this work and white boxes existing work?",
                    "label": 0
                },
                {
                    "sent": "And in this talk we cover the four boxes with a green mark.",
                    "label": 0
                },
                {
                    "sent": "And as we can see in the bottom, based on the bottom Ridge regression method, we can have that kernel Ridge regression by capturing nonlinearity.",
                    "label": 1
                },
                {
                    "sent": "And we can have recursive Ridge regression by capturing dynamics and moving upwards.",
                    "label": 0
                },
                {
                    "sent": "We have the lipki method to capture all the three aspects and we further propose approximation methods to scale up the computations.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let's go to the experiments.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "She can now experience with study two data sets, the Stackoverflow and mathematics Stackexchange.",
                    "label": 0
                },
                {
                    "sent": "They're popular, secret size for programming and maths, and both of us as a publicly available.",
                    "label": 0
                },
                {
                    "sent": "And for features we choose some common content features, an context or features.",
                    "label": 0
                },
                {
                    "sent": "And then we divide the questions and their answers into several segmentations based on the chronological order.",
                    "label": 0
                },
                {
                    "sent": "And we use the last segmentation as a test set and for the remaining training set we start from the initial set and gradually add the incremental set.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are the evaluation objectives.",
                    "label": 0
                },
                {
                    "sent": "First, how accurate are the proposed algorithms for our long-term impact prediction problem, and how scalable are the proposed algorithms?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's first see the effect in the results.",
                    "label": 0
                },
                {
                    "sent": "And here we compare our methods with two existing methods, the kernel, Ridge regression, an SVR and we report the root mean squared error.",
                    "label": 0
                },
                {
                    "sent": "And as we can see, our methods are better than the two compared methods, especially for lip Kemaman and Lipkin.",
                    "label": 1
                },
                {
                    "sent": "Follicular square, although it is not as good as lip Kim, it is still better than the two competitors in most of the cases.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next, let's see the efficiency results.",
                    "label": 1
                },
                {
                    "sent": "Here we compare the wall Clock time of different algorithms and the Y axis is in log scale.",
                    "label": 0
                },
                {
                    "sent": "And as we can see, live kyma Animal Square are much faster than the other methods.",
                    "label": 0
                },
                {
                    "sent": "And we also show the result of Leukemia Square in the top right corner with the Y axis in linear scale.",
                    "label": 0
                },
                {
                    "sent": "So there we can observe a sub near scalability.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also do a quality speed balance of study of the different algorithms.",
                    "label": 0
                },
                {
                    "sent": "And here in Ideal algorithm will sit in the bottom left corner in the figures and as we can see our exams sit in this corner.",
                    "label": 0
                },
                {
                    "sent": "So in practice we recommend the Pima Animal Clinic Square.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this work, we have proposed a family of algorithms to predict the long term impact of CPU posts, and we capture three important aspects by voting consistency, the kernel trick, and recursive updating, and we also propose approximation methods to scale up the computations.",
                    "label": 1
                },
                {
                    "sent": "An empirical evaluations on two security data sets show that one of our algorithms can achieve up to 35% I MSE improvement and up to more than 300 times speedup.",
                    "label": 0
                },
                {
                    "sent": "And also this algorithm scales enjoys this sub linear scalability.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}