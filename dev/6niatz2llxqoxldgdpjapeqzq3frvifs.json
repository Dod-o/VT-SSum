{
    "id": "6niatz2llxqoxldgdpjapeqzq3frvifs",
    "title": "Multi-view Pictorial Structures for 3D Human Pose Estimation",
    "info": {
        "author": [
            "Sikandar Amin, Faculty of Informatics, TU Munich"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_amin_pictorial_structures/",
    "segmentation": [
        [
            "My name is sick and I'm from University of Technology.",
            "Germany is the joint work with any follow every local markets robot and when she left from Mechling Institute for Informatics.",
            "The topic is about multiple pictorial structures for 3D human pose estimation.",
            "Typically, state of the art approaches."
        ],
        [
            "Three human cause information rely on detailed 3D body models involve complex experience in a high dimensional space of the body configurations and normally they require initialization and tracking to perform well.",
            "Using activity specific motion buyers.",
            "These methods have generally been evaluated for control settings with uniform backgrounds.",
            "On the other hand, the defector standard for 2D pose estimation is the pictorial structures approach which uses discriminative part detectors with simple generative Cody body models.",
            "We can offer exactly an efficient inference.",
            "And performed well in realistic settings.",
            "As such, 2D approaches suffer from.",
            "Projection ambiguities.",
            "So our goal is to build upon."
        ],
        [
            "The state of the art pictorial structure approach to allow for robust 3D human pose estimation.",
            "And using multiple calibrated cameras.",
            "We want to estimate the throughput without the need of activity.",
            "Specific priors or temporal filtering, and we want to apply our model for non static backgrounds.",
            "And estimate causes for variety of people without adapting the model.",
            "Therefore, in addition to studio settings, we also evaluate in a more realistic scenario.",
            "Yeah."
        ],
        [
            "Three important Commission has been considered in the literature in a variety of settings.",
            "Various various mechanisms such as approaches based on nonparametric believability propagation and by sigala tell a new particle filtering by Vernon Reid addressed the problem of such complexity in 3D.",
            "But such stochastic approaches does not guarantee global optimality, and they have only been evaluated in control settings.",
            "Other approaches which have been shown to work in more realistic conditions rely on improve the following limitations, such as activity specific priors and structure for motion methods or combining visual and on body inertial sensor information.",
            "Very recently, Bernice ET al proposed 3D pictorial structures using multiple calibrated cameras.",
            "This approach is based on simple tree graph.",
            "They evaluate using weak likelihood and does not model explicit multiview constraints."
        ],
        [
            "Before I present our approach, I will briefly go through the basic pictorial structure model and then I will present our improvements for the single case and."
        ],
        [
            "Extension due in court."
        ],
        [
            "Correct multiple views in the pictorial structure framework.",
            "In the end I will show some of the results."
        ],
        [
            "On two different code estimation data sets."
        ],
        [
            "The pictorial structure model.",
            "This particular approach models the human pose as a configuration of different body parts.",
            "Here is an implementation of a standard 2D pictorial structure model by angry Luca ET al.",
            "And the the posterior is given as the product is represented as a product of image likelihood and 2D body prior.",
            "1st."
        ],
        [
            "Given an image, shape features are extracted over a grid of discrete orientations and locations.",
            "Then image."
        ],
        [
            "Likelihood score is calculated for each part separately using discriminatively, discriminatively, discriminatively trained classifiers.",
            "They finally post."
        ],
        [
            "The reason for using these likelihood scores and the Cody body prior they use some product belief propagation algorithm for exact inference of the part marginals."
        ],
        [
            "These spectral structure methods suffer from various challenges like foreshortening of the body parts."
        ],
        [
            "Multimodal apart dependencies.",
            "Murphy"
        ],
        [
            "Part appearance and extreme."
        ],
        [
            "Open variations.",
            "To address these problems, we extend this model with several improvements.",
            "Inspired by the recent work."
        ],
        [
            "And in Lee joint shape."
        ],
        [
            "Color feature representation.",
            "When people praise terms and mixture of two pictorial structure models.",
            "We've."
        ],
        [
            "Emulate our single model as a conditional random field and assume that the post posterior effect arises into a product of unity and power in previous terms.",
            "The unities or the part like."
        ],
        [
            "Returns are modeled using the boosted part detectors and the boosted particles are represented as the weighted sum of weak single feature classifiers.",
            "And the corresponding works alphas."
        ],
        [
            "Learn using adaboost.",
            "Anne."
        ],
        [
            "In represents the shape context feature vector for part N. We concatenate this shape context with the color features."
        ],
        [
            "And frame the boosted parkitecture on top of this joint representation.",
            "Note that.",
            "Adding the color information with the shape information allows us to automatically learn the relative importance of both features at the power detection stage."
        ],
        [
            "Now in the previous term, between any two parts LINLJR model using a unimodal Gaussian distribution.",
            "In the transform space of the joints between these two parts.",
            "The red ovals here represent these two dimensional Gaussian distributions.",
            "We introduced the mixture model at the level of these pairwise power dependencies.",
            "To that end, we replace this unimodal Gaussian."
        ],
        [
            "Term with the term that maximizes overcame odds and represent each mode with a separate government.",
            "We call it multimodal.",
            "Farewell storms.",
            "And note that it explicitly models foreshortening of the body parts and multiple articulations of the joint.",
            "Now training."
        ],
        [
            "A single component.",
            "That is a single appearance model and a single 2D body.",
            "Prior becomes non descriptive for the activities with cyclic motions such as walking, jogging etc or high viewpoint variations such as people walking in a circle.",
            "As a solution, Johnsons and everything AM."
        ],
        [
            "Presented Multiview presented a mixture of pictorial structure models.",
            "The idea is to.",
            "Cluster the training data into."
        ],
        [
            "Current components.",
            "And these components typically represent the various movements of the person with respect to the camera.",
            "Then learn."
        ],
        [
            "Separate models for each of the component.",
            "As a result, we are able to detect poses with respect to different viewpoints.",
            "Another question is how can we estimate the component index at the test time?",
            "Now for this."
        ],
        [
            "Treat the index of the component as a latent variable and propose to alternative strategies to infer this index.",
            "For our first approach.",
            "We"
        ],
        [
            "Training a holistic classifier that distinguishes the component index based on the contents of the person bounding box.",
            "For this we rely only approach of paprika tell which jointly solves the task of object detection and viewpoint classification.",
            "Alternatively"
        ],
        [
            "Inspired by the recent work of Jamal America at L, We relate the selection of the component directly to the quality of the pose estimation.",
            "We select the component key."
        ],
        [
            "Minimize the overall uncertainty in the marginal distribution of the body parts.",
            "Here uncertain TS is represented as a sum over norm of the covariance matrices of the part marginals.",
            "In our experiments, this approach works better as compared to training the classifier."
        ],
        [
            "Now I will present our multi factorial structures model.",
            "We proposed 3D mixture."
        ],
        [
            "To extend the idea of mixing components to multiple views.",
            "And then I will destroy."
        ],
        [
            "Power user for multiple private sectors to jointly model the poses across use.",
            "In the end, we rely."
        ],
        [
            "On an approximate two stage inference procedure.",
            "If you're given."
        ],
        [
            "Can get up from multiple views.",
            "First we triangulate the noisy to the annotations to get the 3D ground proposes."
        ],
        [
            "Then we clustered these three depots."
        ],
        [
            "Do you think any?",
            "These 3D poses are then reprojected."
        ],
        [
            "The image space to learn separate appearance and 2D body models for each of the component and in all views.",
            "And then there is work we get."
        ],
        [
            "Consistent annotations in multiple views and that we will need next to train our multi view appearance vectors.",
            "We also get consistent to the body priors and we avoid viewpoint ambiguities that the 2D mixture model suffers from."
        ],
        [
            "For the sake of clarity, I will describe our multiview pictorial structure.",
            "For the case of two views.",
            "The joint posterior over the configuration of both views is represented as."
        ],
        [
            "Product of single vectors and multiple pairwise vector.",
            "These single reflectors individually decomposed into part unities and pairwise terms as described before.",
            "On the other hand, the multiple previous factors.",
            "Encode the appearance in correspondence constraint across news."
        ],
        [
            "And the multiple appearance describe the shape and color of different body parts.",
            "In multiple views.",
            "We concatenate the appearance feature vectors of both views."
        ],
        [
            "And then train the boosted parkitecture using this joint representation.",
            "It makes the likelihood terms in our model even more discriminative.",
            "And the multiple correspondence vectors encode encode the geometric constraint that the part locations in different views should agree on the same 30 point.",
            "Therefore, be represented using the reprojection error.",
            "When more than two years or."
        ],
        [
            "We will we connected corresponding body parts in all paraview.",
            "This leads to a loop."
        ],
        [
            "Remember as well our multimodal pairwise terms and multi view previous vectors are non Gaussian.",
            "Therefore, the exact inference becomes."
        ],
        [
            "Intractable.",
            "To performing films in such a case, we rely on an approximate two stage."
        ],
        [
            "Inference procedure introduced by Andre Luca ET al.",
            "At first the experience is done separately for each new.",
            "Then we sample a sufficiently large."
        ],
        [
            "Set apart locations from the marginal distribution of the body parts.",
            "In the second stage."
        ],
        [
            "The inference is done for the full model in the reduced state space of the part locations.",
            "Here Max product belief propagation algorithm is used which allows us to obtain the consistent estimate for the full body and in all views.",
            "Finally, given the two depots estimates, we construct the three poles using triangulation.",
            "We evaluate our."
        ],
        [
            "Which on two different data sets in the first is the human number, one which is the standard for 3D human pose estimation.",
            "Following previous work, we use three color cameras for experiments over 4 different activities, walking, jogging, boxing, combo and this bar graph here shows the 3D error in millimeters, so the lower the better.",
            "We start with our flexible pictorial structures model from CPR 12.",
            "We see that adding mixture component reduces."
        ],
        [
            "The other by 31 millimeters.",
            "Which this huge performance can be explained by the fact that for the human walking sequence the people are walking in circles.",
            "So our single component cannot represent the viewpoint variations.",
            "Combine shapes."
        ],
        [
            "Presentation improves the performance by 8 millimeters.",
            "Then adding multivu."
        ],
        [
            "Previous vectors.",
            "Give us gives us the game of 20 millimeters, which shows the importance of jointly modeling deposes across views.",
            "Finally, the multimodal pair Western herd."
        ],
        [
            "Did you see the 3D error and overall we get improved by almost more than half of the initial error.",
            "Here are some."
        ],
        [
            "In comparison to the state of yard for component walk sequences.",
            "These state of the art approaches rely on initialization and tracking.",
            "Using complex motion models, while we evaluate only for the single time frame.",
            "In the case of combo sequence, which is a combination of walking and jogging activities.",
            "Our approach here shown in green, outperforms the CR VM approach by of Taylor tell by around 24 millimeters.",
            "Similarly, in the case of box sequence, we improve significantly over state of the art."
        ],
        [
            "Now we have some quality."
        ],
        [
            "Qualitative results for the human ever data set is the box sequence in the lower right corner.",
            "We show the component selection.",
            "They've done minimum various criteria."
        ],
        [
            "Next we have results for the combo sequence, the."
        ],
        [
            "It starts with The Walking activity.",
            "And then switches to jogging later.",
            "We note that our model robustly handled multiple activities."
        ],
        [
            "Next we also evaluate overall more challenging MPI cooking data set.",
            "It contains 65 different fine grained activities and significantly large number of subjects interacting with various objects.",
            "Our training set contains 896 images per view.",
            "Antacid contains 1154 images per view with seven different subjects.",
            "Here we compare our our previous work and the flexible pictorial structure model from Cpl.",
            "The graph represents the percentage of correctly estimated parts in the PCP values.",
            "So in this case the higher is better.",
            "We note that our current approach improves significantly for all parts and especially."
        ],
        [
            "For the arm.",
            "It outperforms the previous work by more than 20%."
        ],
        [
            "Here are some quality results for the MPI cooking data set.",
            "We know that we are able to detect poses for different activities.",
            "Variety of people and all viewpoints.",
            "The subjects are interacting with various objects leading to a non static background.",
            "So."
        ],
        [
            "Summarize we propose a multi projector model for 3D human pose estimation inspired by the recent work, we proposed a number of improvements for the two decoding section model.",
            "Then we describe how we extend this model to multiple views.",
            "We show that our approach, which runs for the single time frame, outperforms the state of the art that require initialization and tracking with complex motion models.",
            "For the future work we."
        ],
        [
            "To evaluate for non static camera setup with multiple interacting subjects."
        ],
        [
            "You can download the complete MPI cooking.",
            "That's it with evaluation, training and test sets on this link."
        ],
        [
            "Thank you very much for attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is sick and I'm from University of Technology.",
                    "label": 0
                },
                {
                    "sent": "Germany is the joint work with any follow every local markets robot and when she left from Mechling Institute for Informatics.",
                    "label": 0
                },
                {
                    "sent": "The topic is about multiple pictorial structures for 3D human pose estimation.",
                    "label": 1
                },
                {
                    "sent": "Typically, state of the art approaches.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Three human cause information rely on detailed 3D body models involve complex experience in a high dimensional space of the body configurations and normally they require initialization and tracking to perform well.",
                    "label": 0
                },
                {
                    "sent": "Using activity specific motion buyers.",
                    "label": 1
                },
                {
                    "sent": "These methods have generally been evaluated for control settings with uniform backgrounds.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, the defector standard for 2D pose estimation is the pictorial structures approach which uses discriminative part detectors with simple generative Cody body models.",
                    "label": 1
                },
                {
                    "sent": "We can offer exactly an efficient inference.",
                    "label": 0
                },
                {
                    "sent": "And performed well in realistic settings.",
                    "label": 0
                },
                {
                    "sent": "As such, 2D approaches suffer from.",
                    "label": 0
                },
                {
                    "sent": "Projection ambiguities.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to build upon.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The state of the art pictorial structure approach to allow for robust 3D human pose estimation.",
                    "label": 1
                },
                {
                    "sent": "And using multiple calibrated cameras.",
                    "label": 0
                },
                {
                    "sent": "We want to estimate the throughput without the need of activity.",
                    "label": 1
                },
                {
                    "sent": "Specific priors or temporal filtering, and we want to apply our model for non static backgrounds.",
                    "label": 0
                },
                {
                    "sent": "And estimate causes for variety of people without adapting the model.",
                    "label": 0
                },
                {
                    "sent": "Therefore, in addition to studio settings, we also evaluate in a more realistic scenario.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Three important Commission has been considered in the literature in a variety of settings.",
                    "label": 0
                },
                {
                    "sent": "Various various mechanisms such as approaches based on nonparametric believability propagation and by sigala tell a new particle filtering by Vernon Reid addressed the problem of such complexity in 3D.",
                    "label": 0
                },
                {
                    "sent": "But such stochastic approaches does not guarantee global optimality, and they have only been evaluated in control settings.",
                    "label": 0
                },
                {
                    "sent": "Other approaches which have been shown to work in more realistic conditions rely on improve the following limitations, such as activity specific priors and structure for motion methods or combining visual and on body inertial sensor information.",
                    "label": 1
                },
                {
                    "sent": "Very recently, Bernice ET al proposed 3D pictorial structures using multiple calibrated cameras.",
                    "label": 0
                },
                {
                    "sent": "This approach is based on simple tree graph.",
                    "label": 0
                },
                {
                    "sent": "They evaluate using weak likelihood and does not model explicit multiview constraints.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before I present our approach, I will briefly go through the basic pictorial structure model and then I will present our improvements for the single case and.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extension due in court.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Correct multiple views in the pictorial structure framework.",
                    "label": 0
                },
                {
                    "sent": "In the end I will show some of the results.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On two different code estimation data sets.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The pictorial structure model.",
                    "label": 0
                },
                {
                    "sent": "This particular approach models the human pose as a configuration of different body parts.",
                    "label": 0
                },
                {
                    "sent": "Here is an implementation of a standard 2D pictorial structure model by angry Luca ET al.",
                    "label": 0
                },
                {
                    "sent": "And the the posterior is given as the product is represented as a product of image likelihood and 2D body prior.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given an image, shape features are extracted over a grid of discrete orientations and locations.",
                    "label": 0
                },
                {
                    "sent": "Then image.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Likelihood score is calculated for each part separately using discriminatively, discriminatively, discriminatively trained classifiers.",
                    "label": 0
                },
                {
                    "sent": "They finally post.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason for using these likelihood scores and the Cody body prior they use some product belief propagation algorithm for exact inference of the part marginals.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These spectral structure methods suffer from various challenges like foreshortening of the body parts.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Multimodal apart dependencies.",
                    "label": 0
                },
                {
                    "sent": "Murphy",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part appearance and extreme.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Open variations.",
                    "label": 0
                },
                {
                    "sent": "To address these problems, we extend this model with several improvements.",
                    "label": 0
                },
                {
                    "sent": "Inspired by the recent work.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in Lee joint shape.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Color feature representation.",
                    "label": 0
                },
                {
                    "sent": "When people praise terms and mixture of two pictorial structure models.",
                    "label": 0
                },
                {
                    "sent": "We've.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Emulate our single model as a conditional random field and assume that the post posterior effect arises into a product of unity and power in previous terms.",
                    "label": 0
                },
                {
                    "sent": "The unities or the part like.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Returns are modeled using the boosted part detectors and the boosted particles are represented as the weighted sum of weak single feature classifiers.",
                    "label": 0
                },
                {
                    "sent": "And the corresponding works alphas.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learn using adaboost.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In represents the shape context feature vector for part N. We concatenate this shape context with the color features.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And frame the boosted parkitecture on top of this joint representation.",
                    "label": 0
                },
                {
                    "sent": "Note that.",
                    "label": 0
                },
                {
                    "sent": "Adding the color information with the shape information allows us to automatically learn the relative importance of both features at the power detection stage.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in the previous term, between any two parts LINLJR model using a unimodal Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "In the transform space of the joints between these two parts.",
                    "label": 0
                },
                {
                    "sent": "The red ovals here represent these two dimensional Gaussian distributions.",
                    "label": 0
                },
                {
                    "sent": "We introduced the mixture model at the level of these pairwise power dependencies.",
                    "label": 0
                },
                {
                    "sent": "To that end, we replace this unimodal Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Term with the term that maximizes overcame odds and represent each mode with a separate government.",
                    "label": 0
                },
                {
                    "sent": "We call it multimodal.",
                    "label": 0
                },
                {
                    "sent": "Farewell storms.",
                    "label": 0
                },
                {
                    "sent": "And note that it explicitly models foreshortening of the body parts and multiple articulations of the joint.",
                    "label": 1
                },
                {
                    "sent": "Now training.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A single component.",
                    "label": 0
                },
                {
                    "sent": "That is a single appearance model and a single 2D body.",
                    "label": 0
                },
                {
                    "sent": "Prior becomes non descriptive for the activities with cyclic motions such as walking, jogging etc or high viewpoint variations such as people walking in a circle.",
                    "label": 0
                },
                {
                    "sent": "As a solution, Johnsons and everything AM.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Presented Multiview presented a mixture of pictorial structure models.",
                    "label": 0
                },
                {
                    "sent": "The idea is to.",
                    "label": 0
                },
                {
                    "sent": "Cluster the training data into.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Current components.",
                    "label": 0
                },
                {
                    "sent": "And these components typically represent the various movements of the person with respect to the camera.",
                    "label": 0
                },
                {
                    "sent": "Then learn.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Separate models for each of the component.",
                    "label": 0
                },
                {
                    "sent": "As a result, we are able to detect poses with respect to different viewpoints.",
                    "label": 0
                },
                {
                    "sent": "Another question is how can we estimate the component index at the test time?",
                    "label": 0
                },
                {
                    "sent": "Now for this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Treat the index of the component as a latent variable and propose to alternative strategies to infer this index.",
                    "label": 0
                },
                {
                    "sent": "For our first approach.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Training a holistic classifier that distinguishes the component index based on the contents of the person bounding box.",
                    "label": 0
                },
                {
                    "sent": "For this we rely only approach of paprika tell which jointly solves the task of object detection and viewpoint classification.",
                    "label": 1
                },
                {
                    "sent": "Alternatively",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inspired by the recent work of Jamal America at L, We relate the selection of the component directly to the quality of the pose estimation.",
                    "label": 0
                },
                {
                    "sent": "We select the component key.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Minimize the overall uncertainty in the marginal distribution of the body parts.",
                    "label": 0
                },
                {
                    "sent": "Here uncertain TS is represented as a sum over norm of the covariance matrices of the part marginals.",
                    "label": 0
                },
                {
                    "sent": "In our experiments, this approach works better as compared to training the classifier.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I will present our multi factorial structures model.",
                    "label": 0
                },
                {
                    "sent": "We proposed 3D mixture.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To extend the idea of mixing components to multiple views.",
                    "label": 0
                },
                {
                    "sent": "And then I will destroy.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Power user for multiple private sectors to jointly model the poses across use.",
                    "label": 0
                },
                {
                    "sent": "In the end, we rely.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On an approximate two stage inference procedure.",
                    "label": 0
                },
                {
                    "sent": "If you're given.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can get up from multiple views.",
                    "label": 0
                },
                {
                    "sent": "First we triangulate the noisy to the annotations to get the 3D ground proposes.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we clustered these three depots.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do you think any?",
                    "label": 0
                },
                {
                    "sent": "These 3D poses are then reprojected.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The image space to learn separate appearance and 2D body models for each of the component and in all views.",
                    "label": 0
                },
                {
                    "sent": "And then there is work we get.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consistent annotations in multiple views and that we will need next to train our multi view appearance vectors.",
                    "label": 0
                },
                {
                    "sent": "We also get consistent to the body priors and we avoid viewpoint ambiguities that the 2D mixture model suffers from.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the sake of clarity, I will describe our multiview pictorial structure.",
                    "label": 0
                },
                {
                    "sent": "For the case of two views.",
                    "label": 0
                },
                {
                    "sent": "The joint posterior over the configuration of both views is represented as.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Product of single vectors and multiple pairwise vector.",
                    "label": 0
                },
                {
                    "sent": "These single reflectors individually decomposed into part unities and pairwise terms as described before.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, the multiple previous factors.",
                    "label": 0
                },
                {
                    "sent": "Encode the appearance in correspondence constraint across news.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the multiple appearance describe the shape and color of different body parts.",
                    "label": 0
                },
                {
                    "sent": "In multiple views.",
                    "label": 0
                },
                {
                    "sent": "We concatenate the appearance feature vectors of both views.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then train the boosted parkitecture using this joint representation.",
                    "label": 0
                },
                {
                    "sent": "It makes the likelihood terms in our model even more discriminative.",
                    "label": 0
                },
                {
                    "sent": "And the multiple correspondence vectors encode encode the geometric constraint that the part locations in different views should agree on the same 30 point.",
                    "label": 0
                },
                {
                    "sent": "Therefore, be represented using the reprojection error.",
                    "label": 0
                },
                {
                    "sent": "When more than two years or.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will we connected corresponding body parts in all paraview.",
                    "label": 0
                },
                {
                    "sent": "This leads to a loop.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remember as well our multimodal pairwise terms and multi view previous vectors are non Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Therefore, the exact inference becomes.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Intractable.",
                    "label": 0
                },
                {
                    "sent": "To performing films in such a case, we rely on an approximate two stage.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inference procedure introduced by Andre Luca ET al.",
                    "label": 0
                },
                {
                    "sent": "At first the experience is done separately for each new.",
                    "label": 0
                },
                {
                    "sent": "Then we sample a sufficiently large.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set apart locations from the marginal distribution of the body parts.",
                    "label": 0
                },
                {
                    "sent": "In the second stage.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The inference is done for the full model in the reduced state space of the part locations.",
                    "label": 0
                },
                {
                    "sent": "Here Max product belief propagation algorithm is used which allows us to obtain the consistent estimate for the full body and in all views.",
                    "label": 0
                },
                {
                    "sent": "Finally, given the two depots estimates, we construct the three poles using triangulation.",
                    "label": 0
                },
                {
                    "sent": "We evaluate our.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which on two different data sets in the first is the human number, one which is the standard for 3D human pose estimation.",
                    "label": 1
                },
                {
                    "sent": "Following previous work, we use three color cameras for experiments over 4 different activities, walking, jogging, boxing, combo and this bar graph here shows the 3D error in millimeters, so the lower the better.",
                    "label": 1
                },
                {
                    "sent": "We start with our flexible pictorial structures model from CPR 12.",
                    "label": 0
                },
                {
                    "sent": "We see that adding mixture component reduces.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other by 31 millimeters.",
                    "label": 0
                },
                {
                    "sent": "Which this huge performance can be explained by the fact that for the human walking sequence the people are walking in circles.",
                    "label": 0
                },
                {
                    "sent": "So our single component cannot represent the viewpoint variations.",
                    "label": 0
                },
                {
                    "sent": "Combine shapes.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Presentation improves the performance by 8 millimeters.",
                    "label": 0
                },
                {
                    "sent": "Then adding multivu.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Previous vectors.",
                    "label": 0
                },
                {
                    "sent": "Give us gives us the game of 20 millimeters, which shows the importance of jointly modeling deposes across views.",
                    "label": 0
                },
                {
                    "sent": "Finally, the multimodal pair Western herd.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did you see the 3D error and overall we get improved by almost more than half of the initial error.",
                    "label": 0
                },
                {
                    "sent": "Here are some.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In comparison to the state of yard for component walk sequences.",
                    "label": 0
                },
                {
                    "sent": "These state of the art approaches rely on initialization and tracking.",
                    "label": 0
                },
                {
                    "sent": "Using complex motion models, while we evaluate only for the single time frame.",
                    "label": 0
                },
                {
                    "sent": "In the case of combo sequence, which is a combination of walking and jogging activities.",
                    "label": 0
                },
                {
                    "sent": "Our approach here shown in green, outperforms the CR VM approach by of Taylor tell by around 24 millimeters.",
                    "label": 0
                },
                {
                    "sent": "Similarly, in the case of box sequence, we improve significantly over state of the art.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we have some quality.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Qualitative results for the human ever data set is the box sequence in the lower right corner.",
                    "label": 0
                },
                {
                    "sent": "We show the component selection.",
                    "label": 0
                },
                {
                    "sent": "They've done minimum various criteria.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next we have results for the combo sequence, the.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It starts with The Walking activity.",
                    "label": 0
                },
                {
                    "sent": "And then switches to jogging later.",
                    "label": 0
                },
                {
                    "sent": "We note that our model robustly handled multiple activities.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next we also evaluate overall more challenging MPI cooking data set.",
                    "label": 0
                },
                {
                    "sent": "It contains 65 different fine grained activities and significantly large number of subjects interacting with various objects.",
                    "label": 1
                },
                {
                    "sent": "Our training set contains 896 images per view.",
                    "label": 1
                },
                {
                    "sent": "Antacid contains 1154 images per view with seven different subjects.",
                    "label": 0
                },
                {
                    "sent": "Here we compare our our previous work and the flexible pictorial structure model from Cpl.",
                    "label": 0
                },
                {
                    "sent": "The graph represents the percentage of correctly estimated parts in the PCP values.",
                    "label": 0
                },
                {
                    "sent": "So in this case the higher is better.",
                    "label": 0
                },
                {
                    "sent": "We note that our current approach improves significantly for all parts and especially.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the arm.",
                    "label": 0
                },
                {
                    "sent": "It outperforms the previous work by more than 20%.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are some quality results for the MPI cooking data set.",
                    "label": 0
                },
                {
                    "sent": "We know that we are able to detect poses for different activities.",
                    "label": 0
                },
                {
                    "sent": "Variety of people and all viewpoints.",
                    "label": 0
                },
                {
                    "sent": "The subjects are interacting with various objects leading to a non static background.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summarize we propose a multi projector model for 3D human pose estimation inspired by the recent work, we proposed a number of improvements for the two decoding section model.",
                    "label": 1
                },
                {
                    "sent": "Then we describe how we extend this model to multiple views.",
                    "label": 0
                },
                {
                    "sent": "We show that our approach, which runs for the single time frame, outperforms the state of the art that require initialization and tracking with complex motion models.",
                    "label": 0
                },
                {
                    "sent": "For the future work we.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To evaluate for non static camera setup with multiple interacting subjects.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can download the complete MPI cooking.",
                    "label": 0
                },
                {
                    "sent": "That's it with evaluation, training and test sets on this link.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for attention.",
                    "label": 0
                }
            ]
        }
    }
}