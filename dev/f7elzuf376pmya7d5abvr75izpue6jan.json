{
    "id": "f7elzuf376pmya7d5abvr75izpue6jan",
    "title": "Some Machine Learning Problems that We in the Computer Vision Community Would Like to See Solved",
    "info": {
        "author": [
            "William T. Freeman, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Jan. 14, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_freeman_smlptwcvcwlss/",
    "segmentation": [
        [
            "So I want to ask your permission to give a different kind of talk.",
            "They invited me to this workshop on learning and large graphical models, learning of large graphical models, and I thought, well, Gee, I haven't really done anything about learning large graphical models have done stuff on inference and large graphical models, but that was a little while ago.",
            "And so I think I may be not appropriate for this all comers talk anyway, so it's OK.",
            "Listen, I'll give a sort of consumers talk of what I would like to see done by you.",
            "People in this room so.",
            "So that's where this talk is.",
            "It's a different flavor.",
            "I was thinking actually it's kind of like when you go to a restaurant in fancy restaurant and sometimes they give a little sorbet to cleanse your palette.",
            "You know between the other things.",
            "And that's where this talk is like a pallet cleanser.",
            "Talk OK."
        ],
        [
            "So.",
            "Here's what I want to talk about.",
            "I want to talk about what and also, if you're really up on computer processing, which I see many people are actually in the audience, this might not be the talk for you, but that's OK.",
            "I hope it is.",
            "Let me talk about what works in computer vision, what doesn't work in low level and high level vision, and what other people think doesn't work where other people think we need."
        ],
        [
            "Help so.",
            "Let's just talk a little bit about what works.",
            "So there's a whole lot of companies.",
            "That make computer vision product.",
            "So there's something that's got it."
        ],
        [
            "Work and we've got Cognex, which is the world leader in machine vision.",
            "Typically it's manufacturing or semiconductors, so it's really controlled environments.",
            "We've got that problem solved."
        ],
        [
            "Well.",
            "There's a basically a lifeguard program that looks in swimming pools and detects when someone's there at the bottom drowning, and so that's I haven't.",
            "Actually, I'm not up on exactly what methods they use, but I suspect that's.",
            "In a lot of careful work in sort of environment modeling."
        ],
        [
            "Change detection but you know that's something that works and it's installed and sometimes people ask well, why wasn't this installed in the pool?",
            "If there's a?"
        ],
        [
            "Tragedy.",
            "There's soon now in very high end cars and soon in other cars there's driving aids that tell you when you're shifting lanes when you shouldn't.",
            "That tell the car with the expected time to collision with the car ahead of you is so that the car can start preparing.",
            "Again, that's a fairly controlled environment, rigid objects, but we."
        ],
        [
            "We do pretty well there.",
            "And then also faces if someone puts their face forward at a camera.",
            "We're pretty good at detecting it and recognizing where it is.",
            "We gotta eringer here in the audience for back Mogadon.",
            "We've done a lot of work on that."
        ],
        [
            "OK and and then also when you have images with lots of texture, we're really good at putting it on top of each other so that they registered well and so Microsoft has this nice Photosynth product that lets."
        ],
        [
            "Do that.",
            "So, so here's a little very high level summary.",
            "What does work?",
            "You know, understanding the relationships between rigid objects and fairly constrained settings?",
            "Automobile Lane finding recognizing rigid objects are reasonably rigid, matching textured regions of different images.",
            "Finding changes in images."
        ],
        [
            "OK, what doesn't work?",
            "Well, I want to kind of address that at two different levels.",
            "One low level vision and one high level vision.",
            "So low level vision I think of as images in an image is out of some other kind in the high level, vision is sort of images in and some description out words."
        ],
        [
            "So here's a graphical model of what you'd like to do for an image.",
            "You explain all the pixels of an image as being resulting from the particular viewpoint you're looking at it from.",
            "Lighting conditions and.",
            "And it's also caused by the surfaces that are in the world, which are in turn caused by objects in the world and which is in turn even higher level called by some caused by some story of what's going on.",
            "So, for example, if you look at this picture here.",
            "You can kind of recognize that all these different levels.",
            "You can see the surface is there.",
            "You can figure out what the lighting conditions are.",
            "You can see the different objects is there and you can even see the different story that Alyosha is upset at.",
            "This Alyosha Efros a colleague, and he happens actually.",
            "So really hate graphical models and everything, so this is.",
            "Appropriate.",
            "Um?",
            "So that's we love to have out of a graphical models.",
            "We'd love to have, you know, to get the picture in and just get out the surface object."
        ],
        [
            "All these latent variables and it's hard to do.",
            "Let's go all the way down, not from the story.",
            "Now from the object, follow down to the sort of surface level descriptions.",
            "We'd like to get a computer to handle this image looks so trivial it's almost the same.",
            "Image data in both sides, but there's been a little shift and you're percept of it.",
            "You're such brilliant perceivers there you understand everything.",
            "This one you perceive as a 3D surface.",
            "This when you perceive as paint on paper on the screen and.",
            "You'd love to have an graphical model that would look at lots of examples of images in the world and come up with a latent variable representation of this.",
            "It was appropriate for those two different cases."
        ],
        [
            "Shading and paint.",
            "And here's another kind of picture of that same story.",
            "You have an image which is formed by some shading image shown here, multiplied by some reflectance image shown there.",
            "These are latent images.",
            "You'd like to be able to extract from this.",
            "Rendered image.",
            "Um?",
            "And bear antenna Brown.",
            "Josh Tenenbaum's father worked on this."
        ],
        [
            "From years ago.",
            "Just to mention things we've done, so I should say we haven't solved this problem.",
            "I'd love to solve this problem.",
            "We've done kind of heuristic approaches to it.",
            "We made a local classifier that looked local image data and tried to separate out into shading, painting and property things with the marker and field.",
            "But it really wasn't very elegant and it doesn't work all that well.",
            "Here's the output are Marshall tapping student Professor Edward Elson, joint work with them.",
            "This is the output of our algorithm on this image input and it's got a lot of flaws.",
            "And also it wasn't.",
            "It wasn't done in the kind of elegant way of having.",
            "An algorithm look at a lot of images and and find these latent variables that we think ought to be there.",
            "It might work if you want interrupt with questions too, that might serve."
        ],
        [
            "Help things along.",
            "So here other examples of things that don't work, so usually want to show these outlook how well it works.",
            "Now I'm just showing this look how terribly it works, so this is, you know what we can do for taking this image and breaking it up into these latent components.",
            "The shading component and the reflections component."
        ],
        [
            "And here's another one, sort of the quintessential thing he's got the graffiti on the rock you'd like to separate out those two processes.",
            "The paint from the rock process.",
            "And again, there are sort of initial attempts.",
            "Do something but you'd like to have a principled approach, but doesn't much better."
        ],
        [
            "And that leads to another graphical model I'd like to solve.",
            "You like to look at an image, which again results from lighting viewpoint and separated into two statistical processes that make this thing.",
            "Here's an example of what I mean."
        ],
        [
            "This image here on the left.",
            "Is this one plus this form?",
            "Now you'd like to get your.",
            "Algorithm to look at this one and say I look, there's two different things going on here.",
            "We're going to separate them out into different latent layers.",
            "The straw thing and the.",
            "Matt thing and you can have other processes to this.",
            "How would this be useful?",
            "This would be useful for interpreting images that would be useful for.",
            "Removing noise and it kind of generic way from many classes of images, seismic or optical images as well."
        ],
        [
            "And so we, Edward Elson, and his student, young, gently have done some initial work on this problem.",
            "Here's two different textures."
        ],
        [
            "And they had used that as training and then has this input as images input an separated out into these two things but.",
            "They didn't all have a generic general solution and you'd like to have.",
            "And a large graphical model that was able to look at this and separate out into this or specifically coherent different processes."
        ],
        [
            "And then finally, here's the kind of the simplest of all graphical models.",
            "I'd like to have a really good prior for images.",
            "You could use this everywhere.",
            "Um?"
        ],
        [
            "Here's and I say you all have fantastic priors for images in your head.",
            "You can look at this.",
            "You've never seen it before.",
            "You don't know what it's supposed to be, but you can form both an interpretation and say, well, there's something wrong with that image too.",
            "It's not a good image.",
            "And it's very hard to get an algorithm to look at a pile of pixel data and make that inference also, so you can say this is a blurry image, you can say."
        ],
        [
            "This is a sharp image."
        ],
        [
            "It's a blurry image.",
            "You're all very good at that."
        ],
        [
            "Let me just briefly show you work we've done using a pathetic little image prior, which tries to solve the deep learning problem and could do it much better if we had a much stronger prior for images.",
            "Here's the.",
            "Here's the problem of deblurring image.",
            "You have your data here, and you think it's formed by a convolution of latent sharp image and some unknown blur kernel.",
            "I'm.",
            "Making a little picture of the Blur kernel by showing what a camera with a photograph would look like if you move the camera in the same way as you did here and photograph the point of light while you're doing that.",
            "So this is how a single point gets modulated, and so the whole image that happens for every point in the image.",
            "Therefore you convolve this with the image to get that data."
        ],
        [
            "What's so nice about this as a kind of conceptualism problem is there are just many different solutions that could arise from any given piece of image, blurred image data.",
            "So here's a blurry image.",
            "What are some of the ways we can explain it?",
            "That is a perfectly good explanation of the image.",
            "This is what was out there and you took a sharp picture of that image, OK?",
            "So to avoid this solution you have to know what an image auto look like, even though you've never seen what's being photographed before.",
            "You have to have some idea.",
            "No, that's not a good image, and so we need those things.",
            "Here's another one you can come up with.",
            "If you're sort of diabolical, you can say, well, it's not exact, but it's pretty close.",
            "But if you convolve this with this, you get that data.",
            "And then also there's this other one that we're looking for.",
            "If you can't see it, it's just the sharp image, and the unknown blur kernel.",
            "How do you pick between these?",
            "You've got to have priors on images.",
            "Um?"
        ],
        [
            "So for the work we've done on this, we used to really.",
            "It's almost a toy prior, so we just says if you look at the pixel and look at his neighbor most of the time they're going to be saying that's the prior with a little more detail.",
            "So here's it's actually a parametric prior on what the grade distribution of gradients in the image will look like, so here's a vertical is the log on this log.",
            "Vertical scale is the probability of finding that gradient value and then zeros here and then.",
            "The other ones go away because in this log vertical scale it's not a parabola.",
            "You can see that images are very different than Gaussian.",
            "Noise and what's so beautiful about images is that this particular curve is pretty rock solid for many different kinds of images, and so actually was this image that we used as our Canonical prior for images.",
            "We fit this curve to it.",
            "If you took it."
        ],
        [
            "Blurred image, you get a different distribution and this is a pretty reliable indicator of whether it's.",
            "Learned or not, and this is helpful to us in doing our Bayesian method of navigating that very high, very rich space of feasible solutions to find which one is the right feasible solution."
        ],
        [
            "So we fit a parametric curve to that history."
        ],
        [
            "Ingredients and then we have these different terms in our variational in our Bayesian formulation, we have the likelihood term that whatever you come up with for the latent sharp image and the estimate blur kernel logic involved together give you the data that you saw and then you have your image prior.",
            "We also had a small simple prior on what the blurs could be."
        ],
        [
            "And we made a one that works.",
            "It's actually the we believe.",
            "It's the best one so far.",
            "Although it really falls short of what it could do so.",
            "Same interpretation, so here's a blurry image is kind of tells the whole story.",
            "All in one photo.",
            "It's someone taking a picture of herself in the mirror, so you got the camera and she's wiggling the camera during the exposure, and so you get the blurry picture of the photographer, and then our algorithm estimates the unknown blur kernel and evolves and give you this.",
            "There are plenty of artifacts yet to be fixed with this, but."
        ],
        [
            "Does better than the state than the previous state of the art and better than other ones since.",
            "Um?",
            "If you just naively sharpen, you get a sharper version of things.",
            "Something is wrong, and if you go and estimate with, the kernel really was, then you much better.",
            "We used a variational Bayesian inference too."
        ],
        [
            "Um?",
            "Find the solution.",
            "But here's a picture that shows this is from paper this summer by not living an others.",
            "See sale.",
            "Comparing different algorithms and it's hard to come up with a good metric for comparing these so she looked at the ratio of the.",
            "The error as a function of the deconvolution using the perf kernel and what you want, or the numbers that are high here and you see forgiven error ratio.",
            "How many pixels are have that error ratio or smaller than this one that's doing best is that simple gradient prior on the image data.",
            "So why am I saying we need better Pryor as well?",
            "Every time we modeled the problem better, we got better results and but you can never model it exactly and I think we could also a different approach to getting better results would be to have a very strong priority images that would let you.",
            "Avoid having to know all the details of your camera and all the details of the nonlinearities, and rely on this.",
            "Rely still more on your image prior to solve."
        ],
        [
            "Problem.",
            "Other applications of image priors include texture synthesis, so this is Romero Simoncelli's lab.",
            "Here's input images and training on those images.",
            "They can then output textures that have the same statistics.",
            "These statistics across space across scale of these bandpass filters."
        ],
        [
            "But we're still not there yet, and one real strong indicator that we're not there is these tradeoffs you have when you try to do noise removal using these image priors.",
            "In every case I've seen, you've got this.",
            "You got this nob that you can pick, telling how much you rely on your prior verses on your on the local noisy data.",
            "And as you turn that nob, you go from having an image that's way too noisy to an image that's just really artifact Y.",
            "Now if you had a really great image prior, the thing that you would turn the extremes, you would go between as you turn that Nob would be a noisy image, or some image that didn't look like the real image, but it looked like a valid image.",
            "But in every case I've seen.",
            "When you crank up the image prior, you get something that doesn't look image like it's pasty its artifact.",
            "To hear all these little, and if you can see them from the back there a lot of little wavelet artifacts that pop up and you'd like to have a really rock solid image prior with you cranked up the prior too much well, it would give you something that really look like an image.",
            "It wouldn't be the right one, but it looked like a good image and I've really never seen that in any of the noise removal results of people so far, so we still have a long way to go."
        ],
        [
            "There.",
            "OK, so problem this statistical characterizations images.",
            "Applications noise removal super resolution filling in texture synthesis and this is something that.",
            "Needs work."
        ],
        [
            "I'm.",
            "So that's kind of why I'm done with the low level part.",
            "The three things that we really need are good latent variable models.",
            "Signal dissection is a task that we could use help with and really good image priors also.",
            "So let me just touch on."
        ],
        [
            "The high level stuff."
        ],
        [
            "Um?",
            "So these these next two slides are from web page by Philly Rob Ferguson, Antonio Torralba on Object recognition, which I'd really recommend for people starting to get into the field so.",
            "Object Recognition is a tough problem.",
            "All these things are chairs and you can look at them and decide they're all chairs, but it's really hard to find a visual commonality that tells you that they're all chairs, so that's the task of vision."
        ],
        [
            "And there are a lot of issues in object recognition.",
            "Do you want to use generative or discriminative or some hybrid between the two?",
            "How much do you want to require the things being particular position, or how much can you allow that to vary?",
            "One thing I just want to focus on here are the use of features.",
            "In each image which leads to the big advance that happened in computer vision, I'll tell you about that."
        ],
        [
            "At.",
            "So first of all I want to take you back in time.",
            "Let's go to the 1980s."
        ],
        [
            "Here's what we all looked like back then.",
            "Everything had these nice geometric features and points and edges."
        ],
        [
            "And this is the."
        ],
        [
            "The vision that we did.",
            "Then we had these.",
            "We had scissors and wrenches and we find them in images.",
            "And we'd find them even if the plane was different than the way we train them on."
        ],
        [
            "But now going back to the present, we're dealing with images that are more like this.",
            "And big advance in the."
        ],
        [
            "Past 10 years in computer vision probably are these so called sift features by David Lowe that are.",
            "On the one hand, give you nice rich descriptors of local image appearance.",
            "And on the other hand, allow for slop in the exact positions of things and slot in the lighting.",
            "Relatively robust to changes in lighting and so forth, so that's what's nice about them.",
            "Their high dimensional and their descriptive, but at the same time they're forgiving.",
            "So how do they work?",
            "You look at the little Patch of image gradients an you make little histograms of how often each gradient orientation occurs in each of these little sub patches of your.",
            "Image region.",
            "And these little histograms you stack 'em all up into a big vector, and that's your feature vector that describes the local region.",
            "So you've got some positional slot because you're pulling things over space, but at the same time you've got this rich high dimensional descriptor and it's.",
            "It's really found a nice balance that lets you.",
            "Use these things to find correspondences where before just using image intensities we weren't able to find correspond."
        ],
        [
            "So here's an example.",
            "Here's a this is from David Lowe's.",
            "Really paper on this.",
            "Here's a test image, another image.",
            "From your training set, here's the.",
            "Image you want to find these things in, so if you look for that you categories categories according to their sift descriptors, and there's a second step they haven't told you about of.",
            "Finding special regions where you should calculate this set of gradients, but that's a.",
            "Relatively straightforward task.",
            "So you calculate those.",
            "Descriptors and you might get maybe several 100 and each one.",
            "And then you look for where they occur in this image, and that lets you find the instances of those test objects in this image, even though they might be very much included like.",
            "Here's the little train there and it can find it, and there it is again.",
            "You can find it.",
            "So these are used all the time for objects."
        ],
        [
            "Ignition."
        ],
        [
            "And here's the kind of away they are often used.",
            "You take an image you want to analyze.",
            "You find those special locations where you're going to calculate these descriptors, and then you vector quantize the set of all possible descriptors.",
            "And then.",
            "Collapse this image into account of how often you found each one of those descriptors within this image.",
            "And so now you've reduced the problem to one that a computer scientist can solve.",
            "So you have your histogram of.",
            "Sift feature occurrences and you want to go and match it to your model set."
        ],
        [
            "So so now you have a sort of combinatorial problem.",
            "That's one that again, people in the room might.",
            "Find interesting of how do you go to a data set.",
            "First of all, how do you find the nearest neighbor?",
            "Histogram quickly and then how do you account for the small differences in the distribution of those quantized features from your test in your training?",
            "And how do you find the best matches?",
            "So this is a rich area?",
            "That we still need a lot of work on.",
            "But this is a very successful approach for object recognition and object categorization.",
            "Carrots.",
            "It's I would call it a fat except it really is quite useful and I think it might be here to stay for awhile."
        ],
        [
            "So.",
            "This problem is category level recognition using a visual words representation.",
            "Applications are object recognition, here's some.",
            "Sort of.",
            "Typical papers that you could look at to get started on.",
            "How to approach this problem with your tools?"
        ],
        [
            "OK, so that's what I wanted to say about things.",
            "I think computer vision people need help with and then I want to report the results of my informal survey.",
            "So I went to this computer vision workshop in the summer which had.",
            "Not every I don't want anyone to feel left out here.",
            "It didn't have every single leading researcher in computer vision, but it had many of them.",
            "Rest in there in this room and you know who you are.",
            "But so I went around asking them what what computer science or machine learning problem would you like to see?",
            "Solve to help you in your work?",
            "And I'm going to report on the."
        ],
        [
            "Results of those.",
            "So a lot of people.",
            "And here's these three.",
            "At least.",
            "I had a very similar answer which was."
        ],
        [
            "We want nearest neighbor search in high dimensions.",
            "And this is something that there's been a lot of work on, and there's various techniques that are supposed to work well.",
            "But in practice, people find they don't work as well as they are advertised.",
            "And again, this is helpful for object recognition and for many, many tests.",
            "Lots of times we have, you know hundreds or millions of examples and those are all labeled.",
            "And if you just match them up to your test image should be all set.",
            "Of course, is the problem that other fields have as well.",
            "But that's one."
        ],
        [
            "Response.",
            "Um?",
            "And here's a recent paper in SIGGRAPH which does a nice.",
            "Job on this in a special case of when the Patch is within the same image you're you're working in."
        ],
        [
            "This is a pathological case javidan has this."
        ],
        [
            "Particular problem once were called blind vision and.",
            "I guess it depends on whether you think this is a task that will need to be solved, but he thinks you're going to have companies that can process images.",
            "But and people are going to send their things to them, but they don't want to have their images looked at.",
            "And this company that has his algorithm doesn't want algorithm let out.",
            "So you need to come up with a secure transaction mechanism where the person can send them an image in some coded way that the person with the algorithm can't ever look at it or decode it.",
            "But they can take their algorithm and run it on this coded data and return an answer and the people with the images can't figure out what the algorithm was, but you can process the image and complete the transaction without ever.",
            "Anyone seeing what was without either party having access to the other new and you could imagine how this might work if you had, it could be the case with you had some of the world's best face recognizer, but you didn't let the code out and people had faces they want detected but didn't want those let out."
        ],
        [
            "So another pathological task was request was to develop secure multiparty techniques for vision algorithms and she has started to work on this and you can look at some of his papers if you're interested in that.",
            "Problem."
        ],
        [
            "Have a ramanan."
        ],
        [
            "Said he wants to be able to evaluate some function over the powerset of all possible segmentations in the image.",
            "And.",
            "That indeed would be useful many times a problem is really simple if we just knew what the segmentation was, but of course we don't know what the segmentation is, so we'd like to evaluate some task over all possible segmentations and pick the one which was which worked out best.",
            "That's another task."
        ],
        [
            "And Alyosha efros."
        ],
        [
            "He he was an outlier, sort of.",
            "He let's see.",
            "Um?",
            "He wanted one thing he wanted was to be able to generalize from graphical models.",
            "He said those were good toy problems with a lot of conditional independence, but we don't have that.",
            "Everything depends on something else.",
            "Want some abstractions where you have many possible conditions conditional in dependencies?",
            "Um?",
            "Only see only a few of the conditional Independencies are active at any one time, as with sparse coding.",
            "And anyway.",
            "His or more less easily mapped onto particular task you want to solve, solve the needle in the haystack problem.",
            "Find clusters of characteristics, even when there's lots of clusters of characteristics.",
            "Even with lots of noise.",
            "So for example, four of us that I'm wearing a hat you want to look at the picture for people with hats, and determine that it's hats that are in common."
        ],
        [
            "Pietro perona"
        ],
        [
            "Again, wanted nearest nervous nearest neighbor search in high dimensions."
        ],
        [
            "And then David Lowe, the person who developed the features that we all use, said he thinks we need."
        ],
        [
            "Better features.",
            "OK, so an artist can draw the end of an elephant's trunk and you can look at it and immediately know what it is.",
            "But our features don't capture that.",
            "That similarity at all.",
            "So."
        ],
        [
            "So to summarize.",
            "For low level vision we want latent variable models, signal dissection, good image priors for high level vision.",
            "We want fast nearest neighbor matching and better features for object recognition.",
            "Um?",
            "Yes, and for amusement let me."
        ],
        [
            "Show you one thing."
        ],
        [
            "Here's what you can do if you have fast nearest neighbor finding in high dimensions.",
            "Here's a picture.",
            "It's gonna work my network.",
            "OK, so here's a little video.",
            "That is all made up.",
            "We just started from an image we had this large data set of Flickr images and we just found ones that matched in these places where we wanted to drive to.",
            "So."
        ],
        [
            "We have this database."
        ],
        [
            "And we used a matching based on this representation called just that on Twitter."
        ],
        [
            "Developed we.",
            "Do initial classifier to put these images into themes.",
            "Because if we didn't then we would jump from theme theme and."
        ],
        [
            "Things will go badly, but we again just by searching through a large database, let us in effect have a joystick where we could say turn left, turn right and we would go find the."
        ],
        [
            "Speed, image and.",
            "And so if you're here and you want to turn right, then you want you're looking for an image.",
            "Looks like this has this stuff on the left side and you don't care where it is on the right.",
            "So you go look for an image that matches their, wiggle it around so it finds a good match, and then use computer graphics methods to blend it in in a seamless fashion."
        ],
        [
            "And you've synthesized.",
            "What it takes to turn right?"
        ],
        [
            "And so you can make these large panoramas of things that don't exist anywhere.",
            "Again, if you have fast nearest neighbor search."
        ],
        [
            "And so you can find.",
            "You know what?",
            "It's off to the right of famous scenes, so here's the Hollywood sign.",
            "And here's what's off to the right of it."
        ],
        [
            "Here's another one.",
            "So we can zoom in.",
            "Zoom back out."
        ],
        [
            "And finally, for all of you who really want to know what is off to the right of the Windows XP screensaver.",
            "Here it is.",
            "OK, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I want to ask your permission to give a different kind of talk.",
                    "label": 0
                },
                {
                    "sent": "They invited me to this workshop on learning and large graphical models, learning of large graphical models, and I thought, well, Gee, I haven't really done anything about learning large graphical models have done stuff on inference and large graphical models, but that was a little while ago.",
                    "label": 0
                },
                {
                    "sent": "And so I think I may be not appropriate for this all comers talk anyway, so it's OK.",
                    "label": 0
                },
                {
                    "sent": "Listen, I'll give a sort of consumers talk of what I would like to see done by you.",
                    "label": 1
                },
                {
                    "sent": "People in this room so.",
                    "label": 0
                },
                {
                    "sent": "So that's where this talk is.",
                    "label": 0
                },
                {
                    "sent": "It's a different flavor.",
                    "label": 0
                },
                {
                    "sent": "I was thinking actually it's kind of like when you go to a restaurant in fancy restaurant and sometimes they give a little sorbet to cleanse your palette.",
                    "label": 0
                },
                {
                    "sent": "You know between the other things.",
                    "label": 0
                },
                {
                    "sent": "And that's where this talk is like a pallet cleanser.",
                    "label": 0
                },
                {
                    "sent": "Talk OK.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here's what I want to talk about.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about what and also, if you're really up on computer processing, which I see many people are actually in the audience, this might not be the talk for you, but that's OK.",
                    "label": 0
                },
                {
                    "sent": "I hope it is.",
                    "label": 0
                },
                {
                    "sent": "Let me talk about what works in computer vision, what doesn't work in low level and high level vision, and what other people think doesn't work where other people think we need.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Help so.",
                    "label": 0
                },
                {
                    "sent": "Let's just talk a little bit about what works.",
                    "label": 0
                },
                {
                    "sent": "So there's a whole lot of companies.",
                    "label": 0
                },
                {
                    "sent": "That make computer vision product.",
                    "label": 0
                },
                {
                    "sent": "So there's something that's got it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work and we've got Cognex, which is the world leader in machine vision.",
                    "label": 0
                },
                {
                    "sent": "Typically it's manufacturing or semiconductors, so it's really controlled environments.",
                    "label": 0
                },
                {
                    "sent": "We've got that problem solved.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "There's a basically a lifeguard program that looks in swimming pools and detects when someone's there at the bottom drowning, and so that's I haven't.",
                    "label": 0
                },
                {
                    "sent": "Actually, I'm not up on exactly what methods they use, but I suspect that's.",
                    "label": 0
                },
                {
                    "sent": "In a lot of careful work in sort of environment modeling.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change detection but you know that's something that works and it's installed and sometimes people ask well, why wasn't this installed in the pool?",
                    "label": 0
                },
                {
                    "sent": "If there's a?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tragedy.",
                    "label": 0
                },
                {
                    "sent": "There's soon now in very high end cars and soon in other cars there's driving aids that tell you when you're shifting lanes when you shouldn't.",
                    "label": 0
                },
                {
                    "sent": "That tell the car with the expected time to collision with the car ahead of you is so that the car can start preparing.",
                    "label": 0
                },
                {
                    "sent": "Again, that's a fairly controlled environment, rigid objects, but we.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do pretty well there.",
                    "label": 0
                },
                {
                    "sent": "And then also faces if someone puts their face forward at a camera.",
                    "label": 0
                },
                {
                    "sent": "We're pretty good at detecting it and recognizing where it is.",
                    "label": 0
                },
                {
                    "sent": "We gotta eringer here in the audience for back Mogadon.",
                    "label": 0
                },
                {
                    "sent": "We've done a lot of work on that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK and and then also when you have images with lots of texture, we're really good at putting it on top of each other so that they registered well and so Microsoft has this nice Photosynth product that lets.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do that.",
                    "label": 0
                },
                {
                    "sent": "So, so here's a little very high level summary.",
                    "label": 0
                },
                {
                    "sent": "What does work?",
                    "label": 0
                },
                {
                    "sent": "You know, understanding the relationships between rigid objects and fairly constrained settings?",
                    "label": 0
                },
                {
                    "sent": "Automobile Lane finding recognizing rigid objects are reasonably rigid, matching textured regions of different images.",
                    "label": 1
                },
                {
                    "sent": "Finding changes in images.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, what doesn't work?",
                    "label": 0
                },
                {
                    "sent": "Well, I want to kind of address that at two different levels.",
                    "label": 0
                },
                {
                    "sent": "One low level vision and one high level vision.",
                    "label": 0
                },
                {
                    "sent": "So low level vision I think of as images in an image is out of some other kind in the high level, vision is sort of images in and some description out words.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a graphical model of what you'd like to do for an image.",
                    "label": 0
                },
                {
                    "sent": "You explain all the pixels of an image as being resulting from the particular viewpoint you're looking at it from.",
                    "label": 0
                },
                {
                    "sent": "Lighting conditions and.",
                    "label": 0
                },
                {
                    "sent": "And it's also caused by the surfaces that are in the world, which are in turn caused by objects in the world and which is in turn even higher level called by some caused by some story of what's going on.",
                    "label": 0
                },
                {
                    "sent": "So, for example, if you look at this picture here.",
                    "label": 0
                },
                {
                    "sent": "You can kind of recognize that all these different levels.",
                    "label": 0
                },
                {
                    "sent": "You can see the surface is there.",
                    "label": 0
                },
                {
                    "sent": "You can figure out what the lighting conditions are.",
                    "label": 0
                },
                {
                    "sent": "You can see the different objects is there and you can even see the different story that Alyosha is upset at.",
                    "label": 0
                },
                {
                    "sent": "This Alyosha Efros a colleague, and he happens actually.",
                    "label": 0
                },
                {
                    "sent": "So really hate graphical models and everything, so this is.",
                    "label": 0
                },
                {
                    "sent": "Appropriate.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So that's we love to have out of a graphical models.",
                    "label": 0
                },
                {
                    "sent": "We'd love to have, you know, to get the picture in and just get out the surface object.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All these latent variables and it's hard to do.",
                    "label": 0
                },
                {
                    "sent": "Let's go all the way down, not from the story.",
                    "label": 0
                },
                {
                    "sent": "Now from the object, follow down to the sort of surface level descriptions.",
                    "label": 0
                },
                {
                    "sent": "We'd like to get a computer to handle this image looks so trivial it's almost the same.",
                    "label": 0
                },
                {
                    "sent": "Image data in both sides, but there's been a little shift and you're percept of it.",
                    "label": 0
                },
                {
                    "sent": "You're such brilliant perceivers there you understand everything.",
                    "label": 0
                },
                {
                    "sent": "This one you perceive as a 3D surface.",
                    "label": 0
                },
                {
                    "sent": "This when you perceive as paint on paper on the screen and.",
                    "label": 0
                },
                {
                    "sent": "You'd love to have an graphical model that would look at lots of examples of images in the world and come up with a latent variable representation of this.",
                    "label": 0
                },
                {
                    "sent": "It was appropriate for those two different cases.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shading and paint.",
                    "label": 0
                },
                {
                    "sent": "And here's another kind of picture of that same story.",
                    "label": 0
                },
                {
                    "sent": "You have an image which is formed by some shading image shown here, multiplied by some reflectance image shown there.",
                    "label": 1
                },
                {
                    "sent": "These are latent images.",
                    "label": 0
                },
                {
                    "sent": "You'd like to be able to extract from this.",
                    "label": 0
                },
                {
                    "sent": "Rendered image.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And bear antenna Brown.",
                    "label": 0
                },
                {
                    "sent": "Josh Tenenbaum's father worked on this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From years ago.",
                    "label": 0
                },
                {
                    "sent": "Just to mention things we've done, so I should say we haven't solved this problem.",
                    "label": 0
                },
                {
                    "sent": "I'd love to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "We've done kind of heuristic approaches to it.",
                    "label": 0
                },
                {
                    "sent": "We made a local classifier that looked local image data and tried to separate out into shading, painting and property things with the marker and field.",
                    "label": 0
                },
                {
                    "sent": "But it really wasn't very elegant and it doesn't work all that well.",
                    "label": 0
                },
                {
                    "sent": "Here's the output are Marshall tapping student Professor Edward Elson, joint work with them.",
                    "label": 1
                },
                {
                    "sent": "This is the output of our algorithm on this image input and it's got a lot of flaws.",
                    "label": 0
                },
                {
                    "sent": "And also it wasn't.",
                    "label": 0
                },
                {
                    "sent": "It wasn't done in the kind of elegant way of having.",
                    "label": 0
                },
                {
                    "sent": "An algorithm look at a lot of images and and find these latent variables that we think ought to be there.",
                    "label": 0
                },
                {
                    "sent": "It might work if you want interrupt with questions too, that might serve.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Help things along.",
                    "label": 0
                },
                {
                    "sent": "So here other examples of things that don't work, so usually want to show these outlook how well it works.",
                    "label": 0
                },
                {
                    "sent": "Now I'm just showing this look how terribly it works, so this is, you know what we can do for taking this image and breaking it up into these latent components.",
                    "label": 0
                },
                {
                    "sent": "The shading component and the reflections component.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's another one, sort of the quintessential thing he's got the graffiti on the rock you'd like to separate out those two processes.",
                    "label": 0
                },
                {
                    "sent": "The paint from the rock process.",
                    "label": 0
                },
                {
                    "sent": "And again, there are sort of initial attempts.",
                    "label": 0
                },
                {
                    "sent": "Do something but you'd like to have a principled approach, but doesn't much better.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that leads to another graphical model I'd like to solve.",
                    "label": 0
                },
                {
                    "sent": "You like to look at an image, which again results from lighting viewpoint and separated into two statistical processes that make this thing.",
                    "label": 1
                },
                {
                    "sent": "Here's an example of what I mean.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This image here on the left.",
                    "label": 0
                },
                {
                    "sent": "Is this one plus this form?",
                    "label": 0
                },
                {
                    "sent": "Now you'd like to get your.",
                    "label": 0
                },
                {
                    "sent": "Algorithm to look at this one and say I look, there's two different things going on here.",
                    "label": 0
                },
                {
                    "sent": "We're going to separate them out into different latent layers.",
                    "label": 0
                },
                {
                    "sent": "The straw thing and the.",
                    "label": 0
                },
                {
                    "sent": "Matt thing and you can have other processes to this.",
                    "label": 0
                },
                {
                    "sent": "How would this be useful?",
                    "label": 0
                },
                {
                    "sent": "This would be useful for interpreting images that would be useful for.",
                    "label": 0
                },
                {
                    "sent": "Removing noise and it kind of generic way from many classes of images, seismic or optical images as well.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we, Edward Elson, and his student, young, gently have done some initial work on this problem.",
                    "label": 0
                },
                {
                    "sent": "Here's two different textures.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they had used that as training and then has this input as images input an separated out into these two things but.",
                    "label": 0
                },
                {
                    "sent": "They didn't all have a generic general solution and you'd like to have.",
                    "label": 0
                },
                {
                    "sent": "And a large graphical model that was able to look at this and separate out into this or specifically coherent different processes.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then finally, here's the kind of the simplest of all graphical models.",
                    "label": 0
                },
                {
                    "sent": "I'd like to have a really good prior for images.",
                    "label": 1
                },
                {
                    "sent": "You could use this everywhere.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's and I say you all have fantastic priors for images in your head.",
                    "label": 0
                },
                {
                    "sent": "You can look at this.",
                    "label": 0
                },
                {
                    "sent": "You've never seen it before.",
                    "label": 0
                },
                {
                    "sent": "You don't know what it's supposed to be, but you can form both an interpretation and say, well, there's something wrong with that image too.",
                    "label": 0
                },
                {
                    "sent": "It's not a good image.",
                    "label": 0
                },
                {
                    "sent": "And it's very hard to get an algorithm to look at a pile of pixel data and make that inference also, so you can say this is a blurry image, you can say.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a sharp image.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a blurry image.",
                    "label": 0
                },
                {
                    "sent": "You're all very good at that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me just briefly show you work we've done using a pathetic little image prior, which tries to solve the deep learning problem and could do it much better if we had a much stronger prior for images.",
                    "label": 0
                },
                {
                    "sent": "Here's the.",
                    "label": 0
                },
                {
                    "sent": "Here's the problem of deblurring image.",
                    "label": 0
                },
                {
                    "sent": "You have your data here, and you think it's formed by a convolution of latent sharp image and some unknown blur kernel.",
                    "label": 1
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Making a little picture of the Blur kernel by showing what a camera with a photograph would look like if you move the camera in the same way as you did here and photograph the point of light while you're doing that.",
                    "label": 0
                },
                {
                    "sent": "So this is how a single point gets modulated, and so the whole image that happens for every point in the image.",
                    "label": 0
                },
                {
                    "sent": "Therefore you convolve this with the image to get that data.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's so nice about this as a kind of conceptualism problem is there are just many different solutions that could arise from any given piece of image, blurred image data.",
                    "label": 0
                },
                {
                    "sent": "So here's a blurry image.",
                    "label": 1
                },
                {
                    "sent": "What are some of the ways we can explain it?",
                    "label": 0
                },
                {
                    "sent": "That is a perfectly good explanation of the image.",
                    "label": 0
                },
                {
                    "sent": "This is what was out there and you took a sharp picture of that image, OK?",
                    "label": 0
                },
                {
                    "sent": "So to avoid this solution you have to know what an image auto look like, even though you've never seen what's being photographed before.",
                    "label": 0
                },
                {
                    "sent": "You have to have some idea.",
                    "label": 0
                },
                {
                    "sent": "No, that's not a good image, and so we need those things.",
                    "label": 0
                },
                {
                    "sent": "Here's another one you can come up with.",
                    "label": 0
                },
                {
                    "sent": "If you're sort of diabolical, you can say, well, it's not exact, but it's pretty close.",
                    "label": 0
                },
                {
                    "sent": "But if you convolve this with this, you get that data.",
                    "label": 0
                },
                {
                    "sent": "And then also there's this other one that we're looking for.",
                    "label": 0
                },
                {
                    "sent": "If you can't see it, it's just the sharp image, and the unknown blur kernel.",
                    "label": 1
                },
                {
                    "sent": "How do you pick between these?",
                    "label": 0
                },
                {
                    "sent": "You've got to have priors on images.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the work we've done on this, we used to really.",
                    "label": 0
                },
                {
                    "sent": "It's almost a toy prior, so we just says if you look at the pixel and look at his neighbor most of the time they're going to be saying that's the prior with a little more detail.",
                    "label": 0
                },
                {
                    "sent": "So here's it's actually a parametric prior on what the grade distribution of gradients in the image will look like, so here's a vertical is the log on this log.",
                    "label": 0
                },
                {
                    "sent": "Vertical scale is the probability of finding that gradient value and then zeros here and then.",
                    "label": 0
                },
                {
                    "sent": "The other ones go away because in this log vertical scale it's not a parabola.",
                    "label": 0
                },
                {
                    "sent": "You can see that images are very different than Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Noise and what's so beautiful about images is that this particular curve is pretty rock solid for many different kinds of images, and so actually was this image that we used as our Canonical prior for images.",
                    "label": 0
                },
                {
                    "sent": "We fit this curve to it.",
                    "label": 0
                },
                {
                    "sent": "If you took it.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Blurred image, you get a different distribution and this is a pretty reliable indicator of whether it's.",
                    "label": 0
                },
                {
                    "sent": "Learned or not, and this is helpful to us in doing our Bayesian method of navigating that very high, very rich space of feasible solutions to find which one is the right feasible solution.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we fit a parametric curve to that history.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ingredients and then we have these different terms in our variational in our Bayesian formulation, we have the likelihood term that whatever you come up with for the latent sharp image and the estimate blur kernel logic involved together give you the data that you saw and then you have your image prior.",
                    "label": 0
                },
                {
                    "sent": "We also had a small simple prior on what the blurs could be.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we made a one that works.",
                    "label": 0
                },
                {
                    "sent": "It's actually the we believe.",
                    "label": 0
                },
                {
                    "sent": "It's the best one so far.",
                    "label": 0
                },
                {
                    "sent": "Although it really falls short of what it could do so.",
                    "label": 0
                },
                {
                    "sent": "Same interpretation, so here's a blurry image is kind of tells the whole story.",
                    "label": 0
                },
                {
                    "sent": "All in one photo.",
                    "label": 0
                },
                {
                    "sent": "It's someone taking a picture of herself in the mirror, so you got the camera and she's wiggling the camera during the exposure, and so you get the blurry picture of the photographer, and then our algorithm estimates the unknown blur kernel and evolves and give you this.",
                    "label": 0
                },
                {
                    "sent": "There are plenty of artifacts yet to be fixed with this, but.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does better than the state than the previous state of the art and better than other ones since.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "If you just naively sharpen, you get a sharper version of things.",
                    "label": 0
                },
                {
                    "sent": "Something is wrong, and if you go and estimate with, the kernel really was, then you much better.",
                    "label": 0
                },
                {
                    "sent": "We used a variational Bayesian inference too.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Find the solution.",
                    "label": 0
                },
                {
                    "sent": "But here's a picture that shows this is from paper this summer by not living an others.",
                    "label": 0
                },
                {
                    "sent": "See sale.",
                    "label": 0
                },
                {
                    "sent": "Comparing different algorithms and it's hard to come up with a good metric for comparing these so she looked at the ratio of the.",
                    "label": 0
                },
                {
                    "sent": "The error as a function of the deconvolution using the perf kernel and what you want, or the numbers that are high here and you see forgiven error ratio.",
                    "label": 0
                },
                {
                    "sent": "How many pixels are have that error ratio or smaller than this one that's doing best is that simple gradient prior on the image data.",
                    "label": 0
                },
                {
                    "sent": "So why am I saying we need better Pryor as well?",
                    "label": 0
                },
                {
                    "sent": "Every time we modeled the problem better, we got better results and but you can never model it exactly and I think we could also a different approach to getting better results would be to have a very strong priority images that would let you.",
                    "label": 0
                },
                {
                    "sent": "Avoid having to know all the details of your camera and all the details of the nonlinearities, and rely on this.",
                    "label": 0
                },
                {
                    "sent": "Rely still more on your image prior to solve.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "Other applications of image priors include texture synthesis, so this is Romero Simoncelli's lab.",
                    "label": 0
                },
                {
                    "sent": "Here's input images and training on those images.",
                    "label": 0
                },
                {
                    "sent": "They can then output textures that have the same statistics.",
                    "label": 0
                },
                {
                    "sent": "These statistics across space across scale of these bandpass filters.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we're still not there yet, and one real strong indicator that we're not there is these tradeoffs you have when you try to do noise removal using these image priors.",
                    "label": 0
                },
                {
                    "sent": "In every case I've seen, you've got this.",
                    "label": 0
                },
                {
                    "sent": "You got this nob that you can pick, telling how much you rely on your prior verses on your on the local noisy data.",
                    "label": 0
                },
                {
                    "sent": "And as you turn that nob, you go from having an image that's way too noisy to an image that's just really artifact Y.",
                    "label": 0
                },
                {
                    "sent": "Now if you had a really great image prior, the thing that you would turn the extremes, you would go between as you turn that Nob would be a noisy image, or some image that didn't look like the real image, but it looked like a valid image.",
                    "label": 0
                },
                {
                    "sent": "But in every case I've seen.",
                    "label": 0
                },
                {
                    "sent": "When you crank up the image prior, you get something that doesn't look image like it's pasty its artifact.",
                    "label": 0
                },
                {
                    "sent": "To hear all these little, and if you can see them from the back there a lot of little wavelet artifacts that pop up and you'd like to have a really rock solid image prior with you cranked up the prior too much well, it would give you something that really look like an image.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't be the right one, but it looked like a good image and I've really never seen that in any of the noise removal results of people so far, so we still have a long way to go.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "OK, so problem this statistical characterizations images.",
                    "label": 0
                },
                {
                    "sent": "Applications noise removal super resolution filling in texture synthesis and this is something that.",
                    "label": 0
                },
                {
                    "sent": "Needs work.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of why I'm done with the low level part.",
                    "label": 0
                },
                {
                    "sent": "The three things that we really need are good latent variable models.",
                    "label": 1
                },
                {
                    "sent": "Signal dissection is a task that we could use help with and really good image priors also.",
                    "label": 0
                },
                {
                    "sent": "So let me just touch on.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The high level stuff.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So these these next two slides are from web page by Philly Rob Ferguson, Antonio Torralba on Object recognition, which I'd really recommend for people starting to get into the field so.",
                    "label": 1
                },
                {
                    "sent": "Object Recognition is a tough problem.",
                    "label": 0
                },
                {
                    "sent": "All these things are chairs and you can look at them and decide they're all chairs, but it's really hard to find a visual commonality that tells you that they're all chairs, so that's the task of vision.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are a lot of issues in object recognition.",
                    "label": 1
                },
                {
                    "sent": "Do you want to use generative or discriminative or some hybrid between the two?",
                    "label": 0
                },
                {
                    "sent": "How much do you want to require the things being particular position, or how much can you allow that to vary?",
                    "label": 1
                },
                {
                    "sent": "One thing I just want to focus on here are the use of features.",
                    "label": 0
                },
                {
                    "sent": "In each image which leads to the big advance that happened in computer vision, I'll tell you about that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "So first of all I want to take you back in time.",
                    "label": 0
                },
                {
                    "sent": "Let's go to the 1980s.",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's what we all looked like back then.",
                    "label": 0
                },
                {
                    "sent": "Everything had these nice geometric features and points and edges.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The vision that we did.",
                    "label": 0
                },
                {
                    "sent": "Then we had these.",
                    "label": 0
                },
                {
                    "sent": "We had scissors and wrenches and we find them in images.",
                    "label": 0
                },
                {
                    "sent": "And we'd find them even if the plane was different than the way we train them on.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now going back to the present, we're dealing with images that are more like this.",
                    "label": 0
                },
                {
                    "sent": "And big advance in the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Past 10 years in computer vision probably are these so called sift features by David Lowe that are.",
                    "label": 0
                },
                {
                    "sent": "On the one hand, give you nice rich descriptors of local image appearance.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, allow for slop in the exact positions of things and slot in the lighting.",
                    "label": 0
                },
                {
                    "sent": "Relatively robust to changes in lighting and so forth, so that's what's nice about them.",
                    "label": 0
                },
                {
                    "sent": "Their high dimensional and their descriptive, but at the same time they're forgiving.",
                    "label": 0
                },
                {
                    "sent": "So how do they work?",
                    "label": 0
                },
                {
                    "sent": "You look at the little Patch of image gradients an you make little histograms of how often each gradient orientation occurs in each of these little sub patches of your.",
                    "label": 0
                },
                {
                    "sent": "Image region.",
                    "label": 0
                },
                {
                    "sent": "And these little histograms you stack 'em all up into a big vector, and that's your feature vector that describes the local region.",
                    "label": 0
                },
                {
                    "sent": "So you've got some positional slot because you're pulling things over space, but at the same time you've got this rich high dimensional descriptor and it's.",
                    "label": 0
                },
                {
                    "sent": "It's really found a nice balance that lets you.",
                    "label": 0
                },
                {
                    "sent": "Use these things to find correspondences where before just using image intensities we weren't able to find correspond.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "Here's a this is from David Lowe's.",
                    "label": 0
                },
                {
                    "sent": "Really paper on this.",
                    "label": 0
                },
                {
                    "sent": "Here's a test image, another image.",
                    "label": 0
                },
                {
                    "sent": "From your training set, here's the.",
                    "label": 0
                },
                {
                    "sent": "Image you want to find these things in, so if you look for that you categories categories according to their sift descriptors, and there's a second step they haven't told you about of.",
                    "label": 0
                },
                {
                    "sent": "Finding special regions where you should calculate this set of gradients, but that's a.",
                    "label": 0
                },
                {
                    "sent": "Relatively straightforward task.",
                    "label": 0
                },
                {
                    "sent": "So you calculate those.",
                    "label": 0
                },
                {
                    "sent": "Descriptors and you might get maybe several 100 and each one.",
                    "label": 0
                },
                {
                    "sent": "And then you look for where they occur in this image, and that lets you find the instances of those test objects in this image, even though they might be very much included like.",
                    "label": 0
                },
                {
                    "sent": "Here's the little train there and it can find it, and there it is again.",
                    "label": 0
                },
                {
                    "sent": "You can find it.",
                    "label": 0
                },
                {
                    "sent": "So these are used all the time for objects.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ignition.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's the kind of away they are often used.",
                    "label": 0
                },
                {
                    "sent": "You take an image you want to analyze.",
                    "label": 0
                },
                {
                    "sent": "You find those special locations where you're going to calculate these descriptors, and then you vector quantize the set of all possible descriptors.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Collapse this image into account of how often you found each one of those descriptors within this image.",
                    "label": 0
                },
                {
                    "sent": "And so now you've reduced the problem to one that a computer scientist can solve.",
                    "label": 0
                },
                {
                    "sent": "So you have your histogram of.",
                    "label": 0
                },
                {
                    "sent": "Sift feature occurrences and you want to go and match it to your model set.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so now you have a sort of combinatorial problem.",
                    "label": 0
                },
                {
                    "sent": "That's one that again, people in the room might.",
                    "label": 0
                },
                {
                    "sent": "Find interesting of how do you go to a data set.",
                    "label": 0
                },
                {
                    "sent": "First of all, how do you find the nearest neighbor?",
                    "label": 0
                },
                {
                    "sent": "Histogram quickly and then how do you account for the small differences in the distribution of those quantized features from your test in your training?",
                    "label": 0
                },
                {
                    "sent": "And how do you find the best matches?",
                    "label": 1
                },
                {
                    "sent": "So this is a rich area?",
                    "label": 0
                },
                {
                    "sent": "That we still need a lot of work on.",
                    "label": 0
                },
                {
                    "sent": "But this is a very successful approach for object recognition and object categorization.",
                    "label": 1
                },
                {
                    "sent": "Carrots.",
                    "label": 0
                },
                {
                    "sent": "It's I would call it a fat except it really is quite useful and I think it might be here to stay for awhile.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This problem is category level recognition using a visual words representation.",
                    "label": 1
                },
                {
                    "sent": "Applications are object recognition, here's some.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "Typical papers that you could look at to get started on.",
                    "label": 0
                },
                {
                    "sent": "How to approach this problem with your tools?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's what I wanted to say about things.",
                    "label": 0
                },
                {
                    "sent": "I think computer vision people need help with and then I want to report the results of my informal survey.",
                    "label": 0
                },
                {
                    "sent": "So I went to this computer vision workshop in the summer which had.",
                    "label": 1
                },
                {
                    "sent": "Not every I don't want anyone to feel left out here.",
                    "label": 0
                },
                {
                    "sent": "It didn't have every single leading researcher in computer vision, but it had many of them.",
                    "label": 0
                },
                {
                    "sent": "Rest in there in this room and you know who you are.",
                    "label": 0
                },
                {
                    "sent": "But so I went around asking them what what computer science or machine learning problem would you like to see?",
                    "label": 0
                },
                {
                    "sent": "Solve to help you in your work?",
                    "label": 0
                },
                {
                    "sent": "And I'm going to report on the.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results of those.",
                    "label": 0
                },
                {
                    "sent": "So a lot of people.",
                    "label": 0
                },
                {
                    "sent": "And here's these three.",
                    "label": 0
                },
                {
                    "sent": "At least.",
                    "label": 0
                },
                {
                    "sent": "I had a very similar answer which was.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We want nearest neighbor search in high dimensions.",
                    "label": 1
                },
                {
                    "sent": "And this is something that there's been a lot of work on, and there's various techniques that are supposed to work well.",
                    "label": 1
                },
                {
                    "sent": "But in practice, people find they don't work as well as they are advertised.",
                    "label": 0
                },
                {
                    "sent": "And again, this is helpful for object recognition and for many, many tests.",
                    "label": 1
                },
                {
                    "sent": "Lots of times we have, you know hundreds or millions of examples and those are all labeled.",
                    "label": 0
                },
                {
                    "sent": "And if you just match them up to your test image should be all set.",
                    "label": 0
                },
                {
                    "sent": "Of course, is the problem that other fields have as well.",
                    "label": 0
                },
                {
                    "sent": "But that's one.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Response.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And here's a recent paper in SIGGRAPH which does a nice.",
                    "label": 0
                },
                {
                    "sent": "Job on this in a special case of when the Patch is within the same image you're you're working in.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a pathological case javidan has this.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particular problem once were called blind vision and.",
                    "label": 0
                },
                {
                    "sent": "I guess it depends on whether you think this is a task that will need to be solved, but he thinks you're going to have companies that can process images.",
                    "label": 0
                },
                {
                    "sent": "But and people are going to send their things to them, but they don't want to have their images looked at.",
                    "label": 0
                },
                {
                    "sent": "And this company that has his algorithm doesn't want algorithm let out.",
                    "label": 0
                },
                {
                    "sent": "So you need to come up with a secure transaction mechanism where the person can send them an image in some coded way that the person with the algorithm can't ever look at it or decode it.",
                    "label": 0
                },
                {
                    "sent": "But they can take their algorithm and run it on this coded data and return an answer and the people with the images can't figure out what the algorithm was, but you can process the image and complete the transaction without ever.",
                    "label": 0
                },
                {
                    "sent": "Anyone seeing what was without either party having access to the other new and you could imagine how this might work if you had, it could be the case with you had some of the world's best face recognizer, but you didn't let the code out and people had faces they want detected but didn't want those let out.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So another pathological task was request was to develop secure multiparty techniques for vision algorithms and she has started to work on this and you can look at some of his papers if you're interested in that.",
                    "label": 0
                },
                {
                    "sent": "Problem.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have a ramanan.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Said he wants to be able to evaluate some function over the powerset of all possible segmentations in the image.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "That indeed would be useful many times a problem is really simple if we just knew what the segmentation was, but of course we don't know what the segmentation is, so we'd like to evaluate some task over all possible segmentations and pick the one which was which worked out best.",
                    "label": 0
                },
                {
                    "sent": "That's another task.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Alyosha efros.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He he was an outlier, sort of.",
                    "label": 0
                },
                {
                    "sent": "He let's see.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "He wanted one thing he wanted was to be able to generalize from graphical models.",
                    "label": 1
                },
                {
                    "sent": "He said those were good toy problems with a lot of conditional independence, but we don't have that.",
                    "label": 1
                },
                {
                    "sent": "Everything depends on something else.",
                    "label": 0
                },
                {
                    "sent": "Want some abstractions where you have many possible conditions conditional in dependencies?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Only see only a few of the conditional Independencies are active at any one time, as with sparse coding.",
                    "label": 1
                },
                {
                    "sent": "And anyway.",
                    "label": 0
                },
                {
                    "sent": "His or more less easily mapped onto particular task you want to solve, solve the needle in the haystack problem.",
                    "label": 0
                },
                {
                    "sent": "Find clusters of characteristics, even when there's lots of clusters of characteristics.",
                    "label": 1
                },
                {
                    "sent": "Even with lots of noise.",
                    "label": 0
                },
                {
                    "sent": "So for example, four of us that I'm wearing a hat you want to look at the picture for people with hats, and determine that it's hats that are in common.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pietro perona",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, wanted nearest nervous nearest neighbor search in high dimensions.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then David Lowe, the person who developed the features that we all use, said he thinks we need.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Better features.",
                    "label": 0
                },
                {
                    "sent": "OK, so an artist can draw the end of an elephant's trunk and you can look at it and immediately know what it is.",
                    "label": 1
                },
                {
                    "sent": "But our features don't capture that.",
                    "label": 0
                },
                {
                    "sent": "That similarity at all.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize.",
                    "label": 0
                },
                {
                    "sent": "For low level vision we want latent variable models, signal dissection, good image priors for high level vision.",
                    "label": 1
                },
                {
                    "sent": "We want fast nearest neighbor matching and better features for object recognition.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yes, and for amusement let me.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show you one thing.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's what you can do if you have fast nearest neighbor finding in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "Here's a picture.",
                    "label": 0
                },
                {
                    "sent": "It's gonna work my network.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a little video.",
                    "label": 0
                },
                {
                    "sent": "That is all made up.",
                    "label": 0
                },
                {
                    "sent": "We just started from an image we had this large data set of Flickr images and we just found ones that matched in these places where we wanted to drive to.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have this database.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we used a matching based on this representation called just that on Twitter.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Developed we.",
                    "label": 0
                },
                {
                    "sent": "Do initial classifier to put these images into themes.",
                    "label": 1
                },
                {
                    "sent": "Because if we didn't then we would jump from theme theme and.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things will go badly, but we again just by searching through a large database, let us in effect have a joystick where we could say turn left, turn right and we would go find the.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speed, image and.",
                    "label": 0
                },
                {
                    "sent": "And so if you're here and you want to turn right, then you want you're looking for an image.",
                    "label": 0
                },
                {
                    "sent": "Looks like this has this stuff on the left side and you don't care where it is on the right.",
                    "label": 0
                },
                {
                    "sent": "So you go look for an image that matches their, wiggle it around so it finds a good match, and then use computer graphics methods to blend it in in a seamless fashion.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you've synthesized.",
                    "label": 0
                },
                {
                    "sent": "What it takes to turn right?",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you can make these large panoramas of things that don't exist anywhere.",
                    "label": 0
                },
                {
                    "sent": "Again, if you have fast nearest neighbor search.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you can find.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "It's off to the right of famous scenes, so here's the Hollywood sign.",
                    "label": 0
                },
                {
                    "sent": "And here's what's off to the right of it.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another one.",
                    "label": 0
                },
                {
                    "sent": "So we can zoom in.",
                    "label": 0
                },
                {
                    "sent": "Zoom back out.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, for all of you who really want to know what is off to the right of the Windows XP screensaver.",
                    "label": 0
                },
                {
                    "sent": "Here it is.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}