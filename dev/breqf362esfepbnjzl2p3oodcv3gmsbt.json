{
    "id": "breqf362esfepbnjzl2p3oodcv3gmsbt",
    "title": "Multi-View Learning in the Presence of View Disagreement",
    "info": {
        "author": [
            "C. Mario Christoudias, Linguistics and Philosophy, Massachusetts Institute of Technology, MIT"
        ],
        "published": "July 30, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/uai08_christoudias_mvl/",
    "segmentation": [
        [
            "Good morning everybody.",
            "My name is Mario.",
            "The topic of this talk in today's talk I'm going to introduce the problem of view disagreement in Multiview learning.",
            "I'm going to present an information theoretic approach for coping with this problem, and I'm going to demonstrate its effectiveness.",
            "An audiovisual speech and gesture recognition tasks."
        ],
        [
            "So the world is multi view, at least.",
            "I like to believe there are several problems in multi learning for some datasets are.",
            "Naturally split into different views or feature sets.",
            "For example, in conversational data sets, people use both speech and gesture in datasets involving document classification, you have the classic example of the text on the page and the text on the hyperlinks pointing to the page.",
            "And you also have the images within the document.",
            "So a key property for these kind of datasets is that each view provides a potentially redundant indication of the underlying class of interest."
        ],
        [
            "An multi view learning techniques exploit these potentially redundant views to learn from partially labeled data and they have been shown to be advantageous to learning with only a single view.",
            "Kind of especially in the case where the weaknesses of 1 view compliment districts strengths of the other kind of loosely speaking."
        ],
        [
            "So the challenge of multiple learning, however, is trying to deal with noisy observations or view insufficiency.",
            "So there have been a fair amount of approaches in the multi learning literature that in fact try and gauge the global amount of noise in each of you and essentially down weight the views for which the noise which that are insufficient and kind of focus on the views that are that are sufficient.",
            "So this gets us part of the way there, but in real."
        ],
        [
            "The kind of datasets that we face look more like this.",
            "We're essentially, the noise is not only purview, but it's actually also per sample.",
            "So the question is, you know, how can we deal with these kinds of datasets?",
            "In particular, kind of the most problematic samples are the ones that are really highly corrupted and.",
            "These samples you can see as belonging to a neutral or background class that essentially Co occur with other samples of interest."
        ],
        [
            "So this view corruption problem can be seen as a source of view disagreement, where essentially the samples in each view potentially belong to a different class.",
            "In this talk, we're particularly interested in audio visual problems and in these kind of problems you disagreement is caused by, for example, unimodal expression for.",
            "So if a person is expressing agreement, they can say yes without head nodding or head nod without saying yes.",
            "It could also be called by temporal, temporary view occlusions, so person can leave the field of view of the camera that can be included.",
            "Someone can speak over the person and also in general just just general noise through the environment or or the sensor."
        ],
        [
            "So in this talk we consider view disagreement caused by view corruption, and in particular we propose to detect and filter samples with few disagreement using an information theoretic measure based on a conditional view entropy."
        ],
        [
            "So some related work.",
            "Well, view disagreement can be seen as a new type of view insufficiency.",
            "So there's been a fair amount of work in multiview learning for dealing with the viewing for dealing with the insufficiency assumption, for example, has been working for regularization, where you explicitly optimized for the agreement between classifiers.",
            "When learning the classifiers, there's also been workin view validation, as these are the methods that I pointed to earlier, where essentially you down with the views that are noisier, insufficient, and focus on the sufficient ones.",
            "And there's also been work and would like to call multiview manifold learning where essentially.",
            "You form a consensus between the views when learning a low dimensional representation of your feature space.",
            "So kind of the key property here of all these approaches, although they've come a fairway of dealing with view insufficiency in its traditional sense, they still assume that for all samples, the samples across views come from the same class.",
            "And as we saw in the case of you corruption, that's not necessarily the case and is what we deal with in this talk."
        ],
        [
            "So before getting into the details of our approach, I just want to talk a little bit about the specific multiview learning algorithms we consider in this work.",
            "In particular, we deal with multiview bootstrapping algorithms such as code training and special case of coaching, which we call Crossview bootstrapping.",
            "So right now I'm going to take a moment to talk about each of these interns, starting with the latter approach."
        ],
        [
            "So across the bootstrapping, essentially the idea here is that you want to learn a classifier in one view from a classifier in the other, and this kind of approach can be beneficial if either A you have labeled data in one view but not the other, or or if you know apriori that the the classifier one view is more well suited to your data than the classifier and others, you can get more reliable labels in some sense from that from that classifier, and the way it works is kind of straightforward so.",
            "What you have is this unlabeled audiovisual data here that you like to learn this visual classifier from.",
            "So here each box is an audio sample or a visual sample and you have a set of labels in the middle.",
            "And the way this way."
        ],
        [
            "Works is you evaluate your classifier on this data and it returns.",
            "It's a set of labels for which it's confident on that it is doing a good job."
        ],
        [
            "And then we simply train the classifier using those labels."
        ],
        [
            "So, the more general instantiation.",
            "This approach is code training, where essentially here we learn a set of classifiers iteratively by bootstrapping them on partially labeled data.",
            "The assumptions of code training, our class conditional independence, which I won't talk too much about here, and also the sufficiency assumptions we've been talking about a bit.",
            "It's received quite amount of success.",
            "It's been applied to a variety of areas, including text classification, visual object detection, information retrieval."
        ],
        [
            "So just kind of another high level schematic of how that algorithm works.",
            "So here again we like to learn these audio visual classifiers from this partially labeled data.",
            "And the way we proceed is we."
        ],
        [
            "We first learn the classifier, get initial classifier in each view from the initial labeled set."
        ],
        [
            "And then we seek to improve these classifiers on the unlabeled data by first of all."
        ],
        [
            "Waiting is classified."
        ],
        [
            "And having it return it's most common."
        ],
        [
            "Examples."
        ],
        [
            "And."
        ],
        [
            "Then it then re training the classifiers and iterating this procedure of training test.",
            "So we either labeled all the data which is set number of iterations."
        ],
        [
            "So now kind of returning.",
            "Returning to the problem of view disagreement consider.",
            "This this toy example of two views are two dimensional data consisting of three normally distributed classes.",
            "So we have class one Class 2 and background.",
            "So in the typical Co training scenario, what we have is.",
            "We have samples for which the the corresponding sample in each view belongs to the same class.",
            "So here we've done.",
            "Foreground class sample were done in background.",
            "So the samples that cause problem, however those with you disagreement right?",
            "So here we have the sample belonging to Class 2 in V1, but the corresponding sample in view 2 is corrupted and now belongs to background right?",
            "So we like to be able to still learn in these scenarios, essentially taking advantage of the samples for which for which they have the same class in each view and not Co training on the sample of the disagreement.",
            "So to kind of show that conventional code training has has difficulty with these kind of datasets, we performed an experiment using this kind of this toy example with varying amounts of view disagreement."
        ],
        [
            "This is what we got.",
            "So what I'm showing here is the performance of the classifier learned in V1 and V2 with varying amounts of you disagreement.",
            "Increasing view disagreements in the X axis and correct classification rate in the Y.",
            "And what I show in red, the red line here is supervised performance that we achieved by from the classifier trained on the unlabeled data.",
            "And what I show in black is the performance of Co training as we increase the amount of disagreement.",
            "And here I'm showing average performance averaged over.",
            "Random splits of the data and suddenly will train and label set.",
            "And essentially what we see here.",
            "Surprisingly, code training is able to handle up to 40% view disagreements.",
            "But then for higher amounts 50% above as we expect, it does quite poorly.",
            "And what's important to note here is that in audiovisual datasets that we see, it is typical that will have you disagreement levels above 50%.",
            "So in fact we do want to be able to perform well in these in this range.",
            "So now let's see how we can do better by detecting if you disagree."
        ],
        [
            "And so with our approach, the key assumption is so, given N foreground classes in the background class, the key assumption is that the foreground classes can Co occur with either themselves or background and the background class can Co occur with itself or any other class.",
            "And this seems like a reasonable assumption for a lot of problems, but it's a particularly reasonable assumption for 40 visual problems which we care about in this work."
        ],
        [
            "So to kind of give you some intuition behind behind our approach.",
            "Once again, consider this.",
            "This notion of example.",
            "So what I'm showing here is the joint space for two for two view problem X One X2, and what's shown in diagonal or samples which we have agreement samples that belong to the same class which only off diagonal or samples of you disagreements, samples that Co occur with background.",
            "So now consider this scenario conditioning on a foreground sample in V1.",
            "So we see if we get a conditional distribution with two modes.",
            "Similarly, if we condition on the background sample in view 2.",
            "This results in a conditional distribution with three modes and essentially what this kind of intuition gives us.",
            "So here we are only showing it for kind of 3 two classes in background.",
            "But in general, as we as we increase the number of classes which will see the trend that if we if we condition on foreground we kind of get a distribution with with low entropy while conditioning on background we get a distribution with kind of high entropy and this kind of seen by the fact that when conditioning on background you get a distribution that is more uniform in some sense."
        ],
        [
            "So using that intuition, we derive if we use the following conditional entropy measure.",
            "So here let XK via multi sample with views.",
            "What we do is we define an indicator function M overview pairs.",
            "Of these samples, where essentially the indicator function returns one if the conditional entropy conditioning on sample K&J is less than some threshold.",
            "Where here we use the mean entropy as a threshold and returns 0 otherwise, and also hear the conditional entropy, we could be computed empirically over the unlabeled data.",
            "And here we use a probability estimate using kernel density estimator, but other methods are also applicable.",
            "So it's important to take away from this slide is essentially that because you can see here the indicator function, the text foreground samples right?",
            "So essentially, if the condition conditioning on a foreground sample gives us a low entropy, then it returns one is foreground, otherwise return zeros background."
        ],
        [
            "So using this measure we can.",
            "We can detect whether or not a sample XC is redundant, foreground to background.",
            "In particular, if for all views are all view pairs of a sample XKR indicator function returns one, then we know it's the redundant foreground sample.",
            "Similarly, for any of you pair are indicator function doesn't return one.",
            "Then we know is there going to background sample.",
            "So here we've defined measures that function over the entire."
        ],
        [
            "Sample we can also define a measure overview pairs for view disagreement, in particular for two views I&J of a multisample XC.",
            "We know that these user in view disagreement if their indicator functions disagree, so one indicator function says foreground are the ones is background.",
            "Then we know that it's you disagreement and this kind of captured by this logic.",
            "Bookstore operator here."
        ],
        [
            "So now we like to do is using this measure define a modified Co training algorithm that detects and filter samples with you disagreement and is able to learn from these kind of datasets.",
            "So as before, we have a partial label data set for she want to learn these audiovisual classifiers.",
            "Ann, what's different here?",
            "Initially?",
            "As you can see, is that instead of having a single labeled set over over both your views, you have a different label set as the result of a potential view disagreement."
        ],
        [
            "So the way this works is as before we train an initial classifier in each view from our labeled set OK, and that gives us."
        ],
        [
            "Our initial classifier."
        ],
        [
            "And then with as in with Co training, we seek to improve these classifiers on the unlabeled data by."
        ],
        [
            "First evaluating."
        ],
        [
            "Each view and having it return it send most conf."
        ],
        [
            "Examples."
        ],
        [
            "But now the key difference is that when."
        ],
        [
            "When we map these labels, we check our few disagreement, measure to see whether or not in fact the redundant or or there's view disagreement, and if they're redundant, we map the label."
        ],
        [
            "Otherwise, we don't."
        ],
        [
            "And then somewhere before we repeat this iteration of of evaluation and training, it's a lot of labeled all the data or reach a set number of iterations."
        ],
        [
            "So now if we return to that toy example we saw before with normally distributed classes, we saw that for greater than 50% Co training proteins diverge compared to supervised baseline.",
            "Now, if you see our approach, what we get if you're doing this detection and filtering, we actually get performance across the board where we're able to.",
            "Get an accurate classifier in each view."
        ],
        [
            "So next I'd like to show you some experiments on real data.",
            "So here we consider the problem of user agreement recognition from head, gesture and speech.",
            "And for this problem we had a set of subjects interacting with an avatar.",
            "15 subjects answering a set of yes, no questions, using nods and shakes in the visual modality and saying yes or no in the audio modality.",
            "And for this data set, we simulated the disagreements by randomly replacing segments using using background in the visual domain and randomly replacing segments with Babble noise."
        ],
        [
            "Audio.",
            "So this data set is a temporal data set, so for each, for each response we have a temporal sequence of observations, and for our experiments we initially convert these these temporal observations in the single frame observations for which the details I'll just point you to the paper in interest of time.",
            "And also we were learning a naive Bayes classifier in each view for audio and video.",
            "And in our experiments, we randomly separated subjects into 10, train in five tests an we show results averaged over 5 splits of the data."
        ],
        [
            "So in our first experiment we look at Crossview bootstrapping, where our goal here is to learn a visual classifier from audio labels and what I show I'd like to 1st focus your attention here on the on the left and what I show is for increasing view disagreement.",
            "I show conventional Crossview bootstrapping where I'm not doing this detection filtering.",
            "I show Oracle performance.",
            "If I were to use the classifier trained on the ground truth labels on the unlabeled data, and I show the performance of our approach in blue and what we can see is that for greater than about 10 or 20% conventional Crossview learning, this is pretty poorly in the presence of a few disagreements where our approach is robust.",
            "To view disagreement to 50%, which is pretty good.",
            "An above that it also.",
            "It also performs poorly, but once again it's also it's doing fairly well up to 50% compared to baseline performance.",
            "And what I show here on the right is receiver operator curves redundant foreground and background detection.",
            "And we can see that our algorithm is doing for this data set is doing fairly good job at detecting."
        ],
        [
            "Disagreement.",
            "So for the last experiment we looked at code training, where we learn both in audiovisual classifier in the presence of disagreement so.",
            "What I'm showing here now is the performance of the auto classifier individual classifier for increasing amount of disagreements before what I'm showing in this green line is supervised performance.",
            "The performance obtained by a training classifier just on the labeled data.",
            "And I'm also showing here the Oracle performance in each view and essentially what we can see in this data set is that it's kind of imbalanced and that the visual classifier here is is in fact the stronger one.",
            "But what's kind of important to note is that compared to conventional code training, our approach is able to learn an accurate classifier in each of you.",
            "Even though without having apriori knowledge of which classifier is stronger, right?",
            "So conventional code training here we can see in the auto audio modality, also individual modality has increased the view disagreement, so the performance diverges the supervised performance, whereas our approach is able to able to still successfully learn accurate classifiers even up to 70% of disagreement."
        ],
        [
            "So in conclusion, we investigated the problem of disagreement in multiview learning, which is a fairly important problem I think for learning with datasets that have noisy observations.",
            "In particular, we kind of took a first step and towards this problem and proposing an information theoretic measure for detecting samples of view disagreement caused by view corruption.",
            "On the task of user agreement recognition, we show that our method was robust to fairly gross amounts of disagreement.",
            "It kind of some future work in an open directions is looking at more general view disagreement distribution, so here were particular to audiovisual datasets.",
            "But what about thinking about other kinds of datasets and scenarios is also what we're interested in, and also and also look into integrating view disagreement, predicament certainty.",
            "So training instead of doing this detection, filtering and using a more continuous measure.",
            "Thank you for your attention.",
            "So question.",
            "Coach training thoroughly make the assumption that spreads.",
            "You have independent given the labels over 'cause.",
            "If that's sufficient to prove their theorem.",
            "I. I wonder when people from other assumptions I wonder is there we have some sort of conjecture?",
            "We ran, one might be able to prove about the yeah, so I haven't done really a theoretical analysis here.",
            "Yeah, this is more an empirical study.",
            "But yeah, I mean that's something that I like to look at as well as here.",
            "Kind of.",
            "The key thing is not less about the conditional independence.",
            "I guess it's more about just the view insufficiency.",
            "The fact that if you have a really corrupted observation, one view then essentially that sample now effectively belongs to a different class.",
            "Anan there kind of.",
            "The intuition here is you want to enforce agreement on the samples for which they are clean and belong to the same class and kind of not enforce agreement on the ones that are corrupted, but I haven't done a theoretical analysis on this problem.",
            "And I missed it.",
            "You have two classes for yes and no.",
            "Or was there three classes?",
            "Yes, no and no signal.",
            "Yeah, so it was yes.",
            "Knowing background it was three classes right England?",
            "Yep.",
            "Let's thank Mario."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "My name is Mario.",
                    "label": 0
                },
                {
                    "sent": "The topic of this talk in today's talk I'm going to introduce the problem of view disagreement in Multiview learning.",
                    "label": 1
                },
                {
                    "sent": "I'm going to present an information theoretic approach for coping with this problem, and I'm going to demonstrate its effectiveness.",
                    "label": 0
                },
                {
                    "sent": "An audiovisual speech and gesture recognition tasks.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the world is multi view, at least.",
                    "label": 1
                },
                {
                    "sent": "I like to believe there are several problems in multi learning for some datasets are.",
                    "label": 1
                },
                {
                    "sent": "Naturally split into different views or feature sets.",
                    "label": 0
                },
                {
                    "sent": "For example, in conversational data sets, people use both speech and gesture in datasets involving document classification, you have the classic example of the text on the page and the text on the hyperlinks pointing to the page.",
                    "label": 0
                },
                {
                    "sent": "And you also have the images within the document.",
                    "label": 0
                },
                {
                    "sent": "So a key property for these kind of datasets is that each view provides a potentially redundant indication of the underlying class of interest.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An multi view learning techniques exploit these potentially redundant views to learn from partially labeled data and they have been shown to be advantageous to learning with only a single view.",
                    "label": 0
                },
                {
                    "sent": "Kind of especially in the case where the weaknesses of 1 view compliment districts strengths of the other kind of loosely speaking.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the challenge of multiple learning, however, is trying to deal with noisy observations or view insufficiency.",
                    "label": 1
                },
                {
                    "sent": "So there have been a fair amount of approaches in the multi learning literature that in fact try and gauge the global amount of noise in each of you and essentially down weight the views for which the noise which that are insufficient and kind of focus on the views that are that are sufficient.",
                    "label": 0
                },
                {
                    "sent": "So this gets us part of the way there, but in real.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The kind of datasets that we face look more like this.",
                    "label": 0
                },
                {
                    "sent": "We're essentially, the noise is not only purview, but it's actually also per sample.",
                    "label": 0
                },
                {
                    "sent": "So the question is, you know, how can we deal with these kinds of datasets?",
                    "label": 0
                },
                {
                    "sent": "In particular, kind of the most problematic samples are the ones that are really highly corrupted and.",
                    "label": 0
                },
                {
                    "sent": "These samples you can see as belonging to a neutral or background class that essentially Co occur with other samples of interest.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this view corruption problem can be seen as a source of view disagreement, where essentially the samples in each view potentially belong to a different class.",
                    "label": 1
                },
                {
                    "sent": "In this talk, we're particularly interested in audio visual problems and in these kind of problems you disagreement is caused by, for example, unimodal expression for.",
                    "label": 0
                },
                {
                    "sent": "So if a person is expressing agreement, they can say yes without head nodding or head nod without saying yes.",
                    "label": 0
                },
                {
                    "sent": "It could also be called by temporal, temporary view occlusions, so person can leave the field of view of the camera that can be included.",
                    "label": 0
                },
                {
                    "sent": "Someone can speak over the person and also in general just just general noise through the environment or or the sensor.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this talk we consider view disagreement caused by view corruption, and in particular we propose to detect and filter samples with few disagreement using an information theoretic measure based on a conditional view entropy.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So some related work.",
                    "label": 0
                },
                {
                    "sent": "Well, view disagreement can be seen as a new type of view insufficiency.",
                    "label": 1
                },
                {
                    "sent": "So there's been a fair amount of work in multiview learning for dealing with the viewing for dealing with the insufficiency assumption, for example, has been working for regularization, where you explicitly optimized for the agreement between classifiers.",
                    "label": 0
                },
                {
                    "sent": "When learning the classifiers, there's also been workin view validation, as these are the methods that I pointed to earlier, where essentially you down with the views that are noisier, insufficient, and focus on the sufficient ones.",
                    "label": 1
                },
                {
                    "sent": "And there's also been work and would like to call multiview manifold learning where essentially.",
                    "label": 0
                },
                {
                    "sent": "You form a consensus between the views when learning a low dimensional representation of your feature space.",
                    "label": 0
                },
                {
                    "sent": "So kind of the key property here of all these approaches, although they've come a fairway of dealing with view insufficiency in its traditional sense, they still assume that for all samples, the samples across views come from the same class.",
                    "label": 0
                },
                {
                    "sent": "And as we saw in the case of you corruption, that's not necessarily the case and is what we deal with in this talk.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before getting into the details of our approach, I just want to talk a little bit about the specific multiview learning algorithms we consider in this work.",
                    "label": 0
                },
                {
                    "sent": "In particular, we deal with multiview bootstrapping algorithms such as code training and special case of coaching, which we call Crossview bootstrapping.",
                    "label": 1
                },
                {
                    "sent": "So right now I'm going to take a moment to talk about each of these interns, starting with the latter approach.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So across the bootstrapping, essentially the idea here is that you want to learn a classifier in one view from a classifier in the other, and this kind of approach can be beneficial if either A you have labeled data in one view but not the other, or or if you know apriori that the the classifier one view is more well suited to your data than the classifier and others, you can get more reliable labels in some sense from that from that classifier, and the way it works is kind of straightforward so.",
                    "label": 1
                },
                {
                    "sent": "What you have is this unlabeled audiovisual data here that you like to learn this visual classifier from.",
                    "label": 0
                },
                {
                    "sent": "So here each box is an audio sample or a visual sample and you have a set of labels in the middle.",
                    "label": 0
                },
                {
                    "sent": "And the way this way.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Works is you evaluate your classifier on this data and it returns.",
                    "label": 0
                },
                {
                    "sent": "It's a set of labels for which it's confident on that it is doing a good job.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we simply train the classifier using those labels.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, the more general instantiation.",
                    "label": 0
                },
                {
                    "sent": "This approach is code training, where essentially here we learn a set of classifiers iteratively by bootstrapping them on partially labeled data.",
                    "label": 1
                },
                {
                    "sent": "The assumptions of code training, our class conditional independence, which I won't talk too much about here, and also the sufficiency assumptions we've been talking about a bit.",
                    "label": 0
                },
                {
                    "sent": "It's received quite amount of success.",
                    "label": 0
                },
                {
                    "sent": "It's been applied to a variety of areas, including text classification, visual object detection, information retrieval.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just kind of another high level schematic of how that algorithm works.",
                    "label": 0
                },
                {
                    "sent": "So here again we like to learn these audio visual classifiers from this partially labeled data.",
                    "label": 0
                },
                {
                    "sent": "And the way we proceed is we.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We first learn the classifier, get initial classifier in each view from the initial labeled set.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we seek to improve these classifiers on the unlabeled data by first of all.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Waiting is classified.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And having it return it's most common.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then it then re training the classifiers and iterating this procedure of training test.",
                    "label": 0
                },
                {
                    "sent": "So we either labeled all the data which is set number of iterations.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now kind of returning.",
                    "label": 0
                },
                {
                    "sent": "Returning to the problem of view disagreement consider.",
                    "label": 1
                },
                {
                    "sent": "This this toy example of two views are two dimensional data consisting of three normally distributed classes.",
                    "label": 1
                },
                {
                    "sent": "So we have class one Class 2 and background.",
                    "label": 0
                },
                {
                    "sent": "So in the typical Co training scenario, what we have is.",
                    "label": 0
                },
                {
                    "sent": "We have samples for which the the corresponding sample in each view belongs to the same class.",
                    "label": 0
                },
                {
                    "sent": "So here we've done.",
                    "label": 0
                },
                {
                    "sent": "Foreground class sample were done in background.",
                    "label": 0
                },
                {
                    "sent": "So the samples that cause problem, however those with you disagreement right?",
                    "label": 0
                },
                {
                    "sent": "So here we have the sample belonging to Class 2 in V1, but the corresponding sample in view 2 is corrupted and now belongs to background right?",
                    "label": 0
                },
                {
                    "sent": "So we like to be able to still learn in these scenarios, essentially taking advantage of the samples for which for which they have the same class in each view and not Co training on the sample of the disagreement.",
                    "label": 0
                },
                {
                    "sent": "So to kind of show that conventional code training has has difficulty with these kind of datasets, we performed an experiment using this kind of this toy example with varying amounts of view disagreement.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is what we got.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing here is the performance of the classifier learned in V1 and V2 with varying amounts of you disagreement.",
                    "label": 0
                },
                {
                    "sent": "Increasing view disagreements in the X axis and correct classification rate in the Y.",
                    "label": 0
                },
                {
                    "sent": "And what I show in red, the red line here is supervised performance that we achieved by from the classifier trained on the unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "And what I show in black is the performance of Co training as we increase the amount of disagreement.",
                    "label": 0
                },
                {
                    "sent": "And here I'm showing average performance averaged over.",
                    "label": 0
                },
                {
                    "sent": "Random splits of the data and suddenly will train and label set.",
                    "label": 0
                },
                {
                    "sent": "And essentially what we see here.",
                    "label": 0
                },
                {
                    "sent": "Surprisingly, code training is able to handle up to 40% view disagreements.",
                    "label": 0
                },
                {
                    "sent": "But then for higher amounts 50% above as we expect, it does quite poorly.",
                    "label": 0
                },
                {
                    "sent": "And what's important to note here is that in audiovisual datasets that we see, it is typical that will have you disagreement levels above 50%.",
                    "label": 0
                },
                {
                    "sent": "So in fact we do want to be able to perform well in these in this range.",
                    "label": 0
                },
                {
                    "sent": "So now let's see how we can do better by detecting if you disagree.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so with our approach, the key assumption is so, given N foreground classes in the background class, the key assumption is that the foreground classes can Co occur with either themselves or background and the background class can Co occur with itself or any other class.",
                    "label": 0
                },
                {
                    "sent": "And this seems like a reasonable assumption for a lot of problems, but it's a particularly reasonable assumption for 40 visual problems which we care about in this work.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to kind of give you some intuition behind behind our approach.",
                    "label": 0
                },
                {
                    "sent": "Once again, consider this.",
                    "label": 0
                },
                {
                    "sent": "This notion of example.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing here is the joint space for two for two view problem X One X2, and what's shown in diagonal or samples which we have agreement samples that belong to the same class which only off diagonal or samples of you disagreements, samples that Co occur with background.",
                    "label": 0
                },
                {
                    "sent": "So now consider this scenario conditioning on a foreground sample in V1.",
                    "label": 1
                },
                {
                    "sent": "So we see if we get a conditional distribution with two modes.",
                    "label": 0
                },
                {
                    "sent": "Similarly, if we condition on the background sample in view 2.",
                    "label": 0
                },
                {
                    "sent": "This results in a conditional distribution with three modes and essentially what this kind of intuition gives us.",
                    "label": 0
                },
                {
                    "sent": "So here we are only showing it for kind of 3 two classes in background.",
                    "label": 0
                },
                {
                    "sent": "But in general, as we as we increase the number of classes which will see the trend that if we if we condition on foreground we kind of get a distribution with with low entropy while conditioning on background we get a distribution with kind of high entropy and this kind of seen by the fact that when conditioning on background you get a distribution that is more uniform in some sense.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So using that intuition, we derive if we use the following conditional entropy measure.",
                    "label": 1
                },
                {
                    "sent": "So here let XK via multi sample with views.",
                    "label": 0
                },
                {
                    "sent": "What we do is we define an indicator function M overview pairs.",
                    "label": 1
                },
                {
                    "sent": "Of these samples, where essentially the indicator function returns one if the conditional entropy conditioning on sample K&J is less than some threshold.",
                    "label": 0
                },
                {
                    "sent": "Where here we use the mean entropy as a threshold and returns 0 otherwise, and also hear the conditional entropy, we could be computed empirically over the unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "And here we use a probability estimate using kernel density estimator, but other methods are also applicable.",
                    "label": 0
                },
                {
                    "sent": "So it's important to take away from this slide is essentially that because you can see here the indicator function, the text foreground samples right?",
                    "label": 0
                },
                {
                    "sent": "So essentially, if the condition conditioning on a foreground sample gives us a low entropy, then it returns one is foreground, otherwise return zeros background.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So using this measure we can.",
                    "label": 0
                },
                {
                    "sent": "We can detect whether or not a sample XC is redundant, foreground to background.",
                    "label": 1
                },
                {
                    "sent": "In particular, if for all views are all view pairs of a sample XKR indicator function returns one, then we know it's the redundant foreground sample.",
                    "label": 1
                },
                {
                    "sent": "Similarly, for any of you pair are indicator function doesn't return one.",
                    "label": 1
                },
                {
                    "sent": "Then we know is there going to background sample.",
                    "label": 0
                },
                {
                    "sent": "So here we've defined measures that function over the entire.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sample we can also define a measure overview pairs for view disagreement, in particular for two views I&J of a multisample XC.",
                    "label": 1
                },
                {
                    "sent": "We know that these user in view disagreement if their indicator functions disagree, so one indicator function says foreground are the ones is background.",
                    "label": 0
                },
                {
                    "sent": "Then we know that it's you disagreement and this kind of captured by this logic.",
                    "label": 0
                },
                {
                    "sent": "Bookstore operator here.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we like to do is using this measure define a modified Co training algorithm that detects and filter samples with you disagreement and is able to learn from these kind of datasets.",
                    "label": 0
                },
                {
                    "sent": "So as before, we have a partial label data set for she want to learn these audiovisual classifiers.",
                    "label": 0
                },
                {
                    "sent": "Ann, what's different here?",
                    "label": 0
                },
                {
                    "sent": "Initially?",
                    "label": 0
                },
                {
                    "sent": "As you can see, is that instead of having a single labeled set over over both your views, you have a different label set as the result of a potential view disagreement.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way this works is as before we train an initial classifier in each view from our labeled set OK, and that gives us.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our initial classifier.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then with as in with Co training, we seek to improve these classifiers on the unlabeled data by.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First evaluating.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each view and having it return it send most conf.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now the key difference is that when.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we map these labels, we check our few disagreement, measure to see whether or not in fact the redundant or or there's view disagreement, and if they're redundant, we map the label.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Otherwise, we don't.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then somewhere before we repeat this iteration of of evaluation and training, it's a lot of labeled all the data or reach a set number of iterations.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now if we return to that toy example we saw before with normally distributed classes, we saw that for greater than 50% Co training proteins diverge compared to supervised baseline.",
                    "label": 0
                },
                {
                    "sent": "Now, if you see our approach, what we get if you're doing this detection and filtering, we actually get performance across the board where we're able to.",
                    "label": 0
                },
                {
                    "sent": "Get an accurate classifier in each view.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So next I'd like to show you some experiments on real data.",
                    "label": 0
                },
                {
                    "sent": "So here we consider the problem of user agreement recognition from head, gesture and speech.",
                    "label": 1
                },
                {
                    "sent": "And for this problem we had a set of subjects interacting with an avatar.",
                    "label": 1
                },
                {
                    "sent": "15 subjects answering a set of yes, no questions, using nods and shakes in the visual modality and saying yes or no in the audio modality.",
                    "label": 0
                },
                {
                    "sent": "And for this data set, we simulated the disagreements by randomly replacing segments using using background in the visual domain and randomly replacing segments with Babble noise.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Audio.",
                    "label": 0
                },
                {
                    "sent": "So this data set is a temporal data set, so for each, for each response we have a temporal sequence of observations, and for our experiments we initially convert these these temporal observations in the single frame observations for which the details I'll just point you to the paper in interest of time.",
                    "label": 0
                },
                {
                    "sent": "And also we were learning a naive Bayes classifier in each view for audio and video.",
                    "label": 1
                },
                {
                    "sent": "And in our experiments, we randomly separated subjects into 10, train in five tests an we show results averaged over 5 splits of the data.",
                    "label": 1
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in our first experiment we look at Crossview bootstrapping, where our goal here is to learn a visual classifier from audio labels and what I show I'd like to 1st focus your attention here on the on the left and what I show is for increasing view disagreement.",
                    "label": 1
                },
                {
                    "sent": "I show conventional Crossview bootstrapping where I'm not doing this detection filtering.",
                    "label": 0
                },
                {
                    "sent": "I show Oracle performance.",
                    "label": 0
                },
                {
                    "sent": "If I were to use the classifier trained on the ground truth labels on the unlabeled data, and I show the performance of our approach in blue and what we can see is that for greater than about 10 or 20% conventional Crossview learning, this is pretty poorly in the presence of a few disagreements where our approach is robust.",
                    "label": 0
                },
                {
                    "sent": "To view disagreement to 50%, which is pretty good.",
                    "label": 0
                },
                {
                    "sent": "An above that it also.",
                    "label": 0
                },
                {
                    "sent": "It also performs poorly, but once again it's also it's doing fairly well up to 50% compared to baseline performance.",
                    "label": 0
                },
                {
                    "sent": "And what I show here on the right is receiver operator curves redundant foreground and background detection.",
                    "label": 0
                },
                {
                    "sent": "And we can see that our algorithm is doing for this data set is doing fairly good job at detecting.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Disagreement.",
                    "label": 0
                },
                {
                    "sent": "So for the last experiment we looked at code training, where we learn both in audiovisual classifier in the presence of disagreement so.",
                    "label": 1
                },
                {
                    "sent": "What I'm showing here now is the performance of the auto classifier individual classifier for increasing amount of disagreements before what I'm showing in this green line is supervised performance.",
                    "label": 0
                },
                {
                    "sent": "The performance obtained by a training classifier just on the labeled data.",
                    "label": 0
                },
                {
                    "sent": "And I'm also showing here the Oracle performance in each view and essentially what we can see in this data set is that it's kind of imbalanced and that the visual classifier here is is in fact the stronger one.",
                    "label": 0
                },
                {
                    "sent": "But what's kind of important to note is that compared to conventional code training, our approach is able to learn an accurate classifier in each of you.",
                    "label": 0
                },
                {
                    "sent": "Even though without having apriori knowledge of which classifier is stronger, right?",
                    "label": 0
                },
                {
                    "sent": "So conventional code training here we can see in the auto audio modality, also individual modality has increased the view disagreement, so the performance diverges the supervised performance, whereas our approach is able to able to still successfully learn accurate classifiers even up to 70% of disagreement.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we investigated the problem of disagreement in multiview learning, which is a fairly important problem I think for learning with datasets that have noisy observations.",
                    "label": 1
                },
                {
                    "sent": "In particular, we kind of took a first step and towards this problem and proposing an information theoretic measure for detecting samples of view disagreement caused by view corruption.",
                    "label": 0
                },
                {
                    "sent": "On the task of user agreement recognition, we show that our method was robust to fairly gross amounts of disagreement.",
                    "label": 1
                },
                {
                    "sent": "It kind of some future work in an open directions is looking at more general view disagreement distribution, so here were particular to audiovisual datasets.",
                    "label": 0
                },
                {
                    "sent": "But what about thinking about other kinds of datasets and scenarios is also what we're interested in, and also and also look into integrating view disagreement, predicament certainty.",
                    "label": 0
                },
                {
                    "sent": "So training instead of doing this detection, filtering and using a more continuous measure.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "So question.",
                    "label": 0
                },
                {
                    "sent": "Coach training thoroughly make the assumption that spreads.",
                    "label": 0
                },
                {
                    "sent": "You have independent given the labels over 'cause.",
                    "label": 0
                },
                {
                    "sent": "If that's sufficient to prove their theorem.",
                    "label": 0
                },
                {
                    "sent": "I. I wonder when people from other assumptions I wonder is there we have some sort of conjecture?",
                    "label": 0
                },
                {
                    "sent": "We ran, one might be able to prove about the yeah, so I haven't done really a theoretical analysis here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is more an empirical study.",
                    "label": 0
                },
                {
                    "sent": "But yeah, I mean that's something that I like to look at as well as here.",
                    "label": 0
                },
                {
                    "sent": "Kind of.",
                    "label": 0
                },
                {
                    "sent": "The key thing is not less about the conditional independence.",
                    "label": 0
                },
                {
                    "sent": "I guess it's more about just the view insufficiency.",
                    "label": 0
                },
                {
                    "sent": "The fact that if you have a really corrupted observation, one view then essentially that sample now effectively belongs to a different class.",
                    "label": 0
                },
                {
                    "sent": "Anan there kind of.",
                    "label": 0
                },
                {
                    "sent": "The intuition here is you want to enforce agreement on the samples for which they are clean and belong to the same class and kind of not enforce agreement on the ones that are corrupted, but I haven't done a theoretical analysis on this problem.",
                    "label": 0
                },
                {
                    "sent": "And I missed it.",
                    "label": 0
                },
                {
                    "sent": "You have two classes for yes and no.",
                    "label": 0
                },
                {
                    "sent": "Or was there three classes?",
                    "label": 0
                },
                {
                    "sent": "Yes, no and no signal.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it was yes.",
                    "label": 0
                },
                {
                    "sent": "Knowing background it was three classes right England?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Let's thank Mario.",
                    "label": 0
                }
            ]
        }
    }
}