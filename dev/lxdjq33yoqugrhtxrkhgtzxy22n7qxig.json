{
    "id": "lxdjq33yoqugrhtxrkhgtzxy22n7qxig",
    "title": "Efficient Weight Learning for Markov Logic Networks",
    "info": {
        "author": [
            "Daniel Lowd, Dept. of Computer Science & Engineering, University of Washington"
        ],
        "published": "Jan. 29, 2008",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/ecml07_lowd_ewl/",
    "segmentation": [
        [
            "Welcome to this session of Markov models.",
            "We have more exciting posts.",
            "The first one is going to be presented by God alone.",
            "It's joint work with federal mingles and it's about efficient way of writing for Michael Logic memory.",
            "So I'm going to start with."
        ],
        [
            "Brief outline of my talk.",
            "I'm going to start by giving you some background about Markov random.",
            "Excuse me, Markov logic networks and why we care about them, and then I'm going to talk about the algorithms that we adapt for learning them quickly and show you some exciting spiritism experiments on real."
        ],
        [
            "World datasets.",
            "So Markov logic networks are part of statistical relational learning.",
            "So the goal here is we want to somehow unify probability and logic.",
            "So probability handles uncertainty very well, and 1st order logic allows us to capture these complex relationships, and ideally we want to do both.",
            "So the way Markov logic networks handle this is with a weighted set of 1st order formulas.",
            "Or you can think of a knowledge base in first order logic and to each of the formulas you simply attach a weight.",
            "This gives you a probability distribution as follows, so over all of the set of ground atoms the joint probability is simply the normalized exponentiated weighted sum of formula counts.",
            "So when the formula is true, more times that tells you that the world is more likely than a similar world with the formula being true fewer times and the weights tell you the relative importance of those formulas.",
            "There are already been many applications of Markov logic networks to such problems as link prediction, entity resolution, information extraction and more, and I'm going to start by just showing you."
        ],
        [
            "A simple example of a Markov logic network and why you'd want to use it.",
            "So consider the web domain so you're doing collective classification of web pages and a few statements that you might find helpful.",
            "Logical statements might find helpful in this is.",
            "Suppose you you're trying to use the words and the links on the page to classify them into different categories.",
            "You might say that a course web page is more likely to have the word homework on it and you might say that a student web page is unlikely to have the word sabbatical.",
            "And in order to capture some relational information between these pages, you might say that student pages are likely to link to professor pages of graduate students linked to their advisor.",
            "Now clearly these rules will not be true all of the time, and if you were trying to try to make a hard knowledge base with all of these constraints, it would break very quickly.",
            "But Markov logic allows you to do is attach a weight to each of these, representing its relative strength.",
            "Now would take a very long time to list all of the possibly useful rules by hand, so we have some syntax."
        ],
        [
            "Sugar that helps us here.",
            "I'm going to create an instance of each of these rules with each possible word in my domain and each possible class so.",
            "For my particular domain, this actually ends up with about 10,000 rules, and that means we have 10,000 waits to learn, and this is not an unusual circumstance where we have this many weights to learn simultaneously, and this is the."
        ],
        [
            "The problem I'm looking at.",
            "So we're trying to do discriminative weight learning by discriminative weight learning.",
            "I mean that some of the atoms are given as evidence, and some of them are query and we wish to know the query items given the evidence.",
            "And this is a convex optimization problem which is really nice because when we find an optimum, it's guaranteed to be global optimum, not just a local optimum.",
            "The problem is that the existing methods for weight learning can be prohibitively slow.",
            "And I'll show you that.",
            "So the natural solution that you would want to use is second order optimization methods that can get beyond the simple gradient descent.",
            "But the problem is that for Markov logic networks, linesearch and function evaluations, which most of these second order methods assume are easy, are actually intractable.",
            "So I will show you how we modify these algorithms and come up with new algorithms."
        ],
        [
            "That work in this domain, and because you're all getting impatient for a graph?",
            "Here's a sneak preview of some of the results we get, so I haven't really labeled this.",
            "This is the web data set we're looking at area under the precision recall curve, but we have a before kervinen after curve before curve is the baseline.",
            "This was the standard algorithm before and in theory it should converge to the global optimum because we have a convex optimization problem.",
            "But what we see is that it's really not converging there at all because of all these weights to learn, some of them aren't getting anywhere close to convergence.",
            "So if you were to estimate how long would it take that curve to get up to the optimum?",
            "Years I don't know very long time.",
            "And after we apply these new methods, we get the after curve and I won't tell you what algorithm that is.",
            "You can guess during the talk.",
            "But this doesn't prove."
        ],
        [
            "This does work OK."
        ],
        [
            "So now the algorithms.",
            "Starting with simple gradient descent, you just move in the direction of steepest descent, scaled by learning rate."
        ],
        [
            "Basic.",
            "In Markov logic networks, the gradient is the of the conditional log.",
            "Likelihood is just the number of true.",
            "Formula counts minus the expected number of formula counts according to the model.",
            "And the true counts are easy to compute, but the expected counts, it turns out, are intractable to compute, at least to compute exactly.",
            "So, the standard solution to this, and the only algorithm there's ever been applied to this problem before, is the voter perception algorithm.",
            "So this was introduced by Collins in 2002 for hidden Markov models, and was applied to Markov logic networks by singling Domingo's in 2005, and the idea is because you cannot compute that expectation exactly.",
            "You approximating made it using the MAP state, most likely state of all the atoms, and you can't actually compute the empty state either, so you run the Max walks out algorithm and approximate that.",
            "A different solution is the contrastive divergent, so the basic idea here is we're going to run Markov chain Monte Carlo sampling, but we don't actually have time to run to full convergence in every single iteration, so instead we just get a few samples and this tells us enough to pick a good direction for the gradient and figure out what direction we need to move our weights in.",
            "Even though we're not running to full convergence.",
            "And we use the MC SAT algorithm for this, which gives us less correlated samples than Gibbs sampling and is able to jump between modes very easily."
        ],
        [
            "So one of the problems you find when you apply a gradient descent method to Markov logic networks is that some clauses or formulas have vastly more grounding than others.",
            "So consider the case we have a social network application and you have 100 people.",
            "This smokes X implies cancer.",
            "X smoking causes cancer.",
            "Would have 100 groundings, one for each person, whereas this transitivity here that says that friends of friends or friends that would have 100 ^3 groundings, or a million groundings.",
            "And since the gradient recall is proportional to the difference between true and expected counts, you're going to get much bigger differences with the second clause than with the 1st.",
            "So the grading can be many, many orders of magnitude larger in some dimensions than others, and this leads to huge problems because there's no learning rate that works for all clauses.",
            "Any learning rate that would prevent divergance on some clauses will make it so the other clauses never converge, and that's what we were seeing earlier with that line that just didn't converge.",
            "So it's not practical to tune the learning rate by hand in every single dimension.",
            "So what we do instead is we have this simple heuristic.",
            "We divide by the number of true clause groundings, and so this affectively rescales everything so that the gradient is approximately the same magnitude in most directions.",
            "And hopefully makes our problem better."
        ],
        [
            "That problem that I just described is actually an instance of ill conditioning, which is well known and well studied in function optimization.",
            "The basic idea is that when you have a very skewed surface that you're trying to do gradient descent on, you can get these horrible, horrible zig zags, and even though you're taking some optimum step along the direction in every single iteration, you can still zigzag like this and can take a long time to converge.",
            "There's a way of quantifying this using the Hessian matrix, and if you look at the eigenvalues, those tell you roughly you can think of them as the relative scale of the different dimensions of this ellipsoid, and if you have one.",
            "Dimension much longer than another.",
            "Then you can have this."
        ],
        [
            "Problem.",
            "So the Hessian matrix is the matrix of all the second derivatives, and in our case it's the second derivatives of the conditional log likelihood and for a Markov logic network this just works out to be the negative covariance matrix of clause counts.",
            "So with sampling with just the empty set algorithm, we can actually compute what the Hessian matrix should be or approximated.",
            "So the diagonal entries are just the clause variances and the off diagonal entries show the correlations among the clauses.",
            "And you can also think about this as showing the curvature of the error function.",
            "So instead of just looking at the gradient, which tells you which way is down or which way is up, you're looking at the change in the gradient in all directions, and this is very useful information to have to take advantage of so that you can converge much more quickly.",
            "And this is the basis of all the 2nd order methods that I'm going to show you."
        ],
        [
            "So.",
            "Newton's method applies the Hessian matrix directly by inverting it, multiplying by the gradient, and if we had a quadratic function, then this would actually get us there in a single step.",
            "Um?",
            "Now we don't have a quadratic function, but Even so it might help us make very good progress in every single step.",
            "The problem is that this requires inverting the Hessian matrix, and if you have 10,000 weights then let's see your Hessian matrix would have 100 million entries, and inverting it is not very practical.",
            "So instead."
        ],
        [
            "We apply a diagonalized version of this method, so if all of our clauses were entirely uncorrelated, then the off diagonal entries would be 0 and we could just ignore them, and inverting would be easy.",
            "Only look at the diagonal entries, so let's pretend that's the case, and even though this is an approximation, it will still hopefully allow us to make good progress and get closer and closer to the optimum.",
            "And I haven't told you how to determine the exact step length you want, but I'll get to that in a little bit."
        ],
        [
            "So a different approach is also been well studied.",
            "Is the conjugate gradient algorithm, and this combats the ill conditioning problem by including the previous search direction in the new search direction, so it avoids zigzagging problem.",
            "And if you have a quadratic function is not going to get there in one step, but it should get there in 10 steps.",
            "If you have an end dimensional problem.",
            "And that's assuming it's quadratic, but it depends heavily online searches, so it's going to be going along each search direction trying to find the optimum along that direction before it picks a new direction and line searches are very problematic for us because we cannot efficiently compute the function value.",
            "Even approximating it is hard, so line searches are a bad idea.",
            "What we can do?"
        ],
        [
            "Instead.",
            "Is scaled conjugate gradient which replaces that linesearch with using the Hessian matrix to figure out a good step length to take now.",
            "We still can't store the entire Hessian matrix in memory, or at least we don't want to, so I'll tell you how we get around that."
        ],
        [
            "Shortly.",
            "So the way scale conjugate gradient chooses a step length instead of the.",
            "Line search, it computes the optimal quadratic step length.",
            "So if our function was actually quadratic, this would be the exact step length you would want, which is just a function of the gradient.",
            "The search direction D and the Hessian matrix, and.",
            "So you can compute that, but that may not be very good because your function isn't necessarily quadratic, so you limit the step size to some trust region where the quadratic approximation is likely to be good, or at least good enough, because if you if you limit your step size small enough, then the quadratic approximation will get better and better and better.",
            "But don't be taking smaller and smaller steps.",
            "So how do you choose the size of the trust region?",
            "Well, you updated with each iteration, so after you take a step, you check to see well, what do I predict my function value to be and what is my actual function value?",
            "And if they closely lineup, you grow the trust region and say, OK, I can take larger steps now.",
            "And if it's bad then you take smaller steps.",
            "You shrink the trust region so this is dynamically updated with every step so that you can automatically adjust the size of the steps you're taking.",
            "So there's two problems with this.",
            "First, that would alluded to before.",
            "You don't really want to store the Hessian matrix in memory an what we have to get around that is, it turns out that simply from the samples you can compute this.",
            "Product, it's just the difference of these two expectations, and you can compute those directly from the samples and from the vector.",
            "So that turns out to not be a problem with memory.",
            "We can do that efficiently.",
            "And the other thing we have is to get the actual change in the function.",
            "Since I've already told you that function evaluations are extremely expensive, this isn't something that we can do.",
            "But it turns out that we can have a lower bound on the actual function change.",
            "But simply by looking at the current gradient and the previous step that we took, and we this works because the function is convex and we're going towards the optimum.",
            "So although we can't compute the actual change, we have a lower bound on it, and so we're still able to adjust the trust region appropriately.",
            "One more detail."
        ],
        [
            "To talk about with skilled conjugate gradient is the importance of preconditioning.",
            "So the initial direction that scaled conjugate gradient takes is in the direction of the gradient, and that's actually not a very good direction to choose, because as I showed you with condition problems, that's horrible so well known fixes preconditioning where you multiply by a matrix to hopefully lower the condition number of your problem, and so you try to do your problem in a much easier space.",
            "And the standard standard preconditioner to use is the inverse diagonal Hessian.",
            "One way you can think about the scale conjugate gradient with the preconditioner is you can think about it as combining the best of diagonal Newton.",
            "An scaled conjugate gradient 'cause it's sort of using both algorithms together."
        ],
        [
            "K."
        ],
        [
            "On to some experiments.",
            "So just to refresh your memory from like 5 seconds ago, these are all the algorithms that we're going to consider along with the abbreviations I'm going to use.",
            "So we have voted Perceptron with and without per word learning rate per weight.",
            "Learning rates contrastive divergent's without probate learning rates, diagonal Newton and we have scaled conjugate gradient both with and without the preconditioner and the only algorithm that's ever really been applied to Emma Lens before is voted Perceptron.",
            "All of the others are new in this paper."
        ],
        [
            "So the datasets we're looking at our core and web KB for core of the task is to deep duplicate citations to computer science papers and the MLN we use has over 6000 weights.",
            "And this is very similar to the MLN used by singling Domingo's only when they tried it because they only had the voter suppression algorithm, they were only able to learn about a dozen weights, all of the other weights they had to set with the heuristic because they simply couldn't learn all of these together, and we're going to do just that, learn all the weights together.",
            "And we have over 3 million ground clauses and the condition number is over 600,000.",
            "So even though 1000 citations may not seem that hard, this is still a significant and challenging problem.",
            "When you use all of these interesting relational dependencies as we're doing here.",
            "For the web task we have about 4000 web pages and we're trying to predict predict their categories, and here we have almost 11,000 weights, but we have fewer ground clauses when we're actually learning and we have a condition number that's two orders of magnitude lower, so this is still a challenging problem that is very ill conditioned, but we expect it to be much easier than Cora, relatively speaking."
        ],
        [
            "So we tuned.",
            "We are learning rates on held out data.",
            "We I should mention.",
            "We also have a Gaussian prior on each way to control overfitting we trained all of these algorithms for 10 hours and we evaluate on test data using two metrics area under the precision recall curve and average conditional log likelihood of all the query."
        ],
        [
            "Tickets so here's our baseline algorithm on Cora, and note that time is on a log rhythmic scale here."
        ],
        [
            "And if you make that simple change of adding the per weight learning rates, then you get a huge gain.",
            "An area and AUC.",
            "So this tells us that the till conditioning was really really hurting voted Perceptron and making that simple change buys us a whole lot and it's so easy."
        ],
        [
            "With contrastive divergent.",
            "We see similar behavior with the probate learning rates.",
            "It makes all the difference without it doesn't do very well.",
            "Overall, contrastive divergent seems to do a little bit better."
        ],
        [
            "Inverted perceptron.",
            "And now for the 2nd order methods, so I'm going to start at the bottom.",
            "That orange line is scaled conjugate gradient.",
            "As I said, it's initial direction is the direction of the gradient, and that's not a very good direction, so it stays stuck down there, with voter perceptron contrastive divergent's.",
            "Meanwhile, Diagonal Newton and PSG dominate, and they have the highest AUC on this data set that we know of."
        ],
        [
            "For conditional log likelihood."
        ],
        [
            "Adding those per weight learning rates doesn't actually fix voter perceptron because it has problems with probability estimation is using the MVP state to estimate things, and this doesn't give you good calibration which CLL."
        ],
        [
            "Cares about you, contrasted.",
            "Divergent does better when you have them."
        ],
        [
            "Learning rates and again dagnan PCG clearly dominate.",
            "We actually have a little bit of overfitting, in fact, which wasn't possible before because we were."
        ],
        [
            "Underfitting so badly for web KB.",
            "We see something different before the probate learning rates helped voter perceptron or certainly didn't hurt it, but here they actually work against us because they.",
            "Downward clauses that should actually have large weights, and so they cripple the learning instead of helping it.",
            "And so this shows you that this heuristic is not always helpful."
        ],
        [
            "And we see similar behavior for contrastive divergent's.",
            "That blue line is without the per weight learning rates and it does better than when you have the per weight learning rates.",
            "So this tells us that we really do need second order methods to figure out why."
        ],
        [
            "To do.",
            "And here we have the 2nd order methods.",
            "Back on doing skills, gradient an with a preconditioner and PCG does the best of the three."
        ],
        [
            "And briefly, here's conditional log likelihood.",
            "It's a similar ordering, slightly different shape.",
            "It's about what you would expect."
        ],
        [
            "So to conclude, ill conditioning is a real problem in statistical relational learning and an interesting and important one to solve.",
            "PSG and DN are an effective solution to this problem.",
            "We see that they officially converge to good models.",
            "There's no learning rate to tune which is an added bonus.",
            "They automatically figure out their own step sizes and their orders and orders of magnitude faster than voted Perceptron.",
            "So voted perceptron.",
            "If you actually set a low enough learning rate to converge to the true model, then over the optimal weights then you would be running for.",
            "I don't even want to speculate how long years maybe.",
            "But we're actually able to reasonably efficiently converge in hours with these better algorithms.",
            "So there's a few remaining details we'd like to detect convergence so that we can stop when we get there, rather than continuing to run, and we'd like to prevent overfitting something overfitting you saw in a couple of those cases, we'd like to figure out exactly how much approximate inference is hurting us, because we're just doing this with sampling, we might get stuck, or the noise might be a problem.",
            "It seems like we'd be able to be able to make it work this much, but in what cases would approximate inference really hurt us?",
            "And can we prevent that?",
            "And you can?",
            "Try out all of this in alchemy.",
            "It's already integrated into the latest release of Alchemy, which is just sort of toolkit for Markov logic networks, and you can download it from that URL.",
            "Any questions?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome to this session of Markov models.",
                    "label": 0
                },
                {
                    "sent": "We have more exciting posts.",
                    "label": 0
                },
                {
                    "sent": "The first one is going to be presented by God alone.",
                    "label": 0
                },
                {
                    "sent": "It's joint work with federal mingles and it's about efficient way of writing for Michael Logic memory.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to start with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Brief outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "I'm going to start by giving you some background about Markov random.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, Markov logic networks and why we care about them, and then I'm going to talk about the algorithms that we adapt for learning them quickly and show you some exciting spiritism experiments on real.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "World datasets.",
                    "label": 0
                },
                {
                    "sent": "So Markov logic networks are part of statistical relational learning.",
                    "label": 1
                },
                {
                    "sent": "So the goal here is we want to somehow unify probability and logic.",
                    "label": 0
                },
                {
                    "sent": "So probability handles uncertainty very well, and 1st order logic allows us to capture these complex relationships, and ideally we want to do both.",
                    "label": 1
                },
                {
                    "sent": "So the way Markov logic networks handle this is with a weighted set of 1st order formulas.",
                    "label": 0
                },
                {
                    "sent": "Or you can think of a knowledge base in first order logic and to each of the formulas you simply attach a weight.",
                    "label": 0
                },
                {
                    "sent": "This gives you a probability distribution as follows, so over all of the set of ground atoms the joint probability is simply the normalized exponentiated weighted sum of formula counts.",
                    "label": 0
                },
                {
                    "sent": "So when the formula is true, more times that tells you that the world is more likely than a similar world with the formula being true fewer times and the weights tell you the relative importance of those formulas.",
                    "label": 0
                },
                {
                    "sent": "There are already been many applications of Markov logic networks to such problems as link prediction, entity resolution, information extraction and more, and I'm going to start by just showing you.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A simple example of a Markov logic network and why you'd want to use it.",
                    "label": 0
                },
                {
                    "sent": "So consider the web domain so you're doing collective classification of web pages and a few statements that you might find helpful.",
                    "label": 1
                },
                {
                    "sent": "Logical statements might find helpful in this is.",
                    "label": 0
                },
                {
                    "sent": "Suppose you you're trying to use the words and the links on the page to classify them into different categories.",
                    "label": 0
                },
                {
                    "sent": "You might say that a course web page is more likely to have the word homework on it and you might say that a student web page is unlikely to have the word sabbatical.",
                    "label": 0
                },
                {
                    "sent": "And in order to capture some relational information between these pages, you might say that student pages are likely to link to professor pages of graduate students linked to their advisor.",
                    "label": 0
                },
                {
                    "sent": "Now clearly these rules will not be true all of the time, and if you were trying to try to make a hard knowledge base with all of these constraints, it would break very quickly.",
                    "label": 0
                },
                {
                    "sent": "But Markov logic allows you to do is attach a weight to each of these, representing its relative strength.",
                    "label": 0
                },
                {
                    "sent": "Now would take a very long time to list all of the possibly useful rules by hand, so we have some syntax.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sugar that helps us here.",
                    "label": 0
                },
                {
                    "sent": "I'm going to create an instance of each of these rules with each possible word in my domain and each possible class so.",
                    "label": 0
                },
                {
                    "sent": "For my particular domain, this actually ends up with about 10,000 rules, and that means we have 10,000 waits to learn, and this is not an unusual circumstance where we have this many weights to learn simultaneously, and this is the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem I'm looking at.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to do discriminative weight learning by discriminative weight learning.",
                    "label": 0
                },
                {
                    "sent": "I mean that some of the atoms are given as evidence, and some of them are query and we wish to know the query items given the evidence.",
                    "label": 0
                },
                {
                    "sent": "And this is a convex optimization problem which is really nice because when we find an optimum, it's guaranteed to be global optimum, not just a local optimum.",
                    "label": 1
                },
                {
                    "sent": "The problem is that the existing methods for weight learning can be prohibitively slow.",
                    "label": 1
                },
                {
                    "sent": "And I'll show you that.",
                    "label": 0
                },
                {
                    "sent": "So the natural solution that you would want to use is second order optimization methods that can get beyond the simple gradient descent.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that for Markov logic networks, linesearch and function evaluations, which most of these second order methods assume are easy, are actually intractable.",
                    "label": 0
                },
                {
                    "sent": "So I will show you how we modify these algorithms and come up with new algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That work in this domain, and because you're all getting impatient for a graph?",
                    "label": 0
                },
                {
                    "sent": "Here's a sneak preview of some of the results we get, so I haven't really labeled this.",
                    "label": 1
                },
                {
                    "sent": "This is the web data set we're looking at area under the precision recall curve, but we have a before kervinen after curve before curve is the baseline.",
                    "label": 0
                },
                {
                    "sent": "This was the standard algorithm before and in theory it should converge to the global optimum because we have a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "But what we see is that it's really not converging there at all because of all these weights to learn, some of them aren't getting anywhere close to convergence.",
                    "label": 0
                },
                {
                    "sent": "So if you were to estimate how long would it take that curve to get up to the optimum?",
                    "label": 0
                },
                {
                    "sent": "Years I don't know very long time.",
                    "label": 0
                },
                {
                    "sent": "And after we apply these new methods, we get the after curve and I won't tell you what algorithm that is.",
                    "label": 0
                },
                {
                    "sent": "You can guess during the talk.",
                    "label": 0
                },
                {
                    "sent": "But this doesn't prove.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This does work OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the algorithms.",
                    "label": 0
                },
                {
                    "sent": "Starting with simple gradient descent, you just move in the direction of steepest descent, scaled by learning rate.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basic.",
                    "label": 0
                },
                {
                    "sent": "In Markov logic networks, the gradient is the of the conditional log.",
                    "label": 1
                },
                {
                    "sent": "Likelihood is just the number of true.",
                    "label": 0
                },
                {
                    "sent": "Formula counts minus the expected number of formula counts according to the model.",
                    "label": 0
                },
                {
                    "sent": "And the true counts are easy to compute, but the expected counts, it turns out, are intractable to compute, at least to compute exactly.",
                    "label": 0
                },
                {
                    "sent": "So, the standard solution to this, and the only algorithm there's ever been applied to this problem before, is the voter perception algorithm.",
                    "label": 1
                },
                {
                    "sent": "So this was introduced by Collins in 2002 for hidden Markov models, and was applied to Markov logic networks by singling Domingo's in 2005, and the idea is because you cannot compute that expectation exactly.",
                    "label": 0
                },
                {
                    "sent": "You approximating made it using the MAP state, most likely state of all the atoms, and you can't actually compute the empty state either, so you run the Max walks out algorithm and approximate that.",
                    "label": 0
                },
                {
                    "sent": "A different solution is the contrastive divergent, so the basic idea here is we're going to run Markov chain Monte Carlo sampling, but we don't actually have time to run to full convergence in every single iteration, so instead we just get a few samples and this tells us enough to pick a good direction for the gradient and figure out what direction we need to move our weights in.",
                    "label": 0
                },
                {
                    "sent": "Even though we're not running to full convergence.",
                    "label": 0
                },
                {
                    "sent": "And we use the MC SAT algorithm for this, which gives us less correlated samples than Gibbs sampling and is able to jump between modes very easily.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the problems you find when you apply a gradient descent method to Markov logic networks is that some clauses or formulas have vastly more grounding than others.",
                    "label": 1
                },
                {
                    "sent": "So consider the case we have a social network application and you have 100 people.",
                    "label": 0
                },
                {
                    "sent": "This smokes X implies cancer.",
                    "label": 0
                },
                {
                    "sent": "X smoking causes cancer.",
                    "label": 0
                },
                {
                    "sent": "Would have 100 groundings, one for each person, whereas this transitivity here that says that friends of friends or friends that would have 100 ^3 groundings, or a million groundings.",
                    "label": 0
                },
                {
                    "sent": "And since the gradient recall is proportional to the difference between true and expected counts, you're going to get much bigger differences with the second clause than with the 1st.",
                    "label": 0
                },
                {
                    "sent": "So the grading can be many, many orders of magnitude larger in some dimensions than others, and this leads to huge problems because there's no learning rate that works for all clauses.",
                    "label": 0
                },
                {
                    "sent": "Any learning rate that would prevent divergance on some clauses will make it so the other clauses never converge, and that's what we were seeing earlier with that line that just didn't converge.",
                    "label": 1
                },
                {
                    "sent": "So it's not practical to tune the learning rate by hand in every single dimension.",
                    "label": 1
                },
                {
                    "sent": "So what we do instead is we have this simple heuristic.",
                    "label": 0
                },
                {
                    "sent": "We divide by the number of true clause groundings, and so this affectively rescales everything so that the gradient is approximately the same magnitude in most directions.",
                    "label": 0
                },
                {
                    "sent": "And hopefully makes our problem better.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That problem that I just described is actually an instance of ill conditioning, which is well known and well studied in function optimization.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that when you have a very skewed surface that you're trying to do gradient descent on, you can get these horrible, horrible zig zags, and even though you're taking some optimum step along the direction in every single iteration, you can still zigzag like this and can take a long time to converge.",
                    "label": 0
                },
                {
                    "sent": "There's a way of quantifying this using the Hessian matrix, and if you look at the eigenvalues, those tell you roughly you can think of them as the relative scale of the different dimensions of this ellipsoid, and if you have one.",
                    "label": 0
                },
                {
                    "sent": "Dimension much longer than another.",
                    "label": 0
                },
                {
                    "sent": "Then you can have this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "So the Hessian matrix is the matrix of all the second derivatives, and in our case it's the second derivatives of the conditional log likelihood and for a Markov logic network this just works out to be the negative covariance matrix of clause counts.",
                    "label": 1
                },
                {
                    "sent": "So with sampling with just the empty set algorithm, we can actually compute what the Hessian matrix should be or approximated.",
                    "label": 0
                },
                {
                    "sent": "So the diagonal entries are just the clause variances and the off diagonal entries show the correlations among the clauses.",
                    "label": 0
                },
                {
                    "sent": "And you can also think about this as showing the curvature of the error function.",
                    "label": 0
                },
                {
                    "sent": "So instead of just looking at the gradient, which tells you which way is down or which way is up, you're looking at the change in the gradient in all directions, and this is very useful information to have to take advantage of so that you can converge much more quickly.",
                    "label": 0
                },
                {
                    "sent": "And this is the basis of all the 2nd order methods that I'm going to show you.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Newton's method applies the Hessian matrix directly by inverting it, multiplying by the gradient, and if we had a quadratic function, then this would actually get us there in a single step.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now we don't have a quadratic function, but Even so it might help us make very good progress in every single step.",
                    "label": 0
                },
                {
                    "sent": "The problem is that this requires inverting the Hessian matrix, and if you have 10,000 weights then let's see your Hessian matrix would have 100 million entries, and inverting it is not very practical.",
                    "label": 1
                },
                {
                    "sent": "So instead.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We apply a diagonalized version of this method, so if all of our clauses were entirely uncorrelated, then the off diagonal entries would be 0 and we could just ignore them, and inverting would be easy.",
                    "label": 0
                },
                {
                    "sent": "Only look at the diagonal entries, so let's pretend that's the case, and even though this is an approximation, it will still hopefully allow us to make good progress and get closer and closer to the optimum.",
                    "label": 0
                },
                {
                    "sent": "And I haven't told you how to determine the exact step length you want, but I'll get to that in a little bit.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a different approach is also been well studied.",
                    "label": 0
                },
                {
                    "sent": "Is the conjugate gradient algorithm, and this combats the ill conditioning problem by including the previous search direction in the new search direction, so it avoids zigzagging problem.",
                    "label": 1
                },
                {
                    "sent": "And if you have a quadratic function is not going to get there in one step, but it should get there in 10 steps.",
                    "label": 0
                },
                {
                    "sent": "If you have an end dimensional problem.",
                    "label": 0
                },
                {
                    "sent": "And that's assuming it's quadratic, but it depends heavily online searches, so it's going to be going along each search direction trying to find the optimum along that direction before it picks a new direction and line searches are very problematic for us because we cannot efficiently compute the function value.",
                    "label": 1
                },
                {
                    "sent": "Even approximating it is hard, so line searches are a bad idea.",
                    "label": 0
                },
                {
                    "sent": "What we can do?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instead.",
                    "label": 0
                },
                {
                    "sent": "Is scaled conjugate gradient which replaces that linesearch with using the Hessian matrix to figure out a good step length to take now.",
                    "label": 0
                },
                {
                    "sent": "We still can't store the entire Hessian matrix in memory, or at least we don't want to, so I'll tell you how we get around that.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shortly.",
                    "label": 0
                },
                {
                    "sent": "So the way scale conjugate gradient chooses a step length instead of the.",
                    "label": 0
                },
                {
                    "sent": "Line search, it computes the optimal quadratic step length.",
                    "label": 1
                },
                {
                    "sent": "So if our function was actually quadratic, this would be the exact step length you would want, which is just a function of the gradient.",
                    "label": 0
                },
                {
                    "sent": "The search direction D and the Hessian matrix, and.",
                    "label": 1
                },
                {
                    "sent": "So you can compute that, but that may not be very good because your function isn't necessarily quadratic, so you limit the step size to some trust region where the quadratic approximation is likely to be good, or at least good enough, because if you if you limit your step size small enough, then the quadratic approximation will get better and better and better.",
                    "label": 0
                },
                {
                    "sent": "But don't be taking smaller and smaller steps.",
                    "label": 1
                },
                {
                    "sent": "So how do you choose the size of the trust region?",
                    "label": 0
                },
                {
                    "sent": "Well, you updated with each iteration, so after you take a step, you check to see well, what do I predict my function value to be and what is my actual function value?",
                    "label": 0
                },
                {
                    "sent": "And if they closely lineup, you grow the trust region and say, OK, I can take larger steps now.",
                    "label": 0
                },
                {
                    "sent": "And if it's bad then you take smaller steps.",
                    "label": 0
                },
                {
                    "sent": "You shrink the trust region so this is dynamically updated with every step so that you can automatically adjust the size of the steps you're taking.",
                    "label": 0
                },
                {
                    "sent": "So there's two problems with this.",
                    "label": 0
                },
                {
                    "sent": "First, that would alluded to before.",
                    "label": 0
                },
                {
                    "sent": "You don't really want to store the Hessian matrix in memory an what we have to get around that is, it turns out that simply from the samples you can compute this.",
                    "label": 0
                },
                {
                    "sent": "Product, it's just the difference of these two expectations, and you can compute those directly from the samples and from the vector.",
                    "label": 0
                },
                {
                    "sent": "So that turns out to not be a problem with memory.",
                    "label": 0
                },
                {
                    "sent": "We can do that efficiently.",
                    "label": 1
                },
                {
                    "sent": "And the other thing we have is to get the actual change in the function.",
                    "label": 0
                },
                {
                    "sent": "Since I've already told you that function evaluations are extremely expensive, this isn't something that we can do.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that we can have a lower bound on the actual function change.",
                    "label": 1
                },
                {
                    "sent": "But simply by looking at the current gradient and the previous step that we took, and we this works because the function is convex and we're going towards the optimum.",
                    "label": 0
                },
                {
                    "sent": "So although we can't compute the actual change, we have a lower bound on it, and so we're still able to adjust the trust region appropriately.",
                    "label": 0
                },
                {
                    "sent": "One more detail.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To talk about with skilled conjugate gradient is the importance of preconditioning.",
                    "label": 0
                },
                {
                    "sent": "So the initial direction that scaled conjugate gradient takes is in the direction of the gradient, and that's actually not a very good direction to choose, because as I showed you with condition problems, that's horrible so well known fixes preconditioning where you multiply by a matrix to hopefully lower the condition number of your problem, and so you try to do your problem in a much easier space.",
                    "label": 1
                },
                {
                    "sent": "And the standard standard preconditioner to use is the inverse diagonal Hessian.",
                    "label": 0
                },
                {
                    "sent": "One way you can think about the scale conjugate gradient with the preconditioner is you can think about it as combining the best of diagonal Newton.",
                    "label": 0
                },
                {
                    "sent": "An scaled conjugate gradient 'cause it's sort of using both algorithms together.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On to some experiments.",
                    "label": 0
                },
                {
                    "sent": "So just to refresh your memory from like 5 seconds ago, these are all the algorithms that we're going to consider along with the abbreviations I'm going to use.",
                    "label": 0
                },
                {
                    "sent": "So we have voted Perceptron with and without per word learning rate per weight.",
                    "label": 0
                },
                {
                    "sent": "Learning rates contrastive divergent's without probate learning rates, diagonal Newton and we have scaled conjugate gradient both with and without the preconditioner and the only algorithm that's ever really been applied to Emma Lens before is voted Perceptron.",
                    "label": 1
                },
                {
                    "sent": "All of the others are new in this paper.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the datasets we're looking at our core and web KB for core of the task is to deep duplicate citations to computer science papers and the MLN we use has over 6000 weights.",
                    "label": 0
                },
                {
                    "sent": "And this is very similar to the MLN used by singling Domingo's only when they tried it because they only had the voter suppression algorithm, they were only able to learn about a dozen weights, all of the other weights they had to set with the heuristic because they simply couldn't learn all of these together, and we're going to do just that, learn all the weights together.",
                    "label": 0
                },
                {
                    "sent": "And we have over 3 million ground clauses and the condition number is over 600,000.",
                    "label": 1
                },
                {
                    "sent": "So even though 1000 citations may not seem that hard, this is still a significant and challenging problem.",
                    "label": 0
                },
                {
                    "sent": "When you use all of these interesting relational dependencies as we're doing here.",
                    "label": 0
                },
                {
                    "sent": "For the web task we have about 4000 web pages and we're trying to predict predict their categories, and here we have almost 11,000 weights, but we have fewer ground clauses when we're actually learning and we have a condition number that's two orders of magnitude lower, so this is still a challenging problem that is very ill conditioned, but we expect it to be much easier than Cora, relatively speaking.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we tuned.",
                    "label": 0
                },
                {
                    "sent": "We are learning rates on held out data.",
                    "label": 0
                },
                {
                    "sent": "We I should mention.",
                    "label": 0
                },
                {
                    "sent": "We also have a Gaussian prior on each way to control overfitting we trained all of these algorithms for 10 hours and we evaluate on test data using two metrics area under the precision recall curve and average conditional log likelihood of all the query.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tickets so here's our baseline algorithm on Cora, and note that time is on a log rhythmic scale here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you make that simple change of adding the per weight learning rates, then you get a huge gain.",
                    "label": 0
                },
                {
                    "sent": "An area and AUC.",
                    "label": 0
                },
                {
                    "sent": "So this tells us that the till conditioning was really really hurting voted Perceptron and making that simple change buys us a whole lot and it's so easy.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With contrastive divergent.",
                    "label": 0
                },
                {
                    "sent": "We see similar behavior with the probate learning rates.",
                    "label": 0
                },
                {
                    "sent": "It makes all the difference without it doesn't do very well.",
                    "label": 0
                },
                {
                    "sent": "Overall, contrastive divergent seems to do a little bit better.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inverted perceptron.",
                    "label": 0
                },
                {
                    "sent": "And now for the 2nd order methods, so I'm going to start at the bottom.",
                    "label": 0
                },
                {
                    "sent": "That orange line is scaled conjugate gradient.",
                    "label": 0
                },
                {
                    "sent": "As I said, it's initial direction is the direction of the gradient, and that's not a very good direction, so it stays stuck down there, with voter perceptron contrastive divergent's.",
                    "label": 0
                },
                {
                    "sent": "Meanwhile, Diagonal Newton and PSG dominate, and they have the highest AUC on this data set that we know of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For conditional log likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding those per weight learning rates doesn't actually fix voter perceptron because it has problems with probability estimation is using the MVP state to estimate things, and this doesn't give you good calibration which CLL.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cares about you, contrasted.",
                    "label": 0
                },
                {
                    "sent": "Divergent does better when you have them.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learning rates and again dagnan PCG clearly dominate.",
                    "label": 0
                },
                {
                    "sent": "We actually have a little bit of overfitting, in fact, which wasn't possible before because we were.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Underfitting so badly for web KB.",
                    "label": 0
                },
                {
                    "sent": "We see something different before the probate learning rates helped voter perceptron or certainly didn't hurt it, but here they actually work against us because they.",
                    "label": 0
                },
                {
                    "sent": "Downward clauses that should actually have large weights, and so they cripple the learning instead of helping it.",
                    "label": 0
                },
                {
                    "sent": "And so this shows you that this heuristic is not always helpful.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we see similar behavior for contrastive divergent's.",
                    "label": 0
                },
                {
                    "sent": "That blue line is without the per weight learning rates and it does better than when you have the per weight learning rates.",
                    "label": 0
                },
                {
                    "sent": "So this tells us that we really do need second order methods to figure out why.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do.",
                    "label": 0
                },
                {
                    "sent": "And here we have the 2nd order methods.",
                    "label": 0
                },
                {
                    "sent": "Back on doing skills, gradient an with a preconditioner and PCG does the best of the three.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And briefly, here's conditional log likelihood.",
                    "label": 0
                },
                {
                    "sent": "It's a similar ordering, slightly different shape.",
                    "label": 0
                },
                {
                    "sent": "It's about what you would expect.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, ill conditioning is a real problem in statistical relational learning and an interesting and important one to solve.",
                    "label": 1
                },
                {
                    "sent": "PSG and DN are an effective solution to this problem.",
                    "label": 1
                },
                {
                    "sent": "We see that they officially converge to good models.",
                    "label": 0
                },
                {
                    "sent": "There's no learning rate to tune which is an added bonus.",
                    "label": 0
                },
                {
                    "sent": "They automatically figure out their own step sizes and their orders and orders of magnitude faster than voted Perceptron.",
                    "label": 0
                },
                {
                    "sent": "So voted perceptron.",
                    "label": 0
                },
                {
                    "sent": "If you actually set a low enough learning rate to converge to the true model, then over the optimal weights then you would be running for.",
                    "label": 0
                },
                {
                    "sent": "I don't even want to speculate how long years maybe.",
                    "label": 0
                },
                {
                    "sent": "But we're actually able to reasonably efficiently converge in hours with these better algorithms.",
                    "label": 0
                },
                {
                    "sent": "So there's a few remaining details we'd like to detect convergence so that we can stop when we get there, rather than continuing to run, and we'd like to prevent overfitting something overfitting you saw in a couple of those cases, we'd like to figure out exactly how much approximate inference is hurting us, because we're just doing this with sampling, we might get stuck, or the noise might be a problem.",
                    "label": 0
                },
                {
                    "sent": "It seems like we'd be able to be able to make it work this much, but in what cases would approximate inference really hurt us?",
                    "label": 0
                },
                {
                    "sent": "And can we prevent that?",
                    "label": 0
                },
                {
                    "sent": "And you can?",
                    "label": 0
                },
                {
                    "sent": "Try out all of this in alchemy.",
                    "label": 0
                },
                {
                    "sent": "It's already integrated into the latest release of Alchemy, which is just sort of toolkit for Markov logic networks, and you can download it from that URL.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                }
            ]
        }
    }
}