{
    "id": "xypspo2bijwfkkgwupepurp2mp3ldh64",
    "title": "Cognitive science for machine learning 3: Models and theories in cognitive science",
    "info": {
        "author": [
            "Tom Griffiths, Computational Cognitive Science Lab, Department of Psychology, UC Berkeley"
        ],
        "published": "June 15, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss2010_griffiths_csfml3/",
    "segmentation": [
        [
            "So I'm going to be giving 2 1/2 lectures and the titles that we have in the program are fairly approximate, so Nick and I are down to split electron models and theories in cognitive science, so I'm going to start off a little bit talking about general strategies for connecting cognitive science and machine learning, an approach that we can use for doing that, and then I'll talk mostly today about causality and then in the next 2 lectures I'm going to give our talk.",
            "About a little bit about nonparametric Bayesian methods that will be in the lecture that split with Josh and then on the last lecture I'll talk about Monte Carlo methods and how those can be used in both machine learning and in cognitive science.",
            "So the general theme of these lectures is going to be about ideas that kind of bridge cognitive science and machine learning in ways that we can develop strategies for, making sure that that's a productive relationship.",
            "So."
        ],
        [
            "I'm going to start off with his return to a point which has come up a few times in the lectures that you've seen, so this is the idea of different levels of analysis, so you might remember these different levels that you heard about.",
            "So David Myron talked about 3 levels at which we can analyze and information processing systems such as the human mind.",
            "We can analyze data computational level, asking what the goal of the computation is, way that goal is appropriate, and what the logic is of the strategy by which it can be carried out at the level of representation algorithm asking what's the representation for the input and output.",
            "And the algorithm for the transformation or at the level of implementation where we ask how the representation algorithm can be realized physically and these are different levels that really historically have tended to be explored by different kinds of disciplines.",
            "So implementation is something which neuroscience tends to explore, looking at how our brain performs computations.",
            "Representation algorithm is a traditional level for cognitive psychology.",
            "Basically, trying to figure out what the sorts of cognitive processes are that support the things that we do every day and the level of computation is 1, which historically.",
            "Maybe it's been neglected in the world the way that we go about thinking about how the mind works.",
            "It's a level of thinking about the abstract kinds of problems that people need to solve, and the solutions to those problems.",
            "And in fact, it's this level which I'm going to focus on which many of the talks that you seem to be focusing on, and I'm going to give you some arguments for why that might be a good idea.",
            "So this level."
        ],
        [
            "Is one that David Mar instead of proposing these these different levels of analysis that one of the main goals of his proposal was actually to identify the fact that there was this separate computational level and to argue that that was something that we should be investigating.",
            "So his argument with something like this?",
            "He says an algorithm is likely to be understood more readily by understanding the nature of the problem being solved and by examining the mechanism and the hardware in which it's embodied.",
            "In a similar vein, trying to understand perception by studying only neurons is like trying to understand bird flight by studying only feathers.",
            "It just cannot be done.",
            "In order to understand Bird flight, we have to understand aerodynamics only the end of the structure of fellows in the different shapes of birds wings makes sense, and so there's kind of an idea here that thinking about the function that's being served by a certain kind of process, and in this case thinking about the abstract problems that we're solving, is something that's going to give us insight into how that process works in a way which is fundamentally different from studying the mechanisms by which it's executed."
        ],
        [
            "So you could have some different questions.",
            "Sort of, you know, in recognizing that, maybe this is a good thing to do.",
            "So one question is, how do you actually go about doing a computational level analysis of some aspect of behavior?",
            "You know, we've sort of argue that this might be a good thing, but how would you actually do that?",
            "Another is what the equivalent is of aerodynamics for cognition.",
            "So what's the kind of set of principles that we might appeal to in order to explain these functional properties of human cognition?",
            "And the third, what the consequences of this kind of approach might be for understanding the mind?",
            "So I'm going to sort of briefly give some answers to these questions before."
        ],
        [
            "Going on so for this first question of how it is that you go about conducting a computational level analysis.",
            "Really, this wasn't something that was necessarily made clear by Mara, but it's something which has emerged in subsequent work which is advocated.",
            "An approach called rational analysis."
        ],
        [
            "This where the basic idea is that what you want to do is to 1st think about the underlying computational problem which is involved in some aspect of cognition.",
            "So if there's something that you want to understand about human cognition, the first step is to sit down and think about it and say, well, you know what's the data that people are getting.",
            "One of the hypothesis they might be evaluating what's a way of describing what the problem is that people are solving, and then having formulated that problem?",
            "The second thing to do is to find a good solution to that problem, and this is normally the point where you go off and read some machine learning books, and you read some things from statistics and so on.",
            "Because that's where you're going to find solutions to those kinds of problems where you know they're going to tell you.",
            "Well, you know, given this kind of problem, here's a good method for solving that problem, and then compare human cognition to that solution.",
            "So this is where we use these methods like Felix was talking about methods that come from psychology, which give us a way of evaluating whether the predictions that come out of these models are accurate, and then if they're not you, hopefully you know go back and start revising your theory and thinking about whether that's a good theory, whether you've got something wrong in the way that you characterize that problem, or whether this approach isn't necessarily going to work for that domain.",
            "So one thing that's important about this kind of strategy is that it's not just something which is likely to give us insight into human cognition, it's something which is going to directly relate cognition and computation.",
            "The fact that at that second step you have to, you know, go off and read some statistics and machine learning books is actually an important aspect of this strategy, because it's something which is going to give us connections between the way that we end up understanding human cognition.",
            "If we understand human cognition in terms of these optimal solutions to these underlying problems and the kinds of methods that are being used in engineering and computer science.",
            "To solve problems out in the world.",
            "So this is an interesting outcome of this, and I think that this is in some ways an even better argument than the argument that Mou is making for why this is a reasonable way to proceed.",
            "It's something which is going to give us a link between human and machine learning that's just a consequence of following this kind of strategy."
        ],
        [
            "So you know, in order to make this work, we have to sort of answer this question of what aerodynamics might be.",
            "So aerodynamics is the solution to the problem which is posed to birds.",
            "So what's the solution to the kind of problems that opposed to people?",
            "Well, for the sorts of problems that we've been talking about that are inductive problems where you have to go from observed data and evaluate underdetermined type."
        ],
        [
            "This is the answer is 1 which should be very familiar to you by now.",
            "Basically the idea is that the equivalent of aerodynamics for people is something like statistics.",
            "So if you want to understand what sort of structure you are allowed to infer from data, which is basically the problem that is posed to us whenever we're trying to make one of these inductive inferences, then that's exactly what statistics is about.",
            "Statistics is the science of telling you what you're justified in believing based on the data that you see, and in particular, you know the way that I'm going to frame things in the way that you will see at some of the other talks, frame things in terms of Bayesian inference.",
            "But I think the idea more generally is that statistics is going to give us a guide to understanding what solutions to these problems look like.",
            "So you've all seen Bayes rule by now.",
            "It's worth pointing out some interesting components of Bayes rule.",
            "One of these components is the fact that it gives us a way of, you know, I think this is something that came up in Neil's presentation.",
            "If you just look at Bayes rule in terms of way of talking about defining conditional probabilities, then it's not.",
            "Not controversial in any way.",
            "What makes it controversial and interesting is the idea that it's actually something which gives us a description of how people should go about learning.",
            "So you can think about Bayes rule is telling you how you should go from your current degrees of belief in something and revise them in light of the evidence you see to obtain new degrees of belief.",
            "And once valuable about that as it gives us a way of encoding what the expectations of a learner are and expressing those through this prior distribution over hypothesis and through the choice of the space of hypothesis that we're considering and those two things actually going to turn out to be important in terms of describing.",
            "Human learning and understanding.",
            "Some of the things about how people are so good at making, and, uh."
        ],
        [
            "Of inferences.",
            "So the last of my questions is what the consequences are of this kind of approach and there are a couple of interesting consequences of pursuing this kind."
        ],
        [
            "Of analysis.",
            "So the first is that what we get out of this is a direct set of connections between problems in computers are in cognitive science and problems in statistics.",
            "So one of the things that's come out of pursuing this approach over the last 10 to 20."
        ],
        [
            "Years is kind of a list where on one side you've got things that we're interested in understanding about human learning, and on the other side what you've got is things that we sort of know how to handle.",
            "Are interested in being able to solve using methods that come from machine learning or statistics, so you can kind of learn a way of translating between these two kinds of.",
            "Formalizations are different kinds of problems, but if you're interested in, say, understanding human categorisation, then maybe you should learn something about density estimation.",
            "If you're interested in graphene causal learning, then graphical models function learning is sort of like regression and so on.",
            "So for each of these different kinds of problems that we might be interested in cognitive science, there's a parallel literature in machine learning, and after a while you kind of get used to going to a poster instead of translating it.",
            "If you're in machine learning conference, you can translate it into what it is in cognitive science that that poster is going to help you understand, or if you go to a cognitive science poster, you can translate it into.",
            "What aspect of machine learning might be interesting for understanding the problem that people are solving?",
            "So the idea is that you know forming these kind."
        ],
        [
            "Connections first of all, gives us a way of taking ideas that come from machine learning and using them to inform our understanding of human learning.",
            "It gives us a set of tools that we can use for formalizing the problems that people need to solve and working out what the solutions those problems might be so that we can then go on and try and figure out whether people do something that looks like those solutions."
        ],
        [
            "Another thing that we get out of pursuing this strategy is a characterization of the inductive biases of human learners.",
            "So when people talk about machine learning algorithms having inductive biases, what those inductive biases are?",
            "Are any factor other than the data which leads you to to favor one hypothesis over another.",
            "So these kinds of inductive biases are something which are very important in making good inductive inferences.",
            "The whole sort of thing that makes induction hard is that the hypothesis you're evaluating or under determined by the data.",
            "So all you really have to go on is those inductive biases.",
            "The thing that's going to make 1 machine learning system a better machine learning system than another is that it's going to have inductive biases that better match the problem, and this is kind of a point that came up in some of the talks that you've seen already.",
            "So when you want to have a good hypothesis space, Anna good.",
            "Form of regularization for characterizing the solutions which you want to produce for any particular problem, and how well you solve a problem is going to depend on how good your inductive biases are.",
            "You can give a simple example of the importance of these kinds of inductive biases in here."
        ],
        [
            "I'm learning so if I was going to teach you a new word, so I'm going to show you, you can imagine you were traveling around in Sardinia and one of the natives pointed out something to you and then said this word pakora Does anybody who actually knows what this, who it is?",
            "Can you pronounce it properly for me?",
            "Thank you.",
            "OK, and then you are trying to learn a little bit of the native language so you are then sort of forming some hypothesis about what this word might mean.",
            "OK, so you think about the hypothesis that you entertain, so who's entertaining hypothesis?",
            "Something like sheep.",
            "White thing.",
            "Willie thing four legged thing.",
            "OK, things under 3 feet tall.",
            "Things that are sheep on a Saturday and a glass of milk on a Tuesday.",
            "Things that have less than eight legs.",
            "OK, so nobody was entertaining the last three hypothesis right?",
            "And you can kind of recognize that those last three hypotheses are in some ways less good hypothesis then the first hypothesis that I named.",
            "But each of those hypothesis is equally consistent with the data that you observed, right?",
            "Each of those hypothesis logically matches the information that you saw and you know the the fact that this is the object that was labeled.",
            "Is you know it's equally consistent with each of those different hypothesis.",
            "The only thing that makes you favor one hypothesis over another is the inductive biases that you have and those inductive biases tell you certain kinds of things are likely to be labeled by words, and the words that we use.",
            "We have expectations about how it is that they map onto things like objects in the world.",
            "You can ask a native speaker what this word actually means.",
            "If you're still curious.",
            "OK, so these kind of inductive biases are part of what makes human learners so good at learning.",
            "So if we want to make machine learning systems that are good at solving the kinds of problems that people are good at solving, then what we need to do is figure out something like human inductive biases.",
            "So this is kind of my argument for why people who are interested in machine learning should become cognitive scientists.",
            "You know, if we sort of take these arguments, then that Bernard's been making about, you know.",
            "The importance of having you know the right hypothesis space in the right sort of regularization, or the sort of more general idea that you should have inductive biases that match the problems that you're solving.",
            "If your goal is to make systems that can solve the kinds of problems that people are good at solving, then you could go out and keep making your machine learning algorithms that have different kinds of inductive biases, and then you know, keep comparing them and do some evaluation and cross validation and so on, and try and workout how well they fit their their data and all of these different kinds of things.",
            "Really what you're doing by doing that is exploring that space of inductive biases until you find something that solves the problem well.",
            "Could go off and study a system that you know solves that problem well.",
            "Workout.",
            "What is inductive?",
            "Biases are and then figure out a way of translating that into a machine learning algorithm, right?",
            "So if you're interested in making working machine learning systems, maybe one of the strategies that you could use for doing that is looking at human learning systems and seeing what we can figure out about those inductive biases that make humans so good and then translate them over to machine learning systems."
        ],
        [
            "So what's valuable about this kind of statistical framework is that it gives us a very transparent way of characterizing the inductive biases of learners.",
            "So if we're trying to model human inferences in terms of something like Bayesian statistics, then in looking at the prior probability distributions that we need to identify in order to produce Bayesian models that make predictions which are similar to human behavior, then what we're doing is essentially exploring the space of inductive biases trying to find inductive biases that match those of human learners, and so this is a.",
            "You know one of the attractive things about this framework is that it gives us a very clear way of talking about those inductive biases being expressed through things like prior probabilities, and more generally, the space of hypothesis that you select."
        ],
        [
            "So the last thing that we might hope to get out of this kind of computational analysis is some understanding of where it is that these inductive biases come from.",
            "So, having identified what those inductive biases are by using this kind of strategy, that sets us up with the opportunity to try and figure out where it is that they come from.",
            "And I'm going to talk a little more about that in one of the examples that I go through today and give you some sort of ideas that you might be able to generalize, but other cases, but the basic idea is that.",
            "If we can figure out, you know if these are things which say people learn from the environment around them, then we can go on and build machine learning systems that in the same way can learn appropriate inductive biases for solving the problems we want.",
            "Those machine learning systems to solve.",
            "So."
        ],
        [
            "Again, part of the reason why this is interesting is because all of these sorts of things over here on the left hand side tend to be things that people are pretty good at, and that we're still trying to make better machine learning systems for solving these problems.",
            "So to the extent that we can understand how it is that people do these things, then we can improve the algorithms that we have for working with these different kinds of formalisms as a way of improving the performance of those machine learning systems."
        ],
        [
            "So this is really an opportunity for us to sort of close the loop and take something from human learning.",
            "Something about what the inductive biases of people are and where those come from and use it to inform machine learning.",
            "So what I'm going to do today is illustrate this."
        ],
        [
            "Have argument by picking one of the things on this list.",
            "Causal learning and then talking about how it is that we can get insights into human causal learning from machine learning, and then how it is that we can get insights about what might make better machine learning systems from studying human causal learning.",
            "So you've already heard a little bit about causal learning and some of the challenges that it poses.",
            "One of the things that I think are most interesting about causal learning is that.",
            "If you think about our intuitive ability to evaluate causal relationships, this is really all that we had for doing science before the development of statistics.",
            "So you know, statistics has only really been something which is worked for, say, the last 100, maybe 200 years, right?",
            "That's the you know the only.",
            "Between which people have actually had formal statistical methods for evaluating the amount of evidence that their observations provide for the particular hypothesis that they're interested in.",
            "But if you think about it, science has been going on for much longer than that.",
            "So before the development of formal statistical methods.",
            "The way that scientists had to figure out if there was a causal relationship between two things and the way that we in our everyday lives have to figure out whether there's a causal relationship between two things.",
            "We're just relying on their intuitions about what their data told them.",
            "So you can actually go back and find some interesting examples where people are making essentially statistical arguments that rely on these."
        ],
        [
            "Kinds of intuitions, so here's one example.",
            "This is from a report that was published in 1798, which was about whether taking people who had fevers and then giving sort of treating them, covering their body and cold water, or putting them in cold baths was actually something that was an effective remedy.",
            "So Curry, who is a ship's doctor, describes what happened.",
            "So he says the contagion spread rapidly and before its progress could be arrested, 16 persons were affected, of which two died.",
            "Of these 16, eight were under my care.",
            "On this occasion I used for the first time the Fusion of cold water in the manner described by doctor Right.",
            "It was first trade in two cases that employed in five other cases it was repeated daily, and of these seven patients, the whole recovered.",
            "OK, So what he's doing here?",
            "This is his argument for why this might be."
        ],
        [
            "Good method is really giving you all of the information that you need to construct a contingency table that we now could apply our statistical methods to to figure out whether there is a causal relationship.",
            "His question is whether the treatment causes recovery and his data.",
            "He had seven people who were treated, all of whom recovered, and there were nine people who weren't treated, two of whom died right?",
            "So the question is, for the reader of one of his papers.",
            "Is this something which suggests that there might be an interesting underlying causal relationship?",
            "So this is."
        ],
        [
            "Problem with psychologist have studied the way that they do.",
            "This is by basically using exactly the same kind of task.",
            "They would take contingency table with some numbers here represented by ABC and D Give that contingency table to somebody and then ask them does see cozy or something like to what extent does see Causey and ask him to give it rating on a scale from zero to 100 of the extent to which they believe that there's a causal relationship between those two things and psychologists are interested in understanding what the mapping is from these kinds of contingency data.",
            "To our intuitive sense of whether there's a causal relationship, so they develop lots of different theory."
        ],
        [
            "So how this works?",
            "Two of the most prominent theories are something called Delta P, which is that the way that you should evaluate a causal relationship is by just thinking about the impact of the cores on the probability of the effect.",
            "So what you do is take the difference between the probability effect in the presence of the cores and the probability effect in the absence of the course.",
            "So this is the change in probability that's a result of the cause being present.",
            "And then another theory which is called the PowerPC theory, where the idea is that Delta P seems like a reasonable way of measuring the magnitude of a causal relationship, but it doesn't necessarily reflect the fact that the base rate of the of the effect occurring should be relevant.",
            "So the idea is that as the probability of the effect in the absence of the cores increases, there's less dynamic range for the cause to express itself.",
            "So a small difference in Delta P could actually be quite meaningful.",
            "If there's already a relatively high probability of the effect occurring, whereas it's less likely it's less and less meaningful when the probability effect in the absence of the causes lower, because it basically means that a smaller proportion of people have been changed in the extent to which they express the effect as a consequence.",
            "So it just normalizes Delta P by the amount of dynamic range in which this causal relationship could express itself, so you can."
        ],
        [
            "Take both of these kinds of measures and apply them to our contingency table from Doctor Curry so you know here probably effect in the presence of the causes.",
            "One probably effects in the absence of the causes.",
            ".78 if we think about recovery as our effect, so Delta P is .22 and then causal power whips, is is 1.",
            "So what's going on here?",
            "Is it saying that all of the people who would have died, so Delta P is just saying what's the change in the probability causal power is saying of the proportion of people who would have died?",
            "How many of them recover?",
            "And the answer here is that you know 100% of the people who hypothetically would have died had they not been treated, recovered when they were treated.",
            "So perhaps this is a strong causal relationship under Delta P. It might not seem like a very strong relationship, but these are proposed as measures of what's going on inside your head when you're evaluating a causal relationship, the way that."
        ],
        [
            "Are assessed is by comparing them with human data.",
            "So here's some human data.",
            "These are results of a study from Buner and Chang in 1997.",
            "What they did was present people with contingency tables in which the probability effect in the presence in the absence of the cause was varied in increments of .25 over the entire range of possible contingency is consistent with the generative causal relationship.",
            "So one in which the cause increases the probability of the effect.",
            "So here, here are people's ratings on that scale from zero to 100.",
            "Of what extent?",
            "It seems like the cause produces the effect, and here are the predictions of Delta P and causal power for these different contingencies.",
            "So if you look at these data, you can already see some interesting things going on.",
            "These data were collected with the intent of demonstrating that Delta P."
        ],
        [
            "Is a bad model, and in fact you can see Delta P is a bad model right?",
            "So here for these contingencies were Delta P is constant.",
            "It's .25 across here people's judgments very Delta P says that they should be the same.",
            "Causal power predicts that they vary, but it actually turns out that these data are also."
        ],
        [
            "And with causal power.",
            "So for example, here is a range where causal powers always one, so the cause always results in the effect occurring.",
            "And so here cause apparent constant.",
            "But you can see peoples judgments of the causal relationship also very so there's a sense in which these data are consistent with neither of these."
        ],
        [
            "Polls and in fact there are even this sort of effect over here where both of the models make the same prediction and people do something which is completely different.",
            "And what's interesting about this is that these guys basically dismissed this as a kind of irrational effect because what's going on is that Delta P is 0.",
            "There's no difference in the probability effect in the presence in the absence of the cores, but peoples judgments of weather of the causal relationship are varying.",
            "So here when even though there's no difference in contingency, you see variation in peoples judgments.",
            "They think that this is an irrational effect.",
            "It's something that's inconsistent with both of these models, so this is kind of the state of the art in psychology in terms of evaluating how it is that people might assess course role."
        ],
        [
            "Russian ships, but what we can do now is go to machine learning and statistics and see what machine learning statistics has to say about this kind of problem.",
            "So you've already heard about graphical models this morning."
        ],
        [
            "We're going to use a variant on graphical models, causal graphical models which give you a way of representing and reasoning about causal relationships."
        ],
        [
            "So a causal graphical model has a set of variables.",
            "Here we might think about variables being, say, a background cause which is always present and as a potential influence on the effect and the cause which is manipulated in the experiment that I was talking about where the question is whether this course is actually something which influences the effect.",
            "So we represent these variables as nodes in a graph as in."
        ],
        [
            "Graphical model we have some causal structure which reflects the relationships that we believe to exist among these very."
        ],
        [
            "Labels and then we have conditional probabilities that are associated with each variable given its parents in the graph, in exactly the same way that we normally do with a graphical model.",
            "Idea is that what this is going to do is give us a probability distribution over these variables.",
            "The way that a normal graphical model works.",
            "It gives us the distribution over these variables for observations.",
            "So basically it tells us what the joint distribution of these variables is going to be, and we can use that joint distribution.",
            "We can sort of use the structure here to reason about that joint distribution across a graphical model to Excel.",
            "Little tweak on the semantics of graphical models, and it says think about these links is not just reflecting statistical dependency but reflecting a causal relationship and what it means that they reflect a causal relationship.",
            "Is that if you reach into this causal structure and you intervene on one of the variables, so you fix that variable to a particular value, then that breaks all of the incoming links to that variable, and so that's a little twist on the semantics of a graphical model.",
            "It's not something that I'm going to use here, and the rest of the things I'm going to talk about, but it's the thing that makes it a causal graphical model.",
            "The idea is that it's something which you could use to reason about the states of those variables, not just when you're observing them.",
            "When they're giving you correlations, but when you actually reach in and intervene on those variables as well.",
            "So having sort of set this up, we can now see perhaps how we could use this kind of framework to ask some questions about human causal learning.",
            "The first thing that we need to do, we can say these are the variables that are relevant to these kinds of inference tasks that I've been talking about, and the kinds of structures that were interested in structures where we're asking whether you know what's going on with this.",
            "This link between cause and effect.",
            "The one thing that we need to do before we can go any further.",
            "Specify what we think the conditional probabilities are that are relevant to this causal."
        ],
        [
            "And So what I'm going to do is use a particular parameterisation of this graphical model, which is called the noisy or parameterisation.",
            "And what this says is that we associate each of these links with a strength and the way that we calculate the probability of the effect is we basically add up the.",
            "The the the strengths of these relationships as if they were each having an independent opportunity to produce the effect, and then we need to compensate for the fact that we could double count when both of them are present.",
            "So what that does is gives us a characterization about conditional probability, where the probability effect in the presence of the cause, the absence of the background, is just the strength that's associated with this relationship in the presence of the background.",
            "In the absence of the cause is just the strength associated with this relationship in the presence of both variables is.",
            "What you get when you add the strengths together and then subtract off the probability that both of these variables independently produce the effect.",
            "And this is a noisy version of a deterministic or gate.",
            "So in the case where these strengths are one, then you just get back the OR gate.",
            "This is what you get if you have an or gate where each of the inputs to the OR gate stochastically has an opportunity to produce the effect.",
            "We can think about two different causal structures, so one is this one in which the cause produces the effect.",
            "The other is this one, in which there is no causal relationship.",
            "This has a slightly different parameterisations, since the only thing that's relevant to whether the effect occurs is the is the background course.",
            "So now we just have a single parameter which describes the probability of the effect occurring in the presence of the background course.",
            "So having set things up in this way, we've now got our graphical models fully specified and we can ask different kinds of questions about causes."
        ],
        [
            "Relationships using these graphical models, there are two kinds of questions that we can ask, and these correspond to the distinction that's made in people who work with graphical models between structure learning and parameter estimation.",
            "So the structure question is whether a relationship exists, and that's essentially a choice between these two graphical models.",
            "It's asking which of these graphical models actually describe the situation that we're talking about.",
            "The strength question is the question of how strong that relationship might be, so it's a question about the estimate that we end up with for this parameter.",
            "Assuming this particular causal model.",
            "And it turns out that.",
            "Both causal power and Delta P correspond to ways of estimating that strength variable.",
            "So causal power is the estimate of that strength variable under this noisy or assumption.",
            "Delta P is an estimate which assumes that causes just combined linearly.",
            "Without that extra bit of compensation for double counting.",
            "So what this means is that all of the existing psychological models we're looking at only one of the two ways that you could answer a question about a causal relationship they were focusing on the parameter estimation problem, the problem of estimating the strength of the relationship, and the fact that there were things that were going on in those data that they couldn't explain.",
            "Suggest that perhaps we might be able to get some new insight into human cognition by."
        ],
        [
            "At the other one of these questions, the structure question.",
            "So in order to set this up in a Bayesian way, what we're going to do is Bayesian structure."
        ],
        [
            "In comparing these two different structures, we're going to compute a likelihood ratio.",
            "This is what we call causal support.",
            "The likelihood ratio gives us the the likelihood ratio in favor of this hypothesis, in which there is a causal relationship.",
            "The way that we do this is by calculating Bayes factors which people have alluded to in previous talks.",
            "When you calculate the Bayes factor, what you need to do is integrate out the parameters which are associated with each of these models so that we end up with each model just defining a probability distribution over data that we could observe, which in this case corresponds to a probability distribution over those contingency tables.",
            "So for this simple hypothesis here where there's no relationship, we just need to integrate out the background cause an in this one where there is a relationship we need to integrate out.",
            "Both of these causes, and then the way that we calculate the probability of the data given the parameter values is using that noisy or parameterisation that I showed you before and we just defined prior distributions on these parameters.",
            "I'm just going to assume that the uniform and this gives us the quantity that we need in order to evaluate which of these structures might be responsible for generating the data that we observe.",
            "Everybody OK so far.",
            "Yeah, OK, so what's interesting about this is that it gives us a kind of automatic way of penalizing the greater complexity of this structure over the structure.",
            "One of the challenges that you face in structure learning is that structure, which has more links like this, is in many ways sort of more flexible than a structure which doesn't have a link like this.",
            "You've got more parameters here, so in principle you can fit more data better, and this way of integrating out the parameters in order to calculate the Bayes factor.",
            "And she gives us a way of correcting for the fact that there's different flexibility in these two models."
        ],
        [
            "So it implements something that's called the Bayesian Occam's Razor.",
            "This is the idea that just by doing Bayesian inference, integrating over the parameter values of models is going to automatically penalize more complex models and basically the intuition behind this is that you can think about it what we're doing when we're integrating out those parameters is making those models give us a probability distribution over all possible datasets, so in forcing them to give us a distribution over all possible datasets, we've kind of reduced them down to a common currency which is.",
            "A probability distribution where probability is spread over the datasets that those models can explain.",
            "Now if we take the simpler model, the one in which there is no causal relationship.",
            "If we think about ranking or possible datasets in order of increasing Delta P, this model is only going to be able to explain those datasets in which Delta P is relatively small, right?",
            "It says that there's no relationship.",
            "So really the probability of defect in the presence in the absence of the cores that we observe in those contingencies should be about the same regardless of whether the the of what's going on with the cause of variable.",
            "So that means that it's going to put all of its probability over a relatively small region of this space of possible datasets, and as a consequence is going to sign high probability to those datasets, whereas the more complex hypothesis can explain you know this full range of datasets that can explain situations where there's a week cause as well as situations where there's a strong cause and because it covers more of these datasets, it's going to assign less probability to each one, so this is really just sort of falling out of the conservation of probability of the fact that the probabilities have to sum up to one when we integrate them over all possible datasets.",
            "It gives us this kind of Occam's Razor effect where if we observe a data set that can be explained by the simpler model, we're going to prefer to explain it using the simple model, because the simple model is going to end up assigning higher probability to that data set."
        ],
        [
            "So if we saw something that was, say, you know, a big difference in Delta P out here, we choose the more complex model because that's."
        ],
        [
            "Only model that can explain the data, whereas if we see something where there's a small difference in Delta, P will choose the simpler model because the simple model does a better job of accounting for those data sets where there's only a small difference.",
            "So this kind of principle is a nice and sort of important aspects of Bayesian inference, and it just kind of falls out of the math of probability theory.",
            "You don't need to do anything else in order to deal with the different complexity of these models, and a lot of the challenges that frequentist statistics has faced in terms of formulating hypothesis testing methods come down to dealing with this.",
            "This challenge of evaluating hypothesis that differ in complexity.",
            "OK, so that's the principle which is gone by this model.",
            "Now we."
        ],
        [
            "And see what it does.",
            "Well, here's that data set that I showed you before.",
            "Here are the predictions of Delta P and causal power.",
            "And on the bottom here what I'm showing you, the predictions of this causal support model and what you should be able to see is that actually this addresses all of the problems that I was showing you before.",
            "It actually produces predictions that very closely match human judgments as well as interesting Lee producing this effect, which neither of the other models could explain, and something which they considered irrational where it seems like even though there's no change in the contingencies, people are changing the judgments that they make.",
            "So this idea then that people are doing something more like structure learning when they are evaluating these relationships rather than thinking in terms of parameter estimation, is an interesting one, and it seems like it actually captures some of the variance in the data.",
            "Here we've gone on to do other experiments showing that it can explain a pretty broad range of datasets.",
            "There are also cases where people do something which is more clearly related to structure learning, and you can basically ask people different kinds of questions about causal relationships, and some of them tap inferences about structure.",
            "And others tap inferences about parameter estimation, and I can tell you some more about that if you're curious what I'm going to do now is just sort of explore the assumptions behind our model which make."
        ],
        [
            "Possible to get this good fit to the data?",
            "Well, one way of exploring whether a particular assumption is necessary is taking it away, and the big assumption that we made in terms of formulating this model was an assumption about this conditional probability.",
            "The probability effect in the presence of the cause or in the presence of these."
        ],
        [
            "Variables, So what we could do is take that away instead of using the noisy or parameterisation we could just use a generic Bernoulli beta model, or a multinomial Dirichlet model.",
            "This is the standard sort of model which is assumed in.",
            "In most Bayesian structure learning that's done in machine learning where what we do is we just associate.",
            "We say rather than having a strength associated with each of those relationships.",
            "Now we use our parameters to just describe the probability effect in the presence in the absence of the cause and the configuration of the parents of this node is going to be associated with a separate parameter which just describes that probability.",
            "So now you know what we're trying to do is workout.",
            "There's basically this is all this is asserting is that there's a dependency in this distribution where.",
            "You can have a different probability depending on the values of the parents of this node in the graph, so this could be .8 and this could be .2 and point 1.9.",
            "There's no particular relationship that is implied by having a causal link, just that the distribution of the effect differs depending on the values of the background cores and the other costs are variable.",
            "So I call this a generic parameterisation, 'cause it makes basically no assumptions about the nature of that causal relationship."
        ],
        [
            "So if you take that generic model, what happens?",
            "Is it no longer fits the data?",
            "So if you do exactly the same math, you just integrate over all of your parameters and do all of those things, you don't get something that looks like human judgments, so you can.",
            "You know I can go back and compare this if you want, but you can see very clearly that for example, it's failing to produce that effect that I was pointing out where basically as the baseline probability of the effect increased in the human data, we saw an increase in people's judgments, whereas we don't see that relationship being expressed here.",
            "Instead, there's this kind of.",
            "Nonlinear relationship between the baseline probability and the judgment of the assessment of causal relationship.",
            "So it turns out that in order to explain the human data, this assumption that causes increase the probability of their effects, which is the assumption that's built into the noisy or is actually a necessary assumption.",
            "We need that assumption in order to explain the human data.",
            "I understand where."
        ],
        [
            "The way that that's working, if I just go back to that graph, what's going on here?",
            "Is that as this baseline probability increases, people's judgments increase.",
            "The reason why this is a rational inference.",
            "If you believe that causes increase the probability of their effects, is that if you think about it, this is a case where, in the absence of the cores, none of the time was the effect expressed, and none of the time the effect was expressed in the presence of the course.",
            "That's actually pretty good evidence that there's not a causal relationship, right?",
            "You can kind of think about this in this experiment.",
            "There were sort of H opportunities.",
            "These contingencies were calculated out of.",
            "8 trials so this was, you know, a situation where there were eight chances for the cause to express itself, and it didn't express itself on any of those, and so that's a pretty good sort of suggestion that there might not be a relationship.",
            "Whereas if you look over here here, the probability effect in the absence of the course was one.",
            "And the probability effect in the presence of the course was one.",
            "But if the effect is already occurring all the time, there's no opportunity for the cause to influence the effect, and as a consequence you can't make any inference from the data that you've got.",
            "And so basically what's going on is as the dynamic range in which the cause can express itself.",
            "Is increasing.",
            "Then the fact that it didn't express itself as it gets more and more opportunities.",
            "But the fact that it didn't express itself is.",
            "It gives it sort of more and more damning evidence against the causal relationship, and that's why our model says, you know.",
            "Here I've got pretty good evidence against the causal relationship and what's going on.",
            "Is that here?",
            "I'm just sort of completely uncertain, and I'm just going to fall to my prior assumption, which in this case was 5050.",
            "As to whether there was a relationship or default to my prior and so I'll give this sort of intermediate judgment and then what's going on is you're getting more and more evidence against a causal relationship as you go down here.",
            "Well, that only works if you assume that causes generative.",
            "That causes increased the probability of their effects.",
            "And so if you don't make that assumption, then you know something like this isn't necessarily a problem, because it could be that the cause decreases the probability of the effect, and you've got lots of opportunities to observe that if I go."
        ],
        [
            "Back to the generic model.",
            "The reason why it produces this trend is that if you don't have any assumption that causes increase, the probability of their effects, the least diagnostic cases, the middle case, because that's the one where the variance is highest.",
            "But these two extremes you've got equally good opportunities to evaluate whether there is a relationship that exists.",
            "So basically what we take away from this is that people have strong intuitions about the nature of causality, and those intuitions go beyond just statistical dependency.",
            "So if you just taken off the shelf Bayes net learning algorithm.",
            "That you know tries to learn the structure of a Bayesian network and uses those generic assumptions about the conditional probability distributions.",
            "It's not going to look like human learning, part of what makes people good at evaluating these kinds of causal relationships.",
            "Comes out of the assumptions that we make about what it means for something to be a causal relationship.",
            "And here one of those assumptions is that causes increased the probability of their effects.",
            "OK, so.",
            "I'm going to use a little bit of cognitive psychology, so one of the things that we know in cognitive psychology is that there's a U shape retention curve for information.",
            "So what that means is that the things that you see at the start of a lecture and the things that you see at the end of a lecture of the things that you retain best, and the things that are in the middle, they just disappear into nowhere.",
            "So what we're going to do is we're going to simulate, will do a little bit of optimization.",
            "So if we have instead of having one big U shaped curve, I'm going to break it up into two U shaped curves.",
            "So you'll have a greater opportunity to retain information, so let's take a two minute break everyone."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to be giving 2 1/2 lectures and the titles that we have in the program are fairly approximate, so Nick and I are down to split electron models and theories in cognitive science, so I'm going to start off a little bit talking about general strategies for connecting cognitive science and machine learning, an approach that we can use for doing that, and then I'll talk mostly today about causality and then in the next 2 lectures I'm going to give our talk.",
                    "label": 1
                },
                {
                    "sent": "About a little bit about nonparametric Bayesian methods that will be in the lecture that split with Josh and then on the last lecture I'll talk about Monte Carlo methods and how those can be used in both machine learning and in cognitive science.",
                    "label": 0
                },
                {
                    "sent": "So the general theme of these lectures is going to be about ideas that kind of bridge cognitive science and machine learning in ways that we can develop strategies for, making sure that that's a productive relationship.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to start off with his return to a point which has come up a few times in the lectures that you've seen, so this is the idea of different levels of analysis, so you might remember these different levels that you heard about.",
                    "label": 0
                },
                {
                    "sent": "So David Myron talked about 3 levels at which we can analyze and information processing systems such as the human mind.",
                    "label": 0
                },
                {
                    "sent": "We can analyze data computational level, asking what the goal of the computation is, way that goal is appropriate, and what the logic is of the strategy by which it can be carried out at the level of representation algorithm asking what's the representation for the input and output.",
                    "label": 1
                },
                {
                    "sent": "And the algorithm for the transformation or at the level of implementation where we ask how the representation algorithm can be realized physically and these are different levels that really historically have tended to be explored by different kinds of disciplines.",
                    "label": 0
                },
                {
                    "sent": "So implementation is something which neuroscience tends to explore, looking at how our brain performs computations.",
                    "label": 0
                },
                {
                    "sent": "Representation algorithm is a traditional level for cognitive psychology.",
                    "label": 0
                },
                {
                    "sent": "Basically, trying to figure out what the sorts of cognitive processes are that support the things that we do every day and the level of computation is 1, which historically.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's been neglected in the world the way that we go about thinking about how the mind works.",
                    "label": 0
                },
                {
                    "sent": "It's a level of thinking about the abstract kinds of problems that people need to solve, and the solutions to those problems.",
                    "label": 0
                },
                {
                    "sent": "And in fact, it's this level which I'm going to focus on which many of the talks that you seem to be focusing on, and I'm going to give you some arguments for why that might be a good idea.",
                    "label": 0
                },
                {
                    "sent": "So this level.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is one that David Mar instead of proposing these these different levels of analysis that one of the main goals of his proposal was actually to identify the fact that there was this separate computational level and to argue that that was something that we should be investigating.",
                    "label": 0
                },
                {
                    "sent": "So his argument with something like this?",
                    "label": 0
                },
                {
                    "sent": "He says an algorithm is likely to be understood more readily by understanding the nature of the problem being solved and by examining the mechanism and the hardware in which it's embodied.",
                    "label": 1
                },
                {
                    "sent": "In a similar vein, trying to understand perception by studying only neurons is like trying to understand bird flight by studying only feathers.",
                    "label": 0
                },
                {
                    "sent": "It just cannot be done.",
                    "label": 0
                },
                {
                    "sent": "In order to understand Bird flight, we have to understand aerodynamics only the end of the structure of fellows in the different shapes of birds wings makes sense, and so there's kind of an idea here that thinking about the function that's being served by a certain kind of process, and in this case thinking about the abstract problems that we're solving, is something that's going to give us insight into how that process works in a way which is fundamentally different from studying the mechanisms by which it's executed.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you could have some different questions.",
                    "label": 0
                },
                {
                    "sent": "Sort of, you know, in recognizing that, maybe this is a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "So one question is, how do you actually go about doing a computational level analysis of some aspect of behavior?",
                    "label": 0
                },
                {
                    "sent": "You know, we've sort of argue that this might be a good thing, but how would you actually do that?",
                    "label": 0
                },
                {
                    "sent": "Another is what the equivalent is of aerodynamics for cognition.",
                    "label": 1
                },
                {
                    "sent": "So what's the kind of set of principles that we might appeal to in order to explain these functional properties of human cognition?",
                    "label": 0
                },
                {
                    "sent": "And the third, what the consequences of this kind of approach might be for understanding the mind?",
                    "label": 1
                },
                {
                    "sent": "So I'm going to sort of briefly give some answers to these questions before.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going on so for this first question of how it is that you go about conducting a computational level analysis.",
                    "label": 1
                },
                {
                    "sent": "Really, this wasn't something that was necessarily made clear by Mara, but it's something which has emerged in subsequent work which is advocated.",
                    "label": 0
                },
                {
                    "sent": "An approach called rational analysis.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This where the basic idea is that what you want to do is to 1st think about the underlying computational problem which is involved in some aspect of cognition.",
                    "label": 0
                },
                {
                    "sent": "So if there's something that you want to understand about human cognition, the first step is to sit down and think about it and say, well, you know what's the data that people are getting.",
                    "label": 0
                },
                {
                    "sent": "One of the hypothesis they might be evaluating what's a way of describing what the problem is that people are solving, and then having formulated that problem?",
                    "label": 0
                },
                {
                    "sent": "The second thing to do is to find a good solution to that problem, and this is normally the point where you go off and read some machine learning books, and you read some things from statistics and so on.",
                    "label": 0
                },
                {
                    "sent": "Because that's where you're going to find solutions to those kinds of problems where you know they're going to tell you.",
                    "label": 0
                },
                {
                    "sent": "Well, you know, given this kind of problem, here's a good method for solving that problem, and then compare human cognition to that solution.",
                    "label": 1
                },
                {
                    "sent": "So this is where we use these methods like Felix was talking about methods that come from psychology, which give us a way of evaluating whether the predictions that come out of these models are accurate, and then if they're not you, hopefully you know go back and start revising your theory and thinking about whether that's a good theory, whether you've got something wrong in the way that you characterize that problem, or whether this approach isn't necessarily going to work for that domain.",
                    "label": 0
                },
                {
                    "sent": "So one thing that's important about this kind of strategy is that it's not just something which is likely to give us insight into human cognition, it's something which is going to directly relate cognition and computation.",
                    "label": 0
                },
                {
                    "sent": "The fact that at that second step you have to, you know, go off and read some statistics and machine learning books is actually an important aspect of this strategy, because it's something which is going to give us connections between the way that we end up understanding human cognition.",
                    "label": 0
                },
                {
                    "sent": "If we understand human cognition in terms of these optimal solutions to these underlying problems and the kinds of methods that are being used in engineering and computer science.",
                    "label": 1
                },
                {
                    "sent": "To solve problems out in the world.",
                    "label": 0
                },
                {
                    "sent": "So this is an interesting outcome of this, and I think that this is in some ways an even better argument than the argument that Mou is making for why this is a reasonable way to proceed.",
                    "label": 0
                },
                {
                    "sent": "It's something which is going to give us a link between human and machine learning that's just a consequence of following this kind of strategy.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you know, in order to make this work, we have to sort of answer this question of what aerodynamics might be.",
                    "label": 0
                },
                {
                    "sent": "So aerodynamics is the solution to the problem which is posed to birds.",
                    "label": 1
                },
                {
                    "sent": "So what's the solution to the kind of problems that opposed to people?",
                    "label": 0
                },
                {
                    "sent": "Well, for the sorts of problems that we've been talking about that are inductive problems where you have to go from observed data and evaluate underdetermined type.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the answer is 1 which should be very familiar to you by now.",
                    "label": 0
                },
                {
                    "sent": "Basically the idea is that the equivalent of aerodynamics for people is something like statistics.",
                    "label": 0
                },
                {
                    "sent": "So if you want to understand what sort of structure you are allowed to infer from data, which is basically the problem that is posed to us whenever we're trying to make one of these inductive inferences, then that's exactly what statistics is about.",
                    "label": 1
                },
                {
                    "sent": "Statistics is the science of telling you what you're justified in believing based on the data that you see, and in particular, you know the way that I'm going to frame things in the way that you will see at some of the other talks, frame things in terms of Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "But I think the idea more generally is that statistics is going to give us a guide to understanding what solutions to these problems look like.",
                    "label": 0
                },
                {
                    "sent": "So you've all seen Bayes rule by now.",
                    "label": 0
                },
                {
                    "sent": "It's worth pointing out some interesting components of Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "One of these components is the fact that it gives us a way of, you know, I think this is something that came up in Neil's presentation.",
                    "label": 0
                },
                {
                    "sent": "If you just look at Bayes rule in terms of way of talking about defining conditional probabilities, then it's not.",
                    "label": 0
                },
                {
                    "sent": "Not controversial in any way.",
                    "label": 0
                },
                {
                    "sent": "What makes it controversial and interesting is the idea that it's actually something which gives us a description of how people should go about learning.",
                    "label": 0
                },
                {
                    "sent": "So you can think about Bayes rule is telling you how you should go from your current degrees of belief in something and revise them in light of the evidence you see to obtain new degrees of belief.",
                    "label": 0
                },
                {
                    "sent": "And once valuable about that as it gives us a way of encoding what the expectations of a learner are and expressing those through this prior distribution over hypothesis and through the choice of the space of hypothesis that we're considering and those two things actually going to turn out to be important in terms of describing.",
                    "label": 0
                },
                {
                    "sent": "Human learning and understanding.",
                    "label": 0
                },
                {
                    "sent": "Some of the things about how people are so good at making, and, uh.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of inferences.",
                    "label": 0
                },
                {
                    "sent": "So the last of my questions is what the consequences are of this kind of approach and there are a couple of interesting consequences of pursuing this kind.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of analysis.",
                    "label": 0
                },
                {
                    "sent": "So the first is that what we get out of this is a direct set of connections between problems in computers are in cognitive science and problems in statistics.",
                    "label": 1
                },
                {
                    "sent": "So one of the things that's come out of pursuing this approach over the last 10 to 20.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Years is kind of a list where on one side you've got things that we're interested in understanding about human learning, and on the other side what you've got is things that we sort of know how to handle.",
                    "label": 0
                },
                {
                    "sent": "Are interested in being able to solve using methods that come from machine learning or statistics, so you can kind of learn a way of translating between these two kinds of.",
                    "label": 0
                },
                {
                    "sent": "Formalizations are different kinds of problems, but if you're interested in, say, understanding human categorisation, then maybe you should learn something about density estimation.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in graphene causal learning, then graphical models function learning is sort of like regression and so on.",
                    "label": 1
                },
                {
                    "sent": "So for each of these different kinds of problems that we might be interested in cognitive science, there's a parallel literature in machine learning, and after a while you kind of get used to going to a poster instead of translating it.",
                    "label": 0
                },
                {
                    "sent": "If you're in machine learning conference, you can translate it into what it is in cognitive science that that poster is going to help you understand, or if you go to a cognitive science poster, you can translate it into.",
                    "label": 0
                },
                {
                    "sent": "What aspect of machine learning might be interesting for understanding the problem that people are solving?",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you know forming these kind.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Connections first of all, gives us a way of taking ideas that come from machine learning and using them to inform our understanding of human learning.",
                    "label": 0
                },
                {
                    "sent": "It gives us a set of tools that we can use for formalizing the problems that people need to solve and working out what the solutions those problems might be so that we can then go on and try and figure out whether people do something that looks like those solutions.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another thing that we get out of pursuing this strategy is a characterization of the inductive biases of human learners.",
                    "label": 1
                },
                {
                    "sent": "So when people talk about machine learning algorithms having inductive biases, what those inductive biases are?",
                    "label": 0
                },
                {
                    "sent": "Are any factor other than the data which leads you to to favor one hypothesis over another.",
                    "label": 0
                },
                {
                    "sent": "So these kinds of inductive biases are something which are very important in making good inductive inferences.",
                    "label": 0
                },
                {
                    "sent": "The whole sort of thing that makes induction hard is that the hypothesis you're evaluating or under determined by the data.",
                    "label": 0
                },
                {
                    "sent": "So all you really have to go on is those inductive biases.",
                    "label": 0
                },
                {
                    "sent": "The thing that's going to make 1 machine learning system a better machine learning system than another is that it's going to have inductive biases that better match the problem, and this is kind of a point that came up in some of the talks that you've seen already.",
                    "label": 0
                },
                {
                    "sent": "So when you want to have a good hypothesis space, Anna good.",
                    "label": 0
                },
                {
                    "sent": "Form of regularization for characterizing the solutions which you want to produce for any particular problem, and how well you solve a problem is going to depend on how good your inductive biases are.",
                    "label": 0
                },
                {
                    "sent": "You can give a simple example of the importance of these kinds of inductive biases in here.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm learning so if I was going to teach you a new word, so I'm going to show you, you can imagine you were traveling around in Sardinia and one of the natives pointed out something to you and then said this word pakora Does anybody who actually knows what this, who it is?",
                    "label": 0
                },
                {
                    "sent": "Can you pronounce it properly for me?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, and then you are trying to learn a little bit of the native language so you are then sort of forming some hypothesis about what this word might mean.",
                    "label": 0
                },
                {
                    "sent": "OK, so you think about the hypothesis that you entertain, so who's entertaining hypothesis?",
                    "label": 0
                },
                {
                    "sent": "Something like sheep.",
                    "label": 0
                },
                {
                    "sent": "White thing.",
                    "label": 0
                },
                {
                    "sent": "Willie thing four legged thing.",
                    "label": 0
                },
                {
                    "sent": "OK, things under 3 feet tall.",
                    "label": 0
                },
                {
                    "sent": "Things that are sheep on a Saturday and a glass of milk on a Tuesday.",
                    "label": 0
                },
                {
                    "sent": "Things that have less than eight legs.",
                    "label": 0
                },
                {
                    "sent": "OK, so nobody was entertaining the last three hypothesis right?",
                    "label": 0
                },
                {
                    "sent": "And you can kind of recognize that those last three hypotheses are in some ways less good hypothesis then the first hypothesis that I named.",
                    "label": 0
                },
                {
                    "sent": "But each of those hypothesis is equally consistent with the data that you observed, right?",
                    "label": 0
                },
                {
                    "sent": "Each of those hypothesis logically matches the information that you saw and you know the the fact that this is the object that was labeled.",
                    "label": 0
                },
                {
                    "sent": "Is you know it's equally consistent with each of those different hypothesis.",
                    "label": 0
                },
                {
                    "sent": "The only thing that makes you favor one hypothesis over another is the inductive biases that you have and those inductive biases tell you certain kinds of things are likely to be labeled by words, and the words that we use.",
                    "label": 0
                },
                {
                    "sent": "We have expectations about how it is that they map onto things like objects in the world.",
                    "label": 0
                },
                {
                    "sent": "You can ask a native speaker what this word actually means.",
                    "label": 0
                },
                {
                    "sent": "If you're still curious.",
                    "label": 0
                },
                {
                    "sent": "OK, so these kind of inductive biases are part of what makes human learners so good at learning.",
                    "label": 1
                },
                {
                    "sent": "So if we want to make machine learning systems that are good at solving the kinds of problems that people are good at solving, then what we need to do is figure out something like human inductive biases.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of my argument for why people who are interested in machine learning should become cognitive scientists.",
                    "label": 0
                },
                {
                    "sent": "You know, if we sort of take these arguments, then that Bernard's been making about, you know.",
                    "label": 0
                },
                {
                    "sent": "The importance of having you know the right hypothesis space in the right sort of regularization, or the sort of more general idea that you should have inductive biases that match the problems that you're solving.",
                    "label": 0
                },
                {
                    "sent": "If your goal is to make systems that can solve the kinds of problems that people are good at solving, then you could go out and keep making your machine learning algorithms that have different kinds of inductive biases, and then you know, keep comparing them and do some evaluation and cross validation and so on, and try and workout how well they fit their their data and all of these different kinds of things.",
                    "label": 0
                },
                {
                    "sent": "Really what you're doing by doing that is exploring that space of inductive biases until you find something that solves the problem well.",
                    "label": 0
                },
                {
                    "sent": "Could go off and study a system that you know solves that problem well.",
                    "label": 0
                },
                {
                    "sent": "Workout.",
                    "label": 0
                },
                {
                    "sent": "What is inductive?",
                    "label": 0
                },
                {
                    "sent": "Biases are and then figure out a way of translating that into a machine learning algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in making working machine learning systems, maybe one of the strategies that you could use for doing that is looking at human learning systems and seeing what we can figure out about those inductive biases that make humans so good and then translate them over to machine learning systems.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what's valuable about this kind of statistical framework is that it gives us a very transparent way of characterizing the inductive biases of learners.",
                    "label": 0
                },
                {
                    "sent": "So if we're trying to model human inferences in terms of something like Bayesian statistics, then in looking at the prior probability distributions that we need to identify in order to produce Bayesian models that make predictions which are similar to human behavior, then what we're doing is essentially exploring the space of inductive biases trying to find inductive biases that match those of human learners, and so this is a.",
                    "label": 0
                },
                {
                    "sent": "You know one of the attractive things about this framework is that it gives us a very clear way of talking about those inductive biases being expressed through things like prior probabilities, and more generally, the space of hypothesis that you select.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last thing that we might hope to get out of this kind of computational analysis is some understanding of where it is that these inductive biases come from.",
                    "label": 1
                },
                {
                    "sent": "So, having identified what those inductive biases are by using this kind of strategy, that sets us up with the opportunity to try and figure out where it is that they come from.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to talk a little more about that in one of the examples that I go through today and give you some sort of ideas that you might be able to generalize, but other cases, but the basic idea is that.",
                    "label": 0
                },
                {
                    "sent": "If we can figure out, you know if these are things which say people learn from the environment around them, then we can go on and build machine learning systems that in the same way can learn appropriate inductive biases for solving the problems we want.",
                    "label": 0
                },
                {
                    "sent": "Those machine learning systems to solve.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, part of the reason why this is interesting is because all of these sorts of things over here on the left hand side tend to be things that people are pretty good at, and that we're still trying to make better machine learning systems for solving these problems.",
                    "label": 0
                },
                {
                    "sent": "So to the extent that we can understand how it is that people do these things, then we can improve the algorithms that we have for working with these different kinds of formalisms as a way of improving the performance of those machine learning systems.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is really an opportunity for us to sort of close the loop and take something from human learning.",
                    "label": 0
                },
                {
                    "sent": "Something about what the inductive biases of people are and where those come from and use it to inform machine learning.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do today is illustrate this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have argument by picking one of the things on this list.",
                    "label": 0
                },
                {
                    "sent": "Causal learning and then talking about how it is that we can get insights into human causal learning from machine learning, and then how it is that we can get insights about what might make better machine learning systems from studying human causal learning.",
                    "label": 1
                },
                {
                    "sent": "So you've already heard a little bit about causal learning and some of the challenges that it poses.",
                    "label": 0
                },
                {
                    "sent": "One of the things that I think are most interesting about causal learning is that.",
                    "label": 0
                },
                {
                    "sent": "If you think about our intuitive ability to evaluate causal relationships, this is really all that we had for doing science before the development of statistics.",
                    "label": 0
                },
                {
                    "sent": "So you know, statistics has only really been something which is worked for, say, the last 100, maybe 200 years, right?",
                    "label": 0
                },
                {
                    "sent": "That's the you know the only.",
                    "label": 0
                },
                {
                    "sent": "Between which people have actually had formal statistical methods for evaluating the amount of evidence that their observations provide for the particular hypothesis that they're interested in.",
                    "label": 0
                },
                {
                    "sent": "But if you think about it, science has been going on for much longer than that.",
                    "label": 0
                },
                {
                    "sent": "So before the development of formal statistical methods.",
                    "label": 0
                },
                {
                    "sent": "The way that scientists had to figure out if there was a causal relationship between two things and the way that we in our everyday lives have to figure out whether there's a causal relationship between two things.",
                    "label": 0
                },
                {
                    "sent": "We're just relying on their intuitions about what their data told them.",
                    "label": 0
                },
                {
                    "sent": "So you can actually go back and find some interesting examples where people are making essentially statistical arguments that rely on these.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kinds of intuitions, so here's one example.",
                    "label": 0
                },
                {
                    "sent": "This is from a report that was published in 1798, which was about whether taking people who had fevers and then giving sort of treating them, covering their body and cold water, or putting them in cold baths was actually something that was an effective remedy.",
                    "label": 0
                },
                {
                    "sent": "So Curry, who is a ship's doctor, describes what happened.",
                    "label": 0
                },
                {
                    "sent": "So he says the contagion spread rapidly and before its progress could be arrested, 16 persons were affected, of which two died.",
                    "label": 1
                },
                {
                    "sent": "Of these 16, eight were under my care.",
                    "label": 0
                },
                {
                    "sent": "On this occasion I used for the first time the Fusion of cold water in the manner described by doctor Right.",
                    "label": 1
                },
                {
                    "sent": "It was first trade in two cases that employed in five other cases it was repeated daily, and of these seven patients, the whole recovered.",
                    "label": 1
                },
                {
                    "sent": "OK, So what he's doing here?",
                    "label": 0
                },
                {
                    "sent": "This is his argument for why this might be.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good method is really giving you all of the information that you need to construct a contingency table that we now could apply our statistical methods to to figure out whether there is a causal relationship.",
                    "label": 0
                },
                {
                    "sent": "His question is whether the treatment causes recovery and his data.",
                    "label": 1
                },
                {
                    "sent": "He had seven people who were treated, all of whom recovered, and there were nine people who weren't treated, two of whom died right?",
                    "label": 0
                },
                {
                    "sent": "So the question is, for the reader of one of his papers.",
                    "label": 0
                },
                {
                    "sent": "Is this something which suggests that there might be an interesting underlying causal relationship?",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem with psychologist have studied the way that they do.",
                    "label": 0
                },
                {
                    "sent": "This is by basically using exactly the same kind of task.",
                    "label": 0
                },
                {
                    "sent": "They would take contingency table with some numbers here represented by ABC and D Give that contingency table to somebody and then ask them does see cozy or something like to what extent does see Causey and ask him to give it rating on a scale from zero to 100 of the extent to which they believe that there's a causal relationship between those two things and psychologists are interested in understanding what the mapping is from these kinds of contingency data.",
                    "label": 1
                },
                {
                    "sent": "To our intuitive sense of whether there's a causal relationship, so they develop lots of different theory.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how this works?",
                    "label": 0
                },
                {
                    "sent": "Two of the most prominent theories are something called Delta P, which is that the way that you should evaluate a causal relationship is by just thinking about the impact of the cores on the probability of the effect.",
                    "label": 0
                },
                {
                    "sent": "So what you do is take the difference between the probability effect in the presence of the cores and the probability effect in the absence of the course.",
                    "label": 0
                },
                {
                    "sent": "So this is the change in probability that's a result of the cause being present.",
                    "label": 0
                },
                {
                    "sent": "And then another theory which is called the PowerPC theory, where the idea is that Delta P seems like a reasonable way of measuring the magnitude of a causal relationship, but it doesn't necessarily reflect the fact that the base rate of the of the effect occurring should be relevant.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that as the probability of the effect in the absence of the cores increases, there's less dynamic range for the cause to express itself.",
                    "label": 0
                },
                {
                    "sent": "So a small difference in Delta P could actually be quite meaningful.",
                    "label": 0
                },
                {
                    "sent": "If there's already a relatively high probability of the effect occurring, whereas it's less likely it's less and less meaningful when the probability effect in the absence of the causes lower, because it basically means that a smaller proportion of people have been changed in the extent to which they express the effect as a consequence.",
                    "label": 0
                },
                {
                    "sent": "So it just normalizes Delta P by the amount of dynamic range in which this causal relationship could express itself, so you can.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take both of these kinds of measures and apply them to our contingency table from Doctor Curry so you know here probably effect in the presence of the causes.",
                    "label": 0
                },
                {
                    "sent": "One probably effects in the absence of the causes.",
                    "label": 0
                },
                {
                    "sent": ".78 if we think about recovery as our effect, so Delta P is .22 and then causal power whips, is is 1.",
                    "label": 0
                },
                {
                    "sent": "So what's going on here?",
                    "label": 0
                },
                {
                    "sent": "Is it saying that all of the people who would have died, so Delta P is just saying what's the change in the probability causal power is saying of the proportion of people who would have died?",
                    "label": 0
                },
                {
                    "sent": "How many of them recover?",
                    "label": 0
                },
                {
                    "sent": "And the answer here is that you know 100% of the people who hypothetically would have died had they not been treated, recovered when they were treated.",
                    "label": 0
                },
                {
                    "sent": "So perhaps this is a strong causal relationship under Delta P. It might not seem like a very strong relationship, but these are proposed as measures of what's going on inside your head when you're evaluating a causal relationship, the way that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are assessed is by comparing them with human data.",
                    "label": 0
                },
                {
                    "sent": "So here's some human data.",
                    "label": 0
                },
                {
                    "sent": "These are results of a study from Buner and Chang in 1997.",
                    "label": 0
                },
                {
                    "sent": "What they did was present people with contingency tables in which the probability effect in the presence in the absence of the cause was varied in increments of .25 over the entire range of possible contingency is consistent with the generative causal relationship.",
                    "label": 0
                },
                {
                    "sent": "So one in which the cause increases the probability of the effect.",
                    "label": 0
                },
                {
                    "sent": "So here, here are people's ratings on that scale from zero to 100.",
                    "label": 0
                },
                {
                    "sent": "Of what extent?",
                    "label": 0
                },
                {
                    "sent": "It seems like the cause produces the effect, and here are the predictions of Delta P and causal power for these different contingencies.",
                    "label": 0
                },
                {
                    "sent": "So if you look at these data, you can already see some interesting things going on.",
                    "label": 0
                },
                {
                    "sent": "These data were collected with the intent of demonstrating that Delta P.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a bad model, and in fact you can see Delta P is a bad model right?",
                    "label": 0
                },
                {
                    "sent": "So here for these contingencies were Delta P is constant.",
                    "label": 0
                },
                {
                    "sent": "It's .25 across here people's judgments very Delta P says that they should be the same.",
                    "label": 0
                },
                {
                    "sent": "Causal power predicts that they vary, but it actually turns out that these data are also.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with causal power.",
                    "label": 0
                },
                {
                    "sent": "So for example, here is a range where causal powers always one, so the cause always results in the effect occurring.",
                    "label": 0
                },
                {
                    "sent": "And so here cause apparent constant.",
                    "label": 0
                },
                {
                    "sent": "But you can see peoples judgments of the causal relationship also very so there's a sense in which these data are consistent with neither of these.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Polls and in fact there are even this sort of effect over here where both of the models make the same prediction and people do something which is completely different.",
                    "label": 0
                },
                {
                    "sent": "And what's interesting about this is that these guys basically dismissed this as a kind of irrational effect because what's going on is that Delta P is 0.",
                    "label": 0
                },
                {
                    "sent": "There's no difference in the probability effect in the presence in the absence of the cores, but peoples judgments of weather of the causal relationship are varying.",
                    "label": 0
                },
                {
                    "sent": "So here when even though there's no difference in contingency, you see variation in peoples judgments.",
                    "label": 0
                },
                {
                    "sent": "They think that this is an irrational effect.",
                    "label": 0
                },
                {
                    "sent": "It's something that's inconsistent with both of these models, so this is kind of the state of the art in psychology in terms of evaluating how it is that people might assess course role.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Russian ships, but what we can do now is go to machine learning and statistics and see what machine learning statistics has to say about this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "So you've already heard about graphical models this morning.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going to use a variant on graphical models, causal graphical models which give you a way of representing and reasoning about causal relationships.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a causal graphical model has a set of variables.",
                    "label": 1
                },
                {
                    "sent": "Here we might think about variables being, say, a background cause which is always present and as a potential influence on the effect and the cause which is manipulated in the experiment that I was talking about where the question is whether this course is actually something which influences the effect.",
                    "label": 0
                },
                {
                    "sent": "So we represent these variables as nodes in a graph as in.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphical model we have some causal structure which reflects the relationships that we believe to exist among these very.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Labels and then we have conditional probabilities that are associated with each variable given its parents in the graph, in exactly the same way that we normally do with a graphical model.",
                    "label": 0
                },
                {
                    "sent": "Idea is that what this is going to do is give us a probability distribution over these variables.",
                    "label": 0
                },
                {
                    "sent": "The way that a normal graphical model works.",
                    "label": 0
                },
                {
                    "sent": "It gives us the distribution over these variables for observations.",
                    "label": 1
                },
                {
                    "sent": "So basically it tells us what the joint distribution of these variables is going to be, and we can use that joint distribution.",
                    "label": 0
                },
                {
                    "sent": "We can sort of use the structure here to reason about that joint distribution across a graphical model to Excel.",
                    "label": 0
                },
                {
                    "sent": "Little tweak on the semantics of graphical models, and it says think about these links is not just reflecting statistical dependency but reflecting a causal relationship and what it means that they reflect a causal relationship.",
                    "label": 0
                },
                {
                    "sent": "Is that if you reach into this causal structure and you intervene on one of the variables, so you fix that variable to a particular value, then that breaks all of the incoming links to that variable, and so that's a little twist on the semantics of a graphical model.",
                    "label": 0
                },
                {
                    "sent": "It's not something that I'm going to use here, and the rest of the things I'm going to talk about, but it's the thing that makes it a causal graphical model.",
                    "label": 0
                },
                {
                    "sent": "The idea is that it's something which you could use to reason about the states of those variables, not just when you're observing them.",
                    "label": 0
                },
                {
                    "sent": "When they're giving you correlations, but when you actually reach in and intervene on those variables as well.",
                    "label": 0
                },
                {
                    "sent": "So having sort of set this up, we can now see perhaps how we could use this kind of framework to ask some questions about human causal learning.",
                    "label": 0
                },
                {
                    "sent": "The first thing that we need to do, we can say these are the variables that are relevant to these kinds of inference tasks that I've been talking about, and the kinds of structures that were interested in structures where we're asking whether you know what's going on with this.",
                    "label": 0
                },
                {
                    "sent": "This link between cause and effect.",
                    "label": 0
                },
                {
                    "sent": "The one thing that we need to do before we can go any further.",
                    "label": 1
                },
                {
                    "sent": "Specify what we think the conditional probabilities are that are relevant to this causal.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And So what I'm going to do is use a particular parameterisation of this graphical model, which is called the noisy or parameterisation.",
                    "label": 0
                },
                {
                    "sent": "And what this says is that we associate each of these links with a strength and the way that we calculate the probability of the effect is we basically add up the.",
                    "label": 0
                },
                {
                    "sent": "The the the strengths of these relationships as if they were each having an independent opportunity to produce the effect, and then we need to compensate for the fact that we could double count when both of them are present.",
                    "label": 0
                },
                {
                    "sent": "So what that does is gives us a characterization about conditional probability, where the probability effect in the presence of the cause, the absence of the background, is just the strength that's associated with this relationship in the presence of the background.",
                    "label": 0
                },
                {
                    "sent": "In the absence of the cause is just the strength associated with this relationship in the presence of both variables is.",
                    "label": 0
                },
                {
                    "sent": "What you get when you add the strengths together and then subtract off the probability that both of these variables independently produce the effect.",
                    "label": 0
                },
                {
                    "sent": "And this is a noisy version of a deterministic or gate.",
                    "label": 0
                },
                {
                    "sent": "So in the case where these strengths are one, then you just get back the OR gate.",
                    "label": 0
                },
                {
                    "sent": "This is what you get if you have an or gate where each of the inputs to the OR gate stochastically has an opportunity to produce the effect.",
                    "label": 0
                },
                {
                    "sent": "We can think about two different causal structures, so one is this one in which the cause produces the effect.",
                    "label": 0
                },
                {
                    "sent": "The other is this one, in which there is no causal relationship.",
                    "label": 0
                },
                {
                    "sent": "This has a slightly different parameterisations, since the only thing that's relevant to whether the effect occurs is the is the background course.",
                    "label": 0
                },
                {
                    "sent": "So now we just have a single parameter which describes the probability of the effect occurring in the presence of the background course.",
                    "label": 0
                },
                {
                    "sent": "So having set things up in this way, we've now got our graphical models fully specified and we can ask different kinds of questions about causes.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Relationships using these graphical models, there are two kinds of questions that we can ask, and these correspond to the distinction that's made in people who work with graphical models between structure learning and parameter estimation.",
                    "label": 0
                },
                {
                    "sent": "So the structure question is whether a relationship exists, and that's essentially a choice between these two graphical models.",
                    "label": 1
                },
                {
                    "sent": "It's asking which of these graphical models actually describe the situation that we're talking about.",
                    "label": 0
                },
                {
                    "sent": "The strength question is the question of how strong that relationship might be, so it's a question about the estimate that we end up with for this parameter.",
                    "label": 1
                },
                {
                    "sent": "Assuming this particular causal model.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that.",
                    "label": 0
                },
                {
                    "sent": "Both causal power and Delta P correspond to ways of estimating that strength variable.",
                    "label": 0
                },
                {
                    "sent": "So causal power is the estimate of that strength variable under this noisy or assumption.",
                    "label": 0
                },
                {
                    "sent": "Delta P is an estimate which assumes that causes just combined linearly.",
                    "label": 0
                },
                {
                    "sent": "Without that extra bit of compensation for double counting.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that all of the existing psychological models we're looking at only one of the two ways that you could answer a question about a causal relationship they were focusing on the parameter estimation problem, the problem of estimating the strength of the relationship, and the fact that there were things that were going on in those data that they couldn't explain.",
                    "label": 0
                },
                {
                    "sent": "Suggest that perhaps we might be able to get some new insight into human cognition by.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the other one of these questions, the structure question.",
                    "label": 0
                },
                {
                    "sent": "So in order to set this up in a Bayesian way, what we're going to do is Bayesian structure.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In comparing these two different structures, we're going to compute a likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "This is what we call causal support.",
                    "label": 0
                },
                {
                    "sent": "The likelihood ratio gives us the the likelihood ratio in favor of this hypothesis, in which there is a causal relationship.",
                    "label": 0
                },
                {
                    "sent": "The way that we do this is by calculating Bayes factors which people have alluded to in previous talks.",
                    "label": 0
                },
                {
                    "sent": "When you calculate the Bayes factor, what you need to do is integrate out the parameters which are associated with each of these models so that we end up with each model just defining a probability distribution over data that we could observe, which in this case corresponds to a probability distribution over those contingency tables.",
                    "label": 0
                },
                {
                    "sent": "So for this simple hypothesis here where there's no relationship, we just need to integrate out the background cause an in this one where there is a relationship we need to integrate out.",
                    "label": 0
                },
                {
                    "sent": "Both of these causes, and then the way that we calculate the probability of the data given the parameter values is using that noisy or parameterisation that I showed you before and we just defined prior distributions on these parameters.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to assume that the uniform and this gives us the quantity that we need in order to evaluate which of these structures might be responsible for generating the data that we observe.",
                    "label": 0
                },
                {
                    "sent": "Everybody OK so far.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so what's interesting about this is that it gives us a kind of automatic way of penalizing the greater complexity of this structure over the structure.",
                    "label": 0
                },
                {
                    "sent": "One of the challenges that you face in structure learning is that structure, which has more links like this, is in many ways sort of more flexible than a structure which doesn't have a link like this.",
                    "label": 0
                },
                {
                    "sent": "You've got more parameters here, so in principle you can fit more data better, and this way of integrating out the parameters in order to calculate the Bayes factor.",
                    "label": 0
                },
                {
                    "sent": "And she gives us a way of correcting for the fact that there's different flexibility in these two models.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it implements something that's called the Bayesian Occam's Razor.",
                    "label": 1
                },
                {
                    "sent": "This is the idea that just by doing Bayesian inference, integrating over the parameter values of models is going to automatically penalize more complex models and basically the intuition behind this is that you can think about it what we're doing when we're integrating out those parameters is making those models give us a probability distribution over all possible datasets, so in forcing them to give us a distribution over all possible datasets, we've kind of reduced them down to a common currency which is.",
                    "label": 0
                },
                {
                    "sent": "A probability distribution where probability is spread over the datasets that those models can explain.",
                    "label": 0
                },
                {
                    "sent": "Now if we take the simpler model, the one in which there is no causal relationship.",
                    "label": 0
                },
                {
                    "sent": "If we think about ranking or possible datasets in order of increasing Delta P, this model is only going to be able to explain those datasets in which Delta P is relatively small, right?",
                    "label": 0
                },
                {
                    "sent": "It says that there's no relationship.",
                    "label": 0
                },
                {
                    "sent": "So really the probability of defect in the presence in the absence of the cores that we observe in those contingencies should be about the same regardless of whether the the of what's going on with the cause of variable.",
                    "label": 0
                },
                {
                    "sent": "So that means that it's going to put all of its probability over a relatively small region of this space of possible datasets, and as a consequence is going to sign high probability to those datasets, whereas the more complex hypothesis can explain you know this full range of datasets that can explain situations where there's a week cause as well as situations where there's a strong cause and because it covers more of these datasets, it's going to assign less probability to each one, so this is really just sort of falling out of the conservation of probability of the fact that the probabilities have to sum up to one when we integrate them over all possible datasets.",
                    "label": 0
                },
                {
                    "sent": "It gives us this kind of Occam's Razor effect where if we observe a data set that can be explained by the simpler model, we're going to prefer to explain it using the simple model, because the simple model is going to end up assigning higher probability to that data set.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we saw something that was, say, you know, a big difference in Delta P out here, we choose the more complex model because that's.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only model that can explain the data, whereas if we see something where there's a small difference in Delta, P will choose the simpler model because the simple model does a better job of accounting for those data sets where there's only a small difference.",
                    "label": 0
                },
                {
                    "sent": "So this kind of principle is a nice and sort of important aspects of Bayesian inference, and it just kind of falls out of the math of probability theory.",
                    "label": 0
                },
                {
                    "sent": "You don't need to do anything else in order to deal with the different complexity of these models, and a lot of the challenges that frequentist statistics has faced in terms of formulating hypothesis testing methods come down to dealing with this.",
                    "label": 0
                },
                {
                    "sent": "This challenge of evaluating hypothesis that differ in complexity.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the principle which is gone by this model.",
                    "label": 0
                },
                {
                    "sent": "Now we.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And see what it does.",
                    "label": 0
                },
                {
                    "sent": "Well, here's that data set that I showed you before.",
                    "label": 0
                },
                {
                    "sent": "Here are the predictions of Delta P and causal power.",
                    "label": 0
                },
                {
                    "sent": "And on the bottom here what I'm showing you, the predictions of this causal support model and what you should be able to see is that actually this addresses all of the problems that I was showing you before.",
                    "label": 0
                },
                {
                    "sent": "It actually produces predictions that very closely match human judgments as well as interesting Lee producing this effect, which neither of the other models could explain, and something which they considered irrational where it seems like even though there's no change in the contingencies, people are changing the judgments that they make.",
                    "label": 0
                },
                {
                    "sent": "So this idea then that people are doing something more like structure learning when they are evaluating these relationships rather than thinking in terms of parameter estimation, is an interesting one, and it seems like it actually captures some of the variance in the data.",
                    "label": 0
                },
                {
                    "sent": "Here we've gone on to do other experiments showing that it can explain a pretty broad range of datasets.",
                    "label": 0
                },
                {
                    "sent": "There are also cases where people do something which is more clearly related to structure learning, and you can basically ask people different kinds of questions about causal relationships, and some of them tap inferences about structure.",
                    "label": 0
                },
                {
                    "sent": "And others tap inferences about parameter estimation, and I can tell you some more about that if you're curious what I'm going to do now is just sort of explore the assumptions behind our model which make.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Possible to get this good fit to the data?",
                    "label": 0
                },
                {
                    "sent": "Well, one way of exploring whether a particular assumption is necessary is taking it away, and the big assumption that we made in terms of formulating this model was an assumption about this conditional probability.",
                    "label": 0
                },
                {
                    "sent": "The probability effect in the presence of the cause or in the presence of these.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Variables, So what we could do is take that away instead of using the noisy or parameterisation we could just use a generic Bernoulli beta model, or a multinomial Dirichlet model.",
                    "label": 0
                },
                {
                    "sent": "This is the standard sort of model which is assumed in.",
                    "label": 0
                },
                {
                    "sent": "In most Bayesian structure learning that's done in machine learning where what we do is we just associate.",
                    "label": 0
                },
                {
                    "sent": "We say rather than having a strength associated with each of those relationships.",
                    "label": 0
                },
                {
                    "sent": "Now we use our parameters to just describe the probability effect in the presence in the absence of the cause and the configuration of the parents of this node is going to be associated with a separate parameter which just describes that probability.",
                    "label": 0
                },
                {
                    "sent": "So now you know what we're trying to do is workout.",
                    "label": 0
                },
                {
                    "sent": "There's basically this is all this is asserting is that there's a dependency in this distribution where.",
                    "label": 0
                },
                {
                    "sent": "You can have a different probability depending on the values of the parents of this node in the graph, so this could be .8 and this could be .2 and point 1.9.",
                    "label": 0
                },
                {
                    "sent": "There's no particular relationship that is implied by having a causal link, just that the distribution of the effect differs depending on the values of the background cores and the other costs are variable.",
                    "label": 0
                },
                {
                    "sent": "So I call this a generic parameterisation, 'cause it makes basically no assumptions about the nature of that causal relationship.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you take that generic model, what happens?",
                    "label": 0
                },
                {
                    "sent": "Is it no longer fits the data?",
                    "label": 0
                },
                {
                    "sent": "So if you do exactly the same math, you just integrate over all of your parameters and do all of those things, you don't get something that looks like human judgments, so you can.",
                    "label": 0
                },
                {
                    "sent": "You know I can go back and compare this if you want, but you can see very clearly that for example, it's failing to produce that effect that I was pointing out where basically as the baseline probability of the effect increased in the human data, we saw an increase in people's judgments, whereas we don't see that relationship being expressed here.",
                    "label": 0
                },
                {
                    "sent": "Instead, there's this kind of.",
                    "label": 0
                },
                {
                    "sent": "Nonlinear relationship between the baseline probability and the judgment of the assessment of causal relationship.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that in order to explain the human data, this assumption that causes increase the probability of their effects, which is the assumption that's built into the noisy or is actually a necessary assumption.",
                    "label": 1
                },
                {
                    "sent": "We need that assumption in order to explain the human data.",
                    "label": 0
                },
                {
                    "sent": "I understand where.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The way that that's working, if I just go back to that graph, what's going on here?",
                    "label": 0
                },
                {
                    "sent": "Is that as this baseline probability increases, people's judgments increase.",
                    "label": 0
                },
                {
                    "sent": "The reason why this is a rational inference.",
                    "label": 0
                },
                {
                    "sent": "If you believe that causes increase the probability of their effects, is that if you think about it, this is a case where, in the absence of the cores, none of the time was the effect expressed, and none of the time the effect was expressed in the presence of the course.",
                    "label": 0
                },
                {
                    "sent": "That's actually pretty good evidence that there's not a causal relationship, right?",
                    "label": 0
                },
                {
                    "sent": "You can kind of think about this in this experiment.",
                    "label": 0
                },
                {
                    "sent": "There were sort of H opportunities.",
                    "label": 0
                },
                {
                    "sent": "These contingencies were calculated out of.",
                    "label": 0
                },
                {
                    "sent": "8 trials so this was, you know, a situation where there were eight chances for the cause to express itself, and it didn't express itself on any of those, and so that's a pretty good sort of suggestion that there might not be a relationship.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you look over here here, the probability effect in the absence of the course was one.",
                    "label": 0
                },
                {
                    "sent": "And the probability effect in the presence of the course was one.",
                    "label": 0
                },
                {
                    "sent": "But if the effect is already occurring all the time, there's no opportunity for the cause to influence the effect, and as a consequence you can't make any inference from the data that you've got.",
                    "label": 0
                },
                {
                    "sent": "And so basically what's going on is as the dynamic range in which the cause can express itself.",
                    "label": 0
                },
                {
                    "sent": "Is increasing.",
                    "label": 0
                },
                {
                    "sent": "Then the fact that it didn't express itself as it gets more and more opportunities.",
                    "label": 0
                },
                {
                    "sent": "But the fact that it didn't express itself is.",
                    "label": 0
                },
                {
                    "sent": "It gives it sort of more and more damning evidence against the causal relationship, and that's why our model says, you know.",
                    "label": 0
                },
                {
                    "sent": "Here I've got pretty good evidence against the causal relationship and what's going on.",
                    "label": 0
                },
                {
                    "sent": "Is that here?",
                    "label": 0
                },
                {
                    "sent": "I'm just sort of completely uncertain, and I'm just going to fall to my prior assumption, which in this case was 5050.",
                    "label": 0
                },
                {
                    "sent": "As to whether there was a relationship or default to my prior and so I'll give this sort of intermediate judgment and then what's going on is you're getting more and more evidence against a causal relationship as you go down here.",
                    "label": 0
                },
                {
                    "sent": "Well, that only works if you assume that causes generative.",
                    "label": 0
                },
                {
                    "sent": "That causes increased the probability of their effects.",
                    "label": 0
                },
                {
                    "sent": "And so if you don't make that assumption, then you know something like this isn't necessarily a problem, because it could be that the cause decreases the probability of the effect, and you've got lots of opportunities to observe that if I go.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Back to the generic model.",
                    "label": 0
                },
                {
                    "sent": "The reason why it produces this trend is that if you don't have any assumption that causes increase, the probability of their effects, the least diagnostic cases, the middle case, because that's the one where the variance is highest.",
                    "label": 0
                },
                {
                    "sent": "But these two extremes you've got equally good opportunities to evaluate whether there is a relationship that exists.",
                    "label": 0
                },
                {
                    "sent": "So basically what we take away from this is that people have strong intuitions about the nature of causality, and those intuitions go beyond just statistical dependency.",
                    "label": 1
                },
                {
                    "sent": "So if you just taken off the shelf Bayes net learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "That you know tries to learn the structure of a Bayesian network and uses those generic assumptions about the conditional probability distributions.",
                    "label": 0
                },
                {
                    "sent": "It's not going to look like human learning, part of what makes people good at evaluating these kinds of causal relationships.",
                    "label": 0
                },
                {
                    "sent": "Comes out of the assumptions that we make about what it means for something to be a causal relationship.",
                    "label": 1
                },
                {
                    "sent": "And here one of those assumptions is that causes increased the probability of their effects.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I'm going to use a little bit of cognitive psychology, so one of the things that we know in cognitive psychology is that there's a U shape retention curve for information.",
                    "label": 0
                },
                {
                    "sent": "So what that means is that the things that you see at the start of a lecture and the things that you see at the end of a lecture of the things that you retain best, and the things that are in the middle, they just disappear into nowhere.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is we're going to simulate, will do a little bit of optimization.",
                    "label": 0
                },
                {
                    "sent": "So if we have instead of having one big U shaped curve, I'm going to break it up into two U shaped curves.",
                    "label": 0
                },
                {
                    "sent": "So you'll have a greater opportunity to retain information, so let's take a two minute break everyone.",
                    "label": 0
                }
            ]
        }
    }
}