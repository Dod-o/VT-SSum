{
    "id": "wdjfmiwtug32ntdzggguk3ghpb2ghyh2",
    "title": "Top-down Neural Attention by Excitation Backprop",
    "info": {
        "author": [
            "Stan Sclaroff, Department of Computer Science, Boston University"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_sclaroff_excitation_backprop/",
    "segmentation": [
        [
            "So I'll be presenting the paper on behalf of my graduate student who just graduated John Mingxing, who took a position at Adobe and this is in collaboration with folks at Adobe where he was an intern."
        ],
        [
            "Artificial neural network network models are becoming more and more powerful.",
            "We use them to recognize objects, generic captions and even tell stories.",
            "Can these mods?"
        ],
        [
            "Ground their own predictions.",
            "A number of researchers are pursuing this question, as are we.",
            "The basic idea or the goal that we have is as follows.",
            "Given the input to a particular CNN model of interest, we run bottom up in inference with a particular input.",
            "Let's say this image of a.",
            "Elephant.",
            "Oh sorry.",
            "This is not gonna work.",
            "I'm gonna have to wait.",
            "OK so.",
            "Let me just show you this slide so.",
            "Can we ground these these outputs in the image evidence?"
        ],
        [
            "So the basic idea in our approaches that we're given a CNN model and we want to given a particular input that flows through this model and give us an output."
        ],
        [
            "We want to ground the result in the evidence.",
            "OK, so for instance, let's say we want to know what evidence in this image supports the class elephant.",
            "We're going to have a top down attention scheme.",
            "Which will tell us what parts of the stimulus led to that particular class."
        ],
        [
            "Or let's say we're interested in knowing what parts of the image give rise to the zebra class.",
            "OK, so given a single input.",
            "And running it through in the bottom up inference we want to then do top down attention to determine what is discriminative in that input for each of the different classes of interest.",
            "OK, so that's given a particular CNN and this works for various types of CNN models, as we'll see."
        ],
        [
            "So of course there's a lot of related work in this area and I'm just going to group it into four different main areas.",
            "There are masking braced approaches which mask out various parts of the stimulus.",
            "The inputs, and also parts of the layers to determine what's responsible for the score of a particular class by the model.",
            "There are optimization based approaches.",
            "There are fully convolutional based approaches, which have been quite competitive recently.",
            "Our approach is a backdrop based approach.",
            "It has the advantages that it's general and that is applicable to a wide variety of of deep neural networks, and it's simple in that it can generate an attention map in a single backward pass."
        ],
        [
            "So the contributions of our paper are as follows.",
            "We propose a new backpropagation based method for generating attention Maps.",
            "We call it excitation.",
            "Backdrop is based on the biologically inspired selective tuning model of visual attention.",
            "We propose a probabilistic winner.",
            "Take all scheme that is applicable to modern deep neural networks.",
            "In addition, we propose a new method called contrast contrastive top down attention that significantly improves the results and the discriminative Ness of the attention Maps that we're able to produce.",
            "For instance, you can see the output for this particular image and the attention Maps that are generated, and using our model it's able to localize the small objects like the glass.",
            "And also fine grained classes like the boy, the woman and the man.",
            "So we start with an inspiration from an older man."
        ],
        [
            "Model that was proposed in literature bizos at all.",
            "It's called the selective tuning model.",
            "So we start with a forward.",
            "The traditional forward pass through the model to compute the feature values and the activations at the layers within the model.",
            "Then we're interested in doing a backward pass to determine and localize the relevant regions for a particular class given this model.",
            "This model."
        ],
        [
            "Has certain advantages and disadvantages the disadvantage for deep networks is that it's a greedy algorithm and only identifies one path through the graph and it's winner take all in that sense, it produces very sparse binary map and only uses a small portion of the network."
        ],
        [
            "In our approach, we take a winner sampling approach, so it's a probabilistic approach.",
            "So instead of finding the one path through the graph, what we do is we evaluate the probability of taking all of the possible paths through this graph for the network.",
            "So in essence, we're sampling winner paths on the model itself, and so the shading of the vertices in that graph correspond to the.",
            "The probabilities that will compute.",
            "So this can be expressed mathematically pretty simply in terms of marginal winning probability shown here.",
            "So if you look at the preceding layer and then the flow to the next layer, it's a simple conditional times prior over the previous layer.",
            "OK.",
            "So the assumption."
        ],
        [
            "Of our approach are as follows.",
            "The responses of the activation neurons are going to be non negative and this is there are many activation functions for which this is true.",
            "In modern modern neural networks.",
            "In addition, we're going to assume that an activation neuron is tuned to detect certain visual features, and so its response is going to be positively correlated to its confidence of the detection.",
            "One key element of our approach is we're going to assume that there are excitatory neurons, the ones that have positive weights for the connections between the layers, and then they're going to be inhibitory neurons that have negative weights.",
            "And so we're going to express the probability of moving from one layer to the next along one of these weighted connections as follows, moving from.",
            "From one layer to another we have AJ which is the activation of a particular element or sorry activation at a particular.",
            "Node in the network and then the weight, which is the weight of the connection times the normalizing constant so you can see that this actually produces a valid probability distribution.",
            "Using."
        ],
        [
            "Citation backdrop we can extract attention Maps from different layers in the model, so the lower layers can generate Maps that highlight features that is smaller scale.",
            "As you can see, for this example image."
        ],
        [
            "There is one challenge though, and it's a common challenge with back propagation methods for generating attention Maps, and the problem is as follows.",
            "You notice that there's an attention map for zebra and elephant, and they look very similar, and when we first saw this we were quite sceptical.",
            "We thought that there was a bug and we looked more closely at these images and we notice that there are actually subtle variant variations in the two outputs and the reason for this.",
            "Is that the Dom?"
        ],
        [
            "Wouldn't neurons within the deep networks have a tendency to dominate the output for these Maps?",
            "So one way to address this is to actually generate, so in one backward pass we generate the."
        ],
        [
            "Map as before, but we can actually generate."
        ],
        [
            "A non zebra map by negating the."
        ],
        [
            "Output layer and we get a contrastive signal.",
            "Take the difference of those two and then we get a contrastive map.",
            "So."
        ],
        [
            "Here are the two example contrasted Maps that were obtained using this type of an approach.",
            "The negative values are truncated to zero and the image values are rescaled for visualization.",
            "The contrasted tension map can be computed by a single pass.",
            "In our model."
        ],
        [
            "And one thing I guess I neglected to mention because of the slides at the beginning is that the this particular model that we're talking about.",
            "Corresponds to an absorbing Markov chain, and so this would mean that we can actually express the computations in terms of simple linear operations, which you can read about in our supplementary supplemental material for the paper.",
            "So what I'd like to do is now describe some of the experiments that we've conducted.",
            "The experiments that we conduct are called the pointing game.",
            "So imagine you're reading a book to a child and you ask the child to point at the different places in an image that correspond to the different objects of interest.",
            "So given an image, you're to point at the targets and the evaluation metric is the mean pointing accuracy across categories.",
            "Pointing anywhere on targets is fine, and we test with three different commonly used models.",
            "The model training is as follows.",
            "We use the multi label cross entropy loss and we do not use any of the localization annotations."
        ],
        [
            "So here are results on pass on the VOC seven data set you will see that our results are shown with the blue bars in the graph.",
            "There is also a center baseline which is shown in the green bar on the graph and what you see here is that the center baseline does pretty well on this data set and the reason for that is that there are tend to be large objects in many of these images that tend to be centered.",
            "So this is a relatively easy data set.",
            "We compare it against a number of competing methods.",
            "As you can see in the red bars in this graph.",
            "So you can see that the contrastive version of our method outperforms the leading methods by about 4% on this data set, and even without using the contrastive mapping, we can do pretty well."
        ],
        [
            "On a more challenging data set, Ms Coco and using the Google Net.",
            "CNN.",
            "Here are some results.",
            "You see that the baseline that uses the center doesn't work as well, and the reason for this is that there are multiple objects.",
            "There are small ones, there are large ones, and they tend not to be centered all the time.",
            "So you can see here that our method with contrastive mapping does a full 10% better than the other methods that we compared against.",
            "On this data set."
        ],
        [
            "So here's a qualitative comparison.",
            "You can see the ground truth with the red bounding boxes around the objects of interest in the left hand column.",
            "There's a Frisbee in a dog and you could see the output Maps given from our method for this particular model you can see also compare comparison of the results for some other approaches for generating these attention Maps and what you note about hours is that it's a very tightly focused on the small objects and for grad.",
            "For instance, you see that the tension Maps are essentially.",
            "Very similar and spread out."
        ],
        [
            "Here's another qualitative comparison, and again, there's a stop sign and a fire hydrant, and you can see our results versus the results of the other methods."
        ],
        [
            "Alright, so in the second experiment that I'd like to describe, we've we've used our approach.",
            "With a with a CNN that's trained with 18,000 different image tags, so these are distinct image tags.",
            "Using a stock photo set that has been tagged with multiple tags.",
            "There are 6 million images in that stock photo set.",
            "Its pre trained.",
            "We use the pre trained googlenet model.",
            "To add to.",
            "As a starting point for training, and we use the cross entropy multi multi label loss in training.",
            "So given 18,000 tags we can for any word in a particular caption almost any word in a particular caption.",
            "We can produce the attention map.",
            "I so as you see here, we can produce the attention map for the woman, the boy.",
            "The cookie also interesting attention map for the running.",
            "You see that the legs and the runners body are lit up."
        ],
        [
            "But here's an interesting case.",
            "So here we have fine grained classification are fine grained localization for woman, man and couple for Father.",
            "What we find in this data set is that it highlights children because I guess for the people who were annotating the training set that we used with label and image as having a father in it.",
            "If there was also a child.",
            "So what this method is doing is this discovering?",
            "What are the discriminative elements of the input that give rise to that particular class being present?",
            "Alright, so we finally."
        ],
        [
            "We use this for phrase localization using the Flickr 3000 data set, and we use localization based on top down attention Maps.",
            "I won't go into the details of this because I'm running short on time, but you can come to our poster and see this in more detail.",
            "But it's very interesting to see.",
            "Just comment on our results versus CCA that we don't use any localization information in our training and we get results which are comperable.",
            "Or better."
        ],
        [
            "Alright, so to conclude, we propose excitation backdrop and contrast of attention to generate discriminative top down attention Maps.",
            "And the code is available at the website that you see here, and it runs both on GPU and CPU.",
            "So thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll be presenting the paper on behalf of my graduate student who just graduated John Mingxing, who took a position at Adobe and this is in collaboration with folks at Adobe where he was an intern.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Artificial neural network network models are becoming more and more powerful.",
                    "label": 1
                },
                {
                    "sent": "We use them to recognize objects, generic captions and even tell stories.",
                    "label": 0
                },
                {
                    "sent": "Can these mods?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ground their own predictions.",
                    "label": 0
                },
                {
                    "sent": "A number of researchers are pursuing this question, as are we.",
                    "label": 0
                },
                {
                    "sent": "The basic idea or the goal that we have is as follows.",
                    "label": 0
                },
                {
                    "sent": "Given the input to a particular CNN model of interest, we run bottom up in inference with a particular input.",
                    "label": 0
                },
                {
                    "sent": "Let's say this image of a.",
                    "label": 0
                },
                {
                    "sent": "Elephant.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry.",
                    "label": 0
                },
                {
                    "sent": "This is not gonna work.",
                    "label": 0
                },
                {
                    "sent": "I'm gonna have to wait.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Let me just show you this slide so.",
                    "label": 0
                },
                {
                    "sent": "Can we ground these these outputs in the image evidence?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the basic idea in our approaches that we're given a CNN model and we want to given a particular input that flows through this model and give us an output.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to ground the result in the evidence.",
                    "label": 0
                },
                {
                    "sent": "OK, so for instance, let's say we want to know what evidence in this image supports the class elephant.",
                    "label": 0
                },
                {
                    "sent": "We're going to have a top down attention scheme.",
                    "label": 0
                },
                {
                    "sent": "Which will tell us what parts of the stimulus led to that particular class.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or let's say we're interested in knowing what parts of the image give rise to the zebra class.",
                    "label": 0
                },
                {
                    "sent": "OK, so given a single input.",
                    "label": 0
                },
                {
                    "sent": "And running it through in the bottom up inference we want to then do top down attention to determine what is discriminative in that input for each of the different classes of interest.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's given a particular CNN and this works for various types of CNN models, as we'll see.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So of course there's a lot of related work in this area and I'm just going to group it into four different main areas.",
                    "label": 0
                },
                {
                    "sent": "There are masking braced approaches which mask out various parts of the stimulus.",
                    "label": 0
                },
                {
                    "sent": "The inputs, and also parts of the layers to determine what's responsible for the score of a particular class by the model.",
                    "label": 0
                },
                {
                    "sent": "There are optimization based approaches.",
                    "label": 0
                },
                {
                    "sent": "There are fully convolutional based approaches, which have been quite competitive recently.",
                    "label": 0
                },
                {
                    "sent": "Our approach is a backdrop based approach.",
                    "label": 0
                },
                {
                    "sent": "It has the advantages that it's general and that is applicable to a wide variety of of deep neural networks, and it's simple in that it can generate an attention map in a single backward pass.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the contributions of our paper are as follows.",
                    "label": 0
                },
                {
                    "sent": "We propose a new backpropagation based method for generating attention Maps.",
                    "label": 0
                },
                {
                    "sent": "We call it excitation.",
                    "label": 0
                },
                {
                    "sent": "Backdrop is based on the biologically inspired selective tuning model of visual attention.",
                    "label": 1
                },
                {
                    "sent": "We propose a probabilistic winner.",
                    "label": 1
                },
                {
                    "sent": "Take all scheme that is applicable to modern deep neural networks.",
                    "label": 0
                },
                {
                    "sent": "In addition, we propose a new method called contrast contrastive top down attention that significantly improves the results and the discriminative Ness of the attention Maps that we're able to produce.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can see the output for this particular image and the attention Maps that are generated, and using our model it's able to localize the small objects like the glass.",
                    "label": 0
                },
                {
                    "sent": "And also fine grained classes like the boy, the woman and the man.",
                    "label": 0
                },
                {
                    "sent": "So we start with an inspiration from an older man.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model that was proposed in literature bizos at all.",
                    "label": 0
                },
                {
                    "sent": "It's called the selective tuning model.",
                    "label": 1
                },
                {
                    "sent": "So we start with a forward.",
                    "label": 1
                },
                {
                    "sent": "The traditional forward pass through the model to compute the feature values and the activations at the layers within the model.",
                    "label": 1
                },
                {
                    "sent": "Then we're interested in doing a backward pass to determine and localize the relevant regions for a particular class given this model.",
                    "label": 0
                },
                {
                    "sent": "This model.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Has certain advantages and disadvantages the disadvantage for deep networks is that it's a greedy algorithm and only identifies one path through the graph and it's winner take all in that sense, it produces very sparse binary map and only uses a small portion of the network.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our approach, we take a winner sampling approach, so it's a probabilistic approach.",
                    "label": 1
                },
                {
                    "sent": "So instead of finding the one path through the graph, what we do is we evaluate the probability of taking all of the possible paths through this graph for the network.",
                    "label": 0
                },
                {
                    "sent": "So in essence, we're sampling winner paths on the model itself, and so the shading of the vertices in that graph correspond to the.",
                    "label": 0
                },
                {
                    "sent": "The probabilities that will compute.",
                    "label": 1
                },
                {
                    "sent": "So this can be expressed mathematically pretty simply in terms of marginal winning probability shown here.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the preceding layer and then the flow to the next layer, it's a simple conditional times prior over the previous layer.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the assumption.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of our approach are as follows.",
                    "label": 0
                },
                {
                    "sent": "The responses of the activation neurons are going to be non negative and this is there are many activation functions for which this is true.",
                    "label": 0
                },
                {
                    "sent": "In modern modern neural networks.",
                    "label": 0
                },
                {
                    "sent": "In addition, we're going to assume that an activation neuron is tuned to detect certain visual features, and so its response is going to be positively correlated to its confidence of the detection.",
                    "label": 1
                },
                {
                    "sent": "One key element of our approach is we're going to assume that there are excitatory neurons, the ones that have positive weights for the connections between the layers, and then they're going to be inhibitory neurons that have negative weights.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to express the probability of moving from one layer to the next along one of these weighted connections as follows, moving from.",
                    "label": 0
                },
                {
                    "sent": "From one layer to another we have AJ which is the activation of a particular element or sorry activation at a particular.",
                    "label": 0
                },
                {
                    "sent": "Node in the network and then the weight, which is the weight of the connection times the normalizing constant so you can see that this actually produces a valid probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Using.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Citation backdrop we can extract attention Maps from different layers in the model, so the lower layers can generate Maps that highlight features that is smaller scale.",
                    "label": 0
                },
                {
                    "sent": "As you can see, for this example image.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is one challenge though, and it's a common challenge with back propagation methods for generating attention Maps, and the problem is as follows.",
                    "label": 0
                },
                {
                    "sent": "You notice that there's an attention map for zebra and elephant, and they look very similar, and when we first saw this we were quite sceptical.",
                    "label": 0
                },
                {
                    "sent": "We thought that there was a bug and we looked more closely at these images and we notice that there are actually subtle variant variations in the two outputs and the reason for this.",
                    "label": 0
                },
                {
                    "sent": "Is that the Dom?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wouldn't neurons within the deep networks have a tendency to dominate the output for these Maps?",
                    "label": 0
                },
                {
                    "sent": "So one way to address this is to actually generate, so in one backward pass we generate the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Map as before, but we can actually generate.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A non zebra map by negating the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Output layer and we get a contrastive signal.",
                    "label": 1
                },
                {
                    "sent": "Take the difference of those two and then we get a contrastive map.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are the two example contrasted Maps that were obtained using this type of an approach.",
                    "label": 0
                },
                {
                    "sent": "The negative values are truncated to zero and the image values are rescaled for visualization.",
                    "label": 1
                },
                {
                    "sent": "The contrasted tension map can be computed by a single pass.",
                    "label": 1
                },
                {
                    "sent": "In our model.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one thing I guess I neglected to mention because of the slides at the beginning is that the this particular model that we're talking about.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to an absorbing Markov chain, and so this would mean that we can actually express the computations in terms of simple linear operations, which you can read about in our supplementary supplemental material for the paper.",
                    "label": 0
                },
                {
                    "sent": "So what I'd like to do is now describe some of the experiments that we've conducted.",
                    "label": 0
                },
                {
                    "sent": "The experiments that we conduct are called the pointing game.",
                    "label": 0
                },
                {
                    "sent": "So imagine you're reading a book to a child and you ask the child to point at the different places in an image that correspond to the different objects of interest.",
                    "label": 0
                },
                {
                    "sent": "So given an image, you're to point at the targets and the evaluation metric is the mean pointing accuracy across categories.",
                    "label": 1
                },
                {
                    "sent": "Pointing anywhere on targets is fine, and we test with three different commonly used models.",
                    "label": 0
                },
                {
                    "sent": "The model training is as follows.",
                    "label": 0
                },
                {
                    "sent": "We use the multi label cross entropy loss and we do not use any of the localization annotations.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are results on pass on the VOC seven data set you will see that our results are shown with the blue bars in the graph.",
                    "label": 0
                },
                {
                    "sent": "There is also a center baseline which is shown in the green bar on the graph and what you see here is that the center baseline does pretty well on this data set and the reason for that is that there are tend to be large objects in many of these images that tend to be centered.",
                    "label": 0
                },
                {
                    "sent": "So this is a relatively easy data set.",
                    "label": 0
                },
                {
                    "sent": "We compare it against a number of competing methods.",
                    "label": 0
                },
                {
                    "sent": "As you can see in the red bars in this graph.",
                    "label": 0
                },
                {
                    "sent": "So you can see that the contrastive version of our method outperforms the leading methods by about 4% on this data set, and even without using the contrastive mapping, we can do pretty well.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On a more challenging data set, Ms Coco and using the Google Net.",
                    "label": 1
                },
                {
                    "sent": "CNN.",
                    "label": 0
                },
                {
                    "sent": "Here are some results.",
                    "label": 0
                },
                {
                    "sent": "You see that the baseline that uses the center doesn't work as well, and the reason for this is that there are multiple objects.",
                    "label": 0
                },
                {
                    "sent": "There are small ones, there are large ones, and they tend not to be centered all the time.",
                    "label": 0
                },
                {
                    "sent": "So you can see here that our method with contrastive mapping does a full 10% better than the other methods that we compared against.",
                    "label": 0
                },
                {
                    "sent": "On this data set.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a qualitative comparison.",
                    "label": 0
                },
                {
                    "sent": "You can see the ground truth with the red bounding boxes around the objects of interest in the left hand column.",
                    "label": 0
                },
                {
                    "sent": "There's a Frisbee in a dog and you could see the output Maps given from our method for this particular model you can see also compare comparison of the results for some other approaches for generating these attention Maps and what you note about hours is that it's a very tightly focused on the small objects and for grad.",
                    "label": 0
                },
                {
                    "sent": "For instance, you see that the tension Maps are essentially.",
                    "label": 0
                },
                {
                    "sent": "Very similar and spread out.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another qualitative comparison, and again, there's a stop sign and a fire hydrant, and you can see our results versus the results of the other methods.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so in the second experiment that I'd like to describe, we've we've used our approach.",
                    "label": 0
                },
                {
                    "sent": "With a with a CNN that's trained with 18,000 different image tags, so these are distinct image tags.",
                    "label": 0
                },
                {
                    "sent": "Using a stock photo set that has been tagged with multiple tags.",
                    "label": 0
                },
                {
                    "sent": "There are 6 million images in that stock photo set.",
                    "label": 0
                },
                {
                    "sent": "Its pre trained.",
                    "label": 0
                },
                {
                    "sent": "We use the pre trained googlenet model.",
                    "label": 1
                },
                {
                    "sent": "To add to.",
                    "label": 1
                },
                {
                    "sent": "As a starting point for training, and we use the cross entropy multi multi label loss in training.",
                    "label": 0
                },
                {
                    "sent": "So given 18,000 tags we can for any word in a particular caption almost any word in a particular caption.",
                    "label": 0
                },
                {
                    "sent": "We can produce the attention map.",
                    "label": 0
                },
                {
                    "sent": "I so as you see here, we can produce the attention map for the woman, the boy.",
                    "label": 0
                },
                {
                    "sent": "The cookie also interesting attention map for the running.",
                    "label": 0
                },
                {
                    "sent": "You see that the legs and the runners body are lit up.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But here's an interesting case.",
                    "label": 0
                },
                {
                    "sent": "So here we have fine grained classification are fine grained localization for woman, man and couple for Father.",
                    "label": 0
                },
                {
                    "sent": "What we find in this data set is that it highlights children because I guess for the people who were annotating the training set that we used with label and image as having a father in it.",
                    "label": 0
                },
                {
                    "sent": "If there was also a child.",
                    "label": 0
                },
                {
                    "sent": "So what this method is doing is this discovering?",
                    "label": 0
                },
                {
                    "sent": "What are the discriminative elements of the input that give rise to that particular class being present?",
                    "label": 0
                },
                {
                    "sent": "Alright, so we finally.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use this for phrase localization using the Flickr 3000 data set, and we use localization based on top down attention Maps.",
                    "label": 1
                },
                {
                    "sent": "I won't go into the details of this because I'm running short on time, but you can come to our poster and see this in more detail.",
                    "label": 0
                },
                {
                    "sent": "But it's very interesting to see.",
                    "label": 0
                },
                {
                    "sent": "Just comment on our results versus CCA that we don't use any localization information in our training and we get results which are comperable.",
                    "label": 0
                },
                {
                    "sent": "Or better.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so to conclude, we propose excitation backdrop and contrast of attention to generate discriminative top down attention Maps.",
                    "label": 0
                },
                {
                    "sent": "And the code is available at the website that you see here, and it runs both on GPU and CPU.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        }
    }
}