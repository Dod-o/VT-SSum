{
    "id": "gektlugm6gf36la4wjytrvlhmcnjba4a",
    "title": "RDF Ontology (Re-)Engineering through Large-scale Data Mining",
    "info": {
        "author": [
            "Christoph Bohm, Hasso-Plattner-Institute, University of Potsdam"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Semantic Web->Ontologies",
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework"
        ]
    },
    "url": "http://videolectures.net/iswc2011_bohm_ontology/",
    "segmentation": [
        [
            "So hello everybody, I'm crystal from his apartment.",
            "He didn't put some and I'll present our contribution for this year's billion Triple Challenge track, which has mainly been done by Johannesen Savage, but also been authored by Felix and me."
        ],
        [
            "What's the underlying motivation?",
            "So first of all, we discovered that there is ontology specifications as they are given by engineers, so those are plain specification.",
            "But then on the other hand we have ontology usage as it has been done by publishers by different publishers.",
            "So in this example up here we can see that if a person, for instance has names also has decodes and predicates like Myers Briggs, but people never use this.",
            "But on the other hand they add other predicates like predicates from a IMDb or from Perl.",
            "And they don't do it in the same way they do it in different ways.",
            "So there is a divergance here.",
            "Whenever now a third person comes into play and tries to integrate, integrate the data.",
            "Then they should struggle hard to do it since they are expecting predicates that are specified in the original."
        ],
        [
            "Elogy so we identified two basic misconcept misconceptions here which we call over and under."
        ],
        [
            "Suffication so the over specification is whenever the specification of the on top of the class and the ontology has predicates that never occur in the instance data.",
            "So why should this happen?",
            "Reasons for this might include that publishers are simply unaware of specific attributes or they feel that the predicates that are specified are simply ambiguous or unfitting for their needs.",
            "And what do?"
        ],
        [
            "Call underspecification is if.",
            "Alaji class specifications don't include classes that publishers actually use, and the reasons for these might include that publishers simply include include new attributes even though existing ones might exist and are suitable.",
            "Also, the ontology different might.",
            "The ontology definition might simply lack these properties.",
            "So in this case up here, one has edit Pearl, neighbor of and Pearl neighbor."
        ],
        [
            "Lives in.",
            "And to approach this issue, we have a simple yet effective instance data driven approach where we first do some predicate frequency analysis and then run some Association rule mining on the predicates.",
            "These predicate frequencies and these Association rules then help us in a third step to match those anthology specifications against the class.",
            "Know those ontology class definitions against those observations we made and talking bout Association rules.",
            "There's two types of rules.",
            "First of all, we have positive rules where we can say OK, those predicates usually Co occur frequently.",
            "On the other hand, there's negative rules which say, OK, these.",
            "But it's never occur together in the examples here.",
            "Whenever we have a fourth gender, we never have a folk know.",
            "We always have a full web log, but on the other hand, whenever we have a full web log, we never find the home page.",
            "That's the negative rule, the second one."
        ],
        [
            "OK, so here's the workflow as we've treated the data so we were given a dump.",
            "We've expected all the types and then given all these types, we've done two things.",
            "So first we've extracted all the class definitions that what we can see on the left hand side, and for this we've parsed the data set the second time.",
            "But we've also done your eye look ups on the web to complete the data set and on the right hand side you can see that we've extracted all the typed entities from the data, and then given these typed entities from the data, we've run the predicate analysis.",
            "And the Association rules mining for the room mining.",
            "We have used a state of the art algorithm called FP growth.",
            "Yeah, and given those two things, those predicates, statistics and Association rules, and we can then in the last step try to match the specifications of the classes in the ontology with those observations instead."
        ],
        [
            "I had OK, so here's the data.",
            "How did it look like so we were given almost half a TB of uncompressed data, so this is a little less than last years building triple Challenge data set and this data set comprises more than 200,000 RDF triples.",
            "No, not have triplets.",
            "More than 10,000 RDF types.",
            "Distinct types.",
            "Which type more than 440,000, no more than 414 million instances, which is really interesting too, as is even though we did this.",
            "Extra UI look up some classes.",
            "This would actually not necessary since we could find approximately 90% of the class definitions on for the instances for the typed instances in the BDC data set given these instances.",
            "And we run our approach for the most frequent types, so Please note that we can run our approach on any type, but we picked the most frequent ones since.",
            "First of all we think they are the most prominent and as interesting ones.",
            "And also we think that whenever we use less frequent ones, they might stem from fewer sources, which is less system."
        ],
        [
            "Interesting then OK, so at which types that we look at.",
            "So for instance, for instance we looked at persons of which we found more than 360 million we looked at online accounts, documents, statements.",
            "But also we looked at musical artists and agents and so on and looking a little closer at 4th person, we've found that almost all of them have this 4th Nick predicate.",
            "This predicate is still in testing status.",
            "OK, so here one might think whether the status should be revised.",
            "On the other hand, we found that a large portion contains member name, which is an undefined property, so nobody has ever defined this.",
            "The same holds for a property name tag line.",
            "And which is really odd is that another large portion contains an image property.",
            "Which is an actual misuse.",
            "Its usage since the image full image is a class which is there to specify information about images and the right use here would be the IMG predicate.",
            "And last but not least, we found that for the name as the most common property that has been used as the name property, even though there is the first name and the last name in the fourth person specification name stems from agent and overall we found it almost feels almost 4000 new properties have been added by publishers to the original 4th person specific."
        ],
        [
            "OK, and Please note that this observation these observations rely on the building Triple Challenge data set, so this is a crawl that contains data from many sources that are out there, so this is not just.",
            "Patterns that we observe on single sources those holes over many sources.",
            "Those are some sort of common miss you."
        ],
        [
            "Patterns.",
            "So let's look at some such reengineering suggestions that we propose.",
            "So given the 4th person, and though is underspecified, so here, now we are in the Overspecified case.",
            "Given the 4th person, and there are some predicates that are rarely used as Myers Bridge or decode, and obviously only one person has a plan, one can just remove those predicates.",
            "So in this case this is really simple, actually."
        ],
        [
            "In the second case, which is the underspecified case we found, for instance, for the online account that a large portion that has the 4th account name also has this new predicate, which is account of.",
            "But in this case is not as easy.",
            "You cannot simply add this predicate to the ontology, since you might cause fragmentation.",
            "With this.",
            "In this case it might."
        ],
        [
            "I want to consider the rules that we've also mined.",
            "And now, given a certain confidence which was oh point 8 in this case, we find that whenever you have an account name, we also find this account of predicate, so it should be safe to add this to the actual ontology."
        ],
        [
            "I have another example for under specification, which is the music artist from the Music Ontology and here one has added properties from the Musicbrainz Ontology or from Musicbrainz.",
            "Now in this case, considering the Association rules which are negative on the slide, here we find that whenever we have this instrumental artist of predicate, we never find his engineer off or is mixed engineer off.",
            "So is suitable reengineering suggestion would be in this case whynott splitting the class into two disjoint subclasses and then adding the respective.",
            "Properties OK."
        ],
        [
            "Let me wrap up really quick so we find certain divergance types between class definitions and class usage in the building.",
            "Triple Challenge data set, and in order to deal with it, we propose predicate frequency, which is simple but effective and Association rules.",
            "In order to suggest those ontology iterations and why do we do all this when we do all this in order to encourage reengineering ontology reengineering?",
            "Since these ontologies have been around for quite awhile and they could.",
            "Need some revision here and there and eventually in order to have better type data for the consumers.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everybody, I'm crystal from his apartment.",
                    "label": 0
                },
                {
                    "sent": "He didn't put some and I'll present our contribution for this year's billion Triple Challenge track, which has mainly been done by Johannesen Savage, but also been authored by Felix and me.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What's the underlying motivation?",
                    "label": 0
                },
                {
                    "sent": "So first of all, we discovered that there is ontology specifications as they are given by engineers, so those are plain specification.",
                    "label": 0
                },
                {
                    "sent": "But then on the other hand we have ontology usage as it has been done by publishers by different publishers.",
                    "label": 0
                },
                {
                    "sent": "So in this example up here we can see that if a person, for instance has names also has decodes and predicates like Myers Briggs, but people never use this.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand they add other predicates like predicates from a IMDb or from Perl.",
                    "label": 0
                },
                {
                    "sent": "And they don't do it in the same way they do it in different ways.",
                    "label": 0
                },
                {
                    "sent": "So there is a divergance here.",
                    "label": 0
                },
                {
                    "sent": "Whenever now a third person comes into play and tries to integrate, integrate the data.",
                    "label": 0
                },
                {
                    "sent": "Then they should struggle hard to do it since they are expecting predicates that are specified in the original.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elogy so we identified two basic misconcept misconceptions here which we call over and under.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suffication so the over specification is whenever the specification of the on top of the class and the ontology has predicates that never occur in the instance data.",
                    "label": 1
                },
                {
                    "sent": "So why should this happen?",
                    "label": 1
                },
                {
                    "sent": "Reasons for this might include that publishers are simply unaware of specific attributes or they feel that the predicates that are specified are simply ambiguous or unfitting for their needs.",
                    "label": 0
                },
                {
                    "sent": "And what do?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Call underspecification is if.",
                    "label": 0
                },
                {
                    "sent": "Alaji class specifications don't include classes that publishers actually use, and the reasons for these might include that publishers simply include include new attributes even though existing ones might exist and are suitable.",
                    "label": 1
                },
                {
                    "sent": "Also, the ontology different might.",
                    "label": 1
                },
                {
                    "sent": "The ontology definition might simply lack these properties.",
                    "label": 0
                },
                {
                    "sent": "So in this case up here, one has edit Pearl, neighbor of and Pearl neighbor.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lives in.",
                    "label": 0
                },
                {
                    "sent": "And to approach this issue, we have a simple yet effective instance data driven approach where we first do some predicate frequency analysis and then run some Association rule mining on the predicates.",
                    "label": 1
                },
                {
                    "sent": "These predicate frequencies and these Association rules then help us in a third step to match those anthology specifications against the class.",
                    "label": 0
                },
                {
                    "sent": "Know those ontology class definitions against those observations we made and talking bout Association rules.",
                    "label": 0
                },
                {
                    "sent": "There's two types of rules.",
                    "label": 1
                },
                {
                    "sent": "First of all, we have positive rules where we can say OK, those predicates usually Co occur frequently.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, there's negative rules which say, OK, these.",
                    "label": 0
                },
                {
                    "sent": "But it's never occur together in the examples here.",
                    "label": 0
                },
                {
                    "sent": "Whenever we have a fourth gender, we never have a folk know.",
                    "label": 0
                },
                {
                    "sent": "We always have a full web log, but on the other hand, whenever we have a full web log, we never find the home page.",
                    "label": 0
                },
                {
                    "sent": "That's the negative rule, the second one.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the workflow as we've treated the data so we were given a dump.",
                    "label": 0
                },
                {
                    "sent": "We've expected all the types and then given all these types, we've done two things.",
                    "label": 0
                },
                {
                    "sent": "So first we've extracted all the class definitions that what we can see on the left hand side, and for this we've parsed the data set the second time.",
                    "label": 0
                },
                {
                    "sent": "But we've also done your eye look ups on the web to complete the data set and on the right hand side you can see that we've extracted all the typed entities from the data, and then given these typed entities from the data, we've run the predicate analysis.",
                    "label": 0
                },
                {
                    "sent": "And the Association rules mining for the room mining.",
                    "label": 1
                },
                {
                    "sent": "We have used a state of the art algorithm called FP growth.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and given those two things, those predicates, statistics and Association rules, and we can then in the last step try to match the specifications of the classes in the ontology with those observations instead.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I had OK, so here's the data.",
                    "label": 0
                },
                {
                    "sent": "How did it look like so we were given almost half a TB of uncompressed data, so this is a little less than last years building triple Challenge data set and this data set comprises more than 200,000 RDF triples.",
                    "label": 0
                },
                {
                    "sent": "No, not have triplets.",
                    "label": 0
                },
                {
                    "sent": "More than 10,000 RDF types.",
                    "label": 1
                },
                {
                    "sent": "Distinct types.",
                    "label": 0
                },
                {
                    "sent": "Which type more than 440,000, no more than 414 million instances, which is really interesting too, as is even though we did this.",
                    "label": 0
                },
                {
                    "sent": "Extra UI look up some classes.",
                    "label": 0
                },
                {
                    "sent": "This would actually not necessary since we could find approximately 90% of the class definitions on for the instances for the typed instances in the BDC data set given these instances.",
                    "label": 0
                },
                {
                    "sent": "And we run our approach for the most frequent types, so Please note that we can run our approach on any type, but we picked the most frequent ones since.",
                    "label": 1
                },
                {
                    "sent": "First of all we think they are the most prominent and as interesting ones.",
                    "label": 0
                },
                {
                    "sent": "And also we think that whenever we use less frequent ones, they might stem from fewer sources, which is less system.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interesting then OK, so at which types that we look at.",
                    "label": 0
                },
                {
                    "sent": "So for instance, for instance we looked at persons of which we found more than 360 million we looked at online accounts, documents, statements.",
                    "label": 0
                },
                {
                    "sent": "But also we looked at musical artists and agents and so on and looking a little closer at 4th person, we've found that almost all of them have this 4th Nick predicate.",
                    "label": 0
                },
                {
                    "sent": "This predicate is still in testing status.",
                    "label": 0
                },
                {
                    "sent": "OK, so here one might think whether the status should be revised.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we found that a large portion contains member name, which is an undefined property, so nobody has ever defined this.",
                    "label": 1
                },
                {
                    "sent": "The same holds for a property name tag line.",
                    "label": 0
                },
                {
                    "sent": "And which is really odd is that another large portion contains an image property.",
                    "label": 0
                },
                {
                    "sent": "Which is an actual misuse.",
                    "label": 0
                },
                {
                    "sent": "Its usage since the image full image is a class which is there to specify information about images and the right use here would be the IMG predicate.",
                    "label": 0
                },
                {
                    "sent": "And last but not least, we found that for the name as the most common property that has been used as the name property, even though there is the first name and the last name in the fourth person specification name stems from agent and overall we found it almost feels almost 4000 new properties have been added by publishers to the original 4th person specific.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and Please note that this observation these observations rely on the building Triple Challenge data set, so this is a crawl that contains data from many sources that are out there, so this is not just.",
                    "label": 0
                },
                {
                    "sent": "Patterns that we observe on single sources those holes over many sources.",
                    "label": 0
                },
                {
                    "sent": "Those are some sort of common miss you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patterns.",
                    "label": 0
                },
                {
                    "sent": "So let's look at some such reengineering suggestions that we propose.",
                    "label": 0
                },
                {
                    "sent": "So given the 4th person, and though is underspecified, so here, now we are in the Overspecified case.",
                    "label": 0
                },
                {
                    "sent": "Given the 4th person, and there are some predicates that are rarely used as Myers Bridge or decode, and obviously only one person has a plan, one can just remove those predicates.",
                    "label": 0
                },
                {
                    "sent": "So in this case this is really simple, actually.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the second case, which is the underspecified case we found, for instance, for the online account that a large portion that has the 4th account name also has this new predicate, which is account of.",
                    "label": 0
                },
                {
                    "sent": "But in this case is not as easy.",
                    "label": 0
                },
                {
                    "sent": "You cannot simply add this predicate to the ontology, since you might cause fragmentation.",
                    "label": 0
                },
                {
                    "sent": "With this.",
                    "label": 0
                },
                {
                    "sent": "In this case it might.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to consider the rules that we've also mined.",
                    "label": 0
                },
                {
                    "sent": "And now, given a certain confidence which was oh point 8 in this case, we find that whenever you have an account name, we also find this account of predicate, so it should be safe to add this to the actual ontology.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have another example for under specification, which is the music artist from the Music Ontology and here one has added properties from the Musicbrainz Ontology or from Musicbrainz.",
                    "label": 0
                },
                {
                    "sent": "Now in this case, considering the Association rules which are negative on the slide, here we find that whenever we have this instrumental artist of predicate, we never find his engineer off or is mixed engineer off.",
                    "label": 0
                },
                {
                    "sent": "So is suitable reengineering suggestion would be in this case whynott splitting the class into two disjoint subclasses and then adding the respective.",
                    "label": 0
                },
                {
                    "sent": "Properties OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me wrap up really quick so we find certain divergance types between class definitions and class usage in the building.",
                    "label": 1
                },
                {
                    "sent": "Triple Challenge data set, and in order to deal with it, we propose predicate frequency, which is simple but effective and Association rules.",
                    "label": 0
                },
                {
                    "sent": "In order to suggest those ontology iterations and why do we do all this when we do all this in order to encourage reengineering ontology reengineering?",
                    "label": 0
                },
                {
                    "sent": "Since these ontologies have been around for quite awhile and they could.",
                    "label": 0
                },
                {
                    "sent": "Need some revision here and there and eventually in order to have better type data for the consumers.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}