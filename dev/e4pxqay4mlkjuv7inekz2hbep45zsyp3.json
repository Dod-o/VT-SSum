{
    "id": "e4pxqay4mlkjuv7inekz2hbep45zsyp3",
    "title": "Exploiting Duality in Summarization with Deterministic Guarantees",
    "info": {
        "author": [
            "Panagiotis Karras, The Hong Kong University of Science and Technology"
        ],
        "published": "Sept. 14, 2007",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd07_karras_edis/",
    "segmentation": [
        [
            "This talk will be about our work on the impact of duality on data synopsis problems, which is another title different from the one which appears in the proceedings just for variety.",
            "It was done with the Mirror Saint Nicholas at the University of Hong Kong."
        ],
        [
            "So that is an obvious problems which include summarization using histograms or using the hard wavelet transformation and have applications in many areas including data mining and databases.",
            "For example, for selectivity estimation for.",
            "Summarizing Internet traffic data so we asked which only recently?",
            "And many other applications, including social networks and wherever there is a large collection of data which has to be summarized so as to effectuate speed.",
            "At the price of a small error.",
            "So all these problems require the optimization of an error metric.",
            "Under a bound on the space used for the summary, that's the classical definition of the problems with all techniques which have been introduced so far, and the problems that we examine are always about the summarization of 1 dimensional data of sequences of numbers, which may represent any quantity.",
            "So the classical approach is for those problems through them in a straightforward manner.",
            "Trying to produce a solution which will calculate this optimal minimize error under the space.",
            "And usually these solutions are complicated.",
            "They feature complex dynamic programming schemes and that's why sometimes they also heuristics have been developed in order to make the algorithms to run faster.",
            "The basic idea that we introduced in this talk is that since the parameters involved in the problem have a monotonic relationship to each other, so the error is a monotonic function of the space given.",
            "So when the space for the synopsis increases the error.",
            "I cannot increase it will stay equal or decrease.",
            "So thanks to this property of the functions and for the subspace of the problems which involve a maximum error metric, which may be the maximum absolute error or the maximum relative error or any way that maximum error metric.",
            "So for this subset of the problems given the monotonic relationship, an alternative solution is possible, which is based on the solution to that dual problem of the classical program definition.",
            "That is, the error bounded problem, the problem which involves not the optimization of the error, but optimization of the space of the synopsis given a bound for the maximum."
        ],
        [
            "So the outline of the talk is that first we will present our technical aspects applied on histograms, which is a method with a long history in both database and data mining literature.",
            "And then we will see how it has been applied.",
            "Also in the restricted hard wavelet synopsis problem by previous work by Motor Krishnan which is also very relevant to our work.",
            "That's why we introduce it for the sake of completeness and then we will see how the same technique is applied with much more fruitful results.",
            "In the case of unrestricted hard wavelet synopsis, which is an improvement of the restricted model and we will talk about that as well as on the hard plastic structure, which is a structure we have introduced in previous work.",
            "And then we will show our experiments which verify what is already theoretically expected and."
        ],
        [
            "We will show our conclusions.",
            "So beginning with histograms.",
            "A histogram is a segmentation of data sequence.",
            "On consecutive constant value intervals.",
            "So you see an example with the curve and continuous curve, just to make it more aesthetic at the figure there.",
            "So the problem of constructing a histogram can be reduced to the problem of defining the boundaries between the buckets we define, and every of each one of those buckets, which can also come under the name of segment will have a constant value associated with it, so we see that for example, one segment SI will involve the start or begin value, the end value, and the approximation value in that segment.",
            "Of course it in, since they assignments are consecutive, is redundant to keep both of their beginning then value.",
            "Therefore we need 2 values for each segment of the histogram.",
            "And the classical solution to this problem.",
            "Is given in the literature by Jagati since 98 inability paper and it has been specialized for the for a family of relative error metrics, including the maximum relative error in a paper by uja and others involved in it and four and as well as space efficient technique for this program was also developed by Google in building with 1005.",
            "And So what all these techniques do is that they feature a dynamic programming scheme which can be expressed by this equation.",
            "This function is computes the optimal error, which is what we want to optimize for a prefix of the data sequence until the fifth element.",
            "Anfora Space C Not just space allocated to it of value be.",
            "So it finds what is the optimal error for representing the first values with big buckets.",
            "And this is expressed recursively, of course, so the optimal error and when that takes a maximum error metric, which is what we examine and was examined by the paper of Gunderson for this expressed as the minimum possible error out of all possible ways of defining the last bucket of the I prefix.",
            "So we have to choose this value of J, which is a value before I, and so and otherwise the minimum.",
            "The optimal position of J is the one that minimizes the function in the brackets.",
            "Which is a cultural expressed through the through the.",
            "The error for the J prefix and the error with small epsilon.",
            "For the last bucket defined.",
            "So that's the dynamic programming approach, and to express an algorithm has the complexity of end times B times log square of N, where B is the overall synopsis space.",
            "Recently there has been more research on the maximum error historical problem problem.",
            "On the offline.",
            "Maximum medical improvement.",
            "All these algorithms solve the problem in an offline fashion because they need to do many passes over the data.",
            "So there was a paper by Buraco Hennessy 2007, so this is concurrent work.",
            "And it proposes an algorithm of this complexity that we see there.",
            "So which is near linear to end.",
            "But it involves this U factor, which is the possible the cardinality of the set of possible data values.",
            "So this can be quite large.",
            "It cannot be bounded.",
            "It also involves the parameters you see at the denominator there in this practice distraction.",
            "So it grows with be just like this complex, it does.",
            "So all these solutions depend on the B parameter and grow with it.",
            "And there was another solution by guja and shaming TKD this year, which is an improvement over the previous work in VLDB and again it features the parameter and it is also squared as you see.",
            "And it has this complexity.",
            "The first complex that appears is for the case of maximum absolute error.",
            "Or maximum relative error just for these two and not for any possible way that metric.",
            "The other complexity that you see below.",
            "Which has A6 power of the logarithm fan is for any maximum error metric for any weights that we give and also the solution by regulation is also for the maximum absolute error only.",
            "So as we see, this last two complexes are not really linear either becausw when B assumes a reasonable value.",
            "Then we can say that this is a linear algorithm.",
            "For example, if the end is the power of 30, which is 1 billion, any value of be larger than 200 will render the algorithm not linear.",
            "And in any case that the complexity depends."
        ],
        [
            "The B parameter.",
            "What we propose for this problem is a much simpler solution.",
            "Which is based on a greedy algorithm that solves the error bounded problem first.",
            "And let's see how it works for the maximum absolute error.",
            "For the sake of simplicity.",
            "So I assume we have this sequence of numbers and we were given the maximum absolute error bound of epsilon equals 2.",
            "So what we do is they suggest we we greedily construct buckets, making each bucket as large as possible, so we extend the bucket boundary as much to the right, starting from the left as possible.",
            "And since the error bound is this two, we see that the first bucket can include the first 4 numbers and the optimal value to approximate them is the mean of the maximum and minimum, so it is for in this case, and we have to stop there because you see the next value, which is 15, cannot be included without violating the error bound.",
            "We moved Riddle in the same way for the second bucket, and we extended as fast as possible, so it includes the next 2 numbers.",
            "And their average value 16 is the best for them.",
            "And we move forward in the same way.",
            "And that's what the algorithm does, so it's a very simple greedy algorithm.",
            "The same element copy generalized to any weight at Max Mara metrics, so becoming a little bit more complex.",
            "What it has to do is that for its incoming data value, it has to define a tolerance interval, which is which is the interval of approximate values for that value that it can accept.",
            "So if there is a weight WI associated with the data value die and give the error bound.",
            "Of a weighted Markov, a weighted maximum metric is this epsilon.",
            "Then any value within the interval that you see in the figure.",
            "Where epsilon is divided by the weight and the I is subtracted and added to the die.",
            "So any value in this interval can approximate our desired data value within within the desired error.",
            "So each coming coming value defines such a tolerance interval and as the values are arriving, we compute the intersection of those interval.",
            "Intervals when the intersection becomes empty, it means that we have to close the bucket.",
            "We have to close the bucket at the previous position.",
            "And we kind of approximate those values that we have received with by a value within that nonempty interval, which was the last non empty table that we had.",
            "So that's a generalization of this basic idea to anyway that much more metric it does not involve a complex increase.",
            "It is also a linear algorithm.",
            "And so in in this case, as we said, the bucket is closed when they're running union of intervals, so the intersection intersection of intervals becomes know, so the complexity is linear."
        ],
        [
            "Now, the way this is applied in the space bounded problem is through a binary search.",
            "So by performing a binary search on the previous algorithm, this simple linear algorithm that we introduced for different values of the error bound, we can derive the optimal solution to the space bounded problem.",
            "So the problem that asks to optimize the error value with space bound.",
            "So we perform the binary search until we get the optimal the desired value of B and there is some.",
            "Additional stepping that in order to reassure that the solution will converge, we also run the algorithm under the constraint that the error we get is not less than equal of the epsilon, but just less than that.",
            "So that's an additional iteration which will reassure that the algorithm will always converge to the optimal error that we desire.",
            "So for any error value that requires a value of Space B bar which is less than or equal to the of the desired space.",
            "And it has actual error epsilon bug.",
            "We need to run this optimality test.",
            "And if this optimality test requires space.",
            "Be till there which is more than B.",
            "Then it means that the installation has been reached.",
            "Given this additional step, we get the complexity, which is 10 times the logarithm of the optimal error that we get, so this.",
            "Bing factor.",
            "It is just the way that expresses the binary search.",
            "Approach in case the error is someone, it doesn't mean that the time will be negative.",
            "That's just the theoretical expression because we used by previous work.",
            "So we also use it in the same way.",
            "And what we need to notice in this complex is that it is not.",
            "It does not depend on the value of B, so it is an algorithm independent of.",
            "It is much more stable than other algorithms for."
        ],
        [
            "The same problem.",
            "Now we see how the same idea is applied on the restricted hard wavelet synopses problem.",
            "First of all, we see it this way.",
            "We let the transformation so given a data set of this eight values that we see in blue color and the down of the figure.",
            "We first compute compute their pairwise, obviously.",
            "So we see that the first 2 values have the average of 25 and we also keep the difference between the left value and the average, which is 9 for the first pair is minus nine for the 2nd, and so on.",
            "And then we repeat the same process for the averages.",
            "With that we computed in the first step, so we get.",
            "Two more averages from the four ones that we had and again we keep those differences.",
            "And we continue recursively until where it's at the top.",
            "And what we keep at the end is the overall average value, which is 8 in this case.",
            "And the rest 7 differences.",
            "So using this numbers in this tree structure, which is the higher hartry dating from Alfred Haar, which introduced this transform back in 19 in 1910.",
            "So we can reconstruct any one of the original values by just reversing a path through the tree and adding also, or subtracting the differences that we see.",
            "For example, 18 + 0 + 7.",
            "Mine was minus nine which is +9.",
            "Will give us sorry minus 7 + 9 will give us the value of 20 or 18 -- 7 will give us 11 and minus nine will give us the value of two.",
            "So these are the 3rd and the 4th value in the sequence.",
            "What the hardware with Synopsys does is that it maintains.",
            "Only part of those differences that constitute the hardware decomposition.",
            "And it tries to maintain those subsets of them, which will be the optimal which will have the optimal error in the final synopsis constructed.",
            "So the synopsis will be is the representation of the original values through a small number of the wavelet decomposition terms.",
            "So this involves the dynamic programming approach, which is it is a recursive equation like this one.",
            "And the complexity of this algorithm is quadratic to N."
        ],
        [
            "However, the same problem can be solved through the error bounded problem again by this dynamic programming solution, which optimizes not the error, but the space of a solution.",
            "So what you have to notice what the basic differences is that this approach features the B parameter, which is also a parameter that I'm programming, but this one does not.",
            "So this one only applies to optimize the space given an error bound, and again the minimum space under a node in the tree node I with an incoming value of V, which is the value reconstructed in the path above.",
            "Is there a guarantee expressed through the optimal spaces for the problem already solved in the children of that value?",
            "Using a local search approach, the complexity of this solution can be better than quadratic, so it is.",
            "It is given by this square of N divided by log event function.",
            "But still, when the binary sets approach is used with this solution.",
            "We get to this time complexity which doesn't have a significant advantage over the previous one.",
            "Over this one, this quadratic and this is again."
        ],
        [
            "Attractive because it involves the logarithm.",
            "However, when the same idea is applied on the unrestricted hardware, it's not this problem which is the problem of creating a synopsis in which the value that we keep.",
            "Is arbitrary, so the restriction formulation of the problem is 1, in which the values of the hardware that we maintain have to be the values defined by the conversion itself.",
            "For example, we can keep only the value 7 at that node in the tree.",
            "We cannot keep another one.",
            "The understory formulation of the problem introduced by Glen Carbon KTD 2 years ago.",
            "A discards this limitation and allows us to keep any arbitrary value, and it solves this through a quantization scheme, so the values are quantized.",
            "Every possible value stride, and this is done through this dynamic programming scheme, so it is like the previous one, but again there is all possible values of V. Have to be tried for a for a given node of the tree and the optimal assigned value has to be computed, but again it is a dynamic programming approach that has these three parameters, and one of them is B, which is the snap space and there is an improvement on that as well, which is the hard plastic which introduced in previous work.",
            "And the addition done by that is that it involves not only one coefficient per node, but three coefficients in space at the place of 1 coefficient of the classical hardware decomposition."
        ],
        [
            "But we don't have to analyze that data at the present time.",
            "But again, there is a dynamic programming solution.",
            "Which is much simpler if it is applied on the dual problem, which is the error bounded problem.",
            "So again, the dynamic programming for the dual problem is given by these two equations for the unrestricted Harden their heart plus synopsis.",
            "Again, there is no parameter there, so the complexity doesn't feature that parameter.",
            "It features only the cardinality of the sets of incoming values, which is R. And there's no, there's no parameter there.",
            "So when this when our dual problem methodology through binary search is applied on this algorithm in order to solve the original space button problem we get.",
            "This complexity, which has significant both time and."
        ],
        [
            "Space advantage.",
            "We verify refunding through experiments, so this experiment shows the time as a function of N. You see that the indirect solution."
        ],
        [
            "Our solution is much faster than the direct, and that comes both for histograms and for.",
            "And for hard wavelets, here's the time as a function of B.",
            "Our solution was stable time.",
            "Previous solutions have time that grows with."
        ],
        [
            "Free.",
            "And these are again the times, so the previous experiments were for a histogram construction and this experience for hardwood construction and which which involved.",
            "More solutions, we have both the restricted and unrestricted solution.",
            "That is the worst of all because you like it.",
            "Actually quadratic time.",
            "We also have an Oracle solution in which the optimal error is known is supposed to be known in advance, but even that one cannot do better than our."
        ],
        [
            "Gory.",
            "And the same situation appears at with time as it grows as a function of space.",
            "And the same happens with the hard clusters in this construction algorithm.",
            "That's a time as a function of N, and that's the time as a function of space.",
            "So the reason why time grows as far as a function of being this case while it was not going in that case is that in the unrest in the car, there is a possibility to they limit the search space as big growth, but we don't need to."
        ],
        [
            "Elaborate on that.",
            "Our conclusions.",
            "Are the offline space bounded?",
            "Data synopsis problems are solvable more easily through the error bounded.",
            "Problems through their error bounded counterpart counterparts.",
            "In all cases we get synopsis which are lower independent of synopsis space.",
            "And our algorithms are simpler, more scalable than the direct ones.",
            "More general because they directly apply to any weight at maximum metric.",
            "More elegant and more memory, parsimonious than the direct algorithm in the future, we plan to extend our approach to other data representation models like the compactor kilogram which was introduced last year in VLDB and to multi."
        ],
        [
            "Measure and multi dimensional data.",
            "That's a collection of related works, including their works by Ujang Harper Avalex for wavelets and jackets for histograms and motivational, which introduced the technique.",
            "In 2005"
        ],
        [
            "And to that's all we will.",
            "We will have the chance to discuss more about that at both 17 at the poster session this evening.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This talk will be about our work on the impact of duality on data synopsis problems, which is another title different from the one which appears in the proceedings just for variety.",
                    "label": 0
                },
                {
                    "sent": "It was done with the Mirror Saint Nicholas at the University of Hong Kong.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that is an obvious problems which include summarization using histograms or using the hard wavelet transformation and have applications in many areas including data mining and databases.",
                    "label": 0
                },
                {
                    "sent": "For example, for selectivity estimation for.",
                    "label": 0
                },
                {
                    "sent": "Summarizing Internet traffic data so we asked which only recently?",
                    "label": 0
                },
                {
                    "sent": "And many other applications, including social networks and wherever there is a large collection of data which has to be summarized so as to effectuate speed.",
                    "label": 0
                },
                {
                    "sent": "At the price of a small error.",
                    "label": 0
                },
                {
                    "sent": "So all these problems require the optimization of an error metric.",
                    "label": 1
                },
                {
                    "sent": "Under a bound on the space used for the summary, that's the classical definition of the problems with all techniques which have been introduced so far, and the problems that we examine are always about the summarization of 1 dimensional data of sequences of numbers, which may represent any quantity.",
                    "label": 1
                },
                {
                    "sent": "So the classical approach is for those problems through them in a straightforward manner.",
                    "label": 0
                },
                {
                    "sent": "Trying to produce a solution which will calculate this optimal minimize error under the space.",
                    "label": 0
                },
                {
                    "sent": "And usually these solutions are complicated.",
                    "label": 0
                },
                {
                    "sent": "They feature complex dynamic programming schemes and that's why sometimes they also heuristics have been developed in order to make the algorithms to run faster.",
                    "label": 0
                },
                {
                    "sent": "The basic idea that we introduced in this talk is that since the parameters involved in the problem have a monotonic relationship to each other, so the error is a monotonic function of the space given.",
                    "label": 0
                },
                {
                    "sent": "So when the space for the synopsis increases the error.",
                    "label": 0
                },
                {
                    "sent": "I cannot increase it will stay equal or decrease.",
                    "label": 0
                },
                {
                    "sent": "So thanks to this property of the functions and for the subspace of the problems which involve a maximum error metric, which may be the maximum absolute error or the maximum relative error or any way that maximum error metric.",
                    "label": 1
                },
                {
                    "sent": "So for this subset of the problems given the monotonic relationship, an alternative solution is possible, which is based on the solution to that dual problem of the classical program definition.",
                    "label": 0
                },
                {
                    "sent": "That is, the error bounded problem, the problem which involves not the optimization of the error, but optimization of the space of the synopsis given a bound for the maximum.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the outline of the talk is that first we will present our technical aspects applied on histograms, which is a method with a long history in both database and data mining literature.",
                    "label": 0
                },
                {
                    "sent": "And then we will see how it has been applied.",
                    "label": 0
                },
                {
                    "sent": "Also in the restricted hard wavelet synopsis problem by previous work by Motor Krishnan which is also very relevant to our work.",
                    "label": 0
                },
                {
                    "sent": "That's why we introduce it for the sake of completeness and then we will see how the same technique is applied with much more fruitful results.",
                    "label": 0
                },
                {
                    "sent": "In the case of unrestricted hard wavelet synopsis, which is an improvement of the restricted model and we will talk about that as well as on the hard plastic structure, which is a structure we have introduced in previous work.",
                    "label": 0
                },
                {
                    "sent": "And then we will show our experiments which verify what is already theoretically expected and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will show our conclusions.",
                    "label": 0
                },
                {
                    "sent": "So beginning with histograms.",
                    "label": 0
                },
                {
                    "sent": "A histogram is a segmentation of data sequence.",
                    "label": 0
                },
                {
                    "sent": "On consecutive constant value intervals.",
                    "label": 0
                },
                {
                    "sent": "So you see an example with the curve and continuous curve, just to make it more aesthetic at the figure there.",
                    "label": 0
                },
                {
                    "sent": "So the problem of constructing a histogram can be reduced to the problem of defining the boundaries between the buckets we define, and every of each one of those buckets, which can also come under the name of segment will have a constant value associated with it, so we see that for example, one segment SI will involve the start or begin value, the end value, and the approximation value in that segment.",
                    "label": 0
                },
                {
                    "sent": "Of course it in, since they assignments are consecutive, is redundant to keep both of their beginning then value.",
                    "label": 0
                },
                {
                    "sent": "Therefore we need 2 values for each segment of the histogram.",
                    "label": 0
                },
                {
                    "sent": "And the classical solution to this problem.",
                    "label": 0
                },
                {
                    "sent": "Is given in the literature by Jagati since 98 inability paper and it has been specialized for the for a family of relative error metrics, including the maximum relative error in a paper by uja and others involved in it and four and as well as space efficient technique for this program was also developed by Google in building with 1005.",
                    "label": 0
                },
                {
                    "sent": "And So what all these techniques do is that they feature a dynamic programming scheme which can be expressed by this equation.",
                    "label": 0
                },
                {
                    "sent": "This function is computes the optimal error, which is what we want to optimize for a prefix of the data sequence until the fifth element.",
                    "label": 0
                },
                {
                    "sent": "Anfora Space C Not just space allocated to it of value be.",
                    "label": 0
                },
                {
                    "sent": "So it finds what is the optimal error for representing the first values with big buckets.",
                    "label": 0
                },
                {
                    "sent": "And this is expressed recursively, of course, so the optimal error and when that takes a maximum error metric, which is what we examine and was examined by the paper of Gunderson for this expressed as the minimum possible error out of all possible ways of defining the last bucket of the I prefix.",
                    "label": 0
                },
                {
                    "sent": "So we have to choose this value of J, which is a value before I, and so and otherwise the minimum.",
                    "label": 0
                },
                {
                    "sent": "The optimal position of J is the one that minimizes the function in the brackets.",
                    "label": 0
                },
                {
                    "sent": "Which is a cultural expressed through the through the.",
                    "label": 0
                },
                {
                    "sent": "The error for the J prefix and the error with small epsilon.",
                    "label": 0
                },
                {
                    "sent": "For the last bucket defined.",
                    "label": 0
                },
                {
                    "sent": "So that's the dynamic programming approach, and to express an algorithm has the complexity of end times B times log square of N, where B is the overall synopsis space.",
                    "label": 0
                },
                {
                    "sent": "Recently there has been more research on the maximum error historical problem problem.",
                    "label": 0
                },
                {
                    "sent": "On the offline.",
                    "label": 0
                },
                {
                    "sent": "Maximum medical improvement.",
                    "label": 0
                },
                {
                    "sent": "All these algorithms solve the problem in an offline fashion because they need to do many passes over the data.",
                    "label": 0
                },
                {
                    "sent": "So there was a paper by Buraco Hennessy 2007, so this is concurrent work.",
                    "label": 0
                },
                {
                    "sent": "And it proposes an algorithm of this complexity that we see there.",
                    "label": 0
                },
                {
                    "sent": "So which is near linear to end.",
                    "label": 0
                },
                {
                    "sent": "But it involves this U factor, which is the possible the cardinality of the set of possible data values.",
                    "label": 0
                },
                {
                    "sent": "So this can be quite large.",
                    "label": 0
                },
                {
                    "sent": "It cannot be bounded.",
                    "label": 0
                },
                {
                    "sent": "It also involves the parameters you see at the denominator there in this practice distraction.",
                    "label": 0
                },
                {
                    "sent": "So it grows with be just like this complex, it does.",
                    "label": 0
                },
                {
                    "sent": "So all these solutions depend on the B parameter and grow with it.",
                    "label": 0
                },
                {
                    "sent": "And there was another solution by guja and shaming TKD this year, which is an improvement over the previous work in VLDB and again it features the parameter and it is also squared as you see.",
                    "label": 0
                },
                {
                    "sent": "And it has this complexity.",
                    "label": 0
                },
                {
                    "sent": "The first complex that appears is for the case of maximum absolute error.",
                    "label": 0
                },
                {
                    "sent": "Or maximum relative error just for these two and not for any possible way that metric.",
                    "label": 0
                },
                {
                    "sent": "The other complexity that you see below.",
                    "label": 0
                },
                {
                    "sent": "Which has A6 power of the logarithm fan is for any maximum error metric for any weights that we give and also the solution by regulation is also for the maximum absolute error only.",
                    "label": 0
                },
                {
                    "sent": "So as we see, this last two complexes are not really linear either becausw when B assumes a reasonable value.",
                    "label": 0
                },
                {
                    "sent": "Then we can say that this is a linear algorithm.",
                    "label": 0
                },
                {
                    "sent": "For example, if the end is the power of 30, which is 1 billion, any value of be larger than 200 will render the algorithm not linear.",
                    "label": 0
                },
                {
                    "sent": "And in any case that the complexity depends.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The B parameter.",
                    "label": 0
                },
                {
                    "sent": "What we propose for this problem is a much simpler solution.",
                    "label": 0
                },
                {
                    "sent": "Which is based on a greedy algorithm that solves the error bounded problem first.",
                    "label": 0
                },
                {
                    "sent": "And let's see how it works for the maximum absolute error.",
                    "label": 0
                },
                {
                    "sent": "For the sake of simplicity.",
                    "label": 0
                },
                {
                    "sent": "So I assume we have this sequence of numbers and we were given the maximum absolute error bound of epsilon equals 2.",
                    "label": 1
                },
                {
                    "sent": "So what we do is they suggest we we greedily construct buckets, making each bucket as large as possible, so we extend the bucket boundary as much to the right, starting from the left as possible.",
                    "label": 0
                },
                {
                    "sent": "And since the error bound is this two, we see that the first bucket can include the first 4 numbers and the optimal value to approximate them is the mean of the maximum and minimum, so it is for in this case, and we have to stop there because you see the next value, which is 15, cannot be included without violating the error bound.",
                    "label": 0
                },
                {
                    "sent": "We moved Riddle in the same way for the second bucket, and we extended as fast as possible, so it includes the next 2 numbers.",
                    "label": 0
                },
                {
                    "sent": "And their average value 16 is the best for them.",
                    "label": 0
                },
                {
                    "sent": "And we move forward in the same way.",
                    "label": 0
                },
                {
                    "sent": "And that's what the algorithm does, so it's a very simple greedy algorithm.",
                    "label": 1
                },
                {
                    "sent": "The same element copy generalized to any weight at Max Mara metrics, so becoming a little bit more complex.",
                    "label": 0
                },
                {
                    "sent": "What it has to do is that for its incoming data value, it has to define a tolerance interval, which is which is the interval of approximate values for that value that it can accept.",
                    "label": 0
                },
                {
                    "sent": "So if there is a weight WI associated with the data value die and give the error bound.",
                    "label": 0
                },
                {
                    "sent": "Of a weighted Markov, a weighted maximum metric is this epsilon.",
                    "label": 0
                },
                {
                    "sent": "Then any value within the interval that you see in the figure.",
                    "label": 0
                },
                {
                    "sent": "Where epsilon is divided by the weight and the I is subtracted and added to the die.",
                    "label": 0
                },
                {
                    "sent": "So any value in this interval can approximate our desired data value within within the desired error.",
                    "label": 1
                },
                {
                    "sent": "So each coming coming value defines such a tolerance interval and as the values are arriving, we compute the intersection of those interval.",
                    "label": 0
                },
                {
                    "sent": "Intervals when the intersection becomes empty, it means that we have to close the bucket.",
                    "label": 0
                },
                {
                    "sent": "We have to close the bucket at the previous position.",
                    "label": 0
                },
                {
                    "sent": "And we kind of approximate those values that we have received with by a value within that nonempty interval, which was the last non empty table that we had.",
                    "label": 0
                },
                {
                    "sent": "So that's a generalization of this basic idea to anyway that much more metric it does not involve a complex increase.",
                    "label": 0
                },
                {
                    "sent": "It is also a linear algorithm.",
                    "label": 0
                },
                {
                    "sent": "And so in in this case, as we said, the bucket is closed when they're running union of intervals, so the intersection intersection of intervals becomes know, so the complexity is linear.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, the way this is applied in the space bounded problem is through a binary search.",
                    "label": 0
                },
                {
                    "sent": "So by performing a binary search on the previous algorithm, this simple linear algorithm that we introduced for different values of the error bound, we can derive the optimal solution to the space bounded problem.",
                    "label": 1
                },
                {
                    "sent": "So the problem that asks to optimize the error value with space bound.",
                    "label": 0
                },
                {
                    "sent": "So we perform the binary search until we get the optimal the desired value of B and there is some.",
                    "label": 0
                },
                {
                    "sent": "Additional stepping that in order to reassure that the solution will converge, we also run the algorithm under the constraint that the error we get is not less than equal of the epsilon, but just less than that.",
                    "label": 0
                },
                {
                    "sent": "So that's an additional iteration which will reassure that the algorithm will always converge to the optimal error that we desire.",
                    "label": 0
                },
                {
                    "sent": "So for any error value that requires a value of Space B bar which is less than or equal to the of the desired space.",
                    "label": 0
                },
                {
                    "sent": "And it has actual error epsilon bug.",
                    "label": 0
                },
                {
                    "sent": "We need to run this optimality test.",
                    "label": 1
                },
                {
                    "sent": "And if this optimality test requires space.",
                    "label": 1
                },
                {
                    "sent": "Be till there which is more than B.",
                    "label": 0
                },
                {
                    "sent": "Then it means that the installation has been reached.",
                    "label": 0
                },
                {
                    "sent": "Given this additional step, we get the complexity, which is 10 times the logarithm of the optimal error that we get, so this.",
                    "label": 0
                },
                {
                    "sent": "Bing factor.",
                    "label": 0
                },
                {
                    "sent": "It is just the way that expresses the binary search.",
                    "label": 0
                },
                {
                    "sent": "Approach in case the error is someone, it doesn't mean that the time will be negative.",
                    "label": 0
                },
                {
                    "sent": "That's just the theoretical expression because we used by previous work.",
                    "label": 0
                },
                {
                    "sent": "So we also use it in the same way.",
                    "label": 0
                },
                {
                    "sent": "And what we need to notice in this complex is that it is not.",
                    "label": 0
                },
                {
                    "sent": "It does not depend on the value of B, so it is an algorithm independent of.",
                    "label": 0
                },
                {
                    "sent": "It is much more stable than other algorithms for.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same problem.",
                    "label": 0
                },
                {
                    "sent": "Now we see how the same idea is applied on the restricted hard wavelet synopses problem.",
                    "label": 0
                },
                {
                    "sent": "First of all, we see it this way.",
                    "label": 0
                },
                {
                    "sent": "We let the transformation so given a data set of this eight values that we see in blue color and the down of the figure.",
                    "label": 0
                },
                {
                    "sent": "We first compute compute their pairwise, obviously.",
                    "label": 0
                },
                {
                    "sent": "So we see that the first 2 values have the average of 25 and we also keep the difference between the left value and the average, which is 9 for the first pair is minus nine for the 2nd, and so on.",
                    "label": 0
                },
                {
                    "sent": "And then we repeat the same process for the averages.",
                    "label": 0
                },
                {
                    "sent": "With that we computed in the first step, so we get.",
                    "label": 0
                },
                {
                    "sent": "Two more averages from the four ones that we had and again we keep those differences.",
                    "label": 0
                },
                {
                    "sent": "And we continue recursively until where it's at the top.",
                    "label": 0
                },
                {
                    "sent": "And what we keep at the end is the overall average value, which is 8 in this case.",
                    "label": 0
                },
                {
                    "sent": "And the rest 7 differences.",
                    "label": 0
                },
                {
                    "sent": "So using this numbers in this tree structure, which is the higher hartry dating from Alfred Haar, which introduced this transform back in 19 in 1910.",
                    "label": 0
                },
                {
                    "sent": "So we can reconstruct any one of the original values by just reversing a path through the tree and adding also, or subtracting the differences that we see.",
                    "label": 0
                },
                {
                    "sent": "For example, 18 + 0 + 7.",
                    "label": 0
                },
                {
                    "sent": "Mine was minus nine which is +9.",
                    "label": 0
                },
                {
                    "sent": "Will give us sorry minus 7 + 9 will give us the value of 20 or 18 -- 7 will give us 11 and minus nine will give us the value of two.",
                    "label": 0
                },
                {
                    "sent": "So these are the 3rd and the 4th value in the sequence.",
                    "label": 0
                },
                {
                    "sent": "What the hardware with Synopsys does is that it maintains.",
                    "label": 0
                },
                {
                    "sent": "Only part of those differences that constitute the hardware decomposition.",
                    "label": 0
                },
                {
                    "sent": "And it tries to maintain those subsets of them, which will be the optimal which will have the optimal error in the final synopsis constructed.",
                    "label": 0
                },
                {
                    "sent": "So the synopsis will be is the representation of the original values through a small number of the wavelet decomposition terms.",
                    "label": 0
                },
                {
                    "sent": "So this involves the dynamic programming approach, which is it is a recursive equation like this one.",
                    "label": 0
                },
                {
                    "sent": "And the complexity of this algorithm is quadratic to N.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, the same problem can be solved through the error bounded problem again by this dynamic programming solution, which optimizes not the error, but the space of a solution.",
                    "label": 0
                },
                {
                    "sent": "So what you have to notice what the basic differences is that this approach features the B parameter, which is also a parameter that I'm programming, but this one does not.",
                    "label": 0
                },
                {
                    "sent": "So this one only applies to optimize the space given an error bound, and again the minimum space under a node in the tree node I with an incoming value of V, which is the value reconstructed in the path above.",
                    "label": 0
                },
                {
                    "sent": "Is there a guarantee expressed through the optimal spaces for the problem already solved in the children of that value?",
                    "label": 0
                },
                {
                    "sent": "Using a local search approach, the complexity of this solution can be better than quadratic, so it is.",
                    "label": 0
                },
                {
                    "sent": "It is given by this square of N divided by log event function.",
                    "label": 0
                },
                {
                    "sent": "But still, when the binary sets approach is used with this solution.",
                    "label": 0
                },
                {
                    "sent": "We get to this time complexity which doesn't have a significant advantage over the previous one.",
                    "label": 0
                },
                {
                    "sent": "Over this one, this quadratic and this is again.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Attractive because it involves the logarithm.",
                    "label": 0
                },
                {
                    "sent": "However, when the same idea is applied on the unrestricted hardware, it's not this problem which is the problem of creating a synopsis in which the value that we keep.",
                    "label": 0
                },
                {
                    "sent": "Is arbitrary, so the restriction formulation of the problem is 1, in which the values of the hardware that we maintain have to be the values defined by the conversion itself.",
                    "label": 0
                },
                {
                    "sent": "For example, we can keep only the value 7 at that node in the tree.",
                    "label": 0
                },
                {
                    "sent": "We cannot keep another one.",
                    "label": 0
                },
                {
                    "sent": "The understory formulation of the problem introduced by Glen Carbon KTD 2 years ago.",
                    "label": 0
                },
                {
                    "sent": "A discards this limitation and allows us to keep any arbitrary value, and it solves this through a quantization scheme, so the values are quantized.",
                    "label": 0
                },
                {
                    "sent": "Every possible value stride, and this is done through this dynamic programming scheme, so it is like the previous one, but again there is all possible values of V. Have to be tried for a for a given node of the tree and the optimal assigned value has to be computed, but again it is a dynamic programming approach that has these three parameters, and one of them is B, which is the snap space and there is an improvement on that as well, which is the hard plastic which introduced in previous work.",
                    "label": 0
                },
                {
                    "sent": "And the addition done by that is that it involves not only one coefficient per node, but three coefficients in space at the place of 1 coefficient of the classical hardware decomposition.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we don't have to analyze that data at the present time.",
                    "label": 0
                },
                {
                    "sent": "But again, there is a dynamic programming solution.",
                    "label": 0
                },
                {
                    "sent": "Which is much simpler if it is applied on the dual problem, which is the error bounded problem.",
                    "label": 0
                },
                {
                    "sent": "So again, the dynamic programming for the dual problem is given by these two equations for the unrestricted Harden their heart plus synopsis.",
                    "label": 0
                },
                {
                    "sent": "Again, there is no parameter there, so the complexity doesn't feature that parameter.",
                    "label": 0
                },
                {
                    "sent": "It features only the cardinality of the sets of incoming values, which is R. And there's no, there's no parameter there.",
                    "label": 0
                },
                {
                    "sent": "So when this when our dual problem methodology through binary search is applied on this algorithm in order to solve the original space button problem we get.",
                    "label": 0
                },
                {
                    "sent": "This complexity, which has significant both time and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space advantage.",
                    "label": 0
                },
                {
                    "sent": "We verify refunding through experiments, so this experiment shows the time as a function of N. You see that the indirect solution.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our solution is much faster than the direct, and that comes both for histograms and for.",
                    "label": 0
                },
                {
                    "sent": "And for hard wavelets, here's the time as a function of B.",
                    "label": 0
                },
                {
                    "sent": "Our solution was stable time.",
                    "label": 0
                },
                {
                    "sent": "Previous solutions have time that grows with.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Free.",
                    "label": 0
                },
                {
                    "sent": "And these are again the times, so the previous experiments were for a histogram construction and this experience for hardwood construction and which which involved.",
                    "label": 0
                },
                {
                    "sent": "More solutions, we have both the restricted and unrestricted solution.",
                    "label": 0
                },
                {
                    "sent": "That is the worst of all because you like it.",
                    "label": 0
                },
                {
                    "sent": "Actually quadratic time.",
                    "label": 0
                },
                {
                    "sent": "We also have an Oracle solution in which the optimal error is known is supposed to be known in advance, but even that one cannot do better than our.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gory.",
                    "label": 0
                },
                {
                    "sent": "And the same situation appears at with time as it grows as a function of space.",
                    "label": 0
                },
                {
                    "sent": "And the same happens with the hard clusters in this construction algorithm.",
                    "label": 0
                },
                {
                    "sent": "That's a time as a function of N, and that's the time as a function of space.",
                    "label": 0
                },
                {
                    "sent": "So the reason why time grows as far as a function of being this case while it was not going in that case is that in the unrest in the car, there is a possibility to they limit the search space as big growth, but we don't need to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Elaborate on that.",
                    "label": 0
                },
                {
                    "sent": "Our conclusions.",
                    "label": 0
                },
                {
                    "sent": "Are the offline space bounded?",
                    "label": 0
                },
                {
                    "sent": "Data synopsis problems are solvable more easily through the error bounded.",
                    "label": 1
                },
                {
                    "sent": "Problems through their error bounded counterpart counterparts.",
                    "label": 1
                },
                {
                    "sent": "In all cases we get synopsis which are lower independent of synopsis space.",
                    "label": 0
                },
                {
                    "sent": "And our algorithms are simpler, more scalable than the direct ones.",
                    "label": 1
                },
                {
                    "sent": "More general because they directly apply to any weight at maximum metric.",
                    "label": 0
                },
                {
                    "sent": "More elegant and more memory, parsimonious than the direct algorithm in the future, we plan to extend our approach to other data representation models like the compactor kilogram which was introduced last year in VLDB and to multi.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measure and multi dimensional data.",
                    "label": 0
                },
                {
                    "sent": "That's a collection of related works, including their works by Ujang Harper Avalex for wavelets and jackets for histograms and motivational, which introduced the technique.",
                    "label": 0
                },
                {
                    "sent": "In 2005",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to that's all we will.",
                    "label": 0
                },
                {
                    "sent": "We will have the chance to discuss more about that at both 17 at the poster session this evening.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}