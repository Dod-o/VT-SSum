{
    "id": "tr7cbhj5zwjawc7pzdnuzqyjsw2zr2xh",
    "title": "Curriculum Learning",
    "info": {
        "author": [
            "Yoshua Bengio, Department of Computer Science and Operations Research, University of Montreal"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_bengio_cl/",
    "segmentation": [
        [
            "Thank you Max.",
            "So this is joint work with Jerome Guard or from a 2A rockola bear and Jason Weston from NEC, and I want to acknowledge the help of Merriam CTE."
        ],
        [
            "So what is curriculum learning?",
            "We all know about that as humans, and if we had pets.",
            "Um, maybe putting up the lights would be nice.",
            "So the way you've learned a lot of things is that other humans guided you while you were child through education and the way we teach complicated tasks to animals is called shaping, and it goes through a sequence of stages of tasks.",
            "These things have been studied by psychologists like Piaget and Skinner in the 50s.",
            "One of the ideas is that we start from similar examples and we gradually introduce more complicated concepts.",
            "So this thing doesn't seem."
        ],
        [
            "To be a common notion in machine learning, and we might ask why in machine learning there is this dogma?",
            "Almost that this belief that it's best to use as a training set, examples samples from the same distribution that you're going to be testing on later.",
            "But is that really always the right thing to do?",
            "So that's what this paper?"
        ],
        [
            "Is about.",
            "We want to ask this question.",
            "Can machine learning algorithms benefit from the kind of curriculum strategy that I've been just illustrating that are common for?",
            "Humans and animals.",
            "This question has been visited a little bit somewhat on the fringe of machine learning, mostly in Commission.",
            "Actually, only all the papers I know but are in the Cognition Journal.",
            "It was first raised by Element in his 19 three paper where he tried to use a recurrent neural network to learn the grammar, something there was a.",
            "Interesting in those days in with several stages of training and he found that using this sequence of task he was able to learn the task much better than training directly on the target task.",
            "Later, road and plot tried to redo his experiments and found negative results.",
            "So the question stayed a bit in the air.",
            "Recently, just very recently, in fact, Krueger and Ion Revisited exactly the same question in the same Journal.",
            "Anri did similar experiments, slightly different flavor.",
            "An came essentially the same conclusion as Ellman, so this paper is following on these."
        ],
        [
            "The tack that we're taking here is a bit more trying to understand.",
            "Buy things in case the discussion becomes passionate.",
            "Here Sir, here we probably should introduce you if that's well, Max did.",
            "Thank you.",
            "Who's going to introduce Maxwell?",
            "I was going to do.",
            "I got some sort of improved vastly.",
            "Kernel version, but on the other hand we also always review that by pointing to something new.",
            "Interesting, so we decided OK. Let's do something useful.",
            "So.",
            "So if you if you have questions, please keep them for the answer.",
            "So I'm trying to look at this question from trying to understand why this may work.",
            "And looking at 2 cases with very simple experiments.",
            "One with convex training criteria and the other with nonconvex training criteria.",
            "So if the training criterion is convex, you would imagine that changing the order of examples in the selection of examples, eventually sampling from the target distribution wouldn't change anything because you would always end up in the same minimum, same global minimum.",
            "But doing that may change the speed at which you get to that minimum.",
            "In fact, we'll find that in our experiments, maybe the other more interesting case to consider.",
            "Is when the training criterion is nonconvex and there because there are local minima.",
            "Depending on where you start and how the learning dynamics is organized as influenced by the selection of examples, you could find better solutions.",
            "In fact."
        ],
        [
            "This is what we will find.",
            "Motivation for this work?",
            "Comes for me from deep architectures.",
            "Deep architectures are classes of functions organized with multiple levels of transformation and representation, and there are interesting for a number of reasons.",
            "There are 30 arguments suggesting that there might be more efficient at representing some functions than shallower structures.",
            "Classes of functions, and of course there are also appealing for by analogy to how we organize our thoughts and how the brain is organized.",
            "But the main point here is that there are a lot of local minima and we know from experimentation that these minima may matter.",
            "In particular, we have found with these architectures that by initializing using unsupervised learning and guiding the optimization using improvised learning can lead to much better local minima so.",
            "With with those observations, it's interesting to see whether those types of curriculum strategies could be helpful for deeper architectures, and we've tested that."
        ],
        [
            "A few more words about deep training training deep architectures.",
            "Here I'm showing a bunch of trajectories of deep multilayer neural networks.",
            "With either the standard random initialization or unsupervised guidance, each circle or cross represents one model at one point of training.",
            "So this is all the models at the beginning.",
            "We have about 500 different models here, all with different random initialization and then after one epoch one iteration we all get here and then they get here and they get here.",
            "And eventually each model goes into its own different local minimum.",
            "And this is a 2D projection of function space that I'm not going to explain, but what we see is that they all go to a different place and that depending on how you initialize things or guide training.",
            "Those trajectories go to very different regions in the space of functions.",
            "So let's get back to curriculum learning and."
        ],
        [
            "What it is about starting from easy examples that that was Jeff Hellman's paper.",
            "So we want to train with easier lower level abstraction illustrating easier examples illustrating lower level abstractions, and then gradually introduce more difficult ones, eventually presenting the examples that are more interesting.",
            "Representing higher level abstractions and more difficult cases."
        ],
        [
            "Now, this these ideas may remind some of you, so called continuation methods, which are global optimization methods that work on the principle of optimizing something different.",
            "Then, when you care about that, is easier to optimize and then gradually.",
            "Moving towards what you care about.",
            "So let's say you want to optimize this target objective function that has a lot of local minima.",
            "Are we going to smooth it?",
            "Smooth it and smooth it until it's easy to optimize it.",
            "Maybe even convex, so we have this surrogate criterion.",
            "We can optimize it and then we're going to gradually move back towards our target objective, continuously ANAN along the way.",
            "Track local minimum and this way we're going to find a solution is not guaranteed to find to find a global optimum, but in practice this has been used very successfully.",
            "For example in chemistry for finding configurations of molecules, an independent on how you designed to smooth.",
            "How do you sign to change your your family functions?",
            "Is going very well and you can.",
            "You can see the analogy with simulated annealing with it, which would be a stochastic version of this."
        ],
        [
            "So now I'm trying to explore the hypothesis that curriculum learning can be seen as a continuation method, and maybe that's one reason why it could help.",
            "Getting good results.",
            "So we are going to define a sequence of training distributions.",
            "Initially we're going to have the easier examples, as I showed earlier, and so we have a.",
            "We were changing.",
            "The training criterion is we're picking the distribution on those easier examples.",
            "And then we dragged to give more weight to the more difficult ones until we reach the target distribution.",
            "So you can see that we have really a sequence of."
        ],
        [
            "In criteria.",
            "OK, so.",
            "Now we are sort of the experimental part of the presentation.",
            "We have this general notion of organizing representation of examples in the selection of examples.",
            "But it's not clear how to do that, so we're going to do some experiments.",
            "I'm going to tell you about 3 three series of experiments.",
            "The first experiments are with the toy.",
            "Data with a simple distribution where the learner is a perceptron, so the criterion is convex and we're going to try two different ways of ordering examples.",
            "Of presenting easier examples first, one way is to present the examples that are less ambiguous first, in the sense that the.",
            "The distance to the distant surface is greater or the margin is larger the other way we're going to look at is cases where we introduce noise in the examples and we can control how much noise there is in these examples, and then we can order examples by how much noise there is, and so we're going to start with the cleaner examples and then gradually introduce more noisy examples.",
            "The second experiment is an object classification task.",
            "We have three categories of shapes, and we're going to have two stages.",
            "In the first stage, we're going to show similar shapes, and the second stage we can have sort of more variability in the shapes and this will be the distribution we care about in the end.",
            "And finally, the third experiment is going to be a language modeling experiment.",
            "Where are we going to use something that's inspired from how children learn where we're going to show sentences with a smaller vocabulary first?",
            "And we gradually going going to expand the vocabulary, showing sentences illustrating more and more complicated concepts in a sense."
        ],
        [
            "OK, so here are some results.",
            "So these are with the perceptron learning where we have a convex training criterion and we train for just online 4.",
            "Before getting to convergence because of course if you wait long enough with the perceptron here you everything every model goes to the same place.",
            "And what we see here is for different number of inputs that the strategy which orders the examples by by margin.",
            "So the less ambiguous first generally converges faster, so that after a fixed number of updates we get to lower generalization error.",
            "This the upper curve is the standard IID sampling.",
            "Where is here we have taken the same set of examples but just order them differently.",
            "So some."
        ],
        [
            "Is happening.",
            "And basically the same kind of results are obtained if we order by the amount of noise in the input.",
            "So in a sense previously it was.",
            "More like noise in the output.",
            "OK, so now let's move to a slightly more challenging time."
        ],
        [
            "Ask.",
            "We have the data set of interest has triangles, ovals and rectangles with varying size angles.",
            "Scale foreground and background color and so on.",
            "And we made up a simplified version where the triangles can only be equilateral.",
            "The ovals can only be circles and rectangles can only be square, so there's less variability in this version of the data than in the target distribution.",
            "And we going to train with this for awhile and then switch to the target distribution and see if by doing that we get better results than by training all the time.",
            "With this the target distribution.",
            "Just a second set or a mix of.",
            "We tried both."
        ],
        [
            "So this is with the three hidden layer deep neural net that we've been playing with using in supervised pre training and we found for this type of data set and this type of architecture that indeed the local minima issue the way we initialize could could make a difference even though if you always if you use random initialization the results are consistently going to the same quality of solution.",
            "So as I said we're going to train for a fixed number of epochs using the easier shapes and switch the target distribution.",
            "Until either training error becomes saturates or we use early stopping to decide when to stop using a validation set."
        ],
        [
            "Now what I'm showing are the results where we vary the time at which we switch.",
            "From the examples to the hard examples in number of iterations through this 10,000 training examples.",
            "So at 0 means we're training only with the hard examples.",
            "An 128 means the first 128 iterations through the data.",
            "We use these examples and the next remainder, which is roughly another 128.",
            "We use the target distribution.",
            "An only why on the Y axis we see test error box plots over.",
            "Something like 20 random initializations.",
            "And what we see is that.",
            "Translation error is substantially lower if we use these easy examples to get started.",
            "And this is true whether we.",
            "We give more or less time after the switch .2 to both cases because eventually, well, none of these essentially overfits significantly.",
            "We also tried what Nicola asked, which is mixing the two simple and easy and doing IID on those and the results are roughly around here so.",
            "No, no, that's not the same thing.",
            "The question was if we try with IID ordering with a mix of the easy and hard.",
            "So putting in the easy examples helps here, maybe because they just said isn't that big and it introduces more variability in the data.",
            "At some point.",
            "That's true, that's true if you don't.",
            "If you don't switch to the target example, then it's bad, yes.",
            "No, there there is a minimum.",
            "Yeah, Jerome was here would be able to answer that question later.",
            "Hopefully.",
            "Right, so yeah, if you don't train enough with the hard examples, you'll see that in the next experiment you'll see this effect in the next experiment actually.",
            "So the next experiment is with language."
        ],
        [
            "Data.",
            "And the objective is to compute a score for the next word given the previous words.",
            "And the training criterion is a ranking criterion.",
            "So we want the score of the observed word to be larger than the score of any other word with some margin.",
            "It's a hinge loss.",
            "And then we will measure is the rank the average rank of the correct word.",
            "And they the class of functions gained a deep architecture with a particular structure that I started working on in the 2000 and that color and Western.",
            "Or coauthors on this paper.",
            "Presented at last I see ML showing that this kind of architecture actually does very well at a number of natural language processing tasks such as chunking, part of speech, tagging, semantic role labeling, essentially achieving state of the art or better than state of the art in these tasks.",
            "So this is all trained by stochastic gradient descent.",
            "Wikipedia, which has about 500 million words as a training set."
        ],
        [
            "Here are the results that I'm going to explain now.",
            "So what we're going to do?",
            "Well, first let me explain the graph.",
            "The red dots here represent the results with a normal IID training.",
            "So we just get the sentences from Wikipedia and we use a window of words as input and then we predict the next word.",
            "And we look at the rank of the correct word versus the other words, and we get some some test error that decreases as we do more and more updates.",
            "This is this is 1500 million updates but.",
            "It runs reasonably efficiently.",
            "The blue curve is showing what happens with the curriculum training, so the curriculum strategy here is start with the most frequent words only during training.",
            "So we take the sentences that contain only words from the 5000 most frequent words vocabulary and we train with that until this point and then we switch to the vocabulary with 10,000 words and then we switch to 15,000 and 20,000.",
            "So the target distribution here is 20,000 words.",
            "Vocabulary.",
            "And we are always testing on the 20,000 words vocabulary data.",
            "So yeah, the test set is from the target distribution as well.",
            "Now what happens here is that the network trained with only 5 to 5000 most frequent words when it sees a word from the 20,000 large vocabulary doesn't make very good prediction, and so that's why the errors are pretty high when you test on with respect to that.",
            "As soon as you introduce new words, you can see that the error goes down quickly and here you introduce essentially examples from the target distribution.",
            "Very quickly, the network with the current curriculum strategy surpasses that in the other one."
        ],
        [
            "So that seems to work.",
            "We can say yes.",
            "Machine learning algorithms can benefit from a curriculum strategy.",
            "And the next question we are interested in is why?"
        ],
        [
            "And I don't think I have the answers, but at least I have some hypothesis.",
            "As I mentioned, maybe these strategies help to converge faster to a minimum, and what one could maybe suppose that we are wasting less time with those more difficult examples.",
            "Harder to predict examples.",
            "So that's 11 possibility.",
            "The other possibility that applies only to the case where you have non convex training criteria is that we get to better local minimum an maybe because the curriculum might be a particular continuation method.",
            "Now one thing we noted both with the curriculum strategy and with other strategies for deep architectures is that they seem not only to find better local minima with respect to the training criterion, but if I in fact the local minima defined are better in terms of test error.",
            "In fact the effect is even more pronounced on the test error then on the training error.",
            "So the this kind of thing actually acts like a regularizer, but but it's not the kind of regularizer whose effect disappears when the number of examples goes to Infinity.",
            "So that's interesting and my last slide is, well, what's next?",
            "Where?"
        ],
        [
            "We're still stuck with the question how do we define good curriculum strategies?",
            "We presented some simple cases.",
            "Are there some general principles?",
            "We should try to understand what makes curriculum strategy work.",
            "An one thing we're working on now is the idea trying to automate the these things as much as possible and trying to have learning algorithms that right on the frontier of with things that they can do well.",
            "So avoid not only the two easy examples, but also the two hard examples and move that Frontier as the learner gets better.",
            "I'm done."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you Max.",
                    "label": 0
                },
                {
                    "sent": "So this is joint work with Jerome Guard or from a 2A rockola bear and Jason Weston from NEC, and I want to acknowledge the help of Merriam CTE.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is curriculum learning?",
                    "label": 1
                },
                {
                    "sent": "We all know about that as humans, and if we had pets.",
                    "label": 0
                },
                {
                    "sent": "Um, maybe putting up the lights would be nice.",
                    "label": 0
                },
                {
                    "sent": "So the way you've learned a lot of things is that other humans guided you while you were child through education and the way we teach complicated tasks to animals is called shaping, and it goes through a sequence of stages of tasks.",
                    "label": 1
                },
                {
                    "sent": "These things have been studied by psychologists like Piaget and Skinner in the 50s.",
                    "label": 0
                },
                {
                    "sent": "One of the ideas is that we start from similar examples and we gradually introduce more complicated concepts.",
                    "label": 0
                },
                {
                    "sent": "So this thing doesn't seem.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To be a common notion in machine learning, and we might ask why in machine learning there is this dogma?",
                    "label": 0
                },
                {
                    "sent": "Almost that this belief that it's best to use as a training set, examples samples from the same distribution that you're going to be testing on later.",
                    "label": 1
                },
                {
                    "sent": "But is that really always the right thing to do?",
                    "label": 0
                },
                {
                    "sent": "So that's what this paper?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is about.",
                    "label": 0
                },
                {
                    "sent": "We want to ask this question.",
                    "label": 0
                },
                {
                    "sent": "Can machine learning algorithms benefit from the kind of curriculum strategy that I've been just illustrating that are common for?",
                    "label": 1
                },
                {
                    "sent": "Humans and animals.",
                    "label": 0
                },
                {
                    "sent": "This question has been visited a little bit somewhat on the fringe of machine learning, mostly in Commission.",
                    "label": 0
                },
                {
                    "sent": "Actually, only all the papers I know but are in the Cognition Journal.",
                    "label": 0
                },
                {
                    "sent": "It was first raised by Element in his 19 three paper where he tried to use a recurrent neural network to learn the grammar, something there was a.",
                    "label": 0
                },
                {
                    "sent": "Interesting in those days in with several stages of training and he found that using this sequence of task he was able to learn the task much better than training directly on the target task.",
                    "label": 0
                },
                {
                    "sent": "Later, road and plot tried to redo his experiments and found negative results.",
                    "label": 0
                },
                {
                    "sent": "So the question stayed a bit in the air.",
                    "label": 0
                },
                {
                    "sent": "Recently, just very recently, in fact, Krueger and Ion Revisited exactly the same question in the same Journal.",
                    "label": 0
                },
                {
                    "sent": "Anri did similar experiments, slightly different flavor.",
                    "label": 0
                },
                {
                    "sent": "An came essentially the same conclusion as Ellman, so this paper is following on these.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The tack that we're taking here is a bit more trying to understand.",
                    "label": 0
                },
                {
                    "sent": "Buy things in case the discussion becomes passionate.",
                    "label": 0
                },
                {
                    "sent": "Here Sir, here we probably should introduce you if that's well, Max did.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Who's going to introduce Maxwell?",
                    "label": 0
                },
                {
                    "sent": "I was going to do.",
                    "label": 0
                },
                {
                    "sent": "I got some sort of improved vastly.",
                    "label": 0
                },
                {
                    "sent": "Kernel version, but on the other hand we also always review that by pointing to something new.",
                    "label": 0
                },
                {
                    "sent": "Interesting, so we decided OK. Let's do something useful.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So if you if you have questions, please keep them for the answer.",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to look at this question from trying to understand why this may work.",
                    "label": 0
                },
                {
                    "sent": "And looking at 2 cases with very simple experiments.",
                    "label": 0
                },
                {
                    "sent": "One with convex training criteria and the other with nonconvex training criteria.",
                    "label": 0
                },
                {
                    "sent": "So if the training criterion is convex, you would imagine that changing the order of examples in the selection of examples, eventually sampling from the target distribution wouldn't change anything because you would always end up in the same minimum, same global minimum.",
                    "label": 1
                },
                {
                    "sent": "But doing that may change the speed at which you get to that minimum.",
                    "label": 0
                },
                {
                    "sent": "In fact, we'll find that in our experiments, maybe the other more interesting case to consider.",
                    "label": 0
                },
                {
                    "sent": "Is when the training criterion is nonconvex and there because there are local minima.",
                    "label": 0
                },
                {
                    "sent": "Depending on where you start and how the learning dynamics is organized as influenced by the selection of examples, you could find better solutions.",
                    "label": 0
                },
                {
                    "sent": "In fact.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is what we will find.",
                    "label": 0
                },
                {
                    "sent": "Motivation for this work?",
                    "label": 0
                },
                {
                    "sent": "Comes for me from deep architectures.",
                    "label": 1
                },
                {
                    "sent": "Deep architectures are classes of functions organized with multiple levels of transformation and representation, and there are interesting for a number of reasons.",
                    "label": 0
                },
                {
                    "sent": "There are 30 arguments suggesting that there might be more efficient at representing some functions than shallower structures.",
                    "label": 0
                },
                {
                    "sent": "Classes of functions, and of course there are also appealing for by analogy to how we organize our thoughts and how the brain is organized.",
                    "label": 0
                },
                {
                    "sent": "But the main point here is that there are a lot of local minima and we know from experimentation that these minima may matter.",
                    "label": 0
                },
                {
                    "sent": "In particular, we have found with these architectures that by initializing using unsupervised learning and guiding the optimization using improvised learning can lead to much better local minima so.",
                    "label": 1
                },
                {
                    "sent": "With with those observations, it's interesting to see whether those types of curriculum strategies could be helpful for deeper architectures, and we've tested that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A few more words about deep training training deep architectures.",
                    "label": 1
                },
                {
                    "sent": "Here I'm showing a bunch of trajectories of deep multilayer neural networks.",
                    "label": 0
                },
                {
                    "sent": "With either the standard random initialization or unsupervised guidance, each circle or cross represents one model at one point of training.",
                    "label": 1
                },
                {
                    "sent": "So this is all the models at the beginning.",
                    "label": 0
                },
                {
                    "sent": "We have about 500 different models here, all with different random initialization and then after one epoch one iteration we all get here and then they get here and they get here.",
                    "label": 0
                },
                {
                    "sent": "And eventually each model goes into its own different local minimum.",
                    "label": 0
                },
                {
                    "sent": "And this is a 2D projection of function space that I'm not going to explain, but what we see is that they all go to a different place and that depending on how you initialize things or guide training.",
                    "label": 0
                },
                {
                    "sent": "Those trajectories go to very different regions in the space of functions.",
                    "label": 0
                },
                {
                    "sent": "So let's get back to curriculum learning and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What it is about starting from easy examples that that was Jeff Hellman's paper.",
                    "label": 1
                },
                {
                    "sent": "So we want to train with easier lower level abstraction illustrating easier examples illustrating lower level abstractions, and then gradually introduce more difficult ones, eventually presenting the examples that are more interesting.",
                    "label": 1
                },
                {
                    "sent": "Representing higher level abstractions and more difficult cases.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, this these ideas may remind some of you, so called continuation methods, which are global optimization methods that work on the principle of optimizing something different.",
                    "label": 0
                },
                {
                    "sent": "Then, when you care about that, is easier to optimize and then gradually.",
                    "label": 0
                },
                {
                    "sent": "Moving towards what you care about.",
                    "label": 0
                },
                {
                    "sent": "So let's say you want to optimize this target objective function that has a lot of local minima.",
                    "label": 0
                },
                {
                    "sent": "Are we going to smooth it?",
                    "label": 0
                },
                {
                    "sent": "Smooth it and smooth it until it's easy to optimize it.",
                    "label": 0
                },
                {
                    "sent": "Maybe even convex, so we have this surrogate criterion.",
                    "label": 0
                },
                {
                    "sent": "We can optimize it and then we're going to gradually move back towards our target objective, continuously ANAN along the way.",
                    "label": 0
                },
                {
                    "sent": "Track local minimum and this way we're going to find a solution is not guaranteed to find to find a global optimum, but in practice this has been used very successfully.",
                    "label": 1
                },
                {
                    "sent": "For example in chemistry for finding configurations of molecules, an independent on how you designed to smooth.",
                    "label": 0
                },
                {
                    "sent": "How do you sign to change your your family functions?",
                    "label": 0
                },
                {
                    "sent": "Is going very well and you can.",
                    "label": 0
                },
                {
                    "sent": "You can see the analogy with simulated annealing with it, which would be a stochastic version of this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I'm trying to explore the hypothesis that curriculum learning can be seen as a continuation method, and maybe that's one reason why it could help.",
                    "label": 0
                },
                {
                    "sent": "Getting good results.",
                    "label": 0
                },
                {
                    "sent": "So we are going to define a sequence of training distributions.",
                    "label": 1
                },
                {
                    "sent": "Initially we're going to have the easier examples, as I showed earlier, and so we have a.",
                    "label": 0
                },
                {
                    "sent": "We were changing.",
                    "label": 0
                },
                {
                    "sent": "The training criterion is we're picking the distribution on those easier examples.",
                    "label": 0
                },
                {
                    "sent": "And then we dragged to give more weight to the more difficult ones until we reach the target distribution.",
                    "label": 1
                },
                {
                    "sent": "So you can see that we have really a sequence of.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In criteria.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now we are sort of the experimental part of the presentation.",
                    "label": 0
                },
                {
                    "sent": "We have this general notion of organizing representation of examples in the selection of examples.",
                    "label": 0
                },
                {
                    "sent": "But it's not clear how to do that, so we're going to do some experiments.",
                    "label": 1
                },
                {
                    "sent": "I'm going to tell you about 3 three series of experiments.",
                    "label": 1
                },
                {
                    "sent": "The first experiments are with the toy.",
                    "label": 0
                },
                {
                    "sent": "Data with a simple distribution where the learner is a perceptron, so the criterion is convex and we're going to try two different ways of ordering examples.",
                    "label": 0
                },
                {
                    "sent": "Of presenting easier examples first, one way is to present the examples that are less ambiguous first, in the sense that the.",
                    "label": 0
                },
                {
                    "sent": "The distance to the distant surface is greater or the margin is larger the other way we're going to look at is cases where we introduce noise in the examples and we can control how much noise there is in these examples, and then we can order examples by how much noise there is, and so we're going to start with the cleaner examples and then gradually introduce more noisy examples.",
                    "label": 0
                },
                {
                    "sent": "The second experiment is an object classification task.",
                    "label": 0
                },
                {
                    "sent": "We have three categories of shapes, and we're going to have two stages.",
                    "label": 0
                },
                {
                    "sent": "In the first stage, we're going to show similar shapes, and the second stage we can have sort of more variability in the shapes and this will be the distribution we care about in the end.",
                    "label": 0
                },
                {
                    "sent": "And finally, the third experiment is going to be a language modeling experiment.",
                    "label": 1
                },
                {
                    "sent": "Where are we going to use something that's inspired from how children learn where we're going to show sentences with a smaller vocabulary first?",
                    "label": 0
                },
                {
                    "sent": "And we gradually going going to expand the vocabulary, showing sentences illustrating more and more complicated concepts in a sense.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here are some results.",
                    "label": 0
                },
                {
                    "sent": "So these are with the perceptron learning where we have a convex training criterion and we train for just online 4.",
                    "label": 0
                },
                {
                    "sent": "Before getting to convergence because of course if you wait long enough with the perceptron here you everything every model goes to the same place.",
                    "label": 0
                },
                {
                    "sent": "And what we see here is for different number of inputs that the strategy which orders the examples by by margin.",
                    "label": 0
                },
                {
                    "sent": "So the less ambiguous first generally converges faster, so that after a fixed number of updates we get to lower generalization error.",
                    "label": 0
                },
                {
                    "sent": "This the upper curve is the standard IID sampling.",
                    "label": 0
                },
                {
                    "sent": "Where is here we have taken the same set of examples but just order them differently.",
                    "label": 0
                },
                {
                    "sent": "So some.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is happening.",
                    "label": 0
                },
                {
                    "sent": "And basically the same kind of results are obtained if we order by the amount of noise in the input.",
                    "label": 0
                },
                {
                    "sent": "So in a sense previously it was.",
                    "label": 0
                },
                {
                    "sent": "More like noise in the output.",
                    "label": 0
                },
                {
                    "sent": "OK, so now let's move to a slightly more challenging time.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ask.",
                    "label": 0
                },
                {
                    "sent": "We have the data set of interest has triangles, ovals and rectangles with varying size angles.",
                    "label": 0
                },
                {
                    "sent": "Scale foreground and background color and so on.",
                    "label": 0
                },
                {
                    "sent": "And we made up a simplified version where the triangles can only be equilateral.",
                    "label": 0
                },
                {
                    "sent": "The ovals can only be circles and rectangles can only be square, so there's less variability in this version of the data than in the target distribution.",
                    "label": 0
                },
                {
                    "sent": "And we going to train with this for awhile and then switch to the target distribution and see if by doing that we get better results than by training all the time.",
                    "label": 0
                },
                {
                    "sent": "With this the target distribution.",
                    "label": 0
                },
                {
                    "sent": "Just a second set or a mix of.",
                    "label": 0
                },
                {
                    "sent": "We tried both.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is with the three hidden layer deep neural net that we've been playing with using in supervised pre training and we found for this type of data set and this type of architecture that indeed the local minima issue the way we initialize could could make a difference even though if you always if you use random initialization the results are consistently going to the same quality of solution.",
                    "label": 0
                },
                {
                    "sent": "So as I said we're going to train for a fixed number of epochs using the easier shapes and switch the target distribution.",
                    "label": 1
                },
                {
                    "sent": "Until either training error becomes saturates or we use early stopping to decide when to stop using a validation set.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what I'm showing are the results where we vary the time at which we switch.",
                    "label": 0
                },
                {
                    "sent": "From the examples to the hard examples in number of iterations through this 10,000 training examples.",
                    "label": 0
                },
                {
                    "sent": "So at 0 means we're training only with the hard examples.",
                    "label": 0
                },
                {
                    "sent": "An 128 means the first 128 iterations through the data.",
                    "label": 0
                },
                {
                    "sent": "We use these examples and the next remainder, which is roughly another 128.",
                    "label": 0
                },
                {
                    "sent": "We use the target distribution.",
                    "label": 0
                },
                {
                    "sent": "An only why on the Y axis we see test error box plots over.",
                    "label": 0
                },
                {
                    "sent": "Something like 20 random initializations.",
                    "label": 0
                },
                {
                    "sent": "And what we see is that.",
                    "label": 0
                },
                {
                    "sent": "Translation error is substantially lower if we use these easy examples to get started.",
                    "label": 0
                },
                {
                    "sent": "And this is true whether we.",
                    "label": 0
                },
                {
                    "sent": "We give more or less time after the switch .2 to both cases because eventually, well, none of these essentially overfits significantly.",
                    "label": 0
                },
                {
                    "sent": "We also tried what Nicola asked, which is mixing the two simple and easy and doing IID on those and the results are roughly around here so.",
                    "label": 0
                },
                {
                    "sent": "No, no, that's not the same thing.",
                    "label": 0
                },
                {
                    "sent": "The question was if we try with IID ordering with a mix of the easy and hard.",
                    "label": 0
                },
                {
                    "sent": "So putting in the easy examples helps here, maybe because they just said isn't that big and it introduces more variability in the data.",
                    "label": 0
                },
                {
                    "sent": "At some point.",
                    "label": 0
                },
                {
                    "sent": "That's true, that's true if you don't.",
                    "label": 0
                },
                {
                    "sent": "If you don't switch to the target example, then it's bad, yes.",
                    "label": 0
                },
                {
                    "sent": "No, there there is a minimum.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Jerome was here would be able to answer that question later.",
                    "label": 0
                },
                {
                    "sent": "Hopefully.",
                    "label": 0
                },
                {
                    "sent": "Right, so yeah, if you don't train enough with the hard examples, you'll see that in the next experiment you'll see this effect in the next experiment actually.",
                    "label": 0
                },
                {
                    "sent": "So the next experiment is with language.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data.",
                    "label": 0
                },
                {
                    "sent": "And the objective is to compute a score for the next word given the previous words.",
                    "label": 1
                },
                {
                    "sent": "And the training criterion is a ranking criterion.",
                    "label": 1
                },
                {
                    "sent": "So we want the score of the observed word to be larger than the score of any other word with some margin.",
                    "label": 0
                },
                {
                    "sent": "It's a hinge loss.",
                    "label": 0
                },
                {
                    "sent": "And then we will measure is the rank the average rank of the correct word.",
                    "label": 0
                },
                {
                    "sent": "And they the class of functions gained a deep architecture with a particular structure that I started working on in the 2000 and that color and Western.",
                    "label": 0
                },
                {
                    "sent": "Or coauthors on this paper.",
                    "label": 0
                },
                {
                    "sent": "Presented at last I see ML showing that this kind of architecture actually does very well at a number of natural language processing tasks such as chunking, part of speech, tagging, semantic role labeling, essentially achieving state of the art or better than state of the art in these tasks.",
                    "label": 0
                },
                {
                    "sent": "So this is all trained by stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia, which has about 500 million words as a training set.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are the results that I'm going to explain now.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do?",
                    "label": 0
                },
                {
                    "sent": "Well, first let me explain the graph.",
                    "label": 0
                },
                {
                    "sent": "The red dots here represent the results with a normal IID training.",
                    "label": 0
                },
                {
                    "sent": "So we just get the sentences from Wikipedia and we use a window of words as input and then we predict the next word.",
                    "label": 0
                },
                {
                    "sent": "And we look at the rank of the correct word versus the other words, and we get some some test error that decreases as we do more and more updates.",
                    "label": 0
                },
                {
                    "sent": "This is this is 1500 million updates but.",
                    "label": 0
                },
                {
                    "sent": "It runs reasonably efficiently.",
                    "label": 0
                },
                {
                    "sent": "The blue curve is showing what happens with the curriculum training, so the curriculum strategy here is start with the most frequent words only during training.",
                    "label": 0
                },
                {
                    "sent": "So we take the sentences that contain only words from the 5000 most frequent words vocabulary and we train with that until this point and then we switch to the vocabulary with 10,000 words and then we switch to 15,000 and 20,000.",
                    "label": 1
                },
                {
                    "sent": "So the target distribution here is 20,000 words.",
                    "label": 0
                },
                {
                    "sent": "Vocabulary.",
                    "label": 0
                },
                {
                    "sent": "And we are always testing on the 20,000 words vocabulary data.",
                    "label": 0
                },
                {
                    "sent": "So yeah, the test set is from the target distribution as well.",
                    "label": 0
                },
                {
                    "sent": "Now what happens here is that the network trained with only 5 to 5000 most frequent words when it sees a word from the 20,000 large vocabulary doesn't make very good prediction, and so that's why the errors are pretty high when you test on with respect to that.",
                    "label": 0
                },
                {
                    "sent": "As soon as you introduce new words, you can see that the error goes down quickly and here you introduce essentially examples from the target distribution.",
                    "label": 0
                },
                {
                    "sent": "Very quickly, the network with the current curriculum strategy surpasses that in the other one.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that seems to work.",
                    "label": 0
                },
                {
                    "sent": "We can say yes.",
                    "label": 0
                },
                {
                    "sent": "Machine learning algorithms can benefit from a curriculum strategy.",
                    "label": 1
                },
                {
                    "sent": "And the next question we are interested in is why?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I don't think I have the answers, but at least I have some hypothesis.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, maybe these strategies help to converge faster to a minimum, and what one could maybe suppose that we are wasting less time with those more difficult examples.",
                    "label": 1
                },
                {
                    "sent": "Harder to predict examples.",
                    "label": 0
                },
                {
                    "sent": "So that's 11 possibility.",
                    "label": 1
                },
                {
                    "sent": "The other possibility that applies only to the case where you have non convex training criteria is that we get to better local minimum an maybe because the curriculum might be a particular continuation method.",
                    "label": 0
                },
                {
                    "sent": "Now one thing we noted both with the curriculum strategy and with other strategies for deep architectures is that they seem not only to find better local minima with respect to the training criterion, but if I in fact the local minima defined are better in terms of test error.",
                    "label": 0
                },
                {
                    "sent": "In fact the effect is even more pronounced on the test error then on the training error.",
                    "label": 0
                },
                {
                    "sent": "So the this kind of thing actually acts like a regularizer, but but it's not the kind of regularizer whose effect disappears when the number of examples goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So that's interesting and my last slide is, well, what's next?",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're still stuck with the question how do we define good curriculum strategies?",
                    "label": 0
                },
                {
                    "sent": "We presented some simple cases.",
                    "label": 0
                },
                {
                    "sent": "Are there some general principles?",
                    "label": 0
                },
                {
                    "sent": "We should try to understand what makes curriculum strategy work.",
                    "label": 1
                },
                {
                    "sent": "An one thing we're working on now is the idea trying to automate the these things as much as possible and trying to have learning algorithms that right on the frontier of with things that they can do well.",
                    "label": 0
                },
                {
                    "sent": "So avoid not only the two easy examples, but also the two hard examples and move that Frontier as the learner gets better.",
                    "label": 0
                },
                {
                    "sent": "I'm done.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}