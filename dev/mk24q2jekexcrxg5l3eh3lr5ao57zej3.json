{
    "id": "mk24q2jekexcrxg5l3eh3lr5ao57zej3",
    "title": "Efficient Regression for Computational Photography: from Color Management to Omnidirectional Superresolution",
    "info": {
        "author": [
            "Maya Gupta, Department of Electrical Engineering, University of Washington"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Regression",
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_gupta_omnidirectional/",
    "segmentation": [
        [
            "OK, this is joint work with Eric Garcia and with Rahman Aurora."
        ],
        [
            "So we're going to talk today about regression.",
            "So just to make sure we're on the same page, annotation wise will assume that we've been given N training pairs.",
            "These pairs have an XI, an AYI, and this is all very standard.",
            "RX is going to be in some D dimensional space and Ry.",
            "I will just assume a scalar.",
            "And we're going to model these outputs Yi, as some function XI plus some noise, and our goal in regression is to estimate F of X for some new test sample X."
        ],
        [
            "OK, so a lot of computational photography applications can be considered regression applications.",
            "Going to focus today on color management, and I'll talk a little bit about gamma mapping.",
            "It's sort of as a motivation in the first half of the talk, and then the second half all talk about Omni directional super resolution.",
            "But all of these."
        ],
        [
            "Applications to computational photography have in common as something that they really very low dimensional in general, so we're talking about dimensions of two to six dimensions.",
            "So a lot of regression has been focused on high dimensional regression.",
            "Here we're going to focus on low dimensional regression.",
            "The other issue is in computational photography.",
            "In these applications, you want to pump through not just one test sample, but millions of test samples in a very, very fast time.",
            "But if we're doing something like color management videos, we're going to have to pump through a lot of a lot of pixels.",
            "So we need to be able to evaluate this function F very very fast.",
            "So a simple solution if you want a function that you can evaluate very fast."
        ],
        [
            "Maybe if we just did linear regression?",
            "So linear regression is fast, but it's not really good enough and I'll highlight that a little later.",
            "Of course, in this example here, it's not really linear regression that's the problem, but.",
            "OK, let's see here so."
        ],
        [
            "As I said, I'll start off by talking about the color management problem as motivation.",
            "So color management of the problem really is a device dependent.",
            "Colors depend on the device, right?",
            "So if I think about the color 000, what color is that?",
            "You know it's black, right?",
            "But if I look at what the scanner thinks, that Black is an I look at what this monitor thinks that black is.",
            "They're not exactly the same, and if you print out black, that's going to be a different black.",
            "And if you project it well with the projector, black is actually white, right?",
            "So.",
            "We have to be careful about trying to transfer these colors between these different devices."
        ],
        [
            "So the color management solution is to map everything to a device independent color space an all focus on scilab today, because it's the most common device independent color space."
        ],
        [
            "And it has the nice property that in scilab Euclidean distance approximately mimics human perceptual distance.",
            "So if you're if two colors are this far apart, here is Coca Cola red, and here is bright red.",
            "And here's Coca Cola, Renton, here sort of cherry red.",
            "That that'll be sort of perceptually the same distance.",
            "If it's Euclidean the same distance, and I'll talk a little bit more about that later.",
            "OK, as we transform from each of these devices, so we'll go from the scanner RGB and will try to go to this device independent space and we'll use something color management ICC profile.",
            "This is just a regression, so we're going to somehow former regression that Maps us from this color space to this color space and will have regressions.",
            "I go forward and backwards between these independence and the device color spaces here."
        ],
        [
            "And these mappings can be very highly nonlinear, particularly for printers.",
            "These mappings are just gross.",
            "You've got all these effects of the ink and the way it absorbs in the paper, and the halftoning algorithms there's a lot of nasty things that happen that make these these mappings highly nonlinear.",
            "OK, so that's how we met."
        ],
        [
            "Print and other related issues.",
            "Gamut mapping.",
            "So a lot of companies are coming out with these great hardware with great displays that have these really beautiful colors that you can render, so maybe you shot your video an if you're you know, film company you shoot your video very carefully and you know what your colors are supposed to represent and you shoot them for a particular gamut.",
            "So maybe these are the colors that you think you're going to be able to display and now sharp comes along and they've got a new TV where their red is this really bright, beautiful, gorgeous red?",
            "So what happens if you just display the color data there?",
            "Or even if you do some sort of linear transform, if you transform around the neutral axis, all of your skin tones are going to get stretched out.",
            "So here's if you had maybe original gamut, and it's always fun to give talks with color to find out what the display is going to do examples, but hopefully you can see here that if we just do the linear regression, what happens to our skin tones is everyone ends up looking a bit drunk or sunburn, so that's generally not considered good, and so we need to have more complicated nonlinear regressions.",
            "But we still of course want to be very fast, because with gamma mapping you're going to do this very quickly as you go through the device."
        ],
        [
            "OK, here is just another example of where you'd like to be able to do these fast regressions is if you want to do custom color enhancements.",
            "This is an example where we start with the daylight scene and we had an artist transform that to a scene at sunset and we can now go and compare these pixels and create those training samples that say oh this blue should become this color.",
            "This blue should become this color etc and then we can create a regression and use that to create any scene, daylight scene and map it to sort of a sunset sort of look as another."
        ],
        [
            "Example of that, you might want to form a mapping that takes a movie and then re Maps it as if it had been rendered in scenic color, which is kind of early film color.",
            "Using the 1930s, and so you get that 1930s film color.",
            "Look for your for your home video today."
        ],
        [
            "OK, so all of these applications are great.",
            "How do they do this?",
            "Fast regression?",
            "Well, they use a look up table and look up tables is just a grid.",
            "So you started with some data, some color pairs your input color and your output color.",
            "They're all just kind of randomly an you apply your favorite state of the art regression algorithm and you get some F had of X and then you evaluate F out of."
        ],
        [
            "On a grid, and that's going to be a look up table."
        ],
        [
            "Then you throw away your data and you just keep your look up table and now when you get a test."
        ],
        [
            "So here's my test sample.",
            "It came in here off the grid and you just linearly interpolate it from the surrounding vertices.",
            "OK, so."
        ],
        [
            "This sounds great.",
            "As I said, we use your favorite state that regression, so maybe for example, it's an empirical risk minimization.",
            "So what would that do?",
            "An empirical risk minimization is going to make sure that this F had of X is good at making sure that if I put XI in the F hat of XI, will be close to why I write if I have low training loss, low loss of my training data.",
            "But now if we look at the whole joint system, if I put in that same training point XI over here, I'm going to linearly interpolate it from these four points.",
            "And I'm going to get some different value out, so even though I might have done a really good job here, getting this F had of X to be close to this.",
            "Why I?",
            "My final output is screwed up, it's no longer exactly that why I in a sense I'm minimizing the wrong empirical loss because I'm not taking into account this linear interpolation error that's going to happen, or this later tribulation."
        ],
        [
            "OK, so this process is suboptimal because this regression doesn't know what's happening later in the pipeline and in signal and image processing this is often where we still get the big gains is by realizing that we have independent systems that are all fairly good and fairly optimal.",
            "But when we have these joint systems and we start to bring together parts of the block diagram, we can make things more optimal."
        ],
        [
            "OK, so in this talk what I'm going to talk about is how to fix this problem, and basically we're just going to do things jointly.",
            "We're going to take into account these interpolation errors.",
            "So now we do that.",
            "We gotta go back and rethink.",
            "I know everyone thinks they know how interpolation works, but let's just look over the math because then then we can really make sure we under."
        ],
        [
            "And what's going on here?",
            "So here we have a simple 2D example.",
            "And here's my grid and my grid output values are these B1B2B3, etc.",
            "These blue dots, so this is maybe you know the value 3.",
            "And this is the value 5 and the value 27, etc.",
            "And I'm going to linearly interpolate this test point here, and then we'll talk about that one.",
            "So for this test point here, well, linear interpolation does is.",
            "It gives this vertex a weight that corresponds to the area or the volume of this cell over here.",
            "So this vertex is B5, so be 5 gets this area.",
            "And so I see where this point is in the cell.",
            "It's out Lambda 11.",
            "It's out Lambda 1 two here.",
            "We've normalized this to have unit length, so this area is just Lambda 11 times Lambda 1 two.",
            "So I see that why had of one will equal Lambda one Lambda 1 two times B5.",
            "So this B is the vector of B1 through B 9.",
            "Outputs here and similarly the weight on B1.",
            "The first guy is the area of this cell which will be 1 minus Lambda, one 1 * 1 minus Lambda 1 two.",
            "This weight over here etc.",
            "So since I'm only interpolating these four things of the B1 through B9 outputs.",
            "I only have weights on four of them.",
            "OK, so so I can write this as a vector as well.",
            "This weight vector and I can just say my yhat one.",
            "My linear interpolated output is just some weight vector.",
            "Transpose times my output values for the notes."
        ],
        [
            "We can do a similar thing for this.",
            "Why hat too?",
            "And you'll notice that here it's choosing mostly different weights, both Y one and Y two share B5, so they both give some weight to be 5, but otherwise they're using different vertices OK, and so now just as a man."
        ],
        [
            "Notation we're going to take these two outputs, yhat one and Y hat to both scalars and put them together in a vector yhat.",
            "So that's my linear interpolation output vector, and I'm going to take this weight vector here and this way vector here and make them columns of a matrix.",
            "So that's my matrix W. Here, my linear interpolation weights and then this is just, you know, W transpose B might look up table values.",
            "OK, so if I'm interpolating a bunch of points at once, I get this nice matrix equation like this.",
            "OK, So what do I want to do?",
            "I want blue points.",
            "I want a look up table that interpolates my training data really well.",
            "So the."
        ],
        [
            "Is I want to look up table values B such that when I interpolate them W transpose B and I do this for my training inputs that it matches the training outputs Y.",
            "Right, so here is my data again.",
            "These scattered points and I'm going to try to find the points on the grid here.",
            "The colors here such that when I lean into plate, all of these training data points, I'm accurate.",
            "OK, and so this is.",
            "This isn't really very bad, I just need it.",
            "Sounds like a lot of parameters 'cause I have to find the points for all of these good points, but I just need to solve this squared quadratic program.",
            "OK, anybody see a problem?",
            "OK, you might notice there's no.",
            "Maybe there's no data here in this cell.",
            "There's no data in this cell is maybe a point down here if I don't have enough data, I might have nothing that tells me what to set this vertex as, right?",
            "So in general this is."
        ],
        [
            "Going to be underdetermined in a lot of the applications that we worry about.",
            "Underdetermined is always a good thing because it means you get to add more criteria.",
            "You could have more say about which of the many solutions you get to choose, right so?"
        ],
        [
            "Add a regularizer and we're going to add a regularizer that lets us choose solutions that are smooth on the grid.",
            "Now if you want you can add a regularizer that does something else, but I often prefer solutions that are somewhat smooth.",
            "OK, so again, here's our empirical loss now, which doesn't just take into account the interpolation error.",
            "The only loss is the linear interpolation error.",
            "There's no regression step anymore.",
            "All we're doing is directly finding a look up table that minimizes the error when we interpolate the training data.",
            "And then here we have our regularizer, will call Lambda JAB on these output nodes.",
            "OK, so these output nodes basically form a graph, right?",
            "So the possibly obvious."
        ],
        [
            "Regular would be to use the graph Laplacian if you're not familiar with it.",
            "This is going to look at all adjacent nodes in the graph by BJ and just make sure that they're close and squared error, and so if we do this, these blue dots here.",
            "Now my training samples on I do this, this lattice regression as we're calling it, you'll end up with a function fit that looks like this.",
            "Now this is pretty good.",
            "One thing you'll notice about graph Laplacian is it once all the nodes to be similar, which means that it really wants far out nodes it wants everything basically to be close to the average.",
            "Of the function.",
            "So you get this action out here where things are flattening out and things are flattening out.",
            "Now if I have something like a device, whereas I turn up the crank, I want things to get brighter and brighter and brighter.",
            "This flattening out is a bit of a problem, and so we found that this actually didn't work well for the kind of applications we were interested in, so."
        ],
        [
            "So we applied a what we call a graph, Hessian, just a second order version of this.",
            "So we now look at 2nd order differences and minimize that.",
            "So now if my function was just a plain, then this graph asking would be 0, so it doesn't penalize plane fits and the same training data points.",
            "It's hard to tell, but these blue points are exactly the same and you get this radically different function that happens also to be a bit smoother because you're allowing it to go with the natural trends there.",
            "Yes, over gridpoints nonuniform.",
            "You could have nonuniform good points that won't affect."
        ],
        [
            "Much because it just you just have to define the weight matrix, so that's not a big problem, but in all the applications we care about because we're really interested in speed and doing things simply, we don't have nonlinear non uniform good points.",
            "We have nice uniform.",
            "The policy and in the graph as soon as the ordinary Hessian."
        ],
        [
            "If these are just uniform grids, that's my question.",
            "Oh well, it's a discrete version, yeah?",
            "And I'll show you later spherical grid and then some of this intuition goes out the window, but it all works fine."
        ],
        [
            "OK, so this was our so both the graph Laplacian and the graph Hessian are regularised JB that have this quadratic form.",
            "You can write them as be transposed KB where this kernel just depends on the orientation of your grid and the size of your grid.",
            "So you precompute that K and then you have this nice lattice regression problem.",
            "Minimize again, the linear interpolation error and this quadratic term, and you'll notice that everything here is nice and quadratic, and so not surprisingly, we have a nice closed form solution.",
            "Now this closed form solution does require a matrix inverse, but this matrix inverse is very, very sparse, because remember each point is only being triple rated by the cell around it.",
            "That weight matrix is is very, very sparse and you just go back for a second here."
        ],
        [
            "In the 2D case, there was only four nonzero entries in the 3D case will be 8 nonzero entries.",
            "Here in my matrix was nine because I only had a good with nine output values.",
            "In color management, we often use a grid of 17 by 17 by 17, so I don't remember the number of Papa had something like 4318 nodes, of which only eight are going to be on at anytime, so these fairly sparse in that sense."
        ],
        [
            "OK, so we have a nice circles from solution."
        ],
        [
            "Sparse an let's look at some results.",
            "So what we're doing is we got desired color here, so we'd like to be able to output Coca Cola red.",
            "We send that to our look up table that we built an.",
            "It tells us this is the RGB you should send to the printer to get out that Coca Cola.",
            "Read at least its best guess and then we print something and we get out something that probably isn't exactly Coca Cola red and we measure the error between what we actually got out and the color we had hoped to get.",
            "How do we measure the error between this color and this color?",
            "Well, we could just use Euclidean distance in CIELAB space.",
            "Because that's approximately perceptually uniform color management, we call that Delta E 76 for 1976, which is to say we have updated formulas, so we're using the generally accepted best formula, which is Lt. 2000, but very similar to Euclidean distance with some corrections.",
            "And here we're comparing lattice regression.",
            "Our group had done some of the earlier state of the art work in this area for regression.",
            "For color management using a local linear regression with enclosing neighborhoods with either a regularizer or local Tikhonov regularizer.",
            "And then we threw in Gaussian process regression 'cause nips.",
            "People seem to like calcium process regressions we thought will compare to that even though we know it's not state of the questions.",
            "Yeah, how do you measure from the printed?",
            "You have to use another device to measure from the printed output.",
            "How do we get the training data?",
            "No, not in this case.",
            "You said, how do you look at the error?",
            "So you say we measure the CI elab.",
            "There's a spectrometer here.",
            "That yes, there's a spectrophotometer.",
            "Yeah, so this is actually like a piece of paper, yeah?",
            "And then we use a spectrophotometer to get the CIELAB values, and that's how we get the training data as well.",
            "So all of this actually takes kind of a lot of effort.",
            "17 is the grid, yeah, so.",
            "To be able to do this.",
            "Great, of course.",
            "The lookup table comes bigger, but I assume that you get a better result.",
            "It's not the common wisdom, actually.",
            "A lot of people use sparser look up tables more like 9 by 9.",
            "By 9, I mean think about.",
            "Even if you had like a two by two by two, then you be saying that the whole color mapping could be just one linear well, linear regression.",
            "Linear interpolation gives you a more flexible function than just linear regression, but that would already give you something that was sort of more interesting than linear.",
            "And now you've got 17 by 17 by 17.",
            "I don't know.",
            "You've got quite a lot of room to capture some non layers.",
            "What you see is that we're doing pretty well here, yes?",
            "The question process regression, how do we use Gaussian process regression?",
            "Funny you should ask.",
            "When I get back to that.",
            "No, it's here somewhere.",
            "Somewhere in some backslides."
        ],
        [
            "Serial.",
            "OK, so we're modeling the data is being drawn from a Gaussian process, so we had our original color data.",
            "We learn the Gaussian process and then we do what I said.",
            "We estimate the look up table and then we use the look up table as before.",
            "I think the most maybe interesting part of the question is how do we fit the parameters?",
            "We use the maximizing marginal likelihood technique.",
            "Can we use some software?",
            "I think from Williams and Rasmussen seemed like fairly off the shelf application.",
            "We fiddled around with it a bit to get it to work.",
            "As nicely as we could, we we wanted to look nice.",
            "Left final place again though.",
            "It's like a fast preview of the talk."
        ],
        [
            "OK, so in Delta E 2002 is about a just noticeable difference.",
            "So these mean values here all under two, which means that on average you're able to reproduce colors without you wouldn't be able to tell the difference.",
            "Our maximum errors, however, are quite a bit bigger like 6.75, and here we're just looking at how many errors were basically noticeable.",
            "So with the lattice regression you're getting like 60 errors being noticeable as opposed to like 300 errors with the Gaussian process regression.",
            "And let me."
        ],
        [
            "Show you that visually, so here all the test samples is 980 eighteen test sample colors all in the gamut of the printer and the size of the color here shows you how big the error is.",
            "So for local Ridge it made a really bad error.",
            "On Fuchsia you can see that Gaussian process regression is having a lot of Blues and purples, which is just really hard at the lattice.",
            "Regression is doing pretty well throughout.",
            "Its biggest problem seems to be with some of the beige and neutral colors.",
            "But that will depend on the printer.",
            "OK yeah, this also depends on your training data as well right?",
            "Yes, so we use the standard.",
            "I can't remember the number of the tests are, but it's a very standard test chart.",
            "It's the one that promises for all their commercial color management applications.",
            "And it's basically a regular sampling of the space with some extra neutrals and some extra saturated colors."
        ],
        [
            "OK so I'm gonna talk about a second application to Omni directional superresolution, so we're going to take the same lattice regression ideas and the math and just apply to a totally different kind of grid.",
            "So here we've got omnidirectional cameras, an omnidirectional camera hardware is a little more expensive than normal camera hardware, which means the sensors tend to be lower resolution, so.",
            "However, if we have if we have our camera here and we have this low resolution camera, we could just maybe turn it'll it'll take another picture, turn a little, take another picture, turn around, get a few different pictures, and after we got a bunch of these pictures, the hope is that we can just land them all together somehow and create 1 high resolution Omni directional image.",
            "So there's been various work on this."
        ],
        [
            "We consider the state of the art to be arcana Frossard work.",
            "They want to ICPR 2008 best paper award for this work and followed up with a Journal paper and what they're doing is they're using spherical foray transform.",
            "And both they and us, we will assume that we don't necessarily know how these images are registered, so we don't know exactly what the relationship is between these images that you took.",
            "So you have an alignment problem and they saw that with the iterative conjugate gradient descent approach."
        ],
        [
            "OK, So what we're going to do?",
            "This this correct registration issue is really a very nasty non convex optimization problem.",
            "And what we're going to do is, say, say you have a candidate registration.",
            "We need to decide how good is that candidate registration, so will take some subset of the images.",
            "Ann will take those as our training data and will use lattice regression to learn a high resolution spherical grid.",
            "So now are look up tables on a spherical grid, and so are look up tables actually in grid in 2 dimensional units of latitude angles and the lanja tude angles.",
            "So some grid cells look totally different than other grid cells.",
            "But we don't really worry so much about that.",
            "So use lattice regression you on some of the data to get a high resolution spherical grid and now you see how well does that spherical grid interpolate some of the left out low resolution images.",
            "So if it's if it's all sort of consistent, then you probably have a good registration of all the images, and if it's not consistent, then it's not a very good registration.",
            "OK, so this gives us objective function that we can use to evaluate how good any registration is.",
            "Now we still need to register all the images if I have N images.",
            "Each of these images has three degrees of registration freedom compared to each other image.",
            "So this one will stay fixed and so in total will."
        ],
        [
            "Of 3 * N -- 1 dimensions of registration to try to optimize over ASOS is still sort of a nasty global optimization problem, and you could use any global optimizer that you're comfortable with, and I think that's really the trick with global optimization is what do you trust?",
            "Don't trust any of them.",
            "But what we use is fully informed particle swarm, so this is a global optimization method where you make some guesses and then you sort of take these course regional gradients an you move in that direction and there's some inertia and there's some velocity and sort of wanders around the space into someone intelligent way.",
            "But the problem is every time we want to say, here's a candid registration, evaluate how good it is, we need to go and build a lattice regression and then evaluate and able to do this very fast becomes important."
        ],
        [
            "OK, so here's a couple of examples results.",
            "This is, as you can see with real data.",
            "Not sure how well you can see this.",
            "This is dark and foussard spherical for transport method and this is the lattice regression method.",
            "Both of course have problems, at least from where I'm standing.",
            "However, it's a lot easier, for example, to tell that this is a chair, then that's a chair, and it's easy to tell that that's a whiteboard, and there's some pictures on the wall, etc.",
            "And the runtimes here are really significantly faster.",
            "So for 128 by 120 images vehicle for a transform, if I have 80 images, was taking us about 80 minutes to run, whereas with so lot of this lattice regression method on the sphere, we're seeing about 3 minutes to run and for 256 by 256 image we couldn't get this vehicle for transform to really compute it."
        ],
        [
            "And here's some PS in our numbers.",
            "I apologize for the image quality here, so again, this is the number of low resolution images that you have to super resolve and this is the PS and are the two blue lines.",
            "Here are the slightest regression method solar and the two orange lines are the spherical Fourier transform and there's basically attendee be difference to any appropriate comparison here and the two lines one is a 10 degree uncertainty, so I tell you look I took these pictures and I know how closely are within 10 degrees.",
            "I know this guys about 70 degrees off from this guy and this guys about you know here in this guys here.",
            "You just need to futz within a 10 degree window versus the 90 degree uncertainty, which are the dotted lines, which is a lot worse, right?",
            "Just gave you these images.",
            "I'm like I got these other trash can, I don't.",
            "I don't know how these register you help yourself, so that of course is creates quite a bit of gap if you don't know anything about the registration.",
            "OK."
        ],
        [
            "So this is all very pretty visual."
        ],
        [
            "10 DBPSNR sounds great, but the really important."
        ],
        [
            "Question is, how well does it help a robot find home?",
            "So these are these visual homing problems where you throw a robot in a room and you declare that something is at home and you give a robot a picture of what it looks like if he's home.",
            "So the robot starts here and starts taking a bunch of pictures and compares that with its internal notion of home.",
            "And then it does some gradient descent or some some attempt.",
            "In this case it's a match filtering to try to decide which direction to go, and it says, oh, I bet this way is closer to home and it takes a bunch more pictures and it says, oh, I think Holmes, probably over there takes a bunch more pictures, compares to its notion of home, etc so.",
            "The usual metric here is the mean probability that the robot actually finds finds its way home.",
            "And as we can see, as long as we have, if you only have two images, then in this one case with 15 degrees uncertainty, this pickle for transform gets it right 12% of the time we get right 10%, but in every other case we do quite a bit better, for example 5 images we find home 42% of the time versus 22 with 20 images.",
            "If you give it no information about the registration, so 90 degrees.",
            "Uncertainty about the registration of these images.",
            "The last suggestion method, and 20 images is getting home 80% of the time versus 10% of the time there.",
            "Yeah, thank you."
        ],
        [
            "OK, so I'm going to go ahead and start concluding here.",
            "So a lot of suggestion is fast and well.",
            "It's pretty fast and it's pretty accurate, so that's that's kind of."
        ],
        [
            "In handy, it's particularly fast if what you want to output is also on a grid, and then you can just learn the grid in the 1st place so you can learn a grid or learn an output that interpolates your training data well."
        ],
        [
            "Because it's fast, you can spend time and other stuff so a lot of why we do so much better than the other kind of facade method is because we can do this massive global optimization.",
            "And because we can do the global optimization steps very fast, we can do a lot better job exploring the space."
        ],
        [
            "We use a graph fashion, but for your application you might need a slightly different regularizer on the grid, and that's always a fun problem to think about."
        ],
        [
            "And for details, there's some papers that you can check out, thank you.",
            "I'm a practitioner where I photograph art and I use color management to try to get accurate colors.",
            "And what I find is 1 big problem is that in going from the camera which claims to have a 14 bit sensor to a monitor which is difficult to have maybe 10 bits of dynamic range then to the printer which has another.",
            "Kind of different range because of all the halftoning, and so on the flow, the flow around that to get accurate color is very difficult to do.",
            "Now you doing this almost in a laboratory kind of setting.",
            "Have you found that to be a problem to try to fill that loop and have the.",
            "Accurate color correction.",
            "So the question is really sort of about doing these color management techniques in practice and getting them to work in in a real workflow.",
            "And it's true, that's a challenge and there's a lot of practical tools that you can buy that will help you with these things.",
            "I would refer you to the company Cromix happens to be a Seattle based company, which is where I'm from, but they're really one of the state of the art color management companies and they have a lot of tools that are cheap and easy to use to try to get those workflows going as well as just some information that will give you.",
            "Hold on the practical tools and as a practitioner, you don't need to know about the algorithms underneath.",
            "You want to know?",
            "OK, how do I actually get?",
            "You know what software do I use to get things working?",
            "So.",
            "There's something called gridding.",
            "Any comment on and so do you, say creeking.",
            "Not uniform FT where you you interpolate with the kinds of vessel coming onto a grid, and it seems like what you're doing is faster, but you never can compare this.",
            "No, we should talk offline 'cause I'm not sure exactly which techniques are you referring to.",
            "Indeed, the application to color application that you saw is the most sampling an inherent problem.",
            "Or can you overcome this?",
            "So you said that it's undetermined?",
            "Can you make it over determined by just taking more samples or it's?",
            "Yes and no.",
            "It depends on your grid size, so let's say that we have this 17 by 17 by 17 grid.",
            "No matter how much training data you have, you're still limited by that grid size.",
            "So if you do a bad job of learning that look up table from infinite training data, you'll still do a bad job.",
            "That said, more training data is good, but what happens with printers, and especially the kind that they are worrying about.",
            "Color managing is that it's very expensive to print things.",
            "So like say you have a digital press, it may cost you $10,000 to stop the press and do the kind of color calibration that you want to do.",
            "And if you have to use more media and run through more samples and stop your press longer, that makes you very sad.",
            "So you'd like to use as few training samples as you can get away with, which is why the standard targets for this only have around 1000 to 4000 color samples.",
            "So so."
        ],
        [
            "The question is we go from from your color.",
            "We go through a 3D look up table an what I left out is that there's a set of three 1D look up tables.",
            "Before that they are often called toner or calibration curves and I just didn't get into them 'cause it's like an extra detail.",
            "All of the algorithms use the exact same color calibration curve so that everything was controlled in that sense.",
            "But yeah, we do that separately.",
            "You do that to linearize linearize things so you linearize your neutral axis.",
            "Relations, could you just throw that all into the lookup table, especially if you had a more dense.",
            "If you, if you had a dense enough lattice, yeah, you could, but it's just still more computationally and cost effective to do the one day and part of what you're doing is you're just making sure that you're you sample things around neutral, and so then you want things to actually be around neutral.",
            "So if your printer is actually like printing, really blew that day, and so you thought you sampled a bunch of neutral colors, but actually gotta bunch of Blues.",
            "Those windy curve try to correct for that so that when you go to the look up table, things aren't sort of all off.",
            "But yeah, you could technically do it all in one.",
            "Who's runtime to show for combining these only director images 18 minutes versus of four minutes.",
            "Invitations to do use most of them are CPU or."
        ],
        [
            "We use the solar code we used from Markkanen Frossard.",
            "We talked a little bit with them about how to make that as as fast as possible.",
            "Our last regression is all in Matlab.",
            "I'm not sure if their map code is completely invalid.",
            "I think their goal maybe use some X files so.",
            "Not the best runtime comparison, but I think that these differences are runtime probably still relevant.",
            "But I guess since you're doing a uniform sampling, GPU implementation would be suitable as well for your everything's coming.",
            "Yeah, in fact, I mean, if you did this stuff in hardware, should be extremely fast.",
            "There's a lot of things that you could speed up here that we just didn't take advantage of it all because we need to bother, but it's sort of designed it.",
            "OK then.",
            "No more questions, let's thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, this is joint work with Eric Garcia and with Rahman Aurora.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to talk today about regression.",
                    "label": 0
                },
                {
                    "sent": "So just to make sure we're on the same page, annotation wise will assume that we've been given N training pairs.",
                    "label": 0
                },
                {
                    "sent": "These pairs have an XI, an AYI, and this is all very standard.",
                    "label": 0
                },
                {
                    "sent": "RX is going to be in some D dimensional space and Ry.",
                    "label": 0
                },
                {
                    "sent": "I will just assume a scalar.",
                    "label": 0
                },
                {
                    "sent": "And we're going to model these outputs Yi, as some function XI plus some noise, and our goal in regression is to estimate F of X for some new test sample X.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so a lot of computational photography applications can be considered regression applications.",
                    "label": 0
                },
                {
                    "sent": "Going to focus today on color management, and I'll talk a little bit about gamma mapping.",
                    "label": 0
                },
                {
                    "sent": "It's sort of as a motivation in the first half of the talk, and then the second half all talk about Omni directional super resolution.",
                    "label": 0
                },
                {
                    "sent": "But all of these.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applications to computational photography have in common as something that they really very low dimensional in general, so we're talking about dimensions of two to six dimensions.",
                    "label": 0
                },
                {
                    "sent": "So a lot of regression has been focused on high dimensional regression.",
                    "label": 0
                },
                {
                    "sent": "Here we're going to focus on low dimensional regression.",
                    "label": 0
                },
                {
                    "sent": "The other issue is in computational photography.",
                    "label": 0
                },
                {
                    "sent": "In these applications, you want to pump through not just one test sample, but millions of test samples in a very, very fast time.",
                    "label": 0
                },
                {
                    "sent": "But if we're doing something like color management videos, we're going to have to pump through a lot of a lot of pixels.",
                    "label": 0
                },
                {
                    "sent": "So we need to be able to evaluate this function F very very fast.",
                    "label": 0
                },
                {
                    "sent": "So a simple solution if you want a function that you can evaluate very fast.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe if we just did linear regression?",
                    "label": 0
                },
                {
                    "sent": "So linear regression is fast, but it's not really good enough and I'll highlight that a little later.",
                    "label": 1
                },
                {
                    "sent": "Of course, in this example here, it's not really linear regression that's the problem, but.",
                    "label": 0
                },
                {
                    "sent": "OK, let's see here so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I said, I'll start off by talking about the color management problem as motivation.",
                    "label": 0
                },
                {
                    "sent": "So color management of the problem really is a device dependent.",
                    "label": 0
                },
                {
                    "sent": "Colors depend on the device, right?",
                    "label": 1
                },
                {
                    "sent": "So if I think about the color 000, what color is that?",
                    "label": 0
                },
                {
                    "sent": "You know it's black, right?",
                    "label": 0
                },
                {
                    "sent": "But if I look at what the scanner thinks, that Black is an I look at what this monitor thinks that black is.",
                    "label": 0
                },
                {
                    "sent": "They're not exactly the same, and if you print out black, that's going to be a different black.",
                    "label": 0
                },
                {
                    "sent": "And if you project it well with the projector, black is actually white, right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have to be careful about trying to transfer these colors between these different devices.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the color management solution is to map everything to a device independent color space an all focus on scilab today, because it's the most common device independent color space.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it has the nice property that in scilab Euclidean distance approximately mimics human perceptual distance.",
                    "label": 0
                },
                {
                    "sent": "So if you're if two colors are this far apart, here is Coca Cola red, and here is bright red.",
                    "label": 0
                },
                {
                    "sent": "And here's Coca Cola, Renton, here sort of cherry red.",
                    "label": 0
                },
                {
                    "sent": "That that'll be sort of perceptually the same distance.",
                    "label": 0
                },
                {
                    "sent": "If it's Euclidean the same distance, and I'll talk a little bit more about that later.",
                    "label": 0
                },
                {
                    "sent": "OK, as we transform from each of these devices, so we'll go from the scanner RGB and will try to go to this device independent space and we'll use something color management ICC profile.",
                    "label": 1
                },
                {
                    "sent": "This is just a regression, so we're going to somehow former regression that Maps us from this color space to this color space and will have regressions.",
                    "label": 0
                },
                {
                    "sent": "I go forward and backwards between these independence and the device color spaces here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these mappings can be very highly nonlinear, particularly for printers.",
                    "label": 1
                },
                {
                    "sent": "These mappings are just gross.",
                    "label": 0
                },
                {
                    "sent": "You've got all these effects of the ink and the way it absorbs in the paper, and the halftoning algorithms there's a lot of nasty things that happen that make these these mappings highly nonlinear.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's how we met.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Print and other related issues.",
                    "label": 0
                },
                {
                    "sent": "Gamut mapping.",
                    "label": 0
                },
                {
                    "sent": "So a lot of companies are coming out with these great hardware with great displays that have these really beautiful colors that you can render, so maybe you shot your video an if you're you know, film company you shoot your video very carefully and you know what your colors are supposed to represent and you shoot them for a particular gamut.",
                    "label": 0
                },
                {
                    "sent": "So maybe these are the colors that you think you're going to be able to display and now sharp comes along and they've got a new TV where their red is this really bright, beautiful, gorgeous red?",
                    "label": 0
                },
                {
                    "sent": "So what happens if you just display the color data there?",
                    "label": 0
                },
                {
                    "sent": "Or even if you do some sort of linear transform, if you transform around the neutral axis, all of your skin tones are going to get stretched out.",
                    "label": 1
                },
                {
                    "sent": "So here's if you had maybe original gamut, and it's always fun to give talks with color to find out what the display is going to do examples, but hopefully you can see here that if we just do the linear regression, what happens to our skin tones is everyone ends up looking a bit drunk or sunburn, so that's generally not considered good, and so we need to have more complicated nonlinear regressions.",
                    "label": 1
                },
                {
                    "sent": "But we still of course want to be very fast, because with gamma mapping you're going to do this very quickly as you go through the device.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, here is just another example of where you'd like to be able to do these fast regressions is if you want to do custom color enhancements.",
                    "label": 1
                },
                {
                    "sent": "This is an example where we start with the daylight scene and we had an artist transform that to a scene at sunset and we can now go and compare these pixels and create those training samples that say oh this blue should become this color.",
                    "label": 0
                },
                {
                    "sent": "This blue should become this color etc and then we can create a regression and use that to create any scene, daylight scene and map it to sort of a sunset sort of look as another.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example of that, you might want to form a mapping that takes a movie and then re Maps it as if it had been rendered in scenic color, which is kind of early film color.",
                    "label": 0
                },
                {
                    "sent": "Using the 1930s, and so you get that 1930s film color.",
                    "label": 0
                },
                {
                    "sent": "Look for your for your home video today.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so all of these applications are great.",
                    "label": 0
                },
                {
                    "sent": "How do they do this?",
                    "label": 0
                },
                {
                    "sent": "Fast regression?",
                    "label": 0
                },
                {
                    "sent": "Well, they use a look up table and look up tables is just a grid.",
                    "label": 0
                },
                {
                    "sent": "So you started with some data, some color pairs your input color and your output color.",
                    "label": 0
                },
                {
                    "sent": "They're all just kind of randomly an you apply your favorite state of the art regression algorithm and you get some F had of X and then you evaluate F out of.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On a grid, and that's going to be a look up table.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you throw away your data and you just keep your look up table and now when you get a test.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's my test sample.",
                    "label": 0
                },
                {
                    "sent": "It came in here off the grid and you just linearly interpolate it from the surrounding vertices.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This sounds great.",
                    "label": 0
                },
                {
                    "sent": "As I said, we use your favorite state that regression, so maybe for example, it's an empirical risk minimization.",
                    "label": 0
                },
                {
                    "sent": "So what would that do?",
                    "label": 0
                },
                {
                    "sent": "An empirical risk minimization is going to make sure that this F had of X is good at making sure that if I put XI in the F hat of XI, will be close to why I write if I have low training loss, low loss of my training data.",
                    "label": 0
                },
                {
                    "sent": "But now if we look at the whole joint system, if I put in that same training point XI over here, I'm going to linearly interpolate it from these four points.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to get some different value out, so even though I might have done a really good job here, getting this F had of X to be close to this.",
                    "label": 0
                },
                {
                    "sent": "Why I?",
                    "label": 0
                },
                {
                    "sent": "My final output is screwed up, it's no longer exactly that why I in a sense I'm minimizing the wrong empirical loss because I'm not taking into account this linear interpolation error that's going to happen, or this later tribulation.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this process is suboptimal because this regression doesn't know what's happening later in the pipeline and in signal and image processing this is often where we still get the big gains is by realizing that we have independent systems that are all fairly good and fairly optimal.",
                    "label": 0
                },
                {
                    "sent": "But when we have these joint systems and we start to bring together parts of the block diagram, we can make things more optimal.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in this talk what I'm going to talk about is how to fix this problem, and basically we're just going to do things jointly.",
                    "label": 0
                },
                {
                    "sent": "We're going to take into account these interpolation errors.",
                    "label": 0
                },
                {
                    "sent": "So now we do that.",
                    "label": 0
                },
                {
                    "sent": "We gotta go back and rethink.",
                    "label": 0
                },
                {
                    "sent": "I know everyone thinks they know how interpolation works, but let's just look over the math because then then we can really make sure we under.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what's going on here?",
                    "label": 0
                },
                {
                    "sent": "So here we have a simple 2D example.",
                    "label": 0
                },
                {
                    "sent": "And here's my grid and my grid output values are these B1B2B3, etc.",
                    "label": 0
                },
                {
                    "sent": "These blue dots, so this is maybe you know the value 3.",
                    "label": 0
                },
                {
                    "sent": "And this is the value 5 and the value 27, etc.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to linearly interpolate this test point here, and then we'll talk about that one.",
                    "label": 0
                },
                {
                    "sent": "So for this test point here, well, linear interpolation does is.",
                    "label": 1
                },
                {
                    "sent": "It gives this vertex a weight that corresponds to the area or the volume of this cell over here.",
                    "label": 0
                },
                {
                    "sent": "So this vertex is B5, so be 5 gets this area.",
                    "label": 1
                },
                {
                    "sent": "And so I see where this point is in the cell.",
                    "label": 0
                },
                {
                    "sent": "It's out Lambda 11.",
                    "label": 0
                },
                {
                    "sent": "It's out Lambda 1 two here.",
                    "label": 0
                },
                {
                    "sent": "We've normalized this to have unit length, so this area is just Lambda 11 times Lambda 1 two.",
                    "label": 0
                },
                {
                    "sent": "So I see that why had of one will equal Lambda one Lambda 1 two times B5.",
                    "label": 0
                },
                {
                    "sent": "So this B is the vector of B1 through B 9.",
                    "label": 0
                },
                {
                    "sent": "Outputs here and similarly the weight on B1.",
                    "label": 0
                },
                {
                    "sent": "The first guy is the area of this cell which will be 1 minus Lambda, one 1 * 1 minus Lambda 1 two.",
                    "label": 0
                },
                {
                    "sent": "This weight over here etc.",
                    "label": 0
                },
                {
                    "sent": "So since I'm only interpolating these four things of the B1 through B9 outputs.",
                    "label": 0
                },
                {
                    "sent": "I only have weights on four of them.",
                    "label": 0
                },
                {
                    "sent": "OK, so so I can write this as a vector as well.",
                    "label": 0
                },
                {
                    "sent": "This weight vector and I can just say my yhat one.",
                    "label": 0
                },
                {
                    "sent": "My linear interpolated output is just some weight vector.",
                    "label": 0
                },
                {
                    "sent": "Transpose times my output values for the notes.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do a similar thing for this.",
                    "label": 0
                },
                {
                    "sent": "Why hat too?",
                    "label": 0
                },
                {
                    "sent": "And you'll notice that here it's choosing mostly different weights, both Y one and Y two share B5, so they both give some weight to be 5, but otherwise they're using different vertices OK, and so now just as a man.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Notation we're going to take these two outputs, yhat one and Y hat to both scalars and put them together in a vector yhat.",
                    "label": 0
                },
                {
                    "sent": "So that's my linear interpolation output vector, and I'm going to take this weight vector here and this way vector here and make them columns of a matrix.",
                    "label": 0
                },
                {
                    "sent": "So that's my matrix W. Here, my linear interpolation weights and then this is just, you know, W transpose B might look up table values.",
                    "label": 1
                },
                {
                    "sent": "OK, so if I'm interpolating a bunch of points at once, I get this nice matrix equation like this.",
                    "label": 0
                },
                {
                    "sent": "OK, So what do I want to do?",
                    "label": 0
                },
                {
                    "sent": "I want blue points.",
                    "label": 0
                },
                {
                    "sent": "I want a look up table that interpolates my training data really well.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is I want to look up table values B such that when I interpolate them W transpose B and I do this for my training inputs that it matches the training outputs Y.",
                    "label": 0
                },
                {
                    "sent": "Right, so here is my data again.",
                    "label": 0
                },
                {
                    "sent": "These scattered points and I'm going to try to find the points on the grid here.",
                    "label": 1
                },
                {
                    "sent": "The colors here such that when I lean into plate, all of these training data points, I'm accurate.",
                    "label": 0
                },
                {
                    "sent": "OK, and so this is.",
                    "label": 0
                },
                {
                    "sent": "This isn't really very bad, I just need it.",
                    "label": 0
                },
                {
                    "sent": "Sounds like a lot of parameters 'cause I have to find the points for all of these good points, but I just need to solve this squared quadratic program.",
                    "label": 0
                },
                {
                    "sent": "OK, anybody see a problem?",
                    "label": 0
                },
                {
                    "sent": "OK, you might notice there's no.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's no data here in this cell.",
                    "label": 0
                },
                {
                    "sent": "There's no data in this cell is maybe a point down here if I don't have enough data, I might have nothing that tells me what to set this vertex as, right?",
                    "label": 0
                },
                {
                    "sent": "So in general this is.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to be underdetermined in a lot of the applications that we worry about.",
                    "label": 0
                },
                {
                    "sent": "Underdetermined is always a good thing because it means you get to add more criteria.",
                    "label": 0
                },
                {
                    "sent": "You could have more say about which of the many solutions you get to choose, right so?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add a regularizer and we're going to add a regularizer that lets us choose solutions that are smooth on the grid.",
                    "label": 1
                },
                {
                    "sent": "Now if you want you can add a regularizer that does something else, but I often prefer solutions that are somewhat smooth.",
                    "label": 0
                },
                {
                    "sent": "OK, so again, here's our empirical loss now, which doesn't just take into account the interpolation error.",
                    "label": 0
                },
                {
                    "sent": "The only loss is the linear interpolation error.",
                    "label": 0
                },
                {
                    "sent": "There's no regression step anymore.",
                    "label": 0
                },
                {
                    "sent": "All we're doing is directly finding a look up table that minimizes the error when we interpolate the training data.",
                    "label": 0
                },
                {
                    "sent": "And then here we have our regularizer, will call Lambda JAB on these output nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so these output nodes basically form a graph, right?",
                    "label": 0
                },
                {
                    "sent": "So the possibly obvious.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regular would be to use the graph Laplacian if you're not familiar with it.",
                    "label": 0
                },
                {
                    "sent": "This is going to look at all adjacent nodes in the graph by BJ and just make sure that they're close and squared error, and so if we do this, these blue dots here.",
                    "label": 0
                },
                {
                    "sent": "Now my training samples on I do this, this lattice regression as we're calling it, you'll end up with a function fit that looks like this.",
                    "label": 1
                },
                {
                    "sent": "Now this is pretty good.",
                    "label": 0
                },
                {
                    "sent": "One thing you'll notice about graph Laplacian is it once all the nodes to be similar, which means that it really wants far out nodes it wants everything basically to be close to the average.",
                    "label": 0
                },
                {
                    "sent": "Of the function.",
                    "label": 0
                },
                {
                    "sent": "So you get this action out here where things are flattening out and things are flattening out.",
                    "label": 0
                },
                {
                    "sent": "Now if I have something like a device, whereas I turn up the crank, I want things to get brighter and brighter and brighter.",
                    "label": 0
                },
                {
                    "sent": "This flattening out is a bit of a problem, and so we found that this actually didn't work well for the kind of applications we were interested in, so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we applied a what we call a graph, Hessian, just a second order version of this.",
                    "label": 0
                },
                {
                    "sent": "So we now look at 2nd order differences and minimize that.",
                    "label": 0
                },
                {
                    "sent": "So now if my function was just a plain, then this graph asking would be 0, so it doesn't penalize plane fits and the same training data points.",
                    "label": 0
                },
                {
                    "sent": "It's hard to tell, but these blue points are exactly the same and you get this radically different function that happens also to be a bit smoother because you're allowing it to go with the natural trends there.",
                    "label": 0
                },
                {
                    "sent": "Yes, over gridpoints nonuniform.",
                    "label": 0
                },
                {
                    "sent": "You could have nonuniform good points that won't affect.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much because it just you just have to define the weight matrix, so that's not a big problem, but in all the applications we care about because we're really interested in speed and doing things simply, we don't have nonlinear non uniform good points.",
                    "label": 0
                },
                {
                    "sent": "We have nice uniform.",
                    "label": 0
                },
                {
                    "sent": "The policy and in the graph as soon as the ordinary Hessian.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If these are just uniform grids, that's my question.",
                    "label": 0
                },
                {
                    "sent": "Oh well, it's a discrete version, yeah?",
                    "label": 0
                },
                {
                    "sent": "And I'll show you later spherical grid and then some of this intuition goes out the window, but it all works fine.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this was our so both the graph Laplacian and the graph Hessian are regularised JB that have this quadratic form.",
                    "label": 0
                },
                {
                    "sent": "You can write them as be transposed KB where this kernel just depends on the orientation of your grid and the size of your grid.",
                    "label": 0
                },
                {
                    "sent": "So you precompute that K and then you have this nice lattice regression problem.",
                    "label": 1
                },
                {
                    "sent": "Minimize again, the linear interpolation error and this quadratic term, and you'll notice that everything here is nice and quadratic, and so not surprisingly, we have a nice closed form solution.",
                    "label": 1
                },
                {
                    "sent": "Now this closed form solution does require a matrix inverse, but this matrix inverse is very, very sparse, because remember each point is only being triple rated by the cell around it.",
                    "label": 0
                },
                {
                    "sent": "That weight matrix is is very, very sparse and you just go back for a second here.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the 2D case, there was only four nonzero entries in the 3D case will be 8 nonzero entries.",
                    "label": 1
                },
                {
                    "sent": "Here in my matrix was nine because I only had a good with nine output values.",
                    "label": 0
                },
                {
                    "sent": "In color management, we often use a grid of 17 by 17 by 17, so I don't remember the number of Papa had something like 4318 nodes, of which only eight are going to be on at anytime, so these fairly sparse in that sense.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we have a nice circles from solution.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sparse an let's look at some results.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing is we got desired color here, so we'd like to be able to output Coca Cola red.",
                    "label": 0
                },
                {
                    "sent": "We send that to our look up table that we built an.",
                    "label": 0
                },
                {
                    "sent": "It tells us this is the RGB you should send to the printer to get out that Coca Cola.",
                    "label": 0
                },
                {
                    "sent": "Read at least its best guess and then we print something and we get out something that probably isn't exactly Coca Cola red and we measure the error between what we actually got out and the color we had hoped to get.",
                    "label": 0
                },
                {
                    "sent": "How do we measure the error between this color and this color?",
                    "label": 0
                },
                {
                    "sent": "Well, we could just use Euclidean distance in CIELAB space.",
                    "label": 0
                },
                {
                    "sent": "Because that's approximately perceptually uniform color management, we call that Delta E 76 for 1976, which is to say we have updated formulas, so we're using the generally accepted best formula, which is Lt. 2000, but very similar to Euclidean distance with some corrections.",
                    "label": 0
                },
                {
                    "sent": "And here we're comparing lattice regression.",
                    "label": 0
                },
                {
                    "sent": "Our group had done some of the earlier state of the art work in this area for regression.",
                    "label": 0
                },
                {
                    "sent": "For color management using a local linear regression with enclosing neighborhoods with either a regularizer or local Tikhonov regularizer.",
                    "label": 0
                },
                {
                    "sent": "And then we threw in Gaussian process regression 'cause nips.",
                    "label": 0
                },
                {
                    "sent": "People seem to like calcium process regressions we thought will compare to that even though we know it's not state of the questions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, how do you measure from the printed?",
                    "label": 0
                },
                {
                    "sent": "You have to use another device to measure from the printed output.",
                    "label": 0
                },
                {
                    "sent": "How do we get the training data?",
                    "label": 0
                },
                {
                    "sent": "No, not in this case.",
                    "label": 0
                },
                {
                    "sent": "You said, how do you look at the error?",
                    "label": 0
                },
                {
                    "sent": "So you say we measure the CI elab.",
                    "label": 0
                },
                {
                    "sent": "There's a spectrometer here.",
                    "label": 0
                },
                {
                    "sent": "That yes, there's a spectrophotometer.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is actually like a piece of paper, yeah?",
                    "label": 0
                },
                {
                    "sent": "And then we use a spectrophotometer to get the CIELAB values, and that's how we get the training data as well.",
                    "label": 0
                },
                {
                    "sent": "So all of this actually takes kind of a lot of effort.",
                    "label": 0
                },
                {
                    "sent": "17 is the grid, yeah, so.",
                    "label": 0
                },
                {
                    "sent": "To be able to do this.",
                    "label": 0
                },
                {
                    "sent": "Great, of course.",
                    "label": 0
                },
                {
                    "sent": "The lookup table comes bigger, but I assume that you get a better result.",
                    "label": 0
                },
                {
                    "sent": "It's not the common wisdom, actually.",
                    "label": 0
                },
                {
                    "sent": "A lot of people use sparser look up tables more like 9 by 9.",
                    "label": 0
                },
                {
                    "sent": "By 9, I mean think about.",
                    "label": 0
                },
                {
                    "sent": "Even if you had like a two by two by two, then you be saying that the whole color mapping could be just one linear well, linear regression.",
                    "label": 0
                },
                {
                    "sent": "Linear interpolation gives you a more flexible function than just linear regression, but that would already give you something that was sort of more interesting than linear.",
                    "label": 0
                },
                {
                    "sent": "And now you've got 17 by 17 by 17.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "You've got quite a lot of room to capture some non layers.",
                    "label": 0
                },
                {
                    "sent": "What you see is that we're doing pretty well here, yes?",
                    "label": 0
                },
                {
                    "sent": "The question process regression, how do we use Gaussian process regression?",
                    "label": 0
                },
                {
                    "sent": "Funny you should ask.",
                    "label": 0
                },
                {
                    "sent": "When I get back to that.",
                    "label": 0
                },
                {
                    "sent": "No, it's here somewhere.",
                    "label": 0
                },
                {
                    "sent": "Somewhere in some backslides.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Serial.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're modeling the data is being drawn from a Gaussian process, so we had our original color data.",
                    "label": 1
                },
                {
                    "sent": "We learn the Gaussian process and then we do what I said.",
                    "label": 0
                },
                {
                    "sent": "We estimate the look up table and then we use the look up table as before.",
                    "label": 0
                },
                {
                    "sent": "I think the most maybe interesting part of the question is how do we fit the parameters?",
                    "label": 0
                },
                {
                    "sent": "We use the maximizing marginal likelihood technique.",
                    "label": 0
                },
                {
                    "sent": "Can we use some software?",
                    "label": 0
                },
                {
                    "sent": "I think from Williams and Rasmussen seemed like fairly off the shelf application.",
                    "label": 0
                },
                {
                    "sent": "We fiddled around with it a bit to get it to work.",
                    "label": 0
                },
                {
                    "sent": "As nicely as we could, we we wanted to look nice.",
                    "label": 0
                },
                {
                    "sent": "Left final place again though.",
                    "label": 0
                },
                {
                    "sent": "It's like a fast preview of the talk.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in Delta E 2002 is about a just noticeable difference.",
                    "label": 0
                },
                {
                    "sent": "So these mean values here all under two, which means that on average you're able to reproduce colors without you wouldn't be able to tell the difference.",
                    "label": 0
                },
                {
                    "sent": "Our maximum errors, however, are quite a bit bigger like 6.75, and here we're just looking at how many errors were basically noticeable.",
                    "label": 0
                },
                {
                    "sent": "So with the lattice regression you're getting like 60 errors being noticeable as opposed to like 300 errors with the Gaussian process regression.",
                    "label": 0
                },
                {
                    "sent": "And let me.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show you that visually, so here all the test samples is 980 eighteen test sample colors all in the gamut of the printer and the size of the color here shows you how big the error is.",
                    "label": 0
                },
                {
                    "sent": "So for local Ridge it made a really bad error.",
                    "label": 0
                },
                {
                    "sent": "On Fuchsia you can see that Gaussian process regression is having a lot of Blues and purples, which is just really hard at the lattice.",
                    "label": 0
                },
                {
                    "sent": "Regression is doing pretty well throughout.",
                    "label": 0
                },
                {
                    "sent": "Its biggest problem seems to be with some of the beige and neutral colors.",
                    "label": 0
                },
                {
                    "sent": "But that will depend on the printer.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, this also depends on your training data as well right?",
                    "label": 0
                },
                {
                    "sent": "Yes, so we use the standard.",
                    "label": 0
                },
                {
                    "sent": "I can't remember the number of the tests are, but it's a very standard test chart.",
                    "label": 0
                },
                {
                    "sent": "It's the one that promises for all their commercial color management applications.",
                    "label": 0
                },
                {
                    "sent": "And it's basically a regular sampling of the space with some extra neutrals and some extra saturated colors.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I'm gonna talk about a second application to Omni directional superresolution, so we're going to take the same lattice regression ideas and the math and just apply to a totally different kind of grid.",
                    "label": 0
                },
                {
                    "sent": "So here we've got omnidirectional cameras, an omnidirectional camera hardware is a little more expensive than normal camera hardware, which means the sensors tend to be lower resolution, so.",
                    "label": 0
                },
                {
                    "sent": "However, if we have if we have our camera here and we have this low resolution camera, we could just maybe turn it'll it'll take another picture, turn a little, take another picture, turn around, get a few different pictures, and after we got a bunch of these pictures, the hope is that we can just land them all together somehow and create 1 high resolution Omni directional image.",
                    "label": 0
                },
                {
                    "sent": "So there's been various work on this.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We consider the state of the art to be arcana Frossard work.",
                    "label": 1
                },
                {
                    "sent": "They want to ICPR 2008 best paper award for this work and followed up with a Journal paper and what they're doing is they're using spherical foray transform.",
                    "label": 0
                },
                {
                    "sent": "And both they and us, we will assume that we don't necessarily know how these images are registered, so we don't know exactly what the relationship is between these images that you took.",
                    "label": 0
                },
                {
                    "sent": "So you have an alignment problem and they saw that with the iterative conjugate gradient descent approach.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what we're going to do?",
                    "label": 0
                },
                {
                    "sent": "This this correct registration issue is really a very nasty non convex optimization problem.",
                    "label": 1
                },
                {
                    "sent": "And what we're going to do is, say, say you have a candidate registration.",
                    "label": 0
                },
                {
                    "sent": "We need to decide how good is that candidate registration, so will take some subset of the images.",
                    "label": 0
                },
                {
                    "sent": "Ann will take those as our training data and will use lattice regression to learn a high resolution spherical grid.",
                    "label": 0
                },
                {
                    "sent": "So now are look up tables on a spherical grid, and so are look up tables actually in grid in 2 dimensional units of latitude angles and the lanja tude angles.",
                    "label": 0
                },
                {
                    "sent": "So some grid cells look totally different than other grid cells.",
                    "label": 0
                },
                {
                    "sent": "But we don't really worry so much about that.",
                    "label": 0
                },
                {
                    "sent": "So use lattice regression you on some of the data to get a high resolution spherical grid and now you see how well does that spherical grid interpolate some of the left out low resolution images.",
                    "label": 1
                },
                {
                    "sent": "So if it's if it's all sort of consistent, then you probably have a good registration of all the images, and if it's not consistent, then it's not a very good registration.",
                    "label": 0
                },
                {
                    "sent": "OK, so this gives us objective function that we can use to evaluate how good any registration is.",
                    "label": 0
                },
                {
                    "sent": "Now we still need to register all the images if I have N images.",
                    "label": 0
                },
                {
                    "sent": "Each of these images has three degrees of registration freedom compared to each other image.",
                    "label": 0
                },
                {
                    "sent": "So this one will stay fixed and so in total will.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of 3 * N -- 1 dimensions of registration to try to optimize over ASOS is still sort of a nasty global optimization problem, and you could use any global optimizer that you're comfortable with, and I think that's really the trick with global optimization is what do you trust?",
                    "label": 0
                },
                {
                    "sent": "Don't trust any of them.",
                    "label": 0
                },
                {
                    "sent": "But what we use is fully informed particle swarm, so this is a global optimization method where you make some guesses and then you sort of take these course regional gradients an you move in that direction and there's some inertia and there's some velocity and sort of wanders around the space into someone intelligent way.",
                    "label": 0
                },
                {
                    "sent": "But the problem is every time we want to say, here's a candid registration, evaluate how good it is, we need to go and build a lattice regression and then evaluate and able to do this very fast becomes important.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's a couple of examples results.",
                    "label": 0
                },
                {
                    "sent": "This is, as you can see with real data.",
                    "label": 0
                },
                {
                    "sent": "Not sure how well you can see this.",
                    "label": 0
                },
                {
                    "sent": "This is dark and foussard spherical for transport method and this is the lattice regression method.",
                    "label": 0
                },
                {
                    "sent": "Both of course have problems, at least from where I'm standing.",
                    "label": 0
                },
                {
                    "sent": "However, it's a lot easier, for example, to tell that this is a chair, then that's a chair, and it's easy to tell that that's a whiteboard, and there's some pictures on the wall, etc.",
                    "label": 0
                },
                {
                    "sent": "And the runtimes here are really significantly faster.",
                    "label": 0
                },
                {
                    "sent": "So for 128 by 120 images vehicle for a transform, if I have 80 images, was taking us about 80 minutes to run, whereas with so lot of this lattice regression method on the sphere, we're seeing about 3 minutes to run and for 256 by 256 image we couldn't get this vehicle for transform to really compute it.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's some PS in our numbers.",
                    "label": 0
                },
                {
                    "sent": "I apologize for the image quality here, so again, this is the number of low resolution images that you have to super resolve and this is the PS and are the two blue lines.",
                    "label": 0
                },
                {
                    "sent": "Here are the slightest regression method solar and the two orange lines are the spherical Fourier transform and there's basically attendee be difference to any appropriate comparison here and the two lines one is a 10 degree uncertainty, so I tell you look I took these pictures and I know how closely are within 10 degrees.",
                    "label": 0
                },
                {
                    "sent": "I know this guys about 70 degrees off from this guy and this guys about you know here in this guys here.",
                    "label": 0
                },
                {
                    "sent": "You just need to futz within a 10 degree window versus the 90 degree uncertainty, which are the dotted lines, which is a lot worse, right?",
                    "label": 0
                },
                {
                    "sent": "Just gave you these images.",
                    "label": 0
                },
                {
                    "sent": "I'm like I got these other trash can, I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't know how these register you help yourself, so that of course is creates quite a bit of gap if you don't know anything about the registration.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is all very pretty visual.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 DBPSNR sounds great, but the really important.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question is, how well does it help a robot find home?",
                    "label": 0
                },
                {
                    "sent": "So these are these visual homing problems where you throw a robot in a room and you declare that something is at home and you give a robot a picture of what it looks like if he's home.",
                    "label": 0
                },
                {
                    "sent": "So the robot starts here and starts taking a bunch of pictures and compares that with its internal notion of home.",
                    "label": 0
                },
                {
                    "sent": "And then it does some gradient descent or some some attempt.",
                    "label": 0
                },
                {
                    "sent": "In this case it's a match filtering to try to decide which direction to go, and it says, oh, I bet this way is closer to home and it takes a bunch more pictures and it says, oh, I think Holmes, probably over there takes a bunch more pictures, compares to its notion of home, etc so.",
                    "label": 0
                },
                {
                    "sent": "The usual metric here is the mean probability that the robot actually finds finds its way home.",
                    "label": 0
                },
                {
                    "sent": "And as we can see, as long as we have, if you only have two images, then in this one case with 15 degrees uncertainty, this pickle for transform gets it right 12% of the time we get right 10%, but in every other case we do quite a bit better, for example 5 images we find home 42% of the time versus 22 with 20 images.",
                    "label": 0
                },
                {
                    "sent": "If you give it no information about the registration, so 90 degrees.",
                    "label": 0
                },
                {
                    "sent": "Uncertainty about the registration of these images.",
                    "label": 0
                },
                {
                    "sent": "The last suggestion method, and 20 images is getting home 80% of the time versus 10% of the time there.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to go ahead and start concluding here.",
                    "label": 0
                },
                {
                    "sent": "So a lot of suggestion is fast and well.",
                    "label": 0
                },
                {
                    "sent": "It's pretty fast and it's pretty accurate, so that's that's kind of.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In handy, it's particularly fast if what you want to output is also on a grid, and then you can just learn the grid in the 1st place so you can learn a grid or learn an output that interpolates your training data well.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because it's fast, you can spend time and other stuff so a lot of why we do so much better than the other kind of facade method is because we can do this massive global optimization.",
                    "label": 0
                },
                {
                    "sent": "And because we can do the global optimization steps very fast, we can do a lot better job exploring the space.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use a graph fashion, but for your application you might need a slightly different regularizer on the grid, and that's always a fun problem to think about.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for details, there's some papers that you can check out, thank you.",
                    "label": 0
                },
                {
                    "sent": "I'm a practitioner where I photograph art and I use color management to try to get accurate colors.",
                    "label": 0
                },
                {
                    "sent": "And what I find is 1 big problem is that in going from the camera which claims to have a 14 bit sensor to a monitor which is difficult to have maybe 10 bits of dynamic range then to the printer which has another.",
                    "label": 0
                },
                {
                    "sent": "Kind of different range because of all the halftoning, and so on the flow, the flow around that to get accurate color is very difficult to do.",
                    "label": 0
                },
                {
                    "sent": "Now you doing this almost in a laboratory kind of setting.",
                    "label": 0
                },
                {
                    "sent": "Have you found that to be a problem to try to fill that loop and have the.",
                    "label": 0
                },
                {
                    "sent": "Accurate color correction.",
                    "label": 0
                },
                {
                    "sent": "So the question is really sort of about doing these color management techniques in practice and getting them to work in in a real workflow.",
                    "label": 0
                },
                {
                    "sent": "And it's true, that's a challenge and there's a lot of practical tools that you can buy that will help you with these things.",
                    "label": 0
                },
                {
                    "sent": "I would refer you to the company Cromix happens to be a Seattle based company, which is where I'm from, but they're really one of the state of the art color management companies and they have a lot of tools that are cheap and easy to use to try to get those workflows going as well as just some information that will give you.",
                    "label": 0
                },
                {
                    "sent": "Hold on the practical tools and as a practitioner, you don't need to know about the algorithms underneath.",
                    "label": 0
                },
                {
                    "sent": "You want to know?",
                    "label": 0
                },
                {
                    "sent": "OK, how do I actually get?",
                    "label": 0
                },
                {
                    "sent": "You know what software do I use to get things working?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's something called gridding.",
                    "label": 0
                },
                {
                    "sent": "Any comment on and so do you, say creeking.",
                    "label": 0
                },
                {
                    "sent": "Not uniform FT where you you interpolate with the kinds of vessel coming onto a grid, and it seems like what you're doing is faster, but you never can compare this.",
                    "label": 0
                },
                {
                    "sent": "No, we should talk offline 'cause I'm not sure exactly which techniques are you referring to.",
                    "label": 0
                },
                {
                    "sent": "Indeed, the application to color application that you saw is the most sampling an inherent problem.",
                    "label": 0
                },
                {
                    "sent": "Or can you overcome this?",
                    "label": 0
                },
                {
                    "sent": "So you said that it's undetermined?",
                    "label": 0
                },
                {
                    "sent": "Can you make it over determined by just taking more samples or it's?",
                    "label": 0
                },
                {
                    "sent": "Yes and no.",
                    "label": 0
                },
                {
                    "sent": "It depends on your grid size, so let's say that we have this 17 by 17 by 17 grid.",
                    "label": 0
                },
                {
                    "sent": "No matter how much training data you have, you're still limited by that grid size.",
                    "label": 0
                },
                {
                    "sent": "So if you do a bad job of learning that look up table from infinite training data, you'll still do a bad job.",
                    "label": 0
                },
                {
                    "sent": "That said, more training data is good, but what happens with printers, and especially the kind that they are worrying about.",
                    "label": 0
                },
                {
                    "sent": "Color managing is that it's very expensive to print things.",
                    "label": 0
                },
                {
                    "sent": "So like say you have a digital press, it may cost you $10,000 to stop the press and do the kind of color calibration that you want to do.",
                    "label": 0
                },
                {
                    "sent": "And if you have to use more media and run through more samples and stop your press longer, that makes you very sad.",
                    "label": 0
                },
                {
                    "sent": "So you'd like to use as few training samples as you can get away with, which is why the standard targets for this only have around 1000 to 4000 color samples.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question is we go from from your color.",
                    "label": 0
                },
                {
                    "sent": "We go through a 3D look up table an what I left out is that there's a set of three 1D look up tables.",
                    "label": 0
                },
                {
                    "sent": "Before that they are often called toner or calibration curves and I just didn't get into them 'cause it's like an extra detail.",
                    "label": 0
                },
                {
                    "sent": "All of the algorithms use the exact same color calibration curve so that everything was controlled in that sense.",
                    "label": 0
                },
                {
                    "sent": "But yeah, we do that separately.",
                    "label": 0
                },
                {
                    "sent": "You do that to linearize linearize things so you linearize your neutral axis.",
                    "label": 0
                },
                {
                    "sent": "Relations, could you just throw that all into the lookup table, especially if you had a more dense.",
                    "label": 0
                },
                {
                    "sent": "If you, if you had a dense enough lattice, yeah, you could, but it's just still more computationally and cost effective to do the one day and part of what you're doing is you're just making sure that you're you sample things around neutral, and so then you want things to actually be around neutral.",
                    "label": 0
                },
                {
                    "sent": "So if your printer is actually like printing, really blew that day, and so you thought you sampled a bunch of neutral colors, but actually gotta bunch of Blues.",
                    "label": 0
                },
                {
                    "sent": "Those windy curve try to correct for that so that when you go to the look up table, things aren't sort of all off.",
                    "label": 0
                },
                {
                    "sent": "But yeah, you could technically do it all in one.",
                    "label": 0
                },
                {
                    "sent": "Who's runtime to show for combining these only director images 18 minutes versus of four minutes.",
                    "label": 0
                },
                {
                    "sent": "Invitations to do use most of them are CPU or.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use the solar code we used from Markkanen Frossard.",
                    "label": 0
                },
                {
                    "sent": "We talked a little bit with them about how to make that as as fast as possible.",
                    "label": 0
                },
                {
                    "sent": "Our last regression is all in Matlab.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if their map code is completely invalid.",
                    "label": 0
                },
                {
                    "sent": "I think their goal maybe use some X files so.",
                    "label": 0
                },
                {
                    "sent": "Not the best runtime comparison, but I think that these differences are runtime probably still relevant.",
                    "label": 0
                },
                {
                    "sent": "But I guess since you're doing a uniform sampling, GPU implementation would be suitable as well for your everything's coming.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in fact, I mean, if you did this stuff in hardware, should be extremely fast.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of things that you could speed up here that we just didn't take advantage of it all because we need to bother, but it's sort of designed it.",
                    "label": 0
                },
                {
                    "sent": "OK then.",
                    "label": 0
                },
                {
                    "sent": "No more questions, let's thanks.",
                    "label": 0
                }
            ]
        }
    }
}