{
    "id": "dyxxn4nqy35ulbgvzs7npd2jx3uq2xmo",
    "title": "Challenges in Building Large-Scale Information Retrieval Systems",
    "info": {
        "author": [
            "Jeffrey Dean, Google, Inc."
        ],
        "published": "March 12, 2009",
        "recorded": "February 2009",
        "category": [
            "Top->Computer Science",
            "Top->Computer Science->Text Mining",
            "Top->Computer Science->Information Retrieval",
            "Top->Computer Science->Search Engines"
        ]
    },
    "url": "http://videolectures.net/wsdm09_dean_cblirs/",
    "segmentation": [
        [
            "Good morning, welcome to beautiful by salon.",
            "So it's my pleasure, true, introduce here today.",
            "Jeff Dean's invited speaker.",
            "Jeff Jeff was born in Hawaii.",
            "And during his early years.",
            "It spent childhood in many places, from Minnesota to Glenda, Atlanta back to Africa, Seattle.",
            "Then he settled in the Bay Area.",
            "Jeff is an extremely good engineer.",
            "Great vision.",
            "Big dreams.",
            "And he pushes he dreams through very high scale.",
            "In Google, every time that you get a new engineer.",
            "Jeff is the target.",
            "Jeff is there very high level model of accomplishment.",
            "Is also very easy person.",
            "Very easy to get along with.",
            "And very good.",
            "Team builder.",
            "With no further delay.",
            "Ducting."
        ],
        [
            "I'm going to talk today about building large scale retrieval systems.",
            "Something I've been doing for a little while at Google.",
            "One of the things I like best about this area of work is that it provides a challenging blend of both unsolved research problems that we really don't know how to solve.",
            "Interesting directions that this work can go in, and it also provides a bunch of challenging engineering problems, and it's this blend of thing of problems that I think is both very interesting and challenging.",
            "It also spans a lot of different areas of computer science, but I think it's fun.",
            "You get to collaborate with lots of colleagues who have different areas of expertise.",
            "And it's helpful when you sort of expand your horizons and learn more about an area you may not know much about.",
            "When I started a Google, I didn't know much about machine learning.",
            "I've been able to work with experts in machine learning and pick up a little bit of tidbits on the side.",
            "It's fun and the scale of the systems we're building is a lot larger than most other systems that one can work on, and so that's always fun.",
            "And another nice thing is that I think small teams are able to do pretty significant things that it can be used by.",
            "For example, hundreds of millions of people.",
            "And that's a true testament to the power of software.",
            "That's why I love this field because you work can be used by lots of people."
        ],
        [
            "OK, so when you're building a retrieval system, there are lots of different parameters that you might need to consider.",
            "For example, you might have some target of number of documents.",
            "Want to index in your system, and maybe you have some target goal of number of queries per second that your system needs to be able to handle.",
            "You want to be able to update documents at some rate.",
            "You know maybe you'd like to update 10 documents, the second maybe you'd like to be able to update a billion documents per night.",
            "Those sorts of things you'd like to respond quickly to users.",
            "You need a certain amount of information to be kept about every document in your index or other data structures that you're going to be using for running retrieval algorithms.",
            "And then you have some.",
            "Either simple or fairly complicated retrieval algorithms, you're going to be trying to run on this system.",
            "An all of these factors in parameters contribute to sort of the difficulty of the engineering task that you face to it.",
            "If you have small values and all the dimensions, it's not that challenging if you have very large values and all the dimensions that increases the engineering challenge significantly.",
            "And it's kind of equivalent to the product of these things.",
            "It's easy to have a very large index that you never update.",
            "It's harder to have a large index that you update all the time.",
            "And these all affect both performance of the system and what you really care about as an engineer is performance per unit hardware cost or something like that."
        ],
        [
            "OK, so just to give you a sense of the scaling of these parameters since I've been at Google I joined in mid 99.",
            "I'm going to give you a rough sense of how these parameters are scaled so when I joined we had an index of perhaps few 10s of millions of documents and today we have many."
        ],
        [
            "So you know that's 100 X queries processed per day."
        ],
        [
            "1000 X product."
        ],
        [
            "This is kind of a rough measure, but we're basically keeping a lot more information per document that we can use to do ranking than we did 10 years ago.",
            "An R update latency.",
            "This is kind of surprising to me.",
            "When I made this slide."
        ],
        [
            "It's actually gotten better by a factor of about 10,000.",
            "We have some pages that we update in our index within a minute or two, and it used to be.",
            "We would kind of push out a batch update of our whole index once every month or two.",
            "Anne.",
            "While all these parameters have been changing, we've been able to drop the average query latency."
        ],
        [
            "American.",
            "Now, of course, we've been."
        ],
        [
            "Help out a little bit by Moores Law.",
            "An by larger capital budget these days, but you notice that.",
            "The improvement in hardware resources has not really kept up with the changes in all those parameters.",
            "So that's just to give you a sense of the rough scale."
        ],
        [
            "But the other thing I think is illustrated by the previous slide is that all these parameters change constantly.",
            "Overtime you're always getting more queries per month than you did last month.",
            "You're always wanting to index more documents than you did yesterday.",
            "And the important point to make is that the right design at a given design at a given value.",
            "Might might be the wrong design, very wrong when that parameter scales by factor of 10 or 100.",
            "So a good rule of thumb I like to use is that whenever you're designing a system, you want to think about what would happen if that parameter scaled by a factor of, say up to 10, but beyond that it's really difficult to sort of have the same system work for X100X.",
            "At that point, you're probably going to need to sort of redo significant pieces of the system to deal with 100X more queries or hundred X more documents that you're indexing because the same.",
            "Designs may not make sense anymore.",
            "The other cool thing about web search or search in general is that you can sort of replace the entire back end serving system without users really noticing.",
            "And we've done this many, many times over the last 10 years or so.",
            "You can sort of devote a new data center or convert 1 existing data center to a completely new serving system, run some fraction of user traffic through that for awhile an once.",
            "It seems to be stable.",
            "Then you convert over all the other ones and users depending on how visible the changes are that you're making in the retrieval system, you know sometimes it just seems faster to users.",
            "Sometimes that just has a larger index, but other than that it looks pretty much the same with the same user interface.",
            "So that's kind of nice."
        ],
        [
            "It also allows you to rollback if something goes badly.",
            "Just kind of.",
            "So in the rest of the talk I'm going to, I'm going to give you sort of a sense of some of the evolution of our searching systems.",
            "Sort of the internal details of it's going to be focused more on the system design as opposed to the ranking algorithms.",
            "I'll give you a brief description of some of the supporting infrastructure that we've already published papers about.",
            "Just to give you a sense of the tools that we use to build some of these retrieval systems.",
            "Obviously, anything that covers something of this scope is joint work with many, many people there.",
            "I started to try to put a slide together, but it's way too many people to put on the slide, but there are numerous people involved in this effort, and then I'll give you some thoughts about interesting directions and challenges in.",
            "What I see sort of the next few years."
        ],
        [
            "OK, so as many of you probably know, Google started as a research project at Stanford when our founders were grad students there.",
            "They I guess their advisors were mean and wicked and wouldn't really give them computing hardware, so they actually had to go beg and scrounge computing hardware from other research groups.",
            "They would sneak down to the loading dock and intercept the shipments of computers that other research groups had ordered and volunteered to set them up, and then they would kind of keep the machines for a little longer than they really needed.",
            "Of off the float of other research projects arriving hardware.",
            "So.",
            "That's sort of the origins of Google.",
            "Is it always started out as a whole bunch of machines, kind of connected together by networks?",
            "But one problem with this approach is that you end up with a variety of different computer architectures.",
            "It's not really so pleasant to deal with five different CPU types in that environment, so."
        ],
        [
            "We've standardized on less than that, but the original research project had one.",
            "Well, one of the things that it did was it decided they knew that the system they wanted to build was going to be building indices that are way too large for a single machine, and so they started off partitioning both the index and the other aspects of the system across multiple machines.",
            "And this is obviously something we continue to do today.",
            "Do today.",
            "The that's basically the simple architecture of the research project."
        ],
        [
            "Let me talk a little bit about partitioning.",
            "So in indexing system there are two main ways that you can imagine partitioning index data.",
            "The first is by document where you essentially chopped.",
            "The documents are going to index into a bunch of buckets, the.",
            "And each of the buckets is going to have all the information for some of the documents, so that's nice because each Shard basically has all the information for some of the documents and can process queries independently, suddenly queried all the different shards they send the results back.",
            "An then you merge.",
            "The nice thing is that the network traffic in this approach is fairly small, so you send the query down to each of the shards, query.",
            "It's pretty small, they do a lot of computation over a lot of local data stored on disk, but then the data they send back over the network is also fairly small.",
            "It's sort of a collection of documents and score pairs.",
            "A drawback of this approach though, is that you often end up doing order K * N. This seeks where you have a keyword query that you're sending to end different shards, so as sharding in your system as your index scales anyer sharding gets larger.",
            "You start to do more and more disks in this approach.",
            "Another drawback is that the query basically has to be processed by each of the shards.",
            "That's why the end term exists in that in that.",
            "And it's worth saying if you drop one of the shards then you're likely going to be dropping good documents, especially if the number of shards is not too large."
        ],
        [
            "The other approach that you could do is you could charge your index by word, where you essentially build inverted indices and then you give some of the words to one machine.",
            "Some of the other words to another machine to another partition, an then has the nice property that a keyword query is handled by at most K different shards.",
            "You do only order Kata seeks for keyword query.",
            "The drawback is that you're ending up with the information about each document spread across many different machines.",
            "And that you need much higher network bandwidth across.",
            "Because you're streaming, posting less data from one machine to another, and it's also harder.",
            "There's not an obvious place to have per document information.",
            "You might want other information like page rank or the language of the document.",
            "Other kinds of things that you want to use during ranking doesn't have an obvious home."
        ],
        [
            "So in our computing environment where network bandwidth is a fairly scarce resource, we end up partitioning by document, and that's what makes more sense."
        ],
        [
            "Trust.",
            "OK, so the basic principles in most indexing systems are going to assign small integer identifiers to a document.",
            "It's good if you can order the assignment of identifiers to have smaller numbers have been more important or better quality documents in some sense that allows you to stop early.",
            "So if you retrieve a million results and you haven't hit the end of the index yet, you can stop and be assured that you are going to score the million most important documents or highest quality ones.",
            "The interface training server is given a query return a list of score, score and document pairs.",
            "In our case there Charter document the cost of the index serving system which basically returns scores and document ID identifiers is order number of queries times number of documents in your index.",
            "And then the doc servers.",
            "One of the things that the original research project did that most other search engines of that time were not doing, is returning query specific snippets.",
            "So when you show a summary on the result page, the original Google prototype would show the title of the document and then some sampling of word of sentence is from the document that were in the context of your query as opposed to a lot of other search engines which at the time would show just the 1st 20 words the document.",
            "And that's actually a very important.",
            "Thing for improving sort of the usability of your search engine is to show query specific snippets 'cause users can scan a list of results and get a much better sense of whether that document is relevant to their query or not without actually having to click through to the document.",
            "Well, but it's worth saying that the doc serving system that generates the title and snippets is only going to be order number of queries, not order another queries times the number of documents in the index.",
            "So as your index gets larger, the cost of the index serving portion dominates and so we don't focus very much at all on the performance of the dock servers other than trying to reach their latency.",
            "Almost all the performance implications in the system are in the index serving system and the ranking system."
        ],
        [
            "OK, so we knew when the company was started that we wanted to ride the commodity computing wave where cheap cheap commodity hardware was the way to go so that you could have larger indices you could afford to devote more computational resources to each query and so on.",
            "So we push this a bit to the extreme in the early days where.",
            "Now we've actually decided we didn't need all these fancy computer cases and it be better if we could, you know, share power supply between 4 machines so that we didn't have to pay for for power supplies.",
            "And we would buy our own components and assemble them ourselves.",
            "And so this is our first attempt that involved there's a cookie tray there an on top of that cookie Tray is 4 motherboards with a thin layer of Cork to protect the cookie tray from the motherboards there affectionately known as Cork board.",
            "And there's, you know, you can see four reset switches in the front.",
            "Anna shared power supply.",
            "Turns out, sharing a power supply between more for machines is not really that great an idea.",
            "We have dispensed with that idea."
        ],
        [
            "Nor is Cork a good idea.",
            "So the serving system in 99 look pretty much.",
            "Like the original research prototype with a few additions, one is, it was replicated more so each of the index shards in each of the dockyards had multiple replicas and on different machines to have capacity we added an ad system that was actually the first thing I worked on at Google is to build our initial ad system.",
            "And we added caching to cache common query results.",
            "So let me."
        ],
        [
            "Talk a bit about caching.",
            "Cache servers are really important pieces of a retrieval system, especially if you want to boost if you have large query volumes or you want low latency, or both.",
            "We use them to cash both the index results and the snippets.",
            "Mute get hit rates of on the order of 30 to 60%.",
            "It's not like CPU caches.",
            "We're getting 99%, but a lot of that hit rate depends a lot on how frequently updating the index the mix of query traffic you know is it all in different languages?",
            "Or is it mostly in small number of languages?",
            "How much personalization are you doing?",
            "What are the key?",
            "If the cache key has to include?",
            "Aspects of information you're using in order to do personalization, then that sort of takes what would be one simple queries results and spreads them over all the different kinds of things you're using to do personalization.",
            "But the main benefits are performance, so you have perhaps 10s of machines that are doing half the work of your retrieval system and the other half is being done by hundreds or thousands of machines, so it's definitely a good deal.",
            "You should have cashing in there.",
            "It also is really nice because it gives you reduced query latency, time for cash aid is much lower than the time for.",
            "To actually go out to all the index servers, do ranking retrieval and return results an, it also tends to be the queries that hit in the cache tend to be the more expensive queries.",
            "They tend to be ones with more popular words in them or.",
            "Popular phrases that are expensive and they have a lot of documents to score so.",
            "Even more than just cash it right, but the cost of the queries that hit my cash is larger than just the cash rate.",
            "What are the things to be aware of when you introduce caching into the system?",
            "Is that you can get big latency spikes or capacity hits when the cache is flushed, for example, or when you switch over index data to sort of the cash no longer applies and you end up getting a lot of cache misses.",
            "Essentially all your cache hit rate will drop to zero and then start to work its way steadily back up, but in the moment it drops after it drops to zero.",
            "You can have kind of operational disasters so you have to be kind of aware of that."
        ],
        [
            "OK, so the crawling system around you know 98 to 99 was a fairly simple batch oriented crawling system.",
            "The idea is you start with fewer URLs.",
            "Actually it turns out you need remarkably few seed URLs because most things can be reached from just a few places.",
            "You crawl some pages, you extract links from those pages you Adam to a queue, an you stop when you have decided that you've hit your budget of whatever, you can index.",
            "There are a lot of concerns in building and crawling system.",
            "I'm not going to.",
            "Focus on them too much, but you need to not hit any site too hard.",
            "You need to prioritize among the uncalled pages so that if you have fetch bandwidth available, you fetch something that you think is more useful than a random page.",
            "You need some way of maintaining the sun crawled URL Q and efficiently, because you're for every page you crawl you're extracting.",
            "You know perhaps 20 links and having to insert them into the queue.",
            "And you don't want to seek for each one of those, and you have to have some way of dealing with machine failures in the crawling system."
        ],
        [
            "The indexing system in those days was a fairly simple batch indexing system.",
            "It was based on fairly simple tools.",
            "There wasn't really any checkpointing, so machine failures were pretty painful in those days.",
            "They not only did our early machines not have ECC memory, they didn't have parity, which is very painful if you're trying to actually use them.",
            "In particular, if you sort a TB of data on a machine without parity, it ends up mostly sorted.",
            "If you started again, that's mostly sorted some other way.",
            "One of my colleagues liken this to programming with adversarial memory.",
            "And so one of the early things we did to help insulate us from the adversarial memory was we developed a little file system abstraction that had the ability to write records, and it would check some of them and insert sort of re synchronization markers in there, so that if you.",
            "It would insert checksums in the records.",
            "We could know if it was corrupted and you could also then re synchronize to the next valid record with the re synchronization markers.",
            "And ignore the corrupted records and.",
            "One of the nice things about web searches.",
            "There's enough data and redundancy in the world that if you drop a document here or there due to corruption, it's not that big a deal."
        ],
        [
            "Generally, unless it's something really important.",
            "So index updates.",
            "In those days the basics.",
            "Well, they happened infrequently, thank goodness because they were a lot of work, they happen about once per month, so you basically wait until traffic flow.",
            "You take some of your replicas offline.",
            "You'd copy the new index these replicas, and then you'd start new front ends pointing at these replicas.",
            "An service in traffic from there, and you gradually migrate more and more of your machines to serving the, you know April index instead of the Mark Fund."
        ],
        [
            "One of the things that's important in a disk based index is you want to use the outer part of the disk 'cause it's faster, so the index switchover process is actually a little bit more complicated.",
            "You'd start with the current index on disk."
        ],
        [
            "And then you would switch over to the new index by copying it to the."
        ],
        [
            "Free half of the death.",
            "Then you wipe the olden day."
        ],
        [
            "Then you copy the new index back to the faster half of the disk."
        ],
        [
            "Then you delete the old, the original first copy."
        ],
        [
            "And then that would actually free up some disk space that you could use for building various performance.",
            "Improving data structures in the middle.",
            "One of the things we built was something we called the pear cache, which is basically if you look at commonly Co occurring query terms we would offline precompute pre intersected pairs of posting lists for these commonly Co occurring terms.",
            "They don't have to be phrased terms, they just have to be terms that occur frequently in queries together.",
            "So we're not building a phrase index, it's just you know, Barcelona and restaurants occur in the same.",
            "Documents."
        ],
        [
            "Um?",
            "So by 2000 we refined our hardware design a bit.",
            "We had decided cases were OK again.",
            "We managed to get all the connectors on the fronts of the computers, which is good.",
            "It was quite painful to reach around the back of the old Cork boards to install Ethernet cables and we were still not owning our own data centers.",
            "We were leasing space in hosting facilities and they charge by the square foot which was an excellent deal for us.",
            "So we would try to pack as many computers as we possibly could and uses them much electricity as we possibly could into the number of square foot square feet they would license us.",
            "So that."
        ],
        [
            "Grad thank sometimes needed a little extra help with air cooling that we would purchase fans for them."
        ],
        [
            "As a consequence, we also got fairly good at moving out of bankrupt datacenters and moving into new ones.",
            "And so the nice thing is."
        ],
        [
            "It's not actually too hard to move into a new data center.",
            "You have all the racks all cabled up already, and then you basically have to wheel in the racks and then connect together all the rack switches to a central router and you're ready to go."
        ],
        [
            "So in the period of 99 to 2001 roughly we were simultaneously having huge traffic increases, an huge increases in index size, so our index size when I'm roughly by factor 20 and at the same time as we were having roughly ten 1520% growth per month in query traffic.",
            "And we're also out signing deals.",
            "So for example, we signed a search deal with Yahoo to provide their search service.",
            "And that doubled our traffic overnight at the same time we were actually doubling our index size in the previous few days.",
            "This is quite exciting.",
            "And the performance of the index serving system is what is really important in these cases.",
            "And when you're dealing with this sort of thing, we are continuously buying more and more hardware and leasing more and more data center space.",
            "But we basically needed 10 to 30% software improvements every month in order to sort of squeak by in our capacity.",
            "Otherwise we would end up in a bad state."
        ],
        [
            "So the nice thing about this basic.",
            "Structure I've now moved the dock service off to the side 'cause they're not very interesting from a performance standpoint.",
            "The nice thing is that it's fairly easy to add capacity."
        ],
        [
            "You can grow your index by adding more index shards and."
        ],
        [
            "Then you can.",
            "Add more replicas to add."
        ],
        [
            "Capacity an if you're growing your next lot you."
        ],
        [
            "Add more image Shard and more."
        ],
        [
            "Dick shards andmore replicas for capacity."
        ],
        [
            "An order charge and eventually end up with a lot of machines and a lot of shards and a lot of replicas, but it's a fairly.",
            "Reasonable process to do that, as you do, you don't try to do this in the middle of index.",
            "You sort of say OK and then the next months index we're going to do 17 yards instead of 10 or something."
        ],
        [
            "Um?",
            "So one of the things one of the reasons you have to keep adding shards as you increase your index sizes that you want to have query response times be reasonably low and if you make your shards too large then well they they might not fit on the local disks of your machines or be your response time or get too large and so you need to sort of increase the number of shards in linearly as you're increasing your index size.",
            "And.",
            "It's also possible to get pretty big performance improvements, which we did by writing our own discuss scheduling system that was sort of aware of what queries were pending on the particular server, and prioritizing reads in a reasonable way.",
            "We also focused a fair amount on improving our indexing coding, which is what I'm going to talk about now."
        ],
        [
            "So the original encoding done as part of the prototype at Stanford was pretty simple.",
            "It was actually a fairly simple byte aligned format.",
            "Basically you'd have document identifier plus the number of hits encoded in 32 bits, 5 bits for the number of hits, and then 27 bits for the doc ID and many guys 16 bits for each word occurrence for each occurrence of that particular word that encoded both the position of the word as a sequence number within the document.",
            "And some a few bits for attributes of the word like was it a in the title?",
            "Was it in a big font or little font?",
            "And so on.",
            "And for very long posting lists, you eventually want to add skip tables into the data structure so that if you have the word of or something, you have a table on the side that tells you.",
            "Oh yeah, doc ID million is at offset.",
            "Two 2 billion in your posting list.",
            "The byte Align format was pretty simple to decode, but it's not very compact and it actually required lots of disk bandwidth, so we worked for Fairmount on our encoding data."
        ],
        [
            "Pictures.",
            "And I'll give you a brief background on various encoding techniques because they'll be useful to understand the encoding format we used.",
            "Basically, there's several different bit level encodings you can imagine using, which are going to be slower than byte level encodings, but little things are things like unary encoding where you encode the number, and you just have an ones followed by zero gamma where you're going to code some prefix in unary that indicates the length of the number, and then that number of bits rice, which is a special form of Golomb codes.",
            "Where you you basically have a number an you have a base that you're going to do that number in, and it writes codes.",
            "The base is always going to be power of two.",
            "So for example, you encode.",
            "N divided by, let's say our base is 3, then you're going to encode end divided by two to the third in unary and then an MoD.",
            "Eight and three bits.",
            "Anne."
        ],
        [
            "Is everything so?",
            "The format we used for awhile was basically a block based index format, so the nice property.",
            "This had it so word is going to have a skip table and then it's going to have a sequence of blocks.",
            "The Skip Table is optional, only occurs for a small number of words that are very large.",
            "That have a lot of data.",
            "So the nice property of this.",
            "Of the format is that there is a byte aligned header that has two important pieces of information.",
            "First is the Delta from your current doc ID in the posting list to the last doc ID in this block.",
            "Ann, this second thing is the block length in bytes, so you can look at that Delta to the last docket in the block.",
            "If you're trying to go to.",
            "If you're at Doc idea thousand, you're trying to go to Doc ID 10,000 and that Delta says the last block has a Delta of 2000, then you know that this block is not of interest to you because it would only take you to 3000, so you can just read that header completely, skip over the rest of the data in the block, and I'll figure out if indeed you need to put peek inside this block because.",
            "You think you're interested in something in the range of docket is covered by the block.",
            "Then there's a few bit level encoded things that tell you the encoding type of the rest of the data in the block tells you the number of documents in the block, and then we have a bunch of doc ID deltas for the individual documents that are encoded in this block.",
            "So the block is going to have N documents and then H hits.",
            "And then we have N values.",
            "So per document how many hits, how many occurrences of the word were there per document?",
            "That's the next piece of information.",
            "There's any of those values, and there's going to be H hit attributes.",
            "Which tell you things like the font size and things like that, and then the actual positions.",
            "So notice that.",
            "This is an incrementally decodable format, so that if you only care about getting the doc IDs, you can decode just up to the doc ID Delta portion of this, and then you might say, Gee, there's no.",
            "I'm doing and query it.",
            "Turns out you know I thought there might be matches in these two blocks for the two different words, but it turns out that you know Doc 8017 didn't occur in both of them, so that I can skip all the rest of it.",
            "I don't spend anytime decoding the hit positions with the attributes or anything like that.",
            "If what I care about.",
            "Eventually you may need to decode all this for documents that you score, but that's a fairly tiny fraction of all the documents that you're examining during retrieval.",
            "While all the posting list your traversing during retrieval.",
            "So this actually reduced our index size by about 30%, plus it was actually a lot faster decode than the simple byte aligned format.",
            "'cause you can often skip, you know 50 documents at a time just by looking at that byte aligned header."
        ],
        [
            "So one of the implications of this ever increasing index size and thus more shards is that query cost is increasing all the time because as you increase the number of shards you're going to do, typically a disk per Shard per query term, and so as you add more and more shards, even for very rare terms, you're going to seek on each of the of the.",
            "Charge an one of the nice things that happens is the add more replicas for capacity.",
            "Your total amount of memory in your whole serving system increases an.",
            "Eventually, you squinted this and you say, Gee, maybe I could use all that memory for caching, and so you try to come up with complicated ways of caching commonly used posting lists and then G. You kind of squint problem you're like, Gee, you know I could hold the whole one copy of the whole index in memory across all these machines.",
            "Course then it only have one copy of it, but that would be cool and that actually changes a lot about how you think about water.",
            "Expensive things in your retrieval system.",
            "Water cheap things."
        ],
        [
            "So in early 2001 we rolled out our first in memory index, so we were holding the entire index of all the data in memory.",
            "We changed things a bit so we took all the machines that were dedicated to replicas.",
            "In any chart, an instead of them being replicas, they each served a different piece of the Shard in memory.",
            "So we have these things called micro Shards.",
            "We kind of chop an existing Shard up into a bunch of little pieces.",
            "The query now needed to go to many more machines, so rather than going to you know 50 or 60 shards that we need to go to maybe 1000 machines.",
            "And so we introduced another intermediate level of server called Balancers, that would take a query from the web server and then direct the request to all the different shards.",
            "I didn't draw the arrows, but it's actually going to all the different machines in that Shard.",
            "And the balancer is also responsible for sort of coordinating, loading and unloading of these micro shards across all the different in memory servers.",
            "To do both load balancing and when one of the machines fails, it would kind of deal with recovery of that unfortunate event."
        ],
        [
            "So.",
            "The two main benefits of this in memory index are that you get a big increase in throughput.",
            "Anna big consequent, big increase in performance per dollar.",
            "You also get a huge decrease in latency, especially towards the tail of your latency curve.",
            "So queries that used to take a really long time well.",
            "Here's one example is circle of life as a phrase query.",
            "So this is a very expensive query in a disk based index system, because each of those words is relatively common.",
            "But that phrase occurs extremely rarely on the web, and so this query in our old disk based index system would take many many seconds and have many gigabytes of IO, and it would be very expensive in an in memory index system.",
            "It's much faster because you end up well, basically because the Sikhs are 10,000 times faster.",
            "Now there are some issues that you have to solve.",
            "If you have an in memory index system, one of them is that because you're touching many more machines on every query, then you were with a disk based system.",
            "You end up with a lot of variance and that variance can really kill your latency because you essentially need to wait for all the results to come back before you return from.",
            "The query before you return results to the user.",
            "We had issues with.",
            "For example, someone had in our operations group.",
            "We wanted to do something every five minutes.",
            "And so rather than straightforward, Cron job that every five minutes would wake up on all the machines and do something it was thought that it would be a bad idea to have them all doing it at the same time.",
            "So instead we would randomize the time that each machine would do.",
            "It's kind of five minute activities across the five minute interval.",
            "The unfortunate thing about that is, in an in memory index system where your query is actually touching most of the machines in your data center, it's actually a bad idea to randomize the time.",
            "You'd rather kind of have it be done all at once so that you hurt the latency of a few queries.",
            "A lot rather than hurting the latency of all queries, little bit, and the reason it hurts all queries a little bit is at any given time, at least one of these machines is doing this random Cron job and so is running some sort of background activity that is slowing down.",
            "The other thing that hurts is that gets hurt by an in memory system is availability because you have many fewer replicas, typically just one replica in each data center of that documents of a particular documents index data.",
            "There are two problems.",
            "One is we occasionally have bugs in our query serving system that cause a back end to die when it receives the query.",
            "You know, maybe it's not even dependent on the particular index data that machine has it.",
            "Maybe it's just a bug in the query parsing code, something like that those are not good in any system, but they're especially bad in an in memory index system where you have a query of depth you end up killing 1000 machines instead of dictating.",
            "Um?",
            "So those aren't your kids.",
            "You have to figure out some scheme that allows you to insulate or inoculate yourselves from the effect of queries of death.",
            "The other thing that is bad is when a machine fails.",
            "They you end up having a period where the data that machine was serving is completely unavailable, you don't have any copies of that index data and that data center.",
            "So for very important documents we ended up replicating them in multiple different shards an so that we would be insulated to single machine failures and still have CNN's homepage.",
            "For example, when machine went down."
        ],
        [
            "OK, so overtime we've decided that it was better to build our own data center facilities.",
            "This is a picture of our data center and the dals Oregon near a big hydroelectric dam, and so this is just to give you a sense of the kinds of facilities we're building."
        ],
        [
            "Day.",
            "If you look inside it still we're back to no cases.",
            "It turns out airflow is better, but they look much cleaner than the Cork boards, don't they?",
            "So basically the.",
            "The current machine design is essentially an in-house rack design that provides pretty good airflow.",
            "Standard PC class motherboards still fairly low end storage and networking hardware.",
            "They all run Linux plus a bunch of in-house software.",
            "On top of that.",
            "Alright, I'll talk about briefly."
        ],
        [
            "In 2004, we rolled out another fairly significant change with sort of a generalization of some of the stuff we learned from our in memory index.",
            "One of the things that.",
            "Happened is we sort of generalize the notion of this query distribution tree so that you could have a two level or three level treated which ever made sense depending on what size index you're trying to serve.",
            "We generalize the notion of balancers so that there was one manager for doing load balancing across the entire cluster.",
            "There were much cleaned up APIs, so it was possible to basically use this simple.",
            "Same basic system and plug in your own scoring function.",
            "If you're for example implementing a different product at Google like book Search, you want to plug in your own book specific scoring functions, but you still want to use sort of the nice infrastructure that the system provides.",
            "The whole set of API's were designed so that that was pretty easy to do.",
            "We had by this time it developed a distributed file system that we could depend on.",
            "An for reliably use.",
            "So at the bottom level is GFS, which is this sort of cluster level file system where all the index data was actually loaded from the previous systems.",
            "We would sort of manually SCP data to local disks in the new model.",
            "GFS is sort of assumed to exist and you can sort of load index data out of that and so on.",
            "What else is there?"
        ],
        [
            "Say.",
            "So again, we rethought our index encoding data structures.",
            "The block level Index format which we had designed when we were still a disk based index and sort of still continued to use all, be it with smaller blocks in the.",
            "In the in memory index used the two level scheme.",
            "Basically we would encode sequences of Doc IDs and then for each document we would encode a sequence of positions and the doc, ID deltas.",
            "As I said, were encoded with rice encoding, so that's fairly compact bit level encoding.",
            "It gives you very good compression and the block based format meant that it was pretty.",
            "Good for.",
            "It is fairly CPU friendly as well.",
            "'cause you could often use the block headers to skip things in our new format.",
            "We use a single flat position space and we have data structures on the side that keep track of these document boundaries.",
            "So if you have a document with 100 words, that's going to get allocated position zero to 99 and then you have a document with 10 words.",
            "That's going to get positions 100, two, 109 and you're going to have these other data structures on the side to allow you to keep track of which positions map to which document.",
            "The.",
            "Posting less for each word than are going to be a single flat.",
            "Position list as opposed to this two level Doc ID and position.",
            "Pairs it needs to be a compact data structure, so you can't really afford 32 bit values per occurrence, but it needs to be really fast to decode, so that's paramount for your performance."
        ],
        [
            "So it turns out you know you want to use byte aligned encodings and variable length ones for.",
            "Encoding your your sequence of position deltas.",
            "You obviously always use deltas from the previous position, not the actual position, 'cause they're much more compact, specially for very frequent words.",
            "So one encoding that you can imagine using is what I'll call of.",
            "Our encoding is basically 7 bits of data per byte, plus A tag meant that says.",
            "Is this the last value in the bite or not?",
            "So for example, if you have the value one, we're going to use the blue things are going to be tag bits, and so the value one is encoded in those seven bits.",
            "And zero means that's the last bite in the value.",
            "15 is encoded.",
            "Similarly, 511 doesn't fit in.",
            "It's bigger than two to the 7th, so you need two beds, 2 bytes of data.",
            "So there's a one in the first byte, indicating that you have to continue on to the next bit to the next byte and get the data from there.",
            "An hundred thirty 1071 requires 3 bytes in this encoding.",
            "So the problem with that encoding is that it requires an awful lot of shifting and masking and branching, especially unpredictable branches which are very expensive on modern machines.",
            "In order to decode."
        ],
        [
            "So one thing you might try is to take the length of the value that you're going to code and encode that as the low 2 bits of the.",
            "Maybe the first bite in the value, so in this case you know we have one and the low 2 bits indicate 00 indicates it's a one byte value and 01 indicates it's a two byte value.",
            "AN-10 indicates three byte value.",
            "That's pretty simple, but it's very nice because you have fewer branches.",
            "You essentially just load a 32 bit value, look at a low two beds, and that tells you a mask value that you can use to shift the rest of the word right by two bits, and then that mask value tells you how many of those bits you should use to decode.",
            "So there's no branches actually, which is kind of nice."
        ],
        [
            "So an encoding.",
            "We actually came up with that we're pretty happy with is what I'll call a group varint encoding.",
            "So the idea is similar to the previous one.",
            "You're going to encode groups of four values into bundles of five to 17 bytes."
        ],
        [
            "So the first thing you do is you're going to pull out these four 2 bit binary."
        ],
        [
            "Length.",
            "You know a single byte prefix.",
            "And that gives you the tags."
        ],
        [
            "Then you're going to encode the actual values just as either 123 or 4 bytes.",
            "So that's actually pretty nice.",
            "It's a little bit less compact than the 30 bit, and like the two bit embedded in the byte encoding, 'cause you'll use an extra byte up to 20% less compact."
        ],
        [
            "But to decode this, this is pretty fast.",
            "So you load the prefix byte.",
            "That's the blue one and you use the value to look up a entry at 200 and 5600."
        ],
        [
            "And that tells you 2 pieces of information.",
            "First, it tells you the byte offsets of all the different values in the bundle.",
            "And it also gives you the masks to use to decode.",
            "The values.",
            "So by doing a single byte load a single table look up, you now have all the information need you need to decode all the numbers in that bundle.",
            "Furthermore, the data dependence chain in decoding those numbers is very short.",
            "It's all basically that single byte load plus the table look up and then you have all the information that the machine needs to be to have lots of instruction level parallelism and decoding that, whereas in the previous approach you needed to code 2 bits.",
            "Do some step masking and shifting and go to the next number.",
            "Decode 2 bits."
        ],
        [
            "Anyway, it turns out it's a lot faster.",
            "Not.",
            "I'm telling you about it and I like it, so that's why.",
            "Ah."
        ],
        [
            "So in 2007 we rolled out another fairly substantial change.",
            "Was that we really should have done earlier, but it was sort of an operational and sort of logistical effort to get it done.",
            "The main issue was we had our web search product which had a very large index of web pages and then we had all these other products that people could go to directly to.",
            "Do you know you gotta print.google.com to search books you can go to news.google.com to search news.",
            "Anne.",
            "You know, that's really not that great a user experience 'cause the user has to pick which corpus they think is relevant and then go to that particular property and search it.",
            "And so we would sometimes search news when you did a web search and show you an embedded news result if that seemed relevant.",
            "But really, we should be searching all corpuses at all times.",
            "Whenever you do a query on Google so we can find you the most relevant information regardless of what.",
            "You know particular corpus that happens to reside in one of the things that had to happen for that is all the other properties had to be built to have enough capacity to handle full web search query volumes.",
            "And that's actually somewhat challenging to do because a lot of those other products are engineered assuming much lower query volumes.",
            "So the print.google.com for example, was engineered assuming traffic to the book search system, which is a lot lower than our web search traffic.",
            "And so we had to sort of get everyone using common system that had all the same performance enhancements we put in a web search and put them all into the other corpora as part of that, we built an indexing service, so it was easy for different products to dump data to be indexed into the system.",
            "It would get indexed and built on each of those trees.",
            "Each of those triangles is essentially one of those corpus trees that I showed you before with the root and some intermediate servers and some leave.",
            "Handling that.",
            "And then there's obviously lots of interesting challenges in deciding, given the results from each of these corpuses, what which ones are most relevant to show for that particular query an what you I should you use to show them and so on.",
            "I think one of the things we in the past had approached this problem as we said, Gee, we don't have much capacity.",
            "Let's see if we can find some queries that we'd like to send to some of the other corpora that we believe will have good results, but that's a much harder problem because you're actually trying to decide based on 3 words in the query.",
            "Is this going to be an interesting?",
            "Will the Google Groups corpus have interesting results for that three word query?",
            "And that's actually a much harder problem then if you actually send the query down.",
            "Get the scores back from that corpus and the relevant documents and then we can make a decision saying Oh yeah, well, the score from groups is 12 in the score from printed 5, so I'm going to assume that one of them is more relevant in the other, all of the scores may not be directly compareable.",
            "You could overtime over a set of queries understand when one corpus is going to be more relevant than another."
        ],
        [
            "The other big change that's happened relatively recently is that.",
            "We now have the ability to update our index in a matter of a minute or two for a given page, as opposed to waiting fairly long periods and doing very large batch updates.",
            "And there are a lot of things that have to change in your system in order to really do that, right?",
            "First of all, how do you know what pages you want to update?",
            "It's good to have a system that can identify are there interesting new pages on the web that have just shown up in the last minute or two?",
            "Or are there important pages that have been updated that you ideally would like to have any page as soon as it changes be updated in your index, but that's a very difficult thing and there's not enough crawl bandwidth in the world to sort of really do that, and some pages change every time you call them 'cause they have, like the timestamp at the bottom.",
            "So you sort of have to pick and choose your battles and decide.",
            "For a given budget of pages that you can update, what are the most important ones that you want to update and so that your index is fresh and useful to users?",
            "So the crawling system needs to be able to accommodate these very fast update requests like I want to update this page and I want it now not.",
            "Here's a whole bunch of URLs and I want them, you know, in an hour.",
            "The indexing system is challenging because it depends on global information, at least for web search.",
            "For example, where you depend on things like page rank, you depend on the anchor text of pages that point to the to that page.",
            "You need to actually index that data with the other target document, so you must have some way of getting this information or some approximation of it in order to index a paid within a minute or so, and the serving system has to be rethought a bit so that it can be accept updates for different documents while you're actually serving requests.",
            "An accept updates that are fairly frequent interval.",
            "And the data structures you actually want to use are fairly different.",
            "In that case, then something where you update things in batches of an hour or so."
        ],
        [
            "The other thing that I think is important in we've.",
            "Realized overtime is that it's really important when you're trying to make progress on improving ranking and and search quality and so on is that you want to make it easy to do experiments and the faster you can make turn around on a particular experiment from when you have an idea to when you actually can demonstrate prototype of that idea, the better it's going to be.",
            "So we've spent a lot of effort building tools that allow it.",
            "Make it fairly easy to do some kinds of experiments, and that's been.",
            "Beneficial some experiments you don't actually need to sort of do very much, you just want to wait different ranking parameters and those you can actually do without really rolling out anything in terms of new binaries or anything.",
            "You can just do them online.",
            "The ones that are more difficult to the ones that need information that you didn't have the foresight to build into your production index.",
            "So you need some way of computing new information.",
            "Generating it often involves passing, making it pass over all the documents or over some.",
            "Derived information from all the documents and being able to build that data structure on the side that you can then use to do your experiment."
        ],
        [
            "I'm not really going to talk very much about these various systems, but several of the pieces of infrastructure we've built are useful for doing some of these kinds of experiments.",
            "I already talked a little bit about GFS, which is just a big file system spread across thousands of machines.",
            "App produces a abstraction that makes it easy to write and run large scale kind of batch computations, deals with like nasty things that happen like machine failures.",
            "It automatically parallelizes things across lots of machines.",
            "And it basically enables you to write.",
            "Simple, fairly simple programs that can extract information that is of interest to you for your experiments and perform those ad hoc experiments more quickly.",
            "And big Table is a sort of semi structured storage system.",
            "Think of it as a very large row and column oriented store.",
            "So for example, one thing that gives us is online efficient access to per document information.",
            "At anytime you can say what is the current information.",
            "I know about cnn.com.",
            "And it will tell you OK, the page rank is this.",
            "We last crawled at this time.",
            "Here is the current contents that we know about.",
            "So on.",
            "And this is very useful for being able to update documents in a matter of minutes as opposed to days."
        ],
        [
            "OK, so the experimental cycle you want to start with a new ranking idea.",
            "You obviously use these tools to generate interesting data, and then you want to be able to at first run offline experiments.",
            "So users are involved in this.",
            "You essentially just want to run your, say ranking, change an look at what effect it has on how results are ranked for a different query sets, and some human rated query sets and other ones.",
            "Maybe you'll do a random selection of queries and just look at what changes compared to the production ranking.",
            "So the important thing to note here is that the latency or the throughput of this prototype don't really matter.",
            "You know you can run 10,000 queries and it can take hours.",
            "That's OK, it's not ideal, but it's OK, and then you kind of iterate based on the results of this.",
            "Maybe you find that Gee, it works well in this case, but not this case.",
            "And then you change your code a little bit."
        ],
        [
            "So the whole framework or the experiment that you run must operate.",
            "I propose to production latency's.",
            "You know, adding 100 milliseconds is maybe OK, but in a second or two is definitely not."
        ],
        [
            "OK, so now you've managed to solve based on various kinds of user quick metrics and so on that your payment is better than what we're running today, so you want to be able to launch it, and so sometimes it will just work.",
            "'cause you thought about throughput from the beginning.",
            "But sometimes maybe you do fairly expensive things that are computationally not so ideal on our full traffic volume, so you'll need to figure out how you can tune.",
            "Whatever it was you did in your experiment that it can run at full gold.",
            "Traffic.",
            "Volume an 1 one of the techniques you often use as you're going to precompute something instead of competing at runtime.",
            "Another one is maybe there's some much cheaper approximation you can use that will be good enough, although obviously then you need to go back re validate that your approximation is giving you the same kind of quality that your full computation was.",
            "It's really important to have a smooth rollout process for search quality improvements.",
            "You're continuously making these quality versus cost tradeoffs.",
            "You know you might have something you want to launch that increases the CPU cost of every query a little bit.",
            "You need to have some sort of understanding and budget for improving quality, but if you don't then you're going to have not healthy relationships between who want to minimize the number of machines you take an the people who want to improve.",
            "Search results, so having sort of understanding of.",
            "What are the acceptable CPU costs that you can have this quarter for new quality improvements is really helpful thing."
        ],
        [
            "So.",
            "Interesting things, so I think.",
            "We're just starting to scratch the surface that was done in terms of cross language information retrieval.",
            "There's been a lot of progress in base translation.",
            "We have a research group at Google that is working pretty extensively area and is getting pretty good results for sort of automatic machine translation between different languages.",
            "The ideal goal is basically translate be able to translate all the world's documents into all languages.",
            "Obviously this is good for engineering, 'cause it increases index size a lot.",
            "It's really good and there's lots of computational costs.",
            "Just doing the translation.",
            "The way it's done today.",
            "But there's huge benefits if really done well, so you can imagine that anyone, no matter what language they speak and have access to all the information on the web, not just the subset of it in the language that they happen to speak.",
            "It's especially important in languages where there's not a lot of content in that language on the web.",
            "So obviously there's two challenges.",
            "One is continuously making the translation quality better, and there's actually lots of interesting large scale systems work in the actual translation process itself.",
            "Actually, for them a little bit turns out in order to translate one sentence, we need to do a million look ups in a multi TB model.",
            "That basically keeps track of how often every five word sequence occurs in all of our documents.",
            "An that doesn't fit on my machine, so we end up with this huge cups that you need to be able to do in parallel across a large number of machines.",
            "Loaded your model into memory."
        ],
        [
            "Other kind of interesting thing that is happening as we try to sort of.",
            "Have other products like Gmail that is personal information, various other kinds of products like groups that are between groups of you know anywhere between one and a million people is how can you actually build retrieval systems that deal efficiently with documents that are private that are sort of semi private to fairly small numbers of people that are shared extensively or that are completely public like web pages.",
            "The best solution that you can come up with for a given document that are shared with 10 people is pretty different, eh?",
            "Very public document an even worse.",
            "The sharing pattern of document might change overtime.",
            "You know it might be something you author 1st and now you want to publish it to a million people or 1000 people or something like that.",
            "So there's interesting things to do there."
        ],
        [
            "Another area where I think there could be some work is how can we automatically construct?",
            "Retrieval systems, so currently we have several different subsystems or retrieval system that are suited for different kinds of information or different kinds of.",
            "Parameters of the system.",
            "So one system deals with a small number documents but can do sub second update latency on those documents and other one is for very large number of documents but deals only with very large batches of updates at once per day, say.",
            "So we made a lot of progress on having common interfaces for the scoring and ranking function on across all these different subsystems, but the implementation pretty different an that works reasonably well.",
            "They were sort of happy with it, but it takes a lot of effort to build and maintain and extend all these different systems.",
            "So could we have a parameter isable system given you know some information about how many documents 1 update per second per day automatically constructs the right mix of retrieval subsystems too.",
            "Build, you know, minimize your machine cost."
        ],
        [
            "Another interesting area is doing better information extraction from semi structured data.",
            "I think the fully labeled semantic data is pretty interesting, but it's going to be a time fraction of data that exists in the world and there's going to be much more structured data like web pages with tables and so on, and then that is going to provide you with.",
            "A larger set of information, although it's noisier.",
            "So how can you sort of improve algorithms and techniques for extracting this kind of information from these unstructured and semi structured sources?",
            "Obviously there's a lot done in C, so that helps you in sort of.",
            "Dealing with the fact that the data is inherently noisy, you also want to be able to combine incorporated and aggregate all these things across different source."
        ],
        [
            "OK, so in conclusion, it's fun to build these systems.",
            "It's really a lot of challenging problems.",
            "You know.",
            "I work with great colleagues there.",
            "New problems all the time that require sort of continuous evolution of the system built and new directions.",
            "We want to be able to go in.",
            "It's really nice that this work benefits alot of our users.",
            "All of our users and I think that's probably the most fun that I have is because doing is challenging, useful and fun.",
            "OK, so thanks for your attention."
        ],
        [
            "And I don't know if we have time for questions, but.",
            "Then any questions.",
            "Yes.",
            "Yeah.",
            "Why do we want to slide every document to all languages?",
            "I didn't get this.",
            "Isn't this extremely costly at the end or relatively small?",
            "Gain.",
            "Well, it so that seems like a good ideal goal.",
            "Basically, you might make some approximations like you might say, OK, I want to take a moment and translated into the 10 most commonly used languages.",
            "That would not quite as useful, but would be much less costly.",
            "So these kinds of engineering decisions that you're having to make all the time when building a retrieval system, and I think.",
            "You know you're right, it would be pretty costly to it that way, but I think.",
            "Important to keep track of what the goal is and then figure out how we can sort of meet almost all of that goal in a less costly manner than to say, well, we're not ever going to be that well.",
            "So your snippet player in the document clustered seemed separate.",
            "I was wondering where the snippets are actually computed.",
            "So the index and the right.",
            "Sorry, so the snippets are computed in the doc servers talk servers basically have access to the full document text that we crawled and you get a query in Anna Document ID that says OK, I want to snippet this query for document 12 and then it goes and fetches the contents of document 12 and then compute the snippet.",
            "OK.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, welcome to beautiful by salon.",
                    "label": 0
                },
                {
                    "sent": "So it's my pleasure, true, introduce here today.",
                    "label": 0
                },
                {
                    "sent": "Jeff Dean's invited speaker.",
                    "label": 0
                },
                {
                    "sent": "Jeff Jeff was born in Hawaii.",
                    "label": 0
                },
                {
                    "sent": "And during his early years.",
                    "label": 0
                },
                {
                    "sent": "It spent childhood in many places, from Minnesota to Glenda, Atlanta back to Africa, Seattle.",
                    "label": 0
                },
                {
                    "sent": "Then he settled in the Bay Area.",
                    "label": 0
                },
                {
                    "sent": "Jeff is an extremely good engineer.",
                    "label": 0
                },
                {
                    "sent": "Great vision.",
                    "label": 0
                },
                {
                    "sent": "Big dreams.",
                    "label": 0
                },
                {
                    "sent": "And he pushes he dreams through very high scale.",
                    "label": 0
                },
                {
                    "sent": "In Google, every time that you get a new engineer.",
                    "label": 0
                },
                {
                    "sent": "Jeff is the target.",
                    "label": 0
                },
                {
                    "sent": "Jeff is there very high level model of accomplishment.",
                    "label": 0
                },
                {
                    "sent": "Is also very easy person.",
                    "label": 0
                },
                {
                    "sent": "Very easy to get along with.",
                    "label": 0
                },
                {
                    "sent": "And very good.",
                    "label": 0
                },
                {
                    "sent": "Team builder.",
                    "label": 0
                },
                {
                    "sent": "With no further delay.",
                    "label": 0
                },
                {
                    "sent": "Ducting.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to talk today about building large scale retrieval systems.",
                    "label": 1
                },
                {
                    "sent": "Something I've been doing for a little while at Google.",
                    "label": 0
                },
                {
                    "sent": "One of the things I like best about this area of work is that it provides a challenging blend of both unsolved research problems that we really don't know how to solve.",
                    "label": 0
                },
                {
                    "sent": "Interesting directions that this work can go in, and it also provides a bunch of challenging engineering problems, and it's this blend of thing of problems that I think is both very interesting and challenging.",
                    "label": 0
                },
                {
                    "sent": "It also spans a lot of different areas of computer science, but I think it's fun.",
                    "label": 0
                },
                {
                    "sent": "You get to collaborate with lots of colleagues who have different areas of expertise.",
                    "label": 0
                },
                {
                    "sent": "And it's helpful when you sort of expand your horizons and learn more about an area you may not know much about.",
                    "label": 0
                },
                {
                    "sent": "When I started a Google, I didn't know much about machine learning.",
                    "label": 0
                },
                {
                    "sent": "I've been able to work with experts in machine learning and pick up a little bit of tidbits on the side.",
                    "label": 1
                },
                {
                    "sent": "It's fun and the scale of the systems we're building is a lot larger than most other systems that one can work on, and so that's always fun.",
                    "label": 1
                },
                {
                    "sent": "And another nice thing is that I think small teams are able to do pretty significant things that it can be used by.",
                    "label": 1
                },
                {
                    "sent": "For example, hundreds of millions of people.",
                    "label": 0
                },
                {
                    "sent": "And that's a true testament to the power of software.",
                    "label": 0
                },
                {
                    "sent": "That's why I love this field because you work can be used by lots of people.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so when you're building a retrieval system, there are lots of different parameters that you might need to consider.",
                    "label": 0
                },
                {
                    "sent": "For example, you might have some target of number of documents.",
                    "label": 1
                },
                {
                    "sent": "Want to index in your system, and maybe you have some target goal of number of queries per second that your system needs to be able to handle.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to update documents at some rate.",
                    "label": 0
                },
                {
                    "sent": "You know maybe you'd like to update 10 documents, the second maybe you'd like to be able to update a billion documents per night.",
                    "label": 0
                },
                {
                    "sent": "Those sorts of things you'd like to respond quickly to users.",
                    "label": 0
                },
                {
                    "sent": "You need a certain amount of information to be kept about every document in your index or other data structures that you're going to be using for running retrieval algorithms.",
                    "label": 0
                },
                {
                    "sent": "And then you have some.",
                    "label": 0
                },
                {
                    "sent": "Either simple or fairly complicated retrieval algorithms, you're going to be trying to run on this system.",
                    "label": 1
                },
                {
                    "sent": "An all of these factors in parameters contribute to sort of the difficulty of the engineering task that you face to it.",
                    "label": 0
                },
                {
                    "sent": "If you have small values and all the dimensions, it's not that challenging if you have very large values and all the dimensions that increases the engineering challenge significantly.",
                    "label": 0
                },
                {
                    "sent": "And it's kind of equivalent to the product of these things.",
                    "label": 1
                },
                {
                    "sent": "It's easy to have a very large index that you never update.",
                    "label": 0
                },
                {
                    "sent": "It's harder to have a large index that you update all the time.",
                    "label": 0
                },
                {
                    "sent": "And these all affect both performance of the system and what you really care about as an engineer is performance per unit hardware cost or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just to give you a sense of the scaling of these parameters since I've been at Google I joined in mid 99.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give you a rough sense of how these parameters are scaled so when I joined we had an index of perhaps few 10s of millions of documents and today we have many.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you know that's 100 X queries processed per day.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1000 X product.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is kind of a rough measure, but we're basically keeping a lot more information per document that we can use to do ranking than we did 10 years ago.",
                    "label": 0
                },
                {
                    "sent": "An R update latency.",
                    "label": 0
                },
                {
                    "sent": "This is kind of surprising to me.",
                    "label": 0
                },
                {
                    "sent": "When I made this slide.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's actually gotten better by a factor of about 10,000.",
                    "label": 0
                },
                {
                    "sent": "We have some pages that we update in our index within a minute or two, and it used to be.",
                    "label": 0
                },
                {
                    "sent": "We would kind of push out a batch update of our whole index once every month or two.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "While all these parameters have been changing, we've been able to drop the average query latency.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "American.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, we've been.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Help out a little bit by Moores Law.",
                    "label": 0
                },
                {
                    "sent": "An by larger capital budget these days, but you notice that.",
                    "label": 0
                },
                {
                    "sent": "The improvement in hardware resources has not really kept up with the changes in all those parameters.",
                    "label": 0
                },
                {
                    "sent": "So that's just to give you a sense of the rough scale.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the other thing I think is illustrated by the previous slide is that all these parameters change constantly.",
                    "label": 1
                },
                {
                    "sent": "Overtime you're always getting more queries per month than you did last month.",
                    "label": 0
                },
                {
                    "sent": "You're always wanting to index more documents than you did yesterday.",
                    "label": 0
                },
                {
                    "sent": "And the important point to make is that the right design at a given design at a given value.",
                    "label": 1
                },
                {
                    "sent": "Might might be the wrong design, very wrong when that parameter scales by factor of 10 or 100.",
                    "label": 0
                },
                {
                    "sent": "So a good rule of thumb I like to use is that whenever you're designing a system, you want to think about what would happen if that parameter scaled by a factor of, say up to 10, but beyond that it's really difficult to sort of have the same system work for X100X.",
                    "label": 0
                },
                {
                    "sent": "At that point, you're probably going to need to sort of redo significant pieces of the system to deal with 100X more queries or hundred X more documents that you're indexing because the same.",
                    "label": 0
                },
                {
                    "sent": "Designs may not make sense anymore.",
                    "label": 0
                },
                {
                    "sent": "The other cool thing about web search or search in general is that you can sort of replace the entire back end serving system without users really noticing.",
                    "label": 0
                },
                {
                    "sent": "And we've done this many, many times over the last 10 years or so.",
                    "label": 1
                },
                {
                    "sent": "You can sort of devote a new data center or convert 1 existing data center to a completely new serving system, run some fraction of user traffic through that for awhile an once.",
                    "label": 0
                },
                {
                    "sent": "It seems to be stable.",
                    "label": 0
                },
                {
                    "sent": "Then you convert over all the other ones and users depending on how visible the changes are that you're making in the retrieval system, you know sometimes it just seems faster to users.",
                    "label": 0
                },
                {
                    "sent": "Sometimes that just has a larger index, but other than that it looks pretty much the same with the same user interface.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of nice.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It also allows you to rollback if something goes badly.",
                    "label": 0
                },
                {
                    "sent": "Just kind of.",
                    "label": 0
                },
                {
                    "sent": "So in the rest of the talk I'm going to, I'm going to give you sort of a sense of some of the evolution of our searching systems.",
                    "label": 0
                },
                {
                    "sent": "Sort of the internal details of it's going to be focused more on the system design as opposed to the ranking algorithms.",
                    "label": 0
                },
                {
                    "sent": "I'll give you a brief description of some of the supporting infrastructure that we've already published papers about.",
                    "label": 1
                },
                {
                    "sent": "Just to give you a sense of the tools that we use to build some of these retrieval systems.",
                    "label": 0
                },
                {
                    "sent": "Obviously, anything that covers something of this scope is joint work with many, many people there.",
                    "label": 1
                },
                {
                    "sent": "I started to try to put a slide together, but it's way too many people to put on the slide, but there are numerous people involved in this effort, and then I'll give you some thoughts about interesting directions and challenges in.",
                    "label": 0
                },
                {
                    "sent": "What I see sort of the next few years.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so as many of you probably know, Google started as a research project at Stanford when our founders were grad students there.",
                    "label": 0
                },
                {
                    "sent": "They I guess their advisors were mean and wicked and wouldn't really give them computing hardware, so they actually had to go beg and scrounge computing hardware from other research groups.",
                    "label": 0
                },
                {
                    "sent": "They would sneak down to the loading dock and intercept the shipments of computers that other research groups had ordered and volunteered to set them up, and then they would kind of keep the machines for a little longer than they really needed.",
                    "label": 0
                },
                {
                    "sent": "Of off the float of other research projects arriving hardware.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the origins of Google.",
                    "label": 0
                },
                {
                    "sent": "Is it always started out as a whole bunch of machines, kind of connected together by networks?",
                    "label": 0
                },
                {
                    "sent": "But one problem with this approach is that you end up with a variety of different computer architectures.",
                    "label": 0
                },
                {
                    "sent": "It's not really so pleasant to deal with five different CPU types in that environment, so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We've standardized on less than that, but the original research project had one.",
                    "label": 0
                },
                {
                    "sent": "Well, one of the things that it did was it decided they knew that the system they wanted to build was going to be building indices that are way too large for a single machine, and so they started off partitioning both the index and the other aspects of the system across multiple machines.",
                    "label": 0
                },
                {
                    "sent": "And this is obviously something we continue to do today.",
                    "label": 0
                },
                {
                    "sent": "Do today.",
                    "label": 0
                },
                {
                    "sent": "The that's basically the simple architecture of the research project.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me talk a little bit about partitioning.",
                    "label": 0
                },
                {
                    "sent": "So in indexing system there are two main ways that you can imagine partitioning index data.",
                    "label": 0
                },
                {
                    "sent": "The first is by document where you essentially chopped.",
                    "label": 0
                },
                {
                    "sent": "The documents are going to index into a bunch of buckets, the.",
                    "label": 0
                },
                {
                    "sent": "And each of the buckets is going to have all the information for some of the documents, so that's nice because each Shard basically has all the information for some of the documents and can process queries independently, suddenly queried all the different shards they send the results back.",
                    "label": 1
                },
                {
                    "sent": "An then you merge.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is that the network traffic in this approach is fairly small, so you send the query down to each of the shards, query.",
                    "label": 0
                },
                {
                    "sent": "It's pretty small, they do a lot of computation over a lot of local data stored on disk, but then the data they send back over the network is also fairly small.",
                    "label": 0
                },
                {
                    "sent": "It's sort of a collection of documents and score pairs.",
                    "label": 0
                },
                {
                    "sent": "A drawback of this approach though, is that you often end up doing order K * N. This seeks where you have a keyword query that you're sending to end different shards, so as sharding in your system as your index scales anyer sharding gets larger.",
                    "label": 0
                },
                {
                    "sent": "You start to do more and more disks in this approach.",
                    "label": 0
                },
                {
                    "sent": "Another drawback is that the query basically has to be processed by each of the shards.",
                    "label": 1
                },
                {
                    "sent": "That's why the end term exists in that in that.",
                    "label": 0
                },
                {
                    "sent": "And it's worth saying if you drop one of the shards then you're likely going to be dropping good documents, especially if the number of shards is not too large.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other approach that you could do is you could charge your index by word, where you essentially build inverted indices and then you give some of the words to one machine.",
                    "label": 0
                },
                {
                    "sent": "Some of the other words to another machine to another partition, an then has the nice property that a keyword query is handled by at most K different shards.",
                    "label": 1
                },
                {
                    "sent": "You do only order Kata seeks for keyword query.",
                    "label": 0
                },
                {
                    "sent": "The drawback is that you're ending up with the information about each document spread across many different machines.",
                    "label": 1
                },
                {
                    "sent": "And that you need much higher network bandwidth across.",
                    "label": 0
                },
                {
                    "sent": "Because you're streaming, posting less data from one machine to another, and it's also harder.",
                    "label": 0
                },
                {
                    "sent": "There's not an obvious place to have per document information.",
                    "label": 0
                },
                {
                    "sent": "You might want other information like page rank or the language of the document.",
                    "label": 0
                },
                {
                    "sent": "Other kinds of things that you want to use during ranking doesn't have an obvious home.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our computing environment where network bandwidth is a fairly scarce resource, we end up partitioning by document, and that's what makes more sense.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trust.",
                    "label": 0
                },
                {
                    "sent": "OK, so the basic principles in most indexing systems are going to assign small integer identifiers to a document.",
                    "label": 1
                },
                {
                    "sent": "It's good if you can order the assignment of identifiers to have smaller numbers have been more important or better quality documents in some sense that allows you to stop early.",
                    "label": 0
                },
                {
                    "sent": "So if you retrieve a million results and you haven't hit the end of the index yet, you can stop and be assured that you are going to score the million most important documents or highest quality ones.",
                    "label": 0
                },
                {
                    "sent": "The interface training server is given a query return a list of score, score and document pairs.",
                    "label": 1
                },
                {
                    "sent": "In our case there Charter document the cost of the index serving system which basically returns scores and document ID identifiers is order number of queries times number of documents in your index.",
                    "label": 0
                },
                {
                    "sent": "And then the doc servers.",
                    "label": 0
                },
                {
                    "sent": "One of the things that the original research project did that most other search engines of that time were not doing, is returning query specific snippets.",
                    "label": 0
                },
                {
                    "sent": "So when you show a summary on the result page, the original Google prototype would show the title of the document and then some sampling of word of sentence is from the document that were in the context of your query as opposed to a lot of other search engines which at the time would show just the 1st 20 words the document.",
                    "label": 0
                },
                {
                    "sent": "And that's actually a very important.",
                    "label": 0
                },
                {
                    "sent": "Thing for improving sort of the usability of your search engine is to show query specific snippets 'cause users can scan a list of results and get a much better sense of whether that document is relevant to their query or not without actually having to click through to the document.",
                    "label": 0
                },
                {
                    "sent": "Well, but it's worth saying that the doc serving system that generates the title and snippets is only going to be order number of queries, not order another queries times the number of documents in the index.",
                    "label": 0
                },
                {
                    "sent": "So as your index gets larger, the cost of the index serving portion dominates and so we don't focus very much at all on the performance of the dock servers other than trying to reach their latency.",
                    "label": 0
                },
                {
                    "sent": "Almost all the performance implications in the system are in the index serving system and the ranking system.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we knew when the company was started that we wanted to ride the commodity computing wave where cheap cheap commodity hardware was the way to go so that you could have larger indices you could afford to devote more computational resources to each query and so on.",
                    "label": 0
                },
                {
                    "sent": "So we push this a bit to the extreme in the early days where.",
                    "label": 0
                },
                {
                    "sent": "Now we've actually decided we didn't need all these fancy computer cases and it be better if we could, you know, share power supply between 4 machines so that we didn't have to pay for for power supplies.",
                    "label": 0
                },
                {
                    "sent": "And we would buy our own components and assemble them ourselves.",
                    "label": 0
                },
                {
                    "sent": "And so this is our first attempt that involved there's a cookie tray there an on top of that cookie Tray is 4 motherboards with a thin layer of Cork to protect the cookie tray from the motherboards there affectionately known as Cork board.",
                    "label": 0
                },
                {
                    "sent": "And there's, you know, you can see four reset switches in the front.",
                    "label": 0
                },
                {
                    "sent": "Anna shared power supply.",
                    "label": 0
                },
                {
                    "sent": "Turns out, sharing a power supply between more for machines is not really that great an idea.",
                    "label": 0
                },
                {
                    "sent": "We have dispensed with that idea.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nor is Cork a good idea.",
                    "label": 0
                },
                {
                    "sent": "So the serving system in 99 look pretty much.",
                    "label": 1
                },
                {
                    "sent": "Like the original research prototype with a few additions, one is, it was replicated more so each of the index shards in each of the dockyards had multiple replicas and on different machines to have capacity we added an ad system that was actually the first thing I worked on at Google is to build our initial ad system.",
                    "label": 1
                },
                {
                    "sent": "And we added caching to cache common query results.",
                    "label": 0
                },
                {
                    "sent": "So let me.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk a bit about caching.",
                    "label": 0
                },
                {
                    "sent": "Cache servers are really important pieces of a retrieval system, especially if you want to boost if you have large query volumes or you want low latency, or both.",
                    "label": 0
                },
                {
                    "sent": "We use them to cash both the index results and the snippets.",
                    "label": 1
                },
                {
                    "sent": "Mute get hit rates of on the order of 30 to 60%.",
                    "label": 0
                },
                {
                    "sent": "It's not like CPU caches.",
                    "label": 1
                },
                {
                    "sent": "We're getting 99%, but a lot of that hit rate depends a lot on how frequently updating the index the mix of query traffic you know is it all in different languages?",
                    "label": 0
                },
                {
                    "sent": "Or is it mostly in small number of languages?",
                    "label": 0
                },
                {
                    "sent": "How much personalization are you doing?",
                    "label": 0
                },
                {
                    "sent": "What are the key?",
                    "label": 0
                },
                {
                    "sent": "If the cache key has to include?",
                    "label": 0
                },
                {
                    "sent": "Aspects of information you're using in order to do personalization, then that sort of takes what would be one simple queries results and spreads them over all the different kinds of things you're using to do personalization.",
                    "label": 1
                },
                {
                    "sent": "But the main benefits are performance, so you have perhaps 10s of machines that are doing half the work of your retrieval system and the other half is being done by hundreds or thousands of machines, so it's definitely a good deal.",
                    "label": 0
                },
                {
                    "sent": "You should have cashing in there.",
                    "label": 0
                },
                {
                    "sent": "It also is really nice because it gives you reduced query latency, time for cash aid is much lower than the time for.",
                    "label": 0
                },
                {
                    "sent": "To actually go out to all the index servers, do ranking retrieval and return results an, it also tends to be the queries that hit in the cache tend to be the more expensive queries.",
                    "label": 1
                },
                {
                    "sent": "They tend to be ones with more popular words in them or.",
                    "label": 1
                },
                {
                    "sent": "Popular phrases that are expensive and they have a lot of documents to score so.",
                    "label": 0
                },
                {
                    "sent": "Even more than just cash it right, but the cost of the queries that hit my cash is larger than just the cash rate.",
                    "label": 0
                },
                {
                    "sent": "What are the things to be aware of when you introduce caching into the system?",
                    "label": 0
                },
                {
                    "sent": "Is that you can get big latency spikes or capacity hits when the cache is flushed, for example, or when you switch over index data to sort of the cash no longer applies and you end up getting a lot of cache misses.",
                    "label": 0
                },
                {
                    "sent": "Essentially all your cache hit rate will drop to zero and then start to work its way steadily back up, but in the moment it drops after it drops to zero.",
                    "label": 0
                },
                {
                    "sent": "You can have kind of operational disasters so you have to be kind of aware of that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the crawling system around you know 98 to 99 was a fairly simple batch oriented crawling system.",
                    "label": 0
                },
                {
                    "sent": "The idea is you start with fewer URLs.",
                    "label": 1
                },
                {
                    "sent": "Actually it turns out you need remarkably few seed URLs because most things can be reached from just a few places.",
                    "label": 1
                },
                {
                    "sent": "You crawl some pages, you extract links from those pages you Adam to a queue, an you stop when you have decided that you've hit your budget of whatever, you can index.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of concerns in building and crawling system.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to.",
                    "label": 0
                },
                {
                    "sent": "Focus on them too much, but you need to not hit any site too hard.",
                    "label": 1
                },
                {
                    "sent": "You need to prioritize among the uncalled pages so that if you have fetch bandwidth available, you fetch something that you think is more useful than a random page.",
                    "label": 0
                },
                {
                    "sent": "You need some way of maintaining the sun crawled URL Q and efficiently, because you're for every page you crawl you're extracting.",
                    "label": 0
                },
                {
                    "sent": "You know perhaps 20 links and having to insert them into the queue.",
                    "label": 0
                },
                {
                    "sent": "And you don't want to seek for each one of those, and you have to have some way of dealing with machine failures in the crawling system.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The indexing system in those days was a fairly simple batch indexing system.",
                    "label": 1
                },
                {
                    "sent": "It was based on fairly simple tools.",
                    "label": 1
                },
                {
                    "sent": "There wasn't really any checkpointing, so machine failures were pretty painful in those days.",
                    "label": 0
                },
                {
                    "sent": "They not only did our early machines not have ECC memory, they didn't have parity, which is very painful if you're trying to actually use them.",
                    "label": 0
                },
                {
                    "sent": "In particular, if you sort a TB of data on a machine without parity, it ends up mostly sorted.",
                    "label": 1
                },
                {
                    "sent": "If you started again, that's mostly sorted some other way.",
                    "label": 1
                },
                {
                    "sent": "One of my colleagues liken this to programming with adversarial memory.",
                    "label": 1
                },
                {
                    "sent": "And so one of the early things we did to help insulate us from the adversarial memory was we developed a little file system abstraction that had the ability to write records, and it would check some of them and insert sort of re synchronization markers in there, so that if you.",
                    "label": 0
                },
                {
                    "sent": "It would insert checksums in the records.",
                    "label": 0
                },
                {
                    "sent": "We could know if it was corrupted and you could also then re synchronize to the next valid record with the re synchronization markers.",
                    "label": 0
                },
                {
                    "sent": "And ignore the corrupted records and.",
                    "label": 0
                },
                {
                    "sent": "One of the nice things about web searches.",
                    "label": 0
                },
                {
                    "sent": "There's enough data and redundancy in the world that if you drop a document here or there due to corruption, it's not that big a deal.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Generally, unless it's something really important.",
                    "label": 0
                },
                {
                    "sent": "So index updates.",
                    "label": 0
                },
                {
                    "sent": "In those days the basics.",
                    "label": 0
                },
                {
                    "sent": "Well, they happened infrequently, thank goodness because they were a lot of work, they happen about once per month, so you basically wait until traffic flow.",
                    "label": 1
                },
                {
                    "sent": "You take some of your replicas offline.",
                    "label": 0
                },
                {
                    "sent": "You'd copy the new index these replicas, and then you'd start new front ends pointing at these replicas.",
                    "label": 1
                },
                {
                    "sent": "An service in traffic from there, and you gradually migrate more and more of your machines to serving the, you know April index instead of the Mark Fund.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the things that's important in a disk based index is you want to use the outer part of the disk 'cause it's faster, so the index switchover process is actually a little bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "You'd start with the current index on disk.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you would switch over to the new index by copying it to the.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Free half of the death.",
                    "label": 0
                },
                {
                    "sent": "Then you wipe the olden day.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you copy the new index back to the faster half of the disk.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you delete the old, the original first copy.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then that would actually free up some disk space that you could use for building various performance.",
                    "label": 0
                },
                {
                    "sent": "Improving data structures in the middle.",
                    "label": 0
                },
                {
                    "sent": "One of the things we built was something we called the pear cache, which is basically if you look at commonly Co occurring query terms we would offline precompute pre intersected pairs of posting lists for these commonly Co occurring terms.",
                    "label": 1
                },
                {
                    "sent": "They don't have to be phrased terms, they just have to be terms that occur frequently in queries together.",
                    "label": 0
                },
                {
                    "sent": "So we're not building a phrase index, it's just you know, Barcelona and restaurants occur in the same.",
                    "label": 0
                },
                {
                    "sent": "Documents.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So by 2000 we refined our hardware design a bit.",
                    "label": 0
                },
                {
                    "sent": "We had decided cases were OK again.",
                    "label": 0
                },
                {
                    "sent": "We managed to get all the connectors on the fronts of the computers, which is good.",
                    "label": 0
                },
                {
                    "sent": "It was quite painful to reach around the back of the old Cork boards to install Ethernet cables and we were still not owning our own data centers.",
                    "label": 0
                },
                {
                    "sent": "We were leasing space in hosting facilities and they charge by the square foot which was an excellent deal for us.",
                    "label": 0
                },
                {
                    "sent": "So we would try to pack as many computers as we possibly could and uses them much electricity as we possibly could into the number of square foot square feet they would license us.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Grad thank sometimes needed a little extra help with air cooling that we would purchase fans for them.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a consequence, we also got fairly good at moving out of bankrupt datacenters and moving into new ones.",
                    "label": 0
                },
                {
                    "sent": "And so the nice thing is.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not actually too hard to move into a new data center.",
                    "label": 0
                },
                {
                    "sent": "You have all the racks all cabled up already, and then you basically have to wheel in the racks and then connect together all the rack switches to a central router and you're ready to go.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the period of 99 to 2001 roughly we were simultaneously having huge traffic increases, an huge increases in index size, so our index size when I'm roughly by factor 20 and at the same time as we were having roughly ten 1520% growth per month in query traffic.",
                    "label": 1
                },
                {
                    "sent": "And we're also out signing deals.",
                    "label": 0
                },
                {
                    "sent": "So for example, we signed a search deal with Yahoo to provide their search service.",
                    "label": 0
                },
                {
                    "sent": "And that doubled our traffic overnight at the same time we were actually doubling our index size in the previous few days.",
                    "label": 0
                },
                {
                    "sent": "This is quite exciting.",
                    "label": 0
                },
                {
                    "sent": "And the performance of the index serving system is what is really important in these cases.",
                    "label": 0
                },
                {
                    "sent": "And when you're dealing with this sort of thing, we are continuously buying more and more hardware and leasing more and more data center space.",
                    "label": 0
                },
                {
                    "sent": "But we basically needed 10 to 30% software improvements every month in order to sort of squeak by in our capacity.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we would end up in a bad state.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the nice thing about this basic.",
                    "label": 0
                },
                {
                    "sent": "Structure I've now moved the dock service off to the side 'cause they're not very interesting from a performance standpoint.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is that it's fairly easy to add capacity.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can grow your index by adding more index shards and.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you can.",
                    "label": 0
                },
                {
                    "sent": "Add more replicas to add.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Capacity an if you're growing your next lot you.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add more image Shard and more.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dick shards andmore replicas for capacity.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An order charge and eventually end up with a lot of machines and a lot of shards and a lot of replicas, but it's a fairly.",
                    "label": 0
                },
                {
                    "sent": "Reasonable process to do that, as you do, you don't try to do this in the middle of index.",
                    "label": 0
                },
                {
                    "sent": "You sort of say OK and then the next months index we're going to do 17 yards instead of 10 or something.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So one of the things one of the reasons you have to keep adding shards as you increase your index sizes that you want to have query response times be reasonably low and if you make your shards too large then well they they might not fit on the local disks of your machines or be your response time or get too large and so you need to sort of increase the number of shards in linearly as you're increasing your index size.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It's also possible to get pretty big performance improvements, which we did by writing our own discuss scheduling system that was sort of aware of what queries were pending on the particular server, and prioritizing reads in a reasonable way.",
                    "label": 1
                },
                {
                    "sent": "We also focused a fair amount on improving our indexing coding, which is what I'm going to talk about now.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the original encoding done as part of the prototype at Stanford was pretty simple.",
                    "label": 0
                },
                {
                    "sent": "It was actually a fairly simple byte aligned format.",
                    "label": 1
                },
                {
                    "sent": "Basically you'd have document identifier plus the number of hits encoded in 32 bits, 5 bits for the number of hits, and then 27 bits for the doc ID and many guys 16 bits for each word occurrence for each occurrence of that particular word that encoded both the position of the word as a sequence number within the document.",
                    "label": 0
                },
                {
                    "sent": "And some a few bits for attributes of the word like was it a in the title?",
                    "label": 0
                },
                {
                    "sent": "Was it in a big font or little font?",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And for very long posting lists, you eventually want to add skip tables into the data structure so that if you have the word of or something, you have a table on the side that tells you.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, doc ID million is at offset.",
                    "label": 0
                },
                {
                    "sent": "Two 2 billion in your posting list.",
                    "label": 0
                },
                {
                    "sent": "The byte Align format was pretty simple to decode, but it's not very compact and it actually required lots of disk bandwidth, so we worked for Fairmount on our encoding data.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pictures.",
                    "label": 0
                },
                {
                    "sent": "And I'll give you a brief background on various encoding techniques because they'll be useful to understand the encoding format we used.",
                    "label": 0
                },
                {
                    "sent": "Basically, there's several different bit level encodings you can imagine using, which are going to be slower than byte level encodings, but little things are things like unary encoding where you encode the number, and you just have an ones followed by zero gamma where you're going to code some prefix in unary that indicates the length of the number, and then that number of bits rice, which is a special form of Golomb codes.",
                    "label": 1
                },
                {
                    "sent": "Where you you basically have a number an you have a base that you're going to do that number in, and it writes codes.",
                    "label": 0
                },
                {
                    "sent": "The base is always going to be power of two.",
                    "label": 0
                },
                {
                    "sent": "So for example, you encode.",
                    "label": 0
                },
                {
                    "sent": "N divided by, let's say our base is 3, then you're going to encode end divided by two to the third in unary and then an MoD.",
                    "label": 0
                },
                {
                    "sent": "Eight and three bits.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is everything so?",
                    "label": 0
                },
                {
                    "sent": "The format we used for awhile was basically a block based index format, so the nice property.",
                    "label": 0
                },
                {
                    "sent": "This had it so word is going to have a skip table and then it's going to have a sequence of blocks.",
                    "label": 0
                },
                {
                    "sent": "The Skip Table is optional, only occurs for a small number of words that are very large.",
                    "label": 0
                },
                {
                    "sent": "That have a lot of data.",
                    "label": 0
                },
                {
                    "sent": "So the nice property of this.",
                    "label": 0
                },
                {
                    "sent": "Of the format is that there is a byte aligned header that has two important pieces of information.",
                    "label": 0
                },
                {
                    "sent": "First is the Delta from your current doc ID in the posting list to the last doc ID in this block.",
                    "label": 0
                },
                {
                    "sent": "Ann, this second thing is the block length in bytes, so you can look at that Delta to the last docket in the block.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to go to.",
                    "label": 0
                },
                {
                    "sent": "If you're at Doc idea thousand, you're trying to go to Doc ID 10,000 and that Delta says the last block has a Delta of 2000, then you know that this block is not of interest to you because it would only take you to 3000, so you can just read that header completely, skip over the rest of the data in the block, and I'll figure out if indeed you need to put peek inside this block because.",
                    "label": 0
                },
                {
                    "sent": "You think you're interested in something in the range of docket is covered by the block.",
                    "label": 0
                },
                {
                    "sent": "Then there's a few bit level encoded things that tell you the encoding type of the rest of the data in the block tells you the number of documents in the block, and then we have a bunch of doc ID deltas for the individual documents that are encoded in this block.",
                    "label": 0
                },
                {
                    "sent": "So the block is going to have N documents and then H hits.",
                    "label": 1
                },
                {
                    "sent": "And then we have N values.",
                    "label": 0
                },
                {
                    "sent": "So per document how many hits, how many occurrences of the word were there per document?",
                    "label": 0
                },
                {
                    "sent": "That's the next piece of information.",
                    "label": 0
                },
                {
                    "sent": "There's any of those values, and there's going to be H hit attributes.",
                    "label": 0
                },
                {
                    "sent": "Which tell you things like the font size and things like that, and then the actual positions.",
                    "label": 0
                },
                {
                    "sent": "So notice that.",
                    "label": 0
                },
                {
                    "sent": "This is an incrementally decodable format, so that if you only care about getting the doc IDs, you can decode just up to the doc ID Delta portion of this, and then you might say, Gee, there's no.",
                    "label": 0
                },
                {
                    "sent": "I'm doing and query it.",
                    "label": 0
                },
                {
                    "sent": "Turns out you know I thought there might be matches in these two blocks for the two different words, but it turns out that you know Doc 8017 didn't occur in both of them, so that I can skip all the rest of it.",
                    "label": 0
                },
                {
                    "sent": "I don't spend anytime decoding the hit positions with the attributes or anything like that.",
                    "label": 0
                },
                {
                    "sent": "If what I care about.",
                    "label": 0
                },
                {
                    "sent": "Eventually you may need to decode all this for documents that you score, but that's a fairly tiny fraction of all the documents that you're examining during retrieval.",
                    "label": 0
                },
                {
                    "sent": "While all the posting list your traversing during retrieval.",
                    "label": 0
                },
                {
                    "sent": "So this actually reduced our index size by about 30%, plus it was actually a lot faster decode than the simple byte aligned format.",
                    "label": 1
                },
                {
                    "sent": "'cause you can often skip, you know 50 documents at a time just by looking at that byte aligned header.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the implications of this ever increasing index size and thus more shards is that query cost is increasing all the time because as you increase the number of shards you're going to do, typically a disk per Shard per query term, and so as you add more and more shards, even for very rare terms, you're going to seek on each of the of the.",
                    "label": 1
                },
                {
                    "sent": "Charge an one of the nice things that happens is the add more replicas for capacity.",
                    "label": 1
                },
                {
                    "sent": "Your total amount of memory in your whole serving system increases an.",
                    "label": 0
                },
                {
                    "sent": "Eventually, you squinted this and you say, Gee, maybe I could use all that memory for caching, and so you try to come up with complicated ways of caching commonly used posting lists and then G. You kind of squint problem you're like, Gee, you know I could hold the whole one copy of the whole index in memory across all these machines.",
                    "label": 0
                },
                {
                    "sent": "Course then it only have one copy of it, but that would be cool and that actually changes a lot about how you think about water.",
                    "label": 0
                },
                {
                    "sent": "Expensive things in your retrieval system.",
                    "label": 0
                },
                {
                    "sent": "Water cheap things.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in early 2001 we rolled out our first in memory index, so we were holding the entire index of all the data in memory.",
                    "label": 0
                },
                {
                    "sent": "We changed things a bit so we took all the machines that were dedicated to replicas.",
                    "label": 0
                },
                {
                    "sent": "In any chart, an instead of them being replicas, they each served a different piece of the Shard in memory.",
                    "label": 0
                },
                {
                    "sent": "So we have these things called micro Shards.",
                    "label": 0
                },
                {
                    "sent": "We kind of chop an existing Shard up into a bunch of little pieces.",
                    "label": 0
                },
                {
                    "sent": "The query now needed to go to many more machines, so rather than going to you know 50 or 60 shards that we need to go to maybe 1000 machines.",
                    "label": 0
                },
                {
                    "sent": "And so we introduced another intermediate level of server called Balancers, that would take a query from the web server and then direct the request to all the different shards.",
                    "label": 0
                },
                {
                    "sent": "I didn't draw the arrows, but it's actually going to all the different machines in that Shard.",
                    "label": 0
                },
                {
                    "sent": "And the balancer is also responsible for sort of coordinating, loading and unloading of these micro shards across all the different in memory servers.",
                    "label": 0
                },
                {
                    "sent": "To do both load balancing and when one of the machines fails, it would kind of deal with recovery of that unfortunate event.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The two main benefits of this in memory index are that you get a big increase in throughput.",
                    "label": 1
                },
                {
                    "sent": "Anna big consequent, big increase in performance per dollar.",
                    "label": 1
                },
                {
                    "sent": "You also get a huge decrease in latency, especially towards the tail of your latency curve.",
                    "label": 1
                },
                {
                    "sent": "So queries that used to take a really long time well.",
                    "label": 0
                },
                {
                    "sent": "Here's one example is circle of life as a phrase query.",
                    "label": 0
                },
                {
                    "sent": "So this is a very expensive query in a disk based index system, because each of those words is relatively common.",
                    "label": 1
                },
                {
                    "sent": "But that phrase occurs extremely rarely on the web, and so this query in our old disk based index system would take many many seconds and have many gigabytes of IO, and it would be very expensive in an in memory index system.",
                    "label": 0
                },
                {
                    "sent": "It's much faster because you end up well, basically because the Sikhs are 10,000 times faster.",
                    "label": 0
                },
                {
                    "sent": "Now there are some issues that you have to solve.",
                    "label": 0
                },
                {
                    "sent": "If you have an in memory index system, one of them is that because you're touching many more machines on every query, then you were with a disk based system.",
                    "label": 0
                },
                {
                    "sent": "You end up with a lot of variance and that variance can really kill your latency because you essentially need to wait for all the results to come back before you return from.",
                    "label": 0
                },
                {
                    "sent": "The query before you return results to the user.",
                    "label": 0
                },
                {
                    "sent": "We had issues with.",
                    "label": 0
                },
                {
                    "sent": "For example, someone had in our operations group.",
                    "label": 0
                },
                {
                    "sent": "We wanted to do something every five minutes.",
                    "label": 0
                },
                {
                    "sent": "And so rather than straightforward, Cron job that every five minutes would wake up on all the machines and do something it was thought that it would be a bad idea to have them all doing it at the same time.",
                    "label": 0
                },
                {
                    "sent": "So instead we would randomize the time that each machine would do.",
                    "label": 0
                },
                {
                    "sent": "It's kind of five minute activities across the five minute interval.",
                    "label": 0
                },
                {
                    "sent": "The unfortunate thing about that is, in an in memory index system where your query is actually touching most of the machines in your data center, it's actually a bad idea to randomize the time.",
                    "label": 0
                },
                {
                    "sent": "You'd rather kind of have it be done all at once so that you hurt the latency of a few queries.",
                    "label": 0
                },
                {
                    "sent": "A lot rather than hurting the latency of all queries, little bit, and the reason it hurts all queries a little bit is at any given time, at least one of these machines is doing this random Cron job and so is running some sort of background activity that is slowing down.",
                    "label": 0
                },
                {
                    "sent": "The other thing that hurts is that gets hurt by an in memory system is availability because you have many fewer replicas, typically just one replica in each data center of that documents of a particular documents index data.",
                    "label": 0
                },
                {
                    "sent": "There are two problems.",
                    "label": 0
                },
                {
                    "sent": "One is we occasionally have bugs in our query serving system that cause a back end to die when it receives the query.",
                    "label": 0
                },
                {
                    "sent": "You know, maybe it's not even dependent on the particular index data that machine has it.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's just a bug in the query parsing code, something like that those are not good in any system, but they're especially bad in an in memory index system where you have a query of depth you end up killing 1000 machines instead of dictating.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So those aren't your kids.",
                    "label": 0
                },
                {
                    "sent": "You have to figure out some scheme that allows you to insulate or inoculate yourselves from the effect of queries of death.",
                    "label": 0
                },
                {
                    "sent": "The other thing that is bad is when a machine fails.",
                    "label": 1
                },
                {
                    "sent": "They you end up having a period where the data that machine was serving is completely unavailable, you don't have any copies of that index data and that data center.",
                    "label": 0
                },
                {
                    "sent": "So for very important documents we ended up replicating them in multiple different shards an so that we would be insulated to single machine failures and still have CNN's homepage.",
                    "label": 0
                },
                {
                    "sent": "For example, when machine went down.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so overtime we've decided that it was better to build our own data center facilities.",
                    "label": 0
                },
                {
                    "sent": "This is a picture of our data center and the dals Oregon near a big hydroelectric dam, and so this is just to give you a sense of the kinds of facilities we're building.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Day.",
                    "label": 0
                },
                {
                    "sent": "If you look inside it still we're back to no cases.",
                    "label": 0
                },
                {
                    "sent": "It turns out airflow is better, but they look much cleaner than the Cork boards, don't they?",
                    "label": 0
                },
                {
                    "sent": "So basically the.",
                    "label": 0
                },
                {
                    "sent": "The current machine design is essentially an in-house rack design that provides pretty good airflow.",
                    "label": 1
                },
                {
                    "sent": "Standard PC class motherboards still fairly low end storage and networking hardware.",
                    "label": 1
                },
                {
                    "sent": "They all run Linux plus a bunch of in-house software.",
                    "label": 0
                },
                {
                    "sent": "On top of that.",
                    "label": 0
                },
                {
                    "sent": "Alright, I'll talk about briefly.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In 2004, we rolled out another fairly significant change with sort of a generalization of some of the stuff we learned from our in memory index.",
                    "label": 0
                },
                {
                    "sent": "One of the things that.",
                    "label": 0
                },
                {
                    "sent": "Happened is we sort of generalize the notion of this query distribution tree so that you could have a two level or three level treated which ever made sense depending on what size index you're trying to serve.",
                    "label": 0
                },
                {
                    "sent": "We generalize the notion of balancers so that there was one manager for doing load balancing across the entire cluster.",
                    "label": 0
                },
                {
                    "sent": "There were much cleaned up APIs, so it was possible to basically use this simple.",
                    "label": 0
                },
                {
                    "sent": "Same basic system and plug in your own scoring function.",
                    "label": 0
                },
                {
                    "sent": "If you're for example implementing a different product at Google like book Search, you want to plug in your own book specific scoring functions, but you still want to use sort of the nice infrastructure that the system provides.",
                    "label": 0
                },
                {
                    "sent": "The whole set of API's were designed so that that was pretty easy to do.",
                    "label": 0
                },
                {
                    "sent": "We had by this time it developed a distributed file system that we could depend on.",
                    "label": 0
                },
                {
                    "sent": "An for reliably use.",
                    "label": 0
                },
                {
                    "sent": "So at the bottom level is GFS, which is this sort of cluster level file system where all the index data was actually loaded from the previous systems.",
                    "label": 0
                },
                {
                    "sent": "We would sort of manually SCP data to local disks in the new model.",
                    "label": 0
                },
                {
                    "sent": "GFS is sort of assumed to exist and you can sort of load index data out of that and so on.",
                    "label": 0
                },
                {
                    "sent": "What else is there?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "So again, we rethought our index encoding data structures.",
                    "label": 0
                },
                {
                    "sent": "The block level Index format which we had designed when we were still a disk based index and sort of still continued to use all, be it with smaller blocks in the.",
                    "label": 0
                },
                {
                    "sent": "In the in memory index used the two level scheme.",
                    "label": 0
                },
                {
                    "sent": "Basically we would encode sequences of Doc IDs and then for each document we would encode a sequence of positions and the doc, ID deltas.",
                    "label": 0
                },
                {
                    "sent": "As I said, were encoded with rice encoding, so that's fairly compact bit level encoding.",
                    "label": 1
                },
                {
                    "sent": "It gives you very good compression and the block based format meant that it was pretty.",
                    "label": 0
                },
                {
                    "sent": "Good for.",
                    "label": 0
                },
                {
                    "sent": "It is fairly CPU friendly as well.",
                    "label": 0
                },
                {
                    "sent": "'cause you could often use the block headers to skip things in our new format.",
                    "label": 0
                },
                {
                    "sent": "We use a single flat position space and we have data structures on the side that keep track of these document boundaries.",
                    "label": 1
                },
                {
                    "sent": "So if you have a document with 100 words, that's going to get allocated position zero to 99 and then you have a document with 10 words.",
                    "label": 0
                },
                {
                    "sent": "That's going to get positions 100, two, 109 and you're going to have these other data structures on the side to allow you to keep track of which positions map to which document.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Posting less for each word than are going to be a single flat.",
                    "label": 0
                },
                {
                    "sent": "Position list as opposed to this two level Doc ID and position.",
                    "label": 0
                },
                {
                    "sent": "Pairs it needs to be a compact data structure, so you can't really afford 32 bit values per occurrence, but it needs to be really fast to decode, so that's paramount for your performance.",
                    "label": 1
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it turns out you know you want to use byte aligned encodings and variable length ones for.",
                    "label": 0
                },
                {
                    "sent": "Encoding your your sequence of position deltas.",
                    "label": 0
                },
                {
                    "sent": "You obviously always use deltas from the previous position, not the actual position, 'cause they're much more compact, specially for very frequent words.",
                    "label": 0
                },
                {
                    "sent": "So one encoding that you can imagine using is what I'll call of.",
                    "label": 0
                },
                {
                    "sent": "Our encoding is basically 7 bits of data per byte, plus A tag meant that says.",
                    "label": 1
                },
                {
                    "sent": "Is this the last value in the bite or not?",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have the value one, we're going to use the blue things are going to be tag bits, and so the value one is encoded in those seven bits.",
                    "label": 0
                },
                {
                    "sent": "And zero means that's the last bite in the value.",
                    "label": 0
                },
                {
                    "sent": "15 is encoded.",
                    "label": 0
                },
                {
                    "sent": "Similarly, 511 doesn't fit in.",
                    "label": 0
                },
                {
                    "sent": "It's bigger than two to the 7th, so you need two beds, 2 bytes of data.",
                    "label": 0
                },
                {
                    "sent": "So there's a one in the first byte, indicating that you have to continue on to the next bit to the next byte and get the data from there.",
                    "label": 0
                },
                {
                    "sent": "An hundred thirty 1071 requires 3 bytes in this encoding.",
                    "label": 0
                },
                {
                    "sent": "So the problem with that encoding is that it requires an awful lot of shifting and masking and branching, especially unpredictable branches which are very expensive on modern machines.",
                    "label": 0
                },
                {
                    "sent": "In order to decode.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one thing you might try is to take the length of the value that you're going to code and encode that as the low 2 bits of the.",
                    "label": 1
                },
                {
                    "sent": "Maybe the first bite in the value, so in this case you know we have one and the low 2 bits indicate 00 indicates it's a one byte value and 01 indicates it's a two byte value.",
                    "label": 0
                },
                {
                    "sent": "AN-10 indicates three byte value.",
                    "label": 1
                },
                {
                    "sent": "That's pretty simple, but it's very nice because you have fewer branches.",
                    "label": 0
                },
                {
                    "sent": "You essentially just load a 32 bit value, look at a low two beds, and that tells you a mask value that you can use to shift the rest of the word right by two bits, and then that mask value tells you how many of those bits you should use to decode.",
                    "label": 0
                },
                {
                    "sent": "So there's no branches actually, which is kind of nice.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So an encoding.",
                    "label": 0
                },
                {
                    "sent": "We actually came up with that we're pretty happy with is what I'll call a group varint encoding.",
                    "label": 1
                },
                {
                    "sent": "So the idea is similar to the previous one.",
                    "label": 0
                },
                {
                    "sent": "You're going to encode groups of four values into bundles of five to 17 bytes.",
                    "label": 1
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing you do is you're going to pull out these four 2 bit binary.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Length.",
                    "label": 0
                },
                {
                    "sent": "You know a single byte prefix.",
                    "label": 1
                },
                {
                    "sent": "And that gives you the tags.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you're going to encode the actual values just as either 123 or 4 bytes.",
                    "label": 0
                },
                {
                    "sent": "So that's actually pretty nice.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit less compact than the 30 bit, and like the two bit embedded in the byte encoding, 'cause you'll use an extra byte up to 20% less compact.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But to decode this, this is pretty fast.",
                    "label": 0
                },
                {
                    "sent": "So you load the prefix byte.",
                    "label": 1
                },
                {
                    "sent": "That's the blue one and you use the value to look up a entry at 200 and 5600.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that tells you 2 pieces of information.",
                    "label": 0
                },
                {
                    "sent": "First, it tells you the byte offsets of all the different values in the bundle.",
                    "label": 0
                },
                {
                    "sent": "And it also gives you the masks to use to decode.",
                    "label": 0
                },
                {
                    "sent": "The values.",
                    "label": 0
                },
                {
                    "sent": "So by doing a single byte load a single table look up, you now have all the information need you need to decode all the numbers in that bundle.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, the data dependence chain in decoding those numbers is very short.",
                    "label": 0
                },
                {
                    "sent": "It's all basically that single byte load plus the table look up and then you have all the information that the machine needs to be to have lots of instruction level parallelism and decoding that, whereas in the previous approach you needed to code 2 bits.",
                    "label": 0
                },
                {
                    "sent": "Do some step masking and shifting and go to the next number.",
                    "label": 0
                },
                {
                    "sent": "Decode 2 bits.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, it turns out it's a lot faster.",
                    "label": 0
                },
                {
                    "sent": "Not.",
                    "label": 0
                },
                {
                    "sent": "I'm telling you about it and I like it, so that's why.",
                    "label": 0
                },
                {
                    "sent": "Ah.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in 2007 we rolled out another fairly substantial change.",
                    "label": 0
                },
                {
                    "sent": "Was that we really should have done earlier, but it was sort of an operational and sort of logistical effort to get it done.",
                    "label": 0
                },
                {
                    "sent": "The main issue was we had our web search product which had a very large index of web pages and then we had all these other products that people could go to directly to.",
                    "label": 0
                },
                {
                    "sent": "Do you know you gotta print.google.com to search books you can go to news.google.com to search news.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "You know, that's really not that great a user experience 'cause the user has to pick which corpus they think is relevant and then go to that particular property and search it.",
                    "label": 0
                },
                {
                    "sent": "And so we would sometimes search news when you did a web search and show you an embedded news result if that seemed relevant.",
                    "label": 0
                },
                {
                    "sent": "But really, we should be searching all corpuses at all times.",
                    "label": 0
                },
                {
                    "sent": "Whenever you do a query on Google so we can find you the most relevant information regardless of what.",
                    "label": 0
                },
                {
                    "sent": "You know particular corpus that happens to reside in one of the things that had to happen for that is all the other properties had to be built to have enough capacity to handle full web search query volumes.",
                    "label": 0
                },
                {
                    "sent": "And that's actually somewhat challenging to do because a lot of those other products are engineered assuming much lower query volumes.",
                    "label": 0
                },
                {
                    "sent": "So the print.google.com for example, was engineered assuming traffic to the book search system, which is a lot lower than our web search traffic.",
                    "label": 0
                },
                {
                    "sent": "And so we had to sort of get everyone using common system that had all the same performance enhancements we put in a web search and put them all into the other corpora as part of that, we built an indexing service, so it was easy for different products to dump data to be indexed into the system.",
                    "label": 0
                },
                {
                    "sent": "It would get indexed and built on each of those trees.",
                    "label": 0
                },
                {
                    "sent": "Each of those triangles is essentially one of those corpus trees that I showed you before with the root and some intermediate servers and some leave.",
                    "label": 0
                },
                {
                    "sent": "Handling that.",
                    "label": 0
                },
                {
                    "sent": "And then there's obviously lots of interesting challenges in deciding, given the results from each of these corpuses, what which ones are most relevant to show for that particular query an what you I should you use to show them and so on.",
                    "label": 0
                },
                {
                    "sent": "I think one of the things we in the past had approached this problem as we said, Gee, we don't have much capacity.",
                    "label": 0
                },
                {
                    "sent": "Let's see if we can find some queries that we'd like to send to some of the other corpora that we believe will have good results, but that's a much harder problem because you're actually trying to decide based on 3 words in the query.",
                    "label": 0
                },
                {
                    "sent": "Is this going to be an interesting?",
                    "label": 0
                },
                {
                    "sent": "Will the Google Groups corpus have interesting results for that three word query?",
                    "label": 0
                },
                {
                    "sent": "And that's actually a much harder problem then if you actually send the query down.",
                    "label": 0
                },
                {
                    "sent": "Get the scores back from that corpus and the relevant documents and then we can make a decision saying Oh yeah, well, the score from groups is 12 in the score from printed 5, so I'm going to assume that one of them is more relevant in the other, all of the scores may not be directly compareable.",
                    "label": 0
                },
                {
                    "sent": "You could overtime over a set of queries understand when one corpus is going to be more relevant than another.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other big change that's happened relatively recently is that.",
                    "label": 0
                },
                {
                    "sent": "We now have the ability to update our index in a matter of a minute or two for a given page, as opposed to waiting fairly long periods and doing very large batch updates.",
                    "label": 0
                },
                {
                    "sent": "And there are a lot of things that have to change in your system in order to really do that, right?",
                    "label": 0
                },
                {
                    "sent": "First of all, how do you know what pages you want to update?",
                    "label": 0
                },
                {
                    "sent": "It's good to have a system that can identify are there interesting new pages on the web that have just shown up in the last minute or two?",
                    "label": 0
                },
                {
                    "sent": "Or are there important pages that have been updated that you ideally would like to have any page as soon as it changes be updated in your index, but that's a very difficult thing and there's not enough crawl bandwidth in the world to sort of really do that, and some pages change every time you call them 'cause they have, like the timestamp at the bottom.",
                    "label": 0
                },
                {
                    "sent": "So you sort of have to pick and choose your battles and decide.",
                    "label": 0
                },
                {
                    "sent": "For a given budget of pages that you can update, what are the most important ones that you want to update and so that your index is fresh and useful to users?",
                    "label": 0
                },
                {
                    "sent": "So the crawling system needs to be able to accommodate these very fast update requests like I want to update this page and I want it now not.",
                    "label": 0
                },
                {
                    "sent": "Here's a whole bunch of URLs and I want them, you know, in an hour.",
                    "label": 0
                },
                {
                    "sent": "The indexing system is challenging because it depends on global information, at least for web search.",
                    "label": 1
                },
                {
                    "sent": "For example, where you depend on things like page rank, you depend on the anchor text of pages that point to the to that page.",
                    "label": 1
                },
                {
                    "sent": "You need to actually index that data with the other target document, so you must have some way of getting this information or some approximation of it in order to index a paid within a minute or so, and the serving system has to be rethought a bit so that it can be accept updates for different documents while you're actually serving requests.",
                    "label": 0
                },
                {
                    "sent": "An accept updates that are fairly frequent interval.",
                    "label": 0
                },
                {
                    "sent": "And the data structures you actually want to use are fairly different.",
                    "label": 0
                },
                {
                    "sent": "In that case, then something where you update things in batches of an hour or so.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other thing that I think is important in we've.",
                    "label": 0
                },
                {
                    "sent": "Realized overtime is that it's really important when you're trying to make progress on improving ranking and and search quality and so on is that you want to make it easy to do experiments and the faster you can make turn around on a particular experiment from when you have an idea to when you actually can demonstrate prototype of that idea, the better it's going to be.",
                    "label": 0
                },
                {
                    "sent": "So we've spent a lot of effort building tools that allow it.",
                    "label": 0
                },
                {
                    "sent": "Make it fairly easy to do some kinds of experiments, and that's been.",
                    "label": 1
                },
                {
                    "sent": "Beneficial some experiments you don't actually need to sort of do very much, you just want to wait different ranking parameters and those you can actually do without really rolling out anything in terms of new binaries or anything.",
                    "label": 0
                },
                {
                    "sent": "You can just do them online.",
                    "label": 0
                },
                {
                    "sent": "The ones that are more difficult to the ones that need information that you didn't have the foresight to build into your production index.",
                    "label": 1
                },
                {
                    "sent": "So you need some way of computing new information.",
                    "label": 0
                },
                {
                    "sent": "Generating it often involves passing, making it pass over all the documents or over some.",
                    "label": 0
                },
                {
                    "sent": "Derived information from all the documents and being able to build that data structure on the side that you can then use to do your experiment.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm not really going to talk very much about these various systems, but several of the pieces of infrastructure we've built are useful for doing some of these kinds of experiments.",
                    "label": 0
                },
                {
                    "sent": "I already talked a little bit about GFS, which is just a big file system spread across thousands of machines.",
                    "label": 0
                },
                {
                    "sent": "App produces a abstraction that makes it easy to write and run large scale kind of batch computations, deals with like nasty things that happen like machine failures.",
                    "label": 1
                },
                {
                    "sent": "It automatically parallelizes things across lots of machines.",
                    "label": 0
                },
                {
                    "sent": "And it basically enables you to write.",
                    "label": 0
                },
                {
                    "sent": "Simple, fairly simple programs that can extract information that is of interest to you for your experiments and perform those ad hoc experiments more quickly.",
                    "label": 0
                },
                {
                    "sent": "And big Table is a sort of semi structured storage system.",
                    "label": 0
                },
                {
                    "sent": "Think of it as a very large row and column oriented store.",
                    "label": 1
                },
                {
                    "sent": "So for example, one thing that gives us is online efficient access to per document information.",
                    "label": 0
                },
                {
                    "sent": "At anytime you can say what is the current information.",
                    "label": 0
                },
                {
                    "sent": "I know about cnn.com.",
                    "label": 0
                },
                {
                    "sent": "And it will tell you OK, the page rank is this.",
                    "label": 0
                },
                {
                    "sent": "We last crawled at this time.",
                    "label": 0
                },
                {
                    "sent": "Here is the current contents that we know about.",
                    "label": 0
                },
                {
                    "sent": "So on.",
                    "label": 0
                },
                {
                    "sent": "And this is very useful for being able to update documents in a matter of minutes as opposed to days.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the experimental cycle you want to start with a new ranking idea.",
                    "label": 1
                },
                {
                    "sent": "You obviously use these tools to generate interesting data, and then you want to be able to at first run offline experiments.",
                    "label": 0
                },
                {
                    "sent": "So users are involved in this.",
                    "label": 0
                },
                {
                    "sent": "You essentially just want to run your, say ranking, change an look at what effect it has on how results are ranked for a different query sets, and some human rated query sets and other ones.",
                    "label": 0
                },
                {
                    "sent": "Maybe you'll do a random selection of queries and just look at what changes compared to the production ranking.",
                    "label": 1
                },
                {
                    "sent": "So the important thing to note here is that the latency or the throughput of this prototype don't really matter.",
                    "label": 1
                },
                {
                    "sent": "You know you can run 10,000 queries and it can take hours.",
                    "label": 0
                },
                {
                    "sent": "That's OK, it's not ideal, but it's OK, and then you kind of iterate based on the results of this.",
                    "label": 0
                },
                {
                    "sent": "Maybe you find that Gee, it works well in this case, but not this case.",
                    "label": 0
                },
                {
                    "sent": "And then you change your code a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the whole framework or the experiment that you run must operate.",
                    "label": 1
                },
                {
                    "sent": "I propose to production latency's.",
                    "label": 1
                },
                {
                    "sent": "You know, adding 100 milliseconds is maybe OK, but in a second or two is definitely not.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now you've managed to solve based on various kinds of user quick metrics and so on that your payment is better than what we're running today, so you want to be able to launch it, and so sometimes it will just work.",
                    "label": 0
                },
                {
                    "sent": "'cause you thought about throughput from the beginning.",
                    "label": 0
                },
                {
                    "sent": "But sometimes maybe you do fairly expensive things that are computationally not so ideal on our full traffic volume, so you'll need to figure out how you can tune.",
                    "label": 0
                },
                {
                    "sent": "Whatever it was you did in your experiment that it can run at full gold.",
                    "label": 1
                },
                {
                    "sent": "Traffic.",
                    "label": 1
                },
                {
                    "sent": "Volume an 1 one of the techniques you often use as you're going to precompute something instead of competing at runtime.",
                    "label": 1
                },
                {
                    "sent": "Another one is maybe there's some much cheaper approximation you can use that will be good enough, although obviously then you need to go back re validate that your approximation is giving you the same kind of quality that your full computation was.",
                    "label": 0
                },
                {
                    "sent": "It's really important to have a smooth rollout process for search quality improvements.",
                    "label": 1
                },
                {
                    "sent": "You're continuously making these quality versus cost tradeoffs.",
                    "label": 0
                },
                {
                    "sent": "You know you might have something you want to launch that increases the CPU cost of every query a little bit.",
                    "label": 0
                },
                {
                    "sent": "You need to have some sort of understanding and budget for improving quality, but if you don't then you're going to have not healthy relationships between who want to minimize the number of machines you take an the people who want to improve.",
                    "label": 0
                },
                {
                    "sent": "Search results, so having sort of understanding of.",
                    "label": 0
                },
                {
                    "sent": "What are the acceptable CPU costs that you can have this quarter for new quality improvements is really helpful thing.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Interesting things, so I think.",
                    "label": 0
                },
                {
                    "sent": "We're just starting to scratch the surface that was done in terms of cross language information retrieval.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of progress in base translation.",
                    "label": 0
                },
                {
                    "sent": "We have a research group at Google that is working pretty extensively area and is getting pretty good results for sort of automatic machine translation between different languages.",
                    "label": 0
                },
                {
                    "sent": "The ideal goal is basically translate be able to translate all the world's documents into all languages.",
                    "label": 1
                },
                {
                    "sent": "Obviously this is good for engineering, 'cause it increases index size a lot.",
                    "label": 0
                },
                {
                    "sent": "It's really good and there's lots of computational costs.",
                    "label": 0
                },
                {
                    "sent": "Just doing the translation.",
                    "label": 0
                },
                {
                    "sent": "The way it's done today.",
                    "label": 1
                },
                {
                    "sent": "But there's huge benefits if really done well, so you can imagine that anyone, no matter what language they speak and have access to all the information on the web, not just the subset of it in the language that they happen to speak.",
                    "label": 0
                },
                {
                    "sent": "It's especially important in languages where there's not a lot of content in that language on the web.",
                    "label": 0
                },
                {
                    "sent": "So obviously there's two challenges.",
                    "label": 0
                },
                {
                    "sent": "One is continuously making the translation quality better, and there's actually lots of interesting large scale systems work in the actual translation process itself.",
                    "label": 0
                },
                {
                    "sent": "Actually, for them a little bit turns out in order to translate one sentence, we need to do a million look ups in a multi TB model.",
                    "label": 0
                },
                {
                    "sent": "That basically keeps track of how often every five word sequence occurs in all of our documents.",
                    "label": 0
                },
                {
                    "sent": "An that doesn't fit on my machine, so we end up with this huge cups that you need to be able to do in parallel across a large number of machines.",
                    "label": 0
                },
                {
                    "sent": "Loaded your model into memory.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other kind of interesting thing that is happening as we try to sort of.",
                    "label": 0
                },
                {
                    "sent": "Have other products like Gmail that is personal information, various other kinds of products like groups that are between groups of you know anywhere between one and a million people is how can you actually build retrieval systems that deal efficiently with documents that are private that are sort of semi private to fairly small numbers of people that are shared extensively or that are completely public like web pages.",
                    "label": 0
                },
                {
                    "sent": "The best solution that you can come up with for a given document that are shared with 10 people is pretty different, eh?",
                    "label": 1
                },
                {
                    "sent": "Very public document an even worse.",
                    "label": 1
                },
                {
                    "sent": "The sharing pattern of document might change overtime.",
                    "label": 0
                },
                {
                    "sent": "You know it might be something you author 1st and now you want to publish it to a million people or 1000 people or something like that.",
                    "label": 0
                },
                {
                    "sent": "So there's interesting things to do there.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another area where I think there could be some work is how can we automatically construct?",
                    "label": 0
                },
                {
                    "sent": "Retrieval systems, so currently we have several different subsystems or retrieval system that are suited for different kinds of information or different kinds of.",
                    "label": 1
                },
                {
                    "sent": "Parameters of the system.",
                    "label": 1
                },
                {
                    "sent": "So one system deals with a small number documents but can do sub second update latency on those documents and other one is for very large number of documents but deals only with very large batches of updates at once per day, say.",
                    "label": 0
                },
                {
                    "sent": "So we made a lot of progress on having common interfaces for the scoring and ranking function on across all these different subsystems, but the implementation pretty different an that works reasonably well.",
                    "label": 0
                },
                {
                    "sent": "They were sort of happy with it, but it takes a lot of effort to build and maintain and extend all these different systems.",
                    "label": 1
                },
                {
                    "sent": "So could we have a parameter isable system given you know some information about how many documents 1 update per second per day automatically constructs the right mix of retrieval subsystems too.",
                    "label": 0
                },
                {
                    "sent": "Build, you know, minimize your machine cost.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another interesting area is doing better information extraction from semi structured data.",
                    "label": 1
                },
                {
                    "sent": "I think the fully labeled semantic data is pretty interesting, but it's going to be a time fraction of data that exists in the world and there's going to be much more structured data like web pages with tables and so on, and then that is going to provide you with.",
                    "label": 1
                },
                {
                    "sent": "A larger set of information, although it's noisier.",
                    "label": 0
                },
                {
                    "sent": "So how can you sort of improve algorithms and techniques for extracting this kind of information from these unstructured and semi structured sources?",
                    "label": 0
                },
                {
                    "sent": "Obviously there's a lot done in C, so that helps you in sort of.",
                    "label": 1
                },
                {
                    "sent": "Dealing with the fact that the data is inherently noisy, you also want to be able to combine incorporated and aggregate all these things across different source.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in conclusion, it's fun to build these systems.",
                    "label": 0
                },
                {
                    "sent": "It's really a lot of challenging problems.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "I work with great colleagues there.",
                    "label": 0
                },
                {
                    "sent": "New problems all the time that require sort of continuous evolution of the system built and new directions.",
                    "label": 1
                },
                {
                    "sent": "We want to be able to go in.",
                    "label": 0
                },
                {
                    "sent": "It's really nice that this work benefits alot of our users.",
                    "label": 0
                },
                {
                    "sent": "All of our users and I think that's probably the most fun that I have is because doing is challenging, useful and fun.",
                    "label": 0
                },
                {
                    "sent": "OK, so thanks for your attention.",
                    "label": 1
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I don't know if we have time for questions, but.",
                    "label": 0
                },
                {
                    "sent": "Then any questions.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Why do we want to slide every document to all languages?",
                    "label": 0
                },
                {
                    "sent": "I didn't get this.",
                    "label": 0
                },
                {
                    "sent": "Isn't this extremely costly at the end or relatively small?",
                    "label": 0
                },
                {
                    "sent": "Gain.",
                    "label": 0
                },
                {
                    "sent": "Well, it so that seems like a good ideal goal.",
                    "label": 0
                },
                {
                    "sent": "Basically, you might make some approximations like you might say, OK, I want to take a moment and translated into the 10 most commonly used languages.",
                    "label": 0
                },
                {
                    "sent": "That would not quite as useful, but would be much less costly.",
                    "label": 0
                },
                {
                    "sent": "So these kinds of engineering decisions that you're having to make all the time when building a retrieval system, and I think.",
                    "label": 0
                },
                {
                    "sent": "You know you're right, it would be pretty costly to it that way, but I think.",
                    "label": 0
                },
                {
                    "sent": "Important to keep track of what the goal is and then figure out how we can sort of meet almost all of that goal in a less costly manner than to say, well, we're not ever going to be that well.",
                    "label": 0
                },
                {
                    "sent": "So your snippet player in the document clustered seemed separate.",
                    "label": 0
                },
                {
                    "sent": "I was wondering where the snippets are actually computed.",
                    "label": 0
                },
                {
                    "sent": "So the index and the right.",
                    "label": 0
                },
                {
                    "sent": "Sorry, so the snippets are computed in the doc servers talk servers basically have access to the full document text that we crawled and you get a query in Anna Document ID that says OK, I want to snippet this query for document 12 and then it goes and fetches the contents of document 12 and then compute the snippet.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}