{
    "id": "dexkspcpeb3nfrlbrv2j3szek3slx4av",
    "title": "Learning interpretable SVMs for biological sequence classification",
    "info": {
        "author": [
            "S\u00f6ren Sonnenburg, Machine Learning and Intelligent Data Analysis Group, TU Berlin"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "March 2005",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/mlsvmlso05_sonnenburg_lisbs/",
    "segmentation": [
        [
            "Chance.",
            "Yeah, OK, so my name is Susan book and I'm going to talk about learning chapter for biological sequence classification.",
            "And this is joint work with Norwich and Casino Shiva.",
            "OK, So what I'm going to present is first of all the multi."
        ],
        [
            "Rating application so this application motivated like the multiple kernel learning formulation that we have people derive.",
            "The algorithm.",
            "That we propose to present and to to solve.",
            "This might become learning problem and also we do some significance analysis and then I will show some results and give a conclusion."
        ],
        [
            "OK, so let's start with this motivating application.",
            "We have two class classification problem.",
            "OK so first of all originally what we want to do is is gene funding.",
            "So we want to detect genes on DNA.",
            "However.",
            "Yes, this is not a very trivial task.",
            "We need signals reliable signals which can be reliably detected on the DNA.",
            "One of these signals are so called splice sites, and there are boundaries between.",
            "Coding stuff and non coding parts of the DNA.",
            "And so the slicer exactly here.",
            "And what we're given is.",
            "Set of aligned in a sequence is as you can see there.",
            "And some of these sequences are splice sites and some of them are fixed by sites and we want to detect whether, whether in the middle only in the middle there is a supply side or not.",
            "OK.",
            "So this is the this is standard 2 plus."
        ],
        [
            "Location program which you can solve using standard I mean in SVM classifier.",
            "However, it's not.",
            "It's not a standard one because.",
            "The input data we have doesn't live in real valued space, but in some discrete space because it is.",
            "Lifting the skin, a alphabet which is a Sgt only.",
            "So the type of kernel one needs to use there is string kernel.",
            "Which operates on these strings.",
            "And we propose to use so called weighted degree kernel, which is particularly simple explaining.",
            "So we have two sequences.",
            "And what awaited you?",
            "Re kernel does in this loop here.",
            "This it looks whether there is a match at the first position between the two sequences.",
            "And the second position and so on.",
            "It goes through over the.",
            "This is for the whole sequence, so just counts.",
            "Matches of a certain length K. And then waits them with some some weight according to that length.",
            "And then it goes 'cause I'm doing this with two pills.",
            "And three tuples, and so on up to a certain maximum degree D. And again weights these.",
            "The number of matches with this with this weight, so it's particularly simple kernel, but it.",
            "But it turns out to be very."
        ],
        [
            "Yeah, very successful on for this task, which is cause.",
            "Just because then, as we posted, task to sequences are all aligned, so a single shift, which I mean if we shift the sequence just a single by a single character.",
            "Most buyside anymore in the middle.",
            "So what we need to position?",
            "Position dependent kohner and which is what is coming OK.",
            "So.",
            "This code works, however we have to choose a particular waiting for this.",
            "Pretty for the for the better.",
            "And.",
            "But but as you can see it.",
            "On 500,000 training examples we achieve like an area under the RC curve of almost one.",
            "So it's 99.8%.",
            "So this is this is currently the best hope worldwide.",
            "However, it does not.",
            "It is not clear why.",
            "Why does making make sense?",
            "And.",
            "For the week and we can learn a waiting and also whether there is a better rating and better means.",
            "If you can still improve on this task which offer it seems already solved, still important to even better.",
            "And and.",
            "Also, in terms of sense, which means is there particular weighting which is biologically motivated or not?",
            "OK, so.",
            "And of course, what does it all have to do with?"
        ],
        [
            "Simulation.",
            "1st first of all, what do we do?",
            "We gain if we could learn saturating.",
            "Consider we again we have OK so like some of you have, if you have to just display trikona we could choose some high degree and we can learn the weights.",
            "If our method could could learn the weights, then.",
            "Just choose choose some high degree and it will learn the weights that are necessary for the for the task force.",
            "And another thing is that we gain interpretability, so we can give an example.",
            "So on the on the X axis you see the weights.",
            "For the registry, kernel corresponding to matches of a certain link K, so it's in biology, it's called came here.",
            "So this is the wait for match of rank one.",
            "Mr Wait for Metro Bank 12 and indeed turns out that these hexamer matches of things 6.",
            "Are feature that is used and in stab Liszt.",
            "Established biological in establishing gene funding.",
            "And and.",
            "Then Duncan, one can even do more.",
            "The weights where at the moment as we formulated the kernel, the rates for their constant over the whole DNA sequence, which means so.",
            "A match.",
            "Of things one always get the same, get the same weight over the over the whole sequence.",
            "But you can be can also formulate Colonel like this, that data match at a certain position in the sequence.",
            "So we can also make the kernel more position dependent, which means if if you put the sequence, you put a sequence here.",
            "And.",
            "Now you can have for one position for one position in the sequence.",
            "We can have rates for each of the match links for each of the cameras, and we can then plot.",
            "We can then plot these weights as shown here.",
            "And you will see that.",
            "But for example, here to position close to this splice site.",
            "Both minus five days there's some.",
            "Some important weight of order 5503.",
            "And so we can really go through biologists in some portent.",
            "Yeah, but it is something that binds to this position in the.",
            "In the DNA sequence.",
            "Yep, so."
        ],
        [
            "Is what?",
            "Yeah, they look different.",
            "Yeah, so it's been it's because of the second because of the nature of this."
        ],
        [
            "Some.",
            "The problem we want to solve so the so this is this is completely.",
            "I mean these are the so-called coding regions.",
            "And this is a non coding part and actually here somewhere here in front of the Splicer, TST information.",
            "About the splicing and also slightly.",
            "Right of the supply side, so we get it.",
            "Must look different from this right?",
            "OK so.",
            "OK."
        ],
        [
            "It turns out that the designated degree corner is indeed to a kernel which is combined is a linear combination of service occurrence.",
            "So finding so this this would be a subcurrent which just looks a certain.",
            "Um?",
            "Came here K. And it's linearly combined with some positive rate.",
            "Better so.",
            "Away too.",
            "So finding these weights better gives us the so called multiple kernel problem where we have to determine the weights better and solution Alpha and B simultaneously.",
            "So this.",
            "Dismiss it.",
            "I mean, the name might be coning."
        ],
        [
            "Given by.",
            "Language and Buck who first proposed this.",
            "Kind of method.",
            "OK, so.",
            "Now let's forget about the application and do this more formally, so this is actually where the talk now really starts.",
            "We have again have for SVM classifier we have.",
            "We have a kernel which is not a linear combination of these kernels.",
            "And it's it's useful also for other types of kernels like like for example, polynomial kernel.",
            "If you could could for example get model selection up to a certain degree.",
            "Also, if we use a higher order programming kernel, or we can combine kernels on different domains.",
            "So now the notification is how can we learn this this this weights better and.",
            "How do we do we have to constrain them OK?",
            "It's necessary."
        ],
        [
            "To constrain them cause.",
            "If you found a maximization program, the rates would grow infinitely too would go to nfinity.",
            "And if it was a minimization problem, they would they would shrink to 0.",
            "So we have to somehow.",
            "Have a constraint on on this weights.",
            "They were, they were.",
            "One approach is to use the concern the two norm to one.",
            "Stand by in some.",
            "And a different approach.",
            "OK, so this will give us a dense solution.",
            "And it's not what we want.",
            "Different different approaches.",
            "What was behind language also did is to constrain the one norm.",
            "To one and.",
            "This will give us just a convex combination of kernels and the solution will be sparse in terms of these kernels and we might end up and can interpret the result.",
            "OK, so we now have this device some over the betas.",
            "They come to one and they're great.",
            "Equals evil.",
            "OK, let's drive to this."
        ],
        [
            "'cause my account learning problem so this is what we all know.",
            "It's a standard SVM primal formulation.",
            "Um?",
            "What you what you can see in right now is what we have to."
        ],
        [
            "Do it.",
            "For the for the much counseling program and the.",
            "The difference, the difference is now that OK.",
            "So first of all we have this constraint on the weights.",
            "This additional constraints on the on the on the weights better.",
            "And we also map each each feature vector X.",
            "Into J into M different blocks.",
            "Into EM different feature spaces, and in each of these feature spaces we have a different normal vector and we wait this.",
            "According to this.",
            "Certain weight better J.",
            "And then of course the objective also changes slightly.",
            "OK, so other properties of this problem, so it's equivalent to send it as we information if M = 1 and the solution will be sparse.",
            "In blocks, but within each block it will be a dense solution.",
            "And each of these blocks corresponds to one kernel.",
            "OK, so this."
        ],
        [
            "This knowledge behind languages so they drived dual formulation of of this program.",
            "I can I can give an intuition why why it works?",
            "Actually, if M so the number of currently combine equals one, then this.",
            "This inequality here will become inequality.",
            "And if it's any quality we can plug in.",
            "Tacoma squared in the objective and then what you see is that.",
            "That is, some over Alpha Y&K is there and then it's a standard SVM dual formulation again.",
            "OK, so now we want to get.",
            "Which of this this, and former only partial Lagrangian?",
            "So we have this objective and we introduce weight better, which is the same weight.",
            "Also is in a duel in a primer.",
            "And.",
            "OK, so we get this.",
            "You get to some get to something here.",
            "So this is this is Jay Jay of Alpha is just.",
            "It's just a short code for this for this long term.",
            "OK, so if you know, yeah.",
            "Would it be possible to replace accordingly?",
            "Yeah, I mean I don't know.",
            "I'm not sure.",
            "So I mean.",
            "At the moment we have get one constraint for each each of the components, so I don't know whether one can.",
            "Combination there I mean.",
            "OK. To to move on.",
            "We have we have to have this special occasion if he said it."
        ],
        [
            "To do it with respect to this, to zero, we obtain.",
            "Only this maxmin problem.",
            "And.",
            "We will reformulate this this optimization program into a semi so called semi Infinite Linear program.",
            "Which is which is shown in this box.",
            "And what you can see there is that.",
            "The program is linear, so we maximize respect to a scalar living in R. And the scalar is.",
            "Linearly bounded as we.",
            "Pussy.",
            "And.",
            "And however we have, we have a single constraint for each for each Alpha in the interval between zero and C, and as Alpha is real valued, we have infinitely many of these constraints, so it's a linear program, but it's.",
            "It has infinitely many constraints.",
            "OK, I can give can give an intuition how one can come from from the this formulation to the senior program.",
            "But if you, if you fix the beta.",
            "Fix it, fix the beta then.",
            "Then then look at look at this formulation.",
            "Then we can increase.",
            "Data which we which we maximize.",
            "Is high as long you can still increase it as long as no constraint here is.",
            "Is active.",
            "And constraints will become active when this term here becomes minimal, and this term will be fixed later.",
            "This term will become minimal if we minimize this term with respect to some Alpha, so we indeed minimize with respect to Alpha.",
            "And similarly maximize the prospecta beta.",
            "Because if you fix, if you know fix this Alpha.",
            "And.",
            "You know fixing cipher, then Peter will again be.",
            "Maximized in this metric dinner.",
            "Program.",
            "With respect to this picture, which is not flexible.",
            "OK, So what are the properties of this linear program?"
        ],
        [
            "Optimizes a convex combination.",
            "It has infinitely many constraints on on the Alpha.",
            "But the good thing is that it's easy to find the most violated constraints which which we can use to solve this problem will see how it works in.",
            "In a minute.",
            "OK so tech."
        ],
        [
            "To solve such semi infinite linear programs current generation.",
            "It's pretty fast, but there's no known convergence rate for current generation.",
            "There are also boosting like techniques like activity or ADA boost.",
            "They have a convergence rate, but in practice they they were not working, is faster than the current generation algorithm and also we can create some some old type algorithm which empirically was even faster.",
            "So coming to the first algorithm, the column the call."
        ],
        [
            "Relation.",
            "We have now how does whole discrimination work?",
            "As we have infinitely many constraints, as we have a linear program with infinitely many constraints, it's hard to.",
            "It's hard to solve and congelation.",
            "Is to just take a finite subset of these constraints, and so offsetting your program for finite subset constraints.",
            "However, it's important which which constraints you choose.",
            "And.",
            "It makes particularly sense to choose these constraints which which violate which violate this, this this.",
            "So this inequality most.",
            "And.",
            "This most violated constraints can indeed given be given can be found by solving a support vector machine.",
            "So look at look at this return again if you plug in the definition of SJ Alpha again.",
            "We will end up.",
            "50s term and minimizing this term is exactly finding.",
            "Come support vector machine solution, so an Alpha.",
            "For a given hoops.",
            "For a given fixed beta, which which then will violate the constraint constraint.",
            "OK, so we have the way to proceed now is to each actively find the most violated constraints.",
            "For fixed Peter.",
            "Then then use this Alpha to create some.",
            "Some to create this computers constraint.",
            "Then we can.",
            "We can solve this linear program with infinitely many with only finitely many constraints, and we can proceed until convergence.",
            "Um?",
            "OK, so this is this is."
        ],
        [
            "We have as I said before, fixed for fixed beta we.",
            "I'm self inspecting machine and we get in an Alpha.",
            "Put it, we then compute the maximum.",
            "This mixing, mixing, violating constraint and then plug it into this.",
            "Simple linear program and we do so until until we converge.",
            "OK. A different formulation is."
        ],
        [
            "Boosting.",
            "Um?",
            "A different different weight method to solve this.",
            "Similar programs costing and the boosting dual one has.",
            "At the boosting dual looks like this, and in boosting in general one has linear.",
            "Hypothesis HJ, which are linearly combined.",
            "And it turns out that the dual formulation of of boosting.",
            "Maximizes is exactly this to the.",
            "Infinite in your program if you have infinitely many constraints.",
            "Because if we maximize with respect to minus Delta.",
            "And the DM then entered in too.",
            "To always better end.",
            "And HA two large expression containing the.",
            "I'm an Alpha.",
            "Get you get into the formulation we had.",
            "As before, so we can.",
            "We can use boosting techniques like actually or a boost to also solve this problem OK.",
            "So this is how the algorithm would would look."
        ],
        [
            "Then we have again obtained the most cited constraint as as before.",
            "And what is what is right here is extended.",
            "This actually boosting specific part.",
            "You can see the exponential updates here on this on this way it's better which is.",
            "All you.",
            "OK, so now."
        ],
        [
            "We can find the confined waiting on on this.",
            "You're in and.",
            "We can solve this whole college multiple kernel learning problem.",
            "Now the question arises if I if I have learned if I know have learned all the weights and in this case it's on that time stencilled 1000.",
            "Weights.",
            "Then can we?",
            "Can we rely on these on these weights?",
            "Cause the waiting might be very unstable.",
            "If he just commute, if you just choose a different subset of the data for training.",
            "And so it's important to ask the question which weights are significant.",
            "And we derive for the statistical test for this, but I don't want to go into into detail for for this test principle.",
            "For the desert computes.",
            "Boots up computes, replicates of the data and then solve as protecting machine.",
            "At this microphone problem for all of these bootstraps and then we can.",
            "Somehow get in.",
            "And the probability of whether rate is significant or not.",
            "And.",
            "I can, I will give you an example for this, so we have a toy data set."
        ],
        [
            "So this is a DNA sequences.",
            "It consists of DNA sequences of length 50.",
            "And he chose.",
            "To to hide some motives at position 10 to 16 and 3236.",
            "And so this is the.",
            "So it's again this.",
            "Two class problem.",
            "We have data where with these motives are hidden and we have just random data and we try to classify classify random data against the.",
            "From the data with hidden motives.",
            "So.",
            "We then you don't have 8 * 50 of these string kernels, so one one wait eight weights per position in the kernel, one for each of these K Meyers.",
            "And.",
            "Um?",
            "We OK, so we learn computer significance using this bootstrapping type of approach and what you can see here is the case with.",
            "This noise so again we have to position off the sequence.",
            "And we have came here the cameras up to.",
            "My feet.",
            "So we're looking for matches from from.",
            "For metrics of length one up two matches of length 8 and specific for each for each position independently, and we have also and also learned these weights which are in independently for each of the positions in the sequence, and what we can see there now is that.",
            "To just one or two weights are.",
            "Are important.",
            "So what is Prodigy is the probability that weight significant?",
            "And so the brighter the more significant it is.",
            "So these these two weights are the ones which.",
            "So.",
            "Yeah, seems to get Houston in a.",
            "In a solution.",
            "And.",
            "However, this is the non noisy case, so we have really clean motives.",
            "Here is 2 positions.",
            "If you now randomly substitute.",
            "Letters in the motives.",
            "Then from from left to right, we do so we just replies.",
            "Replace 2, four and six positions, then the kernel.",
            "Do not use them.",
            "As long as they're not.",
            "Do not use such high weights.",
            "Anymore it will slowly use only on the.",
            "Only this this lower this lower rates.",
            "Just because the motives split up due to this random substitutions, however, it will still find.",
            "The motives to be significant only in.",
            "In this region now I realize I forgot to say that a upper column is just just short shorts away found to be significant.",
            "Refer certain threshold source like to the Alpha is 5%.",
            "It's the same plug, but for an Alpha value of 5%.",
            "OK.",
            "So.",
            "I would say this method."
        ],
        [
            "Method works to detect features.",
            "And as we have seen in this install data set and what we can do is now is we can apply to some real data again to display site task.",
            "And again we have different rates on this.",
            "In this case, it's 140 * 10, So it's 1400.",
            "Occurrences are kernels that are combined.",
            "And we, I think it went on like 2500 examples only.",
            "And.",
            "As we can see, the weights straight in front of the supply side, we have found to be to be important, and it's indeed like this that.",
            "Some biological thing called spices on binds.",
            "One of the.",
            "This place had swords.",
            "So so 3.",
            "That we expected the method really expected some biological relevant information, OK?",
            "OK, so let's."
        ],
        [
            "Come to the conclusion of this talk.",
            "So if you've developed multiple turn learning algorithm which suitable for large scale.",
            "Problems so we can train this persuaded Recon and 200,000 examples and it takes about the day.",
            "It is, it is fast, so this time estimate and seconds.",
            "And for certain kernels, like in kernels, that will allow you to interpret the support vector machine reside.",
            "And it is future work to apply this to regression or to feature selection.",
            "OK, so let's talk.",
            "Yeah, I'm very happy to see you.",
            "Optimizations here we for instance, in my infinite optimizations here is playing such a nice hole according to my idea very promising.",
            "I tried resetting representation only, also indicated briefly, but I mentioned our officer.",
            "Evening when you spoke about civilianization of mixed type functions, there's also a natural linkage given possible infinite optimization problems.",
            "Understand the problem which was considered here is just before when you take some of it and also QWS.",
            "Sport and at this level and all that, the substance.",
            "If I didn't make a mistake, so you can present this mean problem, you're coming with this.",
            "Problem.",
            "Do also instead of.",
            "You objective is just the sum.",
            "OK.",
            "Wanted to express my appreciation.",
            "Yeah.",
            "It's starting to.",
            "You could bring had mentioned space here, and you know that's perfect insight.",
            "You know you might have a single support vector which single result.",
            "Just yeah.",
            "OK, that's true, but.",
            "Solutions change, but yeah, so that's actually true.",
            "But if he if you get the same solution over and over again, we have an estimate on higher how reliable this overall rating is.",
            "I mean, it's better.",
            "It's better than doing no significance in this at all.",
            "Solution you know that you're OK because you presumably finding some other almost, but actually I mean at least empirically observed.",
            "It always finds similar.",
            "I mean, not, not the same solution.",
            "If he if he chose different subsets of the data.",
            "But through similar.",
            "Similar ways so.",
            "When you put it in something, another bus pass fire in very high dimensions.",
            "It looks strange because you could just simply lose your whole solution.",
            "OK, yeah.",
            "Yeah, I mean OK, yeah, but it's it's.",
            "It's what can happen now."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chance.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so my name is Susan book and I'm going to talk about learning chapter for biological sequence classification.",
                    "label": 1
                },
                {
                    "sent": "And this is joint work with Norwich and Casino Shiva.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'm going to present is first of all the multi.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rating application so this application motivated like the multiple kernel learning formulation that we have people derive.",
                    "label": 1
                },
                {
                    "sent": "The algorithm.",
                    "label": 0
                },
                {
                    "sent": "That we propose to present and to to solve.",
                    "label": 1
                },
                {
                    "sent": "This might become learning problem and also we do some significance analysis and then I will show some results and give a conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with this motivating application.",
                    "label": 0
                },
                {
                    "sent": "We have two class classification problem.",
                    "label": 0
                },
                {
                    "sent": "OK so first of all originally what we want to do is is gene funding.",
                    "label": 0
                },
                {
                    "sent": "So we want to detect genes on DNA.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "Yes, this is not a very trivial task.",
                    "label": 0
                },
                {
                    "sent": "We need signals reliable signals which can be reliably detected on the DNA.",
                    "label": 0
                },
                {
                    "sent": "One of these signals are so called splice sites, and there are boundaries between.",
                    "label": 0
                },
                {
                    "sent": "Coding stuff and non coding parts of the DNA.",
                    "label": 0
                },
                {
                    "sent": "And so the slicer exactly here.",
                    "label": 0
                },
                {
                    "sent": "And what we're given is.",
                    "label": 0
                },
                {
                    "sent": "Set of aligned in a sequence is as you can see there.",
                    "label": 0
                },
                {
                    "sent": "And some of these sequences are splice sites and some of them are fixed by sites and we want to detect whether, whether in the middle only in the middle there is a supply side or not.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the this is standard 2 plus.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Location program which you can solve using standard I mean in SVM classifier.",
                    "label": 1
                },
                {
                    "sent": "However, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not a standard one because.",
                    "label": 0
                },
                {
                    "sent": "The input data we have doesn't live in real valued space, but in some discrete space because it is.",
                    "label": 0
                },
                {
                    "sent": "Lifting the skin, a alphabet which is a Sgt only.",
                    "label": 0
                },
                {
                    "sent": "So the type of kernel one needs to use there is string kernel.",
                    "label": 0
                },
                {
                    "sent": "Which operates on these strings.",
                    "label": 0
                },
                {
                    "sent": "And we propose to use so called weighted degree kernel, which is particularly simple explaining.",
                    "label": 1
                },
                {
                    "sent": "So we have two sequences.",
                    "label": 0
                },
                {
                    "sent": "And what awaited you?",
                    "label": 0
                },
                {
                    "sent": "Re kernel does in this loop here.",
                    "label": 0
                },
                {
                    "sent": "This it looks whether there is a match at the first position between the two sequences.",
                    "label": 0
                },
                {
                    "sent": "And the second position and so on.",
                    "label": 0
                },
                {
                    "sent": "It goes through over the.",
                    "label": 0
                },
                {
                    "sent": "This is for the whole sequence, so just counts.",
                    "label": 0
                },
                {
                    "sent": "Matches of a certain length K. And then waits them with some some weight according to that length.",
                    "label": 0
                },
                {
                    "sent": "And then it goes 'cause I'm doing this with two pills.",
                    "label": 0
                },
                {
                    "sent": "And three tuples, and so on up to a certain maximum degree D. And again weights these.",
                    "label": 0
                },
                {
                    "sent": "The number of matches with this with this weight, so it's particularly simple kernel, but it.",
                    "label": 0
                },
                {
                    "sent": "But it turns out to be very.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, very successful on for this task, which is cause.",
                    "label": 0
                },
                {
                    "sent": "Just because then, as we posted, task to sequences are all aligned, so a single shift, which I mean if we shift the sequence just a single by a single character.",
                    "label": 0
                },
                {
                    "sent": "Most buyside anymore in the middle.",
                    "label": 0
                },
                {
                    "sent": "So what we need to position?",
                    "label": 0
                },
                {
                    "sent": "Position dependent kohner and which is what is coming OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This code works, however we have to choose a particular waiting for this.",
                    "label": 0
                },
                {
                    "sent": "Pretty for the for the better.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "But but as you can see it.",
                    "label": 0
                },
                {
                    "sent": "On 500,000 training examples we achieve like an area under the RC curve of almost one.",
                    "label": 1
                },
                {
                    "sent": "So it's 99.8%.",
                    "label": 0
                },
                {
                    "sent": "So this is this is currently the best hope worldwide.",
                    "label": 0
                },
                {
                    "sent": "However, it does not.",
                    "label": 0
                },
                {
                    "sent": "It is not clear why.",
                    "label": 0
                },
                {
                    "sent": "Why does making make sense?",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For the week and we can learn a waiting and also whether there is a better rating and better means.",
                    "label": 0
                },
                {
                    "sent": "If you can still improve on this task which offer it seems already solved, still important to even better.",
                    "label": 0
                },
                {
                    "sent": "And and.",
                    "label": 0
                },
                {
                    "sent": "Also, in terms of sense, which means is there particular weighting which is biologically motivated or not?",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 1
                },
                {
                    "sent": "And of course, what does it all have to do with?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simulation.",
                    "label": 0
                },
                {
                    "sent": "1st first of all, what do we do?",
                    "label": 0
                },
                {
                    "sent": "We gain if we could learn saturating.",
                    "label": 0
                },
                {
                    "sent": "Consider we again we have OK so like some of you have, if you have to just display trikona we could choose some high degree and we can learn the weights.",
                    "label": 0
                },
                {
                    "sent": "If our method could could learn the weights, then.",
                    "label": 0
                },
                {
                    "sent": "Just choose choose some high degree and it will learn the weights that are necessary for the for the task force.",
                    "label": 0
                },
                {
                    "sent": "And another thing is that we gain interpretability, so we can give an example.",
                    "label": 0
                },
                {
                    "sent": "So on the on the X axis you see the weights.",
                    "label": 0
                },
                {
                    "sent": "For the registry, kernel corresponding to matches of a certain link K, so it's in biology, it's called came here.",
                    "label": 0
                },
                {
                    "sent": "So this is the wait for match of rank one.",
                    "label": 0
                },
                {
                    "sent": "Mr Wait for Metro Bank 12 and indeed turns out that these hexamer matches of things 6.",
                    "label": 0
                },
                {
                    "sent": "Are feature that is used and in stab Liszt.",
                    "label": 1
                },
                {
                    "sent": "Established biological in establishing gene funding.",
                    "label": 0
                },
                {
                    "sent": "And and.",
                    "label": 0
                },
                {
                    "sent": "Then Duncan, one can even do more.",
                    "label": 0
                },
                {
                    "sent": "The weights where at the moment as we formulated the kernel, the rates for their constant over the whole DNA sequence, which means so.",
                    "label": 0
                },
                {
                    "sent": "A match.",
                    "label": 0
                },
                {
                    "sent": "Of things one always get the same, get the same weight over the over the whole sequence.",
                    "label": 0
                },
                {
                    "sent": "But you can be can also formulate Colonel like this, that data match at a certain position in the sequence.",
                    "label": 0
                },
                {
                    "sent": "So we can also make the kernel more position dependent, which means if if you put the sequence, you put a sequence here.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Now you can have for one position for one position in the sequence.",
                    "label": 1
                },
                {
                    "sent": "We can have rates for each of the match links for each of the cameras, and we can then plot.",
                    "label": 0
                },
                {
                    "sent": "We can then plot these weights as shown here.",
                    "label": 0
                },
                {
                    "sent": "And you will see that.",
                    "label": 0
                },
                {
                    "sent": "But for example, here to position close to this splice site.",
                    "label": 0
                },
                {
                    "sent": "Both minus five days there's some.",
                    "label": 0
                },
                {
                    "sent": "Some important weight of order 5503.",
                    "label": 0
                },
                {
                    "sent": "And so we can really go through biologists in some portent.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it is something that binds to this position in the.",
                    "label": 0
                },
                {
                    "sent": "In the DNA sequence.",
                    "label": 0
                },
                {
                    "sent": "Yep, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is what?",
                    "label": 0
                },
                {
                    "sent": "Yeah, they look different.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's been it's because of the second because of the nature of this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "The problem we want to solve so the so this is this is completely.",
                    "label": 0
                },
                {
                    "sent": "I mean these are the so-called coding regions.",
                    "label": 0
                },
                {
                    "sent": "And this is a non coding part and actually here somewhere here in front of the Splicer, TST information.",
                    "label": 0
                },
                {
                    "sent": "About the splicing and also slightly.",
                    "label": 0
                },
                {
                    "sent": "Right of the supply side, so we get it.",
                    "label": 0
                },
                {
                    "sent": "Must look different from this right?",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out that the designated degree corner is indeed to a kernel which is combined is a linear combination of service occurrence.",
                    "label": 0
                },
                {
                    "sent": "So finding so this this would be a subcurrent which just looks a certain.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Came here K. And it's linearly combined with some positive rate.",
                    "label": 0
                },
                {
                    "sent": "Better so.",
                    "label": 0
                },
                {
                    "sent": "Away too.",
                    "label": 0
                },
                {
                    "sent": "So finding these weights better gives us the so called multiple kernel problem where we have to determine the weights better and solution Alpha and B simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Dismiss it.",
                    "label": 0
                },
                {
                    "sent": "I mean, the name might be coning.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Given by.",
                    "label": 0
                },
                {
                    "sent": "Language and Buck who first proposed this.",
                    "label": 0
                },
                {
                    "sent": "Kind of method.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now let's forget about the application and do this more formally, so this is actually where the talk now really starts.",
                    "label": 0
                },
                {
                    "sent": "We have again have for SVM classifier we have.",
                    "label": 1
                },
                {
                    "sent": "We have a kernel which is not a linear combination of these kernels.",
                    "label": 1
                },
                {
                    "sent": "And it's it's useful also for other types of kernels like like for example, polynomial kernel.",
                    "label": 0
                },
                {
                    "sent": "If you could could for example get model selection up to a certain degree.",
                    "label": 1
                },
                {
                    "sent": "Also, if we use a higher order programming kernel, or we can combine kernels on different domains.",
                    "label": 0
                },
                {
                    "sent": "So now the notification is how can we learn this this this weights better and.",
                    "label": 0
                },
                {
                    "sent": "How do we do we have to constrain them OK?",
                    "label": 0
                },
                {
                    "sent": "It's necessary.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To constrain them cause.",
                    "label": 0
                },
                {
                    "sent": "If you found a maximization program, the rates would grow infinitely too would go to nfinity.",
                    "label": 1
                },
                {
                    "sent": "And if it was a minimization problem, they would they would shrink to 0.",
                    "label": 0
                },
                {
                    "sent": "So we have to somehow.",
                    "label": 0
                },
                {
                    "sent": "Have a constraint on on this weights.",
                    "label": 0
                },
                {
                    "sent": "They were, they were.",
                    "label": 0
                },
                {
                    "sent": "One approach is to use the concern the two norm to one.",
                    "label": 0
                },
                {
                    "sent": "Stand by in some.",
                    "label": 0
                },
                {
                    "sent": "And a different approach.",
                    "label": 0
                },
                {
                    "sent": "OK, so this will give us a dense solution.",
                    "label": 0
                },
                {
                    "sent": "And it's not what we want.",
                    "label": 0
                },
                {
                    "sent": "Different different approaches.",
                    "label": 0
                },
                {
                    "sent": "What was behind language also did is to constrain the one norm.",
                    "label": 0
                },
                {
                    "sent": "To one and.",
                    "label": 0
                },
                {
                    "sent": "This will give us just a convex combination of kernels and the solution will be sparse in terms of these kernels and we might end up and can interpret the result.",
                    "label": 1
                },
                {
                    "sent": "OK, so we now have this device some over the betas.",
                    "label": 0
                },
                {
                    "sent": "They come to one and they're great.",
                    "label": 0
                },
                {
                    "sent": "Equals evil.",
                    "label": 0
                },
                {
                    "sent": "OK, let's drive to this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause my account learning problem so this is what we all know.",
                    "label": 0
                },
                {
                    "sent": "It's a standard SVM primal formulation.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What you what you can see in right now is what we have to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do it.",
                    "label": 0
                },
                {
                    "sent": "For the for the much counseling program and the.",
                    "label": 0
                },
                {
                    "sent": "The difference, the difference is now that OK.",
                    "label": 0
                },
                {
                    "sent": "So first of all we have this constraint on the weights.",
                    "label": 0
                },
                {
                    "sent": "This additional constraints on the on the on the weights better.",
                    "label": 0
                },
                {
                    "sent": "And we also map each each feature vector X.",
                    "label": 0
                },
                {
                    "sent": "Into J into M different blocks.",
                    "label": 0
                },
                {
                    "sent": "Into EM different feature spaces, and in each of these feature spaces we have a different normal vector and we wait this.",
                    "label": 0
                },
                {
                    "sent": "According to this.",
                    "label": 0
                },
                {
                    "sent": "Certain weight better J.",
                    "label": 0
                },
                {
                    "sent": "And then of course the objective also changes slightly.",
                    "label": 0
                },
                {
                    "sent": "OK, so other properties of this problem, so it's equivalent to send it as we information if M = 1 and the solution will be sparse.",
                    "label": 0
                },
                {
                    "sent": "In blocks, but within each block it will be a dense solution.",
                    "label": 1
                },
                {
                    "sent": "And each of these blocks corresponds to one kernel.",
                    "label": 1
                },
                {
                    "sent": "OK, so this.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This knowledge behind languages so they drived dual formulation of of this program.",
                    "label": 0
                },
                {
                    "sent": "I can I can give an intuition why why it works?",
                    "label": 0
                },
                {
                    "sent": "Actually, if M so the number of currently combine equals one, then this.",
                    "label": 0
                },
                {
                    "sent": "This inequality here will become inequality.",
                    "label": 0
                },
                {
                    "sent": "And if it's any quality we can plug in.",
                    "label": 0
                },
                {
                    "sent": "Tacoma squared in the objective and then what you see is that.",
                    "label": 0
                },
                {
                    "sent": "That is, some over Alpha Y&K is there and then it's a standard SVM dual formulation again.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we want to get.",
                    "label": 0
                },
                {
                    "sent": "Which of this this, and former only partial Lagrangian?",
                    "label": 0
                },
                {
                    "sent": "So we have this objective and we introduce weight better, which is the same weight.",
                    "label": 0
                },
                {
                    "sent": "Also is in a duel in a primer.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "OK, so we get this.",
                    "label": 0
                },
                {
                    "sent": "You get to some get to something here.",
                    "label": 0
                },
                {
                    "sent": "So this is this is Jay Jay of Alpha is just.",
                    "label": 0
                },
                {
                    "sent": "It's just a short code for this for this long term.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you know, yeah.",
                    "label": 0
                },
                {
                    "sent": "Would it be possible to replace accordingly?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean I don't know.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "So I mean.",
                    "label": 0
                },
                {
                    "sent": "At the moment we have get one constraint for each each of the components, so I don't know whether one can.",
                    "label": 0
                },
                {
                    "sent": "Combination there I mean.",
                    "label": 0
                },
                {
                    "sent": "OK. To to move on.",
                    "label": 0
                },
                {
                    "sent": "We have we have to have this special occasion if he said it.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do it with respect to this, to zero, we obtain.",
                    "label": 0
                },
                {
                    "sent": "Only this maxmin problem.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We will reformulate this this optimization program into a semi so called semi Infinite Linear program.",
                    "label": 0
                },
                {
                    "sent": "Which is which is shown in this box.",
                    "label": 0
                },
                {
                    "sent": "And what you can see there is that.",
                    "label": 0
                },
                {
                    "sent": "The program is linear, so we maximize respect to a scalar living in R. And the scalar is.",
                    "label": 0
                },
                {
                    "sent": "Linearly bounded as we.",
                    "label": 0
                },
                {
                    "sent": "Pussy.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And however we have, we have a single constraint for each for each Alpha in the interval between zero and C, and as Alpha is real valued, we have infinitely many of these constraints, so it's a linear program, but it's.",
                    "label": 0
                },
                {
                    "sent": "It has infinitely many constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, I can give can give an intuition how one can come from from the this formulation to the senior program.",
                    "label": 0
                },
                {
                    "sent": "But if you, if you fix the beta.",
                    "label": 0
                },
                {
                    "sent": "Fix it, fix the beta then.",
                    "label": 0
                },
                {
                    "sent": "Then then look at look at this formulation.",
                    "label": 0
                },
                {
                    "sent": "Then we can increase.",
                    "label": 0
                },
                {
                    "sent": "Data which we which we maximize.",
                    "label": 0
                },
                {
                    "sent": "Is high as long you can still increase it as long as no constraint here is.",
                    "label": 0
                },
                {
                    "sent": "Is active.",
                    "label": 0
                },
                {
                    "sent": "And constraints will become active when this term here becomes minimal, and this term will be fixed later.",
                    "label": 0
                },
                {
                    "sent": "This term will become minimal if we minimize this term with respect to some Alpha, so we indeed minimize with respect to Alpha.",
                    "label": 0
                },
                {
                    "sent": "And similarly maximize the prospecta beta.",
                    "label": 0
                },
                {
                    "sent": "Because if you fix, if you know fix this Alpha.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "You know fixing cipher, then Peter will again be.",
                    "label": 0
                },
                {
                    "sent": "Maximized in this metric dinner.",
                    "label": 0
                },
                {
                    "sent": "Program.",
                    "label": 0
                },
                {
                    "sent": "With respect to this picture, which is not flexible.",
                    "label": 0
                },
                {
                    "sent": "OK, So what are the properties of this linear program?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optimizes a convex combination.",
                    "label": 0
                },
                {
                    "sent": "It has infinitely many constraints on on the Alpha.",
                    "label": 1
                },
                {
                    "sent": "But the good thing is that it's easy to find the most violated constraints which which we can use to solve this problem will see how it works in.",
                    "label": 0
                },
                {
                    "sent": "In a minute.",
                    "label": 0
                },
                {
                    "sent": "OK so tech.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To solve such semi infinite linear programs current generation.",
                    "label": 0
                },
                {
                    "sent": "It's pretty fast, but there's no known convergence rate for current generation.",
                    "label": 1
                },
                {
                    "sent": "There are also boosting like techniques like activity or ADA boost.",
                    "label": 0
                },
                {
                    "sent": "They have a convergence rate, but in practice they they were not working, is faster than the current generation algorithm and also we can create some some old type algorithm which empirically was even faster.",
                    "label": 0
                },
                {
                    "sent": "So coming to the first algorithm, the column the call.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Relation.",
                    "label": 0
                },
                {
                    "sent": "We have now how does whole discrimination work?",
                    "label": 0
                },
                {
                    "sent": "As we have infinitely many constraints, as we have a linear program with infinitely many constraints, it's hard to.",
                    "label": 1
                },
                {
                    "sent": "It's hard to solve and congelation.",
                    "label": 0
                },
                {
                    "sent": "Is to just take a finite subset of these constraints, and so offsetting your program for finite subset constraints.",
                    "label": 0
                },
                {
                    "sent": "However, it's important which which constraints you choose.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It makes particularly sense to choose these constraints which which violate which violate this, this this.",
                    "label": 0
                },
                {
                    "sent": "So this inequality most.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This most violated constraints can indeed given be given can be found by solving a support vector machine.",
                    "label": 1
                },
                {
                    "sent": "So look at look at this return again if you plug in the definition of SJ Alpha again.",
                    "label": 0
                },
                {
                    "sent": "We will end up.",
                    "label": 0
                },
                {
                    "sent": "50s term and minimizing this term is exactly finding.",
                    "label": 0
                },
                {
                    "sent": "Come support vector machine solution, so an Alpha.",
                    "label": 0
                },
                {
                    "sent": "For a given hoops.",
                    "label": 0
                },
                {
                    "sent": "For a given fixed beta, which which then will violate the constraint constraint.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have the way to proceed now is to each actively find the most violated constraints.",
                    "label": 0
                },
                {
                    "sent": "For fixed Peter.",
                    "label": 0
                },
                {
                    "sent": "Then then use this Alpha to create some.",
                    "label": 0
                },
                {
                    "sent": "Some to create this computers constraint.",
                    "label": 0
                },
                {
                    "sent": "Then we can.",
                    "label": 0
                },
                {
                    "sent": "We can solve this linear program with infinitely many with only finitely many constraints, and we can proceed until convergence.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have as I said before, fixed for fixed beta we.",
                    "label": 0
                },
                {
                    "sent": "I'm self inspecting machine and we get in an Alpha.",
                    "label": 0
                },
                {
                    "sent": "Put it, we then compute the maximum.",
                    "label": 0
                },
                {
                    "sent": "This mixing, mixing, violating constraint and then plug it into this.",
                    "label": 0
                },
                {
                    "sent": "Simple linear program and we do so until until we converge.",
                    "label": 0
                },
                {
                    "sent": "OK. A different formulation is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Boosting.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "A different different weight method to solve this.",
                    "label": 0
                },
                {
                    "sent": "Similar programs costing and the boosting dual one has.",
                    "label": 0
                },
                {
                    "sent": "At the boosting dual looks like this, and in boosting in general one has linear.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis HJ, which are linearly combined.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the dual formulation of of boosting.",
                    "label": 0
                },
                {
                    "sent": "Maximizes is exactly this to the.",
                    "label": 0
                },
                {
                    "sent": "Infinite in your program if you have infinitely many constraints.",
                    "label": 0
                },
                {
                    "sent": "Because if we maximize with respect to minus Delta.",
                    "label": 0
                },
                {
                    "sent": "And the DM then entered in too.",
                    "label": 0
                },
                {
                    "sent": "To always better end.",
                    "label": 0
                },
                {
                    "sent": "And HA two large expression containing the.",
                    "label": 0
                },
                {
                    "sent": "I'm an Alpha.",
                    "label": 0
                },
                {
                    "sent": "Get you get into the formulation we had.",
                    "label": 0
                },
                {
                    "sent": "As before, so we can.",
                    "label": 0
                },
                {
                    "sent": "We can use boosting techniques like actually or a boost to also solve this problem OK.",
                    "label": 0
                },
                {
                    "sent": "So this is how the algorithm would would look.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we have again obtained the most cited constraint as as before.",
                    "label": 0
                },
                {
                    "sent": "And what is what is right here is extended.",
                    "label": 0
                },
                {
                    "sent": "This actually boosting specific part.",
                    "label": 0
                },
                {
                    "sent": "You can see the exponential updates here on this on this way it's better which is.",
                    "label": 0
                },
                {
                    "sent": "All you.",
                    "label": 0
                },
                {
                    "sent": "OK, so now.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can find the confined waiting on on this.",
                    "label": 0
                },
                {
                    "sent": "You're in and.",
                    "label": 0
                },
                {
                    "sent": "We can solve this whole college multiple kernel learning problem.",
                    "label": 0
                },
                {
                    "sent": "Now the question arises if I if I have learned if I know have learned all the weights and in this case it's on that time stencilled 1000.",
                    "label": 0
                },
                {
                    "sent": "Weights.",
                    "label": 0
                },
                {
                    "sent": "Then can we?",
                    "label": 0
                },
                {
                    "sent": "Can we rely on these on these weights?",
                    "label": 1
                },
                {
                    "sent": "Cause the waiting might be very unstable.",
                    "label": 0
                },
                {
                    "sent": "If he just commute, if you just choose a different subset of the data for training.",
                    "label": 0
                },
                {
                    "sent": "And so it's important to ask the question which weights are significant.",
                    "label": 1
                },
                {
                    "sent": "And we derive for the statistical test for this, but I don't want to go into into detail for for this test principle.",
                    "label": 0
                },
                {
                    "sent": "For the desert computes.",
                    "label": 0
                },
                {
                    "sent": "Boots up computes, replicates of the data and then solve as protecting machine.",
                    "label": 0
                },
                {
                    "sent": "At this microphone problem for all of these bootstraps and then we can.",
                    "label": 0
                },
                {
                    "sent": "Somehow get in.",
                    "label": 0
                },
                {
                    "sent": "And the probability of whether rate is significant or not.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I can, I will give you an example for this, so we have a toy data set.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a DNA sequences.",
                    "label": 1
                },
                {
                    "sent": "It consists of DNA sequences of length 50.",
                    "label": 1
                },
                {
                    "sent": "And he chose.",
                    "label": 0
                },
                {
                    "sent": "To to hide some motives at position 10 to 16 and 3236.",
                    "label": 0
                },
                {
                    "sent": "And so this is the.",
                    "label": 0
                },
                {
                    "sent": "So it's again this.",
                    "label": 0
                },
                {
                    "sent": "Two class problem.",
                    "label": 0
                },
                {
                    "sent": "We have data where with these motives are hidden and we have just random data and we try to classify classify random data against the.",
                    "label": 0
                },
                {
                    "sent": "From the data with hidden motives.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "We then you don't have 8 * 50 of these string kernels, so one one wait eight weights per position in the kernel, one for each of these K Meyers.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We OK, so we learn computer significance using this bootstrapping type of approach and what you can see here is the case with.",
                    "label": 0
                },
                {
                    "sent": "This noise so again we have to position off the sequence.",
                    "label": 0
                },
                {
                    "sent": "And we have came here the cameras up to.",
                    "label": 0
                },
                {
                    "sent": "My feet.",
                    "label": 0
                },
                {
                    "sent": "So we're looking for matches from from.",
                    "label": 0
                },
                {
                    "sent": "For metrics of length one up two matches of length 8 and specific for each for each position independently, and we have also and also learned these weights which are in independently for each of the positions in the sequence, and what we can see there now is that.",
                    "label": 0
                },
                {
                    "sent": "To just one or two weights are.",
                    "label": 0
                },
                {
                    "sent": "Are important.",
                    "label": 0
                },
                {
                    "sent": "So what is Prodigy is the probability that weight significant?",
                    "label": 0
                },
                {
                    "sent": "And so the brighter the more significant it is.",
                    "label": 0
                },
                {
                    "sent": "So these these two weights are the ones which.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, seems to get Houston in a.",
                    "label": 0
                },
                {
                    "sent": "In a solution.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "However, this is the non noisy case, so we have really clean motives.",
                    "label": 0
                },
                {
                    "sent": "Here is 2 positions.",
                    "label": 0
                },
                {
                    "sent": "If you now randomly substitute.",
                    "label": 0
                },
                {
                    "sent": "Letters in the motives.",
                    "label": 0
                },
                {
                    "sent": "Then from from left to right, we do so we just replies.",
                    "label": 0
                },
                {
                    "sent": "Replace 2, four and six positions, then the kernel.",
                    "label": 0
                },
                {
                    "sent": "Do not use them.",
                    "label": 0
                },
                {
                    "sent": "As long as they're not.",
                    "label": 0
                },
                {
                    "sent": "Do not use such high weights.",
                    "label": 0
                },
                {
                    "sent": "Anymore it will slowly use only on the.",
                    "label": 0
                },
                {
                    "sent": "Only this this lower this lower rates.",
                    "label": 0
                },
                {
                    "sent": "Just because the motives split up due to this random substitutions, however, it will still find.",
                    "label": 0
                },
                {
                    "sent": "The motives to be significant only in.",
                    "label": 0
                },
                {
                    "sent": "In this region now I realize I forgot to say that a upper column is just just short shorts away found to be significant.",
                    "label": 0
                },
                {
                    "sent": "Refer certain threshold source like to the Alpha is 5%.",
                    "label": 0
                },
                {
                    "sent": "It's the same plug, but for an Alpha value of 5%.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I would say this method.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Method works to detect features.",
                    "label": 0
                },
                {
                    "sent": "And as we have seen in this install data set and what we can do is now is we can apply to some real data again to display site task.",
                    "label": 0
                },
                {
                    "sent": "And again we have different rates on this.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's 140 * 10, So it's 1400.",
                    "label": 0
                },
                {
                    "sent": "Occurrences are kernels that are combined.",
                    "label": 0
                },
                {
                    "sent": "And we, I think it went on like 2500 examples only.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "As we can see, the weights straight in front of the supply side, we have found to be to be important, and it's indeed like this that.",
                    "label": 0
                },
                {
                    "sent": "Some biological thing called spices on binds.",
                    "label": 0
                },
                {
                    "sent": "One of the.",
                    "label": 0
                },
                {
                    "sent": "This place had swords.",
                    "label": 0
                },
                {
                    "sent": "So so 3.",
                    "label": 0
                },
                {
                    "sent": "That we expected the method really expected some biological relevant information, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so let's.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come to the conclusion of this talk.",
                    "label": 0
                },
                {
                    "sent": "So if you've developed multiple turn learning algorithm which suitable for large scale.",
                    "label": 1
                },
                {
                    "sent": "Problems so we can train this persuaded Recon and 200,000 examples and it takes about the day.",
                    "label": 0
                },
                {
                    "sent": "It is, it is fast, so this time estimate and seconds.",
                    "label": 1
                },
                {
                    "sent": "And for certain kernels, like in kernels, that will allow you to interpret the support vector machine reside.",
                    "label": 1
                },
                {
                    "sent": "And it is future work to apply this to regression or to feature selection.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's talk.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm very happy to see you.",
                    "label": 0
                },
                {
                    "sent": "Optimizations here we for instance, in my infinite optimizations here is playing such a nice hole according to my idea very promising.",
                    "label": 0
                },
                {
                    "sent": "I tried resetting representation only, also indicated briefly, but I mentioned our officer.",
                    "label": 0
                },
                {
                    "sent": "Evening when you spoke about civilianization of mixed type functions, there's also a natural linkage given possible infinite optimization problems.",
                    "label": 0
                },
                {
                    "sent": "Understand the problem which was considered here is just before when you take some of it and also QWS.",
                    "label": 0
                },
                {
                    "sent": "Sport and at this level and all that, the substance.",
                    "label": 0
                },
                {
                    "sent": "If I didn't make a mistake, so you can present this mean problem, you're coming with this.",
                    "label": 0
                },
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "Do also instead of.",
                    "label": 0
                },
                {
                    "sent": "You objective is just the sum.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Wanted to express my appreciation.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It's starting to.",
                    "label": 0
                },
                {
                    "sent": "You could bring had mentioned space here, and you know that's perfect insight.",
                    "label": 0
                },
                {
                    "sent": "You know you might have a single support vector which single result.",
                    "label": 0
                },
                {
                    "sent": "Just yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, that's true, but.",
                    "label": 0
                },
                {
                    "sent": "Solutions change, but yeah, so that's actually true.",
                    "label": 0
                },
                {
                    "sent": "But if he if you get the same solution over and over again, we have an estimate on higher how reliable this overall rating is.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's better.",
                    "label": 0
                },
                {
                    "sent": "It's better than doing no significance in this at all.",
                    "label": 0
                },
                {
                    "sent": "Solution you know that you're OK because you presumably finding some other almost, but actually I mean at least empirically observed.",
                    "label": 0
                },
                {
                    "sent": "It always finds similar.",
                    "label": 0
                },
                {
                    "sent": "I mean, not, not the same solution.",
                    "label": 0
                },
                {
                    "sent": "If he if he chose different subsets of the data.",
                    "label": 0
                },
                {
                    "sent": "But through similar.",
                    "label": 0
                },
                {
                    "sent": "Similar ways so.",
                    "label": 0
                },
                {
                    "sent": "When you put it in something, another bus pass fire in very high dimensions.",
                    "label": 0
                },
                {
                    "sent": "It looks strange because you could just simply lose your whole solution.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean OK, yeah, but it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's what can happen now.",
                    "label": 0
                }
            ]
        }
    }
}