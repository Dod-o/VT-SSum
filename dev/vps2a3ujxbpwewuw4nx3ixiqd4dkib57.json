{
    "id": "vps2a3ujxbpwewuw4nx3ixiqd4dkib57",
    "title": "IntellAct (2011-14): Intelligent observation and execution of Actions and manipulations",
    "info": {
        "author": [
            "Norbert Kr\u00fcger, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark"
        ],
        "published": "March 14, 2012",
        "recorded": "February 2012",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/cogsys2012_krueger_intelligent/",
    "segmentation": [
        [
            "So the Internet project is running for.",
            "Yeah, approximately."
        ],
        [
            "So enter the email for project is to learn how to execute robot actions and to monitor humans and robot actions.",
            "So it is in a programming by demonstration approach.",
            "So that's what we see here.",
            "There's a human operator, so there's some learning and then it should be transferred to robot execution or to monitor the human operator.",
            "So the particular thing is that learning takes place on a semantic level, so not on a trajectory or motor level.",
            "So it requires seen, understand, seen and action understanding.",
            "So the mapping is supposed to be to be done on a high level."
        ],
        [
            "Hi, semantic level just to get some idea on the structure so we have some sensory input.",
            "We have some kind of mid level representation and then we have a symbolic planning level and send in."
        ],
        [
            "Execution phase we want to go the other way around, so we want to have learned plants and then these become executed."
        ],
        [
            "We have two scenarios, so there's a outer scenarios is kind of an assembly scenario.",
            "This is the platform at Stu.",
            "It's kind of a pretty over determined system, so we have three cameras and actually is not only camera, so it's a connect in stereo.",
            "We can partly circumvent vision problems by using these kind of 60 sensors in the beginning of the project.",
            "We also work in virtual relative, so that hides the high level problems can be.",
            "Addressed directly"
        ],
        [
            "So this is a final task to basically let's robot assembles these kind of crane field benchmark."
        ],
        [
            "Um?",
            "There are five key techniques that I would like to introduce to to achieve so in so the first one is semantic event chains, probabilistic rule learning, probabilistic manipulation functions, and dynamic motor primitives.",
            "So these are for technologies and virtual reality is kind of the tools at the high level guys they cannot say so we need to wait until you give us good inputs so to the television guys so we can start modeling on the on the high levels.",
            "Emede"
        ],
        [
            "So semantic event chain.",
            "Basically you take a stereo image sequence.",
            "Here only more sequences or more images are shown.",
            "Some segmentation is done and then this becomes transfer.",
            "This representation becomes transferred into a graph where here the links between the nodes just represent touch relations.",
            "And touches meant with it.",
            "We have 3D information, so touches meant not in 2D, but in 3D.",
            "So this graph is then can be OK.",
            "So you get a mostly actually here in the grass.",
            "Not much will change because nothing significant has happened in the scene.",
            "Only when there is a significant change when attaching relation has changed.",
            "So then we store actually these graphs and then we represent this graph in matrices.",
            "Where each line represents basically one relation of notes.",
            "Sometimes these matrices become further enhanced by continuous information on Poles.",
            "For example, when this is required for the execution."
        ],
        [
            "Just to give you an idea, in a virtual relative environment how these graphs develop, so we have a number.",
            "This is actually the action plan that is performed here.",
            "The objects and here actually one node corresponds to one object and you see how this kind of.",
            "Semantic event scene develops."
        ],
        [
            "So when you represent it as a as a matrix, you see already that in this representation, for example, you open the door twice.",
            "Actually, you see there is this possible to match that on this level so you don't match it on a trajectory level, but you match it on this rather high level semantic level, so.",
            "Um?"
        ],
        [
            "OK, here just another example.",
            "So in the outer scenario here you see again how this semantic event chain.",
            "Changes so in the beginning, so there's no touch of the hand to the objects.",
            "And here's as attached to the object.",
            "And then here you have attached to to the base plate and then again you.",
            "You leave space.",
            "President leaves the baseplate.",
            "I'm here you see.",
            "So corresponding graphs has I've changed."
        ],
        [
            "Until you see again, so matrix representation and to see if there were two kind.",
            "Sorry I should show the videos that could help.",
            "So this is learning by demonstrations for human shows.",
            "The system what is done.",
            "So here's some picking whole action on the screen field.",
            "Benchmark is performed and here you see the associated matrix and what you see already.",
            "The same actions performed twice, and to see quite a similarity here.",
            "So it is possible to do matching on this level."
        ],
        [
            "The second key technology is probabilistic rule learning, so we want to go from this semantic event chains to learn to learn course effect.",
            "Cost effects and then action learning rules and then finally end."
        ],
        [
            "With plants, so the issues that we can.",
            "Match these kind of semantic inventions.",
            "This matrices to state spaces."
        ],
        [
            "And then we can actually observe from these what kind of actions has been performed so we can make this kind of classification task, and from the large set of observations we are then able to generate plants that then become executed."
        ],
        [
            "And now I'm coming to the execution.",
            "So for the execution there are two key technologies.",
            "So there is manipulation, dentatis or probabilistic manipulation function.",
            "Actually, that's how it should called, and dynamic movement primitives."
        ],
        [
            "So first I would like to explain what this manipulation densities or probabilistic cross functions are.",
            "So basically we represent individual grasp.",
            "Trials is kernels here, so this is work by the new decree at all.",
            "And then we represent the graph successes by some kind of density, which is the sum of these kernels, and that's what you see here and a large.",
            "Hi, large amount of green means as a high likelihood sets this grasp is successful and when you have some kind of working constraints, the idea is that these that you find in maximizing the loud space and this corresponds into optimal grasps.",
            "Important is that these cross densities are actually learned from experience."
        ],
        [
            "In intellect, we want to extend this kind of probabilistic approach of grasp learning to a dexterous grasping with the three finger shock handsets that we're using and also to more complex actions like packing whole or screwing actions."
        ],
        [
            "Here just to remark about where this approach has been applied in an industrial context.",
            "In the context of an echo project.",
            "So here this is a project where we want to introduce learning in been picking, so there is a bin picking company companies that produces a spin picking systems and organs are what is particular for this.",
            "Bin Picking Systems is actually said.",
            "They don't need to perform 100% because they just feed feeding stations.",
            "So for example, for this example it came with 52% grasping performance, so they defined in the beginning grass by hand and foot resent.",
            "It was to learn actually the success chances of these grasps and integrated into grasping strategy of the robot.",
            "And here you see the gain of performance.",
            "We could choose that we can improve this.",
            "We can basically reduce the error by 25% in this industrial setup.",
            "So I think this is a very nice example.",
            "How learning can be introduced in in an industrial context.",
            "So we are quite proud of that actually."
        ],
        [
            "So for ski technology, are dynamic movement primitives that have been already introduced in the context of other project."
        ],
        [
            "And so the problem is now.",
            "Now we want to actually use this dynamic motion primitives to execute these X."
        ],
        [
            "So I want to show you a movie where with which instances learning by demonstration scenario.",
            "But here it is that on the one hand the robot should kind of reproduce emotion, but it should take self collision into account at the same time.",
            "And now I need to switch and I hope that the video works.",
            "And it does, surprisingly.",
            "So here you see now.",
            "The learning demonstration.",
            "Here you see that there has been a collision, but the robot avoid set and it uses this dynamic motion primitives to regulate it by by itself.",
            "K."
        ],
        [
            "OK, so the 5th technology, which is more a shortcut or trick is actually OK. We use virtual, we can make use of virtual relative in the beginning of the process so that we said that we can start.",
            "That's the people doing high level processing can already start with developing set techniques."
        ],
        [
            "What is the status of intellect after one year?",
            "So so this semantic event chain and action recognition on VR, data sources.",
            "Andrew Learnings is this.",
            "This works on VR data.",
            "We have first recordings of learning by demonstration of grasping and picking whole and we have vision working in a rather simplified scenario to be Dina stirred.",
            "The learning of plans in real scenarios for studying of these semantic venturing concept in more realistic setups you've probably seen that.",
            "So we're quite some we meet the life not too difficult for the for the vision system as the generalization of these probabilistic manipulation functions to more complex actions.",
            "And of course the execution of the observed action sequences on the real."
        ],
        [
            "Robot yeah, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the Internet project is running for.",
                    "label": 0
                },
                {
                    "sent": "Yeah, approximately.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So enter the email for project is to learn how to execute robot actions and to monitor humans and robot actions.",
                    "label": 1
                },
                {
                    "sent": "So it is in a programming by demonstration approach.",
                    "label": 0
                },
                {
                    "sent": "So that's what we see here.",
                    "label": 1
                },
                {
                    "sent": "There's a human operator, so there's some learning and then it should be transferred to robot execution or to monitor the human operator.",
                    "label": 0
                },
                {
                    "sent": "So the particular thing is that learning takes place on a semantic level, so not on a trajectory or motor level.",
                    "label": 1
                },
                {
                    "sent": "So it requires seen, understand, seen and action understanding.",
                    "label": 0
                },
                {
                    "sent": "So the mapping is supposed to be to be done on a high level.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, semantic level just to get some idea on the structure so we have some sensory input.",
                    "label": 0
                },
                {
                    "sent": "We have some kind of mid level representation and then we have a symbolic planning level and send in.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Execution phase we want to go the other way around, so we want to have learned plants and then these become executed.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have two scenarios, so there's a outer scenarios is kind of an assembly scenario.",
                    "label": 1
                },
                {
                    "sent": "This is the platform at Stu.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a pretty over determined system, so we have three cameras and actually is not only camera, so it's a connect in stereo.",
                    "label": 0
                },
                {
                    "sent": "We can partly circumvent vision problems by using these kind of 60 sensors in the beginning of the project.",
                    "label": 0
                },
                {
                    "sent": "We also work in virtual relative, so that hides the high level problems can be.",
                    "label": 0
                },
                {
                    "sent": "Addressed directly",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a final task to basically let's robot assembles these kind of crane field benchmark.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There are five key techniques that I would like to introduce to to achieve so in so the first one is semantic event chains, probabilistic rule learning, probabilistic manipulation functions, and dynamic motor primitives.",
                    "label": 1
                },
                {
                    "sent": "So these are for technologies and virtual reality is kind of the tools at the high level guys they cannot say so we need to wait until you give us good inputs so to the television guys so we can start modeling on the on the high levels.",
                    "label": 0
                },
                {
                    "sent": "Emede",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So semantic event chain.",
                    "label": 0
                },
                {
                    "sent": "Basically you take a stereo image sequence.",
                    "label": 0
                },
                {
                    "sent": "Here only more sequences or more images are shown.",
                    "label": 0
                },
                {
                    "sent": "Some segmentation is done and then this becomes transfer.",
                    "label": 0
                },
                {
                    "sent": "This representation becomes transferred into a graph where here the links between the nodes just represent touch relations.",
                    "label": 0
                },
                {
                    "sent": "And touches meant with it.",
                    "label": 0
                },
                {
                    "sent": "We have 3D information, so touches meant not in 2D, but in 3D.",
                    "label": 0
                },
                {
                    "sent": "So this graph is then can be OK.",
                    "label": 0
                },
                {
                    "sent": "So you get a mostly actually here in the grass.",
                    "label": 0
                },
                {
                    "sent": "Not much will change because nothing significant has happened in the scene.",
                    "label": 0
                },
                {
                    "sent": "Only when there is a significant change when attaching relation has changed.",
                    "label": 0
                },
                {
                    "sent": "So then we store actually these graphs and then we represent this graph in matrices.",
                    "label": 0
                },
                {
                    "sent": "Where each line represents basically one relation of notes.",
                    "label": 0
                },
                {
                    "sent": "Sometimes these matrices become further enhanced by continuous information on Poles.",
                    "label": 0
                },
                {
                    "sent": "For example, when this is required for the execution.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to give you an idea, in a virtual relative environment how these graphs develop, so we have a number.",
                    "label": 0
                },
                {
                    "sent": "This is actually the action plan that is performed here.",
                    "label": 0
                },
                {
                    "sent": "The objects and here actually one node corresponds to one object and you see how this kind of.",
                    "label": 0
                },
                {
                    "sent": "Semantic event scene develops.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you represent it as a as a matrix, you see already that in this representation, for example, you open the door twice.",
                    "label": 0
                },
                {
                    "sent": "Actually, you see there is this possible to match that on this level so you don't match it on a trajectory level, but you match it on this rather high level semantic level, so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, here just another example.",
                    "label": 0
                },
                {
                    "sent": "So in the outer scenario here you see again how this semantic event chain.",
                    "label": 0
                },
                {
                    "sent": "Changes so in the beginning, so there's no touch of the hand to the objects.",
                    "label": 0
                },
                {
                    "sent": "And here's as attached to the object.",
                    "label": 0
                },
                {
                    "sent": "And then here you have attached to to the base plate and then again you.",
                    "label": 0
                },
                {
                    "sent": "You leave space.",
                    "label": 0
                },
                {
                    "sent": "President leaves the baseplate.",
                    "label": 0
                },
                {
                    "sent": "I'm here you see.",
                    "label": 0
                },
                {
                    "sent": "So corresponding graphs has I've changed.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Until you see again, so matrix representation and to see if there were two kind.",
                    "label": 0
                },
                {
                    "sent": "Sorry I should show the videos that could help.",
                    "label": 0
                },
                {
                    "sent": "So this is learning by demonstrations for human shows.",
                    "label": 0
                },
                {
                    "sent": "The system what is done.",
                    "label": 0
                },
                {
                    "sent": "So here's some picking whole action on the screen field.",
                    "label": 0
                },
                {
                    "sent": "Benchmark is performed and here you see the associated matrix and what you see already.",
                    "label": 0
                },
                {
                    "sent": "The same actions performed twice, and to see quite a similarity here.",
                    "label": 0
                },
                {
                    "sent": "So it is possible to do matching on this level.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second key technology is probabilistic rule learning, so we want to go from this semantic event chains to learn to learn course effect.",
                    "label": 0
                },
                {
                    "sent": "Cost effects and then action learning rules and then finally end.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With plants, so the issues that we can.",
                    "label": 0
                },
                {
                    "sent": "Match these kind of semantic inventions.",
                    "label": 0
                },
                {
                    "sent": "This matrices to state spaces.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can actually observe from these what kind of actions has been performed so we can make this kind of classification task, and from the large set of observations we are then able to generate plants that then become executed.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now I'm coming to the execution.",
                    "label": 0
                },
                {
                    "sent": "So for the execution there are two key technologies.",
                    "label": 0
                },
                {
                    "sent": "So there is manipulation, dentatis or probabilistic manipulation function.",
                    "label": 0
                },
                {
                    "sent": "Actually, that's how it should called, and dynamic movement primitives.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first I would like to explain what this manipulation densities or probabilistic cross functions are.",
                    "label": 0
                },
                {
                    "sent": "So basically we represent individual grasp.",
                    "label": 0
                },
                {
                    "sent": "Trials is kernels here, so this is work by the new decree at all.",
                    "label": 0
                },
                {
                    "sent": "And then we represent the graph successes by some kind of density, which is the sum of these kernels, and that's what you see here and a large.",
                    "label": 0
                },
                {
                    "sent": "Hi, large amount of green means as a high likelihood sets this grasp is successful and when you have some kind of working constraints, the idea is that these that you find in maximizing the loud space and this corresponds into optimal grasps.",
                    "label": 0
                },
                {
                    "sent": "Important is that these cross densities are actually learned from experience.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In intellect, we want to extend this kind of probabilistic approach of grasp learning to a dexterous grasping with the three finger shock handsets that we're using and also to more complex actions like packing whole or screwing actions.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here just to remark about where this approach has been applied in an industrial context.",
                    "label": 0
                },
                {
                    "sent": "In the context of an echo project.",
                    "label": 0
                },
                {
                    "sent": "So here this is a project where we want to introduce learning in been picking, so there is a bin picking company companies that produces a spin picking systems and organs are what is particular for this.",
                    "label": 0
                },
                {
                    "sent": "Bin Picking Systems is actually said.",
                    "label": 0
                },
                {
                    "sent": "They don't need to perform 100% because they just feed feeding stations.",
                    "label": 0
                },
                {
                    "sent": "So for example, for this example it came with 52% grasping performance, so they defined in the beginning grass by hand and foot resent.",
                    "label": 0
                },
                {
                    "sent": "It was to learn actually the success chances of these grasps and integrated into grasping strategy of the robot.",
                    "label": 0
                },
                {
                    "sent": "And here you see the gain of performance.",
                    "label": 0
                },
                {
                    "sent": "We could choose that we can improve this.",
                    "label": 0
                },
                {
                    "sent": "We can basically reduce the error by 25% in this industrial setup.",
                    "label": 1
                },
                {
                    "sent": "So I think this is a very nice example.",
                    "label": 1
                },
                {
                    "sent": "How learning can be introduced in in an industrial context.",
                    "label": 0
                },
                {
                    "sent": "So we are quite proud of that actually.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for ski technology, are dynamic movement primitives that have been already introduced in the context of other project.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the problem is now.",
                    "label": 0
                },
                {
                    "sent": "Now we want to actually use this dynamic motion primitives to execute these X.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I want to show you a movie where with which instances learning by demonstration scenario.",
                    "label": 0
                },
                {
                    "sent": "But here it is that on the one hand the robot should kind of reproduce emotion, but it should take self collision into account at the same time.",
                    "label": 0
                },
                {
                    "sent": "And now I need to switch and I hope that the video works.",
                    "label": 0
                },
                {
                    "sent": "And it does, surprisingly.",
                    "label": 0
                },
                {
                    "sent": "So here you see now.",
                    "label": 0
                },
                {
                    "sent": "The learning demonstration.",
                    "label": 0
                },
                {
                    "sent": "Here you see that there has been a collision, but the robot avoid set and it uses this dynamic motion primitives to regulate it by by itself.",
                    "label": 0
                },
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the 5th technology, which is more a shortcut or trick is actually OK. We use virtual, we can make use of virtual relative in the beginning of the process so that we said that we can start.",
                    "label": 0
                },
                {
                    "sent": "That's the people doing high level processing can already start with developing set techniques.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is the status of intellect after one year?",
                    "label": 1
                },
                {
                    "sent": "So so this semantic event chain and action recognition on VR, data sources.",
                    "label": 1
                },
                {
                    "sent": "Andrew Learnings is this.",
                    "label": 0
                },
                {
                    "sent": "This works on VR data.",
                    "label": 1
                },
                {
                    "sent": "We have first recordings of learning by demonstration of grasping and picking whole and we have vision working in a rather simplified scenario to be Dina stirred.",
                    "label": 1
                },
                {
                    "sent": "The learning of plans in real scenarios for studying of these semantic venturing concept in more realistic setups you've probably seen that.",
                    "label": 0
                },
                {
                    "sent": "So we're quite some we meet the life not too difficult for the for the vision system as the generalization of these probabilistic manipulation functions to more complex actions.",
                    "label": 1
                },
                {
                    "sent": "And of course the execution of the observed action sequences on the real.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Robot yeah, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}