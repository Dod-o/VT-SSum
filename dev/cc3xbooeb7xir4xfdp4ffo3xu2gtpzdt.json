{
    "id": "cc3xbooeb7xir4xfdp4ffo3xu2gtpzdt",
    "title": "Beam Sampling for the Infinite Hidden Markov Model",
    "info": {
        "author": [
            "Jurgen Van Gael, Computer Laboratory, University of Cambridge"
        ],
        "published": "Aug. 29, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/icml08_van_gael_bsihmm/",
    "segmentation": [
        [
            "Today I'll be giving another talk about the infinite hidden Markov model, and more specifically, I'm going to introduce a new inference algorithm which which we find works really well, and this is work together with Eunice Saatchi, Uitm, Zubin Garg."
        ],
        [
            "Money.",
            "So just to give a bit of context, so we're thinking about time series data here, and more specifically discrete time.",
            "So the hidden Markov model has four 40 years been like a tremendous success in, you know, various number of applications and one of the reasons I would claim that that is it has been successful.",
            "I think is certainly because the the inference algorithms we know Baum Welch and forward backward are very fast inference algorithms."
        ],
        [
            "And just to set the stage and to get everybody on the same page for the notation that I'll be using, so I'll be when I talk about the hidden Markov model.",
            "So at the center of this hidden Markov model we have this hidden chain of states which I will denote with S. Sub.",
            "You know the time step and then a chain of observations why, which I also indexed by by some time T Now central to this hidden Markov model.",
            "Is this transition matrix and the transition matrix I will denote by a matrix \u03c0.",
            "So by J and paisa by Jay means what's the probability of going from state I to stay J?",
            "And then you know, of course, the hidden Markov model has to be augmented with some observation model, and for that I will work in the abstract, and so an observation why is generated by some probability distribution F, which could be, you know, a lot of things, multinomial's normal distributions or more exotic things, But essentially is that it's parameterized by some vector Phi that's indexed by the state that we're in at that point in time T. So the parameters of this hidden Markov model is the number of states that we can be in hidden States and then the transition matrix and the."
        ],
        [
            "Parameters of our observation model.",
            "Now, one of the classic problems with these hidden Markov models is that we you know we have to determine the number of hidden States and the number of hidden states.",
            "Well, there's you know, in some cases we can fix them.",
            "In other cases we might have to guess or learn them, and so the infinite hidden Markov model is 1 specific model that allows you to have an unbounded number of States and you're learning these.",
            "This from your data.",
            "And the hidden.",
            "So the infinite hidden Markov model.",
            "Or as you know, as it's also known as the HTP.",
            "Hmm, was introduced in 2002, where we had the model, but we had only an approximate inference scheme for the model, and in 2006 by 10 all there was a more theoretical foundation, and we had a Gibbs sampler was introduced for this model.",
            "So again, this is still sort of the background, the."
        ],
        [
            "Background information and again to get everybody on the same page, the infinite hidden Markov model that I'll be using here.",
            "It looks very similar, at least this part looks very similar to the hidden Markov model.",
            "So what we have is again we have a transition matrix which is which we denote with \u03c0 or we denote the Rose with Pi sub K and then we have an observation parameter which we do not with fight sub K again and the.",
            "Parameter the hyperparameters for this model are the following.",
            "So first of all, we have a prior distribution on the parameters of our observation model.",
            "We have a. Parameter which controls the our prior information on the number of states that we are trying to learn, which is the parameter gamma.",
            "We have a parameter Alpha which controls how similar the transition or the rows of the transition matrix are to each other or are sparse.",
            "They are and then we have sort of the same thing as in the hidden Markov model so.",
            "Crucial to this, to this infinite hidden Markov model is that this transition matrix is this infinite object that has an infinite number of rows, infinite number of columns, and we're trying."
        ],
        [
            "Learn it.",
            "Now here's the motivation for for the talking.",
            "For for the work we did.",
            "So we wanted to do inferencing.",
            "These hidden Markov models and when we do inference we want to compute posterior distributions either on the hidden states or on the parameters and for hidden Markov models.",
            "As I said before, we can use dynamic programming and it's extreme.",
            "I mean it's fast.",
            "Now for infinite hidden Markov models, so far we only knew how to do Gibbs sampling, and if you recall, I mean some people said it before today for a Gibbs sampler.",
            "What it does is it?",
            "It takes one specific random variable, it conditions it on all the other random variables and it updates it from the conditional distribution.",
            "Now if you think about it for time series, that's a bit weird because in time series we often have strong correlations.",
            "If you know you know the stock market price.",
            "If you know the stock yesterday in the stock tomorrow you have a good guess of what the stock is going to be today, probably.",
            "And we know that Gibbs sampling is slower or slows down when we have these strong correlations.",
            "So it's a bit weird to do Gibbs sampling in a time series model and for that reason we are trying to introduce the dynamic program idea for the infinite hidden Markov model.",
            "So crucial here is if we want to make these nonparametric models usable in the real world.",
            "We really need to have good inference methods, and that's what we're trying to do here."
        ],
        [
            "No.",
            "I will give you one specific dynamic programming algorithm that's been used for the hidden Markov model, which is called the forward filtering backwards sampling algorithm, and we'll see how this how we can adapt this to the infinite to the infinite Markov model.",
            "So the idea here is the following.",
            "So we we want to compute is we want to compute the conditional probability of our hidden States and the first thing that we do is we run a forward filtering step, so we know that the if we start in this dummy state, say of one with probability one and then for each time step we can compute the conditional probability given the observation so far.",
            "And if you run through the math, then you see that it's.",
            "Is proportional to your observations, which makes sense to your transitions and to all the possible previous states you could be in computing this thing is what we need to do it for all time steps.",
            "Order T and then we need to do it.",
            "This can be in case states that adds a factor of K and then we need to do this is a sum over case it's ordered TK Square.",
            "If we have these conditional probabilities then well for the last time so that we can just sample it 'cause we know it's conditioned on all the evidence.",
            "We have all the observations and then we can just.",
            "Backward sample the states using the following formula, so this algorithm gives us a way that if we have the parameters, it allows us to sample the whole chain in one go or sorry the whole."
        ],
        [
            "State sequence in one go.",
            "No, OK can we?",
            "Can we just naively apply this to the infinite Markov model?",
            "While the answer is no, because we have an infinite number of states, so we can do that forward filtering computation.",
            "So one idea that we heard earlier today is to truncate the transition matrix and then run the dynamic program.",
            "Now the idea that I want to introduce is the beam sampler and what we will show is that this approximation of truncation is, well, it's only approximately correct, and it's unnecessary because by what we can do adaptive truncation and the adaptive truncation that I'll show you is an exact algorithm, so you know.",
            "It's a sampling algorithm, so if we have enough iterations it will sample from the true or the exact."
        ],
        [
            "Posterior distribution, so here's the ID.",
            "So here I've.",
            "Depicted a transition matrix, and so these these the height of these columns show what's the transition of, say, state one to state one state, one to stay 6, etc etc.",
            "So at every time step you know we can look at the transition matrix and compute what's the probability of transitioning from St to SD plus one.",
            "Now The thing is, in our sample are only going to store a finite representation of this transition matrix and you know the reason we can do that is because we're not.",
            "If we have only T lengthy Markov model, we're never going to use an infinite number of states, so we can only we can do with a finite representation of this transition matrix.",
            "So what we do at time step T is we look at given our current sample of S. We look at the transition that we took from St to S, T + 1 and imagine it's this blue guy here.",
            "Then the next thing we do is we introduce an auxiliary variable and we sample it uniformly from zero to the transition.",
            "So we sampled uniformly from the height of this of this bar.",
            "And the key observation here is that if since we know that these rows of this transition matrix, I mean their probability distribution, so they have to sum up to one.",
            "So the key observation here is that if we take this slice U, there can only be a finite number of transitions that are higher than this slice, and that's the picture here.",
            "So we slice it up and we see that only a finite number of these transitions stick out.",
            "And now what we're going to do is we're going to run the forward backward.",
            "Or the forward filtering algorithm and we're going to only going to consider the transitions that stick out of this slice, and that will be of course a finite number of them.",
            "As I said before."
        ],
        [
            "Alright, so one thing that you could ask is, well, you're introducing some new variables.",
            "Is this?",
            "Is this a new model?",
            "And that's not the case because so this is just a snapshot of the of the model.",
            "So you see the transition matrix, your hidden states, your observations, your parameters, and we're adding these auxiliary variables you here and they all they depend on the hidden States and on the transition matrix.",
            "Now we're not changing the model because if we integrate out these using if you remember the rules of graphical models.",
            "Then we can just integrate this thing out and you know the whole model.",
            "There's no extra correlations in the model, so the model stays the same, so it's extra."
        ],
        [
            "Cables don't don't really matter.",
            "OK, so here's the algorithm.",
            "So we initialize with some random hidden States and we initialize the parameters and then we start iterating our sampler and we sample.",
            "We first sample all the auxiliary variables.",
            "You, then we compute we want to compute the conditional probability of our hidden state sequence given our variables UNR observations.",
            "Now this is very similar to the finite version, but for one big difference.",
            "So this is sort of like the equation that you saw before, but I want to draw your attention to this.",
            "To the summation here.",
            "So if you do the math and you can find that in the paper you will see that you only have to sum up for in order to compute the conditional probability of your hidden state at time T. You only have to sum up overall states at time T minus one such that the transition from S T -- 1 to St is larger than your slice and that essentially truncates the infinite computation to a finite one, and again then we just do the backward filtering step.",
            "Which is again just a finite computation, and then the resampling of the parameters of the model is exactly the same as in the."
        ],
        [
            "The Gibbs sampling algorithm.",
            "So here are the properties of the of the sampler.",
            "So first of all, the sampler adaptively truncates this infinitely large transition matrix.",
            "Also, one thing that you can see."
        ],
        [
            "From this picture here is that it also sort of sparse affies the transition matrix that you're considering so.",
            "This, you know, in the hidden in the hidden Markov model, if you have K states, there's K squared transitions that you're considering.",
            "In this case there will be less, but it's hard."
        ],
        [
            "See exactly how many, but it's sparsified the dynamic program, the other properties it resamples, the whole state sequence in one go, and this is very different from the deep sample and allows us to sort of work around these strong correlations.",
            "A1 property that you know is different from the Gibson.",
            "Very different from the sample, is that in the deep sample you can sort of integrate out your whole observation model.",
            "If everything is nice and conjugate in the beam sampler."
        ],
        [
            "In order to run this dynamic program, you need to compute these likelihoods and so."
        ],
        [
            "You have to instantiate all the variables, which is a good thing because you can then also run the beam sampler on non conjugate models very easy."
        ],
        [
            "Sleep.",
            "So here's some experimental evidence that this is a good thing to do.",
            "So what we did is we generated synthetic data from a hidden Markov model, and we introduced strong negative correlations.",
            "So the hidden state sequence that ruined state sequence was sort of like 12341234, etc etc.",
            "We what we compute is we run the inference algorithms and what we compute is for one specific sample we compute the error to the true state sequence and we just compute that error greedily.",
            "What you see here is the performance of the beam sampler using three different priors and the performance of the Gibbs sampler using the same three priors and as you can see, this is much more.",
            "This is much, much faster convergence.",
            "One other thing that I want to draw your attention to is the bottom plot.",
            "So remember I said the slice the auxiliary variable sparsified the transition matrix.",
            "Now you can ask yourself or look at empirically like how sparse is this.",
            "Actually what we did is for each.",
            "Time step we computed the average over the number of transitions that you're considering.",
            "So say if you have 10 states, you know in the HMM you would consider 1010 transitions.",
            "Now what we see here in in our sampling algorithm is that in the beginning when we initialize everything randomly, we kind of use quite a lot of these transitions.",
            "But as soon as we kind of get a good idea of what's going on, then we almost consider a bit more than one.",
            "Transition on average, which essentially means that the inference scheme that we just proposed the dynamic program doesn't have a computational complexity of order TK Square, but it has more like a complexity like order TK, which is like the Gibbs sampler.",
            "So this is extremely interesting for."
        ],
        [
            "Or in practice?",
            "Here's a second application.",
            "We tried our algorithm on a changepoint detection problem where we had 4050 noisy measurements from an NMR device and we created a created an infinite Markov model where the observation were observations were student T distributions.",
            "So with the student the priors on the student T distribution on the parameters of the student T was a normal distribution, so this is a non conjugate model.",
            "And we ran the beam sampler and this is just a snapshot of what it gives you after 8000 iterations.",
            "So you can see it finds reasonable segmentations of the of the."
        ],
        [
            "Of the data.",
            "Now here's a more interesting plot.",
            "What we did is we computed the probability of two data points being in the same cluster now.",
            "On the left you can find you see the average over the first 5 samples that we draw.",
            "We drew an on the right for the last 30 samples that we do and the burning there was 5000 burning durations and 1000 iterations between each each sample.",
            "Now as you can see, after the first 5 iterations, the Gibbs sample hasn't even discovered any structure at all, while the beam sample and they were started from the same initialization.",
            "By the way, the Beam Sampler has certainly discovered some structure.",
            "Now it's more interesting is if you look at the last 30 samples here is that these areas are either black or white, which means that two data points in the sequence are either always in the same segment or never in the same segment, which is, you know, seems unlikely because that you know the uncertainty here is 0.",
            "Now if you look at what the Beam sampler produces is an it's hard to see from this plot, but on the paper you can see more clearly there's some white areas, but there's certainly also some more greyish.",
            "Areas, which means that the beam sampler says, well, some of these data points are only in the same cluster.",
            "You know four times or 5 * 3040% or 50% of the time, which is interesting because the beam sampler by resampling these whole state sequences at once has seems to have a much better ability of modeling the uncertainty in the state sequences."
        ],
        [
            "So the last experiment that we did was an experiment on text prediction and this was more to compare it to the finite hidden Markov model.",
            "So what we did was we trained an infinite hmm and a finite hidden Markov model on 1000 characters from the first chapter of Alice in Wonderland, and we looked at just looked at the 35 characters.",
            "So this is the output alphabet.",
            "What we did is we tested on the 1000 subsequent characters and then we compute the predictive log likelihood of the predictions.",
            "What we find is so we trained the hidden Markov model using Variational Bayes to for it to be some kind of Fair comparison and what you see here is that the variational Bayes hmm does a pretty good job.",
            "It gets really close to the performance of the infinite Markov model, but I mean I think the market model stands out here.",
            "Even if you look at the optimal number of states that we selected for the variational Bayes training."
        ],
        [
            "Alright, so what's the conclusion?",
            "Would that want you to get it?",
            "Go get away with in this talk.",
            "So what we did is we introduce dynamic program based inference for the infinite hidden Markov model and we have the adaptive truncation is useful for two reasons.",
            "First, we're sampling from the true posterior, so it's an exact sampling algorithm and it's pretty fast.",
            "Second thing is that because of the dynamic programming.",
            "Sorry, because of the adaptive truncation.",
            "Our dynamic program becomes sparse and it's extremely fast.",
            "It's comperable to the Gibbs sampler, and finally, you know this.",
            "This algorithm is also works perfectly fine for non conjugate models.",
            "And our last experiment showed that the infinite hidden Markov model is in certain cases certainly a good alternative for the HMM, even if you train it with variational Bayes.",
            "So the key concept here is that I think that the beam sampler is first inference algorithm that we know of.",
            "That really makes the inference in the infant hidden Markov model.",
            "I think practical enough to run it on really long sequences and really large datasets.",
            "And to conclude, all the software for the beam samplers available on my website.",
            "So feel free to go and download it and play around with it.",
            "So thank you very much."
        ],
        [
            "Questions.",
            "No, we didn't do any Gibbs sampling."
        ],
        [
            "We did do Gibbs sampling on the infinite Market Mall and that was I mean they.",
            "Rather than having.",
            "Fair enough, yeah, we didn't do that experiment.",
            "If it so happens that use it, it's become very close to 0.",
            "A whole bunch of states so so am I to this day what you doing correctly is that most of the time you'll be OK.",
            "But then once in awhile you just show.",
            "Whoa, just I mean that did the just joking probabilities is really, really small.",
            "It's not 0 sure.",
            "Yeah, absolutely now that's."
        ],
        [
            "It's a good question because in here I chose this uniform distribution.",
            "But as it turns out, this is could be if you want it.",
            "I mean, this works for us in a lot of cases, but it's not critical.",
            "You could choose a different distribution here.",
            "That sort of biases you toward values closer to \u03c0 or values closer to 0 using, say, a beta distribution, and this expression would be a tiny little bit more complicated, but it's just one extra multiplication, and in that sense you can sort of.",
            "Also, if you want tweak.",
            "The sparsity of your sampling method and you know, increase the consider more states or so.",
            "There's some tweaking that you can do, but for all the experiments we've done, this uniform distribution work really, really well, and you know we didn't have very much trouble with.",
            "You know, suddenly getting 100 million states or something like that so.",
            "So.",
            "You know the.",
            "Something small enough, special right?",
            "Compared to which sampling method?",
            "These a truncated matrix.",
            "Sure, and so we haven't done the experiment.",
            "Certainly something that we should do compared to the truncated version.",
            "Now I mean certainly in a model where you want to learn a number of unbounded states, well, it's nice if you can.",
            "Also, in your inference algorithm, have.",
            "Sorry, say it again.",
            "Yeah, so it's.",
            "I think it's nice that you can have this.",
            "This number of states be flexible during the inference algorithm and then again you get this gain from the slice.",
            "The auxiliary variable that your transition matrix is sparsified.",
            "So the dynamic program is also much faster than the dynamic program if you just truncate, because if you should just truncate, you have to run the order TK square algorithm, especially if you have a large K. You know this this could be problematic and really slow down the inference, so I think.",
            "You sort of winning both ways.",
            "Which is.",
            "This is a slight sample, so presumably I'm gonna send directly through just actually applied toward reaching absolutely an.",
            "We know what the exact give sample looks like.",
            "It was blocked.",
            "Examples like we got the idea what this life sample for nation member.",
            "And compare it in what sense compared to in like?",
            "So I I mean, I did the experiments an actually the code for that is is also on the website, so you could try it out and I can't remember the exact results.",
            "Now this is a very interesting question in also a different way because this fact that you're sort of sparsifying the transition matrix using the beam sampler is also interesting for learning really large hidden Markov models.",
            "If you have really large state spaces you're only considering you know a smaller number of them, and you know that's something that we've been playing a little bit with it.",
            "It's not trivial, but we've been playing a little bit with that too.",
            "So, but yeah, I can't remember the numbers off the top of my head, but."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today I'll be giving another talk about the infinite hidden Markov model, and more specifically, I'm going to introduce a new inference algorithm which which we find works really well, and this is work together with Eunice Saatchi, Uitm, Zubin Garg.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Money.",
                    "label": 0
                },
                {
                    "sent": "So just to give a bit of context, so we're thinking about time series data here, and more specifically discrete time.",
                    "label": 1
                },
                {
                    "sent": "So the hidden Markov model has four 40 years been like a tremendous success in, you know, various number of applications and one of the reasons I would claim that that is it has been successful.",
                    "label": 0
                },
                {
                    "sent": "I think is certainly because the the inference algorithms we know Baum Welch and forward backward are very fast inference algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just to set the stage and to get everybody on the same page for the notation that I'll be using, so I'll be when I talk about the hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "So at the center of this hidden Markov model we have this hidden chain of states which I will denote with S. Sub.",
                    "label": 0
                },
                {
                    "sent": "You know the time step and then a chain of observations why, which I also indexed by by some time T Now central to this hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "Is this transition matrix and the transition matrix I will denote by a matrix \u03c0.",
                    "label": 0
                },
                {
                    "sent": "So by J and paisa by Jay means what's the probability of going from state I to stay J?",
                    "label": 0
                },
                {
                    "sent": "And then you know, of course, the hidden Markov model has to be augmented with some observation model, and for that I will work in the abstract, and so an observation why is generated by some probability distribution F, which could be, you know, a lot of things, multinomial's normal distributions or more exotic things, But essentially is that it's parameterized by some vector Phi that's indexed by the state that we're in at that point in time T. So the parameters of this hidden Markov model is the number of states that we can be in hidden States and then the transition matrix and the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parameters of our observation model.",
                    "label": 0
                },
                {
                    "sent": "Now, one of the classic problems with these hidden Markov models is that we you know we have to determine the number of hidden States and the number of hidden states.",
                    "label": 0
                },
                {
                    "sent": "Well, there's you know, in some cases we can fix them.",
                    "label": 0
                },
                {
                    "sent": "In other cases we might have to guess or learn them, and so the infinite hidden Markov model is 1 specific model that allows you to have an unbounded number of States and you're learning these.",
                    "label": 1
                },
                {
                    "sent": "This from your data.",
                    "label": 0
                },
                {
                    "sent": "And the hidden.",
                    "label": 0
                },
                {
                    "sent": "So the infinite hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "Or as you know, as it's also known as the HTP.",
                    "label": 0
                },
                {
                    "sent": "Hmm, was introduced in 2002, where we had the model, but we had only an approximate inference scheme for the model, and in 2006 by 10 all there was a more theoretical foundation, and we had a Gibbs sampler was introduced for this model.",
                    "label": 0
                },
                {
                    "sent": "So again, this is still sort of the background, the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Background information and again to get everybody on the same page, the infinite hidden Markov model that I'll be using here.",
                    "label": 0
                },
                {
                    "sent": "It looks very similar, at least this part looks very similar to the hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "So what we have is again we have a transition matrix which is which we denote with \u03c0 or we denote the Rose with Pi sub K and then we have an observation parameter which we do not with fight sub K again and the.",
                    "label": 0
                },
                {
                    "sent": "Parameter the hyperparameters for this model are the following.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we have a prior distribution on the parameters of our observation model.",
                    "label": 0
                },
                {
                    "sent": "We have a. Parameter which controls the our prior information on the number of states that we are trying to learn, which is the parameter gamma.",
                    "label": 0
                },
                {
                    "sent": "We have a parameter Alpha which controls how similar the transition or the rows of the transition matrix are to each other or are sparse.",
                    "label": 0
                },
                {
                    "sent": "They are and then we have sort of the same thing as in the hidden Markov model so.",
                    "label": 0
                },
                {
                    "sent": "Crucial to this, to this infinite hidden Markov model is that this transition matrix is this infinite object that has an infinite number of rows, infinite number of columns, and we're trying.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learn it.",
                    "label": 0
                },
                {
                    "sent": "Now here's the motivation for for the talking.",
                    "label": 0
                },
                {
                    "sent": "For for the work we did.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to do inferencing.",
                    "label": 0
                },
                {
                    "sent": "These hidden Markov models and when we do inference we want to compute posterior distributions either on the hidden states or on the parameters and for hidden Markov models.",
                    "label": 0
                },
                {
                    "sent": "As I said before, we can use dynamic programming and it's extreme.",
                    "label": 0
                },
                {
                    "sent": "I mean it's fast.",
                    "label": 0
                },
                {
                    "sent": "Now for infinite hidden Markov models, so far we only knew how to do Gibbs sampling, and if you recall, I mean some people said it before today for a Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "What it does is it?",
                    "label": 0
                },
                {
                    "sent": "It takes one specific random variable, it conditions it on all the other random variables and it updates it from the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Now if you think about it for time series, that's a bit weird because in time series we often have strong correlations.",
                    "label": 0
                },
                {
                    "sent": "If you know you know the stock market price.",
                    "label": 0
                },
                {
                    "sent": "If you know the stock yesterday in the stock tomorrow you have a good guess of what the stock is going to be today, probably.",
                    "label": 0
                },
                {
                    "sent": "And we know that Gibbs sampling is slower or slows down when we have these strong correlations.",
                    "label": 0
                },
                {
                    "sent": "So it's a bit weird to do Gibbs sampling in a time series model and for that reason we are trying to introduce the dynamic program idea for the infinite hidden Markov model.",
                    "label": 1
                },
                {
                    "sent": "So crucial here is if we want to make these nonparametric models usable in the real world.",
                    "label": 0
                },
                {
                    "sent": "We really need to have good inference methods, and that's what we're trying to do here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "I will give you one specific dynamic programming algorithm that's been used for the hidden Markov model, which is called the forward filtering backwards sampling algorithm, and we'll see how this how we can adapt this to the infinite to the infinite Markov model.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is the following.",
                    "label": 0
                },
                {
                    "sent": "So we we want to compute is we want to compute the conditional probability of our hidden States and the first thing that we do is we run a forward filtering step, so we know that the if we start in this dummy state, say of one with probability one and then for each time step we can compute the conditional probability given the observation so far.",
                    "label": 0
                },
                {
                    "sent": "And if you run through the math, then you see that it's.",
                    "label": 0
                },
                {
                    "sent": "Is proportional to your observations, which makes sense to your transitions and to all the possible previous states you could be in computing this thing is what we need to do it for all time steps.",
                    "label": 0
                },
                {
                    "sent": "Order T and then we need to do it.",
                    "label": 0
                },
                {
                    "sent": "This can be in case states that adds a factor of K and then we need to do this is a sum over case it's ordered TK Square.",
                    "label": 0
                },
                {
                    "sent": "If we have these conditional probabilities then well for the last time so that we can just sample it 'cause we know it's conditioned on all the evidence.",
                    "label": 0
                },
                {
                    "sent": "We have all the observations and then we can just.",
                    "label": 0
                },
                {
                    "sent": "Backward sample the states using the following formula, so this algorithm gives us a way that if we have the parameters, it allows us to sample the whole chain in one go or sorry the whole.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "State sequence in one go.",
                    "label": 0
                },
                {
                    "sent": "No, OK can we?",
                    "label": 0
                },
                {
                    "sent": "Can we just naively apply this to the infinite Markov model?",
                    "label": 1
                },
                {
                    "sent": "While the answer is no, because we have an infinite number of states, so we can do that forward filtering computation.",
                    "label": 0
                },
                {
                    "sent": "So one idea that we heard earlier today is to truncate the transition matrix and then run the dynamic program.",
                    "label": 0
                },
                {
                    "sent": "Now the idea that I want to introduce is the beam sampler and what we will show is that this approximation of truncation is, well, it's only approximately correct, and it's unnecessary because by what we can do adaptive truncation and the adaptive truncation that I'll show you is an exact algorithm, so you know.",
                    "label": 1
                },
                {
                    "sent": "It's a sampling algorithm, so if we have enough iterations it will sample from the true or the exact.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Posterior distribution, so here's the ID.",
                    "label": 0
                },
                {
                    "sent": "So here I've.",
                    "label": 0
                },
                {
                    "sent": "Depicted a transition matrix, and so these these the height of these columns show what's the transition of, say, state one to state one state, one to stay 6, etc etc.",
                    "label": 0
                },
                {
                    "sent": "So at every time step you know we can look at the transition matrix and compute what's the probability of transitioning from St to SD plus one.",
                    "label": 1
                },
                {
                    "sent": "Now The thing is, in our sample are only going to store a finite representation of this transition matrix and you know the reason we can do that is because we're not.",
                    "label": 1
                },
                {
                    "sent": "If we have only T lengthy Markov model, we're never going to use an infinite number of states, so we can only we can do with a finite representation of this transition matrix.",
                    "label": 1
                },
                {
                    "sent": "So what we do at time step T is we look at given our current sample of S. We look at the transition that we took from St to S, T + 1 and imagine it's this blue guy here.",
                    "label": 0
                },
                {
                    "sent": "Then the next thing we do is we introduce an auxiliary variable and we sample it uniformly from zero to the transition.",
                    "label": 0
                },
                {
                    "sent": "So we sampled uniformly from the height of this of this bar.",
                    "label": 0
                },
                {
                    "sent": "And the key observation here is that if since we know that these rows of this transition matrix, I mean their probability distribution, so they have to sum up to one.",
                    "label": 1
                },
                {
                    "sent": "So the key observation here is that if we take this slice U, there can only be a finite number of transitions that are higher than this slice, and that's the picture here.",
                    "label": 0
                },
                {
                    "sent": "So we slice it up and we see that only a finite number of these transitions stick out.",
                    "label": 0
                },
                {
                    "sent": "And now what we're going to do is we're going to run the forward backward.",
                    "label": 0
                },
                {
                    "sent": "Or the forward filtering algorithm and we're going to only going to consider the transitions that stick out of this slice, and that will be of course a finite number of them.",
                    "label": 0
                },
                {
                    "sent": "As I said before.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so one thing that you could ask is, well, you're introducing some new variables.",
                    "label": 0
                },
                {
                    "sent": "Is this?",
                    "label": 0
                },
                {
                    "sent": "Is this a new model?",
                    "label": 0
                },
                {
                    "sent": "And that's not the case because so this is just a snapshot of the of the model.",
                    "label": 0
                },
                {
                    "sent": "So you see the transition matrix, your hidden states, your observations, your parameters, and we're adding these auxiliary variables you here and they all they depend on the hidden States and on the transition matrix.",
                    "label": 0
                },
                {
                    "sent": "Now we're not changing the model because if we integrate out these using if you remember the rules of graphical models.",
                    "label": 0
                },
                {
                    "sent": "Then we can just integrate this thing out and you know the whole model.",
                    "label": 1
                },
                {
                    "sent": "There's no extra correlations in the model, so the model stays the same, so it's extra.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cables don't don't really matter.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we initialize with some random hidden States and we initialize the parameters and then we start iterating our sampler and we sample.",
                    "label": 0
                },
                {
                    "sent": "We first sample all the auxiliary variables.",
                    "label": 0
                },
                {
                    "sent": "You, then we compute we want to compute the conditional probability of our hidden state sequence given our variables UNR observations.",
                    "label": 0
                },
                {
                    "sent": "Now this is very similar to the finite version, but for one big difference.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of like the equation that you saw before, but I want to draw your attention to this.",
                    "label": 0
                },
                {
                    "sent": "To the summation here.",
                    "label": 0
                },
                {
                    "sent": "So if you do the math and you can find that in the paper you will see that you only have to sum up for in order to compute the conditional probability of your hidden state at time T. You only have to sum up overall states at time T minus one such that the transition from S T -- 1 to St is larger than your slice and that essentially truncates the infinite computation to a finite one, and again then we just do the backward filtering step.",
                    "label": 0
                },
                {
                    "sent": "Which is again just a finite computation, and then the resampling of the parameters of the model is exactly the same as in the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The Gibbs sampling algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here are the properties of the of the sampler.",
                    "label": 0
                },
                {
                    "sent": "So first of all, the sampler adaptively truncates this infinitely large transition matrix.",
                    "label": 1
                },
                {
                    "sent": "Also, one thing that you can see.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From this picture here is that it also sort of sparse affies the transition matrix that you're considering so.",
                    "label": 0
                },
                {
                    "sent": "This, you know, in the hidden in the hidden Markov model, if you have K states, there's K squared transitions that you're considering.",
                    "label": 0
                },
                {
                    "sent": "In this case there will be less, but it's hard.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See exactly how many, but it's sparsified the dynamic program, the other properties it resamples, the whole state sequence in one go, and this is very different from the deep sample and allows us to sort of work around these strong correlations.",
                    "label": 1
                },
                {
                    "sent": "A1 property that you know is different from the Gibson.",
                    "label": 0
                },
                {
                    "sent": "Very different from the sample, is that in the deep sample you can sort of integrate out your whole observation model.",
                    "label": 1
                },
                {
                    "sent": "If everything is nice and conjugate in the beam sampler.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to run this dynamic program, you need to compute these likelihoods and so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have to instantiate all the variables, which is a good thing because you can then also run the beam sampler on non conjugate models very easy.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sleep.",
                    "label": 0
                },
                {
                    "sent": "So here's some experimental evidence that this is a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we generated synthetic data from a hidden Markov model, and we introduced strong negative correlations.",
                    "label": 1
                },
                {
                    "sent": "So the hidden state sequence that ruined state sequence was sort of like 12341234, etc etc.",
                    "label": 0
                },
                {
                    "sent": "We what we compute is we run the inference algorithms and what we compute is for one specific sample we compute the error to the true state sequence and we just compute that error greedily.",
                    "label": 0
                },
                {
                    "sent": "What you see here is the performance of the beam sampler using three different priors and the performance of the Gibbs sampler using the same three priors and as you can see, this is much more.",
                    "label": 0
                },
                {
                    "sent": "This is much, much faster convergence.",
                    "label": 0
                },
                {
                    "sent": "One other thing that I want to draw your attention to is the bottom plot.",
                    "label": 0
                },
                {
                    "sent": "So remember I said the slice the auxiliary variable sparsified the transition matrix.",
                    "label": 0
                },
                {
                    "sent": "Now you can ask yourself or look at empirically like how sparse is this.",
                    "label": 0
                },
                {
                    "sent": "Actually what we did is for each.",
                    "label": 1
                },
                {
                    "sent": "Time step we computed the average over the number of transitions that you're considering.",
                    "label": 0
                },
                {
                    "sent": "So say if you have 10 states, you know in the HMM you would consider 1010 transitions.",
                    "label": 0
                },
                {
                    "sent": "Now what we see here in in our sampling algorithm is that in the beginning when we initialize everything randomly, we kind of use quite a lot of these transitions.",
                    "label": 1
                },
                {
                    "sent": "But as soon as we kind of get a good idea of what's going on, then we almost consider a bit more than one.",
                    "label": 0
                },
                {
                    "sent": "Transition on average, which essentially means that the inference scheme that we just proposed the dynamic program doesn't have a computational complexity of order TK Square, but it has more like a complexity like order TK, which is like the Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "So this is extremely interesting for.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or in practice?",
                    "label": 0
                },
                {
                    "sent": "Here's a second application.",
                    "label": 0
                },
                {
                    "sent": "We tried our algorithm on a changepoint detection problem where we had 4050 noisy measurements from an NMR device and we created a created an infinite Markov model where the observation were observations were student T distributions.",
                    "label": 0
                },
                {
                    "sent": "So with the student the priors on the student T distribution on the parameters of the student T was a normal distribution, so this is a non conjugate model.",
                    "label": 0
                },
                {
                    "sent": "And we ran the beam sampler and this is just a snapshot of what it gives you after 8000 iterations.",
                    "label": 1
                },
                {
                    "sent": "So you can see it finds reasonable segmentations of the of the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the data.",
                    "label": 0
                },
                {
                    "sent": "Now here's a more interesting plot.",
                    "label": 0
                },
                {
                    "sent": "What we did is we computed the probability of two data points being in the same cluster now.",
                    "label": 1
                },
                {
                    "sent": "On the left you can find you see the average over the first 5 samples that we draw.",
                    "label": 0
                },
                {
                    "sent": "We drew an on the right for the last 30 samples that we do and the burning there was 5000 burning durations and 1000 iterations between each each sample.",
                    "label": 0
                },
                {
                    "sent": "Now as you can see, after the first 5 iterations, the Gibbs sample hasn't even discovered any structure at all, while the beam sample and they were started from the same initialization.",
                    "label": 0
                },
                {
                    "sent": "By the way, the Beam Sampler has certainly discovered some structure.",
                    "label": 0
                },
                {
                    "sent": "Now it's more interesting is if you look at the last 30 samples here is that these areas are either black or white, which means that two data points in the sequence are either always in the same segment or never in the same segment, which is, you know, seems unlikely because that you know the uncertainty here is 0.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at what the Beam sampler produces is an it's hard to see from this plot, but on the paper you can see more clearly there's some white areas, but there's certainly also some more greyish.",
                    "label": 0
                },
                {
                    "sent": "Areas, which means that the beam sampler says, well, some of these data points are only in the same cluster.",
                    "label": 0
                },
                {
                    "sent": "You know four times or 5 * 3040% or 50% of the time, which is interesting because the beam sampler by resampling these whole state sequences at once has seems to have a much better ability of modeling the uncertainty in the state sequences.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last experiment that we did was an experiment on text prediction and this was more to compare it to the finite hidden Markov model.",
                    "label": 0
                },
                {
                    "sent": "So what we did was we trained an infinite hmm and a finite hidden Markov model on 1000 characters from the first chapter of Alice in Wonderland, and we looked at just looked at the 35 characters.",
                    "label": 1
                },
                {
                    "sent": "So this is the output alphabet.",
                    "label": 0
                },
                {
                    "sent": "What we did is we tested on the 1000 subsequent characters and then we compute the predictive log likelihood of the predictions.",
                    "label": 0
                },
                {
                    "sent": "What we find is so we trained the hidden Markov model using Variational Bayes to for it to be some kind of Fair comparison and what you see here is that the variational Bayes hmm does a pretty good job.",
                    "label": 0
                },
                {
                    "sent": "It gets really close to the performance of the infinite Markov model, but I mean I think the market model stands out here.",
                    "label": 0
                },
                {
                    "sent": "Even if you look at the optimal number of states that we selected for the variational Bayes training.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so what's the conclusion?",
                    "label": 0
                },
                {
                    "sent": "Would that want you to get it?",
                    "label": 0
                },
                {
                    "sent": "Go get away with in this talk.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we introduce dynamic program based inference for the infinite hidden Markov model and we have the adaptive truncation is useful for two reasons.",
                    "label": 0
                },
                {
                    "sent": "First, we're sampling from the true posterior, so it's an exact sampling algorithm and it's pretty fast.",
                    "label": 1
                },
                {
                    "sent": "Second thing is that because of the dynamic programming.",
                    "label": 1
                },
                {
                    "sent": "Sorry, because of the adaptive truncation.",
                    "label": 0
                },
                {
                    "sent": "Our dynamic program becomes sparse and it's extremely fast.",
                    "label": 0
                },
                {
                    "sent": "It's comperable to the Gibbs sampler, and finally, you know this.",
                    "label": 0
                },
                {
                    "sent": "This algorithm is also works perfectly fine for non conjugate models.",
                    "label": 1
                },
                {
                    "sent": "And our last experiment showed that the infinite hidden Markov model is in certain cases certainly a good alternative for the HMM, even if you train it with variational Bayes.",
                    "label": 0
                },
                {
                    "sent": "So the key concept here is that I think that the beam sampler is first inference algorithm that we know of.",
                    "label": 0
                },
                {
                    "sent": "That really makes the inference in the infant hidden Markov model.",
                    "label": 1
                },
                {
                    "sent": "I think practical enough to run it on really long sequences and really large datasets.",
                    "label": 0
                },
                {
                    "sent": "And to conclude, all the software for the beam samplers available on my website.",
                    "label": 0
                },
                {
                    "sent": "So feel free to go and download it and play around with it.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "No, we didn't do any Gibbs sampling.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We did do Gibbs sampling on the infinite Market Mall and that was I mean they.",
                    "label": 0
                },
                {
                    "sent": "Rather than having.",
                    "label": 0
                },
                {
                    "sent": "Fair enough, yeah, we didn't do that experiment.",
                    "label": 0
                },
                {
                    "sent": "If it so happens that use it, it's become very close to 0.",
                    "label": 0
                },
                {
                    "sent": "A whole bunch of states so so am I to this day what you doing correctly is that most of the time you'll be OK.",
                    "label": 0
                },
                {
                    "sent": "But then once in awhile you just show.",
                    "label": 0
                },
                {
                    "sent": "Whoa, just I mean that did the just joking probabilities is really, really small.",
                    "label": 0
                },
                {
                    "sent": "It's not 0 sure.",
                    "label": 0
                },
                {
                    "sent": "Yeah, absolutely now that's.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a good question because in here I chose this uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "But as it turns out, this is could be if you want it.",
                    "label": 0
                },
                {
                    "sent": "I mean, this works for us in a lot of cases, but it's not critical.",
                    "label": 0
                },
                {
                    "sent": "You could choose a different distribution here.",
                    "label": 0
                },
                {
                    "sent": "That sort of biases you toward values closer to \u03c0 or values closer to 0 using, say, a beta distribution, and this expression would be a tiny little bit more complicated, but it's just one extra multiplication, and in that sense you can sort of.",
                    "label": 0
                },
                {
                    "sent": "Also, if you want tweak.",
                    "label": 0
                },
                {
                    "sent": "The sparsity of your sampling method and you know, increase the consider more states or so.",
                    "label": 0
                },
                {
                    "sent": "There's some tweaking that you can do, but for all the experiments we've done, this uniform distribution work really, really well, and you know we didn't have very much trouble with.",
                    "label": 0
                },
                {
                    "sent": "You know, suddenly getting 100 million states or something like that so.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You know the.",
                    "label": 0
                },
                {
                    "sent": "Something small enough, special right?",
                    "label": 0
                },
                {
                    "sent": "Compared to which sampling method?",
                    "label": 0
                },
                {
                    "sent": "These a truncated matrix.",
                    "label": 0
                },
                {
                    "sent": "Sure, and so we haven't done the experiment.",
                    "label": 0
                },
                {
                    "sent": "Certainly something that we should do compared to the truncated version.",
                    "label": 0
                },
                {
                    "sent": "Now I mean certainly in a model where you want to learn a number of unbounded states, well, it's nice if you can.",
                    "label": 0
                },
                {
                    "sent": "Also, in your inference algorithm, have.",
                    "label": 0
                },
                {
                    "sent": "Sorry, say it again.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's.",
                    "label": 0
                },
                {
                    "sent": "I think it's nice that you can have this.",
                    "label": 0
                },
                {
                    "sent": "This number of states be flexible during the inference algorithm and then again you get this gain from the slice.",
                    "label": 0
                },
                {
                    "sent": "The auxiliary variable that your transition matrix is sparsified.",
                    "label": 0
                },
                {
                    "sent": "So the dynamic program is also much faster than the dynamic program if you just truncate, because if you should just truncate, you have to run the order TK square algorithm, especially if you have a large K. You know this this could be problematic and really slow down the inference, so I think.",
                    "label": 0
                },
                {
                    "sent": "You sort of winning both ways.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "This is a slight sample, so presumably I'm gonna send directly through just actually applied toward reaching absolutely an.",
                    "label": 0
                },
                {
                    "sent": "We know what the exact give sample looks like.",
                    "label": 0
                },
                {
                    "sent": "It was blocked.",
                    "label": 0
                },
                {
                    "sent": "Examples like we got the idea what this life sample for nation member.",
                    "label": 0
                },
                {
                    "sent": "And compare it in what sense compared to in like?",
                    "label": 0
                },
                {
                    "sent": "So I I mean, I did the experiments an actually the code for that is is also on the website, so you could try it out and I can't remember the exact results.",
                    "label": 0
                },
                {
                    "sent": "Now this is a very interesting question in also a different way because this fact that you're sort of sparsifying the transition matrix using the beam sampler is also interesting for learning really large hidden Markov models.",
                    "label": 0
                },
                {
                    "sent": "If you have really large state spaces you're only considering you know a smaller number of them, and you know that's something that we've been playing a little bit with it.",
                    "label": 0
                },
                {
                    "sent": "It's not trivial, but we've been playing a little bit with that too.",
                    "label": 0
                },
                {
                    "sent": "So, but yeah, I can't remember the numbers off the top of my head, but.",
                    "label": 0
                }
            ]
        }
    }
}