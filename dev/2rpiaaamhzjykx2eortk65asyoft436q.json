{
    "id": "2rpiaaamhzjykx2eortk65asyoft436q",
    "title": "Multilabel prediction of drug activity",
    "info": {
        "author": [
            "Juho Rousu, Department of Computer Science, University of Helsinki"
        ],
        "published": "Nov. 8, 2010",
        "recorded": "October 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods",
            "Top->Computer Science->Bioinformatics->Computational Systems Biology",
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/mlsb2010_rousu_mpo/",
    "segmentation": [
        [
            "I think at this time states of the workshop it's allowed to stray a little bit.",
            "OK, so this is a work that hunger Sue has really done the most of the hard hard experimentation of it, and margason me has been more like a supervising role."
        ],
        [
            "So the topic of the talk is drug bioactivity classification so.",
            "In principle, quite simple.",
            "Set up we are given a molecule, some target.",
            "Here I have some kind of cartoon like virus.",
            "In reality we are talking about cancer cancer cell lines, but this is a nicer, nicer picture then it kind of satellizer.",
            "OK so we have molecules annatar again.",
            "The question is which?",
            "Molecules are active against a given product and if you do a little bit of.",
            "Honey, baby, you could say that the state of the art is something like SVM by with some graph kernels on top of the molecules, OK?"
        ],
        [
            "That's the.",
            "OK, so how it goes so that then we have this kind of kind of some target and some of the molecules will be active."
        ],
        [
            "Some of them would be inactive solder target this.",
            "Alive and well.",
            "After administering it this this molecules OK, so this is the single single label label setting people have been doing."
        ],
        [
            "Doing on a long time, but we made this little realization that actually there are much more targets than one.",
            "And so so question question is, for example, different viruses, different types of cancer that share some characteristics with each other?",
            "So our question was that can we somehow utilize this?",
            "Sharing to learn the predict activity against a bunch of targets at the same time.",
            "So we have instead of 1 target we have a set of targets and so the prediction set up."
        ],
        [
            "Once.",
            "A multi label classification so so here is the Clara traditional single lab correct label classification where you have.",
            "Single X.",
            "This could be a molecule and this could be a label binary label indicating weather weather.",
            "Molecule is active against the target or so that's a single label classification.",
            "If you go to multi label classification we have.",
            "For each X we have a vector of.",
            "Why so?",
            "We have a.",
            "For K targets, we have K length, gay binary vector of of of labels.",
            "OK, so this is the.",
            "Basic.",
            "Sandbox we're going to be playing.",
            "And if you think about how you can.",
            "Read this kind of multi label classifier so one very simple basic approach is that OK, we just build single label classifier for each of these targets and then compose the multi label of of that.",
            "So basically build KKS VM's an.",
            "Just compost the multilabel out of out of that.",
            "But of course, if you do that, you are not benefiting from any possible possible dependencies between your labels.",
            "What we want to do here is to somehow.",
            "Impose a structure between these these targets and utilize that in getting better.",
            "Prediction so so our method blocks this structured output prediction family.",
            "So the idea is that that we leverage on the correlation of the neighboring label, so there is a structure where neighboring labels hopefully have some static statistical dependency, and we hope that we can utilize that in when we are learning to model.",
            "Alright."
        ],
        [
            "So in this talk we're going to use one particular model.",
            "A method called Max Martin Conditional random field.",
            "This is a method that we proposed a couple of years ago.",
            "But we haven't really done much much with it so, so this is kind of digging this.",
            "Metal from a dusty closet and trying it on a on a new data.",
            "I'm not going to go into very much detail on the method but but people that know of structured output prediction literature.",
            "This is a relative of the scores method, but there are some key differences to the task orders.",
            "For example, we have fixed output structure an you little bit different optimization algorithm.",
            "Another way of seeing this method is.",
            "Generalisation of the hierarchical multi label classifier we we did early on to the case of general crafts, so we allow in this case loops in the in the craft.",
            "The basic you can, you can see this model as a.",
            "As a conditional random field model.",
            "Where your outputs are connected by.",
            "Biocraft so you have this kind of structure where there is a potential for each edge and then there is this kind of feature function that's a joint feature function for X on X&Y.",
            "So you be coupled axis and wise together in this feature fits a map.",
            "And we want to learn the parameters W in this case.",
            "So this is the.",
            "This is the kind of."
        ],
        [
            "The tool that we are going to use and this is our data.",
            "So this data is sample from.",
            "Inside a cancer.",
            "Dataset where they are.",
            "Several 10s of 1000 molecules.",
            "Tested against different different cancer targets.",
            "This is a data set where we have something like a little over 4000 molecules tested against actually 59 cancer cell lines.",
            "So we have this.",
            "For 4000 samples and the number of multiple number of labels in our month, multi label is is 59.",
            "OK, so this is the data, this some statistics of the data, so this is the multi label distribution of the data.",
            "So this is how you read this we have.",
            "In this first.",
            "Bar we have all molecules that are inactive against all targets, so the multi label is 000.",
            "And then you go to this and you have the molecules that are active against all dark and this is the continuum.",
            "You can see it never is completely 0, but so it's A kind of real real multi label.",
            "Task, but actually quite skewed as well, because over half of the data set is completely inactive.",
            "Right, so this is the output side and this is the input side.",
            "This is 1 one kernel on that we have computed from the molecule data and this this is actually grouped.",
            "In the same way as this histogram, so we have here.",
            "The inactive ones on here we have to.",
            "Molecules that are active against all targets.",
            "So this is the same ordering as this and the red red color means more similar.",
            "An low local color.",
            "Less less similar, so it's dot.",
            "Here is a group of molecules.",
            "Average similarity F average kernel value of a group of molecules.",
            "That are active against certain number of targets so you can see this is peculiar distribution because we have the inactive molecules being mutually mutually similar and also the.",
            "The ones that are active against all targets also mutually similar.",
            "In the middle we have kind of this.",
            "Note not that area of not that much similarity, and then also you see this corners.",
            "So the molecules that are active against all targets also share a lot of similarities with complete inactive ones.",
            "So it's very peculiar kind of kind of a distribution in the input side.",
            "OK, and actually actually this has.",
            "Some kind of?",
            "Causes some trouble to us, as you will see in.",
            "Later."
        ],
        [
            "Stages OK so a little bit about how we represent our our inputs and outputs.",
            "So if you start with the outputs I mentioned that we assume this kind of network.",
            "It's been our labels, but in the day that there is no.",
            "Network you know, predefined network, so we need to construct the network first in order to.",
            "Uh.",
            "Use our method, so Luckily there is a lot of data on this cell line, so people have have done a lot of experiments.",
            "How these cell lines react to different treatments and conditions, and this is kind of independent from the drug drug molecules that we are.",
            "We're going to be working on so this is kind of auxilia data that we can use to build this structure between cell lines.",
            "Targets so.",
            "So we can take any of these datasets and build a correlation matrix using this data.",
            "So how do the cells?",
            "Behave.",
            "In this certain certain days and that correlate some matrix.",
            "OK, it's kind of a similarity matrix of this cell lines on what we do.",
            "We do a very simple things.",
            "We either take a maximum way that spanning tree out of that correlation matrix.",
            "So take the high correlated edge sheets and actually this is a spanning tree spanning tree of taken from the one of the datasets.",
            "Or we can do a correlation thresholding that will give us general crop, not not the tree.",
            "OK, so once we have this kind of tree structure over these targets, these multi labels.",
            "That told.",
            "About how the certain molecule.",
            "Acts against these targets into his labeling for this network.",
            "So our learning problem then actually is now translated to.",
            "Problem with labeling this graph.",
            "Given a molecule label, give a labeling for this for this graph.",
            "OK, and in our method we need to do this learning in this joint feature space.",
            "So this graph actually needs to be embedded.",
            "Throughout feature space.",
            "So we take this labeled graph an an make a feature vector out of it, and this is a very simple mapping where we take each edge.",
            "Look at the labeling so there are four possible labels for an edge.",
            "You may take the node node labels of the.",
            "Both ends of the edge, so you get 4 possible labels for an edge.",
            "And you get the indicator function like this.",
            "So if we have certain label U along that edge, this feature function will have value of 1, so this is very simple feature mapping embedding of that crafter."
        ],
        [
            "Here's a special.",
            "OK, on the input side we basically took.",
            "Different kinds of kernels people have been using for four molecules and tested tested them so.",
            "So here are three different ones that we have been using.",
            "One is a wall kirner.",
            "So basically you take a molecule annual and you consider different kinds of walks.",
            "So for example here you have carbon Atom and then maybe this is well, I'm not sure, but you take the kind of the Atom labels and bond labels of the walk and then you make a spectrum out of it and your kernel is spectrum in the product between these two.",
            "Spectra.",
            "Of two molecules.",
            "So kind of fish that kind of kernel tells you how many shared walks do two molecules have.",
            "Weighted composition kernel does something different.",
            "It it looks at certain centers.",
            "And the context around the center and then looks at what kind of atoms are in the neighborhood of the of the center and makes a kernel out of out of those those guys.",
            "Finally, turning off the kernel is.",
            "Based on fingerprints, so there is a domain expert that tells what kind of structures in the molecule are are important and makes a. Um?",
            "Basically we get feature feature vector where we put.",
            "One to each.",
            "Slot when we have a certain fingerprint print structure in our molecule and the kernel then will be our inner product of of.",
            "Off this kind of fingerprint vectors with some normalization.",
            "So Tanimoto kernel is just certain way of normalizing this kind of fingerprint.",
            "OK, so it's just a comment that actually this stunning model seemed to work the best.",
            "In our experiments, OK?"
        ],
        [
            "So.",
            "Then a little bit little bit of of our joint feed some app and this is actually quite like crucial.",
            "So we have this joint feature space for input or inputs and outputs.",
            "And in our case you can do this many many ways, but we do it as tensor product of input and output.",
            "That basically means that we take each input feature in each output feature.",
            "Take their product and basically can visualize that as a. Matrix of.",
            "Very hard along the columns you have your input features.",
            "Along the rows you have your output features and you have this product.",
            "Product of this features in the intersection and your feature map is basically a matrix which of course you can take us a vector as well, just.",
            "Sestry organizing.",
            "OK, so the point of this feature map is that we can learn context specific features for our input features and context means an edge in our graph between cell lines and.",
            "So we don't need to do any assumption of how our input features and output features are aligned.",
            "So prior assumption is not needed.",
            "Then we learn basically the importance of the features in different contexts."
        ],
        [
            "OK, I'm not going to go into very much detail of of the method.",
            "I don't have the time for it, but this MMCF algorithm basically.",
            "Consist of few components.",
            "The first is Max margin learning so.",
            "Instead of doing some maximum a posteriori or something like that which is useful in conditional random fields, we do this maximizing learning so we try to maximize the margin of the real example an all the correct.",
            "All the incorrect pseudo example.",
            "So there is a.",
            "Correct label for each X and there are bunch of incorrect labels for each X.",
            "Actually an exponential number of of this incorrect.",
            "Labels, so this is one thing.",
            "Second thing we use kernels on the input side to tackle the high dimensionality of the input, so this molecule.",
            "For example, the walk on or can be quite high dimensional, so it's nice to actually use a kernel and not not not the explicit features.",
            "On to tackle this exponential size of the multi level space so.",
            "So basically we have this kind of constraint here.",
            "Which is actually very huge because the.",
            "Number of different multi labels is exponential in the number of labels, so we need to tackle like all this somehow and we use some graphical model techniques.",
            "To do that, people that are interested in you can come and talk to me.",
            "I'm not going to go into details about those here."
        ],
        [
            "Right, OK, so this is the kind of the method.",
            "So and then what we are trying to do with this data.",
            "So actually like I like I mentioned you previously, we have a bit of trouble with skewness of this multi label distribution so we ended up doing 3 versions of the data set.",
            "First the full data.",
            "Second one is where we.",
            "Take this first bar out, so just consider the guys that are active at least one against at least one target.",
            "And finally, is a version where we take this extremes.",
            "Out and only take the middle part of the of the.",
            "Of the data in accordance with the race and an video 5 fold stratified cross validation for for the data.",
            "So basically we divide each of these groups into five folds and then we merge these folds across this these groups to make sure that each fold has representatives of each age group.",
            "OK, so this is data preprocess."
        ],
        [
            "Thing on here I show you some results, so this is comparison against SVM using the same input input Colonel.",
            "So this is stunning model kernel on SVM and our method.",
            "So, so this is first is the full data and you can see it's pretty much the same, so accuracy.",
            "It's pretty much the same for both methods on average, but if you see see the F1 score, we are already better than SVM.",
            "OK, so it shows that we have little bit balance between precision and recall then SV."
        ],
        [
            "OK, so this is the next where we take away to inactive guys.",
            "Basically half of the datasets just went out of the window.",
            "You see, then we are start to be kind of.",
            "Little bit more clearly.",
            "Better done than SVM and you can see this is statistical scientist over there.",
            "Over to.",
            "Oh this set up and it shows that it's kind of a significant role."
        ],
        [
            "And finally we have the middle part there.",
            "We have taken all of the extremes, extremes of the distribution away.",
            "And here you see quite quite clear quite clearly.",
            "Winning over to SVM.",
            "OK, so little bit of wrestling orbit today that we can show that.",
            "OK, we do something that is actually quite good."
        ],
        [
            "OK, and then one slide about computation time.",
            "I think many times people have impression that structured output prediction needs to be slow.",
            "And this is a slide that so should opposite might be true.",
            "So we have here 1 multi level model training time.",
            "Anne.",
            "59 SBMS to predict each of the components of the multi label separately and you can see it.",
            "See the curves that actually we are doing pretty well against SVM, so of course, before somebody comments we haven't really tuned the stopping criterion of SVM or anything like that, but out of the box we are doing.",
            "At least the same, if not better, when the data gets bigger.",
            "And this is native MATLAB code and.",
            "SVM is asleep, SVM, C++ so.",
            "It's not too."
        ],
        [
            "OK, so I'm nearing the end, so just some conclusions.",
            "So we've proposed structured output prediction approach for classification of drug like molecules and as far as we know it's the first time anybody has formulated this problem as multi label problem.",
            "So as I shown you, we are able to utilize the statistical dependencies between the labels.",
            "By means of this output structure that we constructed from oxalate data.",
            "Ann and we can so improvement over over SVM in R. Method future work.",
            "We don't really understand completely what does this output structure actually bring their scheme, why it works, and does it matter what kind of structure you impose there?",
            "Or is any structure as good or something like that, so it's 3 better than general craft for this kind of questions are.",
            "Pretty much open also how to learn it.",
            "We used very simple ways of extracting the network.",
            "Obviously we want to tackle this skewness of the multi label distribution better because now it's just messaged data and that's not completely satisfactory.",
            "You would like to have a method that.",
            "Does this that for you somehow automatically?",
            "And of course we want to actually look at the kind of drug discovery side of the of the problem more deeply in the future.",
            "Right, that's all.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think at this time states of the workshop it's allowed to stray a little bit.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a work that hunger Sue has really done the most of the hard hard experimentation of it, and margason me has been more like a supervising role.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the topic of the talk is drug bioactivity classification so.",
                    "label": 1
                },
                {
                    "sent": "In principle, quite simple.",
                    "label": 0
                },
                {
                    "sent": "Set up we are given a molecule, some target.",
                    "label": 0
                },
                {
                    "sent": "Here I have some kind of cartoon like virus.",
                    "label": 0
                },
                {
                    "sent": "In reality we are talking about cancer cancer cell lines, but this is a nicer, nicer picture then it kind of satellizer.",
                    "label": 0
                },
                {
                    "sent": "OK so we have molecules annatar again.",
                    "label": 0
                },
                {
                    "sent": "The question is which?",
                    "label": 0
                },
                {
                    "sent": "Molecules are active against a given product and if you do a little bit of.",
                    "label": 0
                },
                {
                    "sent": "Honey, baby, you could say that the state of the art is something like SVM by with some graph kernels on top of the molecules, OK?",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's the.",
                    "label": 0
                },
                {
                    "sent": "OK, so how it goes so that then we have this kind of kind of some target and some of the molecules will be active.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of them would be inactive solder target this.",
                    "label": 0
                },
                {
                    "sent": "Alive and well.",
                    "label": 0
                },
                {
                    "sent": "After administering it this this molecules OK, so this is the single single label label setting people have been doing.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing on a long time, but we made this little realization that actually there are much more targets than one.",
                    "label": 0
                },
                {
                    "sent": "And so so question question is, for example, different viruses, different types of cancer that share some characteristics with each other?",
                    "label": 1
                },
                {
                    "sent": "So our question was that can we somehow utilize this?",
                    "label": 0
                },
                {
                    "sent": "Sharing to learn the predict activity against a bunch of targets at the same time.",
                    "label": 1
                },
                {
                    "sent": "So we have instead of 1 target we have a set of targets and so the prediction set up.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once.",
                    "label": 0
                },
                {
                    "sent": "A multi label classification so so here is the Clara traditional single lab correct label classification where you have.",
                    "label": 0
                },
                {
                    "sent": "Single X.",
                    "label": 0
                },
                {
                    "sent": "This could be a molecule and this could be a label binary label indicating weather weather.",
                    "label": 0
                },
                {
                    "sent": "Molecule is active against the target or so that's a single label classification.",
                    "label": 1
                },
                {
                    "sent": "If you go to multi label classification we have.",
                    "label": 0
                },
                {
                    "sent": "For each X we have a vector of.",
                    "label": 0
                },
                {
                    "sent": "Why so?",
                    "label": 0
                },
                {
                    "sent": "We have a.",
                    "label": 0
                },
                {
                    "sent": "For K targets, we have K length, gay binary vector of of of labels.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 0
                },
                {
                    "sent": "Basic.",
                    "label": 0
                },
                {
                    "sent": "Sandbox we're going to be playing.",
                    "label": 0
                },
                {
                    "sent": "And if you think about how you can.",
                    "label": 0
                },
                {
                    "sent": "Read this kind of multi label classifier so one very simple basic approach is that OK, we just build single label classifier for each of these targets and then compose the multi label of of that.",
                    "label": 1
                },
                {
                    "sent": "So basically build KKS VM's an.",
                    "label": 0
                },
                {
                    "sent": "Just compost the multilabel out of out of that.",
                    "label": 0
                },
                {
                    "sent": "But of course, if you do that, you are not benefiting from any possible possible dependencies between your labels.",
                    "label": 0
                },
                {
                    "sent": "What we want to do here is to somehow.",
                    "label": 0
                },
                {
                    "sent": "Impose a structure between these these targets and utilize that in getting better.",
                    "label": 1
                },
                {
                    "sent": "Prediction so so our method blocks this structured output prediction family.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that that we leverage on the correlation of the neighboring label, so there is a structure where neighboring labels hopefully have some static statistical dependency, and we hope that we can utilize that in when we are learning to model.",
                    "label": 1
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk we're going to use one particular model.",
                    "label": 0
                },
                {
                    "sent": "A method called Max Martin Conditional random field.",
                    "label": 1
                },
                {
                    "sent": "This is a method that we proposed a couple of years ago.",
                    "label": 0
                },
                {
                    "sent": "But we haven't really done much much with it so, so this is kind of digging this.",
                    "label": 0
                },
                {
                    "sent": "Metal from a dusty closet and trying it on a on a new data.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into very much detail on the method but but people that know of structured output prediction literature.",
                    "label": 0
                },
                {
                    "sent": "This is a relative of the scores method, but there are some key differences to the task orders.",
                    "label": 0
                },
                {
                    "sent": "For example, we have fixed output structure an you little bit different optimization algorithm.",
                    "label": 1
                },
                {
                    "sent": "Another way of seeing this method is.",
                    "label": 0
                },
                {
                    "sent": "Generalisation of the hierarchical multi label classifier we we did early on to the case of general crafts, so we allow in this case loops in the in the craft.",
                    "label": 0
                },
                {
                    "sent": "The basic you can, you can see this model as a.",
                    "label": 1
                },
                {
                    "sent": "As a conditional random field model.",
                    "label": 0
                },
                {
                    "sent": "Where your outputs are connected by.",
                    "label": 0
                },
                {
                    "sent": "Biocraft so you have this kind of structure where there is a potential for each edge and then there is this kind of feature function that's a joint feature function for X on X&Y.",
                    "label": 0
                },
                {
                    "sent": "So you be coupled axis and wise together in this feature fits a map.",
                    "label": 0
                },
                {
                    "sent": "And we want to learn the parameters W in this case.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "This is the kind of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The tool that we are going to use and this is our data.",
                    "label": 0
                },
                {
                    "sent": "So this data is sample from.",
                    "label": 0
                },
                {
                    "sent": "Inside a cancer.",
                    "label": 0
                },
                {
                    "sent": "Dataset where they are.",
                    "label": 0
                },
                {
                    "sent": "Several 10s of 1000 molecules.",
                    "label": 0
                },
                {
                    "sent": "Tested against different different cancer targets.",
                    "label": 0
                },
                {
                    "sent": "This is a data set where we have something like a little over 4000 molecules tested against actually 59 cancer cell lines.",
                    "label": 1
                },
                {
                    "sent": "So we have this.",
                    "label": 0
                },
                {
                    "sent": "For 4000 samples and the number of multiple number of labels in our month, multi label is is 59.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the data, this some statistics of the data, so this is the multi label distribution of the data.",
                    "label": 0
                },
                {
                    "sent": "So this is how you read this we have.",
                    "label": 0
                },
                {
                    "sent": "In this first.",
                    "label": 0
                },
                {
                    "sent": "Bar we have all molecules that are inactive against all targets, so the multi label is 000.",
                    "label": 0
                },
                {
                    "sent": "And then you go to this and you have the molecules that are active against all dark and this is the continuum.",
                    "label": 0
                },
                {
                    "sent": "You can see it never is completely 0, but so it's A kind of real real multi label.",
                    "label": 0
                },
                {
                    "sent": "Task, but actually quite skewed as well, because over half of the data set is completely inactive.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is the output side and this is the input side.",
                    "label": 0
                },
                {
                    "sent": "This is 1 one kernel on that we have computed from the molecule data and this this is actually grouped.",
                    "label": 0
                },
                {
                    "sent": "In the same way as this histogram, so we have here.",
                    "label": 0
                },
                {
                    "sent": "The inactive ones on here we have to.",
                    "label": 0
                },
                {
                    "sent": "Molecules that are active against all targets.",
                    "label": 1
                },
                {
                    "sent": "So this is the same ordering as this and the red red color means more similar.",
                    "label": 1
                },
                {
                    "sent": "An low local color.",
                    "label": 0
                },
                {
                    "sent": "Less less similar, so it's dot.",
                    "label": 0
                },
                {
                    "sent": "Here is a group of molecules.",
                    "label": 0
                },
                {
                    "sent": "Average similarity F average kernel value of a group of molecules.",
                    "label": 0
                },
                {
                    "sent": "That are active against certain number of targets so you can see this is peculiar distribution because we have the inactive molecules being mutually mutually similar and also the.",
                    "label": 1
                },
                {
                    "sent": "The ones that are active against all targets also mutually similar.",
                    "label": 0
                },
                {
                    "sent": "In the middle we have kind of this.",
                    "label": 0
                },
                {
                    "sent": "Note not that area of not that much similarity, and then also you see this corners.",
                    "label": 0
                },
                {
                    "sent": "So the molecules that are active against all targets also share a lot of similarities with complete inactive ones.",
                    "label": 0
                },
                {
                    "sent": "So it's very peculiar kind of kind of a distribution in the input side.",
                    "label": 0
                },
                {
                    "sent": "OK, and actually actually this has.",
                    "label": 0
                },
                {
                    "sent": "Some kind of?",
                    "label": 0
                },
                {
                    "sent": "Causes some trouble to us, as you will see in.",
                    "label": 0
                },
                {
                    "sent": "Later.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stages OK so a little bit about how we represent our our inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "So if you start with the outputs I mentioned that we assume this kind of network.",
                    "label": 0
                },
                {
                    "sent": "It's been our labels, but in the day that there is no.",
                    "label": 0
                },
                {
                    "sent": "Network you know, predefined network, so we need to construct the network first in order to.",
                    "label": 1
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Use our method, so Luckily there is a lot of data on this cell line, so people have have done a lot of experiments.",
                    "label": 0
                },
                {
                    "sent": "How these cell lines react to different treatments and conditions, and this is kind of independent from the drug drug molecules that we are.",
                    "label": 1
                },
                {
                    "sent": "We're going to be working on so this is kind of auxilia data that we can use to build this structure between cell lines.",
                    "label": 0
                },
                {
                    "sent": "Targets so.",
                    "label": 0
                },
                {
                    "sent": "So we can take any of these datasets and build a correlation matrix using this data.",
                    "label": 1
                },
                {
                    "sent": "So how do the cells?",
                    "label": 1
                },
                {
                    "sent": "Behave.",
                    "label": 1
                },
                {
                    "sent": "In this certain certain days and that correlate some matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, it's kind of a similarity matrix of this cell lines on what we do.",
                    "label": 1
                },
                {
                    "sent": "We do a very simple things.",
                    "label": 0
                },
                {
                    "sent": "We either take a maximum way that spanning tree out of that correlation matrix.",
                    "label": 0
                },
                {
                    "sent": "So take the high correlated edge sheets and actually this is a spanning tree spanning tree of taken from the one of the datasets.",
                    "label": 1
                },
                {
                    "sent": "Or we can do a correlation thresholding that will give us general crop, not not the tree.",
                    "label": 1
                },
                {
                    "sent": "OK, so once we have this kind of tree structure over these targets, these multi labels.",
                    "label": 0
                },
                {
                    "sent": "That told.",
                    "label": 1
                },
                {
                    "sent": "About how the certain molecule.",
                    "label": 0
                },
                {
                    "sent": "Acts against these targets into his labeling for this network.",
                    "label": 0
                },
                {
                    "sent": "So our learning problem then actually is now translated to.",
                    "label": 0
                },
                {
                    "sent": "Problem with labeling this graph.",
                    "label": 0
                },
                {
                    "sent": "Given a molecule label, give a labeling for this for this graph.",
                    "label": 0
                },
                {
                    "sent": "OK, and in our method we need to do this learning in this joint feature space.",
                    "label": 0
                },
                {
                    "sent": "So this graph actually needs to be embedded.",
                    "label": 0
                },
                {
                    "sent": "Throughout feature space.",
                    "label": 0
                },
                {
                    "sent": "So we take this labeled graph an an make a feature vector out of it, and this is a very simple mapping where we take each edge.",
                    "label": 0
                },
                {
                    "sent": "Look at the labeling so there are four possible labels for an edge.",
                    "label": 0
                },
                {
                    "sent": "You may take the node node labels of the.",
                    "label": 0
                },
                {
                    "sent": "Both ends of the edge, so you get 4 possible labels for an edge.",
                    "label": 0
                },
                {
                    "sent": "And you get the indicator function like this.",
                    "label": 0
                },
                {
                    "sent": "So if we have certain label U along that edge, this feature function will have value of 1, so this is very simple feature mapping embedding of that crafter.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's a special.",
                    "label": 0
                },
                {
                    "sent": "OK, on the input side we basically took.",
                    "label": 0
                },
                {
                    "sent": "Different kinds of kernels people have been using for four molecules and tested tested them so.",
                    "label": 0
                },
                {
                    "sent": "So here are three different ones that we have been using.",
                    "label": 0
                },
                {
                    "sent": "One is a wall kirner.",
                    "label": 0
                },
                {
                    "sent": "So basically you take a molecule annual and you consider different kinds of walks.",
                    "label": 0
                },
                {
                    "sent": "So for example here you have carbon Atom and then maybe this is well, I'm not sure, but you take the kind of the Atom labels and bond labels of the walk and then you make a spectrum out of it and your kernel is spectrum in the product between these two.",
                    "label": 0
                },
                {
                    "sent": "Spectra.",
                    "label": 0
                },
                {
                    "sent": "Of two molecules.",
                    "label": 0
                },
                {
                    "sent": "So kind of fish that kind of kernel tells you how many shared walks do two molecules have.",
                    "label": 0
                },
                {
                    "sent": "Weighted composition kernel does something different.",
                    "label": 0
                },
                {
                    "sent": "It it looks at certain centers.",
                    "label": 0
                },
                {
                    "sent": "And the context around the center and then looks at what kind of atoms are in the neighborhood of the of the center and makes a kernel out of out of those those guys.",
                    "label": 0
                },
                {
                    "sent": "Finally, turning off the kernel is.",
                    "label": 0
                },
                {
                    "sent": "Based on fingerprints, so there is a domain expert that tells what kind of structures in the molecule are are important and makes a. Um?",
                    "label": 0
                },
                {
                    "sent": "Basically we get feature feature vector where we put.",
                    "label": 0
                },
                {
                    "sent": "One to each.",
                    "label": 0
                },
                {
                    "sent": "Slot when we have a certain fingerprint print structure in our molecule and the kernel then will be our inner product of of.",
                    "label": 0
                },
                {
                    "sent": "Off this kind of fingerprint vectors with some normalization.",
                    "label": 0
                },
                {
                    "sent": "So Tanimoto kernel is just certain way of normalizing this kind of fingerprint.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's just a comment that actually this stunning model seemed to work the best.",
                    "label": 0
                },
                {
                    "sent": "In our experiments, OK?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Then a little bit little bit of of our joint feed some app and this is actually quite like crucial.",
                    "label": 0
                },
                {
                    "sent": "So we have this joint feature space for input or inputs and outputs.",
                    "label": 1
                },
                {
                    "sent": "And in our case you can do this many many ways, but we do it as tensor product of input and output.",
                    "label": 0
                },
                {
                    "sent": "That basically means that we take each input feature in each output feature.",
                    "label": 0
                },
                {
                    "sent": "Take their product and basically can visualize that as a. Matrix of.",
                    "label": 0
                },
                {
                    "sent": "Very hard along the columns you have your input features.",
                    "label": 0
                },
                {
                    "sent": "Along the rows you have your output features and you have this product.",
                    "label": 0
                },
                {
                    "sent": "Product of this features in the intersection and your feature map is basically a matrix which of course you can take us a vector as well, just.",
                    "label": 0
                },
                {
                    "sent": "Sestry organizing.",
                    "label": 0
                },
                {
                    "sent": "OK, so the point of this feature map is that we can learn context specific features for our input features and context means an edge in our graph between cell lines and.",
                    "label": 1
                },
                {
                    "sent": "So we don't need to do any assumption of how our input features and output features are aligned.",
                    "label": 0
                },
                {
                    "sent": "So prior assumption is not needed.",
                    "label": 0
                },
                {
                    "sent": "Then we learn basically the importance of the features in different contexts.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I'm not going to go into very much detail of of the method.",
                    "label": 0
                },
                {
                    "sent": "I don't have the time for it, but this MMCF algorithm basically.",
                    "label": 0
                },
                {
                    "sent": "Consist of few components.",
                    "label": 0
                },
                {
                    "sent": "The first is Max margin learning so.",
                    "label": 0
                },
                {
                    "sent": "Instead of doing some maximum a posteriori or something like that which is useful in conditional random fields, we do this maximizing learning so we try to maximize the margin of the real example an all the correct.",
                    "label": 1
                },
                {
                    "sent": "All the incorrect pseudo example.",
                    "label": 0
                },
                {
                    "sent": "So there is a.",
                    "label": 0
                },
                {
                    "sent": "Correct label for each X and there are bunch of incorrect labels for each X.",
                    "label": 0
                },
                {
                    "sent": "Actually an exponential number of of this incorrect.",
                    "label": 0
                },
                {
                    "sent": "Labels, so this is one thing.",
                    "label": 1
                },
                {
                    "sent": "Second thing we use kernels on the input side to tackle the high dimensionality of the input, so this molecule.",
                    "label": 0
                },
                {
                    "sent": "For example, the walk on or can be quite high dimensional, so it's nice to actually use a kernel and not not not the explicit features.",
                    "label": 1
                },
                {
                    "sent": "On to tackle this exponential size of the multi level space so.",
                    "label": 0
                },
                {
                    "sent": "So basically we have this kind of constraint here.",
                    "label": 0
                },
                {
                    "sent": "Which is actually very huge because the.",
                    "label": 0
                },
                {
                    "sent": "Number of different multi labels is exponential in the number of labels, so we need to tackle like all this somehow and we use some graphical model techniques.",
                    "label": 0
                },
                {
                    "sent": "To do that, people that are interested in you can come and talk to me.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into details about those here.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, OK, so this is the kind of the method.",
                    "label": 0
                },
                {
                    "sent": "So and then what we are trying to do with this data.",
                    "label": 0
                },
                {
                    "sent": "So actually like I like I mentioned you previously, we have a bit of trouble with skewness of this multi label distribution so we ended up doing 3 versions of the data set.",
                    "label": 1
                },
                {
                    "sent": "First the full data.",
                    "label": 0
                },
                {
                    "sent": "Second one is where we.",
                    "label": 0
                },
                {
                    "sent": "Take this first bar out, so just consider the guys that are active at least one against at least one target.",
                    "label": 0
                },
                {
                    "sent": "And finally, is a version where we take this extremes.",
                    "label": 0
                },
                {
                    "sent": "Out and only take the middle part of the of the.",
                    "label": 0
                },
                {
                    "sent": "Of the data in accordance with the race and an video 5 fold stratified cross validation for for the data.",
                    "label": 0
                },
                {
                    "sent": "So basically we divide each of these groups into five folds and then we merge these folds across this these groups to make sure that each fold has representatives of each age group.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is data preprocess.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing on here I show you some results, so this is comparison against SVM using the same input input Colonel.",
                    "label": 0
                },
                {
                    "sent": "So this is stunning model kernel on SVM and our method.",
                    "label": 0
                },
                {
                    "sent": "So, so this is first is the full data and you can see it's pretty much the same, so accuracy.",
                    "label": 0
                },
                {
                    "sent": "It's pretty much the same for both methods on average, but if you see see the F1 score, we are already better than SVM.",
                    "label": 0
                },
                {
                    "sent": "OK, so it shows that we have little bit balance between precision and recall then SV.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the next where we take away to inactive guys.",
                    "label": 0
                },
                {
                    "sent": "Basically half of the datasets just went out of the window.",
                    "label": 0
                },
                {
                    "sent": "You see, then we are start to be kind of.",
                    "label": 0
                },
                {
                    "sent": "Little bit more clearly.",
                    "label": 0
                },
                {
                    "sent": "Better done than SVM and you can see this is statistical scientist over there.",
                    "label": 0
                },
                {
                    "sent": "Over to.",
                    "label": 0
                },
                {
                    "sent": "Oh this set up and it shows that it's kind of a significant role.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally we have the middle part there.",
                    "label": 0
                },
                {
                    "sent": "We have taken all of the extremes, extremes of the distribution away.",
                    "label": 0
                },
                {
                    "sent": "And here you see quite quite clear quite clearly.",
                    "label": 0
                },
                {
                    "sent": "Winning over to SVM.",
                    "label": 0
                },
                {
                    "sent": "OK, so little bit of wrestling orbit today that we can show that.",
                    "label": 0
                },
                {
                    "sent": "OK, we do something that is actually quite good.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then one slide about computation time.",
                    "label": 0
                },
                {
                    "sent": "I think many times people have impression that structured output prediction needs to be slow.",
                    "label": 0
                },
                {
                    "sent": "And this is a slide that so should opposite might be true.",
                    "label": 0
                },
                {
                    "sent": "So we have here 1 multi level model training time.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "59 SBMS to predict each of the components of the multi label separately and you can see it.",
                    "label": 0
                },
                {
                    "sent": "See the curves that actually we are doing pretty well against SVM, so of course, before somebody comments we haven't really tuned the stopping criterion of SVM or anything like that, but out of the box we are doing.",
                    "label": 0
                },
                {
                    "sent": "At least the same, if not better, when the data gets bigger.",
                    "label": 0
                },
                {
                    "sent": "And this is native MATLAB code and.",
                    "label": 0
                },
                {
                    "sent": "SVM is asleep, SVM, C++ so.",
                    "label": 0
                },
                {
                    "sent": "It's not too.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm nearing the end, so just some conclusions.",
                    "label": 0
                },
                {
                    "sent": "So we've proposed structured output prediction approach for classification of drug like molecules and as far as we know it's the first time anybody has formulated this problem as multi label problem.",
                    "label": 1
                },
                {
                    "sent": "So as I shown you, we are able to utilize the statistical dependencies between the labels.",
                    "label": 0
                },
                {
                    "sent": "By means of this output structure that we constructed from oxalate data.",
                    "label": 0
                },
                {
                    "sent": "Ann and we can so improvement over over SVM in R. Method future work.",
                    "label": 0
                },
                {
                    "sent": "We don't really understand completely what does this output structure actually bring their scheme, why it works, and does it matter what kind of structure you impose there?",
                    "label": 0
                },
                {
                    "sent": "Or is any structure as good or something like that, so it's 3 better than general craft for this kind of questions are.",
                    "label": 0
                },
                {
                    "sent": "Pretty much open also how to learn it.",
                    "label": 0
                },
                {
                    "sent": "We used very simple ways of extracting the network.",
                    "label": 0
                },
                {
                    "sent": "Obviously we want to tackle this skewness of the multi label distribution better because now it's just messaged data and that's not completely satisfactory.",
                    "label": 0
                },
                {
                    "sent": "You would like to have a method that.",
                    "label": 0
                },
                {
                    "sent": "Does this that for you somehow automatically?",
                    "label": 0
                },
                {
                    "sent": "And of course we want to actually look at the kind of drug discovery side of the of the problem more deeply in the future.",
                    "label": 0
                },
                {
                    "sent": "Right, that's all.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}