{
    "id": "2fxc4q7fezk4ytxkr3wwnapvwedb2yds",
    "title": "Text mining for Creative Cross-Domain Knowledge Discovery",
    "info": {
        "author": [
            "Bojan Cestnik, Temida d.o.o.",
            "Nada Lavra\u010d, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 27, 2014",
        "recorded": "November 2013",
        "category": [
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Psychology->Cognitive Psychology",
            "Top->Philosophy",
            "Top->Arts"
        ]
    },
    "url": "http://videolectures.net/ascc2013_lavrac_discovery/",
    "segmentation": [
        [
            "The title of the Talk is text Mining for cross Domain Knowledge Discovery and of course I couldn't avoid to use the word creative.",
            "I should explain that text mining is an area of artificial intelligence which is and then data mining and then text mining, and I will briefly cover this if time allows.",
            "Knowledge discovery we consider the process of knowledge discovery as a general process which in which we are doing data mining and cross domain.",
            "You will see it's a little bit similar to what Amilkar was telling us yesterday that we have two domains and then we would like to cross two domains with our knowledge discovery algorithms.",
            "So this is joint work with several of my colleagues.",
            "Buoyancy is Nick who is in the audience will also be part of this talk.",
            "He will present a little.",
            "Video about one of our algorithms and one of our systems, the other people being massage board slogan Tonya Bunch.",
            "And there are several other people involved."
        ],
        [
            "This is the outline of the talk after having introduced the motivation, I will briefly present some basic technologies so I set text mining and literature based discovery and then I will switch into the main topic of the talk, which is cross domain literature mining where I will focus on two approaches.",
            "One is how can we find interesting seeds of new knowledge when crossing the context and when crossing the context we could potentially find very interesting information in outlier documents.",
            "So I will focus on document on the document mining setting and then I will show how we have addressed the problem of cross context discovery with our system Crosby.",
            "At the end, Boyan will present a video about the system Crosby."
        ],
        [
            "Just to's let's say gently introduction.",
            "Tony mentioned Margaret Boden yesterday, he mentioned that there are three types of creativity, combinatorial, exploratory and transformation.",
            "ULL transformation.",
            "ULL is really the thing we would like to know with computational creativity methods, But I think we are still at least a little bit more modest nowadays and maybe we are able to support humans in combinatorial and exploratory.",
            "Creativity.",
            "I will also base my research on Arthur Koestler and he wrote an influential book in already in 1964 and the book is called the Act of Creation.",
            "And, well, just one citation from that book for warming up.",
            "A creative act uncovers selects.",
            "Reshuffles combines, synthesizes already existing facts, ideas, faculty skills.",
            "So in this sense it would be more often combinatorial types of creativity.",
            "In Margarette Bowdens terminology, the more familiar the parts we are handling, the more striking is the new whole which we can achieve by doing this creative process.",
            "I will also base my presentation on so-called by Sociative knowledge discovery.",
            "It is an area of research which we have kind of found it in our Bison project, which was about by sociative information mining in hetrogenous information networks and which resulted in a book by associative knowledge Discovery which was published by Springer in 2012 and our goal was to develop computational tools which can support humans in creative.",
            "Knowledge discovery, so I would say we are supporting humans in exploratory and combinatorial type of knowledge discovery but not in transformation type of knowledge discovery."
        ],
        [
            "So, continuing with both of them a little bit is that as she states, creativity is the ability to come up with ideas or artifacts that are new, surprising and valuable.",
            "And of course, in our projects which we are starting now in this year, we will be really very much involved in evaluating what is new, surprising and valuable.",
            "So this would be a very hard task, I believe.",
            "So Christler says that ideas often come from different contexts and when we combine them and we look at the same problem from a different angle, suddenly a new idea may pop up.",
            "He kind of expressed it in a little bit cumbersome words from our perspective, saying that an idea comes where we perceive a situation or this idea in two so called self consistent but habitually incompatible frames of reference.",
            "He also calls it a mattress or a context M1 and M2, so let's see what he means by that.",
            "Whoops.",
            "Suppose we have display name one that's our world in which we are trying to solve a problem.",
            "Suddenly this world is crossed by another context M2 and suddenly a new idea pops up which hasn't been of which the human hasn't been aware of before.",
            "So Christler calls this by Sociative reasoning an event is not merely linked to one.",
            "Associative context or domain, but by associated with the tool, and he considers by Association to be a basis for human creativity.",
            "And in his book he addresses this type of creativity in humor science as well as art."
        ],
        [
            "So to illustrate this, let's look at the argument.",
            "This example from Kessler's book, so Arimidex was well known.",
            "Scientists and he had to compute the volume of a Crown because he wanted to determine whether the Crown is made of gold or not.",
            "And at that time there was no method available to compute the volume of a Crown of this irregular object.",
            "And to solve this problem he needed to measure.",
            "Find out whether the Crown is made of gold or not.",
            "He needed to measure the volume of the crowd."
        ],
        [
            "And so one day he took a bus and he actually noticed that so that the Crown.",
            "Whose volume had to be measured.",
            "Could be considered as the volume of the water which is displaced when you put the object into the water.",
            "So we see that while he was thinking about how to solve the problem of computing the volume of this irregular object, suddenly he takes a bus, which is a completely different metrics of thought."
        ],
        [
            "So that would be the matrix M2 suddenly popping up, whereas.",
            "M1 was computing the volume of the Crown and now M2 is taking a bus."
        ],
        [
            "And suddenly there's this Eureka moment where both matrices.",
            "Somehow our similarity simulataneously active."
        ],
        [
            "We could illustrate it as follows.",
            "He was trying to solve the problem within one plane, one metrics of reference, one associative context, and then suddenly another context appears.",
            "Taking a bus and sadly the problem is solved.",
            "So this is in an ideal scenario, the scenario which we would like to address with computational tools.",
            "Of course this is an ambitious scenario, but maybe there are some ways with which we can address this problem."
        ],
        [
            "OK, so another example from the history of computer science.",
            "Evolution in nature compared to.",
            "Leading to evolutionary computing.",
            "So let's illustrate it."
        ],
        [
            "Like that, so we have some human knowledge.",
            "There are computer scientists.",
            "They're doing combinatorial optimization, biologists.",
            "They know about evolution.",
            "Suddenly, Lawrence Fogel had this by Sociative idea that maybe we could combine the two fields and then this led to evolutionary computing and one this.",
            "This established this by Association.",
            "After it has been accepted by people suddenly becomes an Association because it becomes generally known and it becomes a single context, whereas it used to be two different contexts which were completely unrelated.",
            "So can we support?",
            "Such Association discovery.",
            "Through by sociative.",
            "Blending of ideas now I have shamelessly used the word blending.",
            "Maybe it's not true.",
            "Maybe we can try to find connections between by associations and conceptual blending.",
            "It is to us to decide whether there is some potential to make the links between the two."
        ],
        [
            "We were involved in the Bison project.",
            "Not only yours of Steven Institute, but also handles group and ten other groups in Europe.",
            "12 partners the project name was Bisociation Bisociation networks for Creative Information discovery.",
            "The project lasted from 2008 to 11 and finally it resulted in the book which I mentioned by associative knowledge Discovery.",
            "The idea was to explore explore the idea of Bisociation and to compute to develop computational tools which can support humans in creative knowledge discovery."
        ],
        [
            "So this is the book and another shameless advertisement.",
            "It's a book which is Open Access.",
            "It can be freely downloaded, so it's quite nice piece of reading."
        ],
        [
            "So to continue on the idea of by Association.",
            "As we have mentioned, we are trying to find new ideas at the crossing of different associative contexts.",
            "Different frames of reference, different matrices as they are called.",
            "And maybe this new link which crosses different domains will be interesting.",
            "So when we try to define was this by Association in the Bison project we said, well, two concepts.",
            "Now, one concept from one domain and another concept from the other domain are by associated.",
            "And here is the definition.",
            "If there is no direct obvious evidence linking them.",
            "If one has to cross context to find the link and if the new link provides some novel insights.",
            "So this would be all the conditions for us to declare that something is biased."
        ],
        [
            "Ciation.",
            "And by associations can then this means occur across different contexts or different domains.",
            "So one of the different contexts could be different types of data or different types of background knowledge.",
            "So here maybe we can say, well bisociation may occur if we have some data or knowledge in forms of text documents.",
            "Another piece of human knowledge in the form of some network data.",
            "Another source of knowledge in some other format, so crossing such data, formats and knowledge formats might be.",
            "A form of BI sociative reasoning."
        ],
        [
            "And suppose we have the following situation.",
            "In the text documents we are interested in to diseases in the network documents we are interested in the genes like maybe we have a gene ontology there which can be used as a source of knowledge.",
            "Can we make some cross context links between the domains?"
        ],
        [
            "And potentially for a given disease, we can find out that there is strong correlation between this disease and the certain protein, and this could be discovered through text mining approaches where we see that in text these two different concepts cool curve very frequently in the other domain we can find out that a certain gene is coexpressed with another gene and then maybe in the third domain.",
            "Here we can find the link between the two."
        ],
        [
            "And the main bison approach was graph exploration in the first step we tried to encode all the knowledge we had available in different formats.",
            "We try to encode it in the form of a huge graph and then we used graph mining approaches to.",
            "To mine such a huge graph, to find this cross domain links so the open problem which we addressed was how to actually encode all this knowledge into heterogeneous graph which we called by Zonet.",
            "How to construct the relationships between the concepts and then once this is done, how to find unexpected previously unknown links between these bison net concepts or notes?"
        ],
        [
            "So the main approach as I said was find yet unexplored links in a graph crossing different domains.",
            "A simplified setting which we have addressed in our research is the following.",
            "Start from 2 predefined domains because in general maybe you start just from one domain.",
            "Look for another domain and then find cross domain links, but in a simplified setting we have two domains which we have defined in advance and we try to find.",
            "Note at the intersection of the two domains.",
            "And this could be a potentially very interesting new insight."
        ],
        [
            "In Bison we also addressed a complementary approach where we didn't encode all the knowledge into the form of a graph, but we were dealing with text documents and in that setting the problem can be defined as follows.",
            "Find unexplored terms in the intersection of domains, which across different contexts domains, different literatures and help experts in cross domain discovery for new findings.",
            "We address 2 settings.",
            "One is the so-called closed discovery setting, where two domains are predefined and the other one is the so called open discovery setting.",
            "When we define a specific domain and we try to find the other through exploration.",
            "So close discovery setting is also caused literature based discovery in a close discovery setting where we try to find by associations as bridging terms which link different domains.",
            "So I think Amilkar was also using the term bridging the domains in his blending approach."
        ],
        [
            "So we realized during the course of the Bizen project that actually other people address the same problem, but they called it literature based discovery or LBD.",
            "So there is early work of Swanson who was doing literature based discovery in medicine using pub Med articles as source of knowledge and then other people in 1998 Weber in 2001 and many others followed and also our own work in this domain.",
            "By Pete Rich usage and so on."
        ],
        [
            "So just to go a little bit into the history of text mining in this area of cross context discovery."
        ],
        [
            "Literature based discovery may help experts in this cross domain discovery for unknown facts.",
            "Early work of Swanson medical literature as a potential source of knowledge.",
            "His paper from 1988 and he was addressing disclosed discovery setting.",
            "With where we was trying to find this bridging terms so we could illustrate it as follows.",
            "We have documents from one domain, domain A.",
            "Documents from another domain, domain C. We put it in some engine, some computer algorithm.",
            "As a result, we'll get the most relevant terms which have the potential of being this bridging concepts.",
            "Which are now inspected by the human expert and that is a potential bisociation.",
            "Be associative term which crosses the two domains."
        ],
        [
            "Close discovery setting was in early Swanson's work, called the ABC model.",
            "In his work, he said, well, let us try with some domain C. Another domain A we can put.",
            "Let's say one term from the domain C which D."
        ],
        [
            "Finds it in the best way, like let's say magnesium.",
            "Let it be a term which we use as a search term and we search pub Med through that term we get all the articles about magnesium in that way.",
            "Another domain a.",
            "Let's say it is my green.",
            "We put it as a search query.",
            "To pub Med we get all the documents about migraine and can we find some bridging terms of interest for new discoveries at the intersection of the two domains?",
            "So here we say serotonine.",
            "Calcium channel blocker and so forth.",
            "So these are the terms which were.",
            "Discovered by Swanson in quite elaborate search of pub Med literature and it turned out that actually he was interested in migraine and he found out that magnesium, and especially that magnesium, has.",
            "A functionality like I will show in the following."
        ],
        [
            "Slide."
        ],
        [
            "So he found arguments.",
            "He found sentences in one domain and the other domain which are really cross context sentences.",
            "So let's look at the Mygrain literature, which was initially the source of his.",
            "Exploration.",
            "One sentence saying calcium channel blockers can prevent migraine attacks.",
            "And when searching for bridging terms he found in the magnesium literature, magnesium is a natural cancer channel blocker.",
            "So obviously these two things can be put together and then finally we can see that.",
            "Well, maybe migraine can be prevented if we take magnesium, which is a natural calcium channel blocker or stress and type a behavior associated with migraine.",
            "On the other hand, in the magnesium literature, stress and type A behavior can lead to body loss.",
            "Of magnesium migraine may involve sterile inflammation of the cerebral vessels.",
            "On the other hand, magnesium has anti inflammatory properties, so this is really if we would get such pairs of sentences.",
            "This we could really be very happy because there is potentially something new which can which can be discovered this way."
        ],
        [
            "And pop it is an perfect source of knowledge, human knowledge.",
            "There are more than 2000 references.",
            "Edit Every working day to this huge storage of knowledge in more than 21 million citations more than 5006 thousand Journal articles are being indexed in Pub Med, so it's really a valuable source of new discoveries through this.",
            "Repository."
        ],
        [
            "So let me illustrate this cross context discovery.",
            "We take one literature like literature about migraine domain C4 thousand 6600 articles, literature about magnesium, 38,000 articles and we're trying to find this bridging terms or linking terms as they are called sometimes."
        ],
        [
            "In another study by our colleagues Petritsch and or bunches.",
            "Also, Boyan Cystic was involved in this study.",
            "The problem was autism.",
            "And the problem was how to find some new drugs for autism or some new indicators.",
            "For what are the causes of autism and actually, in the open discovery setting, starting from domain C, which is autism, they found with computational means another domain which was calcineurin and they found the bridging terms.",
            "Then in the close discovery setting which followed the open discovery setting."
        ],
        [
            "And again they found some such pairs of sentences, where, for instance, synaptic plasticity was the term which was found automatically and which in theory it turns out to be very important for as a new discovery."
        ],
        [
            "So if I illustrate open discovery versus closed discovery in a closed discovery setting, you have two domains.",
            "C&A, you try to find this breaching terms, whereas in open discovery you start with a single domain.",
            "See and you try to find this bridging terms, which would lead you to know not yet known domain A.",
            "Like let's say if you start with autism.",
            "Then by finding some breaching terms they can lead you to a new domain which was calcineurin in this study.",
            "So this is even more magical, So what they did in the work was they actually were trying to find some rare terms in domain C. And then.",
            "See which rare terms?",
            "Have intersections in some other domains.",
            "This was leading them to other domains and then one of these domains turned out to be interesting, which was.",
            "Casino casino ring."
        ],
        [
            "So open discovery.",
            "All this is known.",
            "And in text mining, we're trying to this do automatically this cross domain knowledge discovery and try to provide systematic support to the closed as well to the open discovery process."
        ],
        [
            "So why is this useful?",
            "There is this growing speed of knowledge in medical domain specially.",
            "Many papers being published every day, this becomes completely.",
            "Non manageable to read even by a single scientist.",
            "So people are getting more and more specialized there.",
            "It's impossible to read all the literature.",
            "So finding potentially interesting connections between these islands of knowledge.",
            "Is very interesting."
        ],
        [
            "So very briefly about text mining, we need to do text mining.",
            "So how many people know everything about text mining?",
            "Or at least a little bit.",
            "Maybe half of the people know a little bit about text mining."
        ],
        [
            "So my background is in data mining.",
            "Where we start data mining process by having available a data table in the data table.",
            "Instances are rows in this table.",
            "Instances are described with attributes or variables.",
            "The attributes have some values which define a certain instance, and finally we have a special variable which is called the target class variable and we try to do classification through such a table by first building a model, a classification model, or by finding a set of interesting patterns in the data."
        ],
        [
            "And the type of rules we can produce rules automatically from such data tables which are used for classification, or we can build decision trees as a result of data mining.",
            "And we can use this models for classifying new instances.",
            "So that's the data mining setting."
        ],
        [
            "We can transform such a table into a binary table where attributes suddenly are the features which are attribute values from the previous table and then the values become just one and one and zero yes and no.",
            "And we have the target class which can now again be transformed into a binary class.",
            "Yes and no, and we are then learning one concept or one class versus other concepts being classification models from this data."
        ],
        [
            "So now suppose we have documents instead of tabular Excel tables.",
            "For instance, one document can be described by the set of words which appear in the document.",
            "A certain word either appears in the document or does not appear in the document.",
            "We can say yes, or one if the word appears in the document.",
            "And now if the word does not appear and our attributes now suddenly are all the words which appear in the entire document collection.",
            "Again, we can deal with the binary classification problem document for is from a certain class or a certain category or from another category.",
            "Again, we can automatically build classification model or predictions model or we can find interesting patterns in such data which are now the documents."
        ],
        [
            "We can also deal with the problem where there is no specific target class attribute and then we are dealing with, not with classification problems, but we are dealing with let's say the problem of clustering the documents according to their similarity and the similarity would be computed as such that documents which have same words in common are more similar to each other than the documents which don't share the same words."
        ],
        [
            "So what is the approach taken in text mining?",
            "Typically, typically you take documents you construct.",
            "What is called a bag of words vector vector representation.",
            "Which means transforming the documents into vectors of zeros and ones.",
            "Once we have such a representation, we can use any data mining algorithm to find the knowledge the classification models, prediction models, categorisation models, or interesting patterns in the data."
        ],
        [
            "So Textmining approach can be now viewed as being consisting of three stages.",
            "First is how to construct these features.",
            "The features could be single words, but then different words can appear in different forms and then you have to do some pre processing in order to put them the different words, different appearance of the same word into a common denominator that is called stemming or lemmatization.",
            "Of course you should also remove stop words like commas or let's say particles which appear in all the documents and have no information value in addition to single words.",
            "We can construct engrams which would be sequences of two or three or four words which appear together 'cause they appear as terms which may have a larger information content than the individual words themselves.",
            "Or we can use.",
            "Terms obtained from Santa hours or we can also use named entities and try to recognize named entities in documents in document preprocessing.",
            "Then we do bag of word construction.",
            "We transformed the text into vectors of zeros and ones.",
            "And finally, once we had that have that we can do some feature elimination.",
            "Find some ways of computing the similarity of documents and finally do text categorization, clustering, summarization or whatever.",
            "Other text mining task."
        ],
        [
            "So just to illustrate, one of the steps which is stemming or lemmatization, we take the words which can appear in different formats, like in one sentence you can find the word learns in another one learned or even in the same document you have different appearances of the word learn, and then you normalize them to learn as the neutral format for the different forms, and this is called.",
            "Stemming when you chunk away the ending of the word or lemmatization when you transform the word into the format which would be for instance found in, that is ours.",
            "So Lemmatization is a process of transforming a word into its normalized form, like in Slovene, where we have very many different endings of the words, maybe even 222 different endings for the same word appearing in different contexts in different cases.",
            "We could transform the words may Allah, which means she was laughing into Mayotte to laugh.",
            "And there are algorithms which can do that, and these are more rhythm center available off the shelf."
        ],
        [
            "So how do we construct the bag of words representation?",
            "We take a document.",
            "We look at the words which appear in the document.",
            "Here 1 document being.",
            "An abstract about what is Journal of artificial intelligence research?",
            "It is a refereed Journal covering all areas of artificial intelligence which is distributed free of charge over the Internet and so on and so forth.",
            "Let's see which words occur in such a document.",
            "Journal.",
            "Occurs.",
            "And here we have it.",
            "Artificial intelligence research Journal covering distributed volume and so on.",
            "So learning Journal intelligence, text agent, Internet data are all the words which appear in different documents.",
            "We pull all the words which appear in all the different documents in the text corpus which we want to analyze and.",
            "In the first step, we could simply count the number of appearances of a certain word.",
            "For instance, Journal appears here once and two times and three times, so we would simply count the frequency and this would be the term frequency of a word appearing in a document.",
            "That is the most simple representation of a document by term frequencies."
        ],
        [
            "But people in text mining usually use waiting of words or weighting of terms by the so called TF IDF weight and the TF IDF weight actually consists of two parts term frequency, which would be kind of counting of the number of words appearing in a single document.",
            "But then.",
            "This is a another part of this computation.",
            "Relative importance of the words in the document.",
            "Which is boosted up by the high frequency, should be counterpart it with the fact that if the same word appears very frequently in the document corpus, then it's not so important for the document of a given class.",
            "So each it is inverse document frequency.",
            "So the number of occurrences containing the word in the entire document corpus and it is in the denominator of this formula.",
            "So this would be the most standard weighting approach, so instead of."
        ],
        [
            "Zeros and ones or instead of counters with each word or with each ngram or with each named entity, you would have actually the weights which are at the interval 01."
        ],
        [
            "And then one of the important things is to count how somehow find out similarity of different documents which is computed through the similarity of vectors, bag of words, vectors, and if each bag of word vectors contains the weights.",
            "Associated to each word or named entity, then the similarity can be computed with the cosine similarity formula.",
            "So suppose one vector in the space is in this direction, which is defined by the vector, and this is in the other one.",
            "The cosine similarity would say well, if the two vectors are similar, the cosine of the angle, the angle is zero, and the two orthogonal vectors would be the most dissimilar.",
            "So the similarity.",
            "Computed through cosine similarity models.",
            "The similarity of two bag of words vectors."
        ],
        [
            "So this was the very short course on text mining and now we can go to the real thing and let me see.",
            "Well, I still have time.",
            "Fortunately for the real thing.",
            "So how can we find new seeds of knowledge through cross context literature mining?",
            "I will present two approaches.",
            "One approaches is through outlier detection and let me start with that.",
            "Our assumption is that much of the interesting knowledge lies in so-called outlier documents."
        ],
        [
            "So what are outliers?",
            "These are special cases in a document collection, and outliers appear everywhere.",
            "So outliers and noise are two terms which we want to address with our methods.",
            "So such a guy with in big bunch of other documents could be very interesting for inspection.",
            "Either it is a noisy document which we would like to remove because it was simply erroneous, or it is a very special case which is worse inspecting."
        ],
        [
            "So the goal is now to find interesting terms which bridge different contexts.",
            "In this cross context discovery, we will say we have domain A and domain C. We have documents from Domain A.",
            "We have documents from the main C. And we would like now to find outlier documents when we put the two document collections together, we could find out that some documents from this domain are more similar to the documents in the other domain than to the domain itself.",
            "And let's see how."
        ],
        [
            "To find this so we thought we would project.",
            "Document collection a.",
            "And B and color these documents with two different colors.",
            "We could see that in the blue domain, let's say domain C. Some blue documents are very similar to the red documents.",
            "And some red documents are very similar to the blue documents there appear here and so forth here.",
            "And these are potentially interesting outlier documents."
        ],
        [
            "Our hypothesis is that the bridging terms are more frequent in the outlier documents.",
            "So can we found find outliers.",
            "So we developed two different approaches to outlier detection.",
            "One was through the classical noise detection in machine learning.",
            "The other one was through document clustering using auto gain approach and the third approach is outlier document out time term detection using the so-called banded matrices approach, which is our current work which is slightly out of the scope of this presentation by the approach was presented at the idea a conference this year in London."
        ],
        [
            "So let's see the situation.",
            "Suppose we have documents from the domain A.",
            "And documents from the domain C. Now we put them together.",
            "And we get the document collection a Union C. Then we try to buy build the classifier from this document collection so some documents are labeled with Class A.",
            "Some documents are labeled with Class C. Our classifier when used on the same document collection will not brilliantly distinguish between A&C, but it will make some mistakes.",
            "And the documents from document collection.",
            "Most of them will be classified as a, but some are some errors will be made and some of the C documents will be classified as a.",
            "On the other hand, it will also.",
            "The classifier will also make some errors on the C class and classify some documents.",
            "As belonging to the other class.",
            "It's always like that.",
            "If we have, let's say, noise in the data, we can never build a perfect classifier with machine learning tools.",
            "So in our case we can illustrate it as follows.",
            "So if we have documents from Domain A and which are classified as a, they are perfect in the sense of machine learning and text mining.",
            "However, some documents will be wrongly classified into the C domain.",
            "And originally they are actually from the SI domain, but they have now been classified into a, so they are potentially outliers of the SI domain, 'cause there may be more similar to the main adenta its own domain, although they were initially labeled with C. And similarly we can find some documents which are outliers order of their own domain.",
            "So these are potentially interesting documents."
        ],
        [
            "Our approach to this is an ensemble based noise and outlier detection approach, which we call noise rank because it ranks the documents according to their outlier NIS.",
            "We use for this approach standard classifiers like Naive Bayes algorithm, random forest, support vector machines.",
            "We use them in an assemble setting and we see how many times these classifiers wrongly classified the documents from the two different classes and then we rank the misclassified documents by the voting of the ensemble of classifiers."
        ],
        [
            "And then we used the following representation.",
            "We have different classifiers here.",
            "Bayesian classifier, random forest, random forest, support vector machine, support vector machines, iteration filter and so forth, and we list the documents according to how many classifiers.",
            "Classified them in the wrong class.",
            "In this case we took articles from newspapers about Kenyan elections, which were held a couple of years ago, and after Kenyan relections there will be riots and many dead people.",
            "So interesting case was how the different newspapers, local media or Western media reported on the same events which words they were using, and so forth.",
            "So we used our machine learning approach to look at the documents and find outlier documents.",
            "So the first best ranked document and the best ranked in terms of outlier is not the best ranked in the sense that it is characteristic for its own class, but it was characteristic from the other class actually.",
            "Initially it was an article which was published in the Western media.",
            "But all the classifiers were misclassified the document then.",
            "We have seven other documents.",
            "First one belonging which was published in the local media 5.",
            "Classifiers, misclassified it into the western media context, and so forth and so forth.",
            "So we looked at the first data articles and showed them to the pragmatics experts from the University of Antwerp and."
        ],
        [
            "Actually they went one by one and found out that all these documents were really a bit unusual.",
            "So the first article which was.",
            "A western published in western media.",
            "Actually turned out to be an out of topic article.",
            "The article was later indeed removed from the corpus.",
            "Since it was not about Kenyans on the social political climate like the Kenyan elections, but it was about British tourists when they were robbed in some tourist resort.",
            "So another Article 173."
        ],
        [
            "That is.",
            "Let's say this one misclassified by 5 different classifiers.",
            "Initially it was published in local media."
        ],
        [
            "It was wrongly classified 'cause it could be regarded as a Western article among the local Kenyan press.",
            "The authors doesn't.",
            "Doesn't do not have the cultural sensitivity and don't follow the editorial guidelines, which requires to be careful when mentioning words like Tribe in the negative context, one could even say it was a kind of Western writing style.",
            "So actually in the Western articles it was many times mentioned much ads.",
            "Tribes, problems, ethnics and so forth, whereas in local media you couldn't find this kind of words.",
            "OK, so it it was indeed interesting from the pragmatic point of view to analyze these outlier documents."
        ],
        [
            "Now, can we evaluate whether we found something interesting in this cross context discovery, specially in literature based discovery when we looked at documents from different domains.",
            "So for dissent we used Mygrain magnesium again as a domain and autism calcineurin, which was investigated in our previous research.",
            "We used an ensemble consisting of three different elementary classifiers and we try to evaluate whether there is some potential.",
            "Or be term detection in those documents and we knew which bit term there was because other researchers have proven which are the cross context terms.",
            "So we did it through number of the terms appearing in the detected documents.",
            "Oh I'm I'm very late actually, yeah."
        ],
        [
            "And it turns out that there is strong bias and outlier documents indeed have a much larger number of bridging terms than the average documents."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The title of the Talk is text Mining for cross Domain Knowledge Discovery and of course I couldn't avoid to use the word creative.",
                    "label": 1
                },
                {
                    "sent": "I should explain that text mining is an area of artificial intelligence which is and then data mining and then text mining, and I will briefly cover this if time allows.",
                    "label": 0
                },
                {
                    "sent": "Knowledge discovery we consider the process of knowledge discovery as a general process which in which we are doing data mining and cross domain.",
                    "label": 0
                },
                {
                    "sent": "You will see it's a little bit similar to what Amilkar was telling us yesterday that we have two domains and then we would like to cross two domains with our knowledge discovery algorithms.",
                    "label": 0
                },
                {
                    "sent": "So this is joint work with several of my colleagues.",
                    "label": 0
                },
                {
                    "sent": "Buoyancy is Nick who is in the audience will also be part of this talk.",
                    "label": 0
                },
                {
                    "sent": "He will present a little.",
                    "label": 0
                },
                {
                    "sent": "Video about one of our algorithms and one of our systems, the other people being massage board slogan Tonya Bunch.",
                    "label": 0
                },
                {
                    "sent": "And there are several other people involved.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the outline of the talk after having introduced the motivation, I will briefly present some basic technologies so I set text mining and literature based discovery and then I will switch into the main topic of the talk, which is cross domain literature mining where I will focus on two approaches.",
                    "label": 1
                },
                {
                    "sent": "One is how can we find interesting seeds of new knowledge when crossing the context and when crossing the context we could potentially find very interesting information in outlier documents.",
                    "label": 1
                },
                {
                    "sent": "So I will focus on document on the document mining setting and then I will show how we have addressed the problem of cross context discovery with our system Crosby.",
                    "label": 0
                },
                {
                    "sent": "At the end, Boyan will present a video about the system Crosby.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to's let's say gently introduction.",
                    "label": 0
                },
                {
                    "sent": "Tony mentioned Margaret Boden yesterday, he mentioned that there are three types of creativity, combinatorial, exploratory and transformation.",
                    "label": 1
                },
                {
                    "sent": "ULL transformation.",
                    "label": 0
                },
                {
                    "sent": "ULL is really the thing we would like to know with computational creativity methods, But I think we are still at least a little bit more modest nowadays and maybe we are able to support humans in combinatorial and exploratory.",
                    "label": 0
                },
                {
                    "sent": "Creativity.",
                    "label": 0
                },
                {
                    "sent": "I will also base my research on Arthur Koestler and he wrote an influential book in already in 1964 and the book is called the Act of Creation.",
                    "label": 0
                },
                {
                    "sent": "And, well, just one citation from that book for warming up.",
                    "label": 0
                },
                {
                    "sent": "A creative act uncovers selects.",
                    "label": 1
                },
                {
                    "sent": "Reshuffles combines, synthesizes already existing facts, ideas, faculty skills.",
                    "label": 1
                },
                {
                    "sent": "So in this sense it would be more often combinatorial types of creativity.",
                    "label": 0
                },
                {
                    "sent": "In Margarette Bowdens terminology, the more familiar the parts we are handling, the more striking is the new whole which we can achieve by doing this creative process.",
                    "label": 1
                },
                {
                    "sent": "I will also base my presentation on so-called by Sociative knowledge discovery.",
                    "label": 0
                },
                {
                    "sent": "It is an area of research which we have kind of found it in our Bison project, which was about by sociative information mining in hetrogenous information networks and which resulted in a book by associative knowledge Discovery which was published by Springer in 2012 and our goal was to develop computational tools which can support humans in creative.",
                    "label": 0
                },
                {
                    "sent": "Knowledge discovery, so I would say we are supporting humans in exploratory and combinatorial type of knowledge discovery but not in transformation type of knowledge discovery.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, continuing with both of them a little bit is that as she states, creativity is the ability to come up with ideas or artifacts that are new, surprising and valuable.",
                    "label": 1
                },
                {
                    "sent": "And of course, in our projects which we are starting now in this year, we will be really very much involved in evaluating what is new, surprising and valuable.",
                    "label": 0
                },
                {
                    "sent": "So this would be a very hard task, I believe.",
                    "label": 0
                },
                {
                    "sent": "So Christler says that ideas often come from different contexts and when we combine them and we look at the same problem from a different angle, suddenly a new idea may pop up.",
                    "label": 0
                },
                {
                    "sent": "He kind of expressed it in a little bit cumbersome words from our perspective, saying that an idea comes where we perceive a situation or this idea in two so called self consistent but habitually incompatible frames of reference.",
                    "label": 0
                },
                {
                    "sent": "He also calls it a mattress or a context M1 and M2, so let's see what he means by that.",
                    "label": 0
                },
                {
                    "sent": "Whoops.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have display name one that's our world in which we are trying to solve a problem.",
                    "label": 0
                },
                {
                    "sent": "Suddenly this world is crossed by another context M2 and suddenly a new idea pops up which hasn't been of which the human hasn't been aware of before.",
                    "label": 1
                },
                {
                    "sent": "So Christler calls this by Sociative reasoning an event is not merely linked to one.",
                    "label": 0
                },
                {
                    "sent": "Associative context or domain, but by associated with the tool, and he considers by Association to be a basis for human creativity.",
                    "label": 0
                },
                {
                    "sent": "And in his book he addresses this type of creativity in humor science as well as art.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to illustrate this, let's look at the argument.",
                    "label": 0
                },
                {
                    "sent": "This example from Kessler's book, so Arimidex was well known.",
                    "label": 0
                },
                {
                    "sent": "Scientists and he had to compute the volume of a Crown because he wanted to determine whether the Crown is made of gold or not.",
                    "label": 1
                },
                {
                    "sent": "And at that time there was no method available to compute the volume of a Crown of this irregular object.",
                    "label": 0
                },
                {
                    "sent": "And to solve this problem he needed to measure.",
                    "label": 0
                },
                {
                    "sent": "Find out whether the Crown is made of gold or not.",
                    "label": 0
                },
                {
                    "sent": "He needed to measure the volume of the crowd.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so one day he took a bus and he actually noticed that so that the Crown.",
                    "label": 1
                },
                {
                    "sent": "Whose volume had to be measured.",
                    "label": 1
                },
                {
                    "sent": "Could be considered as the volume of the water which is displaced when you put the object into the water.",
                    "label": 1
                },
                {
                    "sent": "So we see that while he was thinking about how to solve the problem of computing the volume of this irregular object, suddenly he takes a bus, which is a completely different metrics of thought.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that would be the matrix M2 suddenly popping up, whereas.",
                    "label": 0
                },
                {
                    "sent": "M1 was computing the volume of the Crown and now M2 is taking a bus.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And suddenly there's this Eureka moment where both matrices.",
                    "label": 0
                },
                {
                    "sent": "Somehow our similarity simulataneously active.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We could illustrate it as follows.",
                    "label": 0
                },
                {
                    "sent": "He was trying to solve the problem within one plane, one metrics of reference, one associative context, and then suddenly another context appears.",
                    "label": 0
                },
                {
                    "sent": "Taking a bus and sadly the problem is solved.",
                    "label": 1
                },
                {
                    "sent": "So this is in an ideal scenario, the scenario which we would like to address with computational tools.",
                    "label": 0
                },
                {
                    "sent": "Of course this is an ambitious scenario, but maybe there are some ways with which we can address this problem.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so another example from the history of computer science.",
                    "label": 1
                },
                {
                    "sent": "Evolution in nature compared to.",
                    "label": 0
                },
                {
                    "sent": "Leading to evolutionary computing.",
                    "label": 0
                },
                {
                    "sent": "So let's illustrate it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like that, so we have some human knowledge.",
                    "label": 0
                },
                {
                    "sent": "There are computer scientists.",
                    "label": 0
                },
                {
                    "sent": "They're doing combinatorial optimization, biologists.",
                    "label": 0
                },
                {
                    "sent": "They know about evolution.",
                    "label": 0
                },
                {
                    "sent": "Suddenly, Lawrence Fogel had this by Sociative idea that maybe we could combine the two fields and then this led to evolutionary computing and one this.",
                    "label": 0
                },
                {
                    "sent": "This established this by Association.",
                    "label": 0
                },
                {
                    "sent": "After it has been accepted by people suddenly becomes an Association because it becomes generally known and it becomes a single context, whereas it used to be two different contexts which were completely unrelated.",
                    "label": 0
                },
                {
                    "sent": "So can we support?",
                    "label": 0
                },
                {
                    "sent": "Such Association discovery.",
                    "label": 0
                },
                {
                    "sent": "Through by sociative.",
                    "label": 0
                },
                {
                    "sent": "Blending of ideas now I have shamelessly used the word blending.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not true.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can try to find connections between by associations and conceptual blending.",
                    "label": 0
                },
                {
                    "sent": "It is to us to decide whether there is some potential to make the links between the two.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We were involved in the Bison project.",
                    "label": 0
                },
                {
                    "sent": "Not only yours of Steven Institute, but also handles group and ten other groups in Europe.",
                    "label": 0
                },
                {
                    "sent": "12 partners the project name was Bisociation Bisociation networks for Creative Information discovery.",
                    "label": 1
                },
                {
                    "sent": "The project lasted from 2008 to 11 and finally it resulted in the book which I mentioned by associative knowledge Discovery.",
                    "label": 0
                },
                {
                    "sent": "The idea was to explore explore the idea of Bisociation and to compute to develop computational tools which can support humans in creative knowledge discovery.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the book and another shameless advertisement.",
                    "label": 0
                },
                {
                    "sent": "It's a book which is Open Access.",
                    "label": 1
                },
                {
                    "sent": "It can be freely downloaded, so it's quite nice piece of reading.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to continue on the idea of by Association.",
                    "label": 0
                },
                {
                    "sent": "As we have mentioned, we are trying to find new ideas at the crossing of different associative contexts.",
                    "label": 0
                },
                {
                    "sent": "Different frames of reference, different matrices as they are called.",
                    "label": 0
                },
                {
                    "sent": "And maybe this new link which crosses different domains will be interesting.",
                    "label": 0
                },
                {
                    "sent": "So when we try to define was this by Association in the Bison project we said, well, two concepts.",
                    "label": 0
                },
                {
                    "sent": "Now, one concept from one domain and another concept from the other domain are by associated.",
                    "label": 0
                },
                {
                    "sent": "And here is the definition.",
                    "label": 0
                },
                {
                    "sent": "If there is no direct obvious evidence linking them.",
                    "label": 1
                },
                {
                    "sent": "If one has to cross context to find the link and if the new link provides some novel insights.",
                    "label": 1
                },
                {
                    "sent": "So this would be all the conditions for us to declare that something is biased.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ciation.",
                    "label": 0
                },
                {
                    "sent": "And by associations can then this means occur across different contexts or different domains.",
                    "label": 0
                },
                {
                    "sent": "So one of the different contexts could be different types of data or different types of background knowledge.",
                    "label": 0
                },
                {
                    "sent": "So here maybe we can say, well bisociation may occur if we have some data or knowledge in forms of text documents.",
                    "label": 0
                },
                {
                    "sent": "Another piece of human knowledge in the form of some network data.",
                    "label": 0
                },
                {
                    "sent": "Another source of knowledge in some other format, so crossing such data, formats and knowledge formats might be.",
                    "label": 0
                },
                {
                    "sent": "A form of BI sociative reasoning.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And suppose we have the following situation.",
                    "label": 0
                },
                {
                    "sent": "In the text documents we are interested in to diseases in the network documents we are interested in the genes like maybe we have a gene ontology there which can be used as a source of knowledge.",
                    "label": 0
                },
                {
                    "sent": "Can we make some cross context links between the domains?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And potentially for a given disease, we can find out that there is strong correlation between this disease and the certain protein, and this could be discovered through text mining approaches where we see that in text these two different concepts cool curve very frequently in the other domain we can find out that a certain gene is coexpressed with another gene and then maybe in the third domain.",
                    "label": 0
                },
                {
                    "sent": "Here we can find the link between the two.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the main bison approach was graph exploration in the first step we tried to encode all the knowledge we had available in different formats.",
                    "label": 0
                },
                {
                    "sent": "We try to encode it in the form of a huge graph and then we used graph mining approaches to.",
                    "label": 0
                },
                {
                    "sent": "To mine such a huge graph, to find this cross domain links so the open problem which we addressed was how to actually encode all this knowledge into heterogeneous graph which we called by Zonet.",
                    "label": 0
                },
                {
                    "sent": "How to construct the relationships between the concepts and then once this is done, how to find unexpected previously unknown links between these bison net concepts or notes?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main approach as I said was find yet unexplored links in a graph crossing different domains.",
                    "label": 0
                },
                {
                    "sent": "A simplified setting which we have addressed in our research is the following.",
                    "label": 0
                },
                {
                    "sent": "Start from 2 predefined domains because in general maybe you start just from one domain.",
                    "label": 0
                },
                {
                    "sent": "Look for another domain and then find cross domain links, but in a simplified setting we have two domains which we have defined in advance and we try to find.",
                    "label": 0
                },
                {
                    "sent": "Note at the intersection of the two domains.",
                    "label": 0
                },
                {
                    "sent": "And this could be a potentially very interesting new insight.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In Bison we also addressed a complementary approach where we didn't encode all the knowledge into the form of a graph, but we were dealing with text documents and in that setting the problem can be defined as follows.",
                    "label": 0
                },
                {
                    "sent": "Find unexplored terms in the intersection of domains, which across different contexts domains, different literatures and help experts in cross domain discovery for new findings.",
                    "label": 1
                },
                {
                    "sent": "We address 2 settings.",
                    "label": 1
                },
                {
                    "sent": "One is the so-called closed discovery setting, where two domains are predefined and the other one is the so called open discovery setting.",
                    "label": 0
                },
                {
                    "sent": "When we define a specific domain and we try to find the other through exploration.",
                    "label": 0
                },
                {
                    "sent": "So close discovery setting is also caused literature based discovery in a close discovery setting where we try to find by associations as bridging terms which link different domains.",
                    "label": 0
                },
                {
                    "sent": "So I think Amilkar was also using the term bridging the domains in his blending approach.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we realized during the course of the Bizen project that actually other people address the same problem, but they called it literature based discovery or LBD.",
                    "label": 0
                },
                {
                    "sent": "So there is early work of Swanson who was doing literature based discovery in medicine using pub Med articles as source of knowledge and then other people in 1998 Weber in 2001 and many others followed and also our own work in this domain.",
                    "label": 0
                },
                {
                    "sent": "By Pete Rich usage and so on.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to go a little bit into the history of text mining in this area of cross context discovery.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Literature based discovery may help experts in this cross domain discovery for unknown facts.",
                    "label": 0
                },
                {
                    "sent": "Early work of Swanson medical literature as a potential source of knowledge.",
                    "label": 1
                },
                {
                    "sent": "His paper from 1988 and he was addressing disclosed discovery setting.",
                    "label": 0
                },
                {
                    "sent": "With where we was trying to find this bridging terms so we could illustrate it as follows.",
                    "label": 0
                },
                {
                    "sent": "We have documents from one domain, domain A.",
                    "label": 0
                },
                {
                    "sent": "Documents from another domain, domain C. We put it in some engine, some computer algorithm.",
                    "label": 0
                },
                {
                    "sent": "As a result, we'll get the most relevant terms which have the potential of being this bridging concepts.",
                    "label": 0
                },
                {
                    "sent": "Which are now inspected by the human expert and that is a potential bisociation.",
                    "label": 0
                },
                {
                    "sent": "Be associative term which crosses the two domains.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Close discovery setting was in early Swanson's work, called the ABC model.",
                    "label": 1
                },
                {
                    "sent": "In his work, he said, well, let us try with some domain C. Another domain A we can put.",
                    "label": 0
                },
                {
                    "sent": "Let's say one term from the domain C which D.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finds it in the best way, like let's say magnesium.",
                    "label": 0
                },
                {
                    "sent": "Let it be a term which we use as a search term and we search pub Med through that term we get all the articles about magnesium in that way.",
                    "label": 0
                },
                {
                    "sent": "Another domain a.",
                    "label": 0
                },
                {
                    "sent": "Let's say it is my green.",
                    "label": 0
                },
                {
                    "sent": "We put it as a search query.",
                    "label": 0
                },
                {
                    "sent": "To pub Med we get all the documents about migraine and can we find some bridging terms of interest for new discoveries at the intersection of the two domains?",
                    "label": 1
                },
                {
                    "sent": "So here we say serotonine.",
                    "label": 0
                },
                {
                    "sent": "Calcium channel blocker and so forth.",
                    "label": 0
                },
                {
                    "sent": "So these are the terms which were.",
                    "label": 0
                },
                {
                    "sent": "Discovered by Swanson in quite elaborate search of pub Med literature and it turned out that actually he was interested in migraine and he found out that magnesium, and especially that magnesium, has.",
                    "label": 0
                },
                {
                    "sent": "A functionality like I will show in the following.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slide.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So he found arguments.",
                    "label": 0
                },
                {
                    "sent": "He found sentences in one domain and the other domain which are really cross context sentences.",
                    "label": 0
                },
                {
                    "sent": "So let's look at the Mygrain literature, which was initially the source of his.",
                    "label": 0
                },
                {
                    "sent": "Exploration.",
                    "label": 0
                },
                {
                    "sent": "One sentence saying calcium channel blockers can prevent migraine attacks.",
                    "label": 0
                },
                {
                    "sent": "And when searching for bridging terms he found in the magnesium literature, magnesium is a natural cancer channel blocker.",
                    "label": 1
                },
                {
                    "sent": "So obviously these two things can be put together and then finally we can see that.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe migraine can be prevented if we take magnesium, which is a natural calcium channel blocker or stress and type a behavior associated with migraine.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, in the magnesium literature, stress and type A behavior can lead to body loss.",
                    "label": 0
                },
                {
                    "sent": "Of magnesium migraine may involve sterile inflammation of the cerebral vessels.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, magnesium has anti inflammatory properties, so this is really if we would get such pairs of sentences.",
                    "label": 0
                },
                {
                    "sent": "This we could really be very happy because there is potentially something new which can which can be discovered this way.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And pop it is an perfect source of knowledge, human knowledge.",
                    "label": 0
                },
                {
                    "sent": "There are more than 2000 references.",
                    "label": 0
                },
                {
                    "sent": "Edit Every working day to this huge storage of knowledge in more than 21 million citations more than 5006 thousand Journal articles are being indexed in Pub Med, so it's really a valuable source of new discoveries through this.",
                    "label": 1
                },
                {
                    "sent": "Repository.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me illustrate this cross context discovery.",
                    "label": 0
                },
                {
                    "sent": "We take one literature like literature about migraine domain C4 thousand 6600 articles, literature about magnesium, 38,000 articles and we're trying to find this bridging terms or linking terms as they are called sometimes.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In another study by our colleagues Petritsch and or bunches.",
                    "label": 0
                },
                {
                    "sent": "Also, Boyan Cystic was involved in this study.",
                    "label": 0
                },
                {
                    "sent": "The problem was autism.",
                    "label": 0
                },
                {
                    "sent": "And the problem was how to find some new drugs for autism or some new indicators.",
                    "label": 0
                },
                {
                    "sent": "For what are the causes of autism and actually, in the open discovery setting, starting from domain C, which is autism, they found with computational means another domain which was calcineurin and they found the bridging terms.",
                    "label": 1
                },
                {
                    "sent": "Then in the close discovery setting which followed the open discovery setting.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again they found some such pairs of sentences, where, for instance, synaptic plasticity was the term which was found automatically and which in theory it turns out to be very important for as a new discovery.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if I illustrate open discovery versus closed discovery in a closed discovery setting, you have two domains.",
                    "label": 1
                },
                {
                    "sent": "C&A, you try to find this breaching terms, whereas in open discovery you start with a single domain.",
                    "label": 0
                },
                {
                    "sent": "See and you try to find this bridging terms, which would lead you to know not yet known domain A.",
                    "label": 0
                },
                {
                    "sent": "Like let's say if you start with autism.",
                    "label": 0
                },
                {
                    "sent": "Then by finding some breaching terms they can lead you to a new domain which was calcineurin in this study.",
                    "label": 0
                },
                {
                    "sent": "So this is even more magical, So what they did in the work was they actually were trying to find some rare terms in domain C. And then.",
                    "label": 0
                },
                {
                    "sent": "See which rare terms?",
                    "label": 0
                },
                {
                    "sent": "Have intersections in some other domains.",
                    "label": 0
                },
                {
                    "sent": "This was leading them to other domains and then one of these domains turned out to be interesting, which was.",
                    "label": 0
                },
                {
                    "sent": "Casino casino ring.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So open discovery.",
                    "label": 0
                },
                {
                    "sent": "All this is known.",
                    "label": 0
                },
                {
                    "sent": "And in text mining, we're trying to this do automatically this cross domain knowledge discovery and try to provide systematic support to the closed as well to the open discovery process.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why is this useful?",
                    "label": 0
                },
                {
                    "sent": "There is this growing speed of knowledge in medical domain specially.",
                    "label": 1
                },
                {
                    "sent": "Many papers being published every day, this becomes completely.",
                    "label": 0
                },
                {
                    "sent": "Non manageable to read even by a single scientist.",
                    "label": 0
                },
                {
                    "sent": "So people are getting more and more specialized there.",
                    "label": 0
                },
                {
                    "sent": "It's impossible to read all the literature.",
                    "label": 0
                },
                {
                    "sent": "So finding potentially interesting connections between these islands of knowledge.",
                    "label": 1
                },
                {
                    "sent": "Is very interesting.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So very briefly about text mining, we need to do text mining.",
                    "label": 0
                },
                {
                    "sent": "So how many people know everything about text mining?",
                    "label": 0
                },
                {
                    "sent": "Or at least a little bit.",
                    "label": 0
                },
                {
                    "sent": "Maybe half of the people know a little bit about text mining.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So my background is in data mining.",
                    "label": 1
                },
                {
                    "sent": "Where we start data mining process by having available a data table in the data table.",
                    "label": 1
                },
                {
                    "sent": "Instances are rows in this table.",
                    "label": 0
                },
                {
                    "sent": "Instances are described with attributes or variables.",
                    "label": 0
                },
                {
                    "sent": "The attributes have some values which define a certain instance, and finally we have a special variable which is called the target class variable and we try to do classification through such a table by first building a model, a classification model, or by finding a set of interesting patterns in the data.",
                    "label": 1
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the type of rules we can produce rules automatically from such data tables which are used for classification, or we can build decision trees as a result of data mining.",
                    "label": 0
                },
                {
                    "sent": "And we can use this models for classifying new instances.",
                    "label": 0
                },
                {
                    "sent": "So that's the data mining setting.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can transform such a table into a binary table where attributes suddenly are the features which are attribute values from the previous table and then the values become just one and one and zero yes and no.",
                    "label": 0
                },
                {
                    "sent": "And we have the target class which can now again be transformed into a binary class.",
                    "label": 0
                },
                {
                    "sent": "Yes and no, and we are then learning one concept or one class versus other concepts being classification models from this data.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now suppose we have documents instead of tabular Excel tables.",
                    "label": 0
                },
                {
                    "sent": "For instance, one document can be described by the set of words which appear in the document.",
                    "label": 0
                },
                {
                    "sent": "A certain word either appears in the document or does not appear in the document.",
                    "label": 0
                },
                {
                    "sent": "We can say yes, or one if the word appears in the document.",
                    "label": 0
                },
                {
                    "sent": "And now if the word does not appear and our attributes now suddenly are all the words which appear in the entire document collection.",
                    "label": 0
                },
                {
                    "sent": "Again, we can deal with the binary classification problem document for is from a certain class or a certain category or from another category.",
                    "label": 0
                },
                {
                    "sent": "Again, we can automatically build classification model or predictions model or we can find interesting patterns in such data which are now the documents.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also deal with the problem where there is no specific target class attribute and then we are dealing with, not with classification problems, but we are dealing with let's say the problem of clustering the documents according to their similarity and the similarity would be computed as such that documents which have same words in common are more similar to each other than the documents which don't share the same words.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is the approach taken in text mining?",
                    "label": 0
                },
                {
                    "sent": "Typically, typically you take documents you construct.",
                    "label": 0
                },
                {
                    "sent": "What is called a bag of words vector vector representation.",
                    "label": 0
                },
                {
                    "sent": "Which means transforming the documents into vectors of zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "Once we have such a representation, we can use any data mining algorithm to find the knowledge the classification models, prediction models, categorisation models, or interesting patterns in the data.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Textmining approach can be now viewed as being consisting of three stages.",
                    "label": 0
                },
                {
                    "sent": "First is how to construct these features.",
                    "label": 0
                },
                {
                    "sent": "The features could be single words, but then different words can appear in different forms and then you have to do some pre processing in order to put them the different words, different appearance of the same word into a common denominator that is called stemming or lemmatization.",
                    "label": 0
                },
                {
                    "sent": "Of course you should also remove stop words like commas or let's say particles which appear in all the documents and have no information value in addition to single words.",
                    "label": 0
                },
                {
                    "sent": "We can construct engrams which would be sequences of two or three or four words which appear together 'cause they appear as terms which may have a larger information content than the individual words themselves.",
                    "label": 0
                },
                {
                    "sent": "Or we can use.",
                    "label": 0
                },
                {
                    "sent": "Terms obtained from Santa hours or we can also use named entities and try to recognize named entities in documents in document preprocessing.",
                    "label": 1
                },
                {
                    "sent": "Then we do bag of word construction.",
                    "label": 0
                },
                {
                    "sent": "We transformed the text into vectors of zeros and ones.",
                    "label": 0
                },
                {
                    "sent": "And finally, once we had that have that we can do some feature elimination.",
                    "label": 0
                },
                {
                    "sent": "Find some ways of computing the similarity of documents and finally do text categorization, clustering, summarization or whatever.",
                    "label": 1
                },
                {
                    "sent": "Other text mining task.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to illustrate, one of the steps which is stemming or lemmatization, we take the words which can appear in different formats, like in one sentence you can find the word learns in another one learned or even in the same document you have different appearances of the word learn, and then you normalize them to learn as the neutral format for the different forms, and this is called.",
                    "label": 0
                },
                {
                    "sent": "Stemming when you chunk away the ending of the word or lemmatization when you transform the word into the format which would be for instance found in, that is ours.",
                    "label": 0
                },
                {
                    "sent": "So Lemmatization is a process of transforming a word into its normalized form, like in Slovene, where we have very many different endings of the words, maybe even 222 different endings for the same word appearing in different contexts in different cases.",
                    "label": 1
                },
                {
                    "sent": "We could transform the words may Allah, which means she was laughing into Mayotte to laugh.",
                    "label": 0
                },
                {
                    "sent": "And there are algorithms which can do that, and these are more rhythm center available off the shelf.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we construct the bag of words representation?",
                    "label": 0
                },
                {
                    "sent": "We take a document.",
                    "label": 0
                },
                {
                    "sent": "We look at the words which appear in the document.",
                    "label": 0
                },
                {
                    "sent": "Here 1 document being.",
                    "label": 0
                },
                {
                    "sent": "An abstract about what is Journal of artificial intelligence research?",
                    "label": 0
                },
                {
                    "sent": "It is a refereed Journal covering all areas of artificial intelligence which is distributed free of charge over the Internet and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "Let's see which words occur in such a document.",
                    "label": 0
                },
                {
                    "sent": "Journal.",
                    "label": 0
                },
                {
                    "sent": "Occurs.",
                    "label": 0
                },
                {
                    "sent": "And here we have it.",
                    "label": 0
                },
                {
                    "sent": "Artificial intelligence research Journal covering distributed volume and so on.",
                    "label": 0
                },
                {
                    "sent": "So learning Journal intelligence, text agent, Internet data are all the words which appear in different documents.",
                    "label": 0
                },
                {
                    "sent": "We pull all the words which appear in all the different documents in the text corpus which we want to analyze and.",
                    "label": 0
                },
                {
                    "sent": "In the first step, we could simply count the number of appearances of a certain word.",
                    "label": 0
                },
                {
                    "sent": "For instance, Journal appears here once and two times and three times, so we would simply count the frequency and this would be the term frequency of a word appearing in a document.",
                    "label": 0
                },
                {
                    "sent": "That is the most simple representation of a document by term frequencies.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But people in text mining usually use waiting of words or weighting of terms by the so called TF IDF weight and the TF IDF weight actually consists of two parts term frequency, which would be kind of counting of the number of words appearing in a single document.",
                    "label": 0
                },
                {
                    "sent": "But then.",
                    "label": 0
                },
                {
                    "sent": "This is a another part of this computation.",
                    "label": 0
                },
                {
                    "sent": "Relative importance of the words in the document.",
                    "label": 1
                },
                {
                    "sent": "Which is boosted up by the high frequency, should be counterpart it with the fact that if the same word appears very frequently in the document corpus, then it's not so important for the document of a given class.",
                    "label": 1
                },
                {
                    "sent": "So each it is inverse document frequency.",
                    "label": 1
                },
                {
                    "sent": "So the number of occurrences containing the word in the entire document corpus and it is in the denominator of this formula.",
                    "label": 0
                },
                {
                    "sent": "So this would be the most standard weighting approach, so instead of.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zeros and ones or instead of counters with each word or with each ngram or with each named entity, you would have actually the weights which are at the interval 01.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then one of the important things is to count how somehow find out similarity of different documents which is computed through the similarity of vectors, bag of words, vectors, and if each bag of word vectors contains the weights.",
                    "label": 0
                },
                {
                    "sent": "Associated to each word or named entity, then the similarity can be computed with the cosine similarity formula.",
                    "label": 0
                },
                {
                    "sent": "So suppose one vector in the space is in this direction, which is defined by the vector, and this is in the other one.",
                    "label": 0
                },
                {
                    "sent": "The cosine similarity would say well, if the two vectors are similar, the cosine of the angle, the angle is zero, and the two orthogonal vectors would be the most dissimilar.",
                    "label": 1
                },
                {
                    "sent": "So the similarity.",
                    "label": 0
                },
                {
                    "sent": "Computed through cosine similarity models.",
                    "label": 1
                },
                {
                    "sent": "The similarity of two bag of words vectors.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this was the very short course on text mining and now we can go to the real thing and let me see.",
                    "label": 1
                },
                {
                    "sent": "Well, I still have time.",
                    "label": 0
                },
                {
                    "sent": "Fortunately for the real thing.",
                    "label": 0
                },
                {
                    "sent": "So how can we find new seeds of knowledge through cross context literature mining?",
                    "label": 1
                },
                {
                    "sent": "I will present two approaches.",
                    "label": 0
                },
                {
                    "sent": "One approaches is through outlier detection and let me start with that.",
                    "label": 1
                },
                {
                    "sent": "Our assumption is that much of the interesting knowledge lies in so-called outlier documents.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what are outliers?",
                    "label": 0
                },
                {
                    "sent": "These are special cases in a document collection, and outliers appear everywhere.",
                    "label": 0
                },
                {
                    "sent": "So outliers and noise are two terms which we want to address with our methods.",
                    "label": 0
                },
                {
                    "sent": "So such a guy with in big bunch of other documents could be very interesting for inspection.",
                    "label": 0
                },
                {
                    "sent": "Either it is a noisy document which we would like to remove because it was simply erroneous, or it is a very special case which is worse inspecting.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal is now to find interesting terms which bridge different contexts.",
                    "label": 1
                },
                {
                    "sent": "In this cross context discovery, we will say we have domain A and domain C. We have documents from Domain A.",
                    "label": 0
                },
                {
                    "sent": "We have documents from the main C. And we would like now to find outlier documents when we put the two document collections together, we could find out that some documents from this domain are more similar to the documents in the other domain than to the domain itself.",
                    "label": 0
                },
                {
                    "sent": "And let's see how.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To find this so we thought we would project.",
                    "label": 0
                },
                {
                    "sent": "Document collection a.",
                    "label": 0
                },
                {
                    "sent": "And B and color these documents with two different colors.",
                    "label": 0
                },
                {
                    "sent": "We could see that in the blue domain, let's say domain C. Some blue documents are very similar to the red documents.",
                    "label": 0
                },
                {
                    "sent": "And some red documents are very similar to the blue documents there appear here and so forth here.",
                    "label": 1
                },
                {
                    "sent": "And these are potentially interesting outlier documents.",
                    "label": 1
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our hypothesis is that the bridging terms are more frequent in the outlier documents.",
                    "label": 0
                },
                {
                    "sent": "So can we found find outliers.",
                    "label": 0
                },
                {
                    "sent": "So we developed two different approaches to outlier detection.",
                    "label": 1
                },
                {
                    "sent": "One was through the classical noise detection in machine learning.",
                    "label": 0
                },
                {
                    "sent": "The other one was through document clustering using auto gain approach and the third approach is outlier document out time term detection using the so-called banded matrices approach, which is our current work which is slightly out of the scope of this presentation by the approach was presented at the idea a conference this year in London.",
                    "label": 1
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see the situation.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have documents from the domain A.",
                    "label": 0
                },
                {
                    "sent": "And documents from the domain C. Now we put them together.",
                    "label": 0
                },
                {
                    "sent": "And we get the document collection a Union C. Then we try to buy build the classifier from this document collection so some documents are labeled with Class A.",
                    "label": 0
                },
                {
                    "sent": "Some documents are labeled with Class C. Our classifier when used on the same document collection will not brilliantly distinguish between A&C, but it will make some mistakes.",
                    "label": 0
                },
                {
                    "sent": "And the documents from document collection.",
                    "label": 0
                },
                {
                    "sent": "Most of them will be classified as a, but some are some errors will be made and some of the C documents will be classified as a.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it will also.",
                    "label": 0
                },
                {
                    "sent": "The classifier will also make some errors on the C class and classify some documents.",
                    "label": 0
                },
                {
                    "sent": "As belonging to the other class.",
                    "label": 0
                },
                {
                    "sent": "It's always like that.",
                    "label": 0
                },
                {
                    "sent": "If we have, let's say, noise in the data, we can never build a perfect classifier with machine learning tools.",
                    "label": 0
                },
                {
                    "sent": "So in our case we can illustrate it as follows.",
                    "label": 0
                },
                {
                    "sent": "So if we have documents from Domain A and which are classified as a, they are perfect in the sense of machine learning and text mining.",
                    "label": 0
                },
                {
                    "sent": "However, some documents will be wrongly classified into the C domain.",
                    "label": 0
                },
                {
                    "sent": "And originally they are actually from the SI domain, but they have now been classified into a, so they are potentially outliers of the SI domain, 'cause there may be more similar to the main adenta its own domain, although they were initially labeled with C. And similarly we can find some documents which are outliers order of their own domain.",
                    "label": 0
                },
                {
                    "sent": "So these are potentially interesting documents.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach to this is an ensemble based noise and outlier detection approach, which we call noise rank because it ranks the documents according to their outlier NIS.",
                    "label": 1
                },
                {
                    "sent": "We use for this approach standard classifiers like Naive Bayes algorithm, random forest, support vector machines.",
                    "label": 0
                },
                {
                    "sent": "We use them in an assemble setting and we see how many times these classifiers wrongly classified the documents from the two different classes and then we rank the misclassified documents by the voting of the ensemble of classifiers.",
                    "label": 1
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we used the following representation.",
                    "label": 0
                },
                {
                    "sent": "We have different classifiers here.",
                    "label": 0
                },
                {
                    "sent": "Bayesian classifier, random forest, random forest, support vector machine, support vector machines, iteration filter and so forth, and we list the documents according to how many classifiers.",
                    "label": 0
                },
                {
                    "sent": "Classified them in the wrong class.",
                    "label": 0
                },
                {
                    "sent": "In this case we took articles from newspapers about Kenyan elections, which were held a couple of years ago, and after Kenyan relections there will be riots and many dead people.",
                    "label": 0
                },
                {
                    "sent": "So interesting case was how the different newspapers, local media or Western media reported on the same events which words they were using, and so forth.",
                    "label": 0
                },
                {
                    "sent": "So we used our machine learning approach to look at the documents and find outlier documents.",
                    "label": 0
                },
                {
                    "sent": "So the first best ranked document and the best ranked in terms of outlier is not the best ranked in the sense that it is characteristic for its own class, but it was characteristic from the other class actually.",
                    "label": 0
                },
                {
                    "sent": "Initially it was an article which was published in the Western media.",
                    "label": 1
                },
                {
                    "sent": "But all the classifiers were misclassified the document then.",
                    "label": 0
                },
                {
                    "sent": "We have seven other documents.",
                    "label": 0
                },
                {
                    "sent": "First one belonging which was published in the local media 5.",
                    "label": 0
                },
                {
                    "sent": "Classifiers, misclassified it into the western media context, and so forth and so forth.",
                    "label": 0
                },
                {
                    "sent": "So we looked at the first data articles and showed them to the pragmatics experts from the University of Antwerp and.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually they went one by one and found out that all these documents were really a bit unusual.",
                    "label": 0
                },
                {
                    "sent": "So the first article which was.",
                    "label": 0
                },
                {
                    "sent": "A western published in western media.",
                    "label": 0
                },
                {
                    "sent": "Actually turned out to be an out of topic article.",
                    "label": 0
                },
                {
                    "sent": "The article was later indeed removed from the corpus.",
                    "label": 1
                },
                {
                    "sent": "Since it was not about Kenyans on the social political climate like the Kenyan elections, but it was about British tourists when they were robbed in some tourist resort.",
                    "label": 0
                },
                {
                    "sent": "So another Article 173.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is.",
                    "label": 0
                },
                {
                    "sent": "Let's say this one misclassified by 5 different classifiers.",
                    "label": 0
                },
                {
                    "sent": "Initially it was published in local media.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It was wrongly classified 'cause it could be regarded as a Western article among the local Kenyan press.",
                    "label": 1
                },
                {
                    "sent": "The authors doesn't.",
                    "label": 0
                },
                {
                    "sent": "Doesn't do not have the cultural sensitivity and don't follow the editorial guidelines, which requires to be careful when mentioning words like Tribe in the negative context, one could even say it was a kind of Western writing style.",
                    "label": 1
                },
                {
                    "sent": "So actually in the Western articles it was many times mentioned much ads.",
                    "label": 0
                },
                {
                    "sent": "Tribes, problems, ethnics and so forth, whereas in local media you couldn't find this kind of words.",
                    "label": 0
                },
                {
                    "sent": "OK, so it it was indeed interesting from the pragmatic point of view to analyze these outlier documents.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, can we evaluate whether we found something interesting in this cross context discovery, specially in literature based discovery when we looked at documents from different domains.",
                    "label": 0
                },
                {
                    "sent": "So for dissent we used Mygrain magnesium again as a domain and autism calcineurin, which was investigated in our previous research.",
                    "label": 0
                },
                {
                    "sent": "We used an ensemble consisting of three different elementary classifiers and we try to evaluate whether there is some potential.",
                    "label": 1
                },
                {
                    "sent": "Or be term detection in those documents and we knew which bit term there was because other researchers have proven which are the cross context terms.",
                    "label": 0
                },
                {
                    "sent": "So we did it through number of the terms appearing in the detected documents.",
                    "label": 1
                },
                {
                    "sent": "Oh I'm I'm very late actually, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that there is strong bias and outlier documents indeed have a much larger number of bridging terms than the average documents.",
                    "label": 0
                }
            ]
        }
    }
}