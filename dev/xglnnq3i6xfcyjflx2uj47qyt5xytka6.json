{
    "id": "xglnnq3i6xfcyjflx2uj47qyt5xytka6",
    "title": "Pinview: Implicit Feedback in Content-Based Image Retrieval",
    "info": {
        "author": [
            "Zakria Hussain, Department of Computer Science, University College London"
        ],
        "published": "Sept. 20, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Information Retrieval",
            "Top->Computer Science->Semantic Web->Annotation"
        ]
    },
    "url": "http://videolectures.net/wapa2010_hussain_pifc/",
    "segmentation": [
        [
            "Yeah, so I'm going to be talking about Ping View and say.",
            "So that would be 7 funded grant.",
            "Through a few years back and I've been working on this in the Post office at University College London for the last two and a half.",
            "So here's this joint work with a number of people and their based University of New bananas, UCL also University in Finland and University of Southampton."
        ],
        [
            "So what is the Pindo project?",
            "So as I said, it's an FP7 funded grant.",
            "It's a European wide Commission and your proposed you would ask her proposal and sending something that they think is relevant to to fund an this preview project.",
            "The goal of this project was to find out a proactive personal information navigator that allows retrieval of multimedia, such as still images, text and video from unannotated interface basis.",
            "So what does this mean?",
            "So we want to find that out given a database of images that don't have tags or or any information related to them.",
            "In that way we want to use the content of those images in order to to retrieve relevant information, and you want to do this using some implicit feedback, so that if you actually stands for personal Information Navigator that's interviewing and that's where the preview acronym comes from.",
            "So implicit feedback in this case is eye movement.",
            "That we used.",
            "We have night tracker track.",
            "The island was off for the user or web page or a page.",
            "Generally in this context, over a page of images and then based on what they're looking at, we want to infer what it is that they're interested in, and from that information we want to give them more relevant images.",
            "And the retrieval part is this content based image retrieval.",
            "So I mean this this information navigating you could do in many different ways, but this a CBI.",
            "Our system is typically known as is quite nice.",
            "A nice framework for working and so maybe the framework that we've used in this in this painting project.",
            "If anybody is interested you can go to the website on the discontinued."
        ],
        [
            "So who's involved as the ultimate University of Science and Technology?",
            "Previously TKK Technical University?",
            "Helsinki University College London.",
            "University of Southampton University, but these are the four academic partners and then we've got two industrial partners.",
            "One is 0 research in France and wanted to see them in Austria."
        ],
        [
            "Schedule.",
            "So what's the motivation?",
            "So the motivation is the following thing.",
            "So we've got on the left here picture of this is an eye tracker.",
            "Distracts the eye movements of of the user and these these two dots here or there for pupils of the of the user, and so initially would go on to this system and it would calibrate your eyes so you would move your eyes up and down to the top left, top right and follow a ball and it will be able to follow your your pupils.",
            "So here's a user at the desk here with which has been set up with this Toby I tracker.",
            "So this is the eye tracker here.",
            "You gotta keep quite still.",
            "I mean there are this eye tracker here is is quite an expensive piece of kit and this is one of the I mean.",
            "I went to an eye tracking conference earlier this year and there was lots of different eye trackers there.",
            "Some of them actually place you into a thing that you can't even move your head with everyone.",
            "19 essentially, and I think a lot of psychologists that do these experiments tend to it to like those.",
            "This Toby I tracker.",
            "You've gotta more movement that you can.",
            "You know.",
            "Obviously you can move your head, but you don't want to move it too much because you would lose the calibration.",
            "So you do have to stay pretty still, but so the idea here is that this user here is being attracted to calibrate the eyes.",
            "So this screen.",
            "Then when then we give them some images and based on what they're looking at, we want to then, so we give them.",
            "Collage of images so 15 images in our case, based on what they're looking at, we can infer what they're interested in based on what they were looking at, and then they click the money major or a couple of images to give us, you know, some explicit feedback on those that are relevant, and then we update our algorithms.",
            "We update the system and then we give them a new set of images that hopefully should now be more relevant to what they were looking for.",
            "OK, so that's the motivation is.",
            "This was the goal."
        ],
        [
            "Of the project.",
            "I'm so confused.",
            "Images people as I mentioned earlier, is to find relevant images in another annotated database, so content based means that you analyze the actual contents of the images, are not keywords such as tags or image descriptors descriptors, because you don't have these things.",
            "You may have lots and lots of hundreds of thousands of images, millions of images that you've not not happen, taxable.",
            "There's no description about those images.",
            "The relevance feedback is feedback provided by user on retrieved images during pure search, and there's two types of feedback on this.",
            "2 broad classes of feedback and there's this explicit feedback which is very user states.",
            "The relevance of an image using the direct method, so this may be a politically I think in the picture I had, there's a guy had a thing there which is to move the image images forward.",
            "But hey, you would have a mass and you would do basically click.",
            "Maybe would have a box underneath the image and you click this relevant or you maybe just click on the image to say OK this is relevant and then the other form is this implicit feedback.",
            "This is what we're interested in or what we've been interested in throughout the project.",
            "This is brilliant.",
            "The relevance of images based on the user's behavior and the behavior that we're looking at modeling.",
            "This is at these diamonds, so tracking my numbers we want to know.",
            "At all to figure out what it is."
        ],
        [
            "So the pin view system components that we have on the components that are needed are these four.",
            "These are 4 broad classes of components that I.",
            "Listed here, so the first one is this relevance prediction.",
            "So relevance prediction is to predict the relevance of images based on the implicit feedback.",
            "So we've got a turbulent tractor.",
            "We track the item, implements people are looking at the images, we extract these features and then based on this construction we we run this through some algorithm.",
            "It's going to be logistic regression to them predict which ones were relevant or not.",
            "So we'll have some offline experiments where we did some offline experiments or what their online.",
            "Experiments and then later on we actually used those to find this decision rules.",
            "So this is just a regression model.",
            "So then give us a function that when we have now future images we would put them through this logistic regression function and then there would be a threshold that we found during this training phase that would then tell us which ones were relevant or not based on this image features.",
            "Then the next step is to actually explore new images and exploit close by images to those considered relevant.",
            "So based on what the user has the information the user is given us on on whether these images are relevant or not.",
            "We want to do carry out this exploration exploitation problem.",
            "So you want to exploit that close to the ones that user is.",
            "As defined as being relevant, but we want to also take into account or explore those images that maybe they may not have the chance to see if we only give them the sportive two choices, which is the choices that are very close to the ones they've already considered.",
            "The next step is to learn the metric.",
            "This is to just generate the richer metric space for the exploration exploitation algorithm.",
            "So we have several different types of feature extraction methods over the images, so we've got these features that we have from the eye movements and then we for each image.",
            "We can have several different types of image feature extraction methods, so we can then learn an appropriate metric for this exploration.",
            "Exploitation algorithms are working and the idea behind this is that sometimes if you're looking for an image, maybe 2 features may be important.",
            "For instance color and texture.",
            "Whereas if you were looking for an image of.",
            "The Sky is something color is probably the most important feature.",
            "Once you have something that's blue and very larger around that image thing, but chances are it's probably going to be via Skype.",
            "So that's the point behind there the learning metric.",
            "The feature selection scenario here is that now we've got these two sets of features.",
            "We've got design movement features from the Toby I tracker, and we've also got these image features.",
            "So is there a way of of of combining these two feature sets?",
            "Can someone explain some form of feature selection?"
        ],
        [
            "So the component algorithms, as I mentioned logistic regression, is for the first one for the relevance prediction.",
            "The second one, the expiration exploitation phase.",
            "Is this associative reinforcement learning with linear value functions in Ralph?",
            "This is this is the expiration exploitation stuff that I was mentioning.",
            "It's very similar to what?",
            "That's alright, I was talking about yesterday with this ad predictor thing for for Microsoft, where there's a sort of like a Bayesian interpretation of this, this algorithm is enroll type of procedure where you can trust to exploration and exploitation.",
            "The learning the metric phases this multiple kernel learning.",
            "This is quite popular in the kernel learning community, where you you may have several or hundreds of different types of kernels and you try to combine them in some way.",
            "And then it's tense.",
            "Recipe ends this feature selection problem."
        ],
        [
            "So this is a picture of of this pin view system that we have.",
            "So we've got I movements here on the left.",
            "So from his arguments we extract some features so it turns out that we first started 3 features that I mentioned.",
            "Some of the features later on Thursday 3 features.",
            "Now these first 3 features are pastoralist expression model, which then then finds a function that can predict relevance of images with some probability, and in the meantime we also pass these black features to this tensor.",
            "Function here.",
            "OK, we've got some images.",
            "We've got an image database with carry out some feature extractions and give us 11.",
            "We're going to have 11 different types of features.",
            "And then these eleven different features would be passed this multiple kernel learning face, multiple color learning phase.",
            "Then with these 11 features, will consider this is 11 different kernels, giving these eleven different kernels will carry out multiple common learning phase where we will learn a good waiting for good combination of these features.",
            "These kernels, this also requires this relevance as well to this.",
            "Residence line should also be going into multiple kernel learning, so this image relevance now goes to this tensor.",
            "The tensor is is now taking the the similarity metric file from multiple kernel learning, which remember is just from the features of the images and it combines it together with the.",
            "With these features here, from the bottom here, so these features were the ideas of features.",
            "These items were features come into the sensor and also from the top.",
            "Here we get the information of the relevance of those images and then from there multiple kind of learning.",
            "Get a combination and you Colonel combination of the image features.",
            "Given this we carry this intense carry out this tensor SVM algorithm which projects into a common space.",
            "Semantic representations not pass this limbrel algorithm discipline REL algorithm is doing the expiration exploitation says linear algorithm is actually given.",
            "Now this new metric feature space it's now going to run and then pass out new images for the user the user now.",
            "I mean this will now repeat the user.",
            "Now will see those images and maybe click on one of the images to give us explicit feedback on one image to say yes this is relevant and then the other information or feedback will get.",
            "Is probably arguments over the other images, so they may have 15 images on the page.",
            "They may click one of those to say yes this is relevant and then three or four of the others based on the right movements and based allow logistic regression model we find to be relevant.",
            "So now in the next step this all goes through again and now we've got 5 images that were relevant for images that were relevant.",
            "One from this explicit click, 3 from his implicit feedback from the eye movement, and then we pass this through the model again.",
            "You know, we learn you metric, you know to update based on what the user has been.",
            "The feedback from users been giving us."
        ],
        [
            "I'm sorry I moved with.",
            "Collected, I don't think everybody can see this, but I mean says 19 here.",
            "There's actually 33.",
            "I don't have 30 three list here, but there's some interesting ones here.",
            "So the top we have.",
            "The log of total time of viewing the image OK would be an important thing.",
            "That's open time for measurements outside fixations.",
            "Then As for here, this fixation features such as total number of fixations to the number of fixations on an image.",
            "Is the number of revisits to the image this one here 14 so the numbers aren't.",
            "You revisit the image so you may you have a set of images and you may look at the image.",
            "Go go and look at some others and you may come back.",
            "So how many times did Russia come back?",
            "So there's it says 33 different features that we actually extracted from their Toby, Toby I tracker."
        ],
        [
            "So this is what typical page will look like, so we have, so there's 15 images.",
            "So in the collage that we will be using will be 15 images.",
            "So you have these images.",
            "The Red, red, red lines of the visa cards with what they used was actually looking at all the movements that their eyes were making the circles of the measurements.",
            "So that the red dots correspond to rule measurements belong to those fixations.",
            "Are the red dots are the very not sure you can see those very very small red dots, so these are fixations that we actually take into account and then the small black ones are.",
            "Maybe, you know, error or something like that.",
            "We don't take into account we don't use these in the measurements of Black dot micro measurements that were not including any of the fixations.",
            "Specifically, a user will will get this screen screen like this and we will give them a task.",
            "We say look for images of.",
            "Of a dog.",
            "OK, so they may get random, so the first page will be a random image of random set of 15 images from some database that we have, and now they're going to mark.",
            "We're going to look at these and then they're going to mark one explicitly and say this is closest to the dog for instance, and then based on what they were looking at and based on our logistic regression model, we will try to infer with high probability which one which other ones were relevant is working, and this will just be updated in our system.",
            "Then in the next step we should hopefully have more relevant images."
        ],
        [
            "Information.",
            "So the relevance prediction isn't mentioned is we want to predict relevance of images based solely on the evidence.",
            "So this this is we dimension vectors.",
            "So we extract us and said this statistical features.",
            "We train a logistic regression model and data set online start sessions.",
            "So this is what I mentioned earlier.",
            "So we we gave them, we gave users a search session.",
            "I don't remember what the searches the queries actually were, but it may be things like you know search for dogs etc etc.",
            "We know in this database which ones are dogs for instance and which ones are not.",
            "The user would go through.",
            "Look at their eyes and see them based on what?",
            "Knowing the ground truth of knowing actually what dogs were, we know the I movements were telling us over those images and what they were saying over the other images.",
            "We run this through the logistic regression models.",
            "Given these labels of dogs and not dogs, and then we have a function which then predicts given new image features that should generalize, giving you image features whether something is relevant or not.",
            "And then we use the logistic regression model to predict relevance of image based on these three."
        ],
        [
            "I'm looking for features.",
            "The expiration exploitation phase.",
            "This is where we actually need to pass in passback the images to to the user.",
            "So now we've we've learned which images are relevant.",
            "We've given this feedback to our model and the expiration really is the heart of the of the system.",
            "This is the part which is actually saying OK. Based on all of these images in the database based on what the user has seen and the relevance feedback they've given me through their eye movements through this point and click.",
            "Now, given all of the other images in the database, I can now give back another 15 images that I think are the most relevant.",
            "OK, this is done through this expiration expectation, so the expectation is to find those that are indicated as relevant finding, which is closer to those indicated as relevant, and the exploration phase is defined images further away, and this is just in case we missed something.",
            "OK, let me use it."
        ],
        [
            "Gorilla so linear algorithm is A is a come from reinforcement learning literature and the objective is to maximize the number of relevant images presented to the user.",
            "So there's some of this YT that sees the relevance of the team image.",
            "OK, assumption the assumption we make is the expected value of the relevance.",
            "Why I is a linear function of the image?",
            "Features excellent, so this is just a linear function here, so this expectations include W transpose, SWS, await vector.",
            "I'm just saying it's just a linear function itself."
        ],
        [
            "Out of this problem is actually equivalent to.",
            "Just the living standard linear regression.",
            "So inspiration T enroll estimates W this way back to W from previously presented images XT16.",
            "Now these are these are rose and the observed relevant scores YT.",
            "So these are the given these images that you see next one up to X T -- 1 each one of these and is an image.",
            "Image vector each of X up and then these whitey's.",
            "These are the corresponding relevance is of those images we can just use within your regression and linear regression to our our men over W. This expression here which is the norm square should give you the norm square error between this prediction of W transpose X or XX WS is written here minus dot YT.",
            "Then the estimated weight vector vector predicts the relevance of image.",
            "As Yi hat is equal to WT hat for us was excellent.",
            "This is exactly what you were doing in your regression adrenaline regression getaway pack.",
            "So you take the product of that weight vector, image vector or image feature and you have some prediction of your.",
            "So our prediction now this is our prediction irrelevance.",
            "General optimistically select images which might be most relevant given the variance Sigma.",
            "I squared away right so we calculate the variance and this variance is the exploration stage.",
            "So the image I with maximum W transpose XIN Plus C. Some constant Sigma I is selected signifies the variance of this term and what this actually means is that.",
            "This term here is the exploitation step and this time here is essentially so this time.",
            "Here's the exploitation step, and this time here is giving us the exploration step.",
            "So this is known as a slim roll algorithm came about and there's no Mr.",
            "Maximizing upper confidence power.",
            "So if you actually maximize this quantity, you actually maximizing our performance.",
            "But which is actually trading off this thing of exploration, exploitation very nicely."
        ],
        [
            "One going to the details of that, but just the detail of this linnros with them just to make it a bit clearer.",
            "Eyes that remember these XT are the images of.",
            "Is there is a matrix of the images previously seen by the user?",
            "OK, so if the users seem to collage in, each collage has 15 images, then there's some 30 images, so this will be a 30.",
            "Number 30 by the number of dimensions of this feature background for this feature space.",
            "His eyes the identity matrix.",
            "So this right hand side here.",
            "Plus YT would essentially give you a linear regression.",
            "Solution of linear regression.",
            "OK, he's supposed to push, and putting in this XI.",
            "Now we now have this AI is respect to AI, which now we can.",
            "We can write in terms of that expression.",
            "I had a previous slide with the W transpose X + Y times the variance as this time here.",
            "So the variance actually comes out of the mathematics is just being the norm of this way vector of this vector sum AI for this work.",
            "This vector AI can take along with.",
            "Responsible parents, so now if you maximize this quantity then you are actually carrying out this expiration interpretation step, so you will give him the old.",
            "The old images given a new image excite, you could say given all of the new images that I've not seen or not presented to the user, compute this upper confidence bound.",
            "Compute this value here and then maximize.",
            "Find findings image that maximizes this, and this is the image that would not present."
        ],
        [
            "OK, we can finalize this linear algorithm which is very simple.",
            "Looks very similar to a kernel version of least squares regression, so you've got this kernel here.",
            "You've got mu, which is the rich brands are the identity matrix here, so the inner product of that, and now what you do is you multiply that by the basis vector, which is the better.",
            "The kernel matrix or the kernel entries between the image that you have by now and the images I want I see most of the images that you saw previously, so you saw 30 images previously.",
            "It would be those images I want to I T -- 1 those 30 with the new image that you have and this will give you a kernel version.",
            "And the reason we're doing this."
        ],
        [
            "Virgil said now we can plug that into the multiple kernel.",
            "That way we could do multiple kernel learning.",
            "Lots of different kernels and then plug that directly into that.",
            "Enrollment is kernelized in round version, so another open open problem is how do you select these images and images at once?",
            "You can select the N images with maximum of confidence bounds so that quantity.",
            "The algorithm I showed in the previous slide."
        ],
        [
            "This one here AI.",
            "So we would given the kernel."
        ],
        [
            "Version, so given this kind of agent version AI, we can plug in this AI."
        ],
        [
            "Into this equation 2 and we have kernel version.",
            "So if we plug that in to this here and then."
        ],
        [
            "And maximized at select the N images with maximal confidence balance.",
            "Then we have this first possibility of choosing, so we would run that algorithm that Lynn role would sort all of the images that we've not seen in descending order.",
            "People stop N we can present most top end.",
            "This would be quite a lot of exploration you would be doing because you've got the various done.",
            "The second one would be where you pick the top one with this upper confidence bound and the next say N -- 1 of them, you would just pick.",
            "The one that's maximizing W transpose X, which is the.",
            "Remember this is the exploitation step, so now you're doing more exploitation, not so much inspiration.",
            "And then you can have a middle ground in the middle ground.",
            "We iteratively select any images by their overconfidence pals, updates, the relevance, the relevance we know is double transpose X, so you update the relevance and then you repeat.",
            "So you add that into your set now.",
            "So the XT now becomes X T + 1 because you've updated and then repeat that up to the end.",
            "This one up to the end that you want to print."
        ],
        [
            "Launch.",
            "Learning the metric.",
            "11 So this is this is the stage where we now want to learn a different metric, wants to learn a different metric.",
            "To pass into the linear algorithm so 11 different feature extraction methods that we use, including skin color, hard transform etc etc.",
            "So each of these feature extraction methods can be can be viewed as a kernel.",
            "So we have now 11 kernels and we'd essentially like to learn a kernel using multiple kernel learning so so so remember here in the mineral algorithm all we need are these kernel entries.",
            "OK, so this this kernel matrix here is just kind of interest between each of the indices IIIJ where these run up to images that were in the sink.",
            "So that's all that needs need.",
            "But that's all we need for kernel version and then run.",
            "So essentially for MCL we have this, this vector, an Easter story, which is, which is the weights of each of the kernels.",
            "So this would be 11 dimensional and.",
            "We would essentially weight each of the KK subscript.",
            "I is one of the kernels that we have to one of the 11 kernels and I would like to take a weighting of these and this would be a convex combination so that someone comes into eaters with some to one.",
            "So each time we get this feedback mechanism we get this feedback and then based on that feedback or relevance we update our feature vector because at the start of the search it may may be clear we may have a lot of the image.",
            "A lot of the feature vectors alot of the kernels are used their important.",
            "A lot of the information from different features are important, but as we as we move on in the iterations after a few pages you would think that as the user is looking for a particular things some of these image features some of these kernels are zeroed out and not any more important.",
            "There are other important features so we're essentially doing more of an exploration at that stage of the motherland.",
            "I won't go over this."
        ],
        [
            "Then there's the feature selection using eye movement, so this is where we take.",
            "If you just look at this this kernel here would be an image kernel to the image panel that we were computed using the multiple kernel learning.",
            "I'm going to take a tensor.",
            "We will take a.",
            "We take the tunnel between the eye movements and we take not an inner product, but componentwise products.",
            "So this corresponds to a tensor product in the feature space, which is essentially the idea here is to actually project your image in your eye movement features into the same space into a common space.",
            "But the problem is is that when you project into this common space, you have images of you have eye movements of the images that the user has seen, but you don't have.",
            "The eye movements of the images they haven't seen so you would project the image features of the images they've seen and the eye movement features into the same space.",
            "And then you can project.",
            "Now the image of the images that have not been seen into the same semantic space and this is somehow we feel using using the information of the eye movements and the image features together in this in this semantic learning the metric type procedure and it also.",
            "Is an STD like procedure, so this carries out feature selection as well, so hopefully removing irrelevant features."
        ],
        [
            "Of the experimental setup was that we had a pastel visual.",
            "We style visual objects database lock 2007.",
            "We perform online experiments with simulated test search sessions.",
            "Sub session intuitively use pin view to select a total of 10 colleges with 15 images need so the total is 150 images so we had 10 central lodges in for each one was 15 images.",
            "The target of each session is one of the categories so this is what challenge has 20 million 21 categories.",
            "So for each of the search sessions one of those countries must be the problem.",
            "Searching for social number of sessions was 40.",
            "We use precision.",
            "Recall is our measure of success.",
            "And the idea was recorded using this to be so we 1750 like."
        ],
        [
            "So this feedback modalities full.",
            "So this is where we use the true label of the scene images.",
            "So we've got the true label of these images.",
            "This is simulated.",
            "Click where relevant random image and collage selected is clicked.",
            "Simulated I is where we simulate the items from previous online experiments to predict relevance images.",
            "This is logistic regression model that we found.",
            "So we keep all of relevant and non relevant image.",
            "I'm moving features and then we sample from these two groups in the offline experiments.",
            "And then this simulated iPod click is where we we we put together the images that were relevant from the Islanders that we found in the randomly selected one from the clinic and we put these together.",
            "So in the first one the simulated clip, we may only give them one image of 15 that is relevant.",
            "In the second one, Mega Extra three or four and then this one we have the 1 + 3 or 4."
        ],
        [
            "And so these are the results.",
            "And what would like to see is that so random here is where randomly each collage each iteration randomly just given 15 images, so that you would expect to be the worst and you can see to the left it's always the worst.",
            "So these these figures here, for each of the categories of the child.",
            "So you've got cats.",
            "Dogs are here with his dog.",
            "He would have images of.",
            "Of dogs and other images in the database and we try to look for for the dog images is as relevant to the white one.",
            "Here is where we use this as best.",
            "Pretty much this is where we use the actual feedback is being the actual images on that page that were dog made the truth.",
            "The truth in the the ones selected that here is the simulated I plus click.",
            "The middle one is basically simulated simulated click.",
            "So this is where you randomly pick one.",
            "The images on page one of the positives, so one of the dog images soon they have $4 and you just run with it once.",
            "OK, that's my feedback, which can use that one.",
            "And then this one here we just use the island lights.",
            "So, so the results here are better than the random.",
            "Obviously not as good as the full, but the point the point in note here is that in most cases I think in the average the simulated plusquellic simulated items plus quit performs better than simulated click or simulated.",
            "Or just having I.",
            "So if you just have eye movements and just have click, it works well, but if you have both together then you really do.",
            "You gain some some improvement.",
            "And so clearly we are.",
            "We are getting some improve."
        ],
        [
            "Based on my movements.",
            "And so that's that's the conclusion to the conclusions are that we proposed and you see our system that uses relevance feedback from my movements.",
            "So implicit relevance feedback, we can infer the relevance of images relatively well from my movements, and this is using the logistic regression model.",
            "Unobtrusively improved user experience by adapting user interface.",
            "The interest of the user.",
            "I'm not sure how unintrusive it is.",
            "2 points and I tracker it somebody's eyes.",
            "But yeah, I mean that's pretty unobtrusive I guess complaints.",
            "Some some methods and then we incorporate this into an algorithm into assistant will pick some system which allows the use of real world image databases.",
            "This is all available online and the future plan is to perform these online experiments on real subjects.",
            "Thank you very much for your time.",
            "Time for a couple of questions maybe?",
            "I wanted to ask a couple things, but one thing was.",
            "If you have a.",
            "The user is searching for something which is maybe less common.",
            "And your initial pool is unlikely to to have that image in it.",
            "Yeah, you're both both metrics of relevant.",
            "Both the click and the eye tracking kind of assume that there is something relevant there due to the image.",
            "Yeah, but there's kind of no way of saying I'm going to look over here and nothing is relevant to me or so.",
            "So The thing is, if.",
            "If what might happen is is the user just sort of, looks around randomly and making looks more or something that's a bit more interesting than not really what he's looking for.",
            "Yeah, he or she sorry and then the system will potentially sort of overlay over Explorer in the wrong direction because it's, well.",
            "OK, so the exploitation is there to exploit or to look for images.",
            "But somebody, a participant said is this is relevant, right?",
            "So you're going to look for things that.",
            "Close the exploration phase is to look for things that are quite far away, so you may you know by chance get something that is then that comes in, But then is similar to what you were looking for.",
            "Another option is just to run the thing and and not to give any feedback, but if you go for many sessions and you not getting feedback and we really got negative data and not got anything positive to learn from.",
            "So I'm not sure how.",
            "Yeah just wonder that it might sort of prematurely exploit.",
            "In the wrong direction, because because your your feedback is positive rather than that there's not.",
            "There's kind of no negative feedback, so this is not working well.",
            "We can then just regression model can give you a probability of.",
            "I mean, it gives you a threshold and an actual function value on this.",
            "On this card, which I think there's a threshold reset, I think there's a threshold found a .3 four so, so we will actually won't actually use.",
            "We won't say these are relevant and everything else is zeroed out or not relevant, but it will sort of be an indication of relevance.",
            "So the higher the value, the more and the lower value, the less room.",
            "I agree that you guys still think that because there is no room for negative influence, there's no way you can discard images.",
            "I mean, there would also be useful feature.",
            "Now when you say simply know none of these images is anywhere near is what I'm looking for.",
            "It will also be information for you.",
            "That is, yeah you could.",
            "You could.",
            "All of them before they make this decision.",
            "Taking my eye movement was a thing like he's actually looking at this picture.",
            "Yes, I'm moving it because I'm deciding I don't want things related to decide this year so.",
            "Yes, normally but still interested question it something because I'm interested in.",
            "These are the images after moving all of them, so.",
            "Alright, but we used.",
            "You know we used the idea that you can generalize from from even a bunch of images that you have the positive and negative you know the relevant and non relevant.",
            "We can generalize from that because we run this model.",
            "This logistic regression model and we know how they've looked at images that are relevant and those that are not regular form that we can generalize.",
            "So it doesn't.",
            "It's not just necessarily that they've looked at a particular image for a certain way, or.",
            "I mean they can look at many images and it doesn't mean that they're going to be ready.",
            "So it's going to be based on this model.",
            "We are going to give those features into.",
            "This model is OK Now, given this logistic regression model with probability.",
            "Is this relevant or not?",
            "Sorry no no.",
            "The number of features that you used for image is actually quite well.",
            "It's 1111 features for Image 11 features and now using your local moving system, you're actually providing some feedback system, reducing the features and you're highlighting words that are more yes.",
            "Order in order to rent the images that are most close to the points that you guys have you done any experiments with completely?",
            "Night bro Chin Hua simple distance matrix based on the 11 features and simply say OK.",
            "But the guys who can give his image given 15 closers in terms of the feature space that you would already be fine because the feature space itself is not changing, you just weighing it slightly differently.",
            "If you don't do anything.",
            "Yeah, so I never.",
            "I never went over this slide here.",
            "Skip this one 'cause of time.",
            "But essentially the multiple kernel learning is is doing this one more.",
            "Regularization is to normalization.",
            "So if you effectively this louder.",
            "Value here is between 01.",
            "If you set this Lambda value to zero, you remove this one more thing and removing this one more means that you don't pick out a small number of them keeping the two norm means you pick out all of them went all of them.",
            "So the question you are asking is that or one thing you can do is essentially you can take those 11 features.",
            "You can concatenate them into one big feature vector and then just run it through distance mode.",
            "Yes, this would correspond to evenly weighted.",
            "This would be where.",
            "Each of the each practice is even rated.",
            "Yes, we've done those experiments in this.",
            "If I set this Lambda zero, then essentially will correspond to something similar to that.",
            "It doesn't mean that each of the what it means.",
            "Each of these kernel matrices will have a value of greater than zero, but not necessarily have equal value or even even waiting.",
            "But when we ran experiments with even waiting, it seems to perform well, but.",
            "Not always better than the combinations that you found just because if you have to fix it, they can do it.",
            "But I'm looking at the image that the pre calculated.",
            "So yeah, then it's very fast.",
            "I mean the other thing I didn't mention is that I mean running multiple kernel learning isn't that expensive because a search session is going to last maybe maximum 20 pages, which is 300 images.",
            "The biggest Colonel you're going to work with this 300 by 3.",
            "Oh yeah, this is going to be pretty pretty fast, but yeah, I mean if you if you want to, if you want I can just set Lambda to 0.",
            "So OK, just find me everything you know, just give me everything.",
            "If I set this to 0.",
            "But if I set this to one then it's going to find a very small number of them.",
            "And somewhere between these things be doing something between and.",
            "I think the idea here was that you know this regularization and the idea was this this thing, where at the start I want to use a lot of features, but near the end I want to make.",
            "A more important so I could in effect after some five collisions or something that could change this Lambda value, could start it big and then make it smaller, but yeah.",
            "Is there a disturbed affect?",
            "What happens if the user does fine make more deliberate eye movements to convey information to certain?",
            "Subjects none say, will use their own movements to improve effectively.",
            "The images that Ben suggested.",
            "So this logistic regression model that I've been talking about this is very fancy model, right?",
            "You don't want to keep falling through, you know 20 pages.",
            "You know 'cause you know if you do a Google search, you want it to be.",
            "You want the hits to be at the top and it's the same.",
            "Same principle here so, but exaggerating.",
            "I'm not sure if exaggerating and having that relevance feedback would actually improve the results for the liberal or the OK so.",
            "Right, I think we should still.",
            "Here we are using it so much, right?",
            "So let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so I'm going to be talking about Ping View and say.",
                    "label": 0
                },
                {
                    "sent": "So that would be 7 funded grant.",
                    "label": 0
                },
                {
                    "sent": "Through a few years back and I've been working on this in the Post office at University College London for the last two and a half.",
                    "label": 0
                },
                {
                    "sent": "So here's this joint work with a number of people and their based University of New bananas, UCL also University in Finland and University of Southampton.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the Pindo project?",
                    "label": 0
                },
                {
                    "sent": "So as I said, it's an FP7 funded grant.",
                    "label": 0
                },
                {
                    "sent": "It's a European wide Commission and your proposed you would ask her proposal and sending something that they think is relevant to to fund an this preview project.",
                    "label": 0
                },
                {
                    "sent": "The goal of this project was to find out a proactive personal information navigator that allows retrieval of multimedia, such as still images, text and video from unannotated interface basis.",
                    "label": 1
                },
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "So we want to find that out given a database of images that don't have tags or or any information related to them.",
                    "label": 0
                },
                {
                    "sent": "In that way we want to use the content of those images in order to to retrieve relevant information, and you want to do this using some implicit feedback, so that if you actually stands for personal Information Navigator that's interviewing and that's where the preview acronym comes from.",
                    "label": 0
                },
                {
                    "sent": "So implicit feedback in this case is eye movement.",
                    "label": 0
                },
                {
                    "sent": "That we used.",
                    "label": 0
                },
                {
                    "sent": "We have night tracker track.",
                    "label": 0
                },
                {
                    "sent": "The island was off for the user or web page or a page.",
                    "label": 0
                },
                {
                    "sent": "Generally in this context, over a page of images and then based on what they're looking at, we want to infer what it is that they're interested in, and from that information we want to give them more relevant images.",
                    "label": 0
                },
                {
                    "sent": "And the retrieval part is this content based image retrieval.",
                    "label": 0
                },
                {
                    "sent": "So I mean this this information navigating you could do in many different ways, but this a CBI.",
                    "label": 0
                },
                {
                    "sent": "Our system is typically known as is quite nice.",
                    "label": 0
                },
                {
                    "sent": "A nice framework for working and so maybe the framework that we've used in this in this painting project.",
                    "label": 0
                },
                {
                    "sent": "If anybody is interested you can go to the website on the discontinued.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So who's involved as the ultimate University of Science and Technology?",
                    "label": 1
                },
                {
                    "sent": "Previously TKK Technical University?",
                    "label": 0
                },
                {
                    "sent": "Helsinki University College London.",
                    "label": 0
                },
                {
                    "sent": "University of Southampton University, but these are the four academic partners and then we've got two industrial partners.",
                    "label": 0
                },
                {
                    "sent": "One is 0 research in France and wanted to see them in Austria.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Schedule.",
                    "label": 0
                },
                {
                    "sent": "So what's the motivation?",
                    "label": 0
                },
                {
                    "sent": "So the motivation is the following thing.",
                    "label": 0
                },
                {
                    "sent": "So we've got on the left here picture of this is an eye tracker.",
                    "label": 0
                },
                {
                    "sent": "Distracts the eye movements of of the user and these these two dots here or there for pupils of the of the user, and so initially would go on to this system and it would calibrate your eyes so you would move your eyes up and down to the top left, top right and follow a ball and it will be able to follow your your pupils.",
                    "label": 0
                },
                {
                    "sent": "So here's a user at the desk here with which has been set up with this Toby I tracker.",
                    "label": 0
                },
                {
                    "sent": "So this is the eye tracker here.",
                    "label": 0
                },
                {
                    "sent": "You gotta keep quite still.",
                    "label": 0
                },
                {
                    "sent": "I mean there are this eye tracker here is is quite an expensive piece of kit and this is one of the I mean.",
                    "label": 0
                },
                {
                    "sent": "I went to an eye tracking conference earlier this year and there was lots of different eye trackers there.",
                    "label": 0
                },
                {
                    "sent": "Some of them actually place you into a thing that you can't even move your head with everyone.",
                    "label": 0
                },
                {
                    "sent": "19 essentially, and I think a lot of psychologists that do these experiments tend to it to like those.",
                    "label": 0
                },
                {
                    "sent": "This Toby I tracker.",
                    "label": 0
                },
                {
                    "sent": "You've gotta more movement that you can.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "Obviously you can move your head, but you don't want to move it too much because you would lose the calibration.",
                    "label": 0
                },
                {
                    "sent": "So you do have to stay pretty still, but so the idea here is that this user here is being attracted to calibrate the eyes.",
                    "label": 0
                },
                {
                    "sent": "So this screen.",
                    "label": 0
                },
                {
                    "sent": "Then when then we give them some images and based on what they're looking at, we want to then, so we give them.",
                    "label": 0
                },
                {
                    "sent": "Collage of images so 15 images in our case, based on what they're looking at, we can infer what they're interested in based on what they were looking at, and then they click the money major or a couple of images to give us, you know, some explicit feedback on those that are relevant, and then we update our algorithms.",
                    "label": 0
                },
                {
                    "sent": "We update the system and then we give them a new set of images that hopefully should now be more relevant to what they were looking for.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the motivation is.",
                    "label": 0
                },
                {
                    "sent": "This was the goal.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the project.",
                    "label": 0
                },
                {
                    "sent": "I'm so confused.",
                    "label": 0
                },
                {
                    "sent": "Images people as I mentioned earlier, is to find relevant images in another annotated database, so content based means that you analyze the actual contents of the images, are not keywords such as tags or image descriptors descriptors, because you don't have these things.",
                    "label": 1
                },
                {
                    "sent": "You may have lots and lots of hundreds of thousands of images, millions of images that you've not not happen, taxable.",
                    "label": 0
                },
                {
                    "sent": "There's no description about those images.",
                    "label": 1
                },
                {
                    "sent": "The relevance feedback is feedback provided by user on retrieved images during pure search, and there's two types of feedback on this.",
                    "label": 0
                },
                {
                    "sent": "2 broad classes of feedback and there's this explicit feedback which is very user states.",
                    "label": 0
                },
                {
                    "sent": "The relevance of an image using the direct method, so this may be a politically I think in the picture I had, there's a guy had a thing there which is to move the image images forward.",
                    "label": 0
                },
                {
                    "sent": "But hey, you would have a mass and you would do basically click.",
                    "label": 0
                },
                {
                    "sent": "Maybe would have a box underneath the image and you click this relevant or you maybe just click on the image to say OK this is relevant and then the other form is this implicit feedback.",
                    "label": 0
                },
                {
                    "sent": "This is what we're interested in or what we've been interested in throughout the project.",
                    "label": 0
                },
                {
                    "sent": "This is brilliant.",
                    "label": 1
                },
                {
                    "sent": "The relevance of images based on the user's behavior and the behavior that we're looking at modeling.",
                    "label": 0
                },
                {
                    "sent": "This is at these diamonds, so tracking my numbers we want to know.",
                    "label": 0
                },
                {
                    "sent": "At all to figure out what it is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the pin view system components that we have on the components that are needed are these four.",
                    "label": 0
                },
                {
                    "sent": "These are 4 broad classes of components that I.",
                    "label": 0
                },
                {
                    "sent": "Listed here, so the first one is this relevance prediction.",
                    "label": 0
                },
                {
                    "sent": "So relevance prediction is to predict the relevance of images based on the implicit feedback.",
                    "label": 1
                },
                {
                    "sent": "So we've got a turbulent tractor.",
                    "label": 0
                },
                {
                    "sent": "We track the item, implements people are looking at the images, we extract these features and then based on this construction we we run this through some algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's going to be logistic regression to them predict which ones were relevant or not.",
                    "label": 0
                },
                {
                    "sent": "So we'll have some offline experiments where we did some offline experiments or what their online.",
                    "label": 0
                },
                {
                    "sent": "Experiments and then later on we actually used those to find this decision rules.",
                    "label": 0
                },
                {
                    "sent": "So this is just a regression model.",
                    "label": 0
                },
                {
                    "sent": "So then give us a function that when we have now future images we would put them through this logistic regression function and then there would be a threshold that we found during this training phase that would then tell us which ones were relevant or not based on this image features.",
                    "label": 0
                },
                {
                    "sent": "Then the next step is to actually explore new images and exploit close by images to those considered relevant.",
                    "label": 1
                },
                {
                    "sent": "So based on what the user has the information the user is given us on on whether these images are relevant or not.",
                    "label": 0
                },
                {
                    "sent": "We want to do carry out this exploration exploitation problem.",
                    "label": 0
                },
                {
                    "sent": "So you want to exploit that close to the ones that user is.",
                    "label": 0
                },
                {
                    "sent": "As defined as being relevant, but we want to also take into account or explore those images that maybe they may not have the chance to see if we only give them the sportive two choices, which is the choices that are very close to the ones they've already considered.",
                    "label": 1
                },
                {
                    "sent": "The next step is to learn the metric.",
                    "label": 0
                },
                {
                    "sent": "This is to just generate the richer metric space for the exploration exploitation algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we have several different types of feature extraction methods over the images, so we've got these features that we have from the eye movements and then we for each image.",
                    "label": 0
                },
                {
                    "sent": "We can have several different types of image feature extraction methods, so we can then learn an appropriate metric for this exploration.",
                    "label": 0
                },
                {
                    "sent": "Exploitation algorithms are working and the idea behind this is that sometimes if you're looking for an image, maybe 2 features may be important.",
                    "label": 0
                },
                {
                    "sent": "For instance color and texture.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you were looking for an image of.",
                    "label": 0
                },
                {
                    "sent": "The Sky is something color is probably the most important feature.",
                    "label": 0
                },
                {
                    "sent": "Once you have something that's blue and very larger around that image thing, but chances are it's probably going to be via Skype.",
                    "label": 0
                },
                {
                    "sent": "So that's the point behind there the learning metric.",
                    "label": 0
                },
                {
                    "sent": "The feature selection scenario here is that now we've got these two sets of features.",
                    "label": 0
                },
                {
                    "sent": "We've got design movement features from the Toby I tracker, and we've also got these image features.",
                    "label": 0
                },
                {
                    "sent": "So is there a way of of of combining these two feature sets?",
                    "label": 0
                },
                {
                    "sent": "Can someone explain some form of feature selection?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the component algorithms, as I mentioned logistic regression, is for the first one for the relevance prediction.",
                    "label": 0
                },
                {
                    "sent": "The second one, the expiration exploitation phase.",
                    "label": 0
                },
                {
                    "sent": "Is this associative reinforcement learning with linear value functions in Ralph?",
                    "label": 1
                },
                {
                    "sent": "This is this is the expiration exploitation stuff that I was mentioning.",
                    "label": 0
                },
                {
                    "sent": "It's very similar to what?",
                    "label": 0
                },
                {
                    "sent": "That's alright, I was talking about yesterday with this ad predictor thing for for Microsoft, where there's a sort of like a Bayesian interpretation of this, this algorithm is enroll type of procedure where you can trust to exploration and exploitation.",
                    "label": 1
                },
                {
                    "sent": "The learning the metric phases this multiple kernel learning.",
                    "label": 0
                },
                {
                    "sent": "This is quite popular in the kernel learning community, where you you may have several or hundreds of different types of kernels and you try to combine them in some way.",
                    "label": 0
                },
                {
                    "sent": "And then it's tense.",
                    "label": 0
                },
                {
                    "sent": "Recipe ends this feature selection problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a picture of of this pin view system that we have.",
                    "label": 0
                },
                {
                    "sent": "So we've got I movements here on the left.",
                    "label": 0
                },
                {
                    "sent": "So from his arguments we extract some features so it turns out that we first started 3 features that I mentioned.",
                    "label": 0
                },
                {
                    "sent": "Some of the features later on Thursday 3 features.",
                    "label": 0
                },
                {
                    "sent": "Now these first 3 features are pastoralist expression model, which then then finds a function that can predict relevance of images with some probability, and in the meantime we also pass these black features to this tensor.",
                    "label": 0
                },
                {
                    "sent": "Function here.",
                    "label": 0
                },
                {
                    "sent": "OK, we've got some images.",
                    "label": 0
                },
                {
                    "sent": "We've got an image database with carry out some feature extractions and give us 11.",
                    "label": 0
                },
                {
                    "sent": "We're going to have 11 different types of features.",
                    "label": 1
                },
                {
                    "sent": "And then these eleven different features would be passed this multiple kernel learning face, multiple color learning phase.",
                    "label": 0
                },
                {
                    "sent": "Then with these 11 features, will consider this is 11 different kernels, giving these eleven different kernels will carry out multiple common learning phase where we will learn a good waiting for good combination of these features.",
                    "label": 0
                },
                {
                    "sent": "These kernels, this also requires this relevance as well to this.",
                    "label": 0
                },
                {
                    "sent": "Residence line should also be going into multiple kernel learning, so this image relevance now goes to this tensor.",
                    "label": 1
                },
                {
                    "sent": "The tensor is is now taking the the similarity metric file from multiple kernel learning, which remember is just from the features of the images and it combines it together with the.",
                    "label": 0
                },
                {
                    "sent": "With these features here, from the bottom here, so these features were the ideas of features.",
                    "label": 0
                },
                {
                    "sent": "These items were features come into the sensor and also from the top.",
                    "label": 0
                },
                {
                    "sent": "Here we get the information of the relevance of those images and then from there multiple kind of learning.",
                    "label": 0
                },
                {
                    "sent": "Get a combination and you Colonel combination of the image features.",
                    "label": 0
                },
                {
                    "sent": "Given this we carry this intense carry out this tensor SVM algorithm which projects into a common space.",
                    "label": 0
                },
                {
                    "sent": "Semantic representations not pass this limbrel algorithm discipline REL algorithm is doing the expiration exploitation says linear algorithm is actually given.",
                    "label": 0
                },
                {
                    "sent": "Now this new metric feature space it's now going to run and then pass out new images for the user the user now.",
                    "label": 0
                },
                {
                    "sent": "I mean this will now repeat the user.",
                    "label": 0
                },
                {
                    "sent": "Now will see those images and maybe click on one of the images to give us explicit feedback on one image to say yes this is relevant and then the other information or feedback will get.",
                    "label": 0
                },
                {
                    "sent": "Is probably arguments over the other images, so they may have 15 images on the page.",
                    "label": 0
                },
                {
                    "sent": "They may click one of those to say yes this is relevant and then three or four of the others based on the right movements and based allow logistic regression model we find to be relevant.",
                    "label": 0
                },
                {
                    "sent": "So now in the next step this all goes through again and now we've got 5 images that were relevant for images that were relevant.",
                    "label": 0
                },
                {
                    "sent": "One from this explicit click, 3 from his implicit feedback from the eye movement, and then we pass this through the model again.",
                    "label": 0
                },
                {
                    "sent": "You know, we learn you metric, you know to update based on what the user has been.",
                    "label": 0
                },
                {
                    "sent": "The feedback from users been giving us.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm sorry I moved with.",
                    "label": 0
                },
                {
                    "sent": "Collected, I don't think everybody can see this, but I mean says 19 here.",
                    "label": 0
                },
                {
                    "sent": "There's actually 33.",
                    "label": 0
                },
                {
                    "sent": "I don't have 30 three list here, but there's some interesting ones here.",
                    "label": 0
                },
                {
                    "sent": "So the top we have.",
                    "label": 0
                },
                {
                    "sent": "The log of total time of viewing the image OK would be an important thing.",
                    "label": 1
                },
                {
                    "sent": "That's open time for measurements outside fixations.",
                    "label": 1
                },
                {
                    "sent": "Then As for here, this fixation features such as total number of fixations to the number of fixations on an image.",
                    "label": 0
                },
                {
                    "sent": "Is the number of revisits to the image this one here 14 so the numbers aren't.",
                    "label": 0
                },
                {
                    "sent": "You revisit the image so you may you have a set of images and you may look at the image.",
                    "label": 0
                },
                {
                    "sent": "Go go and look at some others and you may come back.",
                    "label": 0
                },
                {
                    "sent": "So how many times did Russia come back?",
                    "label": 0
                },
                {
                    "sent": "So there's it says 33 different features that we actually extracted from their Toby, Toby I tracker.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is what typical page will look like, so we have, so there's 15 images.",
                    "label": 0
                },
                {
                    "sent": "So in the collage that we will be using will be 15 images.",
                    "label": 0
                },
                {
                    "sent": "So you have these images.",
                    "label": 0
                },
                {
                    "sent": "The Red, red, red lines of the visa cards with what they used was actually looking at all the movements that their eyes were making the circles of the measurements.",
                    "label": 0
                },
                {
                    "sent": "So that the red dots correspond to rule measurements belong to those fixations.",
                    "label": 1
                },
                {
                    "sent": "Are the red dots are the very not sure you can see those very very small red dots, so these are fixations that we actually take into account and then the small black ones are.",
                    "label": 0
                },
                {
                    "sent": "Maybe, you know, error or something like that.",
                    "label": 1
                },
                {
                    "sent": "We don't take into account we don't use these in the measurements of Black dot micro measurements that were not including any of the fixations.",
                    "label": 0
                },
                {
                    "sent": "Specifically, a user will will get this screen screen like this and we will give them a task.",
                    "label": 0
                },
                {
                    "sent": "We say look for images of.",
                    "label": 0
                },
                {
                    "sent": "Of a dog.",
                    "label": 0
                },
                {
                    "sent": "OK, so they may get random, so the first page will be a random image of random set of 15 images from some database that we have, and now they're going to mark.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at these and then they're going to mark one explicitly and say this is closest to the dog for instance, and then based on what they were looking at and based on our logistic regression model, we will try to infer with high probability which one which other ones were relevant is working, and this will just be updated in our system.",
                    "label": 0
                },
                {
                    "sent": "Then in the next step we should hopefully have more relevant images.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Information.",
                    "label": 0
                },
                {
                    "sent": "So the relevance prediction isn't mentioned is we want to predict relevance of images based solely on the evidence.",
                    "label": 1
                },
                {
                    "sent": "So this this is we dimension vectors.",
                    "label": 1
                },
                {
                    "sent": "So we extract us and said this statistical features.",
                    "label": 0
                },
                {
                    "sent": "We train a logistic regression model and data set online start sessions.",
                    "label": 0
                },
                {
                    "sent": "So this is what I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "So we we gave them, we gave users a search session.",
                    "label": 0
                },
                {
                    "sent": "I don't remember what the searches the queries actually were, but it may be things like you know search for dogs etc etc.",
                    "label": 0
                },
                {
                    "sent": "We know in this database which ones are dogs for instance and which ones are not.",
                    "label": 0
                },
                {
                    "sent": "The user would go through.",
                    "label": 0
                },
                {
                    "sent": "Look at their eyes and see them based on what?",
                    "label": 0
                },
                {
                    "sent": "Knowing the ground truth of knowing actually what dogs were, we know the I movements were telling us over those images and what they were saying over the other images.",
                    "label": 0
                },
                {
                    "sent": "We run this through the logistic regression models.",
                    "label": 0
                },
                {
                    "sent": "Given these labels of dogs and not dogs, and then we have a function which then predicts given new image features that should generalize, giving you image features whether something is relevant or not.",
                    "label": 0
                },
                {
                    "sent": "And then we use the logistic regression model to predict relevance of image based on these three.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm looking for features.",
                    "label": 0
                },
                {
                    "sent": "The expiration exploitation phase.",
                    "label": 0
                },
                {
                    "sent": "This is where we actually need to pass in passback the images to to the user.",
                    "label": 0
                },
                {
                    "sent": "So now we've we've learned which images are relevant.",
                    "label": 0
                },
                {
                    "sent": "We've given this feedback to our model and the expiration really is the heart of the of the system.",
                    "label": 0
                },
                {
                    "sent": "This is the part which is actually saying OK. Based on all of these images in the database based on what the user has seen and the relevance feedback they've given me through their eye movements through this point and click.",
                    "label": 0
                },
                {
                    "sent": "Now, given all of the other images in the database, I can now give back another 15 images that I think are the most relevant.",
                    "label": 0
                },
                {
                    "sent": "OK, this is done through this expiration expectation, so the expectation is to find those that are indicated as relevant finding, which is closer to those indicated as relevant, and the exploration phase is defined images further away, and this is just in case we missed something.",
                    "label": 1
                },
                {
                    "sent": "OK, let me use it.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gorilla so linear algorithm is A is a come from reinforcement learning literature and the objective is to maximize the number of relevant images presented to the user.",
                    "label": 1
                },
                {
                    "sent": "So there's some of this YT that sees the relevance of the team image.",
                    "label": 1
                },
                {
                    "sent": "OK, assumption the assumption we make is the expected value of the relevance.",
                    "label": 0
                },
                {
                    "sent": "Why I is a linear function of the image?",
                    "label": 0
                },
                {
                    "sent": "Features excellent, so this is just a linear function here, so this expectations include W transpose, SWS, await vector.",
                    "label": 0
                },
                {
                    "sent": "I'm just saying it's just a linear function itself.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out of this problem is actually equivalent to.",
                    "label": 0
                },
                {
                    "sent": "Just the living standard linear regression.",
                    "label": 0
                },
                {
                    "sent": "So inspiration T enroll estimates W this way back to W from previously presented images XT16.",
                    "label": 1
                },
                {
                    "sent": "Now these are these are rose and the observed relevant scores YT.",
                    "label": 0
                },
                {
                    "sent": "So these are the given these images that you see next one up to X T -- 1 each one of these and is an image.",
                    "label": 0
                },
                {
                    "sent": "Image vector each of X up and then these whitey's.",
                    "label": 0
                },
                {
                    "sent": "These are the corresponding relevance is of those images we can just use within your regression and linear regression to our our men over W. This expression here which is the norm square should give you the norm square error between this prediction of W transpose X or XX WS is written here minus dot YT.",
                    "label": 0
                },
                {
                    "sent": "Then the estimated weight vector vector predicts the relevance of image.",
                    "label": 1
                },
                {
                    "sent": "As Yi hat is equal to WT hat for us was excellent.",
                    "label": 0
                },
                {
                    "sent": "This is exactly what you were doing in your regression adrenaline regression getaway pack.",
                    "label": 0
                },
                {
                    "sent": "So you take the product of that weight vector, image vector or image feature and you have some prediction of your.",
                    "label": 0
                },
                {
                    "sent": "So our prediction now this is our prediction irrelevance.",
                    "label": 0
                },
                {
                    "sent": "General optimistically select images which might be most relevant given the variance Sigma.",
                    "label": 1
                },
                {
                    "sent": "I squared away right so we calculate the variance and this variance is the exploration stage.",
                    "label": 0
                },
                {
                    "sent": "So the image I with maximum W transpose XIN Plus C. Some constant Sigma I is selected signifies the variance of this term and what this actually means is that.",
                    "label": 0
                },
                {
                    "sent": "This term here is the exploitation step and this time here is essentially so this time.",
                    "label": 0
                },
                {
                    "sent": "Here's the exploitation step, and this time here is giving us the exploration step.",
                    "label": 0
                },
                {
                    "sent": "So this is known as a slim roll algorithm came about and there's no Mr.",
                    "label": 0
                },
                {
                    "sent": "Maximizing upper confidence power.",
                    "label": 0
                },
                {
                    "sent": "So if you actually maximize this quantity, you actually maximizing our performance.",
                    "label": 0
                },
                {
                    "sent": "But which is actually trading off this thing of exploration, exploitation very nicely.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One going to the details of that, but just the detail of this linnros with them just to make it a bit clearer.",
                    "label": 0
                },
                {
                    "sent": "Eyes that remember these XT are the images of.",
                    "label": 1
                },
                {
                    "sent": "Is there is a matrix of the images previously seen by the user?",
                    "label": 1
                },
                {
                    "sent": "OK, so if the users seem to collage in, each collage has 15 images, then there's some 30 images, so this will be a 30.",
                    "label": 0
                },
                {
                    "sent": "Number 30 by the number of dimensions of this feature background for this feature space.",
                    "label": 0
                },
                {
                    "sent": "His eyes the identity matrix.",
                    "label": 0
                },
                {
                    "sent": "So this right hand side here.",
                    "label": 0
                },
                {
                    "sent": "Plus YT would essentially give you a linear regression.",
                    "label": 0
                },
                {
                    "sent": "Solution of linear regression.",
                    "label": 0
                },
                {
                    "sent": "OK, he's supposed to push, and putting in this XI.",
                    "label": 0
                },
                {
                    "sent": "Now we now have this AI is respect to AI, which now we can.",
                    "label": 0
                },
                {
                    "sent": "We can write in terms of that expression.",
                    "label": 0
                },
                {
                    "sent": "I had a previous slide with the W transpose X + Y times the variance as this time here.",
                    "label": 0
                },
                {
                    "sent": "So the variance actually comes out of the mathematics is just being the norm of this way vector of this vector sum AI for this work.",
                    "label": 0
                },
                {
                    "sent": "This vector AI can take along with.",
                    "label": 0
                },
                {
                    "sent": "Responsible parents, so now if you maximize this quantity then you are actually carrying out this expiration interpretation step, so you will give him the old.",
                    "label": 0
                },
                {
                    "sent": "The old images given a new image excite, you could say given all of the new images that I've not seen or not presented to the user, compute this upper confidence bound.",
                    "label": 0
                },
                {
                    "sent": "Compute this value here and then maximize.",
                    "label": 0
                },
                {
                    "sent": "Find findings image that maximizes this, and this is the image that would not present.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, we can finalize this linear algorithm which is very simple.",
                    "label": 0
                },
                {
                    "sent": "Looks very similar to a kernel version of least squares regression, so you've got this kernel here.",
                    "label": 1
                },
                {
                    "sent": "You've got mu, which is the rich brands are the identity matrix here, so the inner product of that, and now what you do is you multiply that by the basis vector, which is the better.",
                    "label": 1
                },
                {
                    "sent": "The kernel matrix or the kernel entries between the image that you have by now and the images I want I see most of the images that you saw previously, so you saw 30 images previously.",
                    "label": 0
                },
                {
                    "sent": "It would be those images I want to I T -- 1 those 30 with the new image that you have and this will give you a kernel version.",
                    "label": 0
                },
                {
                    "sent": "And the reason we're doing this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Virgil said now we can plug that into the multiple kernel.",
                    "label": 0
                },
                {
                    "sent": "That way we could do multiple kernel learning.",
                    "label": 0
                },
                {
                    "sent": "Lots of different kernels and then plug that directly into that.",
                    "label": 0
                },
                {
                    "sent": "Enrollment is kernelized in round version, so another open open problem is how do you select these images and images at once?",
                    "label": 1
                },
                {
                    "sent": "You can select the N images with maximum of confidence bounds so that quantity.",
                    "label": 1
                },
                {
                    "sent": "The algorithm I showed in the previous slide.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one here AI.",
                    "label": 0
                },
                {
                    "sent": "So we would given the kernel.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Version, so given this kind of agent version AI, we can plug in this AI.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into this equation 2 and we have kernel version.",
                    "label": 0
                },
                {
                    "sent": "So if we plug that in to this here and then.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And maximized at select the N images with maximal confidence balance.",
                    "label": 1
                },
                {
                    "sent": "Then we have this first possibility of choosing, so we would run that algorithm that Lynn role would sort all of the images that we've not seen in descending order.",
                    "label": 0
                },
                {
                    "sent": "People stop N we can present most top end.",
                    "label": 0
                },
                {
                    "sent": "This would be quite a lot of exploration you would be doing because you've got the various done.",
                    "label": 1
                },
                {
                    "sent": "The second one would be where you pick the top one with this upper confidence bound and the next say N -- 1 of them, you would just pick.",
                    "label": 0
                },
                {
                    "sent": "The one that's maximizing W transpose X, which is the.",
                    "label": 0
                },
                {
                    "sent": "Remember this is the exploitation step, so now you're doing more exploitation, not so much inspiration.",
                    "label": 1
                },
                {
                    "sent": "And then you can have a middle ground in the middle ground.",
                    "label": 0
                },
                {
                    "sent": "We iteratively select any images by their overconfidence pals, updates, the relevance, the relevance we know is double transpose X, so you update the relevance and then you repeat.",
                    "label": 0
                },
                {
                    "sent": "So you add that into your set now.",
                    "label": 0
                },
                {
                    "sent": "So the XT now becomes X T + 1 because you've updated and then repeat that up to the end.",
                    "label": 0
                },
                {
                    "sent": "This one up to the end that you want to print.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Launch.",
                    "label": 0
                },
                {
                    "sent": "Learning the metric.",
                    "label": 0
                },
                {
                    "sent": "11 So this is this is the stage where we now want to learn a different metric, wants to learn a different metric.",
                    "label": 0
                },
                {
                    "sent": "To pass into the linear algorithm so 11 different feature extraction methods that we use, including skin color, hard transform etc etc.",
                    "label": 1
                },
                {
                    "sent": "So each of these feature extraction methods can be can be viewed as a kernel.",
                    "label": 0
                },
                {
                    "sent": "So we have now 11 kernels and we'd essentially like to learn a kernel using multiple kernel learning so so so remember here in the mineral algorithm all we need are these kernel entries.",
                    "label": 1
                },
                {
                    "sent": "OK, so this this kernel matrix here is just kind of interest between each of the indices IIIJ where these run up to images that were in the sink.",
                    "label": 0
                },
                {
                    "sent": "So that's all that needs need.",
                    "label": 0
                },
                {
                    "sent": "But that's all we need for kernel version and then run.",
                    "label": 0
                },
                {
                    "sent": "So essentially for MCL we have this, this vector, an Easter story, which is, which is the weights of each of the kernels.",
                    "label": 1
                },
                {
                    "sent": "So this would be 11 dimensional and.",
                    "label": 0
                },
                {
                    "sent": "We would essentially weight each of the KK subscript.",
                    "label": 0
                },
                {
                    "sent": "I is one of the kernels that we have to one of the 11 kernels and I would like to take a weighting of these and this would be a convex combination so that someone comes into eaters with some to one.",
                    "label": 0
                },
                {
                    "sent": "So each time we get this feedback mechanism we get this feedback and then based on that feedback or relevance we update our feature vector because at the start of the search it may may be clear we may have a lot of the image.",
                    "label": 0
                },
                {
                    "sent": "A lot of the feature vectors alot of the kernels are used their important.",
                    "label": 0
                },
                {
                    "sent": "A lot of the information from different features are important, but as we as we move on in the iterations after a few pages you would think that as the user is looking for a particular things some of these image features some of these kernels are zeroed out and not any more important.",
                    "label": 0
                },
                {
                    "sent": "There are other important features so we're essentially doing more of an exploration at that stage of the motherland.",
                    "label": 0
                },
                {
                    "sent": "I won't go over this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then there's the feature selection using eye movement, so this is where we take.",
                    "label": 1
                },
                {
                    "sent": "If you just look at this this kernel here would be an image kernel to the image panel that we were computed using the multiple kernel learning.",
                    "label": 1
                },
                {
                    "sent": "I'm going to take a tensor.",
                    "label": 0
                },
                {
                    "sent": "We will take a.",
                    "label": 0
                },
                {
                    "sent": "We take the tunnel between the eye movements and we take not an inner product, but componentwise products.",
                    "label": 0
                },
                {
                    "sent": "So this corresponds to a tensor product in the feature space, which is essentially the idea here is to actually project your image in your eye movement features into the same space into a common space.",
                    "label": 0
                },
                {
                    "sent": "But the problem is is that when you project into this common space, you have images of you have eye movements of the images that the user has seen, but you don't have.",
                    "label": 1
                },
                {
                    "sent": "The eye movements of the images they haven't seen so you would project the image features of the images they've seen and the eye movement features into the same space.",
                    "label": 0
                },
                {
                    "sent": "And then you can project.",
                    "label": 0
                },
                {
                    "sent": "Now the image of the images that have not been seen into the same semantic space and this is somehow we feel using using the information of the eye movements and the image features together in this in this semantic learning the metric type procedure and it also.",
                    "label": 0
                },
                {
                    "sent": "Is an STD like procedure, so this carries out feature selection as well, so hopefully removing irrelevant features.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the experimental setup was that we had a pastel visual.",
                    "label": 0
                },
                {
                    "sent": "We style visual objects database lock 2007.",
                    "label": 0
                },
                {
                    "sent": "We perform online experiments with simulated test search sessions.",
                    "label": 1
                },
                {
                    "sent": "Sub session intuitively use pin view to select a total of 10 colleges with 15 images need so the total is 150 images so we had 10 central lodges in for each one was 15 images.",
                    "label": 1
                },
                {
                    "sent": "The target of each session is one of the categories so this is what challenge has 20 million 21 categories.",
                    "label": 1
                },
                {
                    "sent": "So for each of the search sessions one of those countries must be the problem.",
                    "label": 0
                },
                {
                    "sent": "Searching for social number of sessions was 40.",
                    "label": 0
                },
                {
                    "sent": "We use precision.",
                    "label": 0
                },
                {
                    "sent": "Recall is our measure of success.",
                    "label": 0
                },
                {
                    "sent": "And the idea was recorded using this to be so we 1750 like.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this feedback modalities full.",
                    "label": 1
                },
                {
                    "sent": "So this is where we use the true label of the scene images.",
                    "label": 1
                },
                {
                    "sent": "So we've got the true label of these images.",
                    "label": 0
                },
                {
                    "sent": "This is simulated.",
                    "label": 0
                },
                {
                    "sent": "Click where relevant random image and collage selected is clicked.",
                    "label": 0
                },
                {
                    "sent": "Simulated I is where we simulate the items from previous online experiments to predict relevance images.",
                    "label": 1
                },
                {
                    "sent": "This is logistic regression model that we found.",
                    "label": 1
                },
                {
                    "sent": "So we keep all of relevant and non relevant image.",
                    "label": 0
                },
                {
                    "sent": "I'm moving features and then we sample from these two groups in the offline experiments.",
                    "label": 1
                },
                {
                    "sent": "And then this simulated iPod click is where we we we put together the images that were relevant from the Islanders that we found in the randomly selected one from the clinic and we put these together.",
                    "label": 0
                },
                {
                    "sent": "So in the first one the simulated clip, we may only give them one image of 15 that is relevant.",
                    "label": 0
                },
                {
                    "sent": "In the second one, Mega Extra three or four and then this one we have the 1 + 3 or 4.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so these are the results.",
                    "label": 0
                },
                {
                    "sent": "And what would like to see is that so random here is where randomly each collage each iteration randomly just given 15 images, so that you would expect to be the worst and you can see to the left it's always the worst.",
                    "label": 0
                },
                {
                    "sent": "So these these figures here, for each of the categories of the child.",
                    "label": 0
                },
                {
                    "sent": "So you've got cats.",
                    "label": 0
                },
                {
                    "sent": "Dogs are here with his dog.",
                    "label": 0
                },
                {
                    "sent": "He would have images of.",
                    "label": 0
                },
                {
                    "sent": "Of dogs and other images in the database and we try to look for for the dog images is as relevant to the white one.",
                    "label": 0
                },
                {
                    "sent": "Here is where we use this as best.",
                    "label": 0
                },
                {
                    "sent": "Pretty much this is where we use the actual feedback is being the actual images on that page that were dog made the truth.",
                    "label": 0
                },
                {
                    "sent": "The truth in the the ones selected that here is the simulated I plus click.",
                    "label": 0
                },
                {
                    "sent": "The middle one is basically simulated simulated click.",
                    "label": 0
                },
                {
                    "sent": "So this is where you randomly pick one.",
                    "label": 0
                },
                {
                    "sent": "The images on page one of the positives, so one of the dog images soon they have $4 and you just run with it once.",
                    "label": 0
                },
                {
                    "sent": "OK, that's my feedback, which can use that one.",
                    "label": 0
                },
                {
                    "sent": "And then this one here we just use the island lights.",
                    "label": 0
                },
                {
                    "sent": "So, so the results here are better than the random.",
                    "label": 0
                },
                {
                    "sent": "Obviously not as good as the full, but the point the point in note here is that in most cases I think in the average the simulated plusquellic simulated items plus quit performs better than simulated click or simulated.",
                    "label": 0
                },
                {
                    "sent": "Or just having I.",
                    "label": 0
                },
                {
                    "sent": "So if you just have eye movements and just have click, it works well, but if you have both together then you really do.",
                    "label": 0
                },
                {
                    "sent": "You gain some some improvement.",
                    "label": 0
                },
                {
                    "sent": "And so clearly we are.",
                    "label": 0
                },
                {
                    "sent": "We are getting some improve.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Based on my movements.",
                    "label": 0
                },
                {
                    "sent": "And so that's that's the conclusion to the conclusions are that we proposed and you see our system that uses relevance feedback from my movements.",
                    "label": 1
                },
                {
                    "sent": "So implicit relevance feedback, we can infer the relevance of images relatively well from my movements, and this is using the logistic regression model.",
                    "label": 1
                },
                {
                    "sent": "Unobtrusively improved user experience by adapting user interface.",
                    "label": 0
                },
                {
                    "sent": "The interest of the user.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how unintrusive it is.",
                    "label": 0
                },
                {
                    "sent": "2 points and I tracker it somebody's eyes.",
                    "label": 1
                },
                {
                    "sent": "But yeah, I mean that's pretty unobtrusive I guess complaints.",
                    "label": 1
                },
                {
                    "sent": "Some some methods and then we incorporate this into an algorithm into assistant will pick some system which allows the use of real world image databases.",
                    "label": 0
                },
                {
                    "sent": "This is all available online and the future plan is to perform these online experiments on real subjects.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your time.",
                    "label": 0
                },
                {
                    "sent": "Time for a couple of questions maybe?",
                    "label": 0
                },
                {
                    "sent": "I wanted to ask a couple things, but one thing was.",
                    "label": 0
                },
                {
                    "sent": "If you have a.",
                    "label": 0
                },
                {
                    "sent": "The user is searching for something which is maybe less common.",
                    "label": 0
                },
                {
                    "sent": "And your initial pool is unlikely to to have that image in it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you're both both metrics of relevant.",
                    "label": 0
                },
                {
                    "sent": "Both the click and the eye tracking kind of assume that there is something relevant there due to the image.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but there's kind of no way of saying I'm going to look over here and nothing is relevant to me or so.",
                    "label": 0
                },
                {
                    "sent": "So The thing is, if.",
                    "label": 0
                },
                {
                    "sent": "If what might happen is is the user just sort of, looks around randomly and making looks more or something that's a bit more interesting than not really what he's looking for.",
                    "label": 0
                },
                {
                    "sent": "Yeah, he or she sorry and then the system will potentially sort of overlay over Explorer in the wrong direction because it's, well.",
                    "label": 0
                },
                {
                    "sent": "OK, so the exploitation is there to exploit or to look for images.",
                    "label": 0
                },
                {
                    "sent": "But somebody, a participant said is this is relevant, right?",
                    "label": 0
                },
                {
                    "sent": "So you're going to look for things that.",
                    "label": 0
                },
                {
                    "sent": "Close the exploration phase is to look for things that are quite far away, so you may you know by chance get something that is then that comes in, But then is similar to what you were looking for.",
                    "label": 0
                },
                {
                    "sent": "Another option is just to run the thing and and not to give any feedback, but if you go for many sessions and you not getting feedback and we really got negative data and not got anything positive to learn from.",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure how.",
                    "label": 0
                },
                {
                    "sent": "Yeah just wonder that it might sort of prematurely exploit.",
                    "label": 0
                },
                {
                    "sent": "In the wrong direction, because because your your feedback is positive rather than that there's not.",
                    "label": 0
                },
                {
                    "sent": "There's kind of no negative feedback, so this is not working well.",
                    "label": 0
                },
                {
                    "sent": "We can then just regression model can give you a probability of.",
                    "label": 0
                },
                {
                    "sent": "I mean, it gives you a threshold and an actual function value on this.",
                    "label": 0
                },
                {
                    "sent": "On this card, which I think there's a threshold reset, I think there's a threshold found a .3 four so, so we will actually won't actually use.",
                    "label": 0
                },
                {
                    "sent": "We won't say these are relevant and everything else is zeroed out or not relevant, but it will sort of be an indication of relevance.",
                    "label": 0
                },
                {
                    "sent": "So the higher the value, the more and the lower value, the less room.",
                    "label": 0
                },
                {
                    "sent": "I agree that you guys still think that because there is no room for negative influence, there's no way you can discard images.",
                    "label": 0
                },
                {
                    "sent": "I mean, there would also be useful feature.",
                    "label": 0
                },
                {
                    "sent": "Now when you say simply know none of these images is anywhere near is what I'm looking for.",
                    "label": 0
                },
                {
                    "sent": "It will also be information for you.",
                    "label": 0
                },
                {
                    "sent": "That is, yeah you could.",
                    "label": 0
                },
                {
                    "sent": "You could.",
                    "label": 0
                },
                {
                    "sent": "All of them before they make this decision.",
                    "label": 0
                },
                {
                    "sent": "Taking my eye movement was a thing like he's actually looking at this picture.",
                    "label": 0
                },
                {
                    "sent": "Yes, I'm moving it because I'm deciding I don't want things related to decide this year so.",
                    "label": 0
                },
                {
                    "sent": "Yes, normally but still interested question it something because I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "These are the images after moving all of them, so.",
                    "label": 0
                },
                {
                    "sent": "Alright, but we used.",
                    "label": 0
                },
                {
                    "sent": "You know we used the idea that you can generalize from from even a bunch of images that you have the positive and negative you know the relevant and non relevant.",
                    "label": 0
                },
                {
                    "sent": "We can generalize from that because we run this model.",
                    "label": 0
                },
                {
                    "sent": "This logistic regression model and we know how they've looked at images that are relevant and those that are not regular form that we can generalize.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's not just necessarily that they've looked at a particular image for a certain way, or.",
                    "label": 0
                },
                {
                    "sent": "I mean they can look at many images and it doesn't mean that they're going to be ready.",
                    "label": 0
                },
                {
                    "sent": "So it's going to be based on this model.",
                    "label": 0
                },
                {
                    "sent": "We are going to give those features into.",
                    "label": 0
                },
                {
                    "sent": "This model is OK Now, given this logistic regression model with probability.",
                    "label": 0
                },
                {
                    "sent": "Is this relevant or not?",
                    "label": 0
                },
                {
                    "sent": "Sorry no no.",
                    "label": 0
                },
                {
                    "sent": "The number of features that you used for image is actually quite well.",
                    "label": 0
                },
                {
                    "sent": "It's 1111 features for Image 11 features and now using your local moving system, you're actually providing some feedback system, reducing the features and you're highlighting words that are more yes.",
                    "label": 0
                },
                {
                    "sent": "Order in order to rent the images that are most close to the points that you guys have you done any experiments with completely?",
                    "label": 0
                },
                {
                    "sent": "Night bro Chin Hua simple distance matrix based on the 11 features and simply say OK.",
                    "label": 0
                },
                {
                    "sent": "But the guys who can give his image given 15 closers in terms of the feature space that you would already be fine because the feature space itself is not changing, you just weighing it slightly differently.",
                    "label": 0
                },
                {
                    "sent": "If you don't do anything.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I never.",
                    "label": 0
                },
                {
                    "sent": "I never went over this slide here.",
                    "label": 0
                },
                {
                    "sent": "Skip this one 'cause of time.",
                    "label": 0
                },
                {
                    "sent": "But essentially the multiple kernel learning is is doing this one more.",
                    "label": 0
                },
                {
                    "sent": "Regularization is to normalization.",
                    "label": 0
                },
                {
                    "sent": "So if you effectively this louder.",
                    "label": 0
                },
                {
                    "sent": "Value here is between 01.",
                    "label": 0
                },
                {
                    "sent": "If you set this Lambda value to zero, you remove this one more thing and removing this one more means that you don't pick out a small number of them keeping the two norm means you pick out all of them went all of them.",
                    "label": 0
                },
                {
                    "sent": "So the question you are asking is that or one thing you can do is essentially you can take those 11 features.",
                    "label": 0
                },
                {
                    "sent": "You can concatenate them into one big feature vector and then just run it through distance mode.",
                    "label": 0
                },
                {
                    "sent": "Yes, this would correspond to evenly weighted.",
                    "label": 0
                },
                {
                    "sent": "This would be where.",
                    "label": 0
                },
                {
                    "sent": "Each of the each practice is even rated.",
                    "label": 0
                },
                {
                    "sent": "Yes, we've done those experiments in this.",
                    "label": 0
                },
                {
                    "sent": "If I set this Lambda zero, then essentially will correspond to something similar to that.",
                    "label": 0
                },
                {
                    "sent": "It doesn't mean that each of the what it means.",
                    "label": 0
                },
                {
                    "sent": "Each of these kernel matrices will have a value of greater than zero, but not necessarily have equal value or even even waiting.",
                    "label": 0
                },
                {
                    "sent": "But when we ran experiments with even waiting, it seems to perform well, but.",
                    "label": 0
                },
                {
                    "sent": "Not always better than the combinations that you found just because if you have to fix it, they can do it.",
                    "label": 0
                },
                {
                    "sent": "But I'm looking at the image that the pre calculated.",
                    "label": 0
                },
                {
                    "sent": "So yeah, then it's very fast.",
                    "label": 0
                },
                {
                    "sent": "I mean the other thing I didn't mention is that I mean running multiple kernel learning isn't that expensive because a search session is going to last maybe maximum 20 pages, which is 300 images.",
                    "label": 0
                },
                {
                    "sent": "The biggest Colonel you're going to work with this 300 by 3.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, this is going to be pretty pretty fast, but yeah, I mean if you if you want to, if you want I can just set Lambda to 0.",
                    "label": 0
                },
                {
                    "sent": "So OK, just find me everything you know, just give me everything.",
                    "label": 0
                },
                {
                    "sent": "If I set this to 0.",
                    "label": 0
                },
                {
                    "sent": "But if I set this to one then it's going to find a very small number of them.",
                    "label": 0
                },
                {
                    "sent": "And somewhere between these things be doing something between and.",
                    "label": 0
                },
                {
                    "sent": "I think the idea here was that you know this regularization and the idea was this this thing, where at the start I want to use a lot of features, but near the end I want to make.",
                    "label": 0
                },
                {
                    "sent": "A more important so I could in effect after some five collisions or something that could change this Lambda value, could start it big and then make it smaller, but yeah.",
                    "label": 0
                },
                {
                    "sent": "Is there a disturbed affect?",
                    "label": 0
                },
                {
                    "sent": "What happens if the user does fine make more deliberate eye movements to convey information to certain?",
                    "label": 0
                },
                {
                    "sent": "Subjects none say, will use their own movements to improve effectively.",
                    "label": 0
                },
                {
                    "sent": "The images that Ben suggested.",
                    "label": 0
                },
                {
                    "sent": "So this logistic regression model that I've been talking about this is very fancy model, right?",
                    "label": 0
                },
                {
                    "sent": "You don't want to keep falling through, you know 20 pages.",
                    "label": 0
                },
                {
                    "sent": "You know 'cause you know if you do a Google search, you want it to be.",
                    "label": 0
                },
                {
                    "sent": "You want the hits to be at the top and it's the same.",
                    "label": 0
                },
                {
                    "sent": "Same principle here so, but exaggerating.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if exaggerating and having that relevance feedback would actually improve the results for the liberal or the OK so.",
                    "label": 0
                },
                {
                    "sent": "Right, I think we should still.",
                    "label": 0
                },
                {
                    "sent": "Here we are using it so much, right?",
                    "label": 0
                },
                {
                    "sent": "So let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}