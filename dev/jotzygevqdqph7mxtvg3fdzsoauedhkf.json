{
    "id": "jotzygevqdqph7mxtvg3fdzsoauedhkf",
    "title": "Tracking the Invisible: Learning Where the Object Might Be",
    "info": {
        "author": [
            "Helmut Grabner, Department of Information Technology and Electrical Engineering, ETH Zurich"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Motion and Tracking"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_grabner_tti/",
    "segmentation": [
        [
            "OK, good morning everyone.",
            "Do you hear me?",
            "Yes, thanks for the introduction.",
            "Don't talk about now how to track invisible things and the work I'm presenting today.",
            "It was joint Burger is joint work.",
            "Now with the remote's look from goal and Phillip Carter.",
            "Let's jump into it."
        ],
        [
            "For those of you who do not know, this is Connor and I will show you a short video clip in the following and ask you please try to keep tracking cars through the entire video sequence."
        ],
        [
            "OK, there's Kyle coming down sitting in front of his house, right?",
            "It's going down.",
            "Keep going.",
            "I think most of you have absolutely no problem to keep tracking cars through this entire sequence, or even have a rough idea of where Kyle is in this.",
            "In the six oh, sorry.",
            "The sequence."
        ],
        [
            "And this is exactly the goal we want to focus on in this paper.",
            "So we want to estimate or track the target object if it's visible.",
            "But also when it gets occluded or when it's outside the image.",
            "And how is this possible?",
            "Cause there are?"
        ],
        [
            "There will be many, many other potential very strong links between the target object and other parts of the image, which you can explore.",
            "And we do this by discovering the dynamic elements which we are calling supporters that predicted the position of the target.",
            "If you remember the.",
            "Yesterday morning session there was the session hold about context.",
            "Context is widely used in object detection or categorisation, but they assume a very very fixed link, like a car is always on this tweet or my head is a puff of my daughter and between my shoulders, whereas in tracking we have to dynamically exchange those links in order to benefit from this.",
            "And this is only focused by a few authors in this field.",
            "So."
        ],
        [
            "Such supporters maybe come with different strengths and change overtime, so let's give me an example.",
            "So this is Carl's wife and she's putting a coin into this Piggy Bank and.",
            "While she is carrying the coin, she itself, especially the hand and the fingers, are very, very strong supporters to determine the position of the coin.",
            "But as soon as she has put the coin into this Money Box.",
            "She will that the link from her and the coin will not be valid anymore but the the class itself.",
            "The Money Box will get a very very strong supporter to notice vertic coin is in the image."
        ],
        [
            "Unless you need some money."
        ],
        [
            "OK for real images.",
            "I will shown that supporters help tracking object.",
            "We've changed the appearance very, very quickly or occluded objects or objects outside of the image, or even very small or low textures objects.",
            "So let's consider like the Swiss soccer player who is cheating.",
            "Who was shot the 1 zero against Spain in damage?",
            "You even not possible to see the ball in this image, but you have roughly an idea where it is in the network on the image.",
            "OK, thanks or on the image below.",
            "You can very well estimated trajectory of the stone only by giving that that image here."
        ],
        [
            "OK.",
            "In this work, we focus on a specific, a specific type of supporters.",
            "Local image features.",
            "So given that image."
        ],
        [
            "And say we want to track all through this image."
        ],
        [
            "So we extract some local image features from from the image and."
        ],
        [
            "Is usually done is people build two sets different object features and background features and then they learn a model of the object.",
            "So just by using the object features features to keep tracking the object or they learn discriminative classifiers for example not to distinguish the object features from the background features.",
            "In this work we go beyond having this binary split.",
            "And.",
            "Is it?"
        ],
        [
            "Every feature which is helpful to predict the position of the object should be taken into account, and since these features are not only supposed to lie on the object itself."
        ],
        [
            "Therefore, it's possible to predict very objects even when it gets occluded outside damage."
        ],
        [
            "So in summary, once again, supporters of those features which contributed to the prediction of the target object and they are at least temporarily move in a way which is statistically related to the motion of the object itself."
        ],
        [
            "How do discovering this set of supporters so assume you have an image sequence and we have a few where reliable measurements on very objectives may be given by Newman input or by when the tracker is very, very confident that the object is present here.",
            "Then we try to explain model the relationship between the object and other parts of the image in order to predict the position of the object through the entire video sequence.",
            "For."
        ],
        [
            "Modeling, which is very very simple with just a simple model, we want to estimate the probability that given the image I want to predict the position X of the object and."
        ],
        [
            "We are doing using the principle of the channel halftones form until the implicit shape model.",
            "So let's assume we have already a model of call in that case.",
            "Now a model of our object.",
            "We first extract."
        ],
        [
            "Which features of given the image, some features are extracted, they are matched to our our model.",
            "Then"
        ],
        [
            "Local displacements from the feature to the object position are done so each feature votes for the object position.",
            "By doing this form."
        ],
        [
            "Many features and summing them."
        ],
        [
            "We finally get the voting space and we can consider the maximum or the mode of this voting."
        ],
        [
            "Space as our our final our final position of the object."
        ],
        [
            "So the main question is how do we learn this model?",
            "This model of car?",
            "How is this done?",
            "Usually in in for object detection or categorization.",
            "So you have a lot of training images, so a lot of images from call.",
            "Then you extract local features into his points for example.",
            "Cluster them and build the codebook.",
            "Then these are your prototypes for the for the object, and since you have the ground too, so you know whether very object is.",
            "You can also learn the displacement vectors or distribution further objectives given given that features."
        ],
        [
            "However, since we want to do tracking here.",
            "We have already a model of supporters and we want to maintain them overtime, so we want to update the prototypes in an online manner as well as updating the object displacement voting."
        ],
        [
            "All is just been done, it's quite simple.",
            "So since we when we have reliable information available like here we have this extra stop.",
            "We do for every other into responder.",
            "For every other feature we add them to the set of supporters and estimate this coupling between them and update the distribution of the of the displacement."
        ],
        [
            "By exploring this principle of the China will have transform automatically.",
            "It is distinguished between strong supporters were the voting is very, very Peaky.",
            "So we have a clear vote, very objective or a more blurred vote.",
            "Weaker vote with their motion coupling is not that outspoken.",
            "Or you can also distinguish between almost unrelated features in the image.",
            "Before showing you some experimental results, just give you a."
        ],
        [
            "Few implementation details how we implemented it and we did it.",
            "We did it very, very simple.",
            "One can do it.",
            "Much, much more clever way but.",
            "It also turns out to work quite well, so.",
            "For the image and photo feature extraction, we use simple harvest points, describe them by sift like descriptor matching them.",
            "Do the database.",
            "If it could establish a good match, then everything is fine and we make updating updating it, otherwise it will be added as a possible new supporter.",
            "In addition to this Harris Point feature extraction, we also use KLT tracking from one frame to the other frame too."
        ],
        [
            "Tablets, those matches for the voting of the displacement of the object.",
            "Since for some tracking sequences we only have very, very limited frames where we have reliable information, it choose to approximate this whole distribution by one single caution and discussion.",
            "So the mean and covariance matrix is updated overtime in an online manner, exploring the simple principle of exponential form."
        ],
        [
            "Adding.",
            "OK. Let's go to the experiments.",
            "I will show you one experiment in more detail and then several other experiments which showed the benefit of tracking with supporters.",
            "So here in the first experiment we recorded a sequence where this small.",
            "Bottle is.",
            "Moved behind the Cup.",
            "Then lift it up.",
            "Come back and finally was put back on the table.",
            "So first of all."
        ],
        [
            "We asked 10 humans to label in each frame.",
            "Verda sync the object is and you will see like this.",
            "This stops one for each for each person.",
            "So let's see what the human are doing.",
            "So once the optic is super, they mostly agree.",
            "But even here they're not quite true, and also from our algorithm point.",
            "Now we want to we want to be somewhere in that.",
            "In in that variance, but with the human are doing.",
            "On the other hand, we just put one."
        ],
        [
            "Off the shelf off the web tracker, we download the this tracker and apply this tracker on this image sequence.",
            "Let's see what this tracker does.",
            "And again.",
            "As long as the object is visible, it does the job quite well."
        ],
        [
            "Well, it's invisible or partially occluded.",
            "Now it it was lost keeping it tracking.",
            "However, we use this tracking information as reliable information to train our set of supporters, and this is the result you see.",
            "The voting space opposing duty and."
        ],
        [
            "Sweetie.",
            "And as you can see now.",
            "Also, when the object is occluded by the Cup then.",
            "Then we can roughly datamine its position."
        ],
        [
            "And just some some some results.",
            "And why is it happening?",
            "We could more less double the week also demanded position very object is not without losing much on precision and especially when the object is a cubit one.",
            "Why is it working?",
            "Show a video of the supporters.",
            "The blue guys are the supporters and the yellow circle is the predicted position.",
            "It's the mode of devoting space and."
        ],
        [
            "Greenman is when we have this tracking this reliable results.",
            "OK, here we go.",
            "So features on the object itself are picked up as well as features on the watch.",
            "Now because they have correlated movement and successfully tracked the object most of the time.",
            "And Please note in this image sequence it would have been not be possible, but just into."
        ],
        [
            "Relating between the individual tracking results.",
            "Because there's there's some nontrivial.",
            "Movement going up.",
            "OK. Another show, a couple of other examples, not like tracking here this car in the middle of a very busy Rd in India.",
            "So other objects are moving similarly, like the bus or other cars are picked up as supporters."
        ],
        [
            "Actually, once again I picked up as supporters to demand the position even when the car has left damage.",
            "Oh here now yeah, you have a video with the webcam having we want to track this House of Carner supporters are automatically picked up.",
            "No supporters are on this cube when it's moving, but again if it's on the other side, news reporters will get up to increase."
        ],
        [
            "Determine the position.",
            "Here's another, here's a trailer of the movie up playing in my video browser, and you can move it and there's highly appearance change, right?",
            "It's a movie.",
            "It's a movie playing here, but other stuff now.",
            "Other parts of the windows are moving consistently with it, and so you can you."
        ],
        [
            "You you have an idea very very movies or they can completely disappear and reappear after that.",
            "You can.",
            "You can recover from this as well.",
            "And there are many, many possible types of supporters now.",
            "Here's another example.",
            "Now there's a shadow player doing on and since the hand and the light not, they are strongly correlated with the shadow projected on the wall.",
            "It nicely picks up all those guys as supporters too."
        ],
        [
            "My brother very hand of the shadow player is.",
            "Another example, not into tea only, so we want to track this bottle of beer.",
            "And.",
            "The report is doing is filling the class for us and.",
            "Support is exchanged dynamically overtime from the robot from the object itself."
        ],
        [
            "OK.",
            "However.",
            "Obviously.",
            "Or that they are typically failure cases.",
            "And.",
            "Especially, mathematician knows that now this is all that wichner where we estimate where some object is and our approach breaks down when this capling.",
            "Is is violated since we're not observing the object like it is here?",
            "OK. Let me come to the conclusions.",
            "In this work, we have shown that many dynamic relationships.",
            "Between."
        ],
        [
            "Part of the image which we called supporters and the object exists.",
            "By using this other, it's going beyond the object.",
            "By using this supporters become enhanced which will track it.",
            "From the technical side, we use two very, very simple principles.",
            "We explore the uncertainty of the motion prediction via the general half transform to maintain the set of supporters.",
            "And by using the voting, the prediction is quite robust.",
            "Let's keep home message for you.",
            "Maybe it's just look for supporters.",
            "I think in every image in every tracking image alot of supporters around use them to track and to detect people.",
            "Thank you very much.",
            "Thank you so we have time for questions.",
            "Could you go to the mic please?",
            "Does the relation between the supporters and the direct object has to be rigid?",
            "Has the relation between the supporters, then the object to be rigid do need the duration currently as we presented it is a rigid relation.",
            "Can it be updated to continuously updated now and exploiters get exchanged?",
            "So you saw it?",
            "I think on very different many examples right when the robber is filling the class.",
            "Even supporters news reporters came up now and other supporters will die temporarily as well as the distributions.",
            "Now the Gaussian distribution is updated.",
            "All the time, so there's no.",
            "There's nothing which it which it India.",
            "Of course, if the X is a rigid coupling, this will become automatically very, very strong supporters.",
            "Now if you track some widget object now.",
            "All the features on the object and the object center there will be always have the same movement now, so this will automatically become strong supporters if the coupling is not not that clear by a non rigid object.",
            "My shirt I just meant that maybe if you consider a more involved coupling, not just rigid offset, then maybe you can find additional supporters.",
            "Yeah, I agree.",
            "I agree.",
            "If you have a better motion model you can include this, but as I said not very simple model.",
            "OK thanks.",
            "Have many different scenes.",
            "One short question from the back.",
            "Please come to the microphone.",
            "Thanks for the nice talk.",
            "I just have a very simple question.",
            "What happens if at one time you've lost older supporters?",
            "Then the abstract.",
            "So it doesn't mean that after that you can recover the area.",
            "So if we detect it and if it's like you saw it in the in the trailer in the trailer up, I close the window and then it reappears now.",
            "So you detect all the features again, and if the voting is very strong right?",
            "Because the spatial relations are valid, nothing.",
            "If we detect the object thank you.",
            "OK, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "Do you hear me?",
                    "label": 0
                },
                {
                    "sent": "Yes, thanks for the introduction.",
                    "label": 0
                },
                {
                    "sent": "Don't talk about now how to track invisible things and the work I'm presenting today.",
                    "label": 0
                },
                {
                    "sent": "It was joint Burger is joint work.",
                    "label": 0
                },
                {
                    "sent": "Now with the remote's look from goal and Phillip Carter.",
                    "label": 0
                },
                {
                    "sent": "Let's jump into it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For those of you who do not know, this is Connor and I will show you a short video clip in the following and ask you please try to keep tracking cars through the entire video sequence.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there's Kyle coming down sitting in front of his house, right?",
                    "label": 0
                },
                {
                    "sent": "It's going down.",
                    "label": 0
                },
                {
                    "sent": "Keep going.",
                    "label": 0
                },
                {
                    "sent": "I think most of you have absolutely no problem to keep tracking cars through this entire sequence, or even have a rough idea of where Kyle is in this.",
                    "label": 0
                },
                {
                    "sent": "In the six oh, sorry.",
                    "label": 0
                },
                {
                    "sent": "The sequence.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is exactly the goal we want to focus on in this paper.",
                    "label": 0
                },
                {
                    "sent": "So we want to estimate or track the target object if it's visible.",
                    "label": 0
                },
                {
                    "sent": "But also when it gets occluded or when it's outside the image.",
                    "label": 0
                },
                {
                    "sent": "And how is this possible?",
                    "label": 0
                },
                {
                    "sent": "Cause there are?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There will be many, many other potential very strong links between the target object and other parts of the image, which you can explore.",
                    "label": 0
                },
                {
                    "sent": "And we do this by discovering the dynamic elements which we are calling supporters that predicted the position of the target.",
                    "label": 0
                },
                {
                    "sent": "If you remember the.",
                    "label": 0
                },
                {
                    "sent": "Yesterday morning session there was the session hold about context.",
                    "label": 0
                },
                {
                    "sent": "Context is widely used in object detection or categorisation, but they assume a very very fixed link, like a car is always on this tweet or my head is a puff of my daughter and between my shoulders, whereas in tracking we have to dynamically exchange those links in order to benefit from this.",
                    "label": 0
                },
                {
                    "sent": "And this is only focused by a few authors in this field.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such supporters maybe come with different strengths and change overtime, so let's give me an example.",
                    "label": 0
                },
                {
                    "sent": "So this is Carl's wife and she's putting a coin into this Piggy Bank and.",
                    "label": 0
                },
                {
                    "sent": "While she is carrying the coin, she itself, especially the hand and the fingers, are very, very strong supporters to determine the position of the coin.",
                    "label": 0
                },
                {
                    "sent": "But as soon as she has put the coin into this Money Box.",
                    "label": 0
                },
                {
                    "sent": "She will that the link from her and the coin will not be valid anymore but the the class itself.",
                    "label": 0
                },
                {
                    "sent": "The Money Box will get a very very strong supporter to notice vertic coin is in the image.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unless you need some money.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK for real images.",
                    "label": 0
                },
                {
                    "sent": "I will shown that supporters help tracking object.",
                    "label": 0
                },
                {
                    "sent": "We've changed the appearance very, very quickly or occluded objects or objects outside of the image, or even very small or low textures objects.",
                    "label": 0
                },
                {
                    "sent": "So let's consider like the Swiss soccer player who is cheating.",
                    "label": 0
                },
                {
                    "sent": "Who was shot the 1 zero against Spain in damage?",
                    "label": 0
                },
                {
                    "sent": "You even not possible to see the ball in this image, but you have roughly an idea where it is in the network on the image.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks or on the image below.",
                    "label": 0
                },
                {
                    "sent": "You can very well estimated trajectory of the stone only by giving that that image here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In this work, we focus on a specific, a specific type of supporters.",
                    "label": 0
                },
                {
                    "sent": "Local image features.",
                    "label": 0
                },
                {
                    "sent": "So given that image.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And say we want to track all through this image.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we extract some local image features from from the image and.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is usually done is people build two sets different object features and background features and then they learn a model of the object.",
                    "label": 0
                },
                {
                    "sent": "So just by using the object features features to keep tracking the object or they learn discriminative classifiers for example not to distinguish the object features from the background features.",
                    "label": 0
                },
                {
                    "sent": "In this work we go beyond having this binary split.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Is it?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Every feature which is helpful to predict the position of the object should be taken into account, and since these features are not only supposed to lie on the object itself.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore, it's possible to predict very objects even when it gets occluded outside damage.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in summary, once again, supporters of those features which contributed to the prediction of the target object and they are at least temporarily move in a way which is statistically related to the motion of the object itself.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do discovering this set of supporters so assume you have an image sequence and we have a few where reliable measurements on very objectives may be given by Newman input or by when the tracker is very, very confident that the object is present here.",
                    "label": 1
                },
                {
                    "sent": "Then we try to explain model the relationship between the object and other parts of the image in order to predict the position of the object through the entire video sequence.",
                    "label": 1
                },
                {
                    "sent": "For.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Modeling, which is very very simple with just a simple model, we want to estimate the probability that given the image I want to predict the position X of the object and.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are doing using the principle of the channel halftones form until the implicit shape model.",
                    "label": 0
                },
                {
                    "sent": "So let's assume we have already a model of call in that case.",
                    "label": 0
                },
                {
                    "sent": "Now a model of our object.",
                    "label": 0
                },
                {
                    "sent": "We first extract.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which features of given the image, some features are extracted, they are matched to our our model.",
                    "label": 0
                },
                {
                    "sent": "Then",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Local displacements from the feature to the object position are done so each feature votes for the object position.",
                    "label": 0
                },
                {
                    "sent": "By doing this form.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many features and summing them.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We finally get the voting space and we can consider the maximum or the mode of this voting.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space as our our final our final position of the object.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main question is how do we learn this model?",
                    "label": 0
                },
                {
                    "sent": "This model of car?",
                    "label": 0
                },
                {
                    "sent": "How is this done?",
                    "label": 0
                },
                {
                    "sent": "Usually in in for object detection or categorization.",
                    "label": 0
                },
                {
                    "sent": "So you have a lot of training images, so a lot of images from call.",
                    "label": 0
                },
                {
                    "sent": "Then you extract local features into his points for example.",
                    "label": 0
                },
                {
                    "sent": "Cluster them and build the codebook.",
                    "label": 0
                },
                {
                    "sent": "Then these are your prototypes for the for the object, and since you have the ground too, so you know whether very object is.",
                    "label": 0
                },
                {
                    "sent": "You can also learn the displacement vectors or distribution further objectives given given that features.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, since we want to do tracking here.",
                    "label": 0
                },
                {
                    "sent": "We have already a model of supporters and we want to maintain them overtime, so we want to update the prototypes in an online manner as well as updating the object displacement voting.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All is just been done, it's quite simple.",
                    "label": 0
                },
                {
                    "sent": "So since we when we have reliable information available like here we have this extra stop.",
                    "label": 0
                },
                {
                    "sent": "We do for every other into responder.",
                    "label": 0
                },
                {
                    "sent": "For every other feature we add them to the set of supporters and estimate this coupling between them and update the distribution of the of the displacement.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By exploring this principle of the China will have transform automatically.",
                    "label": 0
                },
                {
                    "sent": "It is distinguished between strong supporters were the voting is very, very Peaky.",
                    "label": 0
                },
                {
                    "sent": "So we have a clear vote, very objective or a more blurred vote.",
                    "label": 0
                },
                {
                    "sent": "Weaker vote with their motion coupling is not that outspoken.",
                    "label": 0
                },
                {
                    "sent": "Or you can also distinguish between almost unrelated features in the image.",
                    "label": 0
                },
                {
                    "sent": "Before showing you some experimental results, just give you a.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Few implementation details how we implemented it and we did it.",
                    "label": 0
                },
                {
                    "sent": "We did it very, very simple.",
                    "label": 0
                },
                {
                    "sent": "One can do it.",
                    "label": 0
                },
                {
                    "sent": "Much, much more clever way but.",
                    "label": 0
                },
                {
                    "sent": "It also turns out to work quite well, so.",
                    "label": 0
                },
                {
                    "sent": "For the image and photo feature extraction, we use simple harvest points, describe them by sift like descriptor matching them.",
                    "label": 0
                },
                {
                    "sent": "Do the database.",
                    "label": 0
                },
                {
                    "sent": "If it could establish a good match, then everything is fine and we make updating updating it, otherwise it will be added as a possible new supporter.",
                    "label": 0
                },
                {
                    "sent": "In addition to this Harris Point feature extraction, we also use KLT tracking from one frame to the other frame too.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tablets, those matches for the voting of the displacement of the object.",
                    "label": 0
                },
                {
                    "sent": "Since for some tracking sequences we only have very, very limited frames where we have reliable information, it choose to approximate this whole distribution by one single caution and discussion.",
                    "label": 0
                },
                {
                    "sent": "So the mean and covariance matrix is updated overtime in an online manner, exploring the simple principle of exponential form.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding.",
                    "label": 0
                },
                {
                    "sent": "OK. Let's go to the experiments.",
                    "label": 0
                },
                {
                    "sent": "I will show you one experiment in more detail and then several other experiments which showed the benefit of tracking with supporters.",
                    "label": 0
                },
                {
                    "sent": "So here in the first experiment we recorded a sequence where this small.",
                    "label": 0
                },
                {
                    "sent": "Bottle is.",
                    "label": 0
                },
                {
                    "sent": "Moved behind the Cup.",
                    "label": 0
                },
                {
                    "sent": "Then lift it up.",
                    "label": 0
                },
                {
                    "sent": "Come back and finally was put back on the table.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We asked 10 humans to label in each frame.",
                    "label": 0
                },
                {
                    "sent": "Verda sync the object is and you will see like this.",
                    "label": 0
                },
                {
                    "sent": "This stops one for each for each person.",
                    "label": 0
                },
                {
                    "sent": "So let's see what the human are doing.",
                    "label": 0
                },
                {
                    "sent": "So once the optic is super, they mostly agree.",
                    "label": 0
                },
                {
                    "sent": "But even here they're not quite true, and also from our algorithm point.",
                    "label": 0
                },
                {
                    "sent": "Now we want to we want to be somewhere in that.",
                    "label": 0
                },
                {
                    "sent": "In in that variance, but with the human are doing.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we just put one.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Off the shelf off the web tracker, we download the this tracker and apply this tracker on this image sequence.",
                    "label": 0
                },
                {
                    "sent": "Let's see what this tracker does.",
                    "label": 0
                },
                {
                    "sent": "And again.",
                    "label": 0
                },
                {
                    "sent": "As long as the object is visible, it does the job quite well.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, it's invisible or partially occluded.",
                    "label": 0
                },
                {
                    "sent": "Now it it was lost keeping it tracking.",
                    "label": 0
                },
                {
                    "sent": "However, we use this tracking information as reliable information to train our set of supporters, and this is the result you see.",
                    "label": 0
                },
                {
                    "sent": "The voting space opposing duty and.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sweetie.",
                    "label": 0
                },
                {
                    "sent": "And as you can see now.",
                    "label": 0
                },
                {
                    "sent": "Also, when the object is occluded by the Cup then.",
                    "label": 0
                },
                {
                    "sent": "Then we can roughly datamine its position.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just some some some results.",
                    "label": 0
                },
                {
                    "sent": "And why is it happening?",
                    "label": 0
                },
                {
                    "sent": "We could more less double the week also demanded position very object is not without losing much on precision and especially when the object is a cubit one.",
                    "label": 0
                },
                {
                    "sent": "Why is it working?",
                    "label": 0
                },
                {
                    "sent": "Show a video of the supporters.",
                    "label": 0
                },
                {
                    "sent": "The blue guys are the supporters and the yellow circle is the predicted position.",
                    "label": 0
                },
                {
                    "sent": "It's the mode of devoting space and.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Greenman is when we have this tracking this reliable results.",
                    "label": 0
                },
                {
                    "sent": "OK, here we go.",
                    "label": 0
                },
                {
                    "sent": "So features on the object itself are picked up as well as features on the watch.",
                    "label": 0
                },
                {
                    "sent": "Now because they have correlated movement and successfully tracked the object most of the time.",
                    "label": 0
                },
                {
                    "sent": "And Please note in this image sequence it would have been not be possible, but just into.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relating between the individual tracking results.",
                    "label": 0
                },
                {
                    "sent": "Because there's there's some nontrivial.",
                    "label": 0
                },
                {
                    "sent": "Movement going up.",
                    "label": 0
                },
                {
                    "sent": "OK. Another show, a couple of other examples, not like tracking here this car in the middle of a very busy Rd in India.",
                    "label": 0
                },
                {
                    "sent": "So other objects are moving similarly, like the bus or other cars are picked up as supporters.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, once again I picked up as supporters to demand the position even when the car has left damage.",
                    "label": 0
                },
                {
                    "sent": "Oh here now yeah, you have a video with the webcam having we want to track this House of Carner supporters are automatically picked up.",
                    "label": 0
                },
                {
                    "sent": "No supporters are on this cube when it's moving, but again if it's on the other side, news reporters will get up to increase.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Determine the position.",
                    "label": 0
                },
                {
                    "sent": "Here's another, here's a trailer of the movie up playing in my video browser, and you can move it and there's highly appearance change, right?",
                    "label": 0
                },
                {
                    "sent": "It's a movie.",
                    "label": 0
                },
                {
                    "sent": "It's a movie playing here, but other stuff now.",
                    "label": 0
                },
                {
                    "sent": "Other parts of the windows are moving consistently with it, and so you can you.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You you have an idea very very movies or they can completely disappear and reappear after that.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "You can recover from this as well.",
                    "label": 0
                },
                {
                    "sent": "And there are many, many possible types of supporters now.",
                    "label": 0
                },
                {
                    "sent": "Here's another example.",
                    "label": 0
                },
                {
                    "sent": "Now there's a shadow player doing on and since the hand and the light not, they are strongly correlated with the shadow projected on the wall.",
                    "label": 0
                },
                {
                    "sent": "It nicely picks up all those guys as supporters too.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My brother very hand of the shadow player is.",
                    "label": 0
                },
                {
                    "sent": "Another example, not into tea only, so we want to track this bottle of beer.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The report is doing is filling the class for us and.",
                    "label": 0
                },
                {
                    "sent": "Support is exchanged dynamically overtime from the robot from the object itself.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "Obviously.",
                    "label": 0
                },
                {
                    "sent": "Or that they are typically failure cases.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Especially, mathematician knows that now this is all that wichner where we estimate where some object is and our approach breaks down when this capling.",
                    "label": 0
                },
                {
                    "sent": "Is is violated since we're not observing the object like it is here?",
                    "label": 0
                },
                {
                    "sent": "OK. Let me come to the conclusions.",
                    "label": 0
                },
                {
                    "sent": "In this work, we have shown that many dynamic relationships.",
                    "label": 0
                },
                {
                    "sent": "Between.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Part of the image which we called supporters and the object exists.",
                    "label": 1
                },
                {
                    "sent": "By using this other, it's going beyond the object.",
                    "label": 0
                },
                {
                    "sent": "By using this supporters become enhanced which will track it.",
                    "label": 0
                },
                {
                    "sent": "From the technical side, we use two very, very simple principles.",
                    "label": 1
                },
                {
                    "sent": "We explore the uncertainty of the motion prediction via the general half transform to maintain the set of supporters.",
                    "label": 1
                },
                {
                    "sent": "And by using the voting, the prediction is quite robust.",
                    "label": 1
                },
                {
                    "sent": "Let's keep home message for you.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's just look for supporters.",
                    "label": 0
                },
                {
                    "sent": "I think in every image in every tracking image alot of supporters around use them to track and to detect people.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you so we have time for questions.",
                    "label": 1
                },
                {
                    "sent": "Could you go to the mic please?",
                    "label": 0
                },
                {
                    "sent": "Does the relation between the supporters and the direct object has to be rigid?",
                    "label": 0
                },
                {
                    "sent": "Has the relation between the supporters, then the object to be rigid do need the duration currently as we presented it is a rigid relation.",
                    "label": 1
                },
                {
                    "sent": "Can it be updated to continuously updated now and exploiters get exchanged?",
                    "label": 1
                },
                {
                    "sent": "So you saw it?",
                    "label": 0
                },
                {
                    "sent": "I think on very different many examples right when the robber is filling the class.",
                    "label": 0
                },
                {
                    "sent": "Even supporters news reporters came up now and other supporters will die temporarily as well as the distributions.",
                    "label": 0
                },
                {
                    "sent": "Now the Gaussian distribution is updated.",
                    "label": 0
                },
                {
                    "sent": "All the time, so there's no.",
                    "label": 0
                },
                {
                    "sent": "There's nothing which it which it India.",
                    "label": 0
                },
                {
                    "sent": "Of course, if the X is a rigid coupling, this will become automatically very, very strong supporters.",
                    "label": 0
                },
                {
                    "sent": "Now if you track some widget object now.",
                    "label": 0
                },
                {
                    "sent": "All the features on the object and the object center there will be always have the same movement now, so this will automatically become strong supporters if the coupling is not not that clear by a non rigid object.",
                    "label": 1
                },
                {
                    "sent": "My shirt I just meant that maybe if you consider a more involved coupling, not just rigid offset, then maybe you can find additional supporters.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I agree.",
                    "label": 1
                },
                {
                    "sent": "I agree.",
                    "label": 0
                },
                {
                    "sent": "If you have a better motion model you can include this, but as I said not very simple model.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                },
                {
                    "sent": "Have many different scenes.",
                    "label": 0
                },
                {
                    "sent": "One short question from the back.",
                    "label": 0
                },
                {
                    "sent": "Please come to the microphone.",
                    "label": 1
                },
                {
                    "sent": "Thanks for the nice talk.",
                    "label": 0
                },
                {
                    "sent": "I just have a very simple question.",
                    "label": 0
                },
                {
                    "sent": "What happens if at one time you've lost older supporters?",
                    "label": 1
                },
                {
                    "sent": "Then the abstract.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't mean that after that you can recover the area.",
                    "label": 0
                },
                {
                    "sent": "So if we detect it and if it's like you saw it in the in the trailer in the trailer up, I close the window and then it reappears now.",
                    "label": 0
                },
                {
                    "sent": "So you detect all the features again, and if the voting is very strong right?",
                    "label": 0
                },
                {
                    "sent": "Because the spatial relations are valid, nothing.",
                    "label": 0
                },
                {
                    "sent": "If we detect the object thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}