{
    "id": "frawjdqa6oqawkaa3o6aijxcuxhava4c",
    "title": "Kernels for Protein Structure Prediction",
    "info": {
        "author": [
            "Narges Sharif-Razavian, Language Technologies Institute, Carnegie Mellon University"
        ],
        "published": "Jan. 18, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods",
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2012_razavian_protein/",
    "segmentation": [
        [
            "I'm going to give a short talk focus on another application of discographical models and so our application is focus on developing probabilistic models of protein structures, and I'll talk about how kernel embedded graphical models come to our rescue or partial rescue."
        ],
        [
            "So for those of you who are not familiar with this application, very briefly, I'll describe the pipeline that we will be dealing with.",
            "So we want to provide some models of protein structure and basically pertains are very large dynamic molecules that are the building blocks of the functionalities within each of ourselves.",
            "So it's very important that we understand the dynamic and functionality, and usually there are several ways that we can understand them, one pipeline.",
            "In the research is that so we can crystallize the protein structure and create one snapshot of the structure?",
            "And create basically the tree structure of 1 snapshot.",
            "That snapshot is not enough to tell us about the dynamics.",
            "So what we do usually is to take that one snapshot and do some special molecular dynamics simulation, which is based based on physics rules and it's very expensive simulation.",
            "But what it does is I create some samples from the fluctuations of this structure which from which we can then estimate our models.",
            "So the next step is that we get this sample data an understand that basically the relationship between the different variables an understand the network of the protein structure.",
            "And once we have this network then actual biologists come into place and they can perform several queries.",
            "They can for example locate important sites in the pertain which are potentially good places for drug targeting and very useful activities.",
            "So we focus on the third step here, where we want to model.",
            "Given the molecular dynamics."
        ],
        [
            "Data and molecular dynamics data has several challenges that make our life very difficult.",
            "First of all, we have very large samples and also not only large samples, but also its sample could be several thousand variables and it's very challenging data and also another challenging.",
            "Perhaps properties that most of the time structures are represented as series of angles, because that makes the structure rotation invariant, and it's very commonly used, and these properties create a lot of challenge so far.",
            "There are several available solutions in classic literature, people use discrete graphical models, but then there is a very inherent problem of resolution versus overfitting, and this is the problem that cannot inherently be solved.",
            "So people move to continuous graphical models which make more sense.",
            "The option of Gaussian graphical model, of course is very easy to estimate and very popular, and recently we have seen one versus graphical model being used and these models are parametric models.",
            "They are fast to implement, but especially this continuous models, they have a major shortcoming and it's the fact that the marginals of both of them are unimodal.",
            "But here for example I'm showing.",
            "The marginals estimated from molecular dynamics simulation of this small pertain here that we have and you can see the marginals, or of course, multimodal, both in most of the cases, and also they have arbitrary.",
            "Distribution, so it's a big challenge for us now too.",
            "Provide a model that can handle Angular variables that can handle multi modality and also of course are variables or continuous and that's why.",
            "Oh, so these are the basically the bond angles that kind of reconstruct your structure.",
            "Right, so these challenges can be solved well by Colonel Ambetter graphical models, and that's exactly why we.",
            "Chose to expl."
        ],
        [
            "Element with this graphical models to see whether we can solve our problem.",
            "So I guess you heard a lot enough about kernel embedded graphical models already just for the sake of completion of the talk.",
            "Briefly, what we do is to embed all the components of our graphical model of our inference into the kernel space, and this allows us to, of course represent all the components nonparametrically, and that's very powerful.",
            "And it has very high representative power.",
            "There is 1 issue with this is that all these.",
            "Components after here they assume that this structure is already given or it's fully connected graph.",
            "Or like we have to already know this structure of.",
            "Right now the models are like that, but I'm sure it will change.",
            "So we need to before we can use this model.",
            "We first have to learn a sparse structure before we can actually do our inference.",
            "Because pertain structures are usually rather sparse and we need."
        ],
        [
            "That so there are several ways to do structural learning, especially in the kernel space.",
            "Recently song at all provided a way to estimate tree structures.",
            "Nonparametric, nonparametric Lee and they used basically the nonparametric correlation coefficients in the kernel space to do the structural learning in terms of if the structure is a tree.",
            "Of course that's approximation.",
            "But right now, in this talk actually I will investigate this option as one of potential options.",
            "The other option, of course, is in the parametric space.",
            "There is no neighborhood selection method which is based on several parallel lasso regression.",
            "Again, this is not ideal and I'll talk about in future work how we can extend this to more appropriate methods, But for this talk of our will perform the structural earnings using these two existing methods and see how."
        ],
        [
            "Models perform.",
            "So moving on to really experiments and see how the models now perform.",
            "My experiments are done using the molecular dynamics simulation of this particular protein is great homeo domain and it's actually a domain within a series of proteins and its function is to bind to DNA.",
            "It's very important and in several diseases we see some mutations in this particles several diseases.",
            "So we want to understand the functionality.",
            "It's ultra fast, so the dynamics exhibit a lot of complex interactions and the data that we have is 500,000 samples.",
            "It's extremely large right now.",
            "Our methods are extremely naive.",
            "In case of scalability, so we had to subsample the data, and I subsample two different sets from this data and perform experiments on that, and so we do leave one out cross validation.",
            "And as the baseline I compared to non paranormal which is the semiparametric graphical models and also the Gauss sparse Gaussian graphical models.",
            "Anne."
        ],
        [
            "Just to show you this is the subsample the two subsample data.",
            "Actually I subsample the first 1000 samples and also uniformly subsampling through the whole data set, and you can clearly still very different complexity in the network, and it's interesting for us to see how the model performs in each of these models.",
            "Each of these datasets."
        ],
        [
            "And here is some results based on.",
            "Doing the structural learning and then nonparametric inference before I go and I just mentioned that since we deal with angles one way that we had, we thought to handle that is to create another kernel which simply closes the circle in.",
            "Let us deal with Angular variables rather than the.",
            "Non angular variables.",
            "So we use Gaussian kernel and also this trigonometric kernel.",
            "And here in this table you can see the 1st two are doing a structural learning bruising neighborhood selection comparing to non paranormal and Gaussian and.",
            "The first is Colonel von Gaussian.",
            "The second is that our econometric kernel on both datasets I showed the root mean square error of this leave one out cross validation.",
            "The distances between our predictions, and Interestingly, so.",
            "First of all, we see that doing the inference using nonparametric kernel better graphical model actually overall outperforms the two other baselines that we have.",
            "But in particular, it's very important that we use the correct kernel for our applications.",
            "Gaussian kernel doesn't really give much improvement.",
            "Also, on the more complex data you can see the improvement is higher, but.",
            "The most important thing is we have to focus on the right kernel for the application and also."
        ],
        [
            "So I said we had option of looking at two different structural learning methods, so we also use the nonparametric tree based structure learning.",
            "And since the kernel, the trigonometric kernel, perform better, I focus on these results for now.",
            "And also I just show you the result in this simpler data set now.",
            "And as you can see, actually.",
            "So both of these structural learning methods still outperform our other.",
            "Baselines and the Gaussian kernel method, but.",
            "Still turns out that even though the nonparametric tree metric is more powerful in it actually makes.",
            "More sense to learn the structure nonparametrically when we're doing the inference in a nonparametric fashion.",
            "Still doing neighborhood selection actually gives us lower error so.",
            "It seems that the tree structure is really not.",
            "Sorry it's over."
        ],
        [
            "Right so.",
            "I guess that's up to hear the results that I have had so far.",
            "So in conclusion, we have seen that doing nonparametric using number metric belief propagation is actually outperforming other inference methods, but only when their appropriate kernel is used and also right now we know that neighborhood selection actually outperforms nonparametric tree graphical model as our future work.",
            "There is a lot to do is more than what we have done.",
            "Of course the list is very large, but.",
            "Definitely we have to improve our structural learning method and we are investigating using nonparametric regression within their neighborhood selection instead of linear regression.",
            "And also today there was a lot of interesting talks about the scalability and we have a problem with scalability.",
            "So the next step is to improve the scalability as well.",
            "So thanks for listening."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to give a short talk focus on another application of discographical models and so our application is focus on developing probabilistic models of protein structures, and I'll talk about how kernel embedded graphical models come to our rescue or partial rescue.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for those of you who are not familiar with this application, very briefly, I'll describe the pipeline that we will be dealing with.",
                    "label": 0
                },
                {
                    "sent": "So we want to provide some models of protein structure and basically pertains are very large dynamic molecules that are the building blocks of the functionalities within each of ourselves.",
                    "label": 1
                },
                {
                    "sent": "So it's very important that we understand the dynamic and functionality, and usually there are several ways that we can understand them, one pipeline.",
                    "label": 1
                },
                {
                    "sent": "In the research is that so we can crystallize the protein structure and create one snapshot of the structure?",
                    "label": 0
                },
                {
                    "sent": "And create basically the tree structure of 1 snapshot.",
                    "label": 0
                },
                {
                    "sent": "That snapshot is not enough to tell us about the dynamics.",
                    "label": 0
                },
                {
                    "sent": "So what we do usually is to take that one snapshot and do some special molecular dynamics simulation, which is based based on physics rules and it's very expensive simulation.",
                    "label": 0
                },
                {
                    "sent": "But what it does is I create some samples from the fluctuations of this structure which from which we can then estimate our models.",
                    "label": 0
                },
                {
                    "sent": "So the next step is that we get this sample data an understand that basically the relationship between the different variables an understand the network of the protein structure.",
                    "label": 0
                },
                {
                    "sent": "And once we have this network then actual biologists come into place and they can perform several queries.",
                    "label": 0
                },
                {
                    "sent": "They can for example locate important sites in the pertain which are potentially good places for drug targeting and very useful activities.",
                    "label": 0
                },
                {
                    "sent": "So we focus on the third step here, where we want to model.",
                    "label": 0
                },
                {
                    "sent": "Given the molecular dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data and molecular dynamics data has several challenges that make our life very difficult.",
                    "label": 0
                },
                {
                    "sent": "First of all, we have very large samples and also not only large samples, but also its sample could be several thousand variables and it's very challenging data and also another challenging.",
                    "label": 0
                },
                {
                    "sent": "Perhaps properties that most of the time structures are represented as series of angles, because that makes the structure rotation invariant, and it's very commonly used, and these properties create a lot of challenge so far.",
                    "label": 1
                },
                {
                    "sent": "There are several available solutions in classic literature, people use discrete graphical models, but then there is a very inherent problem of resolution versus overfitting, and this is the problem that cannot inherently be solved.",
                    "label": 1
                },
                {
                    "sent": "So people move to continuous graphical models which make more sense.",
                    "label": 0
                },
                {
                    "sent": "The option of Gaussian graphical model, of course is very easy to estimate and very popular, and recently we have seen one versus graphical model being used and these models are parametric models.",
                    "label": 0
                },
                {
                    "sent": "They are fast to implement, but especially this continuous models, they have a major shortcoming and it's the fact that the marginals of both of them are unimodal.",
                    "label": 0
                },
                {
                    "sent": "But here for example I'm showing.",
                    "label": 0
                },
                {
                    "sent": "The marginals estimated from molecular dynamics simulation of this small pertain here that we have and you can see the marginals, or of course, multimodal, both in most of the cases, and also they have arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Distribution, so it's a big challenge for us now too.",
                    "label": 1
                },
                {
                    "sent": "Provide a model that can handle Angular variables that can handle multi modality and also of course are variables or continuous and that's why.",
                    "label": 0
                },
                {
                    "sent": "Oh, so these are the basically the bond angles that kind of reconstruct your structure.",
                    "label": 0
                },
                {
                    "sent": "Right, so these challenges can be solved well by Colonel Ambetter graphical models, and that's exactly why we.",
                    "label": 0
                },
                {
                    "sent": "Chose to expl.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Element with this graphical models to see whether we can solve our problem.",
                    "label": 0
                },
                {
                    "sent": "So I guess you heard a lot enough about kernel embedded graphical models already just for the sake of completion of the talk.",
                    "label": 1
                },
                {
                    "sent": "Briefly, what we do is to embed all the components of our graphical model of our inference into the kernel space, and this allows us to, of course represent all the components nonparametrically, and that's very powerful.",
                    "label": 0
                },
                {
                    "sent": "And it has very high representative power.",
                    "label": 0
                },
                {
                    "sent": "There is 1 issue with this is that all these.",
                    "label": 0
                },
                {
                    "sent": "Components after here they assume that this structure is already given or it's fully connected graph.",
                    "label": 0
                },
                {
                    "sent": "Or like we have to already know this structure of.",
                    "label": 0
                },
                {
                    "sent": "Right now the models are like that, but I'm sure it will change.",
                    "label": 0
                },
                {
                    "sent": "So we need to before we can use this model.",
                    "label": 0
                },
                {
                    "sent": "We first have to learn a sparse structure before we can actually do our inference.",
                    "label": 0
                },
                {
                    "sent": "Because pertain structures are usually rather sparse and we need.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That so there are several ways to do structural learning, especially in the kernel space.",
                    "label": 0
                },
                {
                    "sent": "Recently song at all provided a way to estimate tree structures.",
                    "label": 0
                },
                {
                    "sent": "Nonparametric, nonparametric Lee and they used basically the nonparametric correlation coefficients in the kernel space to do the structural learning in terms of if the structure is a tree.",
                    "label": 1
                },
                {
                    "sent": "Of course that's approximation.",
                    "label": 0
                },
                {
                    "sent": "But right now, in this talk actually I will investigate this option as one of potential options.",
                    "label": 0
                },
                {
                    "sent": "The other option, of course, is in the parametric space.",
                    "label": 0
                },
                {
                    "sent": "There is no neighborhood selection method which is based on several parallel lasso regression.",
                    "label": 1
                },
                {
                    "sent": "Again, this is not ideal and I'll talk about in future work how we can extend this to more appropriate methods, But for this talk of our will perform the structural earnings using these two existing methods and see how.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Models perform.",
                    "label": 0
                },
                {
                    "sent": "So moving on to really experiments and see how the models now perform.",
                    "label": 0
                },
                {
                    "sent": "My experiments are done using the molecular dynamics simulation of this particular protein is great homeo domain and it's actually a domain within a series of proteins and its function is to bind to DNA.",
                    "label": 0
                },
                {
                    "sent": "It's very important and in several diseases we see some mutations in this particles several diseases.",
                    "label": 0
                },
                {
                    "sent": "So we want to understand the functionality.",
                    "label": 0
                },
                {
                    "sent": "It's ultra fast, so the dynamics exhibit a lot of complex interactions and the data that we have is 500,000 samples.",
                    "label": 0
                },
                {
                    "sent": "It's extremely large right now.",
                    "label": 0
                },
                {
                    "sent": "Our methods are extremely naive.",
                    "label": 0
                },
                {
                    "sent": "In case of scalability, so we had to subsample the data, and I subsample two different sets from this data and perform experiments on that, and so we do leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "And as the baseline I compared to non paranormal which is the semiparametric graphical models and also the Gauss sparse Gaussian graphical models.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to show you this is the subsample the two subsample data.",
                    "label": 0
                },
                {
                    "sent": "Actually I subsample the first 1000 samples and also uniformly subsampling through the whole data set, and you can clearly still very different complexity in the network, and it's interesting for us to see how the model performs in each of these models.",
                    "label": 1
                },
                {
                    "sent": "Each of these datasets.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here is some results based on.",
                    "label": 0
                },
                {
                    "sent": "Doing the structural learning and then nonparametric inference before I go and I just mentioned that since we deal with angles one way that we had, we thought to handle that is to create another kernel which simply closes the circle in.",
                    "label": 1
                },
                {
                    "sent": "Let us deal with Angular variables rather than the.",
                    "label": 0
                },
                {
                    "sent": "Non angular variables.",
                    "label": 0
                },
                {
                    "sent": "So we use Gaussian kernel and also this trigonometric kernel.",
                    "label": 1
                },
                {
                    "sent": "And here in this table you can see the 1st two are doing a structural learning bruising neighborhood selection comparing to non paranormal and Gaussian and.",
                    "label": 0
                },
                {
                    "sent": "The first is Colonel von Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The second is that our econometric kernel on both datasets I showed the root mean square error of this leave one out cross validation.",
                    "label": 0
                },
                {
                    "sent": "The distances between our predictions, and Interestingly, so.",
                    "label": 1
                },
                {
                    "sent": "First of all, we see that doing the inference using nonparametric kernel better graphical model actually overall outperforms the two other baselines that we have.",
                    "label": 0
                },
                {
                    "sent": "But in particular, it's very important that we use the correct kernel for our applications.",
                    "label": 0
                },
                {
                    "sent": "Gaussian kernel doesn't really give much improvement.",
                    "label": 0
                },
                {
                    "sent": "Also, on the more complex data you can see the improvement is higher, but.",
                    "label": 0
                },
                {
                    "sent": "The most important thing is we have to focus on the right kernel for the application and also.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I said we had option of looking at two different structural learning methods, so we also use the nonparametric tree based structure learning.",
                    "label": 1
                },
                {
                    "sent": "And since the kernel, the trigonometric kernel, perform better, I focus on these results for now.",
                    "label": 0
                },
                {
                    "sent": "And also I just show you the result in this simpler data set now.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, actually.",
                    "label": 0
                },
                {
                    "sent": "So both of these structural learning methods still outperform our other.",
                    "label": 0
                },
                {
                    "sent": "Baselines and the Gaussian kernel method, but.",
                    "label": 0
                },
                {
                    "sent": "Still turns out that even though the nonparametric tree metric is more powerful in it actually makes.",
                    "label": 1
                },
                {
                    "sent": "More sense to learn the structure nonparametrically when we're doing the inference in a nonparametric fashion.",
                    "label": 0
                },
                {
                    "sent": "Still doing neighborhood selection actually gives us lower error so.",
                    "label": 0
                },
                {
                    "sent": "It seems that the tree structure is really not.",
                    "label": 0
                },
                {
                    "sent": "Sorry it's over.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "I guess that's up to hear the results that I have had so far.",
                    "label": 0
                },
                {
                    "sent": "So in conclusion, we have seen that doing nonparametric using number metric belief propagation is actually outperforming other inference methods, but only when their appropriate kernel is used and also right now we know that neighborhood selection actually outperforms nonparametric tree graphical model as our future work.",
                    "label": 1
                },
                {
                    "sent": "There is a lot to do is more than what we have done.",
                    "label": 0
                },
                {
                    "sent": "Of course the list is very large, but.",
                    "label": 1
                },
                {
                    "sent": "Definitely we have to improve our structural learning method and we are investigating using nonparametric regression within their neighborhood selection instead of linear regression.",
                    "label": 0
                },
                {
                    "sent": "And also today there was a lot of interesting talks about the scalability and we have a problem with scalability.",
                    "label": 0
                },
                {
                    "sent": "So the next step is to improve the scalability as well.",
                    "label": 0
                },
                {
                    "sent": "So thanks for listening.",
                    "label": 0
                }
            ]
        }
    }
}