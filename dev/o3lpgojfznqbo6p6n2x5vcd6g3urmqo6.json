{
    "id": "o3lpgojfznqbo6p6n2x5vcd6g3urmqo6",
    "title": "Mining the Web to Facilitate Fast and Accurate Approximate Match",
    "info": {
        "author": [
            "Surajit Chaudhuri, Microsoft Research",
            "Venkatesh Ganti, Microsoft Research",
            "Dong Xin, Microsoft Research"
        ],
        "published": "May 20, 2009",
        "recorded": "April 2009",
        "category": [
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/www09_xin_mtw/",
    "segmentation": [
        [
            "OK, good great so welcome to the web mining session.",
            "We have three thoughts, each half an hour with questions included, and the first talk.",
            "Is by Dongxing, which is researcher at Microsoft Research in US, and the talk is about exploiting web search to generate synonyms for entities.",
            "Good morning everyone.",
            "I'm going to talk about our work on generating synonyms for entities using web search.",
            "Since the joint work with such artery and package candy."
        ],
        [
            "So let me start with some motivating examples.",
            "Often we have a list of entities which may be a people name, product name, place name and want to analyze all these entities.",
            "So one example is that many shopping website.",
            "They have a list of product titles and they want to have some fun little queries over this product titles such as What's the popularity of this products?",
            "What's the sentiment of this product and what's the minimum and maximum price?",
            "Offered on the web for those products."
        ],
        [
            "So in order to answer those queries, the first step is to identify those product name names from web page such as blogs, forums and news news pages.",
            "So here's the input is a dictionary or product titles and a set of documents and the other person is to identify which document at which place mentions which products."
        ],
        [
            "Oh sorry.",
            "So the problem is challenged because actually when we get there authority for the title as usual is very long and concrete.",
            "And when people mention so the product in web pages.",
            "Different people have that peripheral description for the product and often the mentioned form is different from what we have from the database.",
            "For example, in addition, we have the Lenovo ThinkPad X61 laptop tablet and this exact name is not mentioned in the document by users.",
            "So we need to decide where this substring, which is different from the dictionary form, is a match or not."
        ],
        [
            "What's this what's?",
            "So conventionally, people using a string similarity to catch this to catch their approach to match.",
            "For example, here we have two sentence as the first one, use rebel xti and second one use Canon EOS digital rebel camera.",
            "Both of them are candidate for candid match for for the Canon digital camera product title in our dictionary.",
            "Actually, based on common knowledge, we all know that rebel xti actually does refer to the original product, although it has low strength mariti as on the other hand, the Canon EOS digital rebel camera does not refer uniquely refer to the original product because there are many models in this rebel rebel camera.",
            "So so Jenn similarity actually cannot catch.",
            "So the intuition that there are correlations between tokens in the in the in the entity and strength narrative.",
            "Which would you consider the information from this joint only cannot catch this coloration?"
        ],
        [
            "So here we want to analyze this correlation across different multiple documents.",
            "Given the candidate rebel Xti and given the entity Canon EOS digital Rebel XT SLR camera, what we want to do is we want to find a set of related documents which talks about this rebel xti.",
            "And in some document we find in their near neighborhood we found this cannot use your camera.",
            "The other tokens, which also being mentioned in other tokens also in the entity.",
            "But of course in some other document is not mentioned.",
            "So in order to get a robust output we need to aggregate evidence from multiple documents."
        ],
        [
            "So in this talk we would like to focus on a class of synonyms which we call a subset synonyms, which basically the cinnamon is a subset of entity and there's an Oracle function says this subset is synonym of this entity.",
            "So I will talk about how we formulate this Oracle function in a few minutes.",
            "Some example of this obsession is that you owe SSDI is assessment as we talked in a previous slide and cannot use this camera.",
            "Also, it's a subset, but it's not a synonym, so the reason that we focus on substance synonym is that we're pretty much focus on the product title domain, and we are when we got the data is from authority source and the product titles have some critical tokens, but they also had redundant tokens and we also observed that in document people usually use two or three keywords to refer to a product, and most time this tools he was a subset of original.",
            "For the titles, that's why we started this problem by looking at the subset synonyms."
        ],
        [
            "So this is the overall architecture of our approach to extract entities from documents.",
            "So given the entity database, we are exploiting web to generating the synonyms using correlation analysis and after this symptoms are generated we are expanding the original list by those synonyms.",
            "And at any extraction phrase, we just use some exact match method to extract entities."
        ],
        [
            "So this is outline of my talk first or I will define formally defined problem.",
            "Then we talk about algorithms to generate this synonyms and will show some experiment result and finally is ready to work and conclusions."
        ],
        [
            "So to character.",
            "As I mentioned earlier, we have an function which is a synonym to characterize whether this subset is a synonym of originality or not, so basically want to computer a correlation score for this subset and entity pair.",
            "So This is why we are using this to Baxter example throughout this presentation.",
            "So here we found a document which mentions Roblox die, and in its context it's language.",
            "Small window of this Roblox, die.",
            "We found other tokens which also appear in the original entity.",
            "So when we use some strong Jakarta Jakarta similarity to catch this correlation basically within the context, we look at the fraction or weighted sum of tokens in the context of this subset and which also appears in entity.",
            "So when we get next document, we do the same thing.",
            "And finally, we are aggregating all these scores and we're comparing with the threshold.",
            "If the score is larger than some threshold with it synonym otherwise with it's not synonym."
        ],
        [
            "So in order to get a set of documents which related subset, we rely on web search.",
            "For example, we for to study the back style, we send the Baxter as a query to search engine and retrieve toepke snaps as rate documents."
        ],
        [
            "So this is a flow of the function.",
            "We called it synonym.",
            "Basically it verifies whether subset S is a synonym of entity.",
            "Another procedure is that it has four steps.",
            "First issues as as a query to the web search and retrieve toepke snaps at rate documents.",
            "The computer correlation score for each documents and finally aggregated scores and compare with the threshold.",
            "So in the remaining of this talk, I will consider a cinema as an atomic operator.",
            "And obviously this operator.",
            "The cost of this operator is mainly on this web search cost, so we are trying to minimize the number of queries we sent to the search engine."
        ],
        [
            "So this is the problem.",
            "Statements input is a set of entities and our web search API's output is that for each entity in this list, we want to find all subsets as whose correlation scores larger than a certain threshold.",
            "And our objective is that we want to minimize the number of verifications."
        ],
        [
            "So I'll talk about the algorithm."
        ],
        [
            "So, given an additive, all the subsets are possible candidates.",
            "Here all the candidates from actual lattice structure.",
            "So our algorithm rely on an assumption which will call a subset and subset monotonicity assumption basically."
        ],
        [
            "Just says if a subset is not a synonym or the other subset which is smaller than this subject is not a synonym.",
            "For example, this Sony Vaio laptop is not a synonym of Sunnyvale F-150 laptop because there are many, many other models in this Sony Vaio series, and we conclude this subsets of this Sony Vaio laptop are not synonyms as well for numbers on evals on Laptop Dell laptop.",
            "Sunnyvale and laptops.",
            "Their owners anonymous."
        ],
        [
            "On the other hand, if we identify this, Sony F-150 is a synonym of surgeon entity, then all is super set within this lattice structure are also subsets also valid synonyms?"
        ],
        [
            "So given this.",
            "Assumption we can identify a frontier in this lattice structure.",
            "Basically, the frontier consists of minimum synonyms and maximum non synonyms.",
            "So all the remaining subsets in this latest lattice structure can be proved by our super set.",
            "That assumption?"
        ],
        [
            "So, uh, this frontier definition actually give us a hint on how to minimize the cost of verification.",
            "Basically, we only need to verify the subsets in the frontier.",
            "So let me use this oh PTEB, the number of the success, the number of successes in the frontier of it, I'm going to use this symbol in later on later slides."
        ],
        [
            "Because, uh, because before we very fast, but we don't know whether it's me or not.",
            "Whether it's cinnamon, not cinnamon, so our tasks identify this, then identify the subsets in the frontier, and this is done by some greedy algorithm.",
            "Basically, the flow of greedy algorithm that given this entity E, we enumerate all subsets which actually original form a lattice structure, and we subset a subset from this candidate space we verify it.",
            "And after we know the status whether the system or not, we can prove the remaining subsets in this candidate space.",
            "We continue this procedure until there's no success.",
            "Life left in the candidates, so it stops.",
            "So we have a few algorithms, all of them follow this.",
            "Follow this framework."
        ],
        [
            "So the first algorithm we called a single entity algorithm.",
            "Basically we only look at we only German leverage information from one entity, and the way we select subset is using some depth first search.",
            "It's very easy, so it's very simple, so we start from the root and pick the first one.",
            "We verify it.",
            "Here it is is a synonym and there's no subset of this Sony Vaio F-150.",
            "In the latest there, no proving.",
            "Next we get Sunnyvale.",
            "It's not seen him and we can prove this Sony and Val by proving what I mean that there they can.",
            "We do not need to verify them and we also know there not synonym.",
            "So we continue this depth first search.",
            "We found Sunny 105th Sunny F-150.",
            "And the weekend we can also know that these two supersets are also synonyms, and so on so forth.",
            "So although this is a very simple algorithm, it has some nice property, so the number of allocations by depth first search that most E times opt in E means essentially the number of tokens in the entity."
        ],
        [
            "So here's a second algorithm we called Max Benefit algorithm at the different from the depth first search which follows lattice structure.",
            "This one simultaneously consider all the subsets in the lattice.",
            "For example, given the Sony 100F-150.",
            "After verify this one, there are two possibilities.",
            "This could be a synonym, could be an awesome if it is synonym then we can prove three other success in the lattice structure.",
            "If it is not synonym we can prove to other.",
            "Success in the lattice structure.",
            "So because we don't know whether the synonym or not before we verify it, so we can use them.",
            "Some aggregation function to estimate it.",
            "Basically we can do aggressively, let's say Max between this true or false, or conservatively we can do mean between these truffles, or which stood average.",
            "So now."
        ],
        [
            "I'm going to talk about multiple entity scheduling.",
            "The intuition that if we have multiple entities, we can actually leverage the information structure similarity between these entities and give us better hint on whether it is a cinema, not the example that often we have product titles which is very similar to each other like a Sony Vaio One F-150 Sony Vaio P 5035 Thirty and Sony other laptops."
        ],
        [
            "So if we already processed like say Sunnyvale F-150 laptop, we know the result of this this entity.",
            "And when we process a new entity which is very similar to the previous one and we look at Sunnyvale P 5:30."
        ],
        [
            "We may, we may.",
            "The intuition that this is likely to be assigning becauses I the previous one, at the similar structure, one they the conclusions that Sony Vaio F-150 is a synonym."
        ],
        [
            "So actually we the important thing is we need to catch the structural similarity between entities.",
            "And this actually asked requires to enable one to one mapping between subsets across different entities.",
            "So this basically has two requirements.",
            "First, the entities must have the same number of tokens, so that have this they have same same.",
            "Same structure of same lattice structure and the correspond tokens are either same token or tokens with common property.",
            "So we can see this.",
            "This appears that Maps to that subset has some kind of high confidence."
        ],
        [
            "So in order to do this kind of grouping we use, there are other ways to do this.",
            "Grouping.",
            "What we use is rule based mapping, so we typically will two types of rules when the regular expression, for example this this talk if this token contains the letter or number, which we says that number and we also do categorisation for number for their colors we just say that color.",
            "So we apply these rules on entity names and entities with the same normalized name.",
            "Summer group"
        ],
        [
            "So now, given their previous three Sony Vaio laptops, now we have the same normalized form, say LMS that number.",
            "So they they form the same lattice structure and eat at each position.",
            "Each subset position they are they are mapping to each other correspondingly.",
            "Now given this group profile, we can accumulate statistics within the groups."
        ],
        [
            "So the way we're committed status that for each subset we maintain 2 two counts, true or false.",
            "She is number of entities which has been processed, and at this position at this subset it is a synonym for the number of entities which has been processed.",
            "And this subset is not a synonym."
        ],
        [
            "Now let's go back to our previous I mentioned Max Benefit Search at Best Buy for Search.",
            "We don't know whether this is a cinnamon not so we use some aggregation function to estimate the benefit.",
            "Now, since we have some statics within the group, for example in this case, let's say Sony P536 is like a true.",
            "The file forces forces one.",
            "It's more likely to be assigning so instead of using this aggregation function, we just keep saying that this.",
            "More likely to be true, and the benefit should be 3.",
            "So we are still using the Max benefit framework, but the way we estimate the benefit is different."
        ],
        [
            "Now we move to the experimenter's."
        ],
        [
            "But so I'm going to show briefly to show 2 results in the experiments.",
            "In the experiment, more details are in the paper, so data we are using that we use 100K product names from MSN shopping as real data consists of computer title, compare names, GPS cameras, bicycles shows, etc.",
            "And the web search API we use is live search livesearch.com."
        ],
        [
            "And the first is the quality of synonyms.",
            "We ask human experts to label some data for us, and this is the comparison between the correlation based measure with them with a popular stream based measure which is awaited color similarity and we vary the number of the value of threshold.",
            "We got precision recall curve like this.",
            "So as we can see from this graph the document correlation based measure.",
            "Very good position.",
            "Anne.",
            "And it's much better than the customer loyalty."
        ],
        [
            "And this is a performance graph.",
            "Basically we measure the number of verifications, that is the number of web searches we sent to live.com and the red line is the upper bound, which is a naive algorithm, which we do.",
            "We do verification one by one, and green lines optimal solution, which basically we do we computed after we verify the entity.",
            "So we can identify the frontier.",
            "And.",
            "Among those oldest method we found the multiplicity is best, which is reasonable because we leveraging the information across different entities.",
            "And that's for searches generated from better than the Max benefit search."
        ],
        [
            "So our work is, uh, is related to many other things, but the two main streams that we are our generated approximately matching in a lot of database work, basically approximate merging.",
            "They match similarity based on strings, attribute values, link structures that we're looking at evidence from management documents and our calls also related to works in the RP community that they studied measures.",
            "For distribution mathematics, the only difference that are automatic is similar to what they started in their community, but they do not consider the efficient computation."
        ],
        [
            "So in summary, we have developed efficient method to generate synonyms for entities.",
            "Those entities can be also used for, let's say a person match in anticipation in fuzzy matching data cleaning.",
            "So."
        ],
        [
            "If I mean if I have time I would like to spend one minute to talk about the the project background from which we started to start to look at this problem.",
            "So we have project query portal.",
            "Basically our idea is that currently people are looking there are two separate searches going on for documents.",
            "People using web search using Google yahooorlive.com to search documents and their other side that we have a lot of structure database.",
            "And this data is different from what we have on the web and people have different ways to search this stretch data, such as using Amazon to search products using MDB to search movies actor actors.",
            "But these two data are not related or not correlate to each other.",
            "So what we are doing is that we want to build a relationship between this structure database and web documents and want to use this relationship to image search.",
            "So in this for this purpose we need to identify the entities in structure database in the documents.",
            "So we found this approach and match is really important.",
            "So there's another talk in this conference, basically talking about the other big picture of this project, which is exploiting web search engine to search strategy based.",
            "The talk will be presented by my colleague Contratti in this afternoon, and our project is you can use the search key to search Microsoft Research and exploration."
        ],
        [
            "Questions.",
            "Questions.",
            "Is the underlying product database that you are trying to do this multi entity match?",
            "Did you properly?",
            "So is the underlying product database the the entity titles that you are trying to look to do a look up for all of them?",
            "Is that deduped, yes.",
            "So then it seems that.",
            "For a lot of.",
            "The non synonyms you could just infer the fact that it's not a synonym, but just looking at your own database.",
            "So for example Sony Vaio laptop.",
            "Yeah if you have 15 Sunnyvale letter number laptop in your own database, then it's pretty clear without the web search that it's not a synonym.",
            "Yes, yes, I agree.",
            "So you actually can use the frequency of this phrase to do some proving, so it's not easy to do plumbing first.",
            "First, the reason that first the data is not very clean, they have duplicates.",
            "So if you use frequently promise, likely knew I miss something and also some data are weird.",
            "One example like in our data set we have like Apple Nano.",
            "Apple, iPod nano and then another title called Apple Apple Nano Green.",
            "So if you say that anything frequencies large equal to two, you can do not look at it.",
            "For example, Apple Nano frequency tool you're going to miss this synonym because Apple Nano is a synonym of Apple.",
            "Apple Nano right?",
            "So I am saying that yes, you can do some slash proving.",
            "Actually we did that we did not talk about it in stock, which is that, but you need to carefully control the threshold.",
            "So I enjoyed the talk.",
            "I thought it was very interesting, um.",
            "There's there's a product called Xbox that Microsoft came out with a few years ago, and in the sequel was called Xbox 360.",
            "And if you look in social media now, Xbox 360 is often referred to as Xbox, so there's a kind of a temporal problem here where a term, a synonym for a term Xbox 360 is ambiguous with another product that was just which was.",
            "A subset of this term, but is not a.",
            "It's not a synonym.",
            "So, have you thought at all about temporal aspects of the data and how that?",
            "Is implicated in in doing that kind of matching?",
            "This is a good point.",
            "We have not thought about this, so I guess that yeah, it probably will vary time by time, but not in very short period.",
            "So I mean this is we consider this offline processing so if you do not need to do it on daily schedule right?",
            "So probably you can scale it once a month.",
            "I don't know, probably is good enough."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good great so welcome to the web mining session.",
                    "label": 0
                },
                {
                    "sent": "We have three thoughts, each half an hour with questions included, and the first talk.",
                    "label": 0
                },
                {
                    "sent": "Is by Dongxing, which is researcher at Microsoft Research in US, and the talk is about exploiting web search to generate synonyms for entities.",
                    "label": 1
                },
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about our work on generating synonyms for entities using web search.",
                    "label": 0
                },
                {
                    "sent": "Since the joint work with such artery and package candy.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me start with some motivating examples.",
                    "label": 0
                },
                {
                    "sent": "Often we have a list of entities which may be a people name, product name, place name and want to analyze all these entities.",
                    "label": 0
                },
                {
                    "sent": "So one example is that many shopping website.",
                    "label": 0
                },
                {
                    "sent": "They have a list of product titles and they want to have some fun little queries over this product titles such as What's the popularity of this products?",
                    "label": 1
                },
                {
                    "sent": "What's the sentiment of this product and what's the minimum and maximum price?",
                    "label": 0
                },
                {
                    "sent": "Offered on the web for those products.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to answer those queries, the first step is to identify those product name names from web page such as blogs, forums and news news pages.",
                    "label": 0
                },
                {
                    "sent": "So here's the input is a dictionary or product titles and a set of documents and the other person is to identify which document at which place mentions which products.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh sorry.",
                    "label": 0
                },
                {
                    "sent": "So the problem is challenged because actually when we get there authority for the title as usual is very long and concrete.",
                    "label": 0
                },
                {
                    "sent": "And when people mention so the product in web pages.",
                    "label": 0
                },
                {
                    "sent": "Different people have that peripheral description for the product and often the mentioned form is different from what we have from the database.",
                    "label": 0
                },
                {
                    "sent": "For example, in addition, we have the Lenovo ThinkPad X61 laptop tablet and this exact name is not mentioned in the document by users.",
                    "label": 0
                },
                {
                    "sent": "So we need to decide where this substring, which is different from the dictionary form, is a match or not.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's this what's?",
                    "label": 0
                },
                {
                    "sent": "So conventionally, people using a string similarity to catch this to catch their approach to match.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have two sentence as the first one, use rebel xti and second one use Canon EOS digital rebel camera.",
                    "label": 1
                },
                {
                    "sent": "Both of them are candidate for candid match for for the Canon digital camera product title in our dictionary.",
                    "label": 0
                },
                {
                    "sent": "Actually, based on common knowledge, we all know that rebel xti actually does refer to the original product, although it has low strength mariti as on the other hand, the Canon EOS digital rebel camera does not refer uniquely refer to the original product because there are many models in this rebel rebel camera.",
                    "label": 0
                },
                {
                    "sent": "So so Jenn similarity actually cannot catch.",
                    "label": 0
                },
                {
                    "sent": "So the intuition that there are correlations between tokens in the in the in the entity and strength narrative.",
                    "label": 0
                },
                {
                    "sent": "Which would you consider the information from this joint only cannot catch this coloration?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we want to analyze this correlation across different multiple documents.",
                    "label": 0
                },
                {
                    "sent": "Given the candidate rebel Xti and given the entity Canon EOS digital Rebel XT SLR camera, what we want to do is we want to find a set of related documents which talks about this rebel xti.",
                    "label": 1
                },
                {
                    "sent": "And in some document we find in their near neighborhood we found this cannot use your camera.",
                    "label": 0
                },
                {
                    "sent": "The other tokens, which also being mentioned in other tokens also in the entity.",
                    "label": 0
                },
                {
                    "sent": "But of course in some other document is not mentioned.",
                    "label": 0
                },
                {
                    "sent": "So in order to get a robust output we need to aggregate evidence from multiple documents.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk we would like to focus on a class of synonyms which we call a subset synonyms, which basically the cinnamon is a subset of entity and there's an Oracle function says this subset is synonym of this entity.",
                    "label": 1
                },
                {
                    "sent": "So I will talk about how we formulate this Oracle function in a few minutes.",
                    "label": 0
                },
                {
                    "sent": "Some example of this obsession is that you owe SSDI is assessment as we talked in a previous slide and cannot use this camera.",
                    "label": 0
                },
                {
                    "sent": "Also, it's a subset, but it's not a synonym, so the reason that we focus on substance synonym is that we're pretty much focus on the product title domain, and we are when we got the data is from authority source and the product titles have some critical tokens, but they also had redundant tokens and we also observed that in document people usually use two or three keywords to refer to a product, and most time this tools he was a subset of original.",
                    "label": 0
                },
                {
                    "sent": "For the titles, that's why we started this problem by looking at the subset synonyms.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the overall architecture of our approach to extract entities from documents.",
                    "label": 1
                },
                {
                    "sent": "So given the entity database, we are exploiting web to generating the synonyms using correlation analysis and after this symptoms are generated we are expanding the original list by those synonyms.",
                    "label": 1
                },
                {
                    "sent": "And at any extraction phrase, we just use some exact match method to extract entities.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is outline of my talk first or I will define formally defined problem.",
                    "label": 0
                },
                {
                    "sent": "Then we talk about algorithms to generate this synonyms and will show some experiment result and finally is ready to work and conclusions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to character.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned earlier, we have an function which is a synonym to characterize whether this subset is a synonym of originality or not, so basically want to computer a correlation score for this subset and entity pair.",
                    "label": 0
                },
                {
                    "sent": "So This is why we are using this to Baxter example throughout this presentation.",
                    "label": 0
                },
                {
                    "sent": "So here we found a document which mentions Roblox die, and in its context it's language.",
                    "label": 0
                },
                {
                    "sent": "Small window of this Roblox, die.",
                    "label": 0
                },
                {
                    "sent": "We found other tokens which also appear in the original entity.",
                    "label": 0
                },
                {
                    "sent": "So when we use some strong Jakarta Jakarta similarity to catch this correlation basically within the context, we look at the fraction or weighted sum of tokens in the context of this subset and which also appears in entity.",
                    "label": 1
                },
                {
                    "sent": "So when we get next document, we do the same thing.",
                    "label": 0
                },
                {
                    "sent": "And finally, we are aggregating all these scores and we're comparing with the threshold.",
                    "label": 0
                },
                {
                    "sent": "If the score is larger than some threshold with it synonym otherwise with it's not synonym.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to get a set of documents which related subset, we rely on web search.",
                    "label": 0
                },
                {
                    "sent": "For example, we for to study the back style, we send the Baxter as a query to search engine and retrieve toepke snaps as rate documents.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a flow of the function.",
                    "label": 0
                },
                {
                    "sent": "We called it synonym.",
                    "label": 0
                },
                {
                    "sent": "Basically it verifies whether subset S is a synonym of entity.",
                    "label": 1
                },
                {
                    "sent": "Another procedure is that it has four steps.",
                    "label": 1
                },
                {
                    "sent": "First issues as as a query to the web search and retrieve toepke snaps at rate documents.",
                    "label": 1
                },
                {
                    "sent": "The computer correlation score for each documents and finally aggregated scores and compare with the threshold.",
                    "label": 0
                },
                {
                    "sent": "So in the remaining of this talk, I will consider a cinema as an atomic operator.",
                    "label": 0
                },
                {
                    "sent": "And obviously this operator.",
                    "label": 0
                },
                {
                    "sent": "The cost of this operator is mainly on this web search cost, so we are trying to minimize the number of queries we sent to the search engine.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the problem.",
                    "label": 0
                },
                {
                    "sent": "Statements input is a set of entities and our web search API's output is that for each entity in this list, we want to find all subsets as whose correlation scores larger than a certain threshold.",
                    "label": 1
                },
                {
                    "sent": "And our objective is that we want to minimize the number of verifications.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll talk about the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, given an additive, all the subsets are possible candidates.",
                    "label": 0
                },
                {
                    "sent": "Here all the candidates from actual lattice structure.",
                    "label": 0
                },
                {
                    "sent": "So our algorithm rely on an assumption which will call a subset and subset monotonicity assumption basically.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just says if a subset is not a synonym or the other subset which is smaller than this subject is not a synonym.",
                    "label": 0
                },
                {
                    "sent": "For example, this Sony Vaio laptop is not a synonym of Sunnyvale F-150 laptop because there are many, many other models in this Sony Vaio series, and we conclude this subsets of this Sony Vaio laptop are not synonyms as well for numbers on evals on Laptop Dell laptop.",
                    "label": 1
                },
                {
                    "sent": "Sunnyvale and laptops.",
                    "label": 0
                },
                {
                    "sent": "Their owners anonymous.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, if we identify this, Sony F-150 is a synonym of surgeon entity, then all is super set within this lattice structure are also subsets also valid synonyms?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given this.",
                    "label": 0
                },
                {
                    "sent": "Assumption we can identify a frontier in this lattice structure.",
                    "label": 0
                },
                {
                    "sent": "Basically, the frontier consists of minimum synonyms and maximum non synonyms.",
                    "label": 0
                },
                {
                    "sent": "So all the remaining subsets in this latest lattice structure can be proved by our super set.",
                    "label": 0
                },
                {
                    "sent": "That assumption?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, uh, this frontier definition actually give us a hint on how to minimize the cost of verification.",
                    "label": 0
                },
                {
                    "sent": "Basically, we only need to verify the subsets in the frontier.",
                    "label": 1
                },
                {
                    "sent": "So let me use this oh PTEB, the number of the success, the number of successes in the frontier of it, I'm going to use this symbol in later on later slides.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because, uh, because before we very fast, but we don't know whether it's me or not.",
                    "label": 0
                },
                {
                    "sent": "Whether it's cinnamon, not cinnamon, so our tasks identify this, then identify the subsets in the frontier, and this is done by some greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "Basically, the flow of greedy algorithm that given this entity E, we enumerate all subsets which actually original form a lattice structure, and we subset a subset from this candidate space we verify it.",
                    "label": 1
                },
                {
                    "sent": "And after we know the status whether the system or not, we can prove the remaining subsets in this candidate space.",
                    "label": 0
                },
                {
                    "sent": "We continue this procedure until there's no success.",
                    "label": 0
                },
                {
                    "sent": "Life left in the candidates, so it stops.",
                    "label": 0
                },
                {
                    "sent": "So we have a few algorithms, all of them follow this.",
                    "label": 0
                },
                {
                    "sent": "Follow this framework.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first algorithm we called a single entity algorithm.",
                    "label": 0
                },
                {
                    "sent": "Basically we only look at we only German leverage information from one entity, and the way we select subset is using some depth first search.",
                    "label": 0
                },
                {
                    "sent": "It's very easy, so it's very simple, so we start from the root and pick the first one.",
                    "label": 0
                },
                {
                    "sent": "We verify it.",
                    "label": 0
                },
                {
                    "sent": "Here it is is a synonym and there's no subset of this Sony Vaio F-150.",
                    "label": 1
                },
                {
                    "sent": "In the latest there, no proving.",
                    "label": 0
                },
                {
                    "sent": "Next we get Sunnyvale.",
                    "label": 0
                },
                {
                    "sent": "It's not seen him and we can prove this Sony and Val by proving what I mean that there they can.",
                    "label": 0
                },
                {
                    "sent": "We do not need to verify them and we also know there not synonym.",
                    "label": 0
                },
                {
                    "sent": "So we continue this depth first search.",
                    "label": 0
                },
                {
                    "sent": "We found Sunny 105th Sunny F-150.",
                    "label": 0
                },
                {
                    "sent": "And the weekend we can also know that these two supersets are also synonyms, and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "So although this is a very simple algorithm, it has some nice property, so the number of allocations by depth first search that most E times opt in E means essentially the number of tokens in the entity.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a second algorithm we called Max Benefit algorithm at the different from the depth first search which follows lattice structure.",
                    "label": 0
                },
                {
                    "sent": "This one simultaneously consider all the subsets in the lattice.",
                    "label": 0
                },
                {
                    "sent": "For example, given the Sony 100F-150.",
                    "label": 0
                },
                {
                    "sent": "After verify this one, there are two possibilities.",
                    "label": 0
                },
                {
                    "sent": "This could be a synonym, could be an awesome if it is synonym then we can prove three other success in the lattice structure.",
                    "label": 0
                },
                {
                    "sent": "If it is not synonym we can prove to other.",
                    "label": 0
                },
                {
                    "sent": "Success in the lattice structure.",
                    "label": 0
                },
                {
                    "sent": "So because we don't know whether the synonym or not before we verify it, so we can use them.",
                    "label": 0
                },
                {
                    "sent": "Some aggregation function to estimate it.",
                    "label": 0
                },
                {
                    "sent": "Basically we can do aggressively, let's say Max between this true or false, or conservatively we can do mean between these truffles, or which stood average.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about multiple entity scheduling.",
                    "label": 0
                },
                {
                    "sent": "The intuition that if we have multiple entities, we can actually leverage the information structure similarity between these entities and give us better hint on whether it is a cinema, not the example that often we have product titles which is very similar to each other like a Sony Vaio One F-150 Sony Vaio P 5035 Thirty and Sony other laptops.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we already processed like say Sunnyvale F-150 laptop, we know the result of this this entity.",
                    "label": 0
                },
                {
                    "sent": "And when we process a new entity which is very similar to the previous one and we look at Sunnyvale P 5:30.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We may, we may.",
                    "label": 0
                },
                {
                    "sent": "The intuition that this is likely to be assigning becauses I the previous one, at the similar structure, one they the conclusions that Sony Vaio F-150 is a synonym.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So actually we the important thing is we need to catch the structural similarity between entities.",
                    "label": 0
                },
                {
                    "sent": "And this actually asked requires to enable one to one mapping between subsets across different entities.",
                    "label": 0
                },
                {
                    "sent": "So this basically has two requirements.",
                    "label": 0
                },
                {
                    "sent": "First, the entities must have the same number of tokens, so that have this they have same same.",
                    "label": 1
                },
                {
                    "sent": "Same structure of same lattice structure and the correspond tokens are either same token or tokens with common property.",
                    "label": 1
                },
                {
                    "sent": "So we can see this.",
                    "label": 0
                },
                {
                    "sent": "This appears that Maps to that subset has some kind of high confidence.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to do this kind of grouping we use, there are other ways to do this.",
                    "label": 0
                },
                {
                    "sent": "Grouping.",
                    "label": 0
                },
                {
                    "sent": "What we use is rule based mapping, so we typically will two types of rules when the regular expression, for example this this talk if this token contains the letter or number, which we says that number and we also do categorisation for number for their colors we just say that color.",
                    "label": 0
                },
                {
                    "sent": "So we apply these rules on entity names and entities with the same normalized name.",
                    "label": 1
                },
                {
                    "sent": "Summer group",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now, given their previous three Sony Vaio laptops, now we have the same normalized form, say LMS that number.",
                    "label": 1
                },
                {
                    "sent": "So they they form the same lattice structure and eat at each position.",
                    "label": 0
                },
                {
                    "sent": "Each subset position they are they are mapping to each other correspondingly.",
                    "label": 0
                },
                {
                    "sent": "Now given this group profile, we can accumulate statistics within the groups.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way we're committed status that for each subset we maintain 2 two counts, true or false.",
                    "label": 0
                },
                {
                    "sent": "She is number of entities which has been processed, and at this position at this subset it is a synonym for the number of entities which has been processed.",
                    "label": 1
                },
                {
                    "sent": "And this subset is not a synonym.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's go back to our previous I mentioned Max Benefit Search at Best Buy for Search.",
                    "label": 0
                },
                {
                    "sent": "We don't know whether this is a cinnamon not so we use some aggregation function to estimate the benefit.",
                    "label": 0
                },
                {
                    "sent": "Now, since we have some statics within the group, for example in this case, let's say Sony P536 is like a true.",
                    "label": 0
                },
                {
                    "sent": "The file forces forces one.",
                    "label": 0
                },
                {
                    "sent": "It's more likely to be assigning so instead of using this aggregation function, we just keep saying that this.",
                    "label": 0
                },
                {
                    "sent": "More likely to be true, and the benefit should be 3.",
                    "label": 0
                },
                {
                    "sent": "So we are still using the Max benefit framework, but the way we estimate the benefit is different.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we move to the experimenter's.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But so I'm going to show briefly to show 2 results in the experiments.",
                    "label": 0
                },
                {
                    "sent": "In the experiment, more details are in the paper, so data we are using that we use 100K product names from MSN shopping as real data consists of computer title, compare names, GPS cameras, bicycles shows, etc.",
                    "label": 1
                },
                {
                    "sent": "And the web search API we use is live search livesearch.com.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the first is the quality of synonyms.",
                    "label": 1
                },
                {
                    "sent": "We ask human experts to label some data for us, and this is the comparison between the correlation based measure with them with a popular stream based measure which is awaited color similarity and we vary the number of the value of threshold.",
                    "label": 1
                },
                {
                    "sent": "We got precision recall curve like this.",
                    "label": 0
                },
                {
                    "sent": "So as we can see from this graph the document correlation based measure.",
                    "label": 0
                },
                {
                    "sent": "Very good position.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And it's much better than the customer loyalty.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is a performance graph.",
                    "label": 0
                },
                {
                    "sent": "Basically we measure the number of verifications, that is the number of web searches we sent to live.com and the red line is the upper bound, which is a naive algorithm, which we do.",
                    "label": 1
                },
                {
                    "sent": "We do verification one by one, and green lines optimal solution, which basically we do we computed after we verify the entity.",
                    "label": 0
                },
                {
                    "sent": "So we can identify the frontier.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Among those oldest method we found the multiplicity is best, which is reasonable because we leveraging the information across different entities.",
                    "label": 0
                },
                {
                    "sent": "And that's for searches generated from better than the Max benefit search.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our work is, uh, is related to many other things, but the two main streams that we are our generated approximately matching in a lot of database work, basically approximate merging.",
                    "label": 0
                },
                {
                    "sent": "They match similarity based on strings, attribute values, link structures that we're looking at evidence from management documents and our calls also related to works in the RP community that they studied measures.",
                    "label": 1
                },
                {
                    "sent": "For distribution mathematics, the only difference that are automatic is similar to what they started in their community, but they do not consider the efficient computation.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, we have developed efficient method to generate synonyms for entities.",
                    "label": 1
                },
                {
                    "sent": "Those entities can be also used for, let's say a person match in anticipation in fuzzy matching data cleaning.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If I mean if I have time I would like to spend one minute to talk about the the project background from which we started to start to look at this problem.",
                    "label": 0
                },
                {
                    "sent": "So we have project query portal.",
                    "label": 0
                },
                {
                    "sent": "Basically our idea is that currently people are looking there are two separate searches going on for documents.",
                    "label": 0
                },
                {
                    "sent": "People using web search using Google yahooorlive.com to search documents and their other side that we have a lot of structure database.",
                    "label": 0
                },
                {
                    "sent": "And this data is different from what we have on the web and people have different ways to search this stretch data, such as using Amazon to search products using MDB to search movies actor actors.",
                    "label": 0
                },
                {
                    "sent": "But these two data are not related or not correlate to each other.",
                    "label": 0
                },
                {
                    "sent": "So what we are doing is that we want to build a relationship between this structure database and web documents and want to use this relationship to image search.",
                    "label": 0
                },
                {
                    "sent": "So in this for this purpose we need to identify the entities in structure database in the documents.",
                    "label": 0
                },
                {
                    "sent": "So we found this approach and match is really important.",
                    "label": 0
                },
                {
                    "sent": "So there's another talk in this conference, basically talking about the other big picture of this project, which is exploiting web search engine to search strategy based.",
                    "label": 1
                },
                {
                    "sent": "The talk will be presented by my colleague Contratti in this afternoon, and our project is you can use the search key to search Microsoft Research and exploration.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Is the underlying product database that you are trying to do this multi entity match?",
                    "label": 0
                },
                {
                    "sent": "Did you properly?",
                    "label": 0
                },
                {
                    "sent": "So is the underlying product database the the entity titles that you are trying to look to do a look up for all of them?",
                    "label": 0
                },
                {
                    "sent": "Is that deduped, yes.",
                    "label": 0
                },
                {
                    "sent": "So then it seems that.",
                    "label": 0
                },
                {
                    "sent": "For a lot of.",
                    "label": 0
                },
                {
                    "sent": "The non synonyms you could just infer the fact that it's not a synonym, but just looking at your own database.",
                    "label": 0
                },
                {
                    "sent": "So for example Sony Vaio laptop.",
                    "label": 0
                },
                {
                    "sent": "Yeah if you have 15 Sunnyvale letter number laptop in your own database, then it's pretty clear without the web search that it's not a synonym.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, I agree.",
                    "label": 0
                },
                {
                    "sent": "So you actually can use the frequency of this phrase to do some proving, so it's not easy to do plumbing first.",
                    "label": 0
                },
                {
                    "sent": "First, the reason that first the data is not very clean, they have duplicates.",
                    "label": 0
                },
                {
                    "sent": "So if you use frequently promise, likely knew I miss something and also some data are weird.",
                    "label": 0
                },
                {
                    "sent": "One example like in our data set we have like Apple Nano.",
                    "label": 0
                },
                {
                    "sent": "Apple, iPod nano and then another title called Apple Apple Nano Green.",
                    "label": 0
                },
                {
                    "sent": "So if you say that anything frequencies large equal to two, you can do not look at it.",
                    "label": 0
                },
                {
                    "sent": "For example, Apple Nano frequency tool you're going to miss this synonym because Apple Nano is a synonym of Apple.",
                    "label": 0
                },
                {
                    "sent": "Apple Nano right?",
                    "label": 0
                },
                {
                    "sent": "So I am saying that yes, you can do some slash proving.",
                    "label": 0
                },
                {
                    "sent": "Actually we did that we did not talk about it in stock, which is that, but you need to carefully control the threshold.",
                    "label": 0
                },
                {
                    "sent": "So I enjoyed the talk.",
                    "label": 0
                },
                {
                    "sent": "I thought it was very interesting, um.",
                    "label": 0
                },
                {
                    "sent": "There's there's a product called Xbox that Microsoft came out with a few years ago, and in the sequel was called Xbox 360.",
                    "label": 0
                },
                {
                    "sent": "And if you look in social media now, Xbox 360 is often referred to as Xbox, so there's a kind of a temporal problem here where a term, a synonym for a term Xbox 360 is ambiguous with another product that was just which was.",
                    "label": 0
                },
                {
                    "sent": "A subset of this term, but is not a.",
                    "label": 0
                },
                {
                    "sent": "It's not a synonym.",
                    "label": 0
                },
                {
                    "sent": "So, have you thought at all about temporal aspects of the data and how that?",
                    "label": 0
                },
                {
                    "sent": "Is implicated in in doing that kind of matching?",
                    "label": 0
                },
                {
                    "sent": "This is a good point.",
                    "label": 0
                },
                {
                    "sent": "We have not thought about this, so I guess that yeah, it probably will vary time by time, but not in very short period.",
                    "label": 0
                },
                {
                    "sent": "So I mean this is we consider this offline processing so if you do not need to do it on daily schedule right?",
                    "label": 0
                },
                {
                    "sent": "So probably you can scale it once a month.",
                    "label": 0
                },
                {
                    "sent": "I don't know, probably is good enough.",
                    "label": 0
                }
            ]
        }
    }
}