{
    "id": "dauh2frs2d2s3mhwfwvt56s5l2rtzv3s",
    "title": "Smooth Receiver Operating Characteristics Curves (smROC)",
    "info": {
        "author": [
            "William Klement, University of Ottawa"
        ],
        "published": "Oct. 10, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/solomon_klement_smroc/",
    "segmentation": [
        [
            "Thank you very much for coming to listen to me talk.",
            "I hope I'll provide you with a little bit of thought and food for thought.",
            "Thank you for the opportunity to come here and explain to you things that I've been working on for the past few years.",
            "Um, this joint work is technically the basis of my PhD thesis.",
            "This is just the foundation of it.",
            "There's more in the thesis than there is in the talk.",
            "But one thing I noticed of this work is that it actually provided more questions than answers, so there's plenty of applications, plenty of problems to deal with, and I'm hoping that we can.",
            "We can during this week of my visit.",
            "Here we can explore a little bit of these applications.",
            "So this work was done in conjunction with Peter Flack, Natalie Optivision, Stan, Matt, Win over the past three years and we have few publications stemming from it.",
            "Depending on the stage of research, this is the most recent.",
            "So the idea here is that fundamentally my research works on the premise that when we build a machine learning system, it's always difficult to try to assess its quality in terms of either performance and how we define performance, and most of I'm going to visit the approach to evaluation altogether.",
            "That's been followed in machine learning, and I'm going to point out certain missing bits that this research basically.",
            "Filzen"
        ],
        [
            "So just to give you an overall idea, the idea is to bring classification scores if you will into the aerospace.",
            "So to wait the arosi space based on these class membership scores and this would allow us to extend the arosi to cover problems that are beyond ranking.",
            "And I'll explain what that means.",
            "Will also it will also allow us to visualize individual scores in a 2 dimensional plot and the premise of this.",
            "Visualization is a combination between the performance of ranking, classification and scoring, and I'll tell you more details about what scoring means.",
            "So to begin with that, I'll actually examine the information available from the learning task to the performance assessment."
        ],
        [
            "Process, So what I'm going to do first is that I'm going to define an axis of information content, so this is information that you basically build a machine learning model, and you test it, you train it, then you test it or validate it, or do whatever you want with it.",
            "But the performance assessment is always limited by what the model tells you so."
        ],
        [
            "In the case of classification, the model only provides you with decisions.",
            "Usually their binary decisions in binary classification problems it's true or false, positive or negative.",
            "You also have a more."
        ],
        [
            "Convoluted notion of classification of ordinal classification where you have classes that subsume each other.",
            "Something like high risk, medium risk, moderate, or moderate risk, and then low risk, which means that if you get some sort of a decision in the high risk, then you already know it's greater than the other two classes, and that's what I mean by ordinal classes, but nonetheless the decision outcome of this model is a classification.",
            "It's basically yes or no to membership in a particular class.",
            "And then."
        ],
        [
            "You can add more complexity to it an ask for ranking ranking is basically determining an order.",
            "On instance is somewhere in between lies the boundary between the class, the positive class that you're interested in and the negative class, and the negative class could be a collection of classes so.",
            "These are the traditional classifiers that we've been working on.",
            "There is 1."
        ],
        [
            "And more complex, very complex.",
            "It's a totally on the other end type of learning where you no longer get a decision.",
            "You only get a probability estimation of class membership.",
            "So for each data point you get some sort of a probability of it belonging to a particular class, and on that end of the spectrum, there's plenty of statistical methods that actually can assess the quality of these probabilities and how well they map into the domain.",
            "Classes the problem over there is that most of the methods that apply statistical analysis to it.",
            "They either make assumption or they're very restrictive in terms of what it is you you can or cannot do in terms of performance assessment and what I'm actually trying to do is that I'm trying to take concepts that are used in the context of probability estimation and water them down a little bit to see."
        ],
        [
            "What I can do with scores in general scores that I'm looking at are scores that for some reason.",
            "They did not make it into probability, and it's very well known that sometimes you have a probabilistic model that produces probabilities, but they're not really a good estimate of probabilities.",
            "They're very poor and the perfect example would be naive based classifier.",
            "Naive Bayes classifier is a very good class classifier on the classification end of things, right, but discord that it produces are very poorly estimated, and the easiest way to check these things it's a check.",
            "The calibration of these scores.",
            "It's always poor as the naive Bayes estimates them, but if you take something like probability, estimating trees, probability estimating trees are decision trees that are unpruned and smooth.",
            "Those produce very good probability scores because what they actually do is that they smooth this course across the distribution and therefore they match what's called the convex Hull of the arosi and they give you calibrated scores and their viewed to be well behaved probabilities.",
            "But unfortunately they are not good for classification.",
            "There's plenty of research there, and I'm actually exploiting that fact in my experiments to show that I can actually do something interesting in the middle in the middle.",
            "What do we do?",
            "The problem the current state of affairs in terms of supervised learning is that when you have a scoring classifier, whether be it probabilities or not really doesn't matter.",
            "You have scores and based on those scores, you need to make a decision whether a given data point belongs to a given class or not, and what traditionally happens is that most people impose a classification threshold to determine what the decision is now that problem.",
            "That approach reduces the problem to a ranking right, and what happens is that I claimed that you're actually missing some information and the perfect example to illustrate that would be consider a threshold value of 0.5 and then you have two positive examples.",
            "One makes it at 52, the other one makes it at 99.",
            "In the view of ranking or classification, the view of classification, you cannot possibly tell the difference between these two points.",
            "They're equally positive they're both above the threshold and you know no further information.",
            "So when you go to do the performance assessment, they both look the same.",
            "You cannot distinguish between them, whereas if you look at the ranking, all you know is that one comes before the other.",
            "But how far above and how close to it?",
            "You really don't know, because you don't have the marginal distance between these two ranks.",
            "Yes, just.",
            "Rank into rank instances, but when you say scoring fewer ranking classes, is this correct?",
            "Scoring is a bit more than ranking he see.",
            "Ranking is just an order right with exactly so once yes, once you have once you have a score you can easily determine a rank.",
            "You just sort them and go from there.",
            "But this course tell you slightly more than just a rank.",
            "They may tell you about gaps in between, so the perfect example would be search engine's when you're looking for relevant documents, right?",
            "You may be interested in the fact that maybe the top 10 are separated by maybe 1%, but then there is a gap of 10% to the next guy.",
            "It would be natural to make that cut off there so that you can distinguish between clusters of relevant documents.",
            "Things that are more relevant than the others.",
            "With ranking you don't know that all you know is the order from the top, and that's why some people would impose the top end options, right.",
            "Scoring actually tells you that much more information at a higher resolution.",
            "And that's why I'm trying to exploit that in the perform."
        ],
        [
            "Assessment So what are the motivation?",
            "The idea here is that I will now.",
            "So one way of viewing these scores is that the classifier provides a score to tell you how confident it is in its prediction for a given data point, right?",
            "So the point that was classified as positive at 99% is far more confident.",
            "There is more confidence in it than the one at 52%, although both of them made it above the threshold.",
            "And I am using zero point.",
            "Five as an example here, which is the natural cut off for calibrated scores, right?",
            "If they're not calibrated, it's totally different story, but the idea here is that the classifier is telling me two things.",
            "It's telling me what the decision is and it's giving me some sort of a value of confidence right in the traditional arosi curve, this confidence is thrown away.",
            "It's only used to determine a ranking, and then it's ignored completely.",
            "So my aim here is to take that magnitude and bring it back.",
            "Into the arosi.",
            "Now you could easily argue that the arosi curves were developed.",
            "To ignore this particular aspect of scoring because they were designed to.",
            "Convey the performance of ranking that is very true, but it's also a plus for me.",
            "If you look at it the other way.",
            "I'm interested in this course while preserving the performance of ranking, so I can combine them together.",
            "What does that allow me to do?",
            "Well, it now allows me to visualize the margins of these scores.",
            "I can now compare visually.",
            "The differences of these scores I could look for gaps I look I could look for a change of behavior somewhere in the data points, and now if I may approach the same problem but from the other end.",
            "I'm no longer, maybe I'm not interested in the model itself.",
            "You see, traditionally, performance assessment is used to answer.",
            "One common question is that which of the models is the best performing models?",
            "So it's a model selection problem, right?",
            "Imagine you have a good model.",
            "Let's say we're not criticizing the model here, but what we're trying to ask is, how good are the data points, right?",
            "If I have data points that rank close to each other, how do I know that they are close to each other?",
            "Because they are indeed close to each other, or because I haven't observed anything in between them, right?",
            "And that relates to the method of sampling the data?",
            "How do you collect your samples?",
            "Do you really have?",
            "Is your data representative of the space between these two points, right?",
            "So in a sense that I'm now comparing the data points, not the models themselves, or maybe as well as the models themselves.",
            "So what I'm trying to say here is that I'm dealing with scores that are loosely defined.",
            "They're not as stringent and restrictive as probabilities because I'm trying to loosen up some assumptions here, right.",
            "Many models produce scores.",
            "In fact, if you take Wicca and you run it, it's by default the score is called class class membership probabilities.",
            "Although I can point out to half dozen models that are never were never designed to produce probabilities, but they call them probabilities anyways, but their poor probabilities, so now.",
            "I'm trying to address the poor probability estimation by using these scores."
        ],
        [
            "Application to this, the first one that is very intuitive is user preferences, especially when it involves two types of outcome.",
            "When you have a binary decision, Anna scored that goes along with it, or maybe assessing the rebalance the relevance.",
            "Of retrieve documents or retrieved results of a query in a search engine and also, Corina Cortez at ICML 07.",
            "I met up with her and she had an interesting learning problem.",
            "She had a learning problem where the outcome of the learning was no longer the decision but the order.",
            "She wanted to learn the distance between points in a given datasets.",
            "Not particularly the decision, so she wanted that you give this model of particular data set and it would produce exactly similar ordering to the training set, and in this case she had trouble evaluating it because we didn't have anything that is sensitive to the gaps or distances between points, and this was actually the perfect application port.",
            "Another thing also I'd like to somehow look backwards at the research we've been doing in machine learning.",
            "It's been very well documented that probability estimating trees are the the best probability estimating models that we have because they produce calibrated probabilities.",
            "Decision trees, on the other hand, are very poor at estimating probabilities because their pruned in the and they give you their very what's called refined.",
            "They give you close to zero and close to one and nothing in between.",
            "Naive Bayes is very well known to be an effective classifier, but a very poor probability estimator.",
            "This work has been done over the past 10 years.",
            "By hand labor, everybody had to.",
            "They notice this problem with these three models and they experimented with each one of them, and there's half a dozen documents papers illustrating this problem.",
            "The funny thing is that if this tool was available, all you had to do is run one experiment on the three of them, and he would have been able to visually see it right there, and we'll see that in my results.",
            "The other thing also I could apply this to is gene expression levels, where a given gene could be could be upregulated or downregulated at a particular intensity of expression.",
            "Basically this method requires that you have a binary decision and you have a continuous value score along with it, and the question is, do these two agree or not and that's what I tried."
        ],
        [
            "To convey, so, here's a simple example, right?",
            "So my niece and nephew decided to play with me, right?",
            "They got bored of me working all the time, so I decided to give them something interesting to play with.",
            "I gave them a collection of movies.",
            "Movies they like and I ask them.",
            "Two questions number one, do you recommend that I watch this movie yes or no and if so tell me how well not if so but tell me how much you like it on a scale from zero to 1010 being I like it very much.",
            "Zero I dislike it and The funny thing with this problem is that.",
            "She might, for just as an example, she might give me a particular movie and says don't watch it, but I'll give it a 60% score.",
            "I like it right?",
            "So the fact that she she made a negative recommendation may not necessarily correspond to the fact that she liked it or not.",
            "She may have a reason right.",
            "On the other hand, he comes in and he says watch this movie, but I really don't like it right now.",
            "My question is that do they agree or disagree?",
            "If we take their decisions alone, forget about the scores we see that they disagree, and the same thing, but in an opposite direction.",
            "Will say that she gave the same movie a higher score than he did.",
            "He gave it maybe a 52 instead of 60, right?",
            "And the question here is that, do they really disagree?",
            "My claim is that no, they don't disagree.",
            "They in fact they do agree in the fact that they say the movie is not really the greatest movie.",
            "But maybe you should watch it.",
            "Or maybe you shouldn't watch it right?",
            "So there is some sort of a hesitation that may be captured in the combination of the score and the decision, but not necessarily with each of them individually.",
            "So in this case.",
            "I go to Anna and I get her decision recommend, which is a positive or a negative recommendation and a particular score of how well she likes particular movie and this situation I was describing is instance three and four right.",
            "And then I plot a curve for what she says and then I plot a curve for what he says.",
            "And then I compared the two curves to see whether they are close to each other or not.",
            "In the aerospace, that picture does not arrive here at all.",
            "In fact, that picture would look almost identical for both of them.",
            "If they were somewhat in agreement, right, it'll say that they are.",
            "It won't tell gaps in between, so let's take one preference, hers.",
            "We have two positives followed by a negative, then a positive and then with two negatives in the aerospace.",
            "A positive is always indicated by a vertical line segment, right?",
            "So you can look at it from the Top Rank to the bottom rank as sequence of instances along the arrow seeker.",
            "The 1st two are positive, so they're very vertical, then followed by a negative and then positive and then two negatives.",
            "That's the way how you plot a narrow seeker.",
            "And The funny thing in the Roc is that because you have this negative and this positive, you really don't know much.",
            "So you connect the diagonal line at the 0.5 boundary because they're equal, there's one negative followed by 1 positive.",
            "So this shows you just the ranks right?",
            "Funny thing is that I can no longer tell the difference between one and two.",
            "Right?",
            "As far as the arosi curve is concerned, if I were to swap these two instances in a different rank, that would still look the same.",
            "Because I don't have the score, I don't know what that score looks like, even worse somewhere here where I conclude the 0.5 slope of I don't know assumes that this is 0.5 minutes is 0.5 there of equal weight.",
            "But if we look at them they actually have different scores.",
            "The scores are telling you something different about these two instances or these two instances.",
            "Then the Arosi does right?",
            "So this is what I call missing information from the ranking problem.",
            "The ranking problem only tells you the order of how they come.",
            "But it doesn't tell you about distances in between right?",
            "And it turns out that apparently Anna was more confident in that negative being a positive than the following positive right.",
            "She gave it a 60% score.",
            "Now we come to the smooth arosi.",
            "You'll notice that this first positive is not ready at one, so it's actually tilted a little bit, but the graph is not really that sensitive, but the following one at 70%.",
            "Now it's tilted a little more, and the idea here is that I actually take this core.",
            "And I wait, the slope of the associated line segment to the value of the score.",
            "That way you can step back and look at the curve and all of a sudden you realize, haha.",
            "I can distinguish between different points in the data set and where they sit.",
            "So this turns out to be nowhere nearly as positive as the score actually tells you.",
            "So in the smooth Roc space, vertical is very positive.",
            "Horizontal is very negative and anywhere in between is the value of this core.",
            "However, there is a particular problem with when you have Miss Franks.",
            "Miss ranks need to be corrected because the whole idea of performance assessment is that you have a ground truth in the form of the label and then you have a scored that comes along with it.",
            "A negative example like instance #3.",
            "We know it's a negative example because the label is a ground truth.",
            "Now I'm going back into the supervised learning notion where you have a label and you want you want to believe it, and you're trying to measure how good that score against it.",
            "We realize that a 60% positive class membership does not correspond to a negative label.",
            "That's actually an error, right?",
            "But where is the error of it?",
            "Is it a complete bad decision?",
            "Because that's what happens here.",
            "This scored as a false positive.",
            "Right, it said that the model gave you a false positive on this particular instance.",
            "It's not necessarily true because there's 40% of that score that is also negative, right?",
            "So the error happened on 60% of the full one of the score, right?",
            "Not as bad as the arosi would actually say, and this is what happens here is that.",
            "The tilt of the of the line segment is the inverse of that score, which is 1 minus the 60% by 40%, so it's 40% up and 60% down.",
            "That's why it appears to be more horizontal than it is vertical, right?",
            "So you have to swap the two because you're comparing to the ground truth.",
            "Now the beauty about this method here.",
            "Now I can compare the two of them together and it becomes totally subjective since I'm looking at things from an evaluation perspective, not from a model selection.",
            "Or model development perspective, I can take any binary decision and any score.",
            "And boom, I have a curve for it right now if I have multiple users, so let's say I have more people that are recommending these movies.",
            "All I have to do is throw up on the graph a whole bunch of curves, right, and then determine the set of instances the set of movies that they all agree on based on that plot and come back and say I have a clean set where they agree.",
            "Or maybe I will allow 10% tolerance differences between them or whatever I want to do.",
            "I can now select different subsets of instances where given models agree."
        ],
        [
            "So now that the under the hood, the actual method itself.",
            "To simplify things, let's let's go back to the problem of overlapping normal distributions.",
            "Now, the first thing I need to emphasize here is that I have a set of positives and negatives that overlap.",
            "If they do not overlap, then they're separable, and then I can go home.",
            "There is no need to do anything here, right?",
            "The question is what happens when you have errors when you have issues in between, right?",
            "So what I'm trying to define here?",
            "The letters L&H refer to particular score.",
            "Whether the score is high or low, how do we decide?",
            "High and low is by that green line in the middle somewhere, right?",
            "And I say somewhere, just because in the picture everything is balanced nice and they intersect at a given point.",
            "And let's assume we can find that boundary based on that boundary everything to the to your right of that boundary will be a high score.",
            "Everything to the left of that boundary is a low score, right?",
            "However, because the two distributions overlap, we have a subset of the positives.",
            "That are sitting on this side of the boundary and we have a subset of the negatives that sit on that side of the boundary, and those in a sense are false positives and those are false negatives, right?",
            "And the question here is that we want to reason within these scores and these decisions, right?",
            "The label is the ground truth, but it doesn't necessarily have to be.",
            "As I learned last couple of days.",
            "So I will define the set of high scores.",
            "Assign to positive labels and the set of low scores assigned to negative instances.",
            "To be what's called appropriate scores.",
            "Those are good scores, because apparently the score and the label agree, because that's what we want.",
            "We want positives to have higher scores than negatives, right?",
            "And that's the magnitude that I'll use as the score assigned to these.",
            "Another set, which is the complementary set.",
            "The N appropriate score is when you have a negative example that has a high score or a positive example that has a low score, and these I will consider as.",
            "Inappropriate score and when I go to actually deal with them, I will take the inverse of their value and this is the scoring value that I'll use to plot.",
            "So this is the weighing ratio now.",
            "In the context of of some of your work here, I. I came up with this interesting classifier that would detect outliers and it turns out if you have an outlier in the red or blue zones, right?",
            "That's what's called a trivial outlier.",
            "I would consider it as an error, for example, but if you have something in the middle that's a more difficult point, so.",
            "Take this graph and traverse it horizontally.",
            "And think of the top two sets as the set of trivial examples.",
            "Those are the easy positives and the easy negatives because they have high scores and low scores.",
            "If the model.",
            "Makes any misclassifications there.",
            "I think it should be penalized very heavily.",
            "Because those are obvious points that should be, it's no brainer.",
            "You should be able to get them, but somewhere in the middle lies the complexity of this.",
            "Problem in this domain when you have the overlap, those are the points that are interesting right now?",
            "What happens if the model actually classifieds correctly in the middle?",
            "It should be given bonus points because it's actually doing well its fixing some of the problems in the domain because those are difficult points to deal with, right?",
            "So what I actually would propose in the context of the detecting outliers is that outliers lie in the middle.",
            "That's where the problems will happen.",
            "You'll either have a wrong label or wrong score somewhere in between, right?",
            "The fact that so errors in a domain when you apply a particular algorithm to it will stem from 2 problems.",
            "Either you have the right score, but you somehow had a threshold value that somehow caused a misclassification, or you have a good classification threshold, but you have a wrong score assigned above or below on the opposite side of the label, right?",
            "And that's where most of the errors lie in there."
        ],
        [
            "So mechanics of it I start with one contingency table based on this midpoint.",
            "So I derive that midpoint, the vertical line and I look at the scores only first and these scores will divide into pretty much four sets, high scores that are assigned positive positive labels, or the other way around positive instances that are assigned high scores and negative instances that are assigned low scores.",
            "Those are good scores, those are appropriate scores.",
            "Whereas positives are assigned low scores or negatives that are assigned high scores, those are inappropriate and for each of the two, the yes or no.",
            "No, I will build a contingency table separately.",
            "I will deal with the two sets differently and it's just the inverse of the other right.",
            "I'll look in the correctness of them when you have high positive low negative.",
            "There correct when you have yes or no predicted yes or no at the very end of course.",
            "Of the testing cycle, or if it's high positive and predicted Azano low positive negative and predicted as a yes.",
            "If I get this right.",
            "And of course you do the inverse of that.",
            "So looking at that accuracy you can actually visualize it, right?",
            "So let's forget about the normalization right?",
            "And they are OC space, you normalized by the number of positives on the vertical axis and the number of negatives on the horizontal axis.",
            "Let's ignore the.",
            "Normalization, because it's a bit convoluted here, but I'll come back to it and let's look at the score itself.",
            "So if I have a positive instance and it has an appropriate score, that means SI is bigger than 1 -- S I, that's why the vertical rise is bigger than it is running on the horizontal axis, right?",
            "The same thing happens with the negative instance that has an appropriate score.",
            "It has a smaller score than one minus that score, right?",
            "So visually.",
            "I can now plot these two, the inverse of that happens to the inappropriate score, where I have a positive instance that I know has an inappropriate score.",
            "So I use the 1 -- S I as a vertical climb and run by SI and the inverse of that for negative instance.",
            "Is this clear?",
            "This is basically the hardest bit of it."
        ],
        [
            "Up until you see the equations right.",
            "So the reason I have all of this math in there is just to summarize everything in terms of a formula.",
            "These building a system like this takes no more than 10 minutes.",
            "I just redid it yesterday because I had platform issues.",
            "I rewrote it completely.",
            "It's basically these four or five formulas that you need.",
            "Determining the midpoint, and that's the vertical line and I'll come back to this little later because that's actually a big issue.",
            "The vertical climb, which is the true positive rate, or the smooth true positive rate.",
            "Basically you take the appropriate score assignment divided by some sort of a normalizing factor, and the same thing for the false positive rate.",
            "It's the inverse of that which is coded in the function itself by a horizontal normalization factor.",
            "Now the normalization factor.",
            "I know it looks big and ugly here.",
            "But think about it for appropriate scores going up the contribution happens from the SI for positives and the 1 -- S I for the negatives.",
            "Right?"
        ],
        [
            "Back in the previous slide, so for the appropriate ones, this is the vertical contribution.",
            "The horizontal contribution.",
            "Is this right?",
            "So now you see regardless whether it's positive or negative, they all make vertical contribution some bigger than others, and they all make horizontal contribution.",
            "So the curve always goes up and goes over and this is what allows me to determine that slope based on how positive it is.",
            "Right, this is a major distinction between the smoother OC and the regular arosi, because the regular arrow see only positives go up and only negatives rundown, right?"
        ],
        [
            "So if you look at it, there's the set of positives that have high scores.",
            "The set of negatives that have low scores, the set of positives that have low scores, the set of negatives that have high scores right?",
            "And basically it's a cipher.",
            "These 1 -- S I for those right the inverse of that happens on the horizontal run, so you just tally those and that will give you the normalization factor required.",
            "WHI is it required is to keep the two dimensional picture?",
            "Any unit square, right?",
            "Because you want it from zero to 1 zero to one.",
            "You could get rid of that, and I do believe there is an equivalent graph for it done by Peter Flack and it called.",
            "It's called the NP graph, where instead of normalizing between zero and one, you simply visualize the true positive rate and the false positive rate over the number of positives and the negatives.",
            "So you just for each one you go one step up and you don't normalize it right?",
            "But then it becomes a rectangle, not.",
            "A square it's only square if and only if you have the same number of pop."
        ],
        [
            "It is said negatives you could do the same thing here and simplify all of this and get rid of it if you want.",
            "Right now we come to the area under the smooth arosi curve.",
            "If I just quickly restate the definition of the AUC, the area under the standard arosi curve shows you the separation between the two classes and it's defined as the probability of picking a random positive point and see how many negatives are below it, right?",
            "So it shows you the probability of randomly selected positive example being ranked higher than a randomly selected negatives.",
            "So what does that mean in English and natural language?",
            "What does it mean when you have when you calculate the area under the arosi curve basically shows you how the positives are separated from the negatives, right?",
            "It gives you a probability of this particular model in along this curve to separate the positives from the negatives WHI, because along the Y axis you have contributions from only the positives along the X axis.",
            "You have contributions only from the negatives, so the area in between is the separation between the two.",
            "Right here we have a different problem.",
            "We actually have contribution from positives and negatives here and positives and negatives here.",
            "So then you ask, wait a minute?",
            "Then how do you interpret this area under the curve?",
            "Well, if you remember.",
            "The vertical rise of every instance was how positive that particular instance was according to its label.",
            "Right, this was an appropriate score, whereas this was inappropriate score.",
            "So basically the separation between the two shows you how well the model separates the good scores from the bad scores, whether it be positive or negative.",
            "Who cares, right?",
            "In essence, I actually can compare now any point to any point in the data set based on its score, and that is a major distinction between the two.",
            "Which leads me to.",
            "Interpret this naturally in reverse order is that imagine you have a model.",
            "And you build this curve and you get the area under this under the smooth arosi curve and you go back and you say what does it mean?",
            "It actually means how you take a model.",
            "And you hope you assume that the model is OK and you go back and sample your data according to the model you're biasing the model because you're taking the scores and you're saying I'll fix these scores.",
            "I'll take these labels and see how well they agree.",
            "So you're sampling the data based on how good the model is.",
            "Which also brings an interesting weakness of this approach.",
            "You could call it a weakness.",
            "I don't think it's a weakness.",
            "I think it's just irrelevant.",
            "Is the fact that if you have a perfect classifier, this model will collapse.",
            "Because I will have no."
        ],
        [
            "Intersection in between.",
            "If I have a perfect clean division between the two, I have nothing to separate.",
            "The whole visual graph that I'm actually plotting is the separation between the appropriate ones, the ones on the top and this overlap in the middle right, and that's why.",
            "Imagine if you're trying to do outlier detection an.",
            "In a domain where there are no outliers, you basically get no results right.",
            "On the other hand, you could also inverse the same situation by having a system that only gives you outliers absolutely no good points, and the same thing that if I have something that."
        ],
        [
            "Totally random, that is no good.",
            "Then this will collapse again.",
            "So either boundary is a problem.",
            "I need something good to work with and something bad to assess."
        ],
        [
            "So the experiment.",
            "For the experiments.",
            "I want it to show.",
            "That this method will detect similarities when similarities are present and will also measure differences when differences are present right?",
            "And I wanted to compare it to this standard arosi to show that I actually have a gain over the arosi there is that extra information that I capture from this course.",
            "So the first task was how do I produce similarities and how do I make up these differences?",
            "So one approach would be to use synthetic data generators right?",
            "This experiment?",
            "I didn't, I don't have it here, but it's in the thesis.",
            "I did that for something else.",
            "But then I wanted to keep this natural, so I went and I got a whole bunch of data sets.",
            "And then I came back and I thought, wait a minute similarities, you could actually produce similarities if you apply the same model on different subsets of the domain.",
            "Assuming that the data comes from the same domain, you get subsamples of it applied the same model to it within some random variations you should get the same answer right?",
            "It should be similar.",
            "So if I build a decision tree on a model.",
            "On a data set, a subset from a given domain, I build a decision tree and then I build a second one from a different subset from the same domain.",
            "Given that the domain hasn't changed, these two should give me pretty much the same performance, right?",
            "And that's what similarity is.",
            "So if I take a really huge data set, subsample 40% of it.",
            "Train and test and do it again and do it again and do it again and do it again.",
            "The assumption here is that these models eventually will look similar, right?",
            "They have to look similar, otherwise nothing will be good right?",
            "The same thing if I took fundamentally two different algorithms that are known to be different.",
            "Apply them to the same data set.",
            "I should see these differences right now given that I have these differences, I'll see how they pan out given my performance assessment.",
            "So I took twenty data 26 UCI datasets from the machine learning repository.",
            "And I use two models.",
            "I used probability estimating trees and I used naive base.",
            "The reason I use these two is that they are so different from each other, they're both classifiers.",
            "They both produce what so called probabilities.",
            "One is known to produce poor probabilities that are not calibrated.",
            "The other one is known to produce very calibrated probabilities, right?",
            "And I use them to determine similarities and differences.",
            "Now when it comes to similarities, I'm not using both of them together.",
            "I leave one aside.",
            "I use the same model over whole bunch of runs on each of the datasets and then I see how close the curves are when I compare the two to each other.",
            "Exactly the same run.",
            "But to compare two different models.",
            "Then I should have differences.",
            "I did this in using 10 fold cross validation repeated 10 times just to make sure I get all of the averages.",
            "And then I. I basically took the approach is that the same learning model applied to the same data drawn from the domain should produce similarities, whereas different models applied to the same data set should produce differences right?",
            "And I recorded the area under both of the curves.",
            "The problem is that here you can imagine repeated experiments.",
            "Each of them is a curve in the two dimensional space.",
            "It's very difficult to sit down and try to compare each one of them that would have made the thesis this big.",
            "I would say so.",
            "One way of summarizing the whole curve is to take the area under it.",
            "So I took the area under the arosi curve and I took the area under the smooth arosi curve and I compared them in the thesis.",
            "I actually have examples where the curves are available."
        ],
        [
            "So here's what I have.",
            "Similarities, so taking probability, estimating tree and I apply it to all of these datasets and I record the standard deviations of the area under the curve and the standard deviation and the average of that area under the curve.",
            "The blue color is the standard Roc and the red color is the smooth arosi, the one that we came up with.",
            "The first observation I have is that as the standard deviation increases across the data set for one given model.",
            "The smooth arosi gives less deviation than the standard one.",
            "This does make sense if you think about it, because a given point is determined to be above or below this threshold in the standard arosi irrelevant of its distance.",
            "So if you repeat the experiment and this point shows up sometimes here, sometimes there sometimes here the arosi is crude is too rigid, so it generates higher standard deviation in the area then the smooth.",
            "Because this month is more close to each other, chances are that line associated with a given point did not really move too much right?",
            "It's close to each other and we see that even the area under the curve itself.",
            "Is also less than that is in the standard Roc and you ask why?"
        ],
        [
            "I would bring you back to very interesting notion here.",
            "Just visually speaking.",
            "Look at the blue curve and look at the red one.",
            "Wouldn't you say that the red one is some sort of a smoothing?",
            "Of the blue one, it's making it smoother because it's taking all of those hard turns.",
            "Out of it and making them into some sort of slope right so that."
        ],
        [
            "Is an expected piece of results, and in fact it.",
            "It shows that our assumption of similarity actually is captured much better in this mood.",
            "Our OC curve, then it doesn't.",
            "The standard arrow seeker.",
            "Basically the standard error was C curve will give you differences between models that are not necessarily in the model themselves.",
            "It's just due to plotting problems.",
            "And this again if you want to interpret it.",
            "It's the problem with ranking.",
            "If you're using ranking you have no distances between points, but if you use scoring you consider this course you have distances."
        ],
        [
            "So I have another experiment with naive base alone, but I didn't have it here because I had less time to talk, but I have exactly the same results from naive base alone, so I did them separately.",
            "But when I put them together, oh, I have it here.",
            "Well, there you go, surprise, surprise.",
            "Again, exactly the same thing.",
            "The standard deviation in the smooth arosi space is a lot less, with two exceptions here that the area under the curve in this smooth Roc is actually higher.",
            "For two datasets.",
            "You see where the curve the red curve goes above the blue curve in the bottom graph.",
            "Now you step back and you ask the question why?",
            "Can you guess?",
            "Which is the other way.",
            "Smoothing the other way, but is that really smoothing?",
            "So in statistics, that actually means something.",
            "It's the concept of having a calibrated system being refined.",
            "And what does that mean?",
            "In statistics, they assume calibration to examine refinement.",
            "The idea of refinement is that when you estimate probabilities to datapoints, positives and negatives, you want them to be the positives clustered higher towards one and the negatives towards 0.",
            "So if you have that kind of separation that's called a refined system, and in these two datasets, if you look at the curves, I don't have them here, but I can show them to you if you want.",
            "The system is actually very refined.",
            "So it turns out that it has a vertical rise followed by an horizontal run with which is the smoothing the other way, right?",
            "And that's naive.",
            "Based naive based does that very frequently because it gives higher.",
            "Scores to the positives than it does to the negatives.",
            "That's why it's an effective classifier you draw at 0.5 and guess what?",
            "You will have very nice classification results.",
            "However, these scores are not necessarily as good, they're actually smoother.",
            "The arosi cannot tell you that the Arosi will show you the general estimated view of smoothness, but it won't give you sensitivity to scores, and that's where it was very obvious.",
            "Now."
        ],
        [
            "If you consider the two together, you will see their differences with a really interesting piece of results at the end.",
            "So in the bottom graph I have the zero difference between 90 base and probability estimating tree and the idea here is that I'm trying to determine whether the difference in the AUC between the two models is in favor of naive Bayes above or.",
            "Probability estimating tree below.",
            "So above that zero line naive base model has a higher AUC then probability estimating tree below it.",
            "It's the other way around.",
            "Now the interesting thing is when naive base wins the game, apparently the arosi cannot detect it because it keeps going up and down around the zero.",
            "The smooth arosi sees it very well because it's sensitive to this refinement notion.",
            "Of this course, whereas the interesting bit of results is that when probability estimating tree actually comes close to the same classification as Naive Bayes, the two of them sit hand in hand.",
            "What does that tell you?",
            "It tells you that when probability estimating trees produce good classification, you'll also have very good scores.",
            "But when you have good classification from naive base alone, then these scores are not good there.",
            "Poor right?",
            "And that basically is the story that.",
            "People have been trying to tell in the past 10 years when they examined the two, you could see it all in one plot here in one experiment and again the standard deviation.",
            "Of course, we already explained that one right.",
            "So basically we can."
        ],
        [
            "Conclude with this is that the smooth arosi curve is more sensitive to this course assigned to the to the data point then the Roc, which is by now obvious.",
            "It's more sensitive to performance similarities and differences because we basically increase the resolution of performance assessment.",
            "We now can actually look inside the square that the arosi cannot look inside.",
            "The Arosi has a point on one end of the square and the other end of the square, and somehow it guesses the connection between them.",
            "We don't.",
            "We actually have a slope in between and that's added knowledge which extends the whole method.",
            "For similarities.",
            "The smooth arosi this moves AUC actually produces lower standard deviation and better area under the curve.",
            "The question that I omitted so far is the midpoint, right?",
            "What happens with this point?",
            "How do I get the midpoint?",
            "Well, it turns out that if you really think about it when you have labels, the boundary between positives and negatives is very clear.",
            "You have a plus and minus right line is right there, but when you have scores, I'm not sure that's so obvious, right?",
            "There is a special case of scores when you have calibrated scores.",
            "It's natural to take 0.5, so if you have the distribution between them calibrated to the data points then you look for the 0.5 and the peaks of the two distributions will actually match.",
            "You get it there and everything is fine, but we all know in reality nothing is calibrated.",
            "You always work with a subsample of a population that you're not even sure if it's truly representative.",
            "Or not, of what happens in there?",
            "So how do we calculate that and now?"
        ],
        [
            "To go back to this issue, which I am open to suggestions as to how I find it so far."
        ],
        [
            "I'll tell you what I'm doing.",
            "What I'm doing is actually very simple.",
            "M is the average score, M Plus is the average score on the positive instances, and M minus is the average score on an.",
            "I waited by CC is the class distribution.",
            "So when I have a balanced data set that C is 1 and I basically take the average, the average find the midpoint and boom there it is, right?",
            "If it's imbalanced, I just shifted over to the side based on the imbalance of the data set.",
            "This seems to be intuitive.",
            "It works most of the time, but."
        ],
        [
            "What I didn't show you in the in the picture here is that I actually drew perfectly nice equal symmetric type of distributions.",
            "What if I had this?",
            "What if I had this one wider than the other?",
            "Right, well, the class distribution will actually account for this, but this is the headache, right?",
            "So imagine all of the negative scores being clustered over close values with a subset of those that are very sparse away from it.",
            "What do you do at that point?",
            "Well, I can tell you that I've tried that and in some cases that midpoint collapses, because mathematically you can produce a set of scores for which that green line is actually over on this side.",
            "It has to sit somewhere in between them.",
            "If it doesn't sit in between, I have a serious problem.",
            "Intersection of these kind of some kind of distribution graphs like here you have intersection between these two curves.",
            "If I didn't have intersection then I have nothing to analyze right?",
            "So I just go home.",
            "I don't play with it at all right?",
            "I need that could be the midpoint.",
            "The midpoint could be outside the intersection and that's the whole problem.",
            "It's even worse.",
            "It could be outside both distributions, right?",
            "Because I'm taking the average now.",
            "The suggestion I have so far in which I would like to try.",
            "Is taking the median instead of the average right?",
            "The median might give me a good position for the midpoint, however I am actually exploring other ways of calculating this midpoint because as you can imagine that this assignment of appropriate versus inappropriate score is very sensitive to where you put this point, right?",
            "So you want this point to be as good as possible, so the next approach I would like to try.",
            "Is to learn this midpoint.",
            "So imagine I had a high-quality data set from a distribution.",
            "Right, that has scores in it and from there I can estimate the midpoint.",
            "Once I do this front, I get my midpoint and I toss away everything I learn.",
            "I just keep the midpoint and then I build the model that I want and apply the midpoint to it.",
            "So the idea is that can I learn this midpoint somewhere in between, which could be doable for appropriate type of domains?",
            "Other than that, I could run a validation phase where I do training and I have another holdout set from the training over which I actually determine the midpoint, take that midpoint and apply it into testing.",
            "So that's another approach, and of course they're all at this point here.",
            "Open ended.",
            "We can do whatever we want with it.",
            "Another thing which I don't have in this presentation here.",
            "The reason is because I want to write another paper about it.",
            "Is that if you step back a little bit, I think Paul Bennett wrote a technical report talking about the problem he was dealing with.",
            "Misclassification costs right and one of the things that they came across is that the probability estimation for a given domain is usually sensitive by this midpoint, where the overlap is right and the funny part is that if you build a model on this distribution, you sample data from these two.",
            "With this given midpoint.",
            "And then somehow sometime later you could test it and these two shift things change.",
            "They go apart if they go apart you're safe because the midpoint still sits in between.",
            "But this midpoint is sensitive to changes in this domain, which actually tells you that my entire approach could be very sensitive to changes in underlying domain.",
            "Right, and this turns out to be very beneficial in detecting changes in data distributions, so now we're not evaluating the model.",
            "We take a snapshot of the problem we're trying to solve now and take another snapshot Snapshot 20 years later, see if things changed.",
            "Right when things change in the domain, presumably the model that you trained at that point is no longer good.",
            "Right, so it turns out that we have an extra advantage in this smooth arosi curve is that it's sensitive to changes in the underlying domain, which means that curve will change based on differences between training and testing.",
            "So now I step aside and I tell you those who are interested in assessing the quality of data.",
            "Imagine you have multiple samples from the domain and you want to verify that indeed.",
            "You have the same thing.",
            "Right, you can build curves for it and see if they match.",
            "If they don't match, it could be likely that the samples conveyed different views of the domain and maybe a mixture of those would be ideal for training.",
            "So can you identify a subsample of a domain appropriate for training and model at this point?",
            "And this is work that hasn't been done yet.",
            "So yeah, the future is busy.",
            "Let's put it this way and thank you very much for putting up with me.",
            "I think I'm finished.",
            "Questions.",
            "You are dealing with all these things.",
            "You probably know how easy and how stable how, what's the quality of computing probabilities out of scores actually.",
            "So you have a classifier introduces scores.",
            "So Transgenesis somehow SVM, for example.",
            "Now let's say that you have a next component which wants as input once probabilities.",
            "How difficult is it to?",
            "MAP scores into probabilities so that they still so that they make sense.",
            "Or is this like impossible?"
        ],
        [
            "Quote.",
            "That's actually very easy, surprisingly easy.",
            "Pathetically easy, I would say.",
            "See there is an interesting thing.",
            "If you if you go back to the aerospace, the aerospace aerospace has this concept of the arosi convex Hull.",
            "Anne Peter Flack did a lot of work on repairing what's called King cavities.",
            "This is akin cavity into the arosi and you repair it.",
            "In his case, you swap the two right and you effectively fix the ranking.",
            "Swap the two who cares about the scores were not using them anyways and you get a nicely convex curve and theoretically speaking, if you take the convex Hull, it turns out that the slope of the line segment is actually the likelihood of that particular instance being a member in that class.",
            "So all you have to do is repair concavities along the arosi.",
            "Read off the value of those scores and you've got a set of calibrated probabilities as well.",
            "In fact, in a narrow space, if you want to tell how far off a given model is from calibration, you draw the convex Hull and you see the gap between them, right?",
            "So getting those likelihoods is no problem.",
            "However, there is a problem.",
            "Imagine you did have a convex curve.",
            "You are not guaranteed that this particular.",
            "Convexity is actually related to the score.",
            "It may be an over estimate or underestimate in the aerospace.",
            "Same now how to do this on a Golden stand up on a Labor Day, yes.",
            "I mean how do they transfer this to the test?",
            "Oh, you you learn it on the training set and you apply it on the test set.",
            "That's the trick.",
            "And you applied, and that's where the over and underestimation will actually happen is because the arosi over there gives you way too much leeway.",
            "The slope is free to go based on equal weights or whatever the number of observations you have.",
            "Yes, I'm talking about the usual RC.",
            "As soon as I go into mine the magnitude of that problem is significantly reduced because of the resolution of the score.",
            "All I would have to do to get you see the convex Hull for this curve would be here.",
            "I'm barely off calibration, I'm not too far off calibration, whereas this one it's off here, it's off there and it's off there right?",
            "So this if you were to calibrate it would actually give you perfect, so this course you would read likelihood scores you would read out of this convex Hull.",
            "Would be 1 one 0.500 right?",
            "Whereas here the values you would read are actually closer to what you get.",
            "In this scoring, so this is more sensitive to the model itself than this one.",
            "They'll both give you a calibrated scores.",
            "However, having said that, there is a very interesting observation I made there an I have no idea what it means yet I know why.",
            "I know its effect, I can reproduce it and it makes sense.",
            "But what it means, I still don't know.",
            "See.",
            "Look at the decision.",
            "I have three positives and three negatives, right?",
            "And unfortunately, Oh no, this is a beautiful example actually.",
            "If you were to calibrate these scores.",
            "It's natural to take 0.5 as a cutoff point between negatives and positives, right?",
            "That's what calibration gives you.",
            "It fixes the midpoint and distributes the data points around it.",
            "If I were to take 0.5 over there, I actually end up with four positives and two negatives.",
            "Because that 0.51 is above is just above.",
            "And what happens here?",
            "I have a discrepancy in the class distribution between the two criteria if you will label says three and three scores, says four and two.",
            "Visually, this produces a slight rotation when you go to calibrate.",
            "I don't know what it means and I just confessed it.",
            "It makes sense because the distribution of scores is totally different than the distribution of labels, right?",
            "But by the time you calibrate them, the effect of calibration on my curve is actually a very significant piece of work, because once I figure out why this rotation is there, it would be very interesting to solve and I can tell you that when you're dealing with changes in the underlying domain, you get a lot of rotations.",
            "Because the balance changes.",
            "That's how they are.",
            "OC detects changes in data distributions.",
            "Is that you sampled it at 10 out of 100 and then you sample it again at 30 out of 100 over there is class imbalance, but they are.",
            "OC is actually very practical at ignoring these things because the decreasing diagonal is the balanced data set.",
            "Anything below it you have more negatives than positives.",
            "Anything above it you have more positives than negatives.",
            "So the idea is that you draw this an you just figure out for my given balance which point on the arosi should I use?",
            "Those are called the operating points on the RC curve, right?",
            "Over here it's not so obvious because this.",
            "Decreasing diagonal is now the balance between appropriate and inappropriate.",
            "Because remember, the separation is appropriate.",
            "Scores versus inappropriate scores and appropriate scores go across both sets.",
            "The positives and the negatives and the same thing happens on the on the X axes, so the balance between them is what causes that rotation.",
            "It makes perfect sense mathematically, theoretically, an visually, but what does it really mean when you go back to performance assessment?",
            "You have an idea, please tell me."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for coming to listen to me talk.",
                    "label": 0
                },
                {
                    "sent": "I hope I'll provide you with a little bit of thought and food for thought.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the opportunity to come here and explain to you things that I've been working on for the past few years.",
                    "label": 0
                },
                {
                    "sent": "Um, this joint work is technically the basis of my PhD thesis.",
                    "label": 0
                },
                {
                    "sent": "This is just the foundation of it.",
                    "label": 0
                },
                {
                    "sent": "There's more in the thesis than there is in the talk.",
                    "label": 0
                },
                {
                    "sent": "But one thing I noticed of this work is that it actually provided more questions than answers, so there's plenty of applications, plenty of problems to deal with, and I'm hoping that we can.",
                    "label": 0
                },
                {
                    "sent": "We can during this week of my visit.",
                    "label": 0
                },
                {
                    "sent": "Here we can explore a little bit of these applications.",
                    "label": 0
                },
                {
                    "sent": "So this work was done in conjunction with Peter Flack, Natalie Optivision, Stan, Matt, Win over the past three years and we have few publications stemming from it.",
                    "label": 0
                },
                {
                    "sent": "Depending on the stage of research, this is the most recent.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that fundamentally my research works on the premise that when we build a machine learning system, it's always difficult to try to assess its quality in terms of either performance and how we define performance, and most of I'm going to visit the approach to evaluation altogether.",
                    "label": 0
                },
                {
                    "sent": "That's been followed in machine learning, and I'm going to point out certain missing bits that this research basically.",
                    "label": 0
                },
                {
                    "sent": "Filzen",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to give you an overall idea, the idea is to bring classification scores if you will into the aerospace.",
                    "label": 0
                },
                {
                    "sent": "So to wait the arosi space based on these class membership scores and this would allow us to extend the arosi to cover problems that are beyond ranking.",
                    "label": 0
                },
                {
                    "sent": "And I'll explain what that means.",
                    "label": 0
                },
                {
                    "sent": "Will also it will also allow us to visualize individual scores in a 2 dimensional plot and the premise of this.",
                    "label": 1
                },
                {
                    "sent": "Visualization is a combination between the performance of ranking, classification and scoring, and I'll tell you more details about what scoring means.",
                    "label": 1
                },
                {
                    "sent": "So to begin with that, I'll actually examine the information available from the learning task to the performance assessment.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Process, So what I'm going to do first is that I'm going to define an axis of information content, so this is information that you basically build a machine learning model, and you test it, you train it, then you test it or validate it, or do whatever you want with it.",
                    "label": 0
                },
                {
                    "sent": "But the performance assessment is always limited by what the model tells you so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the case of classification, the model only provides you with decisions.",
                    "label": 0
                },
                {
                    "sent": "Usually their binary decisions in binary classification problems it's true or false, positive or negative.",
                    "label": 0
                },
                {
                    "sent": "You also have a more.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convoluted notion of classification of ordinal classification where you have classes that subsume each other.",
                    "label": 1
                },
                {
                    "sent": "Something like high risk, medium risk, moderate, or moderate risk, and then low risk, which means that if you get some sort of a decision in the high risk, then you already know it's greater than the other two classes, and that's what I mean by ordinal classes, but nonetheless the decision outcome of this model is a classification.",
                    "label": 0
                },
                {
                    "sent": "It's basically yes or no to membership in a particular class.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can add more complexity to it an ask for ranking ranking is basically determining an order.",
                    "label": 1
                },
                {
                    "sent": "On instance is somewhere in between lies the boundary between the class, the positive class that you're interested in and the negative class, and the negative class could be a collection of classes so.",
                    "label": 0
                },
                {
                    "sent": "These are the traditional classifiers that we've been working on.",
                    "label": 0
                },
                {
                    "sent": "There is 1.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And more complex, very complex.",
                    "label": 0
                },
                {
                    "sent": "It's a totally on the other end type of learning where you no longer get a decision.",
                    "label": 0
                },
                {
                    "sent": "You only get a probability estimation of class membership.",
                    "label": 1
                },
                {
                    "sent": "So for each data point you get some sort of a probability of it belonging to a particular class, and on that end of the spectrum, there's plenty of statistical methods that actually can assess the quality of these probabilities and how well they map into the domain.",
                    "label": 0
                },
                {
                    "sent": "Classes the problem over there is that most of the methods that apply statistical analysis to it.",
                    "label": 0
                },
                {
                    "sent": "They either make assumption or they're very restrictive in terms of what it is you you can or cannot do in terms of performance assessment and what I'm actually trying to do is that I'm trying to take concepts that are used in the context of probability estimation and water them down a little bit to see.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What I can do with scores in general scores that I'm looking at are scores that for some reason.",
                    "label": 0
                },
                {
                    "sent": "They did not make it into probability, and it's very well known that sometimes you have a probabilistic model that produces probabilities, but they're not really a good estimate of probabilities.",
                    "label": 0
                },
                {
                    "sent": "They're very poor and the perfect example would be naive based classifier.",
                    "label": 0
                },
                {
                    "sent": "Naive Bayes classifier is a very good class classifier on the classification end of things, right, but discord that it produces are very poorly estimated, and the easiest way to check these things it's a check.",
                    "label": 0
                },
                {
                    "sent": "The calibration of these scores.",
                    "label": 0
                },
                {
                    "sent": "It's always poor as the naive Bayes estimates them, but if you take something like probability, estimating trees, probability estimating trees are decision trees that are unpruned and smooth.",
                    "label": 0
                },
                {
                    "sent": "Those produce very good probability scores because what they actually do is that they smooth this course across the distribution and therefore they match what's called the convex Hull of the arosi and they give you calibrated scores and their viewed to be well behaved probabilities.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately they are not good for classification.",
                    "label": 0
                },
                {
                    "sent": "There's plenty of research there, and I'm actually exploiting that fact in my experiments to show that I can actually do something interesting in the middle in the middle.",
                    "label": 0
                },
                {
                    "sent": "What do we do?",
                    "label": 0
                },
                {
                    "sent": "The problem the current state of affairs in terms of supervised learning is that when you have a scoring classifier, whether be it probabilities or not really doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "You have scores and based on those scores, you need to make a decision whether a given data point belongs to a given class or not, and what traditionally happens is that most people impose a classification threshold to determine what the decision is now that problem.",
                    "label": 0
                },
                {
                    "sent": "That approach reduces the problem to a ranking right, and what happens is that I claimed that you're actually missing some information and the perfect example to illustrate that would be consider a threshold value of 0.5 and then you have two positive examples.",
                    "label": 1
                },
                {
                    "sent": "One makes it at 52, the other one makes it at 99.",
                    "label": 0
                },
                {
                    "sent": "In the view of ranking or classification, the view of classification, you cannot possibly tell the difference between these two points.",
                    "label": 0
                },
                {
                    "sent": "They're equally positive they're both above the threshold and you know no further information.",
                    "label": 0
                },
                {
                    "sent": "So when you go to do the performance assessment, they both look the same.",
                    "label": 0
                },
                {
                    "sent": "You cannot distinguish between them, whereas if you look at the ranking, all you know is that one comes before the other.",
                    "label": 0
                },
                {
                    "sent": "But how far above and how close to it?",
                    "label": 0
                },
                {
                    "sent": "You really don't know, because you don't have the marginal distance between these two ranks.",
                    "label": 0
                },
                {
                    "sent": "Yes, just.",
                    "label": 0
                },
                {
                    "sent": "Rank into rank instances, but when you say scoring fewer ranking classes, is this correct?",
                    "label": 0
                },
                {
                    "sent": "Scoring is a bit more than ranking he see.",
                    "label": 1
                },
                {
                    "sent": "Ranking is just an order right with exactly so once yes, once you have once you have a score you can easily determine a rank.",
                    "label": 0
                },
                {
                    "sent": "You just sort them and go from there.",
                    "label": 0
                },
                {
                    "sent": "But this course tell you slightly more than just a rank.",
                    "label": 0
                },
                {
                    "sent": "They may tell you about gaps in between, so the perfect example would be search engine's when you're looking for relevant documents, right?",
                    "label": 0
                },
                {
                    "sent": "You may be interested in the fact that maybe the top 10 are separated by maybe 1%, but then there is a gap of 10% to the next guy.",
                    "label": 0
                },
                {
                    "sent": "It would be natural to make that cut off there so that you can distinguish between clusters of relevant documents.",
                    "label": 0
                },
                {
                    "sent": "Things that are more relevant than the others.",
                    "label": 0
                },
                {
                    "sent": "With ranking you don't know that all you know is the order from the top, and that's why some people would impose the top end options, right.",
                    "label": 0
                },
                {
                    "sent": "Scoring actually tells you that much more information at a higher resolution.",
                    "label": 0
                },
                {
                    "sent": "And that's why I'm trying to exploit that in the perform.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assessment So what are the motivation?",
                    "label": 0
                },
                {
                    "sent": "The idea here is that I will now.",
                    "label": 0
                },
                {
                    "sent": "So one way of viewing these scores is that the classifier provides a score to tell you how confident it is in its prediction for a given data point, right?",
                    "label": 0
                },
                {
                    "sent": "So the point that was classified as positive at 99% is far more confident.",
                    "label": 0
                },
                {
                    "sent": "There is more confidence in it than the one at 52%, although both of them made it above the threshold.",
                    "label": 0
                },
                {
                    "sent": "And I am using zero point.",
                    "label": 0
                },
                {
                    "sent": "Five as an example here, which is the natural cut off for calibrated scores, right?",
                    "label": 0
                },
                {
                    "sent": "If they're not calibrated, it's totally different story, but the idea here is that the classifier is telling me two things.",
                    "label": 0
                },
                {
                    "sent": "It's telling me what the decision is and it's giving me some sort of a value of confidence right in the traditional arosi curve, this confidence is thrown away.",
                    "label": 0
                },
                {
                    "sent": "It's only used to determine a ranking, and then it's ignored completely.",
                    "label": 1
                },
                {
                    "sent": "So my aim here is to take that magnitude and bring it back.",
                    "label": 0
                },
                {
                    "sent": "Into the arosi.",
                    "label": 0
                },
                {
                    "sent": "Now you could easily argue that the arosi curves were developed.",
                    "label": 0
                },
                {
                    "sent": "To ignore this particular aspect of scoring because they were designed to.",
                    "label": 0
                },
                {
                    "sent": "Convey the performance of ranking that is very true, but it's also a plus for me.",
                    "label": 0
                },
                {
                    "sent": "If you look at it the other way.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in this course while preserving the performance of ranking, so I can combine them together.",
                    "label": 0
                },
                {
                    "sent": "What does that allow me to do?",
                    "label": 0
                },
                {
                    "sent": "Well, it now allows me to visualize the margins of these scores.",
                    "label": 1
                },
                {
                    "sent": "I can now compare visually.",
                    "label": 0
                },
                {
                    "sent": "The differences of these scores I could look for gaps I look I could look for a change of behavior somewhere in the data points, and now if I may approach the same problem but from the other end.",
                    "label": 0
                },
                {
                    "sent": "I'm no longer, maybe I'm not interested in the model itself.",
                    "label": 0
                },
                {
                    "sent": "You see, traditionally, performance assessment is used to answer.",
                    "label": 0
                },
                {
                    "sent": "One common question is that which of the models is the best performing models?",
                    "label": 0
                },
                {
                    "sent": "So it's a model selection problem, right?",
                    "label": 0
                },
                {
                    "sent": "Imagine you have a good model.",
                    "label": 0
                },
                {
                    "sent": "Let's say we're not criticizing the model here, but what we're trying to ask is, how good are the data points, right?",
                    "label": 0
                },
                {
                    "sent": "If I have data points that rank close to each other, how do I know that they are close to each other?",
                    "label": 0
                },
                {
                    "sent": "Because they are indeed close to each other, or because I haven't observed anything in between them, right?",
                    "label": 0
                },
                {
                    "sent": "And that relates to the method of sampling the data?",
                    "label": 0
                },
                {
                    "sent": "How do you collect your samples?",
                    "label": 0
                },
                {
                    "sent": "Do you really have?",
                    "label": 0
                },
                {
                    "sent": "Is your data representative of the space between these two points, right?",
                    "label": 0
                },
                {
                    "sent": "So in a sense that I'm now comparing the data points, not the models themselves, or maybe as well as the models themselves.",
                    "label": 0
                },
                {
                    "sent": "So what I'm trying to say here is that I'm dealing with scores that are loosely defined.",
                    "label": 0
                },
                {
                    "sent": "They're not as stringent and restrictive as probabilities because I'm trying to loosen up some assumptions here, right.",
                    "label": 0
                },
                {
                    "sent": "Many models produce scores.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you take Wicca and you run it, it's by default the score is called class class membership probabilities.",
                    "label": 0
                },
                {
                    "sent": "Although I can point out to half dozen models that are never were never designed to produce probabilities, but they call them probabilities anyways, but their poor probabilities, so now.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to address the poor probability estimation by using these scores.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Application to this, the first one that is very intuitive is user preferences, especially when it involves two types of outcome.",
                    "label": 0
                },
                {
                    "sent": "When you have a binary decision, Anna scored that goes along with it, or maybe assessing the rebalance the relevance.",
                    "label": 0
                },
                {
                    "sent": "Of retrieve documents or retrieved results of a query in a search engine and also, Corina Cortez at ICML 07.",
                    "label": 0
                },
                {
                    "sent": "I met up with her and she had an interesting learning problem.",
                    "label": 0
                },
                {
                    "sent": "She had a learning problem where the outcome of the learning was no longer the decision but the order.",
                    "label": 0
                },
                {
                    "sent": "She wanted to learn the distance between points in a given datasets.",
                    "label": 0
                },
                {
                    "sent": "Not particularly the decision, so she wanted that you give this model of particular data set and it would produce exactly similar ordering to the training set, and in this case she had trouble evaluating it because we didn't have anything that is sensitive to the gaps or distances between points, and this was actually the perfect application port.",
                    "label": 0
                },
                {
                    "sent": "Another thing also I'd like to somehow look backwards at the research we've been doing in machine learning.",
                    "label": 0
                },
                {
                    "sent": "It's been very well documented that probability estimating trees are the the best probability estimating models that we have because they produce calibrated probabilities.",
                    "label": 0
                },
                {
                    "sent": "Decision trees, on the other hand, are very poor at estimating probabilities because their pruned in the and they give you their very what's called refined.",
                    "label": 0
                },
                {
                    "sent": "They give you close to zero and close to one and nothing in between.",
                    "label": 0
                },
                {
                    "sent": "Naive Bayes is very well known to be an effective classifier, but a very poor probability estimator.",
                    "label": 0
                },
                {
                    "sent": "This work has been done over the past 10 years.",
                    "label": 0
                },
                {
                    "sent": "By hand labor, everybody had to.",
                    "label": 0
                },
                {
                    "sent": "They notice this problem with these three models and they experimented with each one of them, and there's half a dozen documents papers illustrating this problem.",
                    "label": 0
                },
                {
                    "sent": "The funny thing is that if this tool was available, all you had to do is run one experiment on the three of them, and he would have been able to visually see it right there, and we'll see that in my results.",
                    "label": 0
                },
                {
                    "sent": "The other thing also I could apply this to is gene expression levels, where a given gene could be could be upregulated or downregulated at a particular intensity of expression.",
                    "label": 0
                },
                {
                    "sent": "Basically this method requires that you have a binary decision and you have a continuous value score along with it, and the question is, do these two agree or not and that's what I tried.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To convey, so, here's a simple example, right?",
                    "label": 0
                },
                {
                    "sent": "So my niece and nephew decided to play with me, right?",
                    "label": 0
                },
                {
                    "sent": "They got bored of me working all the time, so I decided to give them something interesting to play with.",
                    "label": 0
                },
                {
                    "sent": "I gave them a collection of movies.",
                    "label": 0
                },
                {
                    "sent": "Movies they like and I ask them.",
                    "label": 0
                },
                {
                    "sent": "Two questions number one, do you recommend that I watch this movie yes or no and if so tell me how well not if so but tell me how much you like it on a scale from zero to 1010 being I like it very much.",
                    "label": 0
                },
                {
                    "sent": "Zero I dislike it and The funny thing with this problem is that.",
                    "label": 0
                },
                {
                    "sent": "She might, for just as an example, she might give me a particular movie and says don't watch it, but I'll give it a 60% score.",
                    "label": 1
                },
                {
                    "sent": "I like it right?",
                    "label": 0
                },
                {
                    "sent": "So the fact that she she made a negative recommendation may not necessarily correspond to the fact that she liked it or not.",
                    "label": 0
                },
                {
                    "sent": "She may have a reason right.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, he comes in and he says watch this movie, but I really don't like it right now.",
                    "label": 0
                },
                {
                    "sent": "My question is that do they agree or disagree?",
                    "label": 0
                },
                {
                    "sent": "If we take their decisions alone, forget about the scores we see that they disagree, and the same thing, but in an opposite direction.",
                    "label": 0
                },
                {
                    "sent": "Will say that she gave the same movie a higher score than he did.",
                    "label": 0
                },
                {
                    "sent": "He gave it maybe a 52 instead of 60, right?",
                    "label": 0
                },
                {
                    "sent": "And the question here is that, do they really disagree?",
                    "label": 0
                },
                {
                    "sent": "My claim is that no, they don't disagree.",
                    "label": 0
                },
                {
                    "sent": "They in fact they do agree in the fact that they say the movie is not really the greatest movie.",
                    "label": 0
                },
                {
                    "sent": "But maybe you should watch it.",
                    "label": 0
                },
                {
                    "sent": "Or maybe you shouldn't watch it right?",
                    "label": 0
                },
                {
                    "sent": "So there is some sort of a hesitation that may be captured in the combination of the score and the decision, but not necessarily with each of them individually.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "I go to Anna and I get her decision recommend, which is a positive or a negative recommendation and a particular score of how well she likes particular movie and this situation I was describing is instance three and four right.",
                    "label": 0
                },
                {
                    "sent": "And then I plot a curve for what she says and then I plot a curve for what he says.",
                    "label": 0
                },
                {
                    "sent": "And then I compared the two curves to see whether they are close to each other or not.",
                    "label": 0
                },
                {
                    "sent": "In the aerospace, that picture does not arrive here at all.",
                    "label": 0
                },
                {
                    "sent": "In fact, that picture would look almost identical for both of them.",
                    "label": 0
                },
                {
                    "sent": "If they were somewhat in agreement, right, it'll say that they are.",
                    "label": 0
                },
                {
                    "sent": "It won't tell gaps in between, so let's take one preference, hers.",
                    "label": 0
                },
                {
                    "sent": "We have two positives followed by a negative, then a positive and then with two negatives in the aerospace.",
                    "label": 0
                },
                {
                    "sent": "A positive is always indicated by a vertical line segment, right?",
                    "label": 0
                },
                {
                    "sent": "So you can look at it from the Top Rank to the bottom rank as sequence of instances along the arrow seeker.",
                    "label": 0
                },
                {
                    "sent": "The 1st two are positive, so they're very vertical, then followed by a negative and then positive and then two negatives.",
                    "label": 0
                },
                {
                    "sent": "That's the way how you plot a narrow seeker.",
                    "label": 0
                },
                {
                    "sent": "And The funny thing in the Roc is that because you have this negative and this positive, you really don't know much.",
                    "label": 0
                },
                {
                    "sent": "So you connect the diagonal line at the 0.5 boundary because they're equal, there's one negative followed by 1 positive.",
                    "label": 0
                },
                {
                    "sent": "So this shows you just the ranks right?",
                    "label": 0
                },
                {
                    "sent": "Funny thing is that I can no longer tell the difference between one and two.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "As far as the arosi curve is concerned, if I were to swap these two instances in a different rank, that would still look the same.",
                    "label": 0
                },
                {
                    "sent": "Because I don't have the score, I don't know what that score looks like, even worse somewhere here where I conclude the 0.5 slope of I don't know assumes that this is 0.5 minutes is 0.5 there of equal weight.",
                    "label": 0
                },
                {
                    "sent": "But if we look at them they actually have different scores.",
                    "label": 0
                },
                {
                    "sent": "The scores are telling you something different about these two instances or these two instances.",
                    "label": 0
                },
                {
                    "sent": "Then the Arosi does right?",
                    "label": 0
                },
                {
                    "sent": "So this is what I call missing information from the ranking problem.",
                    "label": 0
                },
                {
                    "sent": "The ranking problem only tells you the order of how they come.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't tell you about distances in between right?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that apparently Anna was more confident in that negative being a positive than the following positive right.",
                    "label": 0
                },
                {
                    "sent": "She gave it a 60% score.",
                    "label": 0
                },
                {
                    "sent": "Now we come to the smooth arosi.",
                    "label": 0
                },
                {
                    "sent": "You'll notice that this first positive is not ready at one, so it's actually tilted a little bit, but the graph is not really that sensitive, but the following one at 70%.",
                    "label": 0
                },
                {
                    "sent": "Now it's tilted a little more, and the idea here is that I actually take this core.",
                    "label": 0
                },
                {
                    "sent": "And I wait, the slope of the associated line segment to the value of the score.",
                    "label": 0
                },
                {
                    "sent": "That way you can step back and look at the curve and all of a sudden you realize, haha.",
                    "label": 0
                },
                {
                    "sent": "I can distinguish between different points in the data set and where they sit.",
                    "label": 0
                },
                {
                    "sent": "So this turns out to be nowhere nearly as positive as the score actually tells you.",
                    "label": 0
                },
                {
                    "sent": "So in the smooth Roc space, vertical is very positive.",
                    "label": 0
                },
                {
                    "sent": "Horizontal is very negative and anywhere in between is the value of this core.",
                    "label": 0
                },
                {
                    "sent": "However, there is a particular problem with when you have Miss Franks.",
                    "label": 0
                },
                {
                    "sent": "Miss ranks need to be corrected because the whole idea of performance assessment is that you have a ground truth in the form of the label and then you have a scored that comes along with it.",
                    "label": 0
                },
                {
                    "sent": "A negative example like instance #3.",
                    "label": 0
                },
                {
                    "sent": "We know it's a negative example because the label is a ground truth.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going back into the supervised learning notion where you have a label and you want you want to believe it, and you're trying to measure how good that score against it.",
                    "label": 0
                },
                {
                    "sent": "We realize that a 60% positive class membership does not correspond to a negative label.",
                    "label": 0
                },
                {
                    "sent": "That's actually an error, right?",
                    "label": 0
                },
                {
                    "sent": "But where is the error of it?",
                    "label": 0
                },
                {
                    "sent": "Is it a complete bad decision?",
                    "label": 0
                },
                {
                    "sent": "Because that's what happens here.",
                    "label": 0
                },
                {
                    "sent": "This scored as a false positive.",
                    "label": 0
                },
                {
                    "sent": "Right, it said that the model gave you a false positive on this particular instance.",
                    "label": 0
                },
                {
                    "sent": "It's not necessarily true because there's 40% of that score that is also negative, right?",
                    "label": 0
                },
                {
                    "sent": "So the error happened on 60% of the full one of the score, right?",
                    "label": 0
                },
                {
                    "sent": "Not as bad as the arosi would actually say, and this is what happens here is that.",
                    "label": 0
                },
                {
                    "sent": "The tilt of the of the line segment is the inverse of that score, which is 1 minus the 60% by 40%, so it's 40% up and 60% down.",
                    "label": 0
                },
                {
                    "sent": "That's why it appears to be more horizontal than it is vertical, right?",
                    "label": 0
                },
                {
                    "sent": "So you have to swap the two because you're comparing to the ground truth.",
                    "label": 0
                },
                {
                    "sent": "Now the beauty about this method here.",
                    "label": 0
                },
                {
                    "sent": "Now I can compare the two of them together and it becomes totally subjective since I'm looking at things from an evaluation perspective, not from a model selection.",
                    "label": 0
                },
                {
                    "sent": "Or model development perspective, I can take any binary decision and any score.",
                    "label": 0
                },
                {
                    "sent": "And boom, I have a curve for it right now if I have multiple users, so let's say I have more people that are recommending these movies.",
                    "label": 0
                },
                {
                    "sent": "All I have to do is throw up on the graph a whole bunch of curves, right, and then determine the set of instances the set of movies that they all agree on based on that plot and come back and say I have a clean set where they agree.",
                    "label": 0
                },
                {
                    "sent": "Or maybe I will allow 10% tolerance differences between them or whatever I want to do.",
                    "label": 0
                },
                {
                    "sent": "I can now select different subsets of instances where given models agree.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now that the under the hood, the actual method itself.",
                    "label": 0
                },
                {
                    "sent": "To simplify things, let's let's go back to the problem of overlapping normal distributions.",
                    "label": 0
                },
                {
                    "sent": "Now, the first thing I need to emphasize here is that I have a set of positives and negatives that overlap.",
                    "label": 0
                },
                {
                    "sent": "If they do not overlap, then they're separable, and then I can go home.",
                    "label": 0
                },
                {
                    "sent": "There is no need to do anything here, right?",
                    "label": 0
                },
                {
                    "sent": "The question is what happens when you have errors when you have issues in between, right?",
                    "label": 0
                },
                {
                    "sent": "So what I'm trying to define here?",
                    "label": 0
                },
                {
                    "sent": "The letters L&H refer to particular score.",
                    "label": 0
                },
                {
                    "sent": "Whether the score is high or low, how do we decide?",
                    "label": 0
                },
                {
                    "sent": "High and low is by that green line in the middle somewhere, right?",
                    "label": 0
                },
                {
                    "sent": "And I say somewhere, just because in the picture everything is balanced nice and they intersect at a given point.",
                    "label": 0
                },
                {
                    "sent": "And let's assume we can find that boundary based on that boundary everything to the to your right of that boundary will be a high score.",
                    "label": 0
                },
                {
                    "sent": "Everything to the left of that boundary is a low score, right?",
                    "label": 0
                },
                {
                    "sent": "However, because the two distributions overlap, we have a subset of the positives.",
                    "label": 0
                },
                {
                    "sent": "That are sitting on this side of the boundary and we have a subset of the negatives that sit on that side of the boundary, and those in a sense are false positives and those are false negatives, right?",
                    "label": 0
                },
                {
                    "sent": "And the question here is that we want to reason within these scores and these decisions, right?",
                    "label": 0
                },
                {
                    "sent": "The label is the ground truth, but it doesn't necessarily have to be.",
                    "label": 0
                },
                {
                    "sent": "As I learned last couple of days.",
                    "label": 0
                },
                {
                    "sent": "So I will define the set of high scores.",
                    "label": 0
                },
                {
                    "sent": "Assign to positive labels and the set of low scores assigned to negative instances.",
                    "label": 0
                },
                {
                    "sent": "To be what's called appropriate scores.",
                    "label": 0
                },
                {
                    "sent": "Those are good scores, because apparently the score and the label agree, because that's what we want.",
                    "label": 0
                },
                {
                    "sent": "We want positives to have higher scores than negatives, right?",
                    "label": 0
                },
                {
                    "sent": "And that's the magnitude that I'll use as the score assigned to these.",
                    "label": 0
                },
                {
                    "sent": "Another set, which is the complementary set.",
                    "label": 0
                },
                {
                    "sent": "The N appropriate score is when you have a negative example that has a high score or a positive example that has a low score, and these I will consider as.",
                    "label": 0
                },
                {
                    "sent": "Inappropriate score and when I go to actually deal with them, I will take the inverse of their value and this is the scoring value that I'll use to plot.",
                    "label": 0
                },
                {
                    "sent": "So this is the weighing ratio now.",
                    "label": 0
                },
                {
                    "sent": "In the context of of some of your work here, I. I came up with this interesting classifier that would detect outliers and it turns out if you have an outlier in the red or blue zones, right?",
                    "label": 0
                },
                {
                    "sent": "That's what's called a trivial outlier.",
                    "label": 0
                },
                {
                    "sent": "I would consider it as an error, for example, but if you have something in the middle that's a more difficult point, so.",
                    "label": 0
                },
                {
                    "sent": "Take this graph and traverse it horizontally.",
                    "label": 0
                },
                {
                    "sent": "And think of the top two sets as the set of trivial examples.",
                    "label": 0
                },
                {
                    "sent": "Those are the easy positives and the easy negatives because they have high scores and low scores.",
                    "label": 0
                },
                {
                    "sent": "If the model.",
                    "label": 0
                },
                {
                    "sent": "Makes any misclassifications there.",
                    "label": 0
                },
                {
                    "sent": "I think it should be penalized very heavily.",
                    "label": 0
                },
                {
                    "sent": "Because those are obvious points that should be, it's no brainer.",
                    "label": 0
                },
                {
                    "sent": "You should be able to get them, but somewhere in the middle lies the complexity of this.",
                    "label": 0
                },
                {
                    "sent": "Problem in this domain when you have the overlap, those are the points that are interesting right now?",
                    "label": 0
                },
                {
                    "sent": "What happens if the model actually classifieds correctly in the middle?",
                    "label": 0
                },
                {
                    "sent": "It should be given bonus points because it's actually doing well its fixing some of the problems in the domain because those are difficult points to deal with, right?",
                    "label": 0
                },
                {
                    "sent": "So what I actually would propose in the context of the detecting outliers is that outliers lie in the middle.",
                    "label": 0
                },
                {
                    "sent": "That's where the problems will happen.",
                    "label": 0
                },
                {
                    "sent": "You'll either have a wrong label or wrong score somewhere in between, right?",
                    "label": 0
                },
                {
                    "sent": "The fact that so errors in a domain when you apply a particular algorithm to it will stem from 2 problems.",
                    "label": 0
                },
                {
                    "sent": "Either you have the right score, but you somehow had a threshold value that somehow caused a misclassification, or you have a good classification threshold, but you have a wrong score assigned above or below on the opposite side of the label, right?",
                    "label": 0
                },
                {
                    "sent": "And that's where most of the errors lie in there.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So mechanics of it I start with one contingency table based on this midpoint.",
                    "label": 0
                },
                {
                    "sent": "So I derive that midpoint, the vertical line and I look at the scores only first and these scores will divide into pretty much four sets, high scores that are assigned positive positive labels, or the other way around positive instances that are assigned high scores and negative instances that are assigned low scores.",
                    "label": 0
                },
                {
                    "sent": "Those are good scores, those are appropriate scores.",
                    "label": 0
                },
                {
                    "sent": "Whereas positives are assigned low scores or negatives that are assigned high scores, those are inappropriate and for each of the two, the yes or no.",
                    "label": 0
                },
                {
                    "sent": "No, I will build a contingency table separately.",
                    "label": 0
                },
                {
                    "sent": "I will deal with the two sets differently and it's just the inverse of the other right.",
                    "label": 0
                },
                {
                    "sent": "I'll look in the correctness of them when you have high positive low negative.",
                    "label": 0
                },
                {
                    "sent": "There correct when you have yes or no predicted yes or no at the very end of course.",
                    "label": 0
                },
                {
                    "sent": "Of the testing cycle, or if it's high positive and predicted Azano low positive negative and predicted as a yes.",
                    "label": 0
                },
                {
                    "sent": "If I get this right.",
                    "label": 0
                },
                {
                    "sent": "And of course you do the inverse of that.",
                    "label": 0
                },
                {
                    "sent": "So looking at that accuracy you can actually visualize it, right?",
                    "label": 0
                },
                {
                    "sent": "So let's forget about the normalization right?",
                    "label": 0
                },
                {
                    "sent": "And they are OC space, you normalized by the number of positives on the vertical axis and the number of negatives on the horizontal axis.",
                    "label": 0
                },
                {
                    "sent": "Let's ignore the.",
                    "label": 0
                },
                {
                    "sent": "Normalization, because it's a bit convoluted here, but I'll come back to it and let's look at the score itself.",
                    "label": 0
                },
                {
                    "sent": "So if I have a positive instance and it has an appropriate score, that means SI is bigger than 1 -- S I, that's why the vertical rise is bigger than it is running on the horizontal axis, right?",
                    "label": 0
                },
                {
                    "sent": "The same thing happens with the negative instance that has an appropriate score.",
                    "label": 0
                },
                {
                    "sent": "It has a smaller score than one minus that score, right?",
                    "label": 0
                },
                {
                    "sent": "So visually.",
                    "label": 0
                },
                {
                    "sent": "I can now plot these two, the inverse of that happens to the inappropriate score, where I have a positive instance that I know has an inappropriate score.",
                    "label": 0
                },
                {
                    "sent": "So I use the 1 -- S I as a vertical climb and run by SI and the inverse of that for negative instance.",
                    "label": 0
                },
                {
                    "sent": "Is this clear?",
                    "label": 0
                },
                {
                    "sent": "This is basically the hardest bit of it.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up until you see the equations right.",
                    "label": 0
                },
                {
                    "sent": "So the reason I have all of this math in there is just to summarize everything in terms of a formula.",
                    "label": 0
                },
                {
                    "sent": "These building a system like this takes no more than 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "I just redid it yesterday because I had platform issues.",
                    "label": 0
                },
                {
                    "sent": "I rewrote it completely.",
                    "label": 0
                },
                {
                    "sent": "It's basically these four or five formulas that you need.",
                    "label": 0
                },
                {
                    "sent": "Determining the midpoint, and that's the vertical line and I'll come back to this little later because that's actually a big issue.",
                    "label": 0
                },
                {
                    "sent": "The vertical climb, which is the true positive rate, or the smooth true positive rate.",
                    "label": 0
                },
                {
                    "sent": "Basically you take the appropriate score assignment divided by some sort of a normalizing factor, and the same thing for the false positive rate.",
                    "label": 0
                },
                {
                    "sent": "It's the inverse of that which is coded in the function itself by a horizontal normalization factor.",
                    "label": 0
                },
                {
                    "sent": "Now the normalization factor.",
                    "label": 0
                },
                {
                    "sent": "I know it looks big and ugly here.",
                    "label": 0
                },
                {
                    "sent": "But think about it for appropriate scores going up the contribution happens from the SI for positives and the 1 -- S I for the negatives.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back in the previous slide, so for the appropriate ones, this is the vertical contribution.",
                    "label": 0
                },
                {
                    "sent": "The horizontal contribution.",
                    "label": 0
                },
                {
                    "sent": "Is this right?",
                    "label": 0
                },
                {
                    "sent": "So now you see regardless whether it's positive or negative, they all make vertical contribution some bigger than others, and they all make horizontal contribution.",
                    "label": 0
                },
                {
                    "sent": "So the curve always goes up and goes over and this is what allows me to determine that slope based on how positive it is.",
                    "label": 0
                },
                {
                    "sent": "Right, this is a major distinction between the smoother OC and the regular arosi, because the regular arrow see only positives go up and only negatives rundown, right?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you look at it, there's the set of positives that have high scores.",
                    "label": 0
                },
                {
                    "sent": "The set of negatives that have low scores, the set of positives that have low scores, the set of negatives that have high scores right?",
                    "label": 0
                },
                {
                    "sent": "And basically it's a cipher.",
                    "label": 0
                },
                {
                    "sent": "These 1 -- S I for those right the inverse of that happens on the horizontal run, so you just tally those and that will give you the normalization factor required.",
                    "label": 0
                },
                {
                    "sent": "WHI is it required is to keep the two dimensional picture?",
                    "label": 0
                },
                {
                    "sent": "Any unit square, right?",
                    "label": 0
                },
                {
                    "sent": "Because you want it from zero to 1 zero to one.",
                    "label": 0
                },
                {
                    "sent": "You could get rid of that, and I do believe there is an equivalent graph for it done by Peter Flack and it called.",
                    "label": 0
                },
                {
                    "sent": "It's called the NP graph, where instead of normalizing between zero and one, you simply visualize the true positive rate and the false positive rate over the number of positives and the negatives.",
                    "label": 0
                },
                {
                    "sent": "So you just for each one you go one step up and you don't normalize it right?",
                    "label": 0
                },
                {
                    "sent": "But then it becomes a rectangle, not.",
                    "label": 0
                },
                {
                    "sent": "A square it's only square if and only if you have the same number of pop.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is said negatives you could do the same thing here and simplify all of this and get rid of it if you want.",
                    "label": 0
                },
                {
                    "sent": "Right now we come to the area under the smooth arosi curve.",
                    "label": 0
                },
                {
                    "sent": "If I just quickly restate the definition of the AUC, the area under the standard arosi curve shows you the separation between the two classes and it's defined as the probability of picking a random positive point and see how many negatives are below it, right?",
                    "label": 0
                },
                {
                    "sent": "So it shows you the probability of randomly selected positive example being ranked higher than a randomly selected negatives.",
                    "label": 0
                },
                {
                    "sent": "So what does that mean in English and natural language?",
                    "label": 0
                },
                {
                    "sent": "What does it mean when you have when you calculate the area under the arosi curve basically shows you how the positives are separated from the negatives, right?",
                    "label": 0
                },
                {
                    "sent": "It gives you a probability of this particular model in along this curve to separate the positives from the negatives WHI, because along the Y axis you have contributions from only the positives along the X axis.",
                    "label": 0
                },
                {
                    "sent": "You have contributions only from the negatives, so the area in between is the separation between the two.",
                    "label": 0
                },
                {
                    "sent": "Right here we have a different problem.",
                    "label": 0
                },
                {
                    "sent": "We actually have contribution from positives and negatives here and positives and negatives here.",
                    "label": 0
                },
                {
                    "sent": "So then you ask, wait a minute?",
                    "label": 0
                },
                {
                    "sent": "Then how do you interpret this area under the curve?",
                    "label": 0
                },
                {
                    "sent": "Well, if you remember.",
                    "label": 0
                },
                {
                    "sent": "The vertical rise of every instance was how positive that particular instance was according to its label.",
                    "label": 0
                },
                {
                    "sent": "Right, this was an appropriate score, whereas this was inappropriate score.",
                    "label": 0
                },
                {
                    "sent": "So basically the separation between the two shows you how well the model separates the good scores from the bad scores, whether it be positive or negative.",
                    "label": 0
                },
                {
                    "sent": "Who cares, right?",
                    "label": 0
                },
                {
                    "sent": "In essence, I actually can compare now any point to any point in the data set based on its score, and that is a major distinction between the two.",
                    "label": 0
                },
                {
                    "sent": "Which leads me to.",
                    "label": 0
                },
                {
                    "sent": "Interpret this naturally in reverse order is that imagine you have a model.",
                    "label": 0
                },
                {
                    "sent": "And you build this curve and you get the area under this under the smooth arosi curve and you go back and you say what does it mean?",
                    "label": 0
                },
                {
                    "sent": "It actually means how you take a model.",
                    "label": 0
                },
                {
                    "sent": "And you hope you assume that the model is OK and you go back and sample your data according to the model you're biasing the model because you're taking the scores and you're saying I'll fix these scores.",
                    "label": 0
                },
                {
                    "sent": "I'll take these labels and see how well they agree.",
                    "label": 0
                },
                {
                    "sent": "So you're sampling the data based on how good the model is.",
                    "label": 0
                },
                {
                    "sent": "Which also brings an interesting weakness of this approach.",
                    "label": 0
                },
                {
                    "sent": "You could call it a weakness.",
                    "label": 0
                },
                {
                    "sent": "I don't think it's a weakness.",
                    "label": 0
                },
                {
                    "sent": "I think it's just irrelevant.",
                    "label": 0
                },
                {
                    "sent": "Is the fact that if you have a perfect classifier, this model will collapse.",
                    "label": 0
                },
                {
                    "sent": "Because I will have no.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Intersection in between.",
                    "label": 0
                },
                {
                    "sent": "If I have a perfect clean division between the two, I have nothing to separate.",
                    "label": 0
                },
                {
                    "sent": "The whole visual graph that I'm actually plotting is the separation between the appropriate ones, the ones on the top and this overlap in the middle right, and that's why.",
                    "label": 0
                },
                {
                    "sent": "Imagine if you're trying to do outlier detection an.",
                    "label": 0
                },
                {
                    "sent": "In a domain where there are no outliers, you basically get no results right.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you could also inverse the same situation by having a system that only gives you outliers absolutely no good points, and the same thing that if I have something that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Totally random, that is no good.",
                    "label": 0
                },
                {
                    "sent": "Then this will collapse again.",
                    "label": 0
                },
                {
                    "sent": "So either boundary is a problem.",
                    "label": 0
                },
                {
                    "sent": "I need something good to work with and something bad to assess.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the experiment.",
                    "label": 0
                },
                {
                    "sent": "For the experiments.",
                    "label": 0
                },
                {
                    "sent": "I want it to show.",
                    "label": 0
                },
                {
                    "sent": "That this method will detect similarities when similarities are present and will also measure differences when differences are present right?",
                    "label": 0
                },
                {
                    "sent": "And I wanted to compare it to this standard arosi to show that I actually have a gain over the arosi there is that extra information that I capture from this course.",
                    "label": 0
                },
                {
                    "sent": "So the first task was how do I produce similarities and how do I make up these differences?",
                    "label": 0
                },
                {
                    "sent": "So one approach would be to use synthetic data generators right?",
                    "label": 0
                },
                {
                    "sent": "This experiment?",
                    "label": 0
                },
                {
                    "sent": "I didn't, I don't have it here, but it's in the thesis.",
                    "label": 0
                },
                {
                    "sent": "I did that for something else.",
                    "label": 0
                },
                {
                    "sent": "But then I wanted to keep this natural, so I went and I got a whole bunch of data sets.",
                    "label": 0
                },
                {
                    "sent": "And then I came back and I thought, wait a minute similarities, you could actually produce similarities if you apply the same model on different subsets of the domain.",
                    "label": 0
                },
                {
                    "sent": "Assuming that the data comes from the same domain, you get subsamples of it applied the same model to it within some random variations you should get the same answer right?",
                    "label": 0
                },
                {
                    "sent": "It should be similar.",
                    "label": 0
                },
                {
                    "sent": "So if I build a decision tree on a model.",
                    "label": 0
                },
                {
                    "sent": "On a data set, a subset from a given domain, I build a decision tree and then I build a second one from a different subset from the same domain.",
                    "label": 0
                },
                {
                    "sent": "Given that the domain hasn't changed, these two should give me pretty much the same performance, right?",
                    "label": 0
                },
                {
                    "sent": "And that's what similarity is.",
                    "label": 0
                },
                {
                    "sent": "So if I take a really huge data set, subsample 40% of it.",
                    "label": 0
                },
                {
                    "sent": "Train and test and do it again and do it again and do it again and do it again.",
                    "label": 0
                },
                {
                    "sent": "The assumption here is that these models eventually will look similar, right?",
                    "label": 0
                },
                {
                    "sent": "They have to look similar, otherwise nothing will be good right?",
                    "label": 0
                },
                {
                    "sent": "The same thing if I took fundamentally two different algorithms that are known to be different.",
                    "label": 0
                },
                {
                    "sent": "Apply them to the same data set.",
                    "label": 0
                },
                {
                    "sent": "I should see these differences right now given that I have these differences, I'll see how they pan out given my performance assessment.",
                    "label": 0
                },
                {
                    "sent": "So I took twenty data 26 UCI datasets from the machine learning repository.",
                    "label": 1
                },
                {
                    "sent": "And I use two models.",
                    "label": 0
                },
                {
                    "sent": "I used probability estimating trees and I used naive base.",
                    "label": 0
                },
                {
                    "sent": "The reason I use these two is that they are so different from each other, they're both classifiers.",
                    "label": 0
                },
                {
                    "sent": "They both produce what so called probabilities.",
                    "label": 0
                },
                {
                    "sent": "One is known to produce poor probabilities that are not calibrated.",
                    "label": 0
                },
                {
                    "sent": "The other one is known to produce very calibrated probabilities, right?",
                    "label": 0
                },
                {
                    "sent": "And I use them to determine similarities and differences.",
                    "label": 0
                },
                {
                    "sent": "Now when it comes to similarities, I'm not using both of them together.",
                    "label": 0
                },
                {
                    "sent": "I leave one aside.",
                    "label": 0
                },
                {
                    "sent": "I use the same model over whole bunch of runs on each of the datasets and then I see how close the curves are when I compare the two to each other.",
                    "label": 0
                },
                {
                    "sent": "Exactly the same run.",
                    "label": 0
                },
                {
                    "sent": "But to compare two different models.",
                    "label": 0
                },
                {
                    "sent": "Then I should have differences.",
                    "label": 0
                },
                {
                    "sent": "I did this in using 10 fold cross validation repeated 10 times just to make sure I get all of the averages.",
                    "label": 1
                },
                {
                    "sent": "And then I. I basically took the approach is that the same learning model applied to the same data drawn from the domain should produce similarities, whereas different models applied to the same data set should produce differences right?",
                    "label": 1
                },
                {
                    "sent": "And I recorded the area under both of the curves.",
                    "label": 0
                },
                {
                    "sent": "The problem is that here you can imagine repeated experiments.",
                    "label": 0
                },
                {
                    "sent": "Each of them is a curve in the two dimensional space.",
                    "label": 0
                },
                {
                    "sent": "It's very difficult to sit down and try to compare each one of them that would have made the thesis this big.",
                    "label": 0
                },
                {
                    "sent": "I would say so.",
                    "label": 0
                },
                {
                    "sent": "One way of summarizing the whole curve is to take the area under it.",
                    "label": 0
                },
                {
                    "sent": "So I took the area under the arosi curve and I took the area under the smooth arosi curve and I compared them in the thesis.",
                    "label": 0
                },
                {
                    "sent": "I actually have examples where the curves are available.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what I have.",
                    "label": 0
                },
                {
                    "sent": "Similarities, so taking probability, estimating tree and I apply it to all of these datasets and I record the standard deviations of the area under the curve and the standard deviation and the average of that area under the curve.",
                    "label": 0
                },
                {
                    "sent": "The blue color is the standard Roc and the red color is the smooth arosi, the one that we came up with.",
                    "label": 0
                },
                {
                    "sent": "The first observation I have is that as the standard deviation increases across the data set for one given model.",
                    "label": 0
                },
                {
                    "sent": "The smooth arosi gives less deviation than the standard one.",
                    "label": 0
                },
                {
                    "sent": "This does make sense if you think about it, because a given point is determined to be above or below this threshold in the standard arosi irrelevant of its distance.",
                    "label": 0
                },
                {
                    "sent": "So if you repeat the experiment and this point shows up sometimes here, sometimes there sometimes here the arosi is crude is too rigid, so it generates higher standard deviation in the area then the smooth.",
                    "label": 0
                },
                {
                    "sent": "Because this month is more close to each other, chances are that line associated with a given point did not really move too much right?",
                    "label": 0
                },
                {
                    "sent": "It's close to each other and we see that even the area under the curve itself.",
                    "label": 0
                },
                {
                    "sent": "Is also less than that is in the standard Roc and you ask why?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would bring you back to very interesting notion here.",
                    "label": 0
                },
                {
                    "sent": "Just visually speaking.",
                    "label": 0
                },
                {
                    "sent": "Look at the blue curve and look at the red one.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't you say that the red one is some sort of a smoothing?",
                    "label": 0
                },
                {
                    "sent": "Of the blue one, it's making it smoother because it's taking all of those hard turns.",
                    "label": 0
                },
                {
                    "sent": "Out of it and making them into some sort of slope right so that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is an expected piece of results, and in fact it.",
                    "label": 0
                },
                {
                    "sent": "It shows that our assumption of similarity actually is captured much better in this mood.",
                    "label": 0
                },
                {
                    "sent": "Our OC curve, then it doesn't.",
                    "label": 0
                },
                {
                    "sent": "The standard arrow seeker.",
                    "label": 0
                },
                {
                    "sent": "Basically the standard error was C curve will give you differences between models that are not necessarily in the model themselves.",
                    "label": 0
                },
                {
                    "sent": "It's just due to plotting problems.",
                    "label": 0
                },
                {
                    "sent": "And this again if you want to interpret it.",
                    "label": 0
                },
                {
                    "sent": "It's the problem with ranking.",
                    "label": 0
                },
                {
                    "sent": "If you're using ranking you have no distances between points, but if you use scoring you consider this course you have distances.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I have another experiment with naive base alone, but I didn't have it here because I had less time to talk, but I have exactly the same results from naive base alone, so I did them separately.",
                    "label": 0
                },
                {
                    "sent": "But when I put them together, oh, I have it here.",
                    "label": 0
                },
                {
                    "sent": "Well, there you go, surprise, surprise.",
                    "label": 0
                },
                {
                    "sent": "Again, exactly the same thing.",
                    "label": 0
                },
                {
                    "sent": "The standard deviation in the smooth arosi space is a lot less, with two exceptions here that the area under the curve in this smooth Roc is actually higher.",
                    "label": 0
                },
                {
                    "sent": "For two datasets.",
                    "label": 0
                },
                {
                    "sent": "You see where the curve the red curve goes above the blue curve in the bottom graph.",
                    "label": 0
                },
                {
                    "sent": "Now you step back and you ask the question why?",
                    "label": 0
                },
                {
                    "sent": "Can you guess?",
                    "label": 0
                },
                {
                    "sent": "Which is the other way.",
                    "label": 0
                },
                {
                    "sent": "Smoothing the other way, but is that really smoothing?",
                    "label": 0
                },
                {
                    "sent": "So in statistics, that actually means something.",
                    "label": 0
                },
                {
                    "sent": "It's the concept of having a calibrated system being refined.",
                    "label": 0
                },
                {
                    "sent": "And what does that mean?",
                    "label": 0
                },
                {
                    "sent": "In statistics, they assume calibration to examine refinement.",
                    "label": 0
                },
                {
                    "sent": "The idea of refinement is that when you estimate probabilities to datapoints, positives and negatives, you want them to be the positives clustered higher towards one and the negatives towards 0.",
                    "label": 0
                },
                {
                    "sent": "So if you have that kind of separation that's called a refined system, and in these two datasets, if you look at the curves, I don't have them here, but I can show them to you if you want.",
                    "label": 0
                },
                {
                    "sent": "The system is actually very refined.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that it has a vertical rise followed by an horizontal run with which is the smoothing the other way, right?",
                    "label": 0
                },
                {
                    "sent": "And that's naive.",
                    "label": 0
                },
                {
                    "sent": "Based naive based does that very frequently because it gives higher.",
                    "label": 0
                },
                {
                    "sent": "Scores to the positives than it does to the negatives.",
                    "label": 0
                },
                {
                    "sent": "That's why it's an effective classifier you draw at 0.5 and guess what?",
                    "label": 0
                },
                {
                    "sent": "You will have very nice classification results.",
                    "label": 0
                },
                {
                    "sent": "However, these scores are not necessarily as good, they're actually smoother.",
                    "label": 0
                },
                {
                    "sent": "The arosi cannot tell you that the Arosi will show you the general estimated view of smoothness, but it won't give you sensitivity to scores, and that's where it was very obvious.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you consider the two together, you will see their differences with a really interesting piece of results at the end.",
                    "label": 0
                },
                {
                    "sent": "So in the bottom graph I have the zero difference between 90 base and probability estimating tree and the idea here is that I'm trying to determine whether the difference in the AUC between the two models is in favor of naive Bayes above or.",
                    "label": 1
                },
                {
                    "sent": "Probability estimating tree below.",
                    "label": 0
                },
                {
                    "sent": "So above that zero line naive base model has a higher AUC then probability estimating tree below it.",
                    "label": 0
                },
                {
                    "sent": "It's the other way around.",
                    "label": 0
                },
                {
                    "sent": "Now the interesting thing is when naive base wins the game, apparently the arosi cannot detect it because it keeps going up and down around the zero.",
                    "label": 0
                },
                {
                    "sent": "The smooth arosi sees it very well because it's sensitive to this refinement notion.",
                    "label": 0
                },
                {
                    "sent": "Of this course, whereas the interesting bit of results is that when probability estimating tree actually comes close to the same classification as Naive Bayes, the two of them sit hand in hand.",
                    "label": 0
                },
                {
                    "sent": "What does that tell you?",
                    "label": 0
                },
                {
                    "sent": "It tells you that when probability estimating trees produce good classification, you'll also have very good scores.",
                    "label": 0
                },
                {
                    "sent": "But when you have good classification from naive base alone, then these scores are not good there.",
                    "label": 0
                },
                {
                    "sent": "Poor right?",
                    "label": 0
                },
                {
                    "sent": "And that basically is the story that.",
                    "label": 0
                },
                {
                    "sent": "People have been trying to tell in the past 10 years when they examined the two, you could see it all in one plot here in one experiment and again the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "Of course, we already explained that one right.",
                    "label": 0
                },
                {
                    "sent": "So basically we can.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclude with this is that the smooth arosi curve is more sensitive to this course assigned to the to the data point then the Roc, which is by now obvious.",
                    "label": 1
                },
                {
                    "sent": "It's more sensitive to performance similarities and differences because we basically increase the resolution of performance assessment.",
                    "label": 1
                },
                {
                    "sent": "We now can actually look inside the square that the arosi cannot look inside.",
                    "label": 0
                },
                {
                    "sent": "The Arosi has a point on one end of the square and the other end of the square, and somehow it guesses the connection between them.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We actually have a slope in between and that's added knowledge which extends the whole method.",
                    "label": 0
                },
                {
                    "sent": "For similarities.",
                    "label": 0
                },
                {
                    "sent": "The smooth arosi this moves AUC actually produces lower standard deviation and better area under the curve.",
                    "label": 0
                },
                {
                    "sent": "The question that I omitted so far is the midpoint, right?",
                    "label": 0
                },
                {
                    "sent": "What happens with this point?",
                    "label": 0
                },
                {
                    "sent": "How do I get the midpoint?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that if you really think about it when you have labels, the boundary between positives and negatives is very clear.",
                    "label": 0
                },
                {
                    "sent": "You have a plus and minus right line is right there, but when you have scores, I'm not sure that's so obvious, right?",
                    "label": 0
                },
                {
                    "sent": "There is a special case of scores when you have calibrated scores.",
                    "label": 0
                },
                {
                    "sent": "It's natural to take 0.5, so if you have the distribution between them calibrated to the data points then you look for the 0.5 and the peaks of the two distributions will actually match.",
                    "label": 0
                },
                {
                    "sent": "You get it there and everything is fine, but we all know in reality nothing is calibrated.",
                    "label": 0
                },
                {
                    "sent": "You always work with a subsample of a population that you're not even sure if it's truly representative.",
                    "label": 0
                },
                {
                    "sent": "Or not, of what happens in there?",
                    "label": 0
                },
                {
                    "sent": "So how do we calculate that and now?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To go back to this issue, which I am open to suggestions as to how I find it so far.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll tell you what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "What I'm doing is actually very simple.",
                    "label": 0
                },
                {
                    "sent": "M is the average score, M Plus is the average score on the positive instances, and M minus is the average score on an.",
                    "label": 0
                },
                {
                    "sent": "I waited by CC is the class distribution.",
                    "label": 0
                },
                {
                    "sent": "So when I have a balanced data set that C is 1 and I basically take the average, the average find the midpoint and boom there it is, right?",
                    "label": 0
                },
                {
                    "sent": "If it's imbalanced, I just shifted over to the side based on the imbalance of the data set.",
                    "label": 0
                },
                {
                    "sent": "This seems to be intuitive.",
                    "label": 0
                },
                {
                    "sent": "It works most of the time, but.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I didn't show you in the in the picture here is that I actually drew perfectly nice equal symmetric type of distributions.",
                    "label": 0
                },
                {
                    "sent": "What if I had this?",
                    "label": 0
                },
                {
                    "sent": "What if I had this one wider than the other?",
                    "label": 0
                },
                {
                    "sent": "Right, well, the class distribution will actually account for this, but this is the headache, right?",
                    "label": 0
                },
                {
                    "sent": "So imagine all of the negative scores being clustered over close values with a subset of those that are very sparse away from it.",
                    "label": 0
                },
                {
                    "sent": "What do you do at that point?",
                    "label": 0
                },
                {
                    "sent": "Well, I can tell you that I've tried that and in some cases that midpoint collapses, because mathematically you can produce a set of scores for which that green line is actually over on this side.",
                    "label": 0
                },
                {
                    "sent": "It has to sit somewhere in between them.",
                    "label": 0
                },
                {
                    "sent": "If it doesn't sit in between, I have a serious problem.",
                    "label": 0
                },
                {
                    "sent": "Intersection of these kind of some kind of distribution graphs like here you have intersection between these two curves.",
                    "label": 0
                },
                {
                    "sent": "If I didn't have intersection then I have nothing to analyze right?",
                    "label": 0
                },
                {
                    "sent": "So I just go home.",
                    "label": 0
                },
                {
                    "sent": "I don't play with it at all right?",
                    "label": 0
                },
                {
                    "sent": "I need that could be the midpoint.",
                    "label": 0
                },
                {
                    "sent": "The midpoint could be outside the intersection and that's the whole problem.",
                    "label": 0
                },
                {
                    "sent": "It's even worse.",
                    "label": 0
                },
                {
                    "sent": "It could be outside both distributions, right?",
                    "label": 0
                },
                {
                    "sent": "Because I'm taking the average now.",
                    "label": 0
                },
                {
                    "sent": "The suggestion I have so far in which I would like to try.",
                    "label": 0
                },
                {
                    "sent": "Is taking the median instead of the average right?",
                    "label": 0
                },
                {
                    "sent": "The median might give me a good position for the midpoint, however I am actually exploring other ways of calculating this midpoint because as you can imagine that this assignment of appropriate versus inappropriate score is very sensitive to where you put this point, right?",
                    "label": 0
                },
                {
                    "sent": "So you want this point to be as good as possible, so the next approach I would like to try.",
                    "label": 0
                },
                {
                    "sent": "Is to learn this midpoint.",
                    "label": 0
                },
                {
                    "sent": "So imagine I had a high-quality data set from a distribution.",
                    "label": 0
                },
                {
                    "sent": "Right, that has scores in it and from there I can estimate the midpoint.",
                    "label": 0
                },
                {
                    "sent": "Once I do this front, I get my midpoint and I toss away everything I learn.",
                    "label": 0
                },
                {
                    "sent": "I just keep the midpoint and then I build the model that I want and apply the midpoint to it.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that can I learn this midpoint somewhere in between, which could be doable for appropriate type of domains?",
                    "label": 0
                },
                {
                    "sent": "Other than that, I could run a validation phase where I do training and I have another holdout set from the training over which I actually determine the midpoint, take that midpoint and apply it into testing.",
                    "label": 0
                },
                {
                    "sent": "So that's another approach, and of course they're all at this point here.",
                    "label": 0
                },
                {
                    "sent": "Open ended.",
                    "label": 0
                },
                {
                    "sent": "We can do whatever we want with it.",
                    "label": 0
                },
                {
                    "sent": "Another thing which I don't have in this presentation here.",
                    "label": 0
                },
                {
                    "sent": "The reason is because I want to write another paper about it.",
                    "label": 0
                },
                {
                    "sent": "Is that if you step back a little bit, I think Paul Bennett wrote a technical report talking about the problem he was dealing with.",
                    "label": 0
                },
                {
                    "sent": "Misclassification costs right and one of the things that they came across is that the probability estimation for a given domain is usually sensitive by this midpoint, where the overlap is right and the funny part is that if you build a model on this distribution, you sample data from these two.",
                    "label": 0
                },
                {
                    "sent": "With this given midpoint.",
                    "label": 0
                },
                {
                    "sent": "And then somehow sometime later you could test it and these two shift things change.",
                    "label": 0
                },
                {
                    "sent": "They go apart if they go apart you're safe because the midpoint still sits in between.",
                    "label": 0
                },
                {
                    "sent": "But this midpoint is sensitive to changes in this domain, which actually tells you that my entire approach could be very sensitive to changes in underlying domain.",
                    "label": 0
                },
                {
                    "sent": "Right, and this turns out to be very beneficial in detecting changes in data distributions, so now we're not evaluating the model.",
                    "label": 0
                },
                {
                    "sent": "We take a snapshot of the problem we're trying to solve now and take another snapshot Snapshot 20 years later, see if things changed.",
                    "label": 0
                },
                {
                    "sent": "Right when things change in the domain, presumably the model that you trained at that point is no longer good.",
                    "label": 0
                },
                {
                    "sent": "Right, so it turns out that we have an extra advantage in this smooth arosi curve is that it's sensitive to changes in the underlying domain, which means that curve will change based on differences between training and testing.",
                    "label": 0
                },
                {
                    "sent": "So now I step aside and I tell you those who are interested in assessing the quality of data.",
                    "label": 0
                },
                {
                    "sent": "Imagine you have multiple samples from the domain and you want to verify that indeed.",
                    "label": 0
                },
                {
                    "sent": "You have the same thing.",
                    "label": 0
                },
                {
                    "sent": "Right, you can build curves for it and see if they match.",
                    "label": 0
                },
                {
                    "sent": "If they don't match, it could be likely that the samples conveyed different views of the domain and maybe a mixture of those would be ideal for training.",
                    "label": 0
                },
                {
                    "sent": "So can you identify a subsample of a domain appropriate for training and model at this point?",
                    "label": 0
                },
                {
                    "sent": "And this is work that hasn't been done yet.",
                    "label": 0
                },
                {
                    "sent": "So yeah, the future is busy.",
                    "label": 0
                },
                {
                    "sent": "Let's put it this way and thank you very much for putting up with me.",
                    "label": 0
                },
                {
                    "sent": "I think I'm finished.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "You are dealing with all these things.",
                    "label": 0
                },
                {
                    "sent": "You probably know how easy and how stable how, what's the quality of computing probabilities out of scores actually.",
                    "label": 0
                },
                {
                    "sent": "So you have a classifier introduces scores.",
                    "label": 0
                },
                {
                    "sent": "So Transgenesis somehow SVM, for example.",
                    "label": 0
                },
                {
                    "sent": "Now let's say that you have a next component which wants as input once probabilities.",
                    "label": 0
                },
                {
                    "sent": "How difficult is it to?",
                    "label": 0
                },
                {
                    "sent": "MAP scores into probabilities so that they still so that they make sense.",
                    "label": 0
                },
                {
                    "sent": "Or is this like impossible?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quote.",
                    "label": 0
                },
                {
                    "sent": "That's actually very easy, surprisingly easy.",
                    "label": 0
                },
                {
                    "sent": "Pathetically easy, I would say.",
                    "label": 0
                },
                {
                    "sent": "See there is an interesting thing.",
                    "label": 0
                },
                {
                    "sent": "If you if you go back to the aerospace, the aerospace aerospace has this concept of the arosi convex Hull.",
                    "label": 0
                },
                {
                    "sent": "Anne Peter Flack did a lot of work on repairing what's called King cavities.",
                    "label": 0
                },
                {
                    "sent": "This is akin cavity into the arosi and you repair it.",
                    "label": 0
                },
                {
                    "sent": "In his case, you swap the two right and you effectively fix the ranking.",
                    "label": 0
                },
                {
                    "sent": "Swap the two who cares about the scores were not using them anyways and you get a nicely convex curve and theoretically speaking, if you take the convex Hull, it turns out that the slope of the line segment is actually the likelihood of that particular instance being a member in that class.",
                    "label": 0
                },
                {
                    "sent": "So all you have to do is repair concavities along the arosi.",
                    "label": 0
                },
                {
                    "sent": "Read off the value of those scores and you've got a set of calibrated probabilities as well.",
                    "label": 0
                },
                {
                    "sent": "In fact, in a narrow space, if you want to tell how far off a given model is from calibration, you draw the convex Hull and you see the gap between them, right?",
                    "label": 0
                },
                {
                    "sent": "So getting those likelihoods is no problem.",
                    "label": 0
                },
                {
                    "sent": "However, there is a problem.",
                    "label": 0
                },
                {
                    "sent": "Imagine you did have a convex curve.",
                    "label": 0
                },
                {
                    "sent": "You are not guaranteed that this particular.",
                    "label": 0
                },
                {
                    "sent": "Convexity is actually related to the score.",
                    "label": 0
                },
                {
                    "sent": "It may be an over estimate or underestimate in the aerospace.",
                    "label": 0
                },
                {
                    "sent": "Same now how to do this on a Golden stand up on a Labor Day, yes.",
                    "label": 0
                },
                {
                    "sent": "I mean how do they transfer this to the test?",
                    "label": 0
                },
                {
                    "sent": "Oh, you you learn it on the training set and you apply it on the test set.",
                    "label": 0
                },
                {
                    "sent": "That's the trick.",
                    "label": 0
                },
                {
                    "sent": "And you applied, and that's where the over and underestimation will actually happen is because the arosi over there gives you way too much leeway.",
                    "label": 0
                },
                {
                    "sent": "The slope is free to go based on equal weights or whatever the number of observations you have.",
                    "label": 0
                },
                {
                    "sent": "Yes, I'm talking about the usual RC.",
                    "label": 0
                },
                {
                    "sent": "As soon as I go into mine the magnitude of that problem is significantly reduced because of the resolution of the score.",
                    "label": 0
                },
                {
                    "sent": "All I would have to do to get you see the convex Hull for this curve would be here.",
                    "label": 0
                },
                {
                    "sent": "I'm barely off calibration, I'm not too far off calibration, whereas this one it's off here, it's off there and it's off there right?",
                    "label": 0
                },
                {
                    "sent": "So this if you were to calibrate it would actually give you perfect, so this course you would read likelihood scores you would read out of this convex Hull.",
                    "label": 0
                },
                {
                    "sent": "Would be 1 one 0.500 right?",
                    "label": 0
                },
                {
                    "sent": "Whereas here the values you would read are actually closer to what you get.",
                    "label": 0
                },
                {
                    "sent": "In this scoring, so this is more sensitive to the model itself than this one.",
                    "label": 0
                },
                {
                    "sent": "They'll both give you a calibrated scores.",
                    "label": 0
                },
                {
                    "sent": "However, having said that, there is a very interesting observation I made there an I have no idea what it means yet I know why.",
                    "label": 0
                },
                {
                    "sent": "I know its effect, I can reproduce it and it makes sense.",
                    "label": 0
                },
                {
                    "sent": "But what it means, I still don't know.",
                    "label": 0
                },
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "Look at the decision.",
                    "label": 0
                },
                {
                    "sent": "I have three positives and three negatives, right?",
                    "label": 0
                },
                {
                    "sent": "And unfortunately, Oh no, this is a beautiful example actually.",
                    "label": 0
                },
                {
                    "sent": "If you were to calibrate these scores.",
                    "label": 0
                },
                {
                    "sent": "It's natural to take 0.5 as a cutoff point between negatives and positives, right?",
                    "label": 0
                },
                {
                    "sent": "That's what calibration gives you.",
                    "label": 0
                },
                {
                    "sent": "It fixes the midpoint and distributes the data points around it.",
                    "label": 0
                },
                {
                    "sent": "If I were to take 0.5 over there, I actually end up with four positives and two negatives.",
                    "label": 0
                },
                {
                    "sent": "Because that 0.51 is above is just above.",
                    "label": 0
                },
                {
                    "sent": "And what happens here?",
                    "label": 0
                },
                {
                    "sent": "I have a discrepancy in the class distribution between the two criteria if you will label says three and three scores, says four and two.",
                    "label": 0
                },
                {
                    "sent": "Visually, this produces a slight rotation when you go to calibrate.",
                    "label": 0
                },
                {
                    "sent": "I don't know what it means and I just confessed it.",
                    "label": 0
                },
                {
                    "sent": "It makes sense because the distribution of scores is totally different than the distribution of labels, right?",
                    "label": 0
                },
                {
                    "sent": "But by the time you calibrate them, the effect of calibration on my curve is actually a very significant piece of work, because once I figure out why this rotation is there, it would be very interesting to solve and I can tell you that when you're dealing with changes in the underlying domain, you get a lot of rotations.",
                    "label": 0
                },
                {
                    "sent": "Because the balance changes.",
                    "label": 0
                },
                {
                    "sent": "That's how they are.",
                    "label": 0
                },
                {
                    "sent": "OC detects changes in data distributions.",
                    "label": 0
                },
                {
                    "sent": "Is that you sampled it at 10 out of 100 and then you sample it again at 30 out of 100 over there is class imbalance, but they are.",
                    "label": 0
                },
                {
                    "sent": "OC is actually very practical at ignoring these things because the decreasing diagonal is the balanced data set.",
                    "label": 0
                },
                {
                    "sent": "Anything below it you have more negatives than positives.",
                    "label": 0
                },
                {
                    "sent": "Anything above it you have more positives than negatives.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you draw this an you just figure out for my given balance which point on the arosi should I use?",
                    "label": 0
                },
                {
                    "sent": "Those are called the operating points on the RC curve, right?",
                    "label": 0
                },
                {
                    "sent": "Over here it's not so obvious because this.",
                    "label": 0
                },
                {
                    "sent": "Decreasing diagonal is now the balance between appropriate and inappropriate.",
                    "label": 0
                },
                {
                    "sent": "Because remember, the separation is appropriate.",
                    "label": 0
                },
                {
                    "sent": "Scores versus inappropriate scores and appropriate scores go across both sets.",
                    "label": 0
                },
                {
                    "sent": "The positives and the negatives and the same thing happens on the on the X axes, so the balance between them is what causes that rotation.",
                    "label": 0
                },
                {
                    "sent": "It makes perfect sense mathematically, theoretically, an visually, but what does it really mean when you go back to performance assessment?",
                    "label": 0
                },
                {
                    "sent": "You have an idea, please tell me.",
                    "label": 0
                }
            ]
        }
    }
}