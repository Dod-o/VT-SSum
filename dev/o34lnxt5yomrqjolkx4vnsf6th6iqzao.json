{
    "id": "o34lnxt5yomrqjolkx4vnsf6th6iqzao",
    "title": "From Ranking to Intransitive Preference Learning: Rock-Paper-Scissors and Beyond Incorporating Exceptions",
    "info": {
        "author": [
            "Willem Waegeman, Department of Applied Mathematics, Biometrics and Process Control, Ghent University"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_waegeman_friplrpsb/",
    "segmentation": [
        [
            "So I guess the talk of the previous speaker was a very well introduction to the topic.",
            "I want to talk about.",
            "So basically I'm going to talk about what's beyond ranking models.",
            "A lot has been done in the last years on ranking in machine learning.",
            "I want to talk about in which kind of situations you cannot use ranking models.",
            "I should also mention this is joint work with several people.",
            "In particular, I would like to acknowledge the work of top your particula who did all the implementations and experiments for this paper.",
            "So.",
            "If we are talking about.",
            "Beyond ranking, in which I mean in transitive preference learning, that's what I the topic will be about.",
            "Then a classical example, which is often put forward in in order to introduce what transitivity is, it's the rock, paper, scissors relationship.",
            "So for people that are not familiar with rock, paper, scissors is a kind of simple child's game in which you have three different strategies.",
            "Rock, paper and scissors.",
            "For which the relation holds, that saves wins from paper.",
            "Paper wins from rock and rock wins from scissors, so you have a cycle here.",
            "Which means that you cannot use a ranking method in order to represent this type of information.",
            "What you want to do in this paper is discuss methods that are capable of learning this kind of cycles in data."
        ],
        [
            "General, so the basic setting that we will consider is.",
            "We have kind of."
        ],
        [
            "Two objects and we want to learn a relation could be kind of relation and a graph or just a relation in general between two objects.",
            "And the relation can be represented by an edge.",
            "It can be have two values.",
            "In the case of classification, it can also be real valued in the interval 01.",
            "That's would be more a kind of regression type of setting.",
            "So the motivation for doing this kind of research is you can find it."
        ],
        [
            "In many fields I've listed here on this slide, a couple of possible applications, at least some.",
            "Problems were intransitive preferences have been observed, or let me just call it in general, in transitive relations.",
            "One example, an article that has been published in Nature, is about the mating strategy of lizards.",
            "Also, food preference of birds and cats manifests in transitive preferences.",
            "The competition between bacterial speeches also is known to observe intransitive preferences.",
            "Then in biochemistry you have well known example of the Krebs cycle where you have a chain of chemical reactions that lead to a cycle.",
            "So this is also case where you cannot use a ranking method.",
            "Another example is fungie the complex ecosystems phone by phone.",
            "We are known to observe and transitive relations and then other types of applications are all related to games like sports games.",
            "Computer games and board games.",
            "Now in this game type of setting you can think of many potential for machine learning.",
            "Let's say you're an online betting company and you want to predict whether.",
            "One player will win in the next US Open game against someone else.",
            "Then you definitely need an intransitive model.",
            "So this talk you can subdivide it into three main parts."
        ],
        [
            "First I will rephrase some well known facts from decision theory and preference modeling to justify transitivity a bit more in a formal way.",
            "Then I will talk a bit about the learning aspects and then in the last part I will tell you some experimental results.",
            "So in order to define something small."
        ],
        [
            "Formally, let us consider another very well known example of an in transitive relation.",
            "What you see on this slide are three different dice with some numbers on it, and let's assume we want to play a game.",
            "You can choose one of the three dice.",
            "I will pick one of the main ones, and let's say try to choose one of the guys that maximizes your probability of winning in the sense that if we both throw the dice, the guy with the highest number on his dice, he wins.",
            "Let's say 10 euro.",
            "It turns out that you can choose the numbers on the dice in a clever way such that you obtain."
        ],
        [
            "Then the probability that the red one runs from the green one is 5 / 9, and it also holds for the other two cases.",
            "You can compute this very simple As for this green rat one like the 9 rims from 8, six and one the four all only wins from one and two also wins from one.",
            "So the probability here is 5 / 9.",
            "This is a relation which is in transitive innocence that our relation is now valued it.",
            "Can take values between zero and one in the previous example with rock paper scissors it could only take values zero or one in the sense there was an edge or not.",
            "Here it's like an edge with a weight on it.",
            "This relation is has also another property.",
            "It's a reciprocal relation because."
        ],
        [
            "Cause if you shift the dice, the probability that the green one wins from the red one is 4 / 9.",
            "The sum of these two probabilities is always one, and this property we call it."
        ],
        [
            "Reciprocity property.",
            "So in general we call a relation of reciprocal relation.",
            "If the sum of the relation with the first time X as its first element and the second time X prime as its first element is 1.",
            "In this talk, I will concentrate on learning relations where this type of property hold because we want to show that with kernel methods we can embed this quite easily in our framework.",
            "So related to this."
        ],
        [
            "Is.",
            "A property which has been called in decision theory, utility representability, or numerically representability.",
            "I call this ranking representability.",
            "This is a property for relations and we say."
        ],
        [
            "That's a relation is ranking representable if for every pair it holds if the relation is smaller than 1/2, then we should find we should be able to find a ranking function F such that the ranking value for X is smaller than 4X prime.",
            "So an example of this is this thing.",
            "We say that the relate, let's say the relation between red and green is 5 / 9 for the other two also.",
            "For this relation, it doesn't satisfy the weeks.",
            "This ranking representability property becausw you one ranking function shoot always rank are at above green.",
            "The next one green above blue and then blue above red.",
            "So we have a cycle there.",
            "That brings me directly to another property which is called."
        ],
        [
            "Weak stochastic transitivity.",
            "It's a property which is very related to ranking representability.",
            "And basically this property says if you have a triplet XX prime and extra double prime if the relation XX prime is bigger than 1/2 an X prime X double prime is bigger than 1/2, then the relation XX double prime also should be bigger than 1/2.",
            "Now this.",
            "Property has a one to one correspondence with ranking representability.",
            "It means that ranking representability holds if and only if week stochastic transitivity holds.",
            "So an example of this.",
            "I now define."
        ],
        [
            "Here the value is 6 / 9 five over 9 and 2 / 9.",
            "For this example we can just find a ranking that satisfies this thing.",
            "So this is an example of relation which is ranking representable.",
            "It's also weekly, stochastically, transitive.",
            "Now The thing is that.",
            "Many machine learning methods have this kind of property, making them unsuitable to model an transitive relations.",
            "So basically what we want to do is to present a model which is capable of violating this week, so hassick transitivity property.",
            "So that brings me to the third part."
        ],
        [
            "How much minutes do I have already?",
            "Yeah, OK. Set.",
            "OK. Then I should start to talk a bit.",
            "Look, let's fast.",
            "OK, so the setting that we will consider is.",
            "To define some things or."
        ],
        [
            "We have a training data E which is just a data set of pairs consisting of features an labels in our setting.",
            "A pair will be a couple of objects, so the setting is we have two objects with some features.",
            "These are our input and then we have a label associated with it and that's our relation that we want to learn.",
            "OK.",
            "The framework that people consider is maybe I should also say first that we will re scale our relations so our relation Q was defined as.",
            "You was defined as the relation that we want to learn within our framework.",
            "We will work with labels that can take values between minus one and one that just for implementation reasons.",
            "So you have a kind of rescaling here.",
            "So remember Q is the relation that you want to learn X&X prime or our input data with some features.",
            "The framework that we consider adjust the basic.",
            "Structural risk minimization framework in which we optimize kind of loss function plus a regularization term.",
            "The kind of loss function that you optimize could be anything in this case, could be a logistic loss hinge loss.",
            "We will just use the least squares loss leading to an algorithm which is called regularised least squares.",
            "In the literature it's also known as Kernel Ridge regression or least least squares support vector machines, but.",
            "We don't want to focus too hard on this in this implementation, so the method that we propose also works for other kernel methods.",
            "So.",
            "The."
        ],
        [
            "Basic ID is that we need in order to model and transitive preferences.",
            "We need to kind of feature representation which is a combination of the two objects that we take as input.",
            "So our feature representation for East.",
            "We can say it's a feature representation of two objects.",
            "An here we will define a new feature representation that I call PSI.",
            "So we have already defy and I also introduced the PSI, which is just a difference.",
            "Now the reason why I introduced this size.",
            "Site is becausw.",
            "It leads to the representation that has the reciprocity property.",
            "Remember from the beginning at a relation that has this reciprocity property always.",
            "If you dualize this thing so in the dual, you get a kind of construction like this, so you have a kernel KFI define."
        ],
        [
            "Over our feature space Fi, which is a kernel of two edges in a graph, let's say.",
            "So it's a kernel over 4 objects or four nodes and we can rewrite this as follows, leading to a kernel defied defined on our feature presentation.",
            "Sigh as follows.",
            "So the relationship between K5 and Capes I is just that gave 5 as a sum of four different capeside.",
            "Our model in this case looks like this.",
            "So it's a mallet."
        ],
        [
            "Takes 2 objects as input.",
            "It's in the in the primal.",
            "It's just a kind of linear combination of.",
            "Our vector of parameters W and our feature representation and in the dual.",
            "This model can be written as follows, in which we have, so the model is entirely defined in terms of a kernel K5 over quadruples or over four data objects.",
            "Now."
        ],
        [
            "In this framework, we can consider ranking methods as a specific case and the way we do this is just by writing Fi Now again as by writing SCI again as a fi, but now a small file.",
            "So we already have three different feature representations.",
            "We have the big Fi, we have the big sigh and we have the small file.",
            "The small fee is something defined on an object, let's say in a graph.",
            "You have a note.",
            "This is a feature representation for that note the cyan, the Big 5.",
            "These are feature representations combined for two objects.",
            "Um?",
            "So with this construction, the kernel becomes very simple.",
            "The kernel defined over quadruples now just becomes a kernel define."
        ],
        [
            "And over 2 objects from each pair we just take the first one and we throw away the second one.",
            "And our model can in this case be written as follows.",
            "And the nice thing is that."
        ],
        [
            "Here our model just becomes a difference between.",
            "What I call here in F. It's just the difference between the rank value for X&X prime.",
            "So actually by this construction we have reduced our pairwise model to just a ranking model.",
            "But that's not what we want to do.",
            "This kind of representation you can find in many articles on ranking in kernel methods.",
            "We want to do something else.",
            "So the trick that we use is instead of ignoring the 2nd."
        ],
        [
            "Elements in our side.",
            "We will now take a combination of the features for the first object and a feature for the second object and this thing.",
            "Here is the Chronicle product.",
            "It's also called the tensor product and well, it just does is it takes all the features of the first object and all the features of the second object and it combines it like this in a kind of matrix.",
            "So you have to read this.",
            "This thing is a vector.",
            "These things are matrices so.",
            "In essence, you get, you get one very, very big vector.",
            "So this this PSI is actually one very big factor in which you combine all the features from the first object with all the features of the second object.",
            "And in this way we can do something which is much more than only ranking.",
            "Another nice thing about his approach."
        ],
        [
            "Which is that in the dual we can write us very efficiently.",
            "So if you have this chronic product or tensor product, if you rewrite using a property of that product, you can rewrite this line as this line.",
            "And this line is just basically a product of two different kernels.",
            "So what we have done is actually our kernel that we have on quadruples is now defined as just the product of two different kernels.",
            "And we can show mathematically that this kind of construction can learn any type of relations in the sense that it can also learn in transitive relations.",
            "In the paper you can find the mathematical details for that.",
            "So that brings me to the third."
        ],
        [
            "Section in which I was gonna show some experimental results.",
            "Um, for the first experiment, we have done some things with rock paper."
        ],
        [
            "This.",
            "And, well, rock paper scissors as introduced in the beginning, was just the kind of game in which you have three different strategies.",
            "What I'm going to do now is like if you play this game, you have a probability of choosing each strategy.",
            "So as a player, you can say I will in 50% of the cases I will choose this strategy in 20% of the cases I will choose this one, and 30% of the cases I will choose the last strategy.",
            "Now all these different players that you can form in this way you can in some way represent them in a kind of triangle.",
            "So for example this point here."
        ],
        [
            "Corresponds to a player which always plays rock.",
            "In any case, the strategy will be always rock.",
            "The middle point corresponds to a strategy in which you have an equal probability of choosing a certain player, and this edge here at the middle point of the edge, it's a problem.",
            "It's a player for which you have that never plays rock, but it plays paper and scissors with equal probability.",
            "So our.",
            "Population of different players that we have in the game, we can just represent it as all possible.",
            "Values in the in the triangle.",
            "Then the model that."
        ],
        [
            "We try to learn so it's the kind of artificial experiment we know already.",
            "The relation I we want to learn this relation from data and.",
            "In order to compute the probability that a player X wins from X prime, it's just the probability that the first one plays Rock II scissors plus 1/2.",
            "The probability of a tie plus the probability that the 1st place paper, the Second Rock plus again the of the probability of a tie, and then the probability that the first one play scissors and loss one place paper.",
            "So an example of this, let's say the first one.",
            "Plays rock with probability, half paper with probability, half the second one never plays rock.",
            "It plays paper with probability half and says with probability half.",
            "Then you can compute.",
            "Just by taking this cord that it should be 3 / 8.",
            "So that's the thing that we want to learn here.",
            "And in this."
        ],
        [
            "Experiment we use.",
            "A setting in which we have 100 randomly generated games from this triangle for training, and we have 1000 games for testing.",
            "Um, the feature."
        ],
        [
            "These are in this case, so the probabilities of playing a different strategy for the players an our labels can take values minus one, one or zero.",
            "Zero in the case of a tie.",
            "Our test data can take values between zero and one.",
            "So for the test data we are predicting the probability we use."
        ],
        [
            "Here the linear kernel, because the Gaussian RBF kernel doesn't make much sense and.",
            "We will consider three different settings.",
            "In the first setting we SAMP."
        ],
        [
            "So all the different players from a gorgin distribution with center in the middle.",
            "This corresponds to kind of basic setting in which there's not much to learn.",
            "There's also not a lot of intransitivity.",
            "And it happens that in this case, if we compare the intransitive kernel which corresponds to the full model, if we compare it to transitive kernel, which is just the ranking model, then both are worse than the naive approach which is in this case just predicting always probability half or corresponding to the center.",
            "So in this setting, there's really nothing to learn.",
            "And next setting we sample uniformly from the triangle, and in this case it already.",
            "You can already see that intransitive kernel performs remarkably better than the transitive kernel, although the difference is not really that much yet, and both are better than the naive approach.",
            "In the third setting, we sample from the edges or more or less around the edges of the triangle.",
            "This corresponds to a setting where you have many in transitive relations, and in this setting, our intransitive kernel is really remarkably better than the transitive one.",
            "Also remarkably better than the naive approach.",
            "So this is the first experiment in the second one we have found some ideas from papers that have been published in biology, and in particular in theoretical biology.",
            "Some models have been proposed for modeling behavior of bacteria bacteria.",
            "And what you're seeing on this slide is a kind of simulation of such a model.",
            "It's a.",
            "It's a model that has evolves overtime, so you have two dimensions on the X axis, a strong point of a certain speeches is represented on the Y axis, a strong point, a weak point of species is represented, and the labels.",
            "So you have two speeches that have a kind of competition between each other, and the label is a kind of.",
            "A complex relation between the two speeches.",
            "So now what you see also above is the number of iterations.",
            "So the model evolves overtime and you can see that at the end of the movie you get a kind of stable clusters.",
            "So in the beginning it's like a population which is randomly chosen and at the end you get stable clusters.",
            "Maybe I should wait here for a second.",
            "So it's now after 500,000 iterations.",
            "In each iteration we have randomly two speeches that have kind of competition between each other and it's the winner replaces.",
            "In some sense the loser.",
            "So there's a way why these you get these clusters at the end.",
            "So we're there already.",
            "Yet what we're gonna do is for our data for machine learning, we're going to sample from the stable clusters that we had at the end.",
            "So if I move on to the next slide, the relation that we have between our features, so these as of X&X prime and.",
            "W of X&X prime or our two features, our Y axes and our X axis, an hour labels are a kind of combination of these features.",
            "In this sense, in which D is a kind of measure, it's not really a distance measure before, because we're not sure that it satisfies the triangle inequality.",
            "Um?",
            "But in some sense it has to violate the triangle inequality because we are trying to learn something which is intransitive.",
            "So the results.",
            "Are on my next slide.",
            "Um?",
            "OK, this is the last slide.",
            "With a transitive Colonel.",
            "So with the ranking model we got an accuracy of 60% more or less, with the intransitive one, the accuracy is more than 80% and this is the kind of visualization of the test data we randomly sampled.",
            "Some of the test points and you see that the red lines are the errors that are made, so you see that the transitive kernel makes some errors which are quite specific, mainly here and here, which is due to the fact that it has to learn.",
            "Ranking model.",
            "So that brings me to the conclusion.",
            "In this talk.",
            "I've tried to convince you that in some situations you cannot use ranking methods, in particular, in a situation where you want to learn a relation which is intransitive, we have proposed a new method to realize this.",
            "Empirical results on some semi artificial data illustrates that the method really works and I would be happy to find more datasets, applications where we could use is.",
            "I think there's a huge potential in biology and so, but I haven't seen that much concrete yet.",
            "The software will be available on this link.",
            "The datasets are already available there, so if someone else wants to try this, go ahead.",
            "Thanks.",
            "We are a little bit overtime, but I think we can read one or two minutes from the last paper.",
            "Questions and.",
            "I completely agree that there are applications where you do have this kind of transitive behavior and that it's important to look at this also from a learning point of view.",
            "However, and this is a comment that you will probably disagree with, my impression is that the problem becomes a bit less interesting.",
            "Actually, from a learning point of view, because what you do is you drop a condition.",
            "So in a sense you make the learning problem even a bit simpler because the only condition that you.",
            "Have to satisfy is that you want to have a reciprocal relation, yes.",
            "And.",
            "Input it.",
            "In particular, you can see this from this method by Cohen.",
            "That was also presented in the previous talk, and this innocence also answers your question that you raised before because in Cohens method you also learn a binary predicate.",
            "Q of X&X prime and what you have to do in order to.",
            "Make this method able to learn transitive relations is only drop.",
            "The last step of the method where you solve this linear ordering problem.",
            "This method also learns isn't inherently transitive predicate, and only these methods.",
            "These authors in the last step in Forza ranking.",
            "This last step you have actually what you want.",
            "Yeah, I should have a closer look at that method, but I think the main message I want to tell in this talk it's.",
            "First, you need a pairwise model, of course.",
            "Secondly, it's all about the feature representation of the two objects.",
            "If user feature representation, which is common in machine learning which is used in ranking methods and kernel based ranking methods, you can do anything.",
            "If you want to learn in transitive relation.",
            "So it's all about the feature representation that you use.",
            "And I guess the feature representation that we use.",
            "You can also use it in the method of Co and the nice thing here is that this feature representation also gives 2 nice construction in the dual.",
            "Which leads to a product of current of kernels.",
            "More questions.",
            "Go to the next."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I guess the talk of the previous speaker was a very well introduction to the topic.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about.",
                    "label": 0
                },
                {
                    "sent": "So basically I'm going to talk about what's beyond ranking models.",
                    "label": 0
                },
                {
                    "sent": "A lot has been done in the last years on ranking in machine learning.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about in which kind of situations you cannot use ranking models.",
                    "label": 0
                },
                {
                    "sent": "I should also mention this is joint work with several people.",
                    "label": 0
                },
                {
                    "sent": "In particular, I would like to acknowledge the work of top your particula who did all the implementations and experiments for this paper.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we are talking about.",
                    "label": 0
                },
                {
                    "sent": "Beyond ranking, in which I mean in transitive preference learning, that's what I the topic will be about.",
                    "label": 0
                },
                {
                    "sent": "Then a classical example, which is often put forward in in order to introduce what transitivity is, it's the rock, paper, scissors relationship.",
                    "label": 0
                },
                {
                    "sent": "So for people that are not familiar with rock, paper, scissors is a kind of simple child's game in which you have three different strategies.",
                    "label": 0
                },
                {
                    "sent": "Rock, paper and scissors.",
                    "label": 0
                },
                {
                    "sent": "For which the relation holds, that saves wins from paper.",
                    "label": 0
                },
                {
                    "sent": "Paper wins from rock and rock wins from scissors, so you have a cycle here.",
                    "label": 0
                },
                {
                    "sent": "Which means that you cannot use a ranking method in order to represent this type of information.",
                    "label": 0
                },
                {
                    "sent": "What you want to do in this paper is discuss methods that are capable of learning this kind of cycles in data.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "General, so the basic setting that we will consider is.",
                    "label": 0
                },
                {
                    "sent": "We have kind of.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two objects and we want to learn a relation could be kind of relation and a graph or just a relation in general between two objects.",
                    "label": 0
                },
                {
                    "sent": "And the relation can be represented by an edge.",
                    "label": 0
                },
                {
                    "sent": "It can be have two values.",
                    "label": 0
                },
                {
                    "sent": "In the case of classification, it can also be real valued in the interval 01.",
                    "label": 0
                },
                {
                    "sent": "That's would be more a kind of regression type of setting.",
                    "label": 0
                },
                {
                    "sent": "So the motivation for doing this kind of research is you can find it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In many fields I've listed here on this slide, a couple of possible applications, at least some.",
                    "label": 1
                },
                {
                    "sent": "Problems were intransitive preferences have been observed, or let me just call it in general, in transitive relations.",
                    "label": 0
                },
                {
                    "sent": "One example, an article that has been published in Nature, is about the mating strategy of lizards.",
                    "label": 0
                },
                {
                    "sent": "Also, food preference of birds and cats manifests in transitive preferences.",
                    "label": 0
                },
                {
                    "sent": "The competition between bacterial speeches also is known to observe intransitive preferences.",
                    "label": 0
                },
                {
                    "sent": "Then in biochemistry you have well known example of the Krebs cycle where you have a chain of chemical reactions that lead to a cycle.",
                    "label": 0
                },
                {
                    "sent": "So this is also case where you cannot use a ranking method.",
                    "label": 0
                },
                {
                    "sent": "Another example is fungie the complex ecosystems phone by phone.",
                    "label": 0
                },
                {
                    "sent": "We are known to observe and transitive relations and then other types of applications are all related to games like sports games.",
                    "label": 0
                },
                {
                    "sent": "Computer games and board games.",
                    "label": 0
                },
                {
                    "sent": "Now in this game type of setting you can think of many potential for machine learning.",
                    "label": 0
                },
                {
                    "sent": "Let's say you're an online betting company and you want to predict whether.",
                    "label": 0
                },
                {
                    "sent": "One player will win in the next US Open game against someone else.",
                    "label": 0
                },
                {
                    "sent": "Then you definitely need an intransitive model.",
                    "label": 0
                },
                {
                    "sent": "So this talk you can subdivide it into three main parts.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First I will rephrase some well known facts from decision theory and preference modeling to justify transitivity a bit more in a formal way.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk a bit about the learning aspects and then in the last part I will tell you some experimental results.",
                    "label": 0
                },
                {
                    "sent": "So in order to define something small.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formally, let us consider another very well known example of an in transitive relation.",
                    "label": 0
                },
                {
                    "sent": "What you see on this slide are three different dice with some numbers on it, and let's assume we want to play a game.",
                    "label": 0
                },
                {
                    "sent": "You can choose one of the three dice.",
                    "label": 0
                },
                {
                    "sent": "I will pick one of the main ones, and let's say try to choose one of the guys that maximizes your probability of winning in the sense that if we both throw the dice, the guy with the highest number on his dice, he wins.",
                    "label": 0
                },
                {
                    "sent": "Let's say 10 euro.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you can choose the numbers on the dice in a clever way such that you obtain.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the probability that the red one runs from the green one is 5 / 9, and it also holds for the other two cases.",
                    "label": 0
                },
                {
                    "sent": "You can compute this very simple As for this green rat one like the 9 rims from 8, six and one the four all only wins from one and two also wins from one.",
                    "label": 0
                },
                {
                    "sent": "So the probability here is 5 / 9.",
                    "label": 0
                },
                {
                    "sent": "This is a relation which is in transitive innocence that our relation is now valued it.",
                    "label": 1
                },
                {
                    "sent": "Can take values between zero and one in the previous example with rock paper scissors it could only take values zero or one in the sense there was an edge or not.",
                    "label": 0
                },
                {
                    "sent": "Here it's like an edge with a weight on it.",
                    "label": 0
                },
                {
                    "sent": "This relation is has also another property.",
                    "label": 0
                },
                {
                    "sent": "It's a reciprocal relation because.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cause if you shift the dice, the probability that the green one wins from the red one is 4 / 9.",
                    "label": 0
                },
                {
                    "sent": "The sum of these two probabilities is always one, and this property we call it.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reciprocity property.",
                    "label": 0
                },
                {
                    "sent": "So in general we call a relation of reciprocal relation.",
                    "label": 1
                },
                {
                    "sent": "If the sum of the relation with the first time X as its first element and the second time X prime as its first element is 1.",
                    "label": 0
                },
                {
                    "sent": "In this talk, I will concentrate on learning relations where this type of property hold because we want to show that with kernel methods we can embed this quite easily in our framework.",
                    "label": 0
                },
                {
                    "sent": "So related to this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "A property which has been called in decision theory, utility representability, or numerically representability.",
                    "label": 0
                },
                {
                    "sent": "I call this ranking representability.",
                    "label": 0
                },
                {
                    "sent": "This is a property for relations and we say.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's a relation is ranking representable if for every pair it holds if the relation is smaller than 1/2, then we should find we should be able to find a ranking function F such that the ranking value for X is smaller than 4X prime.",
                    "label": 1
                },
                {
                    "sent": "So an example of this is this thing.",
                    "label": 0
                },
                {
                    "sent": "We say that the relate, let's say the relation between red and green is 5 / 9 for the other two also.",
                    "label": 0
                },
                {
                    "sent": "For this relation, it doesn't satisfy the weeks.",
                    "label": 0
                },
                {
                    "sent": "This ranking representability property becausw you one ranking function shoot always rank are at above green.",
                    "label": 0
                },
                {
                    "sent": "The next one green above blue and then blue above red.",
                    "label": 0
                },
                {
                    "sent": "So we have a cycle there.",
                    "label": 0
                },
                {
                    "sent": "That brings me directly to another property which is called.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Weak stochastic transitivity.",
                    "label": 0
                },
                {
                    "sent": "It's a property which is very related to ranking representability.",
                    "label": 0
                },
                {
                    "sent": "And basically this property says if you have a triplet XX prime and extra double prime if the relation XX prime is bigger than 1/2 an X prime X double prime is bigger than 1/2, then the relation XX double prime also should be bigger than 1/2.",
                    "label": 0
                },
                {
                    "sent": "Now this.",
                    "label": 0
                },
                {
                    "sent": "Property has a one to one correspondence with ranking representability.",
                    "label": 0
                },
                {
                    "sent": "It means that ranking representability holds if and only if week stochastic transitivity holds.",
                    "label": 1
                },
                {
                    "sent": "So an example of this.",
                    "label": 0
                },
                {
                    "sent": "I now define.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here the value is 6 / 9 five over 9 and 2 / 9.",
                    "label": 0
                },
                {
                    "sent": "For this example we can just find a ranking that satisfies this thing.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of relation which is ranking representable.",
                    "label": 0
                },
                {
                    "sent": "It's also weekly, stochastically, transitive.",
                    "label": 0
                },
                {
                    "sent": "Now The thing is that.",
                    "label": 0
                },
                {
                    "sent": "Many machine learning methods have this kind of property, making them unsuitable to model an transitive relations.",
                    "label": 0
                },
                {
                    "sent": "So basically what we want to do is to present a model which is capable of violating this week, so hassick transitivity property.",
                    "label": 0
                },
                {
                    "sent": "So that brings me to the third part.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How much minutes do I have already?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK. Set.",
                    "label": 0
                },
                {
                    "sent": "OK. Then I should start to talk a bit.",
                    "label": 0
                },
                {
                    "sent": "Look, let's fast.",
                    "label": 0
                },
                {
                    "sent": "OK, so the setting that we will consider is.",
                    "label": 0
                },
                {
                    "sent": "To define some things or.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a training data E which is just a data set of pairs consisting of features an labels in our setting.",
                    "label": 0
                },
                {
                    "sent": "A pair will be a couple of objects, so the setting is we have two objects with some features.",
                    "label": 0
                },
                {
                    "sent": "These are our input and then we have a label associated with it and that's our relation that we want to learn.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The framework that people consider is maybe I should also say first that we will re scale our relations so our relation Q was defined as.",
                    "label": 0
                },
                {
                    "sent": "You was defined as the relation that we want to learn within our framework.",
                    "label": 0
                },
                {
                    "sent": "We will work with labels that can take values between minus one and one that just for implementation reasons.",
                    "label": 0
                },
                {
                    "sent": "So you have a kind of rescaling here.",
                    "label": 0
                },
                {
                    "sent": "So remember Q is the relation that you want to learn X&X prime or our input data with some features.",
                    "label": 0
                },
                {
                    "sent": "The framework that we consider adjust the basic.",
                    "label": 0
                },
                {
                    "sent": "Structural risk minimization framework in which we optimize kind of loss function plus a regularization term.",
                    "label": 0
                },
                {
                    "sent": "The kind of loss function that you optimize could be anything in this case, could be a logistic loss hinge loss.",
                    "label": 0
                },
                {
                    "sent": "We will just use the least squares loss leading to an algorithm which is called regularised least squares.",
                    "label": 0
                },
                {
                    "sent": "In the literature it's also known as Kernel Ridge regression or least least squares support vector machines, but.",
                    "label": 0
                },
                {
                    "sent": "We don't want to focus too hard on this in this implementation, so the method that we propose also works for other kernel methods.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basic ID is that we need in order to model and transitive preferences.",
                    "label": 0
                },
                {
                    "sent": "We need to kind of feature representation which is a combination of the two objects that we take as input.",
                    "label": 0
                },
                {
                    "sent": "So our feature representation for East.",
                    "label": 0
                },
                {
                    "sent": "We can say it's a feature representation of two objects.",
                    "label": 0
                },
                {
                    "sent": "An here we will define a new feature representation that I call PSI.",
                    "label": 0
                },
                {
                    "sent": "So we have already defy and I also introduced the PSI, which is just a difference.",
                    "label": 0
                },
                {
                    "sent": "Now the reason why I introduced this size.",
                    "label": 0
                },
                {
                    "sent": "Site is becausw.",
                    "label": 0
                },
                {
                    "sent": "It leads to the representation that has the reciprocity property.",
                    "label": 0
                },
                {
                    "sent": "Remember from the beginning at a relation that has this reciprocity property always.",
                    "label": 0
                },
                {
                    "sent": "If you dualize this thing so in the dual, you get a kind of construction like this, so you have a kernel KFI define.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over our feature space Fi, which is a kernel of two edges in a graph, let's say.",
                    "label": 0
                },
                {
                    "sent": "So it's a kernel over 4 objects or four nodes and we can rewrite this as follows, leading to a kernel defied defined on our feature presentation.",
                    "label": 0
                },
                {
                    "sent": "Sigh as follows.",
                    "label": 0
                },
                {
                    "sent": "So the relationship between K5 and Capes I is just that gave 5 as a sum of four different capeside.",
                    "label": 0
                },
                {
                    "sent": "Our model in this case looks like this.",
                    "label": 0
                },
                {
                    "sent": "So it's a mallet.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Takes 2 objects as input.",
                    "label": 0
                },
                {
                    "sent": "It's in the in the primal.",
                    "label": 0
                },
                {
                    "sent": "It's just a kind of linear combination of.",
                    "label": 0
                },
                {
                    "sent": "Our vector of parameters W and our feature representation and in the dual.",
                    "label": 0
                },
                {
                    "sent": "This model can be written as follows, in which we have, so the model is entirely defined in terms of a kernel K5 over quadruples or over four data objects.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this framework, we can consider ranking methods as a specific case and the way we do this is just by writing Fi Now again as by writing SCI again as a fi, but now a small file.",
                    "label": 1
                },
                {
                    "sent": "So we already have three different feature representations.",
                    "label": 0
                },
                {
                    "sent": "We have the big Fi, we have the big sigh and we have the small file.",
                    "label": 0
                },
                {
                    "sent": "The small fee is something defined on an object, let's say in a graph.",
                    "label": 0
                },
                {
                    "sent": "You have a note.",
                    "label": 0
                },
                {
                    "sent": "This is a feature representation for that note the cyan, the Big 5.",
                    "label": 0
                },
                {
                    "sent": "These are feature representations combined for two objects.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So with this construction, the kernel becomes very simple.",
                    "label": 0
                },
                {
                    "sent": "The kernel defined over quadruples now just becomes a kernel define.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And over 2 objects from each pair we just take the first one and we throw away the second one.",
                    "label": 0
                },
                {
                    "sent": "And our model can in this case be written as follows.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing is that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here our model just becomes a difference between.",
                    "label": 0
                },
                {
                    "sent": "What I call here in F. It's just the difference between the rank value for X&X prime.",
                    "label": 0
                },
                {
                    "sent": "So actually by this construction we have reduced our pairwise model to just a ranking model.",
                    "label": 0
                },
                {
                    "sent": "But that's not what we want to do.",
                    "label": 0
                },
                {
                    "sent": "This kind of representation you can find in many articles on ranking in kernel methods.",
                    "label": 0
                },
                {
                    "sent": "We want to do something else.",
                    "label": 0
                },
                {
                    "sent": "So the trick that we use is instead of ignoring the 2nd.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elements in our side.",
                    "label": 0
                },
                {
                    "sent": "We will now take a combination of the features for the first object and a feature for the second object and this thing.",
                    "label": 0
                },
                {
                    "sent": "Here is the Chronicle product.",
                    "label": 0
                },
                {
                    "sent": "It's also called the tensor product and well, it just does is it takes all the features of the first object and all the features of the second object and it combines it like this in a kind of matrix.",
                    "label": 0
                },
                {
                    "sent": "So you have to read this.",
                    "label": 0
                },
                {
                    "sent": "This thing is a vector.",
                    "label": 0
                },
                {
                    "sent": "These things are matrices so.",
                    "label": 0
                },
                {
                    "sent": "In essence, you get, you get one very, very big vector.",
                    "label": 0
                },
                {
                    "sent": "So this this PSI is actually one very big factor in which you combine all the features from the first object with all the features of the second object.",
                    "label": 0
                },
                {
                    "sent": "And in this way we can do something which is much more than only ranking.",
                    "label": 0
                },
                {
                    "sent": "Another nice thing about his approach.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is that in the dual we can write us very efficiently.",
                    "label": 0
                },
                {
                    "sent": "So if you have this chronic product or tensor product, if you rewrite using a property of that product, you can rewrite this line as this line.",
                    "label": 0
                },
                {
                    "sent": "And this line is just basically a product of two different kernels.",
                    "label": 0
                },
                {
                    "sent": "So what we have done is actually our kernel that we have on quadruples is now defined as just the product of two different kernels.",
                    "label": 0
                },
                {
                    "sent": "And we can show mathematically that this kind of construction can learn any type of relations in the sense that it can also learn in transitive relations.",
                    "label": 0
                },
                {
                    "sent": "In the paper you can find the mathematical details for that.",
                    "label": 0
                },
                {
                    "sent": "So that brings me to the third.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Section in which I was gonna show some experimental results.",
                    "label": 0
                },
                {
                    "sent": "Um, for the first experiment, we have done some things with rock paper.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "And, well, rock paper scissors as introduced in the beginning, was just the kind of game in which you have three different strategies.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do now is like if you play this game, you have a probability of choosing each strategy.",
                    "label": 0
                },
                {
                    "sent": "So as a player, you can say I will in 50% of the cases I will choose this strategy in 20% of the cases I will choose this one, and 30% of the cases I will choose the last strategy.",
                    "label": 0
                },
                {
                    "sent": "Now all these different players that you can form in this way you can in some way represent them in a kind of triangle.",
                    "label": 0
                },
                {
                    "sent": "So for example this point here.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Corresponds to a player which always plays rock.",
                    "label": 0
                },
                {
                    "sent": "In any case, the strategy will be always rock.",
                    "label": 0
                },
                {
                    "sent": "The middle point corresponds to a strategy in which you have an equal probability of choosing a certain player, and this edge here at the middle point of the edge, it's a problem.",
                    "label": 0
                },
                {
                    "sent": "It's a player for which you have that never plays rock, but it plays paper and scissors with equal probability.",
                    "label": 0
                },
                {
                    "sent": "So our.",
                    "label": 0
                },
                {
                    "sent": "Population of different players that we have in the game, we can just represent it as all possible.",
                    "label": 0
                },
                {
                    "sent": "Values in the in the triangle.",
                    "label": 0
                },
                {
                    "sent": "Then the model that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We try to learn so it's the kind of artificial experiment we know already.",
                    "label": 0
                },
                {
                    "sent": "The relation I we want to learn this relation from data and.",
                    "label": 0
                },
                {
                    "sent": "In order to compute the probability that a player X wins from X prime, it's just the probability that the first one plays Rock II scissors plus 1/2.",
                    "label": 0
                },
                {
                    "sent": "The probability of a tie plus the probability that the 1st place paper, the Second Rock plus again the of the probability of a tie, and then the probability that the first one play scissors and loss one place paper.",
                    "label": 0
                },
                {
                    "sent": "So an example of this, let's say the first one.",
                    "label": 0
                },
                {
                    "sent": "Plays rock with probability, half paper with probability, half the second one never plays rock.",
                    "label": 0
                },
                {
                    "sent": "It plays paper with probability half and says with probability half.",
                    "label": 0
                },
                {
                    "sent": "Then you can compute.",
                    "label": 0
                },
                {
                    "sent": "Just by taking this cord that it should be 3 / 8.",
                    "label": 0
                },
                {
                    "sent": "So that's the thing that we want to learn here.",
                    "label": 0
                },
                {
                    "sent": "And in this.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experiment we use.",
                    "label": 0
                },
                {
                    "sent": "A setting in which we have 100 randomly generated games from this triangle for training, and we have 1000 games for testing.",
                    "label": 1
                },
                {
                    "sent": "Um, the feature.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are in this case, so the probabilities of playing a different strategy for the players an our labels can take values minus one, one or zero.",
                    "label": 0
                },
                {
                    "sent": "Zero in the case of a tie.",
                    "label": 0
                },
                {
                    "sent": "Our test data can take values between zero and one.",
                    "label": 0
                },
                {
                    "sent": "So for the test data we are predicting the probability we use.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here the linear kernel, because the Gaussian RBF kernel doesn't make much sense and.",
                    "label": 1
                },
                {
                    "sent": "We will consider three different settings.",
                    "label": 1
                },
                {
                    "sent": "In the first setting we SAMP.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So all the different players from a gorgin distribution with center in the middle.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to kind of basic setting in which there's not much to learn.",
                    "label": 0
                },
                {
                    "sent": "There's also not a lot of intransitivity.",
                    "label": 0
                },
                {
                    "sent": "And it happens that in this case, if we compare the intransitive kernel which corresponds to the full model, if we compare it to transitive kernel, which is just the ranking model, then both are worse than the naive approach which is in this case just predicting always probability half or corresponding to the center.",
                    "label": 0
                },
                {
                    "sent": "So in this setting, there's really nothing to learn.",
                    "label": 0
                },
                {
                    "sent": "And next setting we sample uniformly from the triangle, and in this case it already.",
                    "label": 0
                },
                {
                    "sent": "You can already see that intransitive kernel performs remarkably better than the transitive kernel, although the difference is not really that much yet, and both are better than the naive approach.",
                    "label": 0
                },
                {
                    "sent": "In the third setting, we sample from the edges or more or less around the edges of the triangle.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to a setting where you have many in transitive relations, and in this setting, our intransitive kernel is really remarkably better than the transitive one.",
                    "label": 0
                },
                {
                    "sent": "Also remarkably better than the naive approach.",
                    "label": 0
                },
                {
                    "sent": "So this is the first experiment in the second one we have found some ideas from papers that have been published in biology, and in particular in theoretical biology.",
                    "label": 0
                },
                {
                    "sent": "Some models have been proposed for modeling behavior of bacteria bacteria.",
                    "label": 0
                },
                {
                    "sent": "And what you're seeing on this slide is a kind of simulation of such a model.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "It's a model that has evolves overtime, so you have two dimensions on the X axis, a strong point of a certain speeches is represented on the Y axis, a strong point, a weak point of species is represented, and the labels.",
                    "label": 0
                },
                {
                    "sent": "So you have two speeches that have a kind of competition between each other, and the label is a kind of.",
                    "label": 0
                },
                {
                    "sent": "A complex relation between the two speeches.",
                    "label": 0
                },
                {
                    "sent": "So now what you see also above is the number of iterations.",
                    "label": 0
                },
                {
                    "sent": "So the model evolves overtime and you can see that at the end of the movie you get a kind of stable clusters.",
                    "label": 0
                },
                {
                    "sent": "So in the beginning it's like a population which is randomly chosen and at the end you get stable clusters.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should wait here for a second.",
                    "label": 0
                },
                {
                    "sent": "So it's now after 500,000 iterations.",
                    "label": 0
                },
                {
                    "sent": "In each iteration we have randomly two speeches that have kind of competition between each other and it's the winner replaces.",
                    "label": 0
                },
                {
                    "sent": "In some sense the loser.",
                    "label": 0
                },
                {
                    "sent": "So there's a way why these you get these clusters at the end.",
                    "label": 0
                },
                {
                    "sent": "So we're there already.",
                    "label": 0
                },
                {
                    "sent": "Yet what we're gonna do is for our data for machine learning, we're going to sample from the stable clusters that we had at the end.",
                    "label": 0
                },
                {
                    "sent": "So if I move on to the next slide, the relation that we have between our features, so these as of X&X prime and.",
                    "label": 0
                },
                {
                    "sent": "W of X&X prime or our two features, our Y axes and our X axis, an hour labels are a kind of combination of these features.",
                    "label": 0
                },
                {
                    "sent": "In this sense, in which D is a kind of measure, it's not really a distance measure before, because we're not sure that it satisfies the triangle inequality.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But in some sense it has to violate the triangle inequality because we are trying to learn something which is intransitive.",
                    "label": 0
                },
                {
                    "sent": "So the results.",
                    "label": 0
                },
                {
                    "sent": "Are on my next slide.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, this is the last slide.",
                    "label": 0
                },
                {
                    "sent": "With a transitive Colonel.",
                    "label": 0
                },
                {
                    "sent": "So with the ranking model we got an accuracy of 60% more or less, with the intransitive one, the accuracy is more than 80% and this is the kind of visualization of the test data we randomly sampled.",
                    "label": 0
                },
                {
                    "sent": "Some of the test points and you see that the red lines are the errors that are made, so you see that the transitive kernel makes some errors which are quite specific, mainly here and here, which is due to the fact that it has to learn.",
                    "label": 0
                },
                {
                    "sent": "Ranking model.",
                    "label": 0
                },
                {
                    "sent": "So that brings me to the conclusion.",
                    "label": 0
                },
                {
                    "sent": "In this talk.",
                    "label": 0
                },
                {
                    "sent": "I've tried to convince you that in some situations you cannot use ranking methods, in particular, in a situation where you want to learn a relation which is intransitive, we have proposed a new method to realize this.",
                    "label": 0
                },
                {
                    "sent": "Empirical results on some semi artificial data illustrates that the method really works and I would be happy to find more datasets, applications where we could use is.",
                    "label": 0
                },
                {
                    "sent": "I think there's a huge potential in biology and so, but I haven't seen that much concrete yet.",
                    "label": 0
                },
                {
                    "sent": "The software will be available on this link.",
                    "label": 0
                },
                {
                    "sent": "The datasets are already available there, so if someone else wants to try this, go ahead.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "We are a little bit overtime, but I think we can read one or two minutes from the last paper.",
                    "label": 0
                },
                {
                    "sent": "Questions and.",
                    "label": 0
                },
                {
                    "sent": "I completely agree that there are applications where you do have this kind of transitive behavior and that it's important to look at this also from a learning point of view.",
                    "label": 0
                },
                {
                    "sent": "However, and this is a comment that you will probably disagree with, my impression is that the problem becomes a bit less interesting.",
                    "label": 0
                },
                {
                    "sent": "Actually, from a learning point of view, because what you do is you drop a condition.",
                    "label": 0
                },
                {
                    "sent": "So in a sense you make the learning problem even a bit simpler because the only condition that you.",
                    "label": 0
                },
                {
                    "sent": "Have to satisfy is that you want to have a reciprocal relation, yes.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Input it.",
                    "label": 0
                },
                {
                    "sent": "In particular, you can see this from this method by Cohen.",
                    "label": 0
                },
                {
                    "sent": "That was also presented in the previous talk, and this innocence also answers your question that you raised before because in Cohens method you also learn a binary predicate.",
                    "label": 0
                },
                {
                    "sent": "Q of X&X prime and what you have to do in order to.",
                    "label": 0
                },
                {
                    "sent": "Make this method able to learn transitive relations is only drop.",
                    "label": 0
                },
                {
                    "sent": "The last step of the method where you solve this linear ordering problem.",
                    "label": 0
                },
                {
                    "sent": "This method also learns isn't inherently transitive predicate, and only these methods.",
                    "label": 0
                },
                {
                    "sent": "These authors in the last step in Forza ranking.",
                    "label": 0
                },
                {
                    "sent": "This last step you have actually what you want.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I should have a closer look at that method, but I think the main message I want to tell in this talk it's.",
                    "label": 0
                },
                {
                    "sent": "First, you need a pairwise model, of course.",
                    "label": 0
                },
                {
                    "sent": "Secondly, it's all about the feature representation of the two objects.",
                    "label": 0
                },
                {
                    "sent": "If user feature representation, which is common in machine learning which is used in ranking methods and kernel based ranking methods, you can do anything.",
                    "label": 0
                },
                {
                    "sent": "If you want to learn in transitive relation.",
                    "label": 0
                },
                {
                    "sent": "So it's all about the feature representation that you use.",
                    "label": 0
                },
                {
                    "sent": "And I guess the feature representation that we use.",
                    "label": 0
                },
                {
                    "sent": "You can also use it in the method of Co and the nice thing here is that this feature representation also gives 2 nice construction in the dual.",
                    "label": 0
                },
                {
                    "sent": "Which leads to a product of current of kernels.",
                    "label": 0
                },
                {
                    "sent": "More questions.",
                    "label": 0
                },
                {
                    "sent": "Go to the next.",
                    "label": 0
                }
            ]
        }
    }
}