{
    "id": "hgqnu7evn547kheezbmno46gp2rxjaot",
    "title": "Variational filtering in generated coordinates of motion",
    "info": {
        "author": [
            "Karl Friston, Wellcome Trust Centre for Neuroimaging, University College London"
        ],
        "published": "Sept. 9, 2008",
        "recorded": "May 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/aispds08_friston_vfgc/",
    "segmentation": [
        [
            "It's a great pleasure to be here, not least because I very seldom get invited to talk to machine learning audiences, and that to be precise, as a first time that I've spoken to machine learning audience.",
            "So if I use the wrong words, please forgive me and pretend I was using the right words.",
            "I'm actually neuro scientist and the work that I'm going to overview for you has two agendas.",
            "First, my unit is responsible for the analysis of biological Time series data specifically.",
            "You're imaging data.",
            "So much of what I'm showing you is building up on work that enables us to make inferences about the about models of biological time series.",
            "But at the same time, we're also interested in these inversion schemes or optimization schemes as metaphors for how the brain actually works.",
            "So that's sort of a jewel accountability of the work that I'm going to summarize for you at this afternoon, and it might be useful to bat in Michael's it'll it'll pop up.",
            "From time to time, so I'm going to talk."
        ],
        [
            "First of all, about the nature of the models that we deal with.",
            "I repeat, there really models for biological systems formatted in continuous time, specifically focusing on the dynamics and introducing generalized coordinates to the formulation of these causal models or state space models.",
            "And the dynamical priors that these generalized coordinates entail and how they can be useful in providing constraints on the sorts of data that are generated on the optimization or the fitting of the models that are using.",
            "I'm going to recapitulate or repeat the sort of dynamical priors in terms of the structures of the models by lending them a hierarchical forms are going to be considering state space models or dynamic.",
            "Calls and models formulated continuous time that have a hierarchical structure, so the outputs of 1 dynamical system actors control parameters or inputs to a subordinate one and so on and so forth to any arbitrary depth having set up the model and the form of the energy functions that these models imply considering the inversion of these models or the recovery of the conditional densities or approximations to those conditional densities on the state of these models and their parameters.",
            "And hyperparameters.",
            "I'm going to briefly mention two approaches.",
            "One is a simplification of the other, the first variational filtering, which doesn't assume any parametric form for the densities that we're trying to identify.",
            "And then a Laplace approximation or assuming the density Gaussian form, we can actually simplify this variational filtering and get this fixed form scheme here briefly to present some comparative evaluations.",
            "And then finish.",
            "If I have time with two entered, well, I find meditating 2 examples.",
            "One which is an empirical one inverting.",
            "The OR trying to recover neuronal states that are causing observed brain imaging signals and the other one returned to this notion that the brain might actually use these schemes to invert sensory data to disclose the causes.",
            "The environmental causes of those data and that example we use Birdsongs, so the source."
        ],
        [
            "Models that are going to be dealing with a very simple state space models in equation form here and in terms of Bayesian dependency graphs here where the data are Y that are generated by hidden states that have dynamics where those dynamics are perturbed by causes or sources.",
            "V here the functions governing the equations of motion of the hidden states here are parameterized by Theta and their random fluctuations on both the observed data.",
            "And the hidden states got here by Zedd and W."
        ],
        [
            "So I should just make a comment about notation just to simplify things X dot.",
            "Obviously ready change of X with respect to T, but I'm also going to be talking about generalized motion or motion in generalized coordinates, so the X~ means a state and its first order generalized motion, 2nd order acceleration, and so on to arbitrarily high orders in motion.",
            "It's important to realize that the.",
            "At the 1st order, motion is not the speed of movement of the position.",
            "So if one is lucky of one, as we'll see later under special constraints, the 1st order motion will actually be the velocity of the position.",
            "That is not generally the case.",
            "So when I do a neck still there, I'm implying a whole infinite set or series of high order motions which are also indicate with the superscript in square brackets.",
            "Here again, subscript X means a derivative in the usual way.",
            "Definition For 1st order motion.",
            "First, the definition is just, it's the.",
            "Sort of definition, but an analogy here would be like momentum in physics.",
            "So you have position of amentum.",
            "So what I'm saying is that unless you invoke.",
            "Stationality principles not Hamilton stationary principles.",
            "You can't necessarily assume that the rate of change of the position corresponds to the momentum at some scale, but we will see that he does for the most of the dances later on."
        ],
        [
            "So.",
            "Just put the tillers on there 'cause they're going to become quite important, but I just wanted to indicate here in this slide was the generalization in terms of the form of these models from a state space model to a hierarchal version of this where the input now becomes the output of a super ordinate dynamical system, that's all I mean by hierarchal formally.",
            "Imagine repeating that hierarchy to any arbitrary number of hierarchical levels.",
            "I've just sketched in here the conditional densities entailed by these edges.",
            "Here in this graph, but I'm going to go through those insight more detail in the next couple of slides just show you where they come from with a focus."
        ],
        [
            "The first instance on the temporal dependencies and dependencies that are given by considering the evolution of these systems within generalized coordinates.",
            "So what I've done here this is simply re write out a non hierarchical form of state space model rate of change of X is some function plus some random fluctuations and then we observe some generally nonlinear static observer function of the States and the causes.",
            "But critically, noting that this these model specification induces an infinite series of constraints in terms of the higher order generalized motion.",
            "So if I just differentiate both sides of this equation here to 1st order, I can now express a relationship between the 2nd order motion, the 1st order motion and simulate this third automation and the 1st order motion that are all generated by.",
            "The derivatives repeat just the 1st order here of the original functions F and similarly for G here, which means that we have in principle alot of formal information.",
            "That comes for free as embedded in this model that is realized when one considers the evolution of the dynamics in generalized coordinates here.",
            "And I can write that quite compactly just by saying that the generalized motion of Y is equal to its generalized prediction plus the equivalent generalized motion of the random fluctuation and then the D operator.",
            "Here's a derivative operator that just shifts generalized motion up, so the 1st order motion.",
            "Is a function of the of the.",
            "The generalized states X here plus some random fluctuations where again this is a generalized prediction of the generalized motion here, which comes simply or can be drive very trivially from the first derivatives of these functions.",
            "Here this is this is this.",
            "In regard as a derivative operator or sort of.",
            "Diagonal matrix operate here.",
            "That just shifts these the lower higher order motion into the position of a lower order motion and write it out like that.",
            "What can see immediately that we have a form.",
            "So for example, if we assume that Zed had a Gaussian distribution, we have specified implicitly a density on waiora likelihood the probability of Y given the causes.",
            "X&V in generalized coordinates in terms of the expectation that generalized prediction here and some covariance on the fluctuations, generalized fluctuations here and similarly we have a prior density that is furnished by the equations of motion that covers not just the 1st order motion or the velocity of the states itself, but also to our higher orders, which depends upon the covariance.",
            "Of the state noise here in higher order motion, and that's useful in the sense that if there is a finite variance on high order motion of the fluctuations, we can actually use this and it becomes an integral part of the inherent part, or both the likelihood and prior, which will be absolutely critical when it comes to optimize your finding.",
            "The maximum per story estimators of the states, or indeed the parameters governing.",
            "Control in the form of these equations here so."
        ],
        [
            "This slide just makes that explicit and I'm just written out here under Gaussian assumptions about those random fluctuations.",
            "The energy at any one point in time which I'm going to do it by you being the log of the joint probability of the observed data and their underlying causes the.",
            "Cause."
        ],
        [
            "Since I'm going to lump together as you so the hidden States and the causes here, I'm going to lump together as general General States you here.",
            "And Furthermore, sometimes we refer to these States and the parameters of these equations and the random terms at theater here."
        ],
        [
            "Looks like so.",
            "This actually has a terribly simple form under Gaussian assumptions.",
            "It's just basically the error terms of the differences between the predictions and the observed.",
            "Sandwich between the precision and it's the precision which is interesting here, because the precision doesn't just cover the precision of the random fluctuations of the values themselves, but also their generalized motion, and we can derive those quite simply from the covariance of the higher order motion.",
            "In terms of the correlation function on the random fluctuations themselves, and this know that this takes us away from any sort of ina like process or any model that relies upon independence of the increments or the the differences in the random fluctuations between time one and some other point in time.",
            "We're actually here dealing with biologically, or at least by physically realistic processes that are continuous differentiable, have autocorrelation functions, and these enter as random.",
            "Terms into the model and they have well defined correlation functions and that means they actually have a well defined precision over generalized coordinates that is given by sort of classical theory of stochastic processes.",
            "I've written it out generally generally here in terms of the high order derivatives of the auto correlation function for Gaussian form with precision parameter.",
            "Gamma has this simple form here, and I'm just showing an image representation of this covariant or precision matrix.",
            "If this is the covariance in the inverse precision matrix for a Gaussian form where gamma is equal to four, which means that the correlations have a correlation length of about half a time bin and what we see here is that the precisions fall off as the thing gets as we go into higher order motion.",
            "Generally rougher it gets the precision of the higher order terms gets large very very quickly, which is good because we can throw those away.",
            "In the practical sense, this is the equivalent used using simple Taylor expansion.",
            "This is the equivalent decision matrix overtime, so this is the precision into the past and into the future from a current time point.",
            "That's going to become relevant later, because what this says in this particular form of generative model at this instant in time generates data that is only precisely specified locally in time, and that's gonna be quite useful practically when it comes to inverting these models, 'cause it means that.",
            "We can deal with or just process data that is local to time and we can effectively emulate an online scheme but retain the benefits of a Bayesian smoother as opposed to a Bayesian filter.",
            "So.",
            "That's the brief overview introduction to this sort of.",
            "To generalized coordinates and precisions in temple and generalized coordinates and how they enter the specification of the likelihood or the energy.",
            "I just wanted to draw a parallel here in terms of."
        ],
        [
            "Of the what they bring to the model between these dynamical prize and the hierarchal extension which gives you these structural prize when we take a sort of hierarchal extension of this state space model here, which I've just indicated by having superscripts in curly brackets at the top here, where we have the data here that's generated by a state space model where the inputs to the hidden states at the first level are the outputs from a super ordinate dynamical system.",
            "And so on and so forth.",
            "All the formalism both would have just shown, and what I will show is absolutely identical for the hierarchal non hierarchal models.",
            "With the exception that the prediction errors are now supplemented by differences not displaying the data, it's prediction but by all the higher level outputs and their predictions on the basis of each of the levels of the hierarchy.",
            "With that simple generalization here.",
            "Not everything is largely the same as with the non hierarchal form.",
            "If one writes out now again under Gaussian assumptions about those random fluctuations, the priors basically for the probability joint probability on the hidden States and the causal states here, factorizing explicitly over both the levels of the hierarchy structurally and also over the levels of the temporal hierarchy induced by generalized coordinates.",
            "We get this sort of quite nice.",
            "Partition into dynamic priors.",
            "Corresponding to the composition of all these, all these components of the prior probability of the hidden states given the causes causing the dynamics of the hidden states.",
            "An equivalent composition over levels for the structural prize and what this basically means is that the hidden states served to place constraints on motion of their hidden states at lower orders of motion in a hierarchal way, whereas the causes don't really care about the motion, they play the role of providing constraints on the evolution of the causes that are driven by hidden states over lower levels.",
            "So there's a.",
            "There's a if you like.",
            "A dichotomy between the causes V and the hidden states X in terms of their role in mediating the structural priors coming from hierarchical form of the model and the dynamical priors coming from the consideration of these generalized states.",
            "So how can we use this model when all we've got from this specification so far is just?"
        ],
        [
            "Statement of the likelihood.",
            "The form of the generative density in terms of its energy.",
            "The log of the probability of getting some data and some bunch of States and causes and parameters.",
            "So I'm going to briefly rehearse for you.",
            "Sort of conventional variational inversion of these models.",
            "And then in the static context, as a prelude to just slightly extending it to cover this generalized coordinates and the dynamic variation.",
            "Sorry, the dynamic variant of standard variational inversion.",
            "Consider.",
            "Just heuristically, the distinction between sort of a classical variational approach to modeling version, and where it comes from in terms of ensemble learning and ensembles of solutions and use that distinction to motivate something which refer to this variational filtering, and then generalize that or may actually simplify it to give us a sort of fixed form version of that.",
            "The that we will hopefully be able to use to recover.",
            "Posterier conditional densities on the States and the parameters of any arbitrary hierarchical dynamical model of the sort of shown given some data."
        ],
        [
            "So variational learning, forgetting about motion.",
            "OK, this is just about static observation models that may or may not have a hierarchal form.",
            "Does everybody well, that's a silly question.",
            "How many people here are familiar with this?",
            "How many people have never heard of this before?",
            "OK, you lose them really.",
            "You had a minority.",
            "I will go through this quickly.",
            "Skip it so the idea being.",
            "Isn't trying to well, the idea is basically to optimize the evidence for a particular model at the end of the end of the day.",
            "Certainly for us in terms of finding the best models of our data, having established the best model in terms of evidence or integrated likelihood, or the log evidence here, the probability of the model.",
            "Sorry, the data given some model walk and then go into that model and look at the conditional or postira densities on the parameters of states entailed by that model.",
            "However, that computing this log evidence, here's an offer difficult integration problem can be made easier by using a variational free energy bound on the evidence that is afforded by the answer inequality, and we can construct this bound the free energy bound in terms of the log evidence minus this KL divergent between some arbitrary ensemble density of variation density Q here.",
            "And the actual posterior.",
            "We can consider this in terms of physics as comprising Gibbs or internal energy terminal entropy term, and if we can then minimize F. By virtue of the fact that this divergent term is always positive, we have implicitly with respect to Q.",
            "We have implicitly optimized the log evidence, and we can actually use that bound as an approximation to the log evidence for model comparison and the like.",
            "So what form of Q optimizes F?",
            "Well, that's rather simple to show that this is basically is there like a Gibbs or Boltzmann form here, but it is the sorry.",
            "Let me just First off say that in many situations, although it's not necessary, desirable ones obliged to simplify the problem by assuming that this arbitrary form for Q can be factorized.",
            "Khula come to play the role of and be the approximation to the conditional density.",
            "Why's that were quite simply?",
            "Once we've optimized F with suppressed this divergance to its smallest, in which point the Q and the actual posterior should be the same thing.",
            "So optimizing F not only gives us a bound on what we're after, which is the evidence for particular model, but incidentally, because we're optimizing in terms of optimizing the sufficient statistics of Q were also for free, finding the conditional density.",
            "I repeat to make things simpler.",
            "More tractable will normally assumes that this factorizes into variational marginals here, and these are the form of these that minimize optimizes F is basically eat the power of a variational energy where the variational energy is simply the expectation of the energy of the previous part of the talk taken under the Markov blanket of the parameter sets entailed by this mean field approximation here so.",
            "For those of you do this all pretty straightforward.",
            "What I wanted to do, though again, what this may be obvious to many of you, but for those of you who it isn't, it will be important to step through it to understand how we generalize this generalized coordinates.",
            "We're going to do now is this.",
            "Take this solution here.",
            "And show how it also works in the context of a sort of ensemble dynamic approach to finding this approximate.",
            "Conditional density here.",
            "So just reprising the approach for variation loading in temptable assamble learning for steady state and just noting that one can access this Q, the variation density of the approximating conditional density and in terms of the density of an ensemble of particles or solutions to the unknown quantities.",
            "The feature in this model and all that one does is it sets that use."
        ],
        [
            "Of a bunch of particles so they.",
            "Hill climb the free energy sorry variational energy here.",
            "So this being the gradient operator then to ensure they explore the landscape you just put a large value or sort of random term in here.",
            "Temperature of this will depend upon the variance of this.",
            "It has sorry squared world squared squared, two variance, then the solutions 1 gets are exactly the solutions using variational calculus on the previous slide.",
            "So imagine now you've got these particles there just refusing and I'm going to from now on talk about the free energy.",
            "And it's negative physics form so that it goes increases with the log evidence.",
            "So we're just diffusing up the free energy gradients at the same time being dispersed by these random fluctuations here, because the particles are concerned their solutions there are density they describe, or they have a sample density that population or ensemble dynamics is given by the Fokker Planck equation.",
            "If I substitute that expression from the previous slide in the Fokker Planck equation, here these two expressions.",
            "Cancel meeting that we've attained a steady state solution, so I'm just showing you one way to get one way to solve or optimize Q non analytically would be just to use these these ensemble dynamics.",
            "So let's rehearse this.",
            "Now in the context of generalized coordinates."
        ],
        [
            "In generalized coordinates or for systems that now have that are continuous functions of time where both the generating process is as a function of time and the data are going to be continuous functions of time, we're going to extend the notion of optimizing the free energy to optimizing its antiderivative or its path integral.",
            "So I'm just going to find that with the bar on top so that the time derivative of the action here.",
            "It's going to be free energy, using the same variational calculus as we do in conventional variational learning.",
            "What we get out of this is that the.",
            "On some of the solutions that optimize, should you, if you were able to compute them analytically.",
            "For the variational density here, this is basically the exponential of the variational energy, where it.",
            "As before, is simply the expectation under the Markov blanket of the of the states here of the internal energy.",
            "So that just means that it's the energy expected under the approximating conditional of density of the parameters and hyperparameters as it was before.",
            "These are the bits that have changed.",
            "Really.",
            "If we want the conditional density of on the parameters or the hyperparameters here.",
            "Then we have to actually integrate the energy over the entire time series and then adding a prior term that is there before you actually observed any data.",
            "So there may be prior information about the parameters before you actually observe any data, and that's intuitively very sensible.",
            "This focusing here on the conditional density for the states U which is a continuous function of time then can we in the absence of being able to actually compute this expectation here analytically, can we devise a scheme based upon this ensemble learning with particles that will give us the."
        ],
        [
            "The right solution, and that's relatively simple and all all that it requires, is to supplement the static scheme with mean field terms.",
            "Here that correspond to the average flow at any order of motion of all the other particles.",
            "I'll go through this briefly informally, but then give you a much more useful heuristic as to why this should work.",
            "So what I've done here is just build the equations of motion for anyone particle in an infinite ensemble of solutions for the states.",
            "For here just the cause is here, and the equivalent for Planck equation that now is driven or is moving in a frame of reference that corresponds to the sample mean.",
            "Of the ensemble.",
            "And it's quite easy to show that basically when I substitute the expressions from variational calculus from the previous slide into this expression for the ensemble dynamics, we don't get a stationary density.",
            "We can't because the ensemble density is itself changing with time it's moving, and as the data moving as the states evolve.",
            "However, in a moving frame of reference that moves with the mean field modes, here it is stationary and we can see that quite easy just by substituting.",
            "The expression of the previous slide into here and then using a coordinate transform.",
            "Given that we have a moving frame of reference with the velocity, which is just this derivative operator terms of generalized mean of the states.",
            "We can show that the rate of change of the ensemble density is zero stationary in a moving frame of reference.",
            "So heuristically what does that mean?",
            "Well, it it's basically."
        ],
        [
            "Enabling the cloud solutions that's trying to find the peak of the variational energy.",
            "So all these particles are converging and being attracted to moving up the variational gradient variational energy gradients to form a cloud around the peak.",
            "And the dispersion that cloud is actually going to correspond to the conditional precision.",
            "So if the peak is very, very tight and special designed small and there be high conditional precision on this corresponding to the to the conditional density, the problem is in a dynamical system that peak is itself moving.",
            "So by putting in these mean field terms actually had them here mean field terms here, supplementing the ensemble dynamics with these mean field terms that correspond to the average motion overall particles that is seen by every particle.",
            "Then I allow the whole system to move with the peak so that they can basically focus on converging on the on that peak without being left behind, so it allows them to to hit a moving target.",
            "So in this moving peak they can actually get there in an unbiased without being left behind.",
            "I've just shown.",
            "Very simple example here where I've moved the peak according to this black line here, and I've specified some arbitrary function retreat as the variational energy and set off a little bunch.",
            "A little pack of these particles.",
            "I think there were 64 here, and this allowed them to diffuse 2 but move with the peak at the same time, so that after time they surround the peak so their sample density is the conditional mode, which should be faithfully tracking the mode of variational density, which is also.",
            "Of the variation energy, which is also the mode of the variational density and the dispersion, will actually encode the inverse covariance, or that all the conditional precision here.",
            "And I'll show you an example of that that later on.",
            "And in principle this.",
            "Ensemble density.",
            "I will faithfully reproduce any arbitrary form for the variational energy, which means that we have a free form filtering like.",
            "Algorithm or scheme that will approximate.",
            "In real time or online, the conditional density of any arbitrary of any arbitrary form on the unknown states, hidden States and causes of a system.",
            "What I'm going to do is just take you through a simplification to this, which actually is much quicker and then present some brief comparative valuations before closing.",
            "Simplification is that if we assume that the density is actually Gaussian, we don't have to integrate all these stochastic differential equations here to actually generate a free form sample density.",
            "We can just integrate one only differential equation, which is exactly the same as this equation here, but without the random fluctuation, and that basically will give us the mode and then we can work out the.",
            "The covariance would have been had we actually created these particles."
        ],
        [
            "And that comes from."
        ],
        [
            "Middle class approximation and if we can assume that the form of these variation modules here is normal, but in fact the precision becomes an analytic function of the mode, so it's actually very again for those of you know, the plus in the context of variational learning like schemes, this is trivial, but I've just written it out here in full.",
            "If we just write out the expression for the free energy under Gaussian assumptions and facts.",
            "A third order approximation under Gaussian assumptions.",
            "Here we have these recall mean field terms here, which I won't go into.",
            "All I wanted to say was that the weekend is differentiate this with respect to the covariance and sulfur zero.",
            "And what we find is that the.",
            "The precision for each partition is the negative curvature of the energy."
        ],
        [
            "For dynamic models, it's very very similar, if not identical for the states.",
            "For the parameters we actually have to integrate that precision over the duration of time of observed responses and add in the prior, which then just leaves us with finding the mode and all we need to find the mode of the variational energy and actions which are just simple functions of the energy which is prescribed by this hierarchal model that I started off."
        ],
        [
            "With.",
            "So finding the mode is a repeat, exactly like integrating a normal particle, but without removing, freeing it from its random fluctuations, so that hopefully once it finds the mode and it is if you like subject to these mean field.",
            "This mean field guidance in this moving frame of reference that carries along with the mode, it'll just sit there quite happily.",
            "One can show quite easily at least.",
            "Again heuristically, that the for any arbitrary approximating particle that follows this equation here just basically get moves up.",
            "The variational energy gradients and is supplemented by its own generalized motion.",
            "Then the Jacobian, or the rate of change of the velocity with respect to the position of any difference between the true and the approximating mode has.",
            "It's basically negative definite, provided the curvatures is negative and therefore it will at some point converge to the mode and we can use that just too general to produce update equations for the states we use something based on the sock is sort of integration, schemas, gastric differential equation, or integration scheme under local linearization assumptions to provide updates so that after a couple of updates.",
            "One hopes that one's approximate load will actually converge to the true mode."
        ],
        [
            "And then we can just compute the curvature and then one gets the conditional covariance for free.",
            "Then you've got the entire normal form for the ensemble densities.",
            "Just finally before we look at the examples.",
            "Another intuitive perspective on this on this supplement, this augmentation of the flow of the flow of the mode, or the approximating mode by its own generalized motion.",
            "One can regard it as basically simple gradient descent, so the rate of change of the approximating mode here is just the variational is a great dissent on the variational energy.",
            "The variational energy differentiated with respect to the states here.",
            "But is supplemented by its motion so that this motion is itself defined by itself.",
            "It's just another form of itself.",
            "Looks at the form of that and then looks at the the what happens when we hit the mode.",
            "We actually conceive that the solution to this has to maximize variation lemma action by the fundamental lemma, and it's exactly the same as Hamilton's principle of strange reaction, and it is for when this is true, then the velocity of the stage becomes the 1st order generalized motion.",
            "So this is where they come back together again.",
            "Under Hamilton's principle station reaction, so we got this scheme."
        ],
        [
            "Where we've we've got these this mean field partition into states, parameters, and hyperparameters.",
            "We can cycle through overtime points.",
            "The states in this online way to integrate this equation that I showed in the previous slide to optimize the modes of the unknown causal hidden States and compute their precision with that information.",
            "We can integrate that and then optimize the OR update the.",
            "Conditional modes and precision of the parameters and the hyperparameters using exactly this equation.",
            "But we don't have to worry about the time dependent aspects and then just iterate around that in the usual way until we've optimized the overall free energy and then we've got a conditional density on the parameters, the hyperparameters, the states of our system."
        ],
        [
            "So I'm going to just demonstrate this.",
            "Start first of all, using a very simple linear conval."
        ],
        [
            "Russian model that starts off with some cause here.",
            "It'll bump function that perturbs 2 hidden states that are coupled to produce this very simple linear little transient that's mapped linearly to four outputs to generate data, and we're going to try to invert this model to get at the conditional density on this unknown cause here.",
            "And I've cartoon the sort of scheme that is implicit under these.",
            "Under the plus approximation, which is basically just all about minimizing prediction error in hierarchical context with which can be can be formulated in terms of message passing and also neurological terms, which is why the brain underneath."
        ],
        [
            "So first of all, I'm going to show you exactly that system."
        ],
        [
            "Given just the data and the form of the model, can I now estimate the time dependent condition densities on the hidden states?",
            "There are two of them here and the single cores.",
            "Online."
        ],
        [
            "In one pass, using the variational filtering, so I'm not actually using that on sambol like understanding of ensemble learning as a algorithmics scheme to get a sample density that I can use as a conditional conditional density on the states.",
            "Here the hidden States and here are the unknown causes and I think there are 16 particles here and what I've done here is just reported.",
            "The mean here and the sample density at each time point of these particles on the cores and the two hidden states in this format here."
        ],
        [
            "Because in the next slide wanted to show you the comparison of the inversion or deconvolution.",
            "Using this variational filtering.",
            "With exactly the same data and exactly the same model, but using the Laplace approximation or the Dems sort of variational scheme.",
            "So the difference between these two here is that this one we've actually generated sample density by integrating these stochastic differential equations, whereas here we just integrated one particle, which we fondly hope tracks the mode by omitting the stochastic part here and integrating this.",
            "Order differential equation here, but otherwise they're identical and what we see is that the means are actually remarkably similar as one would hope, as are the conditional.",
            "Confidence intervals here based on the conditional precision or covariance as they should be because we actually use Gaussian random terms to generate the data, and there's a linear model, so there should be no surprise there."
        ],
        [
            "This just shows you the dependence of the kualiti or the accuracy of the inversion of the data.",
            "I just showed you on the number of.",
            "Or the order of the generalized motion that we consider.",
            "If you recall, the precision tails off after about the.",
            "5th or 6th High order motion, which basically means that it doesn't matter if we keep the prediction errors at that level or order, they're not going to do anything 'cause there's no precision in them at all.",
            "They don't contribute to the energy they don't contribute to the variational energy, and they don't contribute to the scheme.",
            "And we can demonstrate that quite easily just by using in the limiting case or just one.",
            "Just which correspond to conventional state space model.",
            "So there's one order of motion measuring the actual sum squared error given the true data and then increasing the order of here up until 13 years.",
            "And we can see that we get our best returns of four up to about five.",
            "As for the smoothness of data, which I've usually games, gamma is equal to four.",
            "To generate these data reflect.",
            "This generally holds that we don't normally need to go beyond eight orders or 8 dimensional generalized spaces of motion there.",
            "These are just the fits for the causes with N equals one and equals 7.",
            "This would be more conventional state space model we use.",
            "Thank you like Kalman filter or something like that."
        ],
        [
            "In fact, yeah, here sort of comparative valuations and extended common filtering using Dem where we actually told it that the random fluctuations were venal.",
            "I can have no correlations as opposed to telling the scheme what the actual correlations were, which was basically a precision of four or some deviation of 1/2 on the auto correlation function of the random states.",
            "One can see the progressive improvement just to note that when.",
            "You actually reduce end to one, and you tell the Dem scheme that there are no correlations.",
            "You get exactly the same results as Camel filter as you should do, which will be optimal if there weren't any correlations."
        ],
        [
            "In the random.",
            "In the random components very briefly, this is a nonlinear variation of the demonstration I just showed you this to show how it copes and compare its performance with particle filtering in the context of a nonlinear system, this is a sort of quasi double well, but we have actually forced to occupy 1 one of the two wells to focus on the how the covariance depends upon the nonlinearities.",
            "So that we could compare extended camera filter."
        ],
        [
            "Particle filtering and the variation scheme that I've showed you here notice that this is an analogue scale, so that you particle filtering and variational filtering are much better on average than."
        ],
        [
            "Spending particle Kalman filtering as one might anticipate.",
            "This is just to show the estimation of parameters and states at the same time as a prelude."
        ],
        [
            "2."
        ],
        [
            "Applying these techniques to an actual empirical example where we studied the brain responses of human subject while they were either paying attention or not to moving starfield and thereafter.",
            "Detect any changes in the velocity of these dots that move towards them even though there weren't any actual changes.",
            "The construction of the model that we actually uses basically was based upon."
        ],
        [
            "Known hemodynamics I won't go into this other than to use it as an example of a nonlinear dynamical system that converts in your own activity into measured brain signals that we measured with brain that we measure with brain imaging sufficient.",
            "Critically, it's a bit nonlinear, which is why I'm using it as an empirical example of a non linear convolution model.",
            "The inputs here will basically whether there was a visual input in the field whether input was moving, and whether the subject was paying attention and parameterized.",
            "These in terms of feature here.",
            "Sort of gating variables entered into this system to generate changes in hemodynamics and blood flow and hemoglobin changes.",
            "Actually give us a cig."
        ],
        [
            "Here and here are the results that here in the States after deconvolution and hear the parameters showing that certainly for visual stimulus and motion we can April story be very confident that these were non true."
        ],
        [
            "Real effects, and there's a closer look at the dynamics.",
            "Showing the changes in various blood flow and the."
        ],
        [
            "Dream catcher."
        ],
        [
            "Sticks and I just conclude with an example of this in a sort of more theoretical role where what we've done here is simulate Birdsongs could we play that is that we have sound.",
            "Yeah.",
            "Oh, here it is.",
            "So if I were to.",
            "Navigate it over the.",
            "Perhaps not, but it doesn't matter if.",
            "The So what we've done here is simulate a bird.",
            "Bye.",
            "Taking a Lorentz attractor and extracting two of the states to modulate muscle tone here, that would normally be controlling the frequency of the chirp that the bed was producing and the amplitude.",
            "So taking the frequency and the amplitude from two states of Lorenz attractor to produce birds at bird song of sequence of chirps here that have which you can just about see in this sonogram where this frequency misses time and I had hoped to be able to play.",
            "The church is so you can actually hear this thing singing team.",
            "What we've also done here though, is not just allowed this.",
            "The the deterministic chaos of the attracted us to drive a sequence of chips, which would be the song.",
            "But the control parameters of this dynamical system here are themselves generated by another rents a tractor.",
            "So now we have hopefully a sequence of sequences, and so we have basically a sequence of bird songs, and then we've used this scheme to invert the sonogram.",
            "Here the heard auditory information to see if we can get back at which sequence was being played.",
            "Only one time, but more importantly for you, I just wanted to demonstrate."
        ],
        [
            "Going to try it.",
            "I mean yes, early.",
            "Have to find the cursor first.",
            "That was probably what happened.",
            "Yeah.",
            "Now how do we get?",
            "Laptop.",
            "I could whistle it.",
            "Yes.",
            "Anywhere well out of time, so let's not waste about this time.",
            "I can't know.",
            "Look, maybe I'm touching something.",
            "Wow, nice.",
            "OK, let's just leave it on this slide here then.",
            "That's good, the previous slide did show you the true and the in Ferd conditional densities on the time dependent states.",
            "Both the hierarchical levels of this system.",
            "The first one governing the sonogram dancer, the sonogram and II governing which of the songs this high level events are tractor was going to switch on or switch off, but the real reason I want."
        ],
        [
            "To show you this was just to entertain you and also give you a feeling for what would happen if you took away these two sources of prior constraints that that in this model that if we if we now lesion.",
            "The hierarchy, so we chop off the input from the second Lorentz attractor so that now there are no structural prize of the synthetic bird listening or recognizing the song now doesn't know that the song should change in accord with a Lorenz attractor.",
            "So it now has no knowledge of the evolution of the chirps as yes, it's listening to the chirps.",
            "We can look at the contribution of these.",
            "So here's what this song, actually.",
            "And this very ginger link as I accidentally changed the this is what the song actually sounds like and when correctly inverted, the bird actually hears.",
            "So that's two Lorenz attractors, one governing the other one.",
            "So that's a very radical perception.",
            "If I now remove this sort of higher order empirical.",
            "OK, you probably felt the first one.",
            "OK, so two part is it.",
            "I mean, it's actually not right.",
            "It's not getting these high frequency chirps up here, but it's not too bad.",
            "If I did something really awful to it and cut all its temporal priors by removing the generalized motion so I'm collapsing back down to N is equal to 1.",
            "Then it's perception.",
            "Is very sick, so failing to complete completely, failing to capture any of adamik."
        ],
        [
            "And that's it.",
            "Thank you very much for attention.",
            "Questioning.",
            "It seemed like that was what you were all your variables time.",
            "Anyway, it was your first or should mention in this case, not actually the 100 relative or every point in the inversion scheme."
        ],
        [
            "So for example, this is the mode of causes at the second level, which corresponds to states to the states of rents.",
            "Sorry, one of the states of Lorentz attractor for each point here anymore.",
            "Instant in time they will actually be 8 numbers corresponding to encoding the local trajectory of this path in terms of of the first, second, 3rd update order motion.",
            "Now the actual trajectory that that path is actually encoded at incident time is not necessarily the actual path that the actual state itself follows.",
            "In a sense, the corrections to that path is what the scheme is doing.",
            "Generalized generalized, these are temporal differences.",
            "You take the data so not well practically, you could look at it like that.",
            "It's a generative model.",
            "So what?",
            "You're trying to generate.",
            "The generative model, but yeah.",
            "And what are the primed data points?",
            "Well, the data are in this instance there, so sparsely sampled discrete observations at one point in time, and then a sequence of time points.",
            "So I can generate those data from any point in time and generalized coordinates with local precision.",
            "So for example, let's take the first 10 time bins where I've actually got sort of 1 dimensional data or two dimensional data.",
            "In the sonogram example here, so I've got 8.",
            "Time eight time bins now at say 4.3 two seconds.",
            "I will have a representation of the conditional density and generalized coordinates.",
            "So by Taylor's theorem I can now generate the predictions at each of those time points in the past and in the future.",
            "So I generate locally a projection of the path encoding generalized coordinates onto a discreetly.",
            "Sort of sample timeline.",
            "So that's right.",
            "And then I just move along to the next well.",
            "Natural small as I want to make it depending on that sort of.",
            "Getting dementia, yeah, absolutely yeah yeah.",
            "Very much so.",
            "In fact, I think on the slides actually refer to N as the embedding dimension.",
            "Yeah, yeah.",
            "Yeah.",
            "Let's start again at the top class."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a great pleasure to be here, not least because I very seldom get invited to talk to machine learning audiences, and that to be precise, as a first time that I've spoken to machine learning audience.",
                    "label": 0
                },
                {
                    "sent": "So if I use the wrong words, please forgive me and pretend I was using the right words.",
                    "label": 0
                },
                {
                    "sent": "I'm actually neuro scientist and the work that I'm going to overview for you has two agendas.",
                    "label": 0
                },
                {
                    "sent": "First, my unit is responsible for the analysis of biological Time series data specifically.",
                    "label": 0
                },
                {
                    "sent": "You're imaging data.",
                    "label": 0
                },
                {
                    "sent": "So much of what I'm showing you is building up on work that enables us to make inferences about the about models of biological time series.",
                    "label": 0
                },
                {
                    "sent": "But at the same time, we're also interested in these inversion schemes or optimization schemes as metaphors for how the brain actually works.",
                    "label": 0
                },
                {
                    "sent": "So that's sort of a jewel accountability of the work that I'm going to summarize for you at this afternoon, and it might be useful to bat in Michael's it'll it'll pop up.",
                    "label": 0
                },
                {
                    "sent": "From time to time, so I'm going to talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First of all, about the nature of the models that we deal with.",
                    "label": 0
                },
                {
                    "sent": "I repeat, there really models for biological systems formatted in continuous time, specifically focusing on the dynamics and introducing generalized coordinates to the formulation of these causal models or state space models.",
                    "label": 0
                },
                {
                    "sent": "And the dynamical priors that these generalized coordinates entail and how they can be useful in providing constraints on the sorts of data that are generated on the optimization or the fitting of the models that are using.",
                    "label": 0
                },
                {
                    "sent": "I'm going to recapitulate or repeat the sort of dynamical priors in terms of the structures of the models by lending them a hierarchical forms are going to be considering state space models or dynamic.",
                    "label": 0
                },
                {
                    "sent": "Calls and models formulated continuous time that have a hierarchical structure, so the outputs of 1 dynamical system actors control parameters or inputs to a subordinate one and so on and so forth to any arbitrary depth having set up the model and the form of the energy functions that these models imply considering the inversion of these models or the recovery of the conditional densities or approximations to those conditional densities on the state of these models and their parameters.",
                    "label": 0
                },
                {
                    "sent": "And hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "I'm going to briefly mention two approaches.",
                    "label": 0
                },
                {
                    "sent": "One is a simplification of the other, the first variational filtering, which doesn't assume any parametric form for the densities that we're trying to identify.",
                    "label": 0
                },
                {
                    "sent": "And then a Laplace approximation or assuming the density Gaussian form, we can actually simplify this variational filtering and get this fixed form scheme here briefly to present some comparative evaluations.",
                    "label": 1
                },
                {
                    "sent": "And then finish.",
                    "label": 0
                },
                {
                    "sent": "If I have time with two entered, well, I find meditating 2 examples.",
                    "label": 0
                },
                {
                    "sent": "One which is an empirical one inverting.",
                    "label": 0
                },
                {
                    "sent": "The OR trying to recover neuronal states that are causing observed brain imaging signals and the other one returned to this notion that the brain might actually use these schemes to invert sensory data to disclose the causes.",
                    "label": 0
                },
                {
                    "sent": "The environmental causes of those data and that example we use Birdsongs, so the source.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Models that are going to be dealing with a very simple state space models in equation form here and in terms of Bayesian dependency graphs here where the data are Y that are generated by hidden states that have dynamics where those dynamics are perturbed by causes or sources.",
                    "label": 0
                },
                {
                    "sent": "V here the functions governing the equations of motion of the hidden states here are parameterized by Theta and their random fluctuations on both the observed data.",
                    "label": 0
                },
                {
                    "sent": "And the hidden states got here by Zedd and W.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I should just make a comment about notation just to simplify things X dot.",
                    "label": 0
                },
                {
                    "sent": "Obviously ready change of X with respect to T, but I'm also going to be talking about generalized motion or motion in generalized coordinates, so the X~ means a state and its first order generalized motion, 2nd order acceleration, and so on to arbitrarily high orders in motion.",
                    "label": 0
                },
                {
                    "sent": "It's important to realize that the.",
                    "label": 0
                },
                {
                    "sent": "At the 1st order, motion is not the speed of movement of the position.",
                    "label": 0
                },
                {
                    "sent": "So if one is lucky of one, as we'll see later under special constraints, the 1st order motion will actually be the velocity of the position.",
                    "label": 0
                },
                {
                    "sent": "That is not generally the case.",
                    "label": 0
                },
                {
                    "sent": "So when I do a neck still there, I'm implying a whole infinite set or series of high order motions which are also indicate with the superscript in square brackets.",
                    "label": 0
                },
                {
                    "sent": "Here again, subscript X means a derivative in the usual way.",
                    "label": 0
                },
                {
                    "sent": "Definition For 1st order motion.",
                    "label": 0
                },
                {
                    "sent": "First, the definition is just, it's the.",
                    "label": 0
                },
                {
                    "sent": "Sort of definition, but an analogy here would be like momentum in physics.",
                    "label": 0
                },
                {
                    "sent": "So you have position of amentum.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is that unless you invoke.",
                    "label": 0
                },
                {
                    "sent": "Stationality principles not Hamilton stationary principles.",
                    "label": 0
                },
                {
                    "sent": "You can't necessarily assume that the rate of change of the position corresponds to the momentum at some scale, but we will see that he does for the most of the dances later on.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just put the tillers on there 'cause they're going to become quite important, but I just wanted to indicate here in this slide was the generalization in terms of the form of these models from a state space model to a hierarchal version of this where the input now becomes the output of a super ordinate dynamical system, that's all I mean by hierarchal formally.",
                    "label": 0
                },
                {
                    "sent": "Imagine repeating that hierarchy to any arbitrary number of hierarchical levels.",
                    "label": 0
                },
                {
                    "sent": "I've just sketched in here the conditional densities entailed by these edges.",
                    "label": 0
                },
                {
                    "sent": "Here in this graph, but I'm going to go through those insight more detail in the next couple of slides just show you where they come from with a focus.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first instance on the temporal dependencies and dependencies that are given by considering the evolution of these systems within generalized coordinates.",
                    "label": 0
                },
                {
                    "sent": "So what I've done here this is simply re write out a non hierarchical form of state space model rate of change of X is some function plus some random fluctuations and then we observe some generally nonlinear static observer function of the States and the causes.",
                    "label": 0
                },
                {
                    "sent": "But critically, noting that this these model specification induces an infinite series of constraints in terms of the higher order generalized motion.",
                    "label": 0
                },
                {
                    "sent": "So if I just differentiate both sides of this equation here to 1st order, I can now express a relationship between the 2nd order motion, the 1st order motion and simulate this third automation and the 1st order motion that are all generated by.",
                    "label": 0
                },
                {
                    "sent": "The derivatives repeat just the 1st order here of the original functions F and similarly for G here, which means that we have in principle alot of formal information.",
                    "label": 0
                },
                {
                    "sent": "That comes for free as embedded in this model that is realized when one considers the evolution of the dynamics in generalized coordinates here.",
                    "label": 0
                },
                {
                    "sent": "And I can write that quite compactly just by saying that the generalized motion of Y is equal to its generalized prediction plus the equivalent generalized motion of the random fluctuation and then the D operator.",
                    "label": 0
                },
                {
                    "sent": "Here's a derivative operator that just shifts generalized motion up, so the 1st order motion.",
                    "label": 0
                },
                {
                    "sent": "Is a function of the of the.",
                    "label": 0
                },
                {
                    "sent": "The generalized states X here plus some random fluctuations where again this is a generalized prediction of the generalized motion here, which comes simply or can be drive very trivially from the first derivatives of these functions.",
                    "label": 0
                },
                {
                    "sent": "Here this is this is this.",
                    "label": 0
                },
                {
                    "sent": "In regard as a derivative operator or sort of.",
                    "label": 0
                },
                {
                    "sent": "Diagonal matrix operate here.",
                    "label": 0
                },
                {
                    "sent": "That just shifts these the lower higher order motion into the position of a lower order motion and write it out like that.",
                    "label": 0
                },
                {
                    "sent": "What can see immediately that we have a form.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we assume that Zed had a Gaussian distribution, we have specified implicitly a density on waiora likelihood the probability of Y given the causes.",
                    "label": 0
                },
                {
                    "sent": "X&V in generalized coordinates in terms of the expectation that generalized prediction here and some covariance on the fluctuations, generalized fluctuations here and similarly we have a prior density that is furnished by the equations of motion that covers not just the 1st order motion or the velocity of the states itself, but also to our higher orders, which depends upon the covariance.",
                    "label": 0
                },
                {
                    "sent": "Of the state noise here in higher order motion, and that's useful in the sense that if there is a finite variance on high order motion of the fluctuations, we can actually use this and it becomes an integral part of the inherent part, or both the likelihood and prior, which will be absolutely critical when it comes to optimize your finding.",
                    "label": 0
                },
                {
                    "sent": "The maximum per story estimators of the states, or indeed the parameters governing.",
                    "label": 0
                },
                {
                    "sent": "Control in the form of these equations here so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This slide just makes that explicit and I'm just written out here under Gaussian assumptions about those random fluctuations.",
                    "label": 0
                },
                {
                    "sent": "The energy at any one point in time which I'm going to do it by you being the log of the joint probability of the observed data and their underlying causes the.",
                    "label": 0
                },
                {
                    "sent": "Cause.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since I'm going to lump together as you so the hidden States and the causes here, I'm going to lump together as general General States you here.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, sometimes we refer to these States and the parameters of these equations and the random terms at theater here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looks like so.",
                    "label": 0
                },
                {
                    "sent": "This actually has a terribly simple form under Gaussian assumptions.",
                    "label": 0
                },
                {
                    "sent": "It's just basically the error terms of the differences between the predictions and the observed.",
                    "label": 0
                },
                {
                    "sent": "Sandwich between the precision and it's the precision which is interesting here, because the precision doesn't just cover the precision of the random fluctuations of the values themselves, but also their generalized motion, and we can derive those quite simply from the covariance of the higher order motion.",
                    "label": 0
                },
                {
                    "sent": "In terms of the correlation function on the random fluctuations themselves, and this know that this takes us away from any sort of ina like process or any model that relies upon independence of the increments or the the differences in the random fluctuations between time one and some other point in time.",
                    "label": 0
                },
                {
                    "sent": "We're actually here dealing with biologically, or at least by physically realistic processes that are continuous differentiable, have autocorrelation functions, and these enter as random.",
                    "label": 0
                },
                {
                    "sent": "Terms into the model and they have well defined correlation functions and that means they actually have a well defined precision over generalized coordinates that is given by sort of classical theory of stochastic processes.",
                    "label": 0
                },
                {
                    "sent": "I've written it out generally generally here in terms of the high order derivatives of the auto correlation function for Gaussian form with precision parameter.",
                    "label": 0
                },
                {
                    "sent": "Gamma has this simple form here, and I'm just showing an image representation of this covariant or precision matrix.",
                    "label": 0
                },
                {
                    "sent": "If this is the covariance in the inverse precision matrix for a Gaussian form where gamma is equal to four, which means that the correlations have a correlation length of about half a time bin and what we see here is that the precisions fall off as the thing gets as we go into higher order motion.",
                    "label": 0
                },
                {
                    "sent": "Generally rougher it gets the precision of the higher order terms gets large very very quickly, which is good because we can throw those away.",
                    "label": 0
                },
                {
                    "sent": "In the practical sense, this is the equivalent used using simple Taylor expansion.",
                    "label": 0
                },
                {
                    "sent": "This is the equivalent decision matrix overtime, so this is the precision into the past and into the future from a current time point.",
                    "label": 0
                },
                {
                    "sent": "That's going to become relevant later, because what this says in this particular form of generative model at this instant in time generates data that is only precisely specified locally in time, and that's gonna be quite useful practically when it comes to inverting these models, 'cause it means that.",
                    "label": 0
                },
                {
                    "sent": "We can deal with or just process data that is local to time and we can effectively emulate an online scheme but retain the benefits of a Bayesian smoother as opposed to a Bayesian filter.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's the brief overview introduction to this sort of.",
                    "label": 0
                },
                {
                    "sent": "To generalized coordinates and precisions in temple and generalized coordinates and how they enter the specification of the likelihood or the energy.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to draw a parallel here in terms of.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the what they bring to the model between these dynamical prize and the hierarchal extension which gives you these structural prize when we take a sort of hierarchal extension of this state space model here, which I've just indicated by having superscripts in curly brackets at the top here, where we have the data here that's generated by a state space model where the inputs to the hidden states at the first level are the outputs from a super ordinate dynamical system.",
                    "label": 0
                },
                {
                    "sent": "And so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "All the formalism both would have just shown, and what I will show is absolutely identical for the hierarchal non hierarchal models.",
                    "label": 0
                },
                {
                    "sent": "With the exception that the prediction errors are now supplemented by differences not displaying the data, it's prediction but by all the higher level outputs and their predictions on the basis of each of the levels of the hierarchy.",
                    "label": 0
                },
                {
                    "sent": "With that simple generalization here.",
                    "label": 0
                },
                {
                    "sent": "Not everything is largely the same as with the non hierarchal form.",
                    "label": 0
                },
                {
                    "sent": "If one writes out now again under Gaussian assumptions about those random fluctuations, the priors basically for the probability joint probability on the hidden States and the causal states here, factorizing explicitly over both the levels of the hierarchy structurally and also over the levels of the temporal hierarchy induced by generalized coordinates.",
                    "label": 0
                },
                {
                    "sent": "We get this sort of quite nice.",
                    "label": 0
                },
                {
                    "sent": "Partition into dynamic priors.",
                    "label": 0
                },
                {
                    "sent": "Corresponding to the composition of all these, all these components of the prior probability of the hidden states given the causes causing the dynamics of the hidden states.",
                    "label": 0
                },
                {
                    "sent": "An equivalent composition over levels for the structural prize and what this basically means is that the hidden states served to place constraints on motion of their hidden states at lower orders of motion in a hierarchal way, whereas the causes don't really care about the motion, they play the role of providing constraints on the evolution of the causes that are driven by hidden states over lower levels.",
                    "label": 0
                },
                {
                    "sent": "So there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a if you like.",
                    "label": 0
                },
                {
                    "sent": "A dichotomy between the causes V and the hidden states X in terms of their role in mediating the structural priors coming from hierarchical form of the model and the dynamical priors coming from the consideration of these generalized states.",
                    "label": 0
                },
                {
                    "sent": "So how can we use this model when all we've got from this specification so far is just?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Statement of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "The form of the generative density in terms of its energy.",
                    "label": 0
                },
                {
                    "sent": "The log of the probability of getting some data and some bunch of States and causes and parameters.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to briefly rehearse for you.",
                    "label": 0
                },
                {
                    "sent": "Sort of conventional variational inversion of these models.",
                    "label": 0
                },
                {
                    "sent": "And then in the static context, as a prelude to just slightly extending it to cover this generalized coordinates and the dynamic variation.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the dynamic variant of standard variational inversion.",
                    "label": 0
                },
                {
                    "sent": "Consider.",
                    "label": 0
                },
                {
                    "sent": "Just heuristically, the distinction between sort of a classical variational approach to modeling version, and where it comes from in terms of ensemble learning and ensembles of solutions and use that distinction to motivate something which refer to this variational filtering, and then generalize that or may actually simplify it to give us a sort of fixed form version of that.",
                    "label": 0
                },
                {
                    "sent": "The that we will hopefully be able to use to recover.",
                    "label": 0
                },
                {
                    "sent": "Posterier conditional densities on the States and the parameters of any arbitrary hierarchical dynamical model of the sort of shown given some data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So variational learning, forgetting about motion.",
                    "label": 1
                },
                {
                    "sent": "OK, this is just about static observation models that may or may not have a hierarchal form.",
                    "label": 0
                },
                {
                    "sent": "Does everybody well, that's a silly question.",
                    "label": 0
                },
                {
                    "sent": "How many people here are familiar with this?",
                    "label": 0
                },
                {
                    "sent": "How many people have never heard of this before?",
                    "label": 0
                },
                {
                    "sent": "OK, you lose them really.",
                    "label": 0
                },
                {
                    "sent": "You had a minority.",
                    "label": 0
                },
                {
                    "sent": "I will go through this quickly.",
                    "label": 0
                },
                {
                    "sent": "Skip it so the idea being.",
                    "label": 0
                },
                {
                    "sent": "Isn't trying to well, the idea is basically to optimize the evidence for a particular model at the end of the end of the day.",
                    "label": 0
                },
                {
                    "sent": "Certainly for us in terms of finding the best models of our data, having established the best model in terms of evidence or integrated likelihood, or the log evidence here, the probability of the model.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the data given some model walk and then go into that model and look at the conditional or postira densities on the parameters of states entailed by that model.",
                    "label": 0
                },
                {
                    "sent": "However, that computing this log evidence, here's an offer difficult integration problem can be made easier by using a variational free energy bound on the evidence that is afforded by the answer inequality, and we can construct this bound the free energy bound in terms of the log evidence minus this KL divergent between some arbitrary ensemble density of variation density Q here.",
                    "label": 1
                },
                {
                    "sent": "And the actual posterior.",
                    "label": 0
                },
                {
                    "sent": "We can consider this in terms of physics as comprising Gibbs or internal energy terminal entropy term, and if we can then minimize F. By virtue of the fact that this divergent term is always positive, we have implicitly with respect to Q.",
                    "label": 1
                },
                {
                    "sent": "We have implicitly optimized the log evidence, and we can actually use that bound as an approximation to the log evidence for model comparison and the like.",
                    "label": 0
                },
                {
                    "sent": "So what form of Q optimizes F?",
                    "label": 0
                },
                {
                    "sent": "Well, that's rather simple to show that this is basically is there like a Gibbs or Boltzmann form here, but it is the sorry.",
                    "label": 0
                },
                {
                    "sent": "Let me just First off say that in many situations, although it's not necessary, desirable ones obliged to simplify the problem by assuming that this arbitrary form for Q can be factorized.",
                    "label": 0
                },
                {
                    "sent": "Khula come to play the role of and be the approximation to the conditional density.",
                    "label": 0
                },
                {
                    "sent": "Why's that were quite simply?",
                    "label": 0
                },
                {
                    "sent": "Once we've optimized F with suppressed this divergance to its smallest, in which point the Q and the actual posterior should be the same thing.",
                    "label": 0
                },
                {
                    "sent": "So optimizing F not only gives us a bound on what we're after, which is the evidence for particular model, but incidentally, because we're optimizing in terms of optimizing the sufficient statistics of Q were also for free, finding the conditional density.",
                    "label": 0
                },
                {
                    "sent": "I repeat to make things simpler.",
                    "label": 0
                },
                {
                    "sent": "More tractable will normally assumes that this factorizes into variational marginals here, and these are the form of these that minimize optimizes F is basically eat the power of a variational energy where the variational energy is simply the expectation of the energy of the previous part of the talk taken under the Markov blanket of the parameter sets entailed by this mean field approximation here so.",
                    "label": 0
                },
                {
                    "sent": "For those of you do this all pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "What I wanted to do, though again, what this may be obvious to many of you, but for those of you who it isn't, it will be important to step through it to understand how we generalize this generalized coordinates.",
                    "label": 0
                },
                {
                    "sent": "We're going to do now is this.",
                    "label": 0
                },
                {
                    "sent": "Take this solution here.",
                    "label": 0
                },
                {
                    "sent": "And show how it also works in the context of a sort of ensemble dynamic approach to finding this approximate.",
                    "label": 0
                },
                {
                    "sent": "Conditional density here.",
                    "label": 0
                },
                {
                    "sent": "So just reprising the approach for variation loading in temptable assamble learning for steady state and just noting that one can access this Q, the variation density of the approximating conditional density and in terms of the density of an ensemble of particles or solutions to the unknown quantities.",
                    "label": 0
                },
                {
                    "sent": "The feature in this model and all that one does is it sets that use.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of a bunch of particles so they.",
                    "label": 0
                },
                {
                    "sent": "Hill climb the free energy sorry variational energy here.",
                    "label": 0
                },
                {
                    "sent": "So this being the gradient operator then to ensure they explore the landscape you just put a large value or sort of random term in here.",
                    "label": 0
                },
                {
                    "sent": "Temperature of this will depend upon the variance of this.",
                    "label": 0
                },
                {
                    "sent": "It has sorry squared world squared squared, two variance, then the solutions 1 gets are exactly the solutions using variational calculus on the previous slide.",
                    "label": 1
                },
                {
                    "sent": "So imagine now you've got these particles there just refusing and I'm going to from now on talk about the free energy.",
                    "label": 0
                },
                {
                    "sent": "And it's negative physics form so that it goes increases with the log evidence.",
                    "label": 0
                },
                {
                    "sent": "So we're just diffusing up the free energy gradients at the same time being dispersed by these random fluctuations here, because the particles are concerned their solutions there are density they describe, or they have a sample density that population or ensemble dynamics is given by the Fokker Planck equation.",
                    "label": 1
                },
                {
                    "sent": "If I substitute that expression from the previous slide in the Fokker Planck equation, here these two expressions.",
                    "label": 0
                },
                {
                    "sent": "Cancel meeting that we've attained a steady state solution, so I'm just showing you one way to get one way to solve or optimize Q non analytically would be just to use these these ensemble dynamics.",
                    "label": 0
                },
                {
                    "sent": "So let's rehearse this.",
                    "label": 0
                },
                {
                    "sent": "Now in the context of generalized coordinates.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In generalized coordinates or for systems that now have that are continuous functions of time where both the generating process is as a function of time and the data are going to be continuous functions of time, we're going to extend the notion of optimizing the free energy to optimizing its antiderivative or its path integral.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to find that with the bar on top so that the time derivative of the action here.",
                    "label": 1
                },
                {
                    "sent": "It's going to be free energy, using the same variational calculus as we do in conventional variational learning.",
                    "label": 1
                },
                {
                    "sent": "What we get out of this is that the.",
                    "label": 0
                },
                {
                    "sent": "On some of the solutions that optimize, should you, if you were able to compute them analytically.",
                    "label": 0
                },
                {
                    "sent": "For the variational density here, this is basically the exponential of the variational energy, where it.",
                    "label": 1
                },
                {
                    "sent": "As before, is simply the expectation under the Markov blanket of the of the states here of the internal energy.",
                    "label": 0
                },
                {
                    "sent": "So that just means that it's the energy expected under the approximating conditional of density of the parameters and hyperparameters as it was before.",
                    "label": 0
                },
                {
                    "sent": "These are the bits that have changed.",
                    "label": 0
                },
                {
                    "sent": "Really.",
                    "label": 0
                },
                {
                    "sent": "If we want the conditional density of on the parameters or the hyperparameters here.",
                    "label": 0
                },
                {
                    "sent": "Then we have to actually integrate the energy over the entire time series and then adding a prior term that is there before you actually observed any data.",
                    "label": 0
                },
                {
                    "sent": "So there may be prior information about the parameters before you actually observe any data, and that's intuitively very sensible.",
                    "label": 0
                },
                {
                    "sent": "This focusing here on the conditional density for the states U which is a continuous function of time then can we in the absence of being able to actually compute this expectation here analytically, can we devise a scheme based upon this ensemble learning with particles that will give us the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The right solution, and that's relatively simple and all all that it requires, is to supplement the static scheme with mean field terms.",
                    "label": 0
                },
                {
                    "sent": "Here that correspond to the average flow at any order of motion of all the other particles.",
                    "label": 0
                },
                {
                    "sent": "I'll go through this briefly informally, but then give you a much more useful heuristic as to why this should work.",
                    "label": 0
                },
                {
                    "sent": "So what I've done here is just build the equations of motion for anyone particle in an infinite ensemble of solutions for the states.",
                    "label": 1
                },
                {
                    "sent": "For here just the cause is here, and the equivalent for Planck equation that now is driven or is moving in a frame of reference that corresponds to the sample mean.",
                    "label": 0
                },
                {
                    "sent": "Of the ensemble.",
                    "label": 0
                },
                {
                    "sent": "And it's quite easy to show that basically when I substitute the expressions from variational calculus from the previous slide into this expression for the ensemble dynamics, we don't get a stationary density.",
                    "label": 1
                },
                {
                    "sent": "We can't because the ensemble density is itself changing with time it's moving, and as the data moving as the states evolve.",
                    "label": 1
                },
                {
                    "sent": "However, in a moving frame of reference that moves with the mean field modes, here it is stationary and we can see that quite easy just by substituting.",
                    "label": 0
                },
                {
                    "sent": "The expression of the previous slide into here and then using a coordinate transform.",
                    "label": 0
                },
                {
                    "sent": "Given that we have a moving frame of reference with the velocity, which is just this derivative operator terms of generalized mean of the states.",
                    "label": 1
                },
                {
                    "sent": "We can show that the rate of change of the ensemble density is zero stationary in a moving frame of reference.",
                    "label": 1
                },
                {
                    "sent": "So heuristically what does that mean?",
                    "label": 0
                },
                {
                    "sent": "Well, it it's basically.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Enabling the cloud solutions that's trying to find the peak of the variational energy.",
                    "label": 0
                },
                {
                    "sent": "So all these particles are converging and being attracted to moving up the variational gradient variational energy gradients to form a cloud around the peak.",
                    "label": 0
                },
                {
                    "sent": "And the dispersion that cloud is actually going to correspond to the conditional precision.",
                    "label": 0
                },
                {
                    "sent": "So if the peak is very, very tight and special designed small and there be high conditional precision on this corresponding to the to the conditional density, the problem is in a dynamical system that peak is itself moving.",
                    "label": 0
                },
                {
                    "sent": "So by putting in these mean field terms actually had them here mean field terms here, supplementing the ensemble dynamics with these mean field terms that correspond to the average motion overall particles that is seen by every particle.",
                    "label": 0
                },
                {
                    "sent": "Then I allow the whole system to move with the peak so that they can basically focus on converging on the on that peak without being left behind, so it allows them to to hit a moving target.",
                    "label": 0
                },
                {
                    "sent": "So in this moving peak they can actually get there in an unbiased without being left behind.",
                    "label": 0
                },
                {
                    "sent": "I've just shown.",
                    "label": 0
                },
                {
                    "sent": "Very simple example here where I've moved the peak according to this black line here, and I've specified some arbitrary function retreat as the variational energy and set off a little bunch.",
                    "label": 0
                },
                {
                    "sent": "A little pack of these particles.",
                    "label": 0
                },
                {
                    "sent": "I think there were 64 here, and this allowed them to diffuse 2 but move with the peak at the same time, so that after time they surround the peak so their sample density is the conditional mode, which should be faithfully tracking the mode of variational density, which is also.",
                    "label": 0
                },
                {
                    "sent": "Of the variation energy, which is also the mode of the variational density and the dispersion, will actually encode the inverse covariance, or that all the conditional precision here.",
                    "label": 0
                },
                {
                    "sent": "And I'll show you an example of that that later on.",
                    "label": 0
                },
                {
                    "sent": "And in principle this.",
                    "label": 0
                },
                {
                    "sent": "Ensemble density.",
                    "label": 0
                },
                {
                    "sent": "I will faithfully reproduce any arbitrary form for the variational energy, which means that we have a free form filtering like.",
                    "label": 0
                },
                {
                    "sent": "Algorithm or scheme that will approximate.",
                    "label": 0
                },
                {
                    "sent": "In real time or online, the conditional density of any arbitrary of any arbitrary form on the unknown states, hidden States and causes of a system.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do is just take you through a simplification to this, which actually is much quicker and then present some brief comparative valuations before closing.",
                    "label": 0
                },
                {
                    "sent": "Simplification is that if we assume that the density is actually Gaussian, we don't have to integrate all these stochastic differential equations here to actually generate a free form sample density.",
                    "label": 0
                },
                {
                    "sent": "We can just integrate one only differential equation, which is exactly the same as this equation here, but without the random fluctuation, and that basically will give us the mode and then we can work out the.",
                    "label": 0
                },
                {
                    "sent": "The covariance would have been had we actually created these particles.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that comes from.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Middle class approximation and if we can assume that the form of these variation modules here is normal, but in fact the precision becomes an analytic function of the mode, so it's actually very again for those of you know, the plus in the context of variational learning like schemes, this is trivial, but I've just written it out here in full.",
                    "label": 0
                },
                {
                    "sent": "If we just write out the expression for the free energy under Gaussian assumptions and facts.",
                    "label": 0
                },
                {
                    "sent": "A third order approximation under Gaussian assumptions.",
                    "label": 0
                },
                {
                    "sent": "Here we have these recall mean field terms here, which I won't go into.",
                    "label": 0
                },
                {
                    "sent": "All I wanted to say was that the weekend is differentiate this with respect to the covariance and sulfur zero.",
                    "label": 0
                },
                {
                    "sent": "And what we find is that the.",
                    "label": 0
                },
                {
                    "sent": "The precision for each partition is the negative curvature of the energy.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For dynamic models, it's very very similar, if not identical for the states.",
                    "label": 0
                },
                {
                    "sent": "For the parameters we actually have to integrate that precision over the duration of time of observed responses and add in the prior, which then just leaves us with finding the mode and all we need to find the mode of the variational energy and actions which are just simple functions of the energy which is prescribed by this hierarchal model that I started off.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "So finding the mode is a repeat, exactly like integrating a normal particle, but without removing, freeing it from its random fluctuations, so that hopefully once it finds the mode and it is if you like subject to these mean field.",
                    "label": 1
                },
                {
                    "sent": "This mean field guidance in this moving frame of reference that carries along with the mode, it'll just sit there quite happily.",
                    "label": 0
                },
                {
                    "sent": "One can show quite easily at least.",
                    "label": 0
                },
                {
                    "sent": "Again heuristically, that the for any arbitrary approximating particle that follows this equation here just basically get moves up.",
                    "label": 0
                },
                {
                    "sent": "The variational energy gradients and is supplemented by its own generalized motion.",
                    "label": 0
                },
                {
                    "sent": "Then the Jacobian, or the rate of change of the velocity with respect to the position of any difference between the true and the approximating mode has.",
                    "label": 1
                },
                {
                    "sent": "It's basically negative definite, provided the curvatures is negative and therefore it will at some point converge to the mode and we can use that just too general to produce update equations for the states we use something based on the sock is sort of integration, schemas, gastric differential equation, or integration scheme under local linearization assumptions to provide updates so that after a couple of updates.",
                    "label": 0
                },
                {
                    "sent": "One hopes that one's approximate load will actually converge to the true mode.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we can just compute the curvature and then one gets the conditional covariance for free.",
                    "label": 0
                },
                {
                    "sent": "Then you've got the entire normal form for the ensemble densities.",
                    "label": 0
                },
                {
                    "sent": "Just finally before we look at the examples.",
                    "label": 0
                },
                {
                    "sent": "Another intuitive perspective on this on this supplement, this augmentation of the flow of the flow of the mode, or the approximating mode by its own generalized motion.",
                    "label": 0
                },
                {
                    "sent": "One can regard it as basically simple gradient descent, so the rate of change of the approximating mode here is just the variational is a great dissent on the variational energy.",
                    "label": 0
                },
                {
                    "sent": "The variational energy differentiated with respect to the states here.",
                    "label": 0
                },
                {
                    "sent": "But is supplemented by its motion so that this motion is itself defined by itself.",
                    "label": 0
                },
                {
                    "sent": "It's just another form of itself.",
                    "label": 0
                },
                {
                    "sent": "Looks at the form of that and then looks at the the what happens when we hit the mode.",
                    "label": 0
                },
                {
                    "sent": "We actually conceive that the solution to this has to maximize variation lemma action by the fundamental lemma, and it's exactly the same as Hamilton's principle of strange reaction, and it is for when this is true, then the velocity of the stage becomes the 1st order generalized motion.",
                    "label": 1
                },
                {
                    "sent": "So this is where they come back together again.",
                    "label": 0
                },
                {
                    "sent": "Under Hamilton's principle station reaction, so we got this scheme.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where we've we've got these this mean field partition into states, parameters, and hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "We can cycle through overtime points.",
                    "label": 0
                },
                {
                    "sent": "The states in this online way to integrate this equation that I showed in the previous slide to optimize the modes of the unknown causal hidden States and compute their precision with that information.",
                    "label": 0
                },
                {
                    "sent": "We can integrate that and then optimize the OR update the.",
                    "label": 0
                },
                {
                    "sent": "Conditional modes and precision of the parameters and the hyperparameters using exactly this equation.",
                    "label": 0
                },
                {
                    "sent": "But we don't have to worry about the time dependent aspects and then just iterate around that in the usual way until we've optimized the overall free energy and then we've got a conditional density on the parameters, the hyperparameters, the states of our system.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to just demonstrate this.",
                    "label": 0
                },
                {
                    "sent": "Start first of all, using a very simple linear conval.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Russian model that starts off with some cause here.",
                    "label": 0
                },
                {
                    "sent": "It'll bump function that perturbs 2 hidden states that are coupled to produce this very simple linear little transient that's mapped linearly to four outputs to generate data, and we're going to try to invert this model to get at the conditional density on this unknown cause here.",
                    "label": 0
                },
                {
                    "sent": "And I've cartoon the sort of scheme that is implicit under these.",
                    "label": 0
                },
                {
                    "sent": "Under the plus approximation, which is basically just all about minimizing prediction error in hierarchical context with which can be can be formulated in terms of message passing and also neurological terms, which is why the brain underneath.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, I'm going to show you exactly that system.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given just the data and the form of the model, can I now estimate the time dependent condition densities on the hidden states?",
                    "label": 0
                },
                {
                    "sent": "There are two of them here and the single cores.",
                    "label": 0
                },
                {
                    "sent": "Online.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In one pass, using the variational filtering, so I'm not actually using that on sambol like understanding of ensemble learning as a algorithmics scheme to get a sample density that I can use as a conditional conditional density on the states.",
                    "label": 0
                },
                {
                    "sent": "Here the hidden States and here are the unknown causes and I think there are 16 particles here and what I've done here is just reported.",
                    "label": 0
                },
                {
                    "sent": "The mean here and the sample density at each time point of these particles on the cores and the two hidden states in this format here.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because in the next slide wanted to show you the comparison of the inversion or deconvolution.",
                    "label": 0
                },
                {
                    "sent": "Using this variational filtering.",
                    "label": 0
                },
                {
                    "sent": "With exactly the same data and exactly the same model, but using the Laplace approximation or the Dems sort of variational scheme.",
                    "label": 0
                },
                {
                    "sent": "So the difference between these two here is that this one we've actually generated sample density by integrating these stochastic differential equations, whereas here we just integrated one particle, which we fondly hope tracks the mode by omitting the stochastic part here and integrating this.",
                    "label": 0
                },
                {
                    "sent": "Order differential equation here, but otherwise they're identical and what we see is that the means are actually remarkably similar as one would hope, as are the conditional.",
                    "label": 0
                },
                {
                    "sent": "Confidence intervals here based on the conditional precision or covariance as they should be because we actually use Gaussian random terms to generate the data, and there's a linear model, so there should be no surprise there.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This just shows you the dependence of the kualiti or the accuracy of the inversion of the data.",
                    "label": 0
                },
                {
                    "sent": "I just showed you on the number of.",
                    "label": 0
                },
                {
                    "sent": "Or the order of the generalized motion that we consider.",
                    "label": 0
                },
                {
                    "sent": "If you recall, the precision tails off after about the.",
                    "label": 0
                },
                {
                    "sent": "5th or 6th High order motion, which basically means that it doesn't matter if we keep the prediction errors at that level or order, they're not going to do anything 'cause there's no precision in them at all.",
                    "label": 0
                },
                {
                    "sent": "They don't contribute to the energy they don't contribute to the variational energy, and they don't contribute to the scheme.",
                    "label": 0
                },
                {
                    "sent": "And we can demonstrate that quite easily just by using in the limiting case or just one.",
                    "label": 0
                },
                {
                    "sent": "Just which correspond to conventional state space model.",
                    "label": 0
                },
                {
                    "sent": "So there's one order of motion measuring the actual sum squared error given the true data and then increasing the order of here up until 13 years.",
                    "label": 1
                },
                {
                    "sent": "And we can see that we get our best returns of four up to about five.",
                    "label": 0
                },
                {
                    "sent": "As for the smoothness of data, which I've usually games, gamma is equal to four.",
                    "label": 0
                },
                {
                    "sent": "To generate these data reflect.",
                    "label": 0
                },
                {
                    "sent": "This generally holds that we don't normally need to go beyond eight orders or 8 dimensional generalized spaces of motion there.",
                    "label": 0
                },
                {
                    "sent": "These are just the fits for the causes with N equals one and equals 7.",
                    "label": 0
                },
                {
                    "sent": "This would be more conventional state space model we use.",
                    "label": 0
                },
                {
                    "sent": "Thank you like Kalman filter or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, yeah, here sort of comparative valuations and extended common filtering using Dem where we actually told it that the random fluctuations were venal.",
                    "label": 0
                },
                {
                    "sent": "I can have no correlations as opposed to telling the scheme what the actual correlations were, which was basically a precision of four or some deviation of 1/2 on the auto correlation function of the random states.",
                    "label": 0
                },
                {
                    "sent": "One can see the progressive improvement just to note that when.",
                    "label": 0
                },
                {
                    "sent": "You actually reduce end to one, and you tell the Dem scheme that there are no correlations.",
                    "label": 0
                },
                {
                    "sent": "You get exactly the same results as Camel filter as you should do, which will be optimal if there weren't any correlations.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the random.",
                    "label": 0
                },
                {
                    "sent": "In the random components very briefly, this is a nonlinear variation of the demonstration I just showed you this to show how it copes and compare its performance with particle filtering in the context of a nonlinear system, this is a sort of quasi double well, but we have actually forced to occupy 1 one of the two wells to focus on the how the covariance depends upon the nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "So that we could compare extended camera filter.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particle filtering and the variation scheme that I've showed you here notice that this is an analogue scale, so that you particle filtering and variational filtering are much better on average than.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spending particle Kalman filtering as one might anticipate.",
                    "label": 0
                },
                {
                    "sent": "This is just to show the estimation of parameters and states at the same time as a prelude.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applying these techniques to an actual empirical example where we studied the brain responses of human subject while they were either paying attention or not to moving starfield and thereafter.",
                    "label": 0
                },
                {
                    "sent": "Detect any changes in the velocity of these dots that move towards them even though there weren't any actual changes.",
                    "label": 0
                },
                {
                    "sent": "The construction of the model that we actually uses basically was based upon.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Known hemodynamics I won't go into this other than to use it as an example of a nonlinear dynamical system that converts in your own activity into measured brain signals that we measured with brain that we measure with brain imaging sufficient.",
                    "label": 0
                },
                {
                    "sent": "Critically, it's a bit nonlinear, which is why I'm using it as an empirical example of a non linear convolution model.",
                    "label": 0
                },
                {
                    "sent": "The inputs here will basically whether there was a visual input in the field whether input was moving, and whether the subject was paying attention and parameterized.",
                    "label": 0
                },
                {
                    "sent": "These in terms of feature here.",
                    "label": 0
                },
                {
                    "sent": "Sort of gating variables entered into this system to generate changes in hemodynamics and blood flow and hemoglobin changes.",
                    "label": 0
                },
                {
                    "sent": "Actually give us a cig.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here and here are the results that here in the States after deconvolution and hear the parameters showing that certainly for visual stimulus and motion we can April story be very confident that these were non true.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Real effects, and there's a closer look at the dynamics.",
                    "label": 0
                },
                {
                    "sent": "Showing the changes in various blood flow and the.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dream catcher.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sticks and I just conclude with an example of this in a sort of more theoretical role where what we've done here is simulate Birdsongs could we play that is that we have sound.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh, here it is.",
                    "label": 0
                },
                {
                    "sent": "So if I were to.",
                    "label": 0
                },
                {
                    "sent": "Navigate it over the.",
                    "label": 0
                },
                {
                    "sent": "Perhaps not, but it doesn't matter if.",
                    "label": 0
                },
                {
                    "sent": "The So what we've done here is simulate a bird.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "Taking a Lorentz attractor and extracting two of the states to modulate muscle tone here, that would normally be controlling the frequency of the chirp that the bed was producing and the amplitude.",
                    "label": 0
                },
                {
                    "sent": "So taking the frequency and the amplitude from two states of Lorenz attractor to produce birds at bird song of sequence of chirps here that have which you can just about see in this sonogram where this frequency misses time and I had hoped to be able to play.",
                    "label": 0
                },
                {
                    "sent": "The church is so you can actually hear this thing singing team.",
                    "label": 0
                },
                {
                    "sent": "What we've also done here though, is not just allowed this.",
                    "label": 0
                },
                {
                    "sent": "The the deterministic chaos of the attracted us to drive a sequence of chips, which would be the song.",
                    "label": 0
                },
                {
                    "sent": "But the control parameters of this dynamical system here are themselves generated by another rents a tractor.",
                    "label": 0
                },
                {
                    "sent": "So now we have hopefully a sequence of sequences, and so we have basically a sequence of bird songs, and then we've used this scheme to invert the sonogram.",
                    "label": 0
                },
                {
                    "sent": "Here the heard auditory information to see if we can get back at which sequence was being played.",
                    "label": 0
                },
                {
                    "sent": "Only one time, but more importantly for you, I just wanted to demonstrate.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to try it.",
                    "label": 0
                },
                {
                    "sent": "I mean yes, early.",
                    "label": 0
                },
                {
                    "sent": "Have to find the cursor first.",
                    "label": 0
                },
                {
                    "sent": "That was probably what happened.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Now how do we get?",
                    "label": 0
                },
                {
                    "sent": "Laptop.",
                    "label": 0
                },
                {
                    "sent": "I could whistle it.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Anywhere well out of time, so let's not waste about this time.",
                    "label": 0
                },
                {
                    "sent": "I can't know.",
                    "label": 0
                },
                {
                    "sent": "Look, maybe I'm touching something.",
                    "label": 0
                },
                {
                    "sent": "Wow, nice.",
                    "label": 0
                },
                {
                    "sent": "OK, let's just leave it on this slide here then.",
                    "label": 0
                },
                {
                    "sent": "That's good, the previous slide did show you the true and the in Ferd conditional densities on the time dependent states.",
                    "label": 0
                },
                {
                    "sent": "Both the hierarchical levels of this system.",
                    "label": 0
                },
                {
                    "sent": "The first one governing the sonogram dancer, the sonogram and II governing which of the songs this high level events are tractor was going to switch on or switch off, but the real reason I want.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To show you this was just to entertain you and also give you a feeling for what would happen if you took away these two sources of prior constraints that that in this model that if we if we now lesion.",
                    "label": 0
                },
                {
                    "sent": "The hierarchy, so we chop off the input from the second Lorentz attractor so that now there are no structural prize of the synthetic bird listening or recognizing the song now doesn't know that the song should change in accord with a Lorenz attractor.",
                    "label": 0
                },
                {
                    "sent": "So it now has no knowledge of the evolution of the chirps as yes, it's listening to the chirps.",
                    "label": 0
                },
                {
                    "sent": "We can look at the contribution of these.",
                    "label": 0
                },
                {
                    "sent": "So here's what this song, actually.",
                    "label": 0
                },
                {
                    "sent": "And this very ginger link as I accidentally changed the this is what the song actually sounds like and when correctly inverted, the bird actually hears.",
                    "label": 0
                },
                {
                    "sent": "So that's two Lorenz attractors, one governing the other one.",
                    "label": 0
                },
                {
                    "sent": "So that's a very radical perception.",
                    "label": 0
                },
                {
                    "sent": "If I now remove this sort of higher order empirical.",
                    "label": 0
                },
                {
                    "sent": "OK, you probably felt the first one.",
                    "label": 0
                },
                {
                    "sent": "OK, so two part is it.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's actually not right.",
                    "label": 0
                },
                {
                    "sent": "It's not getting these high frequency chirps up here, but it's not too bad.",
                    "label": 0
                },
                {
                    "sent": "If I did something really awful to it and cut all its temporal priors by removing the generalized motion so I'm collapsing back down to N is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Then it's perception.",
                    "label": 0
                },
                {
                    "sent": "Is very sick, so failing to complete completely, failing to capture any of adamik.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for attention.",
                    "label": 0
                },
                {
                    "sent": "Questioning.",
                    "label": 0
                },
                {
                    "sent": "It seemed like that was what you were all your variables time.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it was your first or should mention in this case, not actually the 100 relative or every point in the inversion scheme.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, this is the mode of causes at the second level, which corresponds to states to the states of rents.",
                    "label": 0
                },
                {
                    "sent": "Sorry, one of the states of Lorentz attractor for each point here anymore.",
                    "label": 0
                },
                {
                    "sent": "Instant in time they will actually be 8 numbers corresponding to encoding the local trajectory of this path in terms of of the first, second, 3rd update order motion.",
                    "label": 0
                },
                {
                    "sent": "Now the actual trajectory that that path is actually encoded at incident time is not necessarily the actual path that the actual state itself follows.",
                    "label": 0
                },
                {
                    "sent": "In a sense, the corrections to that path is what the scheme is doing.",
                    "label": 0
                },
                {
                    "sent": "Generalized generalized, these are temporal differences.",
                    "label": 0
                },
                {
                    "sent": "You take the data so not well practically, you could look at it like that.",
                    "label": 0
                },
                {
                    "sent": "It's a generative model.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "You're trying to generate.",
                    "label": 0
                },
                {
                    "sent": "The generative model, but yeah.",
                    "label": 0
                },
                {
                    "sent": "And what are the primed data points?",
                    "label": 0
                },
                {
                    "sent": "Well, the data are in this instance there, so sparsely sampled discrete observations at one point in time, and then a sequence of time points.",
                    "label": 0
                },
                {
                    "sent": "So I can generate those data from any point in time and generalized coordinates with local precision.",
                    "label": 0
                },
                {
                    "sent": "So for example, let's take the first 10 time bins where I've actually got sort of 1 dimensional data or two dimensional data.",
                    "label": 0
                },
                {
                    "sent": "In the sonogram example here, so I've got 8.",
                    "label": 0
                },
                {
                    "sent": "Time eight time bins now at say 4.3 two seconds.",
                    "label": 0
                },
                {
                    "sent": "I will have a representation of the conditional density and generalized coordinates.",
                    "label": 0
                },
                {
                    "sent": "So by Taylor's theorem I can now generate the predictions at each of those time points in the past and in the future.",
                    "label": 0
                },
                {
                    "sent": "So I generate locally a projection of the path encoding generalized coordinates onto a discreetly.",
                    "label": 0
                },
                {
                    "sent": "Sort of sample timeline.",
                    "label": 0
                },
                {
                    "sent": "So that's right.",
                    "label": 0
                },
                {
                    "sent": "And then I just move along to the next well.",
                    "label": 0
                },
                {
                    "sent": "Natural small as I want to make it depending on that sort of.",
                    "label": 0
                },
                {
                    "sent": "Getting dementia, yeah, absolutely yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Very much so.",
                    "label": 0
                },
                {
                    "sent": "In fact, I think on the slides actually refer to N as the embedding dimension.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Let's start again at the top class.",
                    "label": 0
                }
            ]
        }
    }
}