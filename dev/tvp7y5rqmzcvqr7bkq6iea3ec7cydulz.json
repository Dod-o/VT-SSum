{
    "id": "tvp7y5rqmzcvqr7bkq6iea3ec7cydulz",
    "title": "Bayesian Hyper Networks",
    "info": {
        "author": [
            "David Scott Krueger, Montreal Institute for Learning Algorithms (MILA), University of Montreal"
        ],
        "published": "July 27, 2017",
        "recorded": "July 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_krueger_bayesian_networks/",
    "segmentation": [
        [
            "Alright, thank you so this is some joint work I did with Chin Wei Huang, Rashaad Islam, Ryan Turner in Kerrville.",
            "Where are we are all from you except for a shots from the McGill our lab and mention were joint contributed equally on this."
        ],
        [
            "So here is my attempt to explain this in one slide, so hyper net is just a neural net that generates the parameters for another neural net, which we call the primary net.",
            "So what we do here is we feed the hipernet noise.",
            "And so that gives us a distribution over the parameters of the primary net, and so, concretely, if you want to like predict Y from X.",
            "In this case you had sampled some ID, Gaussian noise passing through neural network is exactly like the decoder Innovia or again.",
            "But really you should be thinking about real MVP and I'll explain why later.",
            "And then we take the output.",
            "We use those of the parameters of the primary net and we feed that Network X and outcomes wife.",
            "And so when we actually want to make a prediction, that's exactly what we do.",
            "Except we're going to do that like maybe 100 times with 100 different zizan average the results.",
            "So why are we doing this?"
        ],
        [
            "We're trying to make a vision neural network basically, so this is something that a lot of people have been working on for a long time, and their various techniques for doing this.",
            "The basic idea with the visual net is that.",
            "We want to have a distribution over the parameters instead of a point estimate on that distribution should be the one that's given to you by Bayes rule here, so it should be the posterior over the parameters given the data which is proportional to the likelihood times the prior.",
            "So what we normally do is we just take the argmax of that which is maximum likelihood or maximum out posteriori because you're incorporating this prior term, but in fact you should be able to make better predictions by integrating out your uncertainty.",
            "And using that to make your prediction.",
            "So that's when you do this integral, you're essentially ensemble in an infinite number of models that all have different parameters.",
            "Yeah."
        ],
        [
            "So.",
            "What's special about that?",
            "Besides just as I argue that you should be able to make better predictions, you also have an idea of how uncertain the network is.",
            "About the model, and so instead of just saying like, that's my best guess that's the argmax.",
            "You also get something like, well, I'm 99% sure I'm only 50% sure or something that's analogous to that, so the model sort of knows what it knows.",
            "In some sense, it has like a calibrated confidence, so it's not going to be overconfident or appear overconfident ideally."
        ],
        [
            "Yeah, so that's useful for something like a self driving car.",
            "51% sure that there's no person in the road, and I'm 99.999999% sure both just mapped to.",
            "That's my best guess.",
            "There's no person in the road.",
            "If you're, if you're doing the argmax thing.",
            "But if you actually have a distribution over your parameters, then you can have this kind of a estimate of how certain you are of that, and then if you're 9 point, whatever, sure, then maybe you can keep driving if you only 51% sure, then you should probably stop and turn over control to human.",
            "So like."
        ],
        [
            "Generally I'm motivated to pursue this line of work because of AI safety, so this is my one slide explanation of that.",
            "How many of you are familiar with this book with the owl on it Superintelligence by Nick Bostrom?",
            "OK, so a pretty small pretty small amount I guess maybe 5 or 10%.",
            "You probably would have at least seen some things in the media about this, I assume.",
            "Anyways, there are some people who think that like AI is going to kill us all on one of them.",
            "And anyways, in this book on across from talks about the existential risk of AI.",
            "In other words, like is it going to kill everybody hears this chapter called this the default outcome Doom, and I think there's a compelling argument to be made that the answer is yes, it's not.",
            "The talk is about, but I'm really passionate about that subject because I think the whole future of the universe is at stake.",
            "So if anyone wants to talk to me about that offline and always happy to talk about it anyways, if you if you buy this premise, the goal of AI safety then is to move the AI that we developed from.",
            "Basically being like, hey, let's kill everybody to what do people want?",
            "And then.",
            "We would also like them when they're uncertain to sort of ask us what we want instead of just taking their best guess and trying to optimize for what they think people want.",
            "This is referred to as Courage ability in the eye safety community, so it's the idea that there is always going to sort of be checking in with us and seeing, oh, am I really optimizing the right thing by doing the right thing?",
            "Anne."
        ],
        [
            "And there's a recent paper from last year from people from like, you know, Google Brain opening I Berkeley.",
            "About AI safety and about like things that you can work on right now.",
            "So a common misconception I would say when people hear about this idea.",
            "And when I talk to people about it, is that there's no work that you can do right now.",
            "It's all just philosophy, mean Nick Bostrom is a plus for, after all.",
            "But actually it's an active topic of research at Berkeley, Stanford Open AI, Google Brain Deep Mind.",
            "So anyways, this is a paper that sort of lays out what they think are promising areas for research in AI safety right now.",
            "And what I'm calling calibrated confidence actually helps in four out of five."
        ],
        [
            "Of these problems, I think which is pretty cool, so I don't know if you can actually read that.",
            "You can look at the paper if you want.",
            "Should I go over this?",
            "Basically, I think the most interesting one from my perspective right now that really made me more interested in this is scaleable oversight.",
            "So that's the idea that as humans we really have a very limited bandwidth of information that we can give to machines, and right now what we're doing is we're like providing labels or writing down a reward function, or maybe providing rewards online and we'd like to really use something more like natural language which might allow much more rich communication with a eyes.",
            "But even in that case, like humans just operate very slowly and the amount of data that AI needs is a lot, especially in something complicated.",
            "And there's kind of consensus in the SFV community.",
            "I would say that we need a eyes to actually learn about human values and learn what we want.",
            "Ultimately, if they're going to be safe, and since our values are very complicated and we have very like you, know complicated preferences about things, that means we're going to need to transmit a lot of information to eyes, and that's sort of what this scalable oversight thing is about to me is like how can we get all the information that we need to the eyes with the limited amount of bits that we can communicate as humans.",
            "So an example of that is active learning who's heard of active learning.",
            "Cool, so that's more like 4050% for the rest of you active learning is this idea that the learning algorithm can actually choose which data points should be labeled and in sort of an online way.",
            "So it's going to look and see, maybe which points is it most uncertain about and ask for labels on those ones, and then repeat this iteratively?",
            "So you start out with unsupervised with an unlabeled data set.",
            "Or maybe just a few examples being labeled."
        ],
        [
            "OK, so that's enough of like the motivation.",
            "Now I'm going to go into."
        ],
        [
            "Details about how this works.",
            "'cause I don't expect that when I did the one slide thing, everyone really encouraged understood enough.",
            "So we're using variational inference to train this thing.",
            "So I told you already that we're going to need a noise, and so we're going to get a noisy distribution out on, but like.",
            "What noisy distribution?",
            "'cause we actually want to match the posterior, or at least approximately match the posterior over the parameters and so the technique we use for that is variational inference on.",
            "So when I first had this idea, I was concerned that if you feed in noise to a hyper net is just going to learn to ignore that noise and just predict something constant with its output biases for the parameters of the primary net.",
            "And that's actually what it should do if you don't do something to encourage Stochastic City.",
            "So what's cool is that when you actually look at the.",
            "Equations for variational inference, on which I guess you guys have seen this a little bit and probably Maxwell and will talk about it more tomorrow.",
            "There's actually this term.",
            "This entropy term that falls out that encourages you to have stochasticity in your parameters, and to actually make the distribution as as random words entropic as possible.",
            "So that's great on this script.",
            "L is what's called the elbow or the variational lower bound, and that's actually what we maximize when we're doing this variational learning, and that's equivalent to minimizing the scale between our approximate posterior Q, so that's what the hypernet is actually learning.",
            "And the true posterior P, which is what we want to want to match.",
            "And that's because this is actually just algebra.",
            "You can you can plug in these things and simplify them, and you find that the log probability of the data is equal to this lower bound plus the scale.",
            "And it's also a constant.",
            "So when we maximize the lower bound, we're minimizing the scale and we're getting better and better approximation to the true posterior.",
            "This is like really popular, maybe the most popular technique for doing Bayesian neural Nets at the moment.",
            "On so like there's this DeepMind paper on weight on certainty that I pulled that figure from earlier that uses variational inference, and there's also work from like yarn gollins ghahremani interpreting.",
            "Dropout is variational inference and then also a lot of work from Maxwell is group as well.",
            "Doing that with like Gaussian dropout called the local repair iteration trick.",
            "And if they have a recent paper that I haven't really looked at enough, that's actually pretty similar, I think to what we're doing, although not."
        ],
        [
            "Same, I like cars better from what I know.",
            "Anyway, so there's a problem with variational inference, especially when you're thinking about these.",
            "These safety critical applications where you want to have calibrated confidence and the problem is that variational inference can underestimate the uncertainty that you have.",
            "So the Cal Divergance, which you should all be familiar with is asymmetric.",
            "So the cable between Q&P is not the same as the cable between P&Q.",
            "And what happens when you run?",
            "If you if you optimize this, KL divergences between a mixture of Gaussian and Gaussian in One Direction, the Gaussian is going to sort of spread out its mass to try and cover all of the modes, and then maybe it's going to put a bunch of mass in between the modes.",
            "As a result, 'cause it's unimodal an in the other direction, it's just going to find one of the modes an fit.",
            "That mode really well, and that's actually the direction that we use in this variational inference techniques.",
            "So that means that if P is the real posterior here.",
            "And Q is our variational approximation and we're trying to use Q to tell us you know how certain we are about something.",
            "We might be very confident that this mode on the that's the left for you guys doesn't exist, right?",
            "Because our variational posterior didn't put any mass there because it just found one of the modes.",
            "So that's kind of a problem.",
            "I think this problem comes both from the use of the KL divergences as a measure of discrepancy, but it also comes from the variational approximation being too simple, so pretty much all of the work.",
            "Actually, I think all of the work that I know of using variational inference in Bayesian DNS uses a unimodal approximate posterior, and it's usually like a factorial Gaussian."
        ],
        [
            "Like I have up here, which means that you just have an independent distribution for every parameter and you're totally ignoring any dependencies between those parameters or any.",
            "Yeah, and since we're using a deep net to parameterise this distribution, we can actually get something that's highly dependent in multimodal.",
            "So in the same way that, like when you sample random noise and then pass it through again or via E, you can actually looks like a picture, and that's because the decoder is introducing dependencies between the outputs.",
            "We have the same effect here."
        ],
        [
            "So here's some qualitative results that just show that.",
            "So on the left here I just look at the correlation between the different parameters.",
            "Actually these are.",
            "This is a histogram of the values.",
            "The values of.",
            "I think it's called Pearson's test, and so a bunch of them are below .5, so I think it's like pretty clear this correlation there and then if you also look at a simple neural net that.",
            "Is given by y = a * B * X.",
            "Sorry if your data is generated that way and you have a neural net that has those two that has the same architecture and you're trying to learn A&B.",
            "A * B = 1 is the solution and any A&B that have the product of 1 give the solution, so that's what those red lines are and the dots here are samples from our posterior and you see that it actually puts a bunch of mass on both of the modes there 1 one and minus 1 -- 1.",
            "This on."
        ],
        [
            "Let's see.",
            "So hyper Nets are kind of a recent thing, although maybe there's more work on them.",
            "In the past people people use them with like a fixed input, whereas what we're doing is different because we're feeding noise into the hyper net and that gives us this distribution on.",
            "Let's see how we do this so, so another issue that we encountered is that there's a lot of parameters, and in the primary netan, if you just have if you put all of those."
        ],
        [
            "Here's your hypernet becomes really large, so instead in our work we were just out putting the scaling factors in weight normalization.",
            "So here you basically decouples the length and direction of a weight vector and the length is given by this extra scaling parameter, and so the way that we parameterized our primary net is the direction parameters are just fixed and the scaling parameters are the output of the hypernet and so that means we reduce the number of outputs that we need to.",
            "Get out of the hipernet from like the number of units squared to just the number of units and that makes things a lot more tractable."
        ],
        [
            "And there's this other background.",
            "I think Aaron talked about this on this morning about like normalizing flows, an invertible degenerative models.",
            "So actually I should have mentioned this when I showed you the equation back here.",
            "This entropy term in order to estimate it, you actually need to have one of these normalizing flow models.",
            "So if you look at the other terms of this expectation, those are just the likelihood in the prior that you would have when you try to normal net.",
            "It's this last one that's kind of different.",
            "Um?",
            "And the way that we get the that we compute these terms by sampling some parameters from the hypernet and then just computing them and what we need to compute this last entry term, we need to find out what the likelihood of the parameters that we sampled is, and so that's where we need to use one of these invertible models.",
            "I'm kind of running out of time, unfortunately, but."
        ],
        [
            "Here's some results where we just show that actually you can beat dropout by having.",
            "By using this model on a subset of Ms on you get better generalization performance.",
            "Um?"
        ],
        [
            "Yeah, I guess I guess I'll stop there and take some questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, thank you so this is some joint work I did with Chin Wei Huang, Rashaad Islam, Ryan Turner in Kerrville.",
                    "label": 0
                },
                {
                    "sent": "Where are we are all from you except for a shots from the McGill our lab and mention were joint contributed equally on this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is my attempt to explain this in one slide, so hyper net is just a neural net that generates the parameters for another neural net, which we call the primary net.",
                    "label": 1
                },
                {
                    "sent": "So what we do here is we feed the hipernet noise.",
                    "label": 0
                },
                {
                    "sent": "And so that gives us a distribution over the parameters of the primary net, and so, concretely, if you want to like predict Y from X.",
                    "label": 1
                },
                {
                    "sent": "In this case you had sampled some ID, Gaussian noise passing through neural network is exactly like the decoder Innovia or again.",
                    "label": 0
                },
                {
                    "sent": "But really you should be thinking about real MVP and I'll explain why later.",
                    "label": 0
                },
                {
                    "sent": "And then we take the output.",
                    "label": 0
                },
                {
                    "sent": "We use those of the parameters of the primary net and we feed that Network X and outcomes wife.",
                    "label": 0
                },
                {
                    "sent": "And so when we actually want to make a prediction, that's exactly what we do.",
                    "label": 0
                },
                {
                    "sent": "Except we're going to do that like maybe 100 times with 100 different zizan average the results.",
                    "label": 0
                },
                {
                    "sent": "So why are we doing this?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're trying to make a vision neural network basically, so this is something that a lot of people have been working on for a long time, and their various techniques for doing this.",
                    "label": 0
                },
                {
                    "sent": "The basic idea with the visual net is that.",
                    "label": 0
                },
                {
                    "sent": "We want to have a distribution over the parameters instead of a point estimate on that distribution should be the one that's given to you by Bayes rule here, so it should be the posterior over the parameters given the data which is proportional to the likelihood times the prior.",
                    "label": 1
                },
                {
                    "sent": "So what we normally do is we just take the argmax of that which is maximum likelihood or maximum out posteriori because you're incorporating this prior term, but in fact you should be able to make better predictions by integrating out your uncertainty.",
                    "label": 1
                },
                {
                    "sent": "And using that to make your prediction.",
                    "label": 0
                },
                {
                    "sent": "So that's when you do this integral, you're essentially ensemble in an infinite number of models that all have different parameters.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What's special about that?",
                    "label": 0
                },
                {
                    "sent": "Besides just as I argue that you should be able to make better predictions, you also have an idea of how uncertain the network is.",
                    "label": 0
                },
                {
                    "sent": "About the model, and so instead of just saying like, that's my best guess that's the argmax.",
                    "label": 1
                },
                {
                    "sent": "You also get something like, well, I'm 99% sure I'm only 50% sure or something that's analogous to that, so the model sort of knows what it knows.",
                    "label": 1
                },
                {
                    "sent": "In some sense, it has like a calibrated confidence, so it's not going to be overconfident or appear overconfident ideally.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so that's useful for something like a self driving car.",
                    "label": 0
                },
                {
                    "sent": "51% sure that there's no person in the road, and I'm 99.999999% sure both just mapped to.",
                    "label": 1
                },
                {
                    "sent": "That's my best guess.",
                    "label": 0
                },
                {
                    "sent": "There's no person in the road.",
                    "label": 0
                },
                {
                    "sent": "If you're, if you're doing the argmax thing.",
                    "label": 0
                },
                {
                    "sent": "But if you actually have a distribution over your parameters, then you can have this kind of a estimate of how certain you are of that, and then if you're 9 point, whatever, sure, then maybe you can keep driving if you only 51% sure, then you should probably stop and turn over control to human.",
                    "label": 0
                },
                {
                    "sent": "So like.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Generally I'm motivated to pursue this line of work because of AI safety, so this is my one slide explanation of that.",
                    "label": 0
                },
                {
                    "sent": "How many of you are familiar with this book with the owl on it Superintelligence by Nick Bostrom?",
                    "label": 0
                },
                {
                    "sent": "OK, so a pretty small pretty small amount I guess maybe 5 or 10%.",
                    "label": 0
                },
                {
                    "sent": "You probably would have at least seen some things in the media about this, I assume.",
                    "label": 0
                },
                {
                    "sent": "Anyways, there are some people who think that like AI is going to kill us all on one of them.",
                    "label": 0
                },
                {
                    "sent": "And anyways, in this book on across from talks about the existential risk of AI.",
                    "label": 1
                },
                {
                    "sent": "In other words, like is it going to kill everybody hears this chapter called this the default outcome Doom, and I think there's a compelling argument to be made that the answer is yes, it's not.",
                    "label": 0
                },
                {
                    "sent": "The talk is about, but I'm really passionate about that subject because I think the whole future of the universe is at stake.",
                    "label": 1
                },
                {
                    "sent": "So if anyone wants to talk to me about that offline and always happy to talk about it anyways, if you if you buy this premise, the goal of AI safety then is to move the AI that we developed from.",
                    "label": 0
                },
                {
                    "sent": "Basically being like, hey, let's kill everybody to what do people want?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We would also like them when they're uncertain to sort of ask us what we want instead of just taking their best guess and trying to optimize for what they think people want.",
                    "label": 0
                },
                {
                    "sent": "This is referred to as Courage ability in the eye safety community, so it's the idea that there is always going to sort of be checking in with us and seeing, oh, am I really optimizing the right thing by doing the right thing?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there's a recent paper from last year from people from like, you know, Google Brain opening I Berkeley.",
                    "label": 0
                },
                {
                    "sent": "About AI safety and about like things that you can work on right now.",
                    "label": 0
                },
                {
                    "sent": "So a common misconception I would say when people hear about this idea.",
                    "label": 0
                },
                {
                    "sent": "And when I talk to people about it, is that there's no work that you can do right now.",
                    "label": 0
                },
                {
                    "sent": "It's all just philosophy, mean Nick Bostrom is a plus for, after all.",
                    "label": 0
                },
                {
                    "sent": "But actually it's an active topic of research at Berkeley, Stanford Open AI, Google Brain Deep Mind.",
                    "label": 0
                },
                {
                    "sent": "So anyways, this is a paper that sort of lays out what they think are promising areas for research in AI safety right now.",
                    "label": 0
                },
                {
                    "sent": "And what I'm calling calibrated confidence actually helps in four out of five.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of these problems, I think which is pretty cool, so I don't know if you can actually read that.",
                    "label": 1
                },
                {
                    "sent": "You can look at the paper if you want.",
                    "label": 0
                },
                {
                    "sent": "Should I go over this?",
                    "label": 0
                },
                {
                    "sent": "Basically, I think the most interesting one from my perspective right now that really made me more interested in this is scaleable oversight.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea that as humans we really have a very limited bandwidth of information that we can give to machines, and right now what we're doing is we're like providing labels or writing down a reward function, or maybe providing rewards online and we'd like to really use something more like natural language which might allow much more rich communication with a eyes.",
                    "label": 0
                },
                {
                    "sent": "But even in that case, like humans just operate very slowly and the amount of data that AI needs is a lot, especially in something complicated.",
                    "label": 0
                },
                {
                    "sent": "And there's kind of consensus in the SFV community.",
                    "label": 0
                },
                {
                    "sent": "I would say that we need a eyes to actually learn about human values and learn what we want.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, if they're going to be safe, and since our values are very complicated and we have very like you, know complicated preferences about things, that means we're going to need to transmit a lot of information to eyes, and that's sort of what this scalable oversight thing is about to me is like how can we get all the information that we need to the eyes with the limited amount of bits that we can communicate as humans.",
                    "label": 1
                },
                {
                    "sent": "So an example of that is active learning who's heard of active learning.",
                    "label": 0
                },
                {
                    "sent": "Cool, so that's more like 4050% for the rest of you active learning is this idea that the learning algorithm can actually choose which data points should be labeled and in sort of an online way.",
                    "label": 0
                },
                {
                    "sent": "So it's going to look and see, maybe which points is it most uncertain about and ask for labels on those ones, and then repeat this iteratively?",
                    "label": 0
                },
                {
                    "sent": "So you start out with unsupervised with an unlabeled data set.",
                    "label": 0
                },
                {
                    "sent": "Or maybe just a few examples being labeled.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's enough of like the motivation.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to go into.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Details about how this works.",
                    "label": 0
                },
                {
                    "sent": "'cause I don't expect that when I did the one slide thing, everyone really encouraged understood enough.",
                    "label": 0
                },
                {
                    "sent": "So we're using variational inference to train this thing.",
                    "label": 1
                },
                {
                    "sent": "So I told you already that we're going to need a noise, and so we're going to get a noisy distribution out on, but like.",
                    "label": 0
                },
                {
                    "sent": "What noisy distribution?",
                    "label": 0
                },
                {
                    "sent": "'cause we actually want to match the posterior, or at least approximately match the posterior over the parameters and so the technique we use for that is variational inference on.",
                    "label": 0
                },
                {
                    "sent": "So when I first had this idea, I was concerned that if you feed in noise to a hyper net is just going to learn to ignore that noise and just predict something constant with its output biases for the parameters of the primary net.",
                    "label": 0
                },
                {
                    "sent": "And that's actually what it should do if you don't do something to encourage Stochastic City.",
                    "label": 0
                },
                {
                    "sent": "So what's cool is that when you actually look at the.",
                    "label": 0
                },
                {
                    "sent": "Equations for variational inference, on which I guess you guys have seen this a little bit and probably Maxwell and will talk about it more tomorrow.",
                    "label": 0
                },
                {
                    "sent": "There's actually this term.",
                    "label": 0
                },
                {
                    "sent": "This entropy term that falls out that encourages you to have stochasticity in your parameters, and to actually make the distribution as as random words entropic as possible.",
                    "label": 1
                },
                {
                    "sent": "So that's great on this script.",
                    "label": 0
                },
                {
                    "sent": "L is what's called the elbow or the variational lower bound, and that's actually what we maximize when we're doing this variational learning, and that's equivalent to minimizing the scale between our approximate posterior Q, so that's what the hypernet is actually learning.",
                    "label": 0
                },
                {
                    "sent": "And the true posterior P, which is what we want to want to match.",
                    "label": 0
                },
                {
                    "sent": "And that's because this is actually just algebra.",
                    "label": 0
                },
                {
                    "sent": "You can you can plug in these things and simplify them, and you find that the log probability of the data is equal to this lower bound plus the scale.",
                    "label": 0
                },
                {
                    "sent": "And it's also a constant.",
                    "label": 0
                },
                {
                    "sent": "So when we maximize the lower bound, we're minimizing the scale and we're getting better and better approximation to the true posterior.",
                    "label": 0
                },
                {
                    "sent": "This is like really popular, maybe the most popular technique for doing Bayesian neural Nets at the moment.",
                    "label": 0
                },
                {
                    "sent": "On so like there's this DeepMind paper on weight on certainty that I pulled that figure from earlier that uses variational inference, and there's also work from like yarn gollins ghahremani interpreting.",
                    "label": 0
                },
                {
                    "sent": "Dropout is variational inference and then also a lot of work from Maxwell is group as well.",
                    "label": 1
                },
                {
                    "sent": "Doing that with like Gaussian dropout called the local repair iteration trick.",
                    "label": 0
                },
                {
                    "sent": "And if they have a recent paper that I haven't really looked at enough, that's actually pretty similar, I think to what we're doing, although not.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Same, I like cars better from what I know.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so there's a problem with variational inference, especially when you're thinking about these.",
                    "label": 1
                },
                {
                    "sent": "These safety critical applications where you want to have calibrated confidence and the problem is that variational inference can underestimate the uncertainty that you have.",
                    "label": 1
                },
                {
                    "sent": "So the Cal Divergance, which you should all be familiar with is asymmetric.",
                    "label": 0
                },
                {
                    "sent": "So the cable between Q&P is not the same as the cable between P&Q.",
                    "label": 1
                },
                {
                    "sent": "And what happens when you run?",
                    "label": 0
                },
                {
                    "sent": "If you if you optimize this, KL divergences between a mixture of Gaussian and Gaussian in One Direction, the Gaussian is going to sort of spread out its mass to try and cover all of the modes, and then maybe it's going to put a bunch of mass in between the modes.",
                    "label": 0
                },
                {
                    "sent": "As a result, 'cause it's unimodal an in the other direction, it's just going to find one of the modes an fit.",
                    "label": 0
                },
                {
                    "sent": "That mode really well, and that's actually the direction that we use in this variational inference techniques.",
                    "label": 0
                },
                {
                    "sent": "So that means that if P is the real posterior here.",
                    "label": 0
                },
                {
                    "sent": "And Q is our variational approximation and we're trying to use Q to tell us you know how certain we are about something.",
                    "label": 0
                },
                {
                    "sent": "We might be very confident that this mode on the that's the left for you guys doesn't exist, right?",
                    "label": 0
                },
                {
                    "sent": "Because our variational posterior didn't put any mass there because it just found one of the modes.",
                    "label": 0
                },
                {
                    "sent": "So that's kind of a problem.",
                    "label": 0
                },
                {
                    "sent": "I think this problem comes both from the use of the KL divergences as a measure of discrepancy, but it also comes from the variational approximation being too simple, so pretty much all of the work.",
                    "label": 0
                },
                {
                    "sent": "Actually, I think all of the work that I know of using variational inference in Bayesian DNS uses a unimodal approximate posterior, and it's usually like a factorial Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like I have up here, which means that you just have an independent distribution for every parameter and you're totally ignoring any dependencies between those parameters or any.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and since we're using a deep net to parameterise this distribution, we can actually get something that's highly dependent in multimodal.",
                    "label": 0
                },
                {
                    "sent": "So in the same way that, like when you sample random noise and then pass it through again or via E, you can actually looks like a picture, and that's because the decoder is introducing dependencies between the outputs.",
                    "label": 0
                },
                {
                    "sent": "We have the same effect here.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's some qualitative results that just show that.",
                    "label": 1
                },
                {
                    "sent": "So on the left here I just look at the correlation between the different parameters.",
                    "label": 0
                },
                {
                    "sent": "Actually these are.",
                    "label": 0
                },
                {
                    "sent": "This is a histogram of the values.",
                    "label": 0
                },
                {
                    "sent": "The values of.",
                    "label": 0
                },
                {
                    "sent": "I think it's called Pearson's test, and so a bunch of them are below .5, so I think it's like pretty clear this correlation there and then if you also look at a simple neural net that.",
                    "label": 0
                },
                {
                    "sent": "Is given by y = a * B * X.",
                    "label": 0
                },
                {
                    "sent": "Sorry if your data is generated that way and you have a neural net that has those two that has the same architecture and you're trying to learn A&B.",
                    "label": 0
                },
                {
                    "sent": "A * B = 1 is the solution and any A&B that have the product of 1 give the solution, so that's what those red lines are and the dots here are samples from our posterior and you see that it actually puts a bunch of mass on both of the modes there 1 one and minus 1 -- 1.",
                    "label": 0
                },
                {
                    "sent": "This on.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see.",
                    "label": 0
                },
                {
                    "sent": "So hyper Nets are kind of a recent thing, although maybe there's more work on them.",
                    "label": 0
                },
                {
                    "sent": "In the past people people use them with like a fixed input, whereas what we're doing is different because we're feeding noise into the hyper net and that gives us this distribution on.",
                    "label": 0
                },
                {
                    "sent": "Let's see how we do this so, so another issue that we encountered is that there's a lot of parameters, and in the primary netan, if you just have if you put all of those.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's your hypernet becomes really large, so instead in our work we were just out putting the scaling factors in weight normalization.",
                    "label": 1
                },
                {
                    "sent": "So here you basically decouples the length and direction of a weight vector and the length is given by this extra scaling parameter, and so the way that we parameterized our primary net is the direction parameters are just fixed and the scaling parameters are the output of the hypernet and so that means we reduce the number of outputs that we need to.",
                    "label": 0
                },
                {
                    "sent": "Get out of the hipernet from like the number of units squared to just the number of units and that makes things a lot more tractable.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there's this other background.",
                    "label": 0
                },
                {
                    "sent": "I think Aaron talked about this on this morning about like normalizing flows, an invertible degenerative models.",
                    "label": 1
                },
                {
                    "sent": "So actually I should have mentioned this when I showed you the equation back here.",
                    "label": 0
                },
                {
                    "sent": "This entropy term in order to estimate it, you actually need to have one of these normalizing flow models.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the other terms of this expectation, those are just the likelihood in the prior that you would have when you try to normal net.",
                    "label": 0
                },
                {
                    "sent": "It's this last one that's kind of different.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And the way that we get the that we compute these terms by sampling some parameters from the hypernet and then just computing them and what we need to compute this last entry term, we need to find out what the likelihood of the parameters that we sampled is, and so that's where we need to use one of these invertible models.",
                    "label": 0
                },
                {
                    "sent": "I'm kind of running out of time, unfortunately, but.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's some results where we just show that actually you can beat dropout by having.",
                    "label": 1
                },
                {
                    "sent": "By using this model on a subset of Ms on you get better generalization performance.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I guess I guess I'll stop there and take some questions.",
                    "label": 0
                }
            ]
        }
    }
}