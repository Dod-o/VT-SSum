{
    "id": "4pb7uvpnfpdpo36jabhczewfxw55awu4",
    "title": "Distributed Markov chain Monte Carlo",
    "info": {
        "author": [
            "Lawrence Murray, CSIRO Mathematics, Informatics and Statistics"
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Monte Carlo Methods",
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_murray_dmc/",
    "segmentation": [
        [
            "OK, so just to motivate this little bit, I'm looking at Bayesian inference in environmental models, potentially quite large scale models.",
            "But to begin with."
        ],
        [
            "Sort of small scale models have quite complex nonlinear dynamics were using particle Markov chain Monte Carlo techniques for those who aren't familiar with that.",
            "In a nutshell, we're doing Metropolis Hastings over the parameters of the model.",
            "We need to use something to estimate the marginal likelihoods over the state, and we're using particle filters for that purpose.",
            "We currently we can execute the particle filters very readily on GPU's propagation of particles.",
            "Forward is independent and we have quite an efficient implementation doing that.",
            "Takes several seconds for the larger models it could take up to minutes, so it's quite a computationally expensive operation.",
            "And to scale things up, what we really want to do, we don't need to distribute over the model or."
        ],
        [
            "The data, as we've seen in other talks today, we really need to sort of distribute over the method if you like and get rid of some of this computational complexity.",
            "So what we're trying to do for that is to use multiple chains, multiple Markov chains, so the sort of issues you begin to deal with multiple chains you have this idea of quasi adicity, so obviously your chains theoretically agatic to some target distribution, but they tend to get in practice in finite time, get trapped in local modes on ridges for correlated variables, and these sorts of things.",
            "Now we don't get over that with.",
            "With multiple chains, for example with multiple chains, we might hope to capture all of our mode.",
            "So here Blue is a target distribution, orange is the starting distribution, will initialize chains, and if we for example initialize a single chain, it might get trapped in one mode.",
            "OK, if we initialize many many chains, they still get trapped.",
            "In modes we might discover all of our modes, but we don't get the waiting between them.",
            "So that's one issue we might like to deal with.",
            "Multiple chains another."
        ],
        [
            "And this from scalability is the most critical issue.",
            "In MCMC we always remove some burning period from the chain.",
            "OK, this is the period weather change converging.",
            "It hasn't yet got to equilibrium, so we can't consider those samples to be from the target distribution.",
            "Now that proportion that we remove is burning is usually quite significant.",
            "It could be up to 50%, but say it's about 20%.",
            "This limits our speed up quite drastically right.",
            "Even if we had as many chains for millions and millions of chain sampling and only need to draw 1 sample each, they still have to get through this burning.",
            "So if it's a 20% burning.",
            "Our maximum."
        ],
        [
            "Speed up, regardless of the number of processes we bring to bear, is is 5 in that case.",
            "So the method looking at here is to say each chain has its own local proposal that might be Gibbs.",
            "It might be a random walk metropolis Hastings type idea, and this method doesn't preclude the adaptation of that or Hamiltonian dynamics sorts of things.",
            "But what we're proposing to do is mix in this other remote component or global component if you like, and this draws on information from all chains in the ensemble.",
            "Now the suggestion is that perhaps you know construct this from a all chains contributor component to each other chain, and in some sense what we're trying to do is get our best estimate of the posterior today.",
            "And if we mix them in this way instead of using a set of using a mixture, take at any point the maximum density from each of those components, we get a density estimate that if you like independent of the number of chains operating in the vicinity of that sample.",
            "OK, just say we can draw from this with rejection sampling, right?",
            "And so this sort of seems a neat sort of way forward perhaps, and also by adapting proposal.",
            "So we're adapting this as we go right?",
            "That adaptation can happen asynchronously, so we're not.",
            "If we were exchanging samples between chains, for example, as would be the case with, say, parallel tempering, then we have synchronous operations, and that might be problematic for us, especially since if you think about the MCMC example that I gave, if it takes you a minute to computer likelihood.",
            "And you have to do synchronous exchange."
        ],
        [
            "Age is potentially a process is waiting up to a minute for another chain to exchange with OK, so this could be quite critical, so just some very preliminary results and I will say that there are some caveats with these plots and if you want to know more about it, please ask me afterwards, but this is for two chains for Chainset Chain 16 chains, just by way of comparison, the dark orange hear or read is a random walk in public Hastings.",
            "This is just a convergence statistics so as it gets towards one we can consider it to be converged.",
            "Blue here is the method that we are proposing.",
            "This distributed MCMC and it seems to converge a fair bit faster using this sort of sort of strategy.",
            "So if this is of interest, I'm happy to talk to people afterwards."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just to motivate this little bit, I'm looking at Bayesian inference in environmental models, potentially quite large scale models.",
                    "label": 0
                },
                {
                    "sent": "But to begin with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sort of small scale models have quite complex nonlinear dynamics were using particle Markov chain Monte Carlo techniques for those who aren't familiar with that.",
                    "label": 1
                },
                {
                    "sent": "In a nutshell, we're doing Metropolis Hastings over the parameters of the model.",
                    "label": 0
                },
                {
                    "sent": "We need to use something to estimate the marginal likelihoods over the state, and we're using particle filters for that purpose.",
                    "label": 0
                },
                {
                    "sent": "We currently we can execute the particle filters very readily on GPU's propagation of particles.",
                    "label": 0
                },
                {
                    "sent": "Forward is independent and we have quite an efficient implementation doing that.",
                    "label": 0
                },
                {
                    "sent": "Takes several seconds for the larger models it could take up to minutes, so it's quite a computationally expensive operation.",
                    "label": 0
                },
                {
                    "sent": "And to scale things up, what we really want to do, we don't need to distribute over the model or.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data, as we've seen in other talks today, we really need to sort of distribute over the method if you like and get rid of some of this computational complexity.",
                    "label": 0
                },
                {
                    "sent": "So what we're trying to do for that is to use multiple chains, multiple Markov chains, so the sort of issues you begin to deal with multiple chains you have this idea of quasi adicity, so obviously your chains theoretically agatic to some target distribution, but they tend to get in practice in finite time, get trapped in local modes on ridges for correlated variables, and these sorts of things.",
                    "label": 0
                },
                {
                    "sent": "Now we don't get over that with.",
                    "label": 0
                },
                {
                    "sent": "With multiple chains, for example with multiple chains, we might hope to capture all of our mode.",
                    "label": 1
                },
                {
                    "sent": "So here Blue is a target distribution, orange is the starting distribution, will initialize chains, and if we for example initialize a single chain, it might get trapped in one mode.",
                    "label": 1
                },
                {
                    "sent": "OK, if we initialize many many chains, they still get trapped.",
                    "label": 0
                },
                {
                    "sent": "In modes we might discover all of our modes, but we don't get the waiting between them.",
                    "label": 0
                },
                {
                    "sent": "So that's one issue we might like to deal with.",
                    "label": 0
                },
                {
                    "sent": "Multiple chains another.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this from scalability is the most critical issue.",
                    "label": 0
                },
                {
                    "sent": "In MCMC we always remove some burning period from the chain.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the period weather change converging.",
                    "label": 0
                },
                {
                    "sent": "It hasn't yet got to equilibrium, so we can't consider those samples to be from the target distribution.",
                    "label": 0
                },
                {
                    "sent": "Now that proportion that we remove is burning is usually quite significant.",
                    "label": 0
                },
                {
                    "sent": "It could be up to 50%, but say it's about 20%.",
                    "label": 0
                },
                {
                    "sent": "This limits our speed up quite drastically right.",
                    "label": 0
                },
                {
                    "sent": "Even if we had as many chains for millions and millions of chain sampling and only need to draw 1 sample each, they still have to get through this burning.",
                    "label": 0
                },
                {
                    "sent": "So if it's a 20% burning.",
                    "label": 0
                },
                {
                    "sent": "Our maximum.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Speed up, regardless of the number of processes we bring to bear, is is 5 in that case.",
                    "label": 0
                },
                {
                    "sent": "So the method looking at here is to say each chain has its own local proposal that might be Gibbs.",
                    "label": 1
                },
                {
                    "sent": "It might be a random walk metropolis Hastings type idea, and this method doesn't preclude the adaptation of that or Hamiltonian dynamics sorts of things.",
                    "label": 1
                },
                {
                    "sent": "But what we're proposing to do is mix in this other remote component or global component if you like, and this draws on information from all chains in the ensemble.",
                    "label": 0
                },
                {
                    "sent": "Now the suggestion is that perhaps you know construct this from a all chains contributor component to each other chain, and in some sense what we're trying to do is get our best estimate of the posterior today.",
                    "label": 0
                },
                {
                    "sent": "And if we mix them in this way instead of using a set of using a mixture, take at any point the maximum density from each of those components, we get a density estimate that if you like independent of the number of chains operating in the vicinity of that sample.",
                    "label": 0
                },
                {
                    "sent": "OK, just say we can draw from this with rejection sampling, right?",
                    "label": 0
                },
                {
                    "sent": "And so this sort of seems a neat sort of way forward perhaps, and also by adapting proposal.",
                    "label": 0
                },
                {
                    "sent": "So we're adapting this as we go right?",
                    "label": 0
                },
                {
                    "sent": "That adaptation can happen asynchronously, so we're not.",
                    "label": 0
                },
                {
                    "sent": "If we were exchanging samples between chains, for example, as would be the case with, say, parallel tempering, then we have synchronous operations, and that might be problematic for us, especially since if you think about the MCMC example that I gave, if it takes you a minute to computer likelihood.",
                    "label": 0
                },
                {
                    "sent": "And you have to do synchronous exchange.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Age is potentially a process is waiting up to a minute for another chain to exchange with OK, so this could be quite critical, so just some very preliminary results and I will say that there are some caveats with these plots and if you want to know more about it, please ask me afterwards, but this is for two chains for Chainset Chain 16 chains, just by way of comparison, the dark orange hear or read is a random walk in public Hastings.",
                    "label": 0
                },
                {
                    "sent": "This is just a convergence statistics so as it gets towards one we can consider it to be converged.",
                    "label": 0
                },
                {
                    "sent": "Blue here is the method that we are proposing.",
                    "label": 0
                },
                {
                    "sent": "This distributed MCMC and it seems to converge a fair bit faster using this sort of sort of strategy.",
                    "label": 0
                },
                {
                    "sent": "So if this is of interest, I'm happy to talk to people afterwards.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}