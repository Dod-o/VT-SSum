{
    "id": "rkiu2emhgsv2zu4jncxzuydhs7asvrjx",
    "title": "Probabilistic Temporal Inference on Reconstructed 3D Scenes",
    "info": {
        "author": [
            "Grant Schindler, College of Computing, Georgia Institute of Technology"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Stereo & Structure from Motion"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_schindler_pti/",
    "segmentation": [
        [
            "Thank you for the introduction, so I'll jump right into it."
        ],
        [
            "The primary question that motivates our work with the primary observation is that the world changes overtime if we hope to model the world from photo collections, we should really have a way of modeling time and the way that structures change overtime, and the fact that images are taken at different times in our models.",
            "So that this work is about."
        ],
        [
            "The temporal inference problem that we're defining here is as follows.",
            "Given a set of photographs, in this case, the area of Lower Manhattan in New York City, taken over a range of time and a set of objects, in this case, buildings that are being observed.",
            "You want to be able to answer three different questions.",
            "First is when was each photograph taken?",
            "Second, when did each building first appear?",
            "And finally, when was each building removed from the scene, if at all?"
        ],
        [
            "So there's a strong relationship between the temporal inference problem in the structure from motion problem and triple typical structure from motion problem.",
            "We start with images and we moved to detecting feature correspondences across those images and we reconstruct 3D model, recovering both of the structure of the scene and information about the cameras, including opposing focal length, camera and XYZ position for each piece of structure.",
            "So in the temporal inference problem, we're really interested in augmenting the structure from motion problem with additional temporal variables.",
            "That is, for every piece of structure in the scene, we have a time interval from time to time be that describes when that piece of structure existed.",
            "As well as a time T for every image for every camera that describes when the image is taken.",
            "So we can formally define the temporal inference problem Now as given observations Z, which are really our correspondences across the images detailing which features and which points are seen in which images and scene geometry X, which is the result of structure from motion.",
            "What are the temporal parameters T which are our time intervals and times for each camera?"
        ],
        [
            "So an overview of the approach that we use and an outline of this talk is as follows.",
            "We start with."
        ],
        [
            "Images.",
            "We find correspondences between those images and reconstruct 3D point part of the scene in this cable case we're also looking at lower Manhattan."
        ],
        [
            "From there we grouped these points into buildings.",
            "An once."
        ],
        [
            "Have these buildings.",
            "It is those buildings that we apply temporal until we figure out when each building existed, so we can look at the model, for example, at different points in time.",
            "So before I jump into the temporal inference framework, I'm going to briefly describe how exactly our structure for motion."
        ],
        [
            "Approach works.",
            "The 3D reconstruction we're using is based on the bundler software by Noah Snavely.",
            "So given a collection of images, in this case around 500 images of Manhattan we get out of three point cloud that looks like the one you see on the right and bundler is really nice open source package.",
            "I recommend people use it works right off the shelf so we so we base our approach on that given this point."
        ],
        [
            "Fire now.",
            "We want to group these points into buildings, so one of the primary reasons for doing so is that when we're performing temporal inference and searching for these temporal variables, it makes much more sense to reason about a few 100 buildings rather than 10s of thousands of points.",
            "So the way we group these points is very simple.",
            "We apply two criteria.",
            "If there's a distance threshold of 2, three points are close enough to each other in 3D space and their simultaneously observed and at least one image, meaning there are features detected for both those points and at least one image.",
            "Then we group them together we find connected components in this space and then for these point groups we simply to get the building geometry.",
            "Convex holes of these groups and extend those chemicals down to a ground plane which is estimated based on where the camera centers are located in the sea.",
            "So this is how we get our."
        ],
        [
            "3D structure for the scene.",
            "This is what it looks like an animation here showing our lower Manhattan data set from 454 images.",
            "We have 83,000 points that we segment into 960 buildings and this is for a scene ranging from 1928 to 2010.",
            "So this scene up till now is this representation is purely without time.",
            "We need to now add the temporal variables when did each camera take the picture an when did each of these buildings exist?",
            "And so that's what I'll do."
        ],
        [
            "Drive now.",
            "So one previous approach to introducing time into this problem was a constraint satisfaction approach that we introduced in CPR 2007 effect and the main topic was inferring the temporal order of images from 3D structure.",
            "So the key idea here was that the visibility pattern of three points across images constrains the ordering of those images in time.",
            "And we use that same idea here.",
            "But there are several disadvantages to the constraint satisfaction approach.",
            "The first disadvantage is that only a relative image ordering comes out, and here we're interested in actually getting absolute image dates from the result of temporal inference.",
            "A second disadvantage is that perfect observations are required because we're looking into constraint satisfaction framework.",
            "That means that every element of scene structure has to be perfectly observed in each image.",
            "If it exists, we need to have detected it there.",
            "And so, since we want to work with fully automatic scene reconstructions, we know that a SIFT features are not detected for every single three point in every single image, so.",
            "Because of this inherent noisiness in automatically constructions, we need something more than a constraint satisfaction framework and so."
        ],
        [
            "Move to a probabilistic temporal inference framework.",
            "So the definition of this problem we're trying to do is we're trying to maximize the probability of our time parameters T given our observations Z which remember our point correspondences that tell which elements of the structure observed in which images in our scene geometry X, which is the result structure from motion.",
            "So proceeding in a Bayesian manner, we factor this probability into two terms, which will go into more detail on here.",
            "The first term as an observation probability.",
            "This is telling us this is essentially encapsulating our visibility reasoning.",
            "Why are we seeing the things that we're seeing in each image?",
            "And we can deal with noisy building observations in this probabilistic framework.",
            "And the second part of the second term here is our image date prior.",
            "If we have any information about image dates, even if they're noisy, we can include those in this temporal problem, and so we incorporate absolute dates into the problem.",
            "So now go into more detail exactly how each of these two terms."
        ],
        [
            "Computed.",
            "So first the image date prior.",
            "So there are many sources of data information for images, primarily for digital images.",
            "We have the Exif tags and all your digital cameras will embed precise date and time stamp for all the images are taking now, so for the past decade or so we have nice.",
            "We have nicely information, but for historical images we have to rely on database annotations and online databases.",
            "For these historical images in those dates are often uncertain.",
            "So for example, we might have an image that's just labeled may 1970.",
            "That's actually pretty good.",
            "We have a month and a year, we just don't have the day, so that's that's pretty precise.",
            "On the other hand, we have completely undated images in which a human archivist might have looked at this image and just had no idea when it was taken from.",
            "And so they said undated.",
            "The most common case in fact, though, is circa dates, so this image is circa 1910.",
            "This means it's a human expert.",
            "Looked at this image in the best they could do is assign a decade to it within within 10 years or so, so these are very useful bits of information these circuits, but they're highly uncertain.",
            "And So what we do is we incorporate these image dates using a prior.",
            "In the case of undated images, we have a uniform prior over the potential values for these variables T that described when the images taken.",
            "If we have any date estimate information, though, we use a normal distribution with a mean is centered around the estimated date that we have and the uncertainty increases for increasing uncertainty in that date.",
            "So for example, circuit images are highly uncertain, whereas this image is dated May 1970.",
            "We have we're fairly certain of that date, so we have a smaller Sigma.",
            "So this is how we incorporate absolutdata information into our scene, but we can still deal with the fact that we have many images that are undated or uncertain."
        ],
        [
            "The next term we look at, and this is really the crux of the method, is the observation probability model.",
            "So I'll go into more detail, but each of these variables and remind you what each of these means, but we're looking at here is really the probability of our observations given a set of temporal parameters and the structure parameters.",
            "So remember, we have known geometry.",
            "We performed a structure for motion already.",
            "We know exactly where the cameras are, where the scene geometry is, and we're testing some hypothesize time parameters and to assign it a score and see how well do these time parameters agree with the observations of why we want to explain why we're seeing each building in each image.",
            "And we can factor this into the product of individual probabilities on these ZJ observations, which ZJ is just a binary variable that describes was it was object I observed in image J.",
            "And we want to make sure that our temporal parameters are choosing explain those observations well.",
            "So the key to to evaluating this probability is answering three different questions.",
            "First, we can ask is the object is object within the field of view of camera J and note that this is dependent upon extra scene structure only and this is an easy question.",
            "We can precompute this before we have any information about time.",
            "The second question is did object exist at the time image was captured?",
            "This is purely dependent on time.",
            "This is also fairly easy to evaluate.",
            "The final question we need to answer is, is there any occlusion is object I excluded by some other objects in image J?",
            "You know that this depends on both X&T depends on the scene structure and the time parameters.",
            "That's because buildings buildings have uncertain dates of when they exist and those buildings act as the occlusion geometry as well.",
            "So we don't even know if our occlusion geometry exists at the time the images taken.",
            "So this is in fact quite a difficult problem.",
            "I will refer you to the paper for details on how we solve this.",
            "One of the technical contributions were making is an efficient way of computing these occlusion terms.",
            "Given that we don't know which objects exist at which time.",
            "A priority.",
            "So this is our, this is our probability model for how we evaluate a set of."
        ],
        [
            "Parameters so we want to know.",
            "How to go about maximizing this?",
            "Finding the optimal temporal parameters.",
            "So we use is a Markov chain Monte Carlo MCMC sampling approach.",
            "What that means is that we start with an initial set of temporal parameters based on the image data information that we do have, and we propose to move one of the image dates.",
            "We then analytically solve for the building date intervals we can maximize.",
            "We can find the maximum probable building date intervals given any set of image dates, and we evaluate the probability of the temporal parameters in this case.",
            "And finally we accept or reject that move based on the ratio of probabilities of the two sets of temporal parameters."
        ],
        [
            "Previous ones are new ones that we're proposing."
        ],
        [
            "So we move around image dates and we keep track of where our samples are landing and so we actually build up a density on our temporal parameters overtime."
        ],
        [
            "So in our experiments here, we're drawing 80,000 samples of.",
            "This takes about 1.3 hours for a case in which we're dealing with 100 images."
        ],
        [
            "So our results here.",
            "I'll start with results on a synthetic scene.",
            "So what we do is we have seen a synthetic scene of 100 images observing 30 buildings over an 80 year time period.",
            "And what we do is we set 1/3 of these dates to be known dates.",
            "130 days to be certain dates which are highly uncertain and 1/3 of the dates on the images to be completely unknown, so.",
            "When we initialize our model under these conditions, we have an initial error of 19.31 years, and that's because we have completely unknown dates for all these updated images.",
            "What we do after a full temporal optimization of the MCMC sampling, the result that we get is our root mean square error is reduced to 2.8 seven years.",
            "So despite the fact that we have unknown dates for 1/3 of the images were able to get an average error of less than three years by incorporating visibility information from those images and combining it with the data information that we do know for the other images in the scene.",
            "And in the visualization you see on the left, the blue pixels represent the density of MCMC samples, while the red pixels represent the ground truth information that we have for these dates.",
            "And you'll notice that in the case of undated images, they are extended extended regions of blue which indicate the possible dates for those images.",
            "We can't do any better than narrowing it down to a region during which the same buildings might have existed.",
            "So next we look at a.",
            "The scene for some real."
        ],
        [
            "At.",
            "So we look at downtown Atlanta, set of data for this case we have 102 images.",
            "These are real historical images.",
            "In fact, don't have ground truth for these images.",
            "This is a real historical problem where we have uncertain dates and some of the images are even undated.",
            "You'll see at the top of the graph here the undated images, which have no, we have no given data estimates.",
            "So we can qualitatively evaluate the results on this data set in a few ways.",
            "First of all week and on the right side here visualize the building date intervals by taking the point cloud and rendering it a different points in time.",
            "So here we see the point cloud from this perspective, rendered in 1960, nineteen, 65 and 1970s.",
            "As buildings are constructed, there added to the model.",
            "And the second week."
        ],
        [
            "Qualitatively evaluate this is by looking at individual images.",
            "So for example, here we have an undated image in our data set.",
            "This means a human look at this image and had no idea when it was taken, and so our method is able to assign a date range of about 1956 to 1961.",
            "You'll notice there's a range of dates over which these MCMC samples exist, which one of the vantage of our system is that we're not just assigning a point date estimate.",
            "We are able to were able to actually have densities over the entire range of time, and so we're not unduly making bad decisions.",
            "About time if we if we don't have certain information."
        ],
        [
            "So to look at some more quantitative results, we did leave one out image dating experiment on Lower Manhattan data set, in which we do have ground truth.",
            "And so for example, you see for the image on the right, which is originally dated 1935, we throw out that image data and keep all the other image dates for the data set and we re estimate this image by running our temporal inference method.",
            "And we get a strongly peaked distribution, which happens to be around 1937.",
            "So we get an error of only two years, and this is.",
            "This is a fairly common occurrence over the whole data set.",
            "We get errors of less than five years for over 48% of our images, so this is promising promising performances task that has been completely impossible before this method."
        ],
        [
            "And finally, we can visualize the building data intervals we have for this point cloud of Manhattan as we scroll through time from 1928 to 2010.",
            "We can see buildings appearing and we see here the Point Cloud, which is what we have is not just a static point cloud but we have segmented this point cloud into semantically meaningful objects, and for each object we know when it existed.",
            "When it came into existence and we may have left existence.",
            "So this is a fairly powerful upgrade to just us."
        ],
        [
            "Static point cloud.",
            "So finally, some conclusions and future work.",
            "We presented an automatic probabilistic temporal inference method.",
            "I've shown you results for synthetic scene and two challenging real world data sets.",
            "And in future work, one of the most challenging tasks here is actually the feature correspondence problem across time.",
            "So you see on the bottom here 2 images of lower Manhattan, 1 from 1930 and 1 from 2009, and they're only 19 point correspondences between these two images, despite the fact that the viewing the exact same scene and many of the buildings still exist.",
            "And this is in fact the best set of correspondences we get for this.",
            "For this range of time so.",
            "There are two solutions to overcoming this problem.",
            "One is to throw more data at the problem and find densely sampled images in space and time, and eventually we'll find enough matches so that we can reconstruct these models and even perform temporal inference in the 1st place.",
            "And 2nd is an interesting direction we design and find some time invariant features.",
            "And we don't know what those might be, but it's an interesting direction to going so no one has looked at features that are invariant specifically to time."
        ],
        [
            "So with that, thank you very much and open questions.",
            "Your work is very clever.",
            "Could you clarify the how you deal with the situation?",
            "We have two buildings that occupy the same space but in different time intervals.",
            "Yes, so in fact the reason we are so yeah, so the question is, I guess you've spoken with microphone, but if we have two buildings occupying the same space at different times, our method is able to deal with that because our grouping criteria for grouping points into building specifies that to group two points they have to be simultaneously observed in the same image.",
            "This is our way.",
            "Of kind of incorporating time into our grouping process without before we explicitly know the times of the images.",
            "So we have this kind of simelton 80 criteria.",
            "Two points have to exist at the same time before we group them, and that eliminates those problems of grouping 2 images, despite the fact that it might be overlapping in space.",
            "Grouping to buildings sorry.",
            "OK I have a question.",
            "If you know that certain building is within a decade of equal circuit, so why wouldn't you model it with uniform distribution rather than a Gaussian like uniform for that Dick decade rather than spreading it for longer period of time?",
            "OK, so you're right.",
            "So so if we if we know that an image is within a certain decade.",
            "So if we have a label that says 1950s, that's actually different from something that says circa 1950.",
            "And there are a variety of labels such as before 1970 after 1945.",
            "That we we haven't.",
            "We haven't explicitly knowledge in this talk, but of course, right we can.",
            "We can make priors that makes sense for those.",
            "For those date labels.",
            "So yes, if we had something that explicitly said 1950s, we could have a 1950 to 1960 prior, but we don't necessarily trust human archivists and historians that much.",
            "So we might want to let them roam outside of those boundaries.",
            "Let's thank the speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for the introduction, so I'll jump right into it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The primary question that motivates our work with the primary observation is that the world changes overtime if we hope to model the world from photo collections, we should really have a way of modeling time and the way that structures change overtime, and the fact that images are taken at different times in our models.",
                    "label": 0
                },
                {
                    "sent": "So that this work is about.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The temporal inference problem that we're defining here is as follows.",
                    "label": 0
                },
                {
                    "sent": "Given a set of photographs, in this case, the area of Lower Manhattan in New York City, taken over a range of time and a set of objects, in this case, buildings that are being observed.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to answer three different questions.",
                    "label": 0
                },
                {
                    "sent": "First is when was each photograph taken?",
                    "label": 0
                },
                {
                    "sent": "Second, when did each building first appear?",
                    "label": 0
                },
                {
                    "sent": "And finally, when was each building removed from the scene, if at all?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a strong relationship between the temporal inference problem in the structure from motion problem and triple typical structure from motion problem.",
                    "label": 0
                },
                {
                    "sent": "We start with images and we moved to detecting feature correspondences across those images and we reconstruct 3D model, recovering both of the structure of the scene and information about the cameras, including opposing focal length, camera and XYZ position for each piece of structure.",
                    "label": 0
                },
                {
                    "sent": "So in the temporal inference problem, we're really interested in augmenting the structure from motion problem with additional temporal variables.",
                    "label": 0
                },
                {
                    "sent": "That is, for every piece of structure in the scene, we have a time interval from time to time be that describes when that piece of structure existed.",
                    "label": 0
                },
                {
                    "sent": "As well as a time T for every image for every camera that describes when the image is taken.",
                    "label": 0
                },
                {
                    "sent": "So we can formally define the temporal inference problem Now as given observations Z, which are really our correspondences across the images detailing which features and which points are seen in which images and scene geometry X, which is the result of structure from motion.",
                    "label": 0
                },
                {
                    "sent": "What are the temporal parameters T which are our time intervals and times for each camera?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So an overview of the approach that we use and an outline of this talk is as follows.",
                    "label": 0
                },
                {
                    "sent": "We start with.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Images.",
                    "label": 0
                },
                {
                    "sent": "We find correspondences between those images and reconstruct 3D point part of the scene in this cable case we're also looking at lower Manhattan.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From there we grouped these points into buildings.",
                    "label": 0
                },
                {
                    "sent": "An once.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have these buildings.",
                    "label": 0
                },
                {
                    "sent": "It is those buildings that we apply temporal until we figure out when each building existed, so we can look at the model, for example, at different points in time.",
                    "label": 0
                },
                {
                    "sent": "So before I jump into the temporal inference framework, I'm going to briefly describe how exactly our structure for motion.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach works.",
                    "label": 0
                },
                {
                    "sent": "The 3D reconstruction we're using is based on the bundler software by Noah Snavely.",
                    "label": 0
                },
                {
                    "sent": "So given a collection of images, in this case around 500 images of Manhattan we get out of three point cloud that looks like the one you see on the right and bundler is really nice open source package.",
                    "label": 0
                },
                {
                    "sent": "I recommend people use it works right off the shelf so we so we base our approach on that given this point.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fire now.",
                    "label": 0
                },
                {
                    "sent": "We want to group these points into buildings, so one of the primary reasons for doing so is that when we're performing temporal inference and searching for these temporal variables, it makes much more sense to reason about a few 100 buildings rather than 10s of thousands of points.",
                    "label": 0
                },
                {
                    "sent": "So the way we group these points is very simple.",
                    "label": 0
                },
                {
                    "sent": "We apply two criteria.",
                    "label": 0
                },
                {
                    "sent": "If there's a distance threshold of 2, three points are close enough to each other in 3D space and their simultaneously observed and at least one image, meaning there are features detected for both those points and at least one image.",
                    "label": 0
                },
                {
                    "sent": "Then we group them together we find connected components in this space and then for these point groups we simply to get the building geometry.",
                    "label": 0
                },
                {
                    "sent": "Convex holes of these groups and extend those chemicals down to a ground plane which is estimated based on where the camera centers are located in the sea.",
                    "label": 0
                },
                {
                    "sent": "So this is how we get our.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "3D structure for the scene.",
                    "label": 0
                },
                {
                    "sent": "This is what it looks like an animation here showing our lower Manhattan data set from 454 images.",
                    "label": 0
                },
                {
                    "sent": "We have 83,000 points that we segment into 960 buildings and this is for a scene ranging from 1928 to 2010.",
                    "label": 0
                },
                {
                    "sent": "So this scene up till now is this representation is purely without time.",
                    "label": 0
                },
                {
                    "sent": "We need to now add the temporal variables when did each camera take the picture an when did each of these buildings exist?",
                    "label": 0
                },
                {
                    "sent": "And so that's what I'll do.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Drive now.",
                    "label": 0
                },
                {
                    "sent": "So one previous approach to introducing time into this problem was a constraint satisfaction approach that we introduced in CPR 2007 effect and the main topic was inferring the temporal order of images from 3D structure.",
                    "label": 0
                },
                {
                    "sent": "So the key idea here was that the visibility pattern of three points across images constrains the ordering of those images in time.",
                    "label": 0
                },
                {
                    "sent": "And we use that same idea here.",
                    "label": 0
                },
                {
                    "sent": "But there are several disadvantages to the constraint satisfaction approach.",
                    "label": 0
                },
                {
                    "sent": "The first disadvantage is that only a relative image ordering comes out, and here we're interested in actually getting absolute image dates from the result of temporal inference.",
                    "label": 0
                },
                {
                    "sent": "A second disadvantage is that perfect observations are required because we're looking into constraint satisfaction framework.",
                    "label": 0
                },
                {
                    "sent": "That means that every element of scene structure has to be perfectly observed in each image.",
                    "label": 0
                },
                {
                    "sent": "If it exists, we need to have detected it there.",
                    "label": 0
                },
                {
                    "sent": "And so, since we want to work with fully automatic scene reconstructions, we know that a SIFT features are not detected for every single three point in every single image, so.",
                    "label": 0
                },
                {
                    "sent": "Because of this inherent noisiness in automatically constructions, we need something more than a constraint satisfaction framework and so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move to a probabilistic temporal inference framework.",
                    "label": 0
                },
                {
                    "sent": "So the definition of this problem we're trying to do is we're trying to maximize the probability of our time parameters T given our observations Z which remember our point correspondences that tell which elements of the structure observed in which images in our scene geometry X, which is the result structure from motion.",
                    "label": 0
                },
                {
                    "sent": "So proceeding in a Bayesian manner, we factor this probability into two terms, which will go into more detail on here.",
                    "label": 0
                },
                {
                    "sent": "The first term as an observation probability.",
                    "label": 0
                },
                {
                    "sent": "This is telling us this is essentially encapsulating our visibility reasoning.",
                    "label": 0
                },
                {
                    "sent": "Why are we seeing the things that we're seeing in each image?",
                    "label": 0
                },
                {
                    "sent": "And we can deal with noisy building observations in this probabilistic framework.",
                    "label": 0
                },
                {
                    "sent": "And the second part of the second term here is our image date prior.",
                    "label": 0
                },
                {
                    "sent": "If we have any information about image dates, even if they're noisy, we can include those in this temporal problem, and so we incorporate absolute dates into the problem.",
                    "label": 0
                },
                {
                    "sent": "So now go into more detail exactly how each of these two terms.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Computed.",
                    "label": 0
                },
                {
                    "sent": "So first the image date prior.",
                    "label": 0
                },
                {
                    "sent": "So there are many sources of data information for images, primarily for digital images.",
                    "label": 0
                },
                {
                    "sent": "We have the Exif tags and all your digital cameras will embed precise date and time stamp for all the images are taking now, so for the past decade or so we have nice.",
                    "label": 0
                },
                {
                    "sent": "We have nicely information, but for historical images we have to rely on database annotations and online databases.",
                    "label": 0
                },
                {
                    "sent": "For these historical images in those dates are often uncertain.",
                    "label": 0
                },
                {
                    "sent": "So for example, we might have an image that's just labeled may 1970.",
                    "label": 0
                },
                {
                    "sent": "That's actually pretty good.",
                    "label": 0
                },
                {
                    "sent": "We have a month and a year, we just don't have the day, so that's that's pretty precise.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we have completely undated images in which a human archivist might have looked at this image and just had no idea when it was taken from.",
                    "label": 0
                },
                {
                    "sent": "And so they said undated.",
                    "label": 0
                },
                {
                    "sent": "The most common case in fact, though, is circa dates, so this image is circa 1910.",
                    "label": 0
                },
                {
                    "sent": "This means it's a human expert.",
                    "label": 0
                },
                {
                    "sent": "Looked at this image in the best they could do is assign a decade to it within within 10 years or so, so these are very useful bits of information these circuits, but they're highly uncertain.",
                    "label": 0
                },
                {
                    "sent": "And So what we do is we incorporate these image dates using a prior.",
                    "label": 0
                },
                {
                    "sent": "In the case of undated images, we have a uniform prior over the potential values for these variables T that described when the images taken.",
                    "label": 0
                },
                {
                    "sent": "If we have any date estimate information, though, we use a normal distribution with a mean is centered around the estimated date that we have and the uncertainty increases for increasing uncertainty in that date.",
                    "label": 0
                },
                {
                    "sent": "So for example, circuit images are highly uncertain, whereas this image is dated May 1970.",
                    "label": 0
                },
                {
                    "sent": "We have we're fairly certain of that date, so we have a smaller Sigma.",
                    "label": 0
                },
                {
                    "sent": "So this is how we incorporate absolutdata information into our scene, but we can still deal with the fact that we have many images that are undated or uncertain.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next term we look at, and this is really the crux of the method, is the observation probability model.",
                    "label": 0
                },
                {
                    "sent": "So I'll go into more detail, but each of these variables and remind you what each of these means, but we're looking at here is really the probability of our observations given a set of temporal parameters and the structure parameters.",
                    "label": 0
                },
                {
                    "sent": "So remember, we have known geometry.",
                    "label": 0
                },
                {
                    "sent": "We performed a structure for motion already.",
                    "label": 0
                },
                {
                    "sent": "We know exactly where the cameras are, where the scene geometry is, and we're testing some hypothesize time parameters and to assign it a score and see how well do these time parameters agree with the observations of why we want to explain why we're seeing each building in each image.",
                    "label": 0
                },
                {
                    "sent": "And we can factor this into the product of individual probabilities on these ZJ observations, which ZJ is just a binary variable that describes was it was object I observed in image J.",
                    "label": 0
                },
                {
                    "sent": "And we want to make sure that our temporal parameters are choosing explain those observations well.",
                    "label": 0
                },
                {
                    "sent": "So the key to to evaluating this probability is answering three different questions.",
                    "label": 0
                },
                {
                    "sent": "First, we can ask is the object is object within the field of view of camera J and note that this is dependent upon extra scene structure only and this is an easy question.",
                    "label": 0
                },
                {
                    "sent": "We can precompute this before we have any information about time.",
                    "label": 0
                },
                {
                    "sent": "The second question is did object exist at the time image was captured?",
                    "label": 0
                },
                {
                    "sent": "This is purely dependent on time.",
                    "label": 0
                },
                {
                    "sent": "This is also fairly easy to evaluate.",
                    "label": 0
                },
                {
                    "sent": "The final question we need to answer is, is there any occlusion is object I excluded by some other objects in image J?",
                    "label": 0
                },
                {
                    "sent": "You know that this depends on both X&T depends on the scene structure and the time parameters.",
                    "label": 0
                },
                {
                    "sent": "That's because buildings buildings have uncertain dates of when they exist and those buildings act as the occlusion geometry as well.",
                    "label": 0
                },
                {
                    "sent": "So we don't even know if our occlusion geometry exists at the time the images taken.",
                    "label": 0
                },
                {
                    "sent": "So this is in fact quite a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "I will refer you to the paper for details on how we solve this.",
                    "label": 0
                },
                {
                    "sent": "One of the technical contributions were making is an efficient way of computing these occlusion terms.",
                    "label": 0
                },
                {
                    "sent": "Given that we don't know which objects exist at which time.",
                    "label": 0
                },
                {
                    "sent": "A priority.",
                    "label": 0
                },
                {
                    "sent": "So this is our, this is our probability model for how we evaluate a set of.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parameters so we want to know.",
                    "label": 0
                },
                {
                    "sent": "How to go about maximizing this?",
                    "label": 0
                },
                {
                    "sent": "Finding the optimal temporal parameters.",
                    "label": 0
                },
                {
                    "sent": "So we use is a Markov chain Monte Carlo MCMC sampling approach.",
                    "label": 0
                },
                {
                    "sent": "What that means is that we start with an initial set of temporal parameters based on the image data information that we do have, and we propose to move one of the image dates.",
                    "label": 0
                },
                {
                    "sent": "We then analytically solve for the building date intervals we can maximize.",
                    "label": 0
                },
                {
                    "sent": "We can find the maximum probable building date intervals given any set of image dates, and we evaluate the probability of the temporal parameters in this case.",
                    "label": 0
                },
                {
                    "sent": "And finally we accept or reject that move based on the ratio of probabilities of the two sets of temporal parameters.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Previous ones are new ones that we're proposing.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we move around image dates and we keep track of where our samples are landing and so we actually build up a density on our temporal parameters overtime.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our experiments here, we're drawing 80,000 samples of.",
                    "label": 0
                },
                {
                    "sent": "This takes about 1.3 hours for a case in which we're dealing with 100 images.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our results here.",
                    "label": 0
                },
                {
                    "sent": "I'll start with results on a synthetic scene.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we have seen a synthetic scene of 100 images observing 30 buildings over an 80 year time period.",
                    "label": 0
                },
                {
                    "sent": "And what we do is we set 1/3 of these dates to be known dates.",
                    "label": 0
                },
                {
                    "sent": "130 days to be certain dates which are highly uncertain and 1/3 of the dates on the images to be completely unknown, so.",
                    "label": 0
                },
                {
                    "sent": "When we initialize our model under these conditions, we have an initial error of 19.31 years, and that's because we have completely unknown dates for all these updated images.",
                    "label": 0
                },
                {
                    "sent": "What we do after a full temporal optimization of the MCMC sampling, the result that we get is our root mean square error is reduced to 2.8 seven years.",
                    "label": 0
                },
                {
                    "sent": "So despite the fact that we have unknown dates for 1/3 of the images were able to get an average error of less than three years by incorporating visibility information from those images and combining it with the data information that we do know for the other images in the scene.",
                    "label": 0
                },
                {
                    "sent": "And in the visualization you see on the left, the blue pixels represent the density of MCMC samples, while the red pixels represent the ground truth information that we have for these dates.",
                    "label": 1
                },
                {
                    "sent": "And you'll notice that in the case of undated images, they are extended extended regions of blue which indicate the possible dates for those images.",
                    "label": 0
                },
                {
                    "sent": "We can't do any better than narrowing it down to a region during which the same buildings might have existed.",
                    "label": 0
                },
                {
                    "sent": "So next we look at a.",
                    "label": 0
                },
                {
                    "sent": "The scene for some real.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "So we look at downtown Atlanta, set of data for this case we have 102 images.",
                    "label": 0
                },
                {
                    "sent": "These are real historical images.",
                    "label": 0
                },
                {
                    "sent": "In fact, don't have ground truth for these images.",
                    "label": 0
                },
                {
                    "sent": "This is a real historical problem where we have uncertain dates and some of the images are even undated.",
                    "label": 0
                },
                {
                    "sent": "You'll see at the top of the graph here the undated images, which have no, we have no given data estimates.",
                    "label": 0
                },
                {
                    "sent": "So we can qualitatively evaluate the results on this data set in a few ways.",
                    "label": 0
                },
                {
                    "sent": "First of all week and on the right side here visualize the building date intervals by taking the point cloud and rendering it a different points in time.",
                    "label": 0
                },
                {
                    "sent": "So here we see the point cloud from this perspective, rendered in 1960, nineteen, 65 and 1970s.",
                    "label": 0
                },
                {
                    "sent": "As buildings are constructed, there added to the model.",
                    "label": 0
                },
                {
                    "sent": "And the second week.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Qualitatively evaluate this is by looking at individual images.",
                    "label": 0
                },
                {
                    "sent": "So for example, here we have an undated image in our data set.",
                    "label": 0
                },
                {
                    "sent": "This means a human look at this image and had no idea when it was taken, and so our method is able to assign a date range of about 1956 to 1961.",
                    "label": 0
                },
                {
                    "sent": "You'll notice there's a range of dates over which these MCMC samples exist, which one of the vantage of our system is that we're not just assigning a point date estimate.",
                    "label": 0
                },
                {
                    "sent": "We are able to were able to actually have densities over the entire range of time, and so we're not unduly making bad decisions.",
                    "label": 0
                },
                {
                    "sent": "About time if we if we don't have certain information.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to look at some more quantitative results, we did leave one out image dating experiment on Lower Manhattan data set, in which we do have ground truth.",
                    "label": 0
                },
                {
                    "sent": "And so for example, you see for the image on the right, which is originally dated 1935, we throw out that image data and keep all the other image dates for the data set and we re estimate this image by running our temporal inference method.",
                    "label": 0
                },
                {
                    "sent": "And we get a strongly peaked distribution, which happens to be around 1937.",
                    "label": 0
                },
                {
                    "sent": "So we get an error of only two years, and this is.",
                    "label": 0
                },
                {
                    "sent": "This is a fairly common occurrence over the whole data set.",
                    "label": 0
                },
                {
                    "sent": "We get errors of less than five years for over 48% of our images, so this is promising promising performances task that has been completely impossible before this method.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, we can visualize the building data intervals we have for this point cloud of Manhattan as we scroll through time from 1928 to 2010.",
                    "label": 0
                },
                {
                    "sent": "We can see buildings appearing and we see here the Point Cloud, which is what we have is not just a static point cloud but we have segmented this point cloud into semantically meaningful objects, and for each object we know when it existed.",
                    "label": 0
                },
                {
                    "sent": "When it came into existence and we may have left existence.",
                    "label": 0
                },
                {
                    "sent": "So this is a fairly powerful upgrade to just us.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Static point cloud.",
                    "label": 0
                },
                {
                    "sent": "So finally, some conclusions and future work.",
                    "label": 0
                },
                {
                    "sent": "We presented an automatic probabilistic temporal inference method.",
                    "label": 0
                },
                {
                    "sent": "I've shown you results for synthetic scene and two challenging real world data sets.",
                    "label": 0
                },
                {
                    "sent": "And in future work, one of the most challenging tasks here is actually the feature correspondence problem across time.",
                    "label": 0
                },
                {
                    "sent": "So you see on the bottom here 2 images of lower Manhattan, 1 from 1930 and 1 from 2009, and they're only 19 point correspondences between these two images, despite the fact that the viewing the exact same scene and many of the buildings still exist.",
                    "label": 0
                },
                {
                    "sent": "And this is in fact the best set of correspondences we get for this.",
                    "label": 0
                },
                {
                    "sent": "For this range of time so.",
                    "label": 0
                },
                {
                    "sent": "There are two solutions to overcoming this problem.",
                    "label": 0
                },
                {
                    "sent": "One is to throw more data at the problem and find densely sampled images in space and time, and eventually we'll find enough matches so that we can reconstruct these models and even perform temporal inference in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "And 2nd is an interesting direction we design and find some time invariant features.",
                    "label": 0
                },
                {
                    "sent": "And we don't know what those might be, but it's an interesting direction to going so no one has looked at features that are invariant specifically to time.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that, thank you very much and open questions.",
                    "label": 0
                },
                {
                    "sent": "Your work is very clever.",
                    "label": 0
                },
                {
                    "sent": "Could you clarify the how you deal with the situation?",
                    "label": 0
                },
                {
                    "sent": "We have two buildings that occupy the same space but in different time intervals.",
                    "label": 0
                },
                {
                    "sent": "Yes, so in fact the reason we are so yeah, so the question is, I guess you've spoken with microphone, but if we have two buildings occupying the same space at different times, our method is able to deal with that because our grouping criteria for grouping points into building specifies that to group two points they have to be simultaneously observed in the same image.",
                    "label": 0
                },
                {
                    "sent": "This is our way.",
                    "label": 0
                },
                {
                    "sent": "Of kind of incorporating time into our grouping process without before we explicitly know the times of the images.",
                    "label": 0
                },
                {
                    "sent": "So we have this kind of simelton 80 criteria.",
                    "label": 0
                },
                {
                    "sent": "Two points have to exist at the same time before we group them, and that eliminates those problems of grouping 2 images, despite the fact that it might be overlapping in space.",
                    "label": 0
                },
                {
                    "sent": "Grouping to buildings sorry.",
                    "label": 0
                },
                {
                    "sent": "OK I have a question.",
                    "label": 0
                },
                {
                    "sent": "If you know that certain building is within a decade of equal circuit, so why wouldn't you model it with uniform distribution rather than a Gaussian like uniform for that Dick decade rather than spreading it for longer period of time?",
                    "label": 0
                },
                {
                    "sent": "OK, so you're right.",
                    "label": 0
                },
                {
                    "sent": "So so if we if we know that an image is within a certain decade.",
                    "label": 0
                },
                {
                    "sent": "So if we have a label that says 1950s, that's actually different from something that says circa 1950.",
                    "label": 0
                },
                {
                    "sent": "And there are a variety of labels such as before 1970 after 1945.",
                    "label": 0
                },
                {
                    "sent": "That we we haven't.",
                    "label": 0
                },
                {
                    "sent": "We haven't explicitly knowledge in this talk, but of course, right we can.",
                    "label": 0
                },
                {
                    "sent": "We can make priors that makes sense for those.",
                    "label": 0
                },
                {
                    "sent": "For those date labels.",
                    "label": 0
                },
                {
                    "sent": "So yes, if we had something that explicitly said 1950s, we could have a 1950 to 1960 prior, but we don't necessarily trust human archivists and historians that much.",
                    "label": 0
                },
                {
                    "sent": "So we might want to let them roam outside of those boundaries.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker.",
                    "label": 0
                }
            ]
        }
    }
}