{
    "id": "4wno5kh3ytucwnams5r7heonmjnzvqn4",
    "title": "Planning Ahead: Stream-Driven Linked-Data Access under Update-Budget Constraints",
    "info": {
        "author": [
            "Shen Gao, Department of Informatics, University of Zurich"
        ],
        "published": "Nov. 10, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2016_gao_planning_ahead/",
    "segmentation": [
        [
            "Alright, so thank everyone coming from my talk.",
            "My name is single and then from University of Zurich."
        ],
        [
            "So today I'm going to present the work that has been done together with people from Pretty Tech Milano and the inside centering airline.",
            "The title of my presentation is very long, so planning ahead stream driven link data access and update budget constraints.",
            "Yay."
        ],
        [
            "More understandable sentence is that we started problem of how can we efficiently access sparkle endpoint in RDF stream processing because they already have stream processing.",
            "We already have the problem that we want to enrich the stream.",
            "In order to enrich the stream, we need background knowledge and to access the background knowledge we need to we need to access our remote sparkle endpoint.",
            "How to avoid overloading our remote sparkle endpoint is the problem in this work."
        ],
        [
            "Alright, so let me last week our use case by a real example, so the use case here is to find trendy hashtags in Twitter.",
            "So we define hashtags which find those trendy hashtags to have two criteria.",
            "The first criteria is that the hashtag has been heavily mentioned during the last minutes.",
            "Let's say it has more than 1000 mention in the last minute.",
            "And the second criteria of the hashtag is that this hashtag is mentioned by the important people, important people in terms of it may have more than 1000 followers.",
            "So in this case the stream coming from the Twitter stream, Twitter Stream API and tweets usually includes the user ID and the hashtag that user to it.",
            "As the stream comes in, we in order to fulfill our first criteria.",
            "We already have a window operation and this this window operation cashed data in the last minutes and this window is.",
            "You really are sliding window that forgets to load this data in order to receive the new data.",
            "So as the windows goes on, we can easily find out what which hashtags are mentioned more than 1000 times overtime.",
            "Now the second part here we want to find those important users and in order to find those important users, we want to find the number of followers for certain user in order to get the number of followers we need to query our background data.",
            "That is from Twitter search API which is a different API from the stream API.",
            "The search API here serve as background knowledge data provider that provides us the user profile.",
            "So what we do is that for each user in our window, we generate a query and we send this query to our search API and the search API would give us the user profile as the background knowledge.",
            "We then join the background knowledge together with our data industry and output it as the result.",
            "Note that in each window we need to do this sending queries and then get user profile for each data in our window and we need to do this repeatedly for our user in our window.",
            "So."
        ],
        [
            "From this use case, we observe that first assessing background knowledge is very expensive, is very costly.",
            "Why be cause for our user in our window we need to send query to our background knowledge.",
            "We are sending a lot of query to the background background knowledge provider and also since we have a continuous query the query runs like forever.",
            "Therefore we might send too much too much query to our background knowledge provider.",
            "A straightforward solution would be having a local cache that cash the user profile, but I work the local cache does not solve the problem completely, why?",
            "Because our background knowledge can change overtime, right?",
            "The number of followers may change overtime with the background knowledge change.",
            "We need to update our local cache.",
            "We need to maintain our local cache by accessing our original remote background knowledge.",
            "So in this maintaining process we still need to access a lot of our search API of our remote sparkle endpoint therefore.",
            "Our remote background knowledge provider you really have some kind of constraints on the access.",
            "For example in case of Twitter, Twitter would have kind of rate limit.",
            "That is, we cannot access modern a certain number of the API in a certain time.",
            "Another kind of constraint may come from the query.",
            "That is assuming we need to get our get our get, get the answer of our query in a very short time.",
            "We assume a very short response time.",
            "Therefore we cannot spend too much time assessing our background knowledge.",
            "In this work we generate, we generalize those constraints as a budget, and we define budget as the number of successes per window that can be sent to our remote data provider.",
            "And in this paper we study how to efficiently allocate those budget."
        ],
        [
            "So the problem is how can we allocate budget efficiently?",
            "To answer this question, let's look at formally look.",
            "Let's look formally our query.",
            "We have a select query and it has two clauses.",
            "First it has a window closes the window, classes supplied on some kind of string and this query a certain pattern over the stream.",
            "The result of the window classes will be joined together with the service classes.",
            "The service classes is supplied on the background knowledge and this query a certain kind of pattern.",
            "So.",
            "The way we, the way we allocate budget efficiently, is that first we model our query by a bipartite graph and 2nd we exploit the bipartite graph for solutions.",
            "So let's look at the first step.",
            "How do we model our query as a bipartite graph?"
        ],
        [
            "In this case, in the windows in the Windows side we have the stream and in the stream we have a window operation in the window operation we catch the three data element as well as three for the last minute.",
            "In the service cloud side, we have a local cache that also cashed relevant data to the stream.",
            "Besides the local cache, the service class also taking care of accessing remote background knowledge of updating those data in the local in the local cache.",
            "So there is no money to manage relationship between the data in the stream and the data in the local cache.",
            "Now imagine that the data in the stream here are those hashtags and the data in my local cache are the user profiles.",
            "So each hashtags might be tweet by several users and each user might have several my mentioned several hashtags therefore destroying between the stream data and the local cache data naturally give us a bipartite graph.",
            "Now the question is, given a certain budget, let's say two, we only allowed to access our remote remote API twice, which which two out of the three data in the local cache I choose to send it to remote?",
            "Is there question?",
            "So Please note that.",
            "Currently the data in our in our local cache we know for sure that they are expired data.",
            "We know that they are not valid anymore.",
            "This is be cause early data in the data in the local cache come with a time to life.",
            "Come come with time to lifetime come with the expiration time."
        ],
        [
            "So.",
            "So, given the problem here, we still need to ask ourselves one more.",
            "One more question, what is our optimization goal and optimization goal actually depends in our query depends on what kind of query we have.",
            "Let's look at our query again.",
            "We have the service clouds and the service class can actually come in two kinds of classes.",
            "The first class is is that the first of the service class having a basic graph pattern query and the second class is the service classes on.",
            "Aggregate query, so let's look at these two cases individually."
        ],
        [
            "The first case, Windows Service classes, the BJP pad is a BDP query.",
            "In this case we are interested in each individual pair of the join between stream data and the local cache data.",
            "For this example, we would have 6 results in total as well.",
            "Join with B1 and as to join with B1 and as to join with history etc.",
            "And the goal here is that to maximize the number of edges that can be updated given the two budget given the two budget in our hand, we want to maximize the number of edges that can be updated.",
            "So with such optimization going."
        ],
        [
            "Might you might?",
            "Let's just try some alternatives.",
            "First, we might choose to opt."
        ],
        [
            "B1B2, and in this case we would have total four updated edges and the number of total fresh result would be.",
            "For another alternative we might choose to update."
        ],
        [
            "B1B3, and in this case we would have total 5 results.",
            "Why we have 5 results?",
            "Because B3 is shared between S2 and S3.",
            "Updating Peachtree once we can actually get to refresh 2 fresh results, we can get actually one more result than our previous previous alternative.",
            "So by looking at this by looking at this property graph, we can derive our first solution, that is, selectivity based maintenance for basic graph pattern query.",
            "In this solution, we propose to select data in our local cache based on their degree based on their selectivity.",
            "What we do is that we choose the ones that has the highest degree.",
            "In this case, we first would select B1 to update because it's shared by most of the data in the stream and after we won we will choose B3 to update because it's shared by two of the data in my stream.",
            "So that's so, that's for the.",
            "Basic cross pattern query in the service."
        ],
        [
            "Now the second car, now the second case in the service class, is an aggregate query.",
            "In this case, the problem becomes much trickier, why?",
            "Because in this case we only we would only have 3 results.",
            "Let's take here as an example.",
            "We are interested in as two and the sum of all is joint partner.",
            "We are interested in the sum of B1B3.",
            "This is corresponding to our use case.",
            "Let's imagine as two is a hashtag and we are interested in.",
            "The total number of followers the user that has mentioned these hashtags, so the total number of followers might be on metric for evaluating how trendy #is."
        ],
        [
            "So here the opposite.",
            "The optimization goal is that we would like to maximize the number of stream elements whose join partners are out fresh.",
            "Since because of because only when all the join partners are out fresh, we would have one correct result for our aggregate query."
        ],
        [
            "So with such a optimization goal in mind, let's again try some alternatives.",
            "We still choose to update B1B2, and in this case we would only have 1 correct result.",
            "Why be cause for the case of S2 one of its joint partner B 3 is not updated, it still is still not valid.",
            "Therefore the aggregate result of B1 and B3 might be wrong.",
            "Therefore we cannot count as two as a correct result.",
            "The same also goes for S3."
        ],
        [
            "Now, another alternative, if we choose to update B1B3.",
            "In this case, our joint partner of B2 has been fresh.",
            "Therefore we can count as two as an incorrect result, and in this case we spend our two update budget and get 2 fresh result.",
            "In our paper, we model.",
            "These problems are saying integer programming part and we as an integer programming problem and we actually show that this problem is more complicated than the classic knapsack problem, and it is NP hard.",
            "Therefore, we proposed a greedy heuristic in this case, and the heuristic is that we choose the ones we choose the data first from the stream set we choose the one with the least degree.",
            "We choose the ones with the.",
            "That requires the lowest minimum effort to update."
        ],
        [
            "So a short summary for basic solutions, selectivity based maintenance for different kind of query will propose two different kind of solution.",
            "But keep in mind that the current solution is only for the current window.",
            "And.",
            "Next step, we proposed an improvement on this on this."
        ],
        [
            "Ocean impact based maintenance.",
            "In this impact based maintenance we would have, we would consider not only the data in the current window but also the data.",
            "In the following week."
        ],
        [
            "So, so let's see how we do that.",
            "We are now trying to propose.",
            "We are not trying to predict the future stream, but however, since we have the notion of sliding window, it will give us a partial view of our future.",
            "Therefore, let's say at our current window we already sure that as two and S3 would be my next window and the data of at three would for sure be in being my system for the next 2 window and using such information we can we might actually want to update some other data in our local cache because.",
            "Their effect would must would last longer.",
            "There they would produce more results overtime since our query is reevaluated every window and they might produce results in every window.",
            "So in our paper we we, we derive, we define the number of results in the current and future window's impact, and we give details of our how to derive this impact for both big query and aggregate query."
        ],
        [
            "So the last part of solution is a flexible budget allocation in this in this in this part of solution will not only consider data in the current window and the future window, but we also consider the budget in the in the current and future windows we allow to move budget around between Windows so."
        ],
        [
            "Let's see up to here.",
            "We assume a fixed budget for different windows.",
            "Fixed budget equals 2."
        ],
        [
            "But however, since we know some data would stay in my system longer and we also know that some data would expire in future.",
            "Therefore it might make sense to save our current budget to use it in future, so that in future those data might produce more result."
        ],
        [
            "So one example would be see Roxy one budget from our current budget and use it in my next window.",
            "The next question would be how much budget we should save for the future Windows, and we actually give details in our paper and.",
            "To decide to win and how to decide how much budget we should save."
        ],
        [
            "So a short summary for solution from our use case we define our query and we used bipartite graph 2.",
            "Two model of query and we propose three solution based on each other.",
            "Selectivity based impact based, inflexible budget allocation.",
            "The key point is that we need to spend budget on the ones that has the largest impact or windows."
        ],
        [
            "No experiment, so we implement our algorithm in the state of RTSP engines.",
            "This bar code and is available on GitHub and we test our algorithm with synthetic and real data."
        ],
        [
            "So the first experiment result will show is that we compare the fresh result ratio.",
            "Fresh result ratio means the correct result or the total number of results there should be and we compare several algorithm.",
            "We use random and are you least recently updated as the baseline and we and the selectivity based an maintenance based the algorithm we propose we vary the number of budget and 1st we can observe that SPM and IBM outperform our baselines consistently and also.",
            "IBM favors favors limited budget, so when the budget is small, IBM actually outperform SPM alot."
        ],
        [
            "And the next experiment we show is by varying the graph density.",
            "So the X axis here is the number of edges to a fully connected graph.",
            "That is, we adding the edge to our graph.",
            "So here we still observe that SBM IBM, outperform our two baselines and IBM actually favors the more dense graph."
        ],
        [
            "And the last set of experiment we show is to compare the flexible budget allocation with the ones without flexible budget allocation."
        ],
        [
            "We increased the number of budget and we compared the accumulated outdated result that is the data we didn't go to update and we."
        ],
        [
            "Imperative we show this accumulated outdated results over the course of experiment or cause of iteration and win.",
            "The gap is larger.",
            "We can see that FBA perform better than IBM.",
            "This is because when the budget is large we have more gap too.",
            "We have more flexibility to move.",
            "Budget around."
        ],
        [
            "As a summary from our use case, we derive we formally defined our query and from our query we define we model query by bipartite graph and based on bipartite graph we propose our solution so."
        ],
        [
            "That's off my presentation.",
            "Thanks.",
            "So if there's any question.",
            "Yes, or just one question.",
            "So one of the approaches that you have shown it takes into account though the window and the fact that you have some items that you can take advantage of in the future.",
            "So have you played in your evaluation about with window sizes and slides?",
            "Because I think this will, I mean, depending on the window size is on the slide you can have different results I guess yes.",
            "So we actually have.",
            "We actually had a few more experiments about varying the window size about.",
            "Varying the stream rate in our paper, and so I guess some time is running out, so we will have there would be more details in our paper for the experiment.",
            "Other questions.",
            "So you mentioned that you consider also the future window.",
            "But how do we have access to the future window?",
            "If so, actually don't access the future window since our window is sliding, so I know that some data will still stay in my next window.",
            "For example, my data just arrived in my window OK. OK, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so thank everyone coming from my talk.",
                    "label": 0
                },
                {
                    "sent": "My name is single and then from University of Zurich.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So today I'm going to present the work that has been done together with people from Pretty Tech Milano and the inside centering airline.",
                    "label": 0
                },
                {
                    "sent": "The title of my presentation is very long, so planning ahead stream driven link data access and update budget constraints.",
                    "label": 1
                },
                {
                    "sent": "Yay.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More understandable sentence is that we started problem of how can we efficiently access sparkle endpoint in RDF stream processing because they already have stream processing.",
                    "label": 1
                },
                {
                    "sent": "We already have the problem that we want to enrich the stream.",
                    "label": 0
                },
                {
                    "sent": "In order to enrich the stream, we need background knowledge and to access the background knowledge we need to we need to access our remote sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "How to avoid overloading our remote sparkle endpoint is the problem in this work.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so let me last week our use case by a real example, so the use case here is to find trendy hashtags in Twitter.",
                    "label": 0
                },
                {
                    "sent": "So we define hashtags which find those trendy hashtags to have two criteria.",
                    "label": 0
                },
                {
                    "sent": "The first criteria is that the hashtag has been heavily mentioned during the last minutes.",
                    "label": 0
                },
                {
                    "sent": "Let's say it has more than 1000 mention in the last minute.",
                    "label": 0
                },
                {
                    "sent": "And the second criteria of the hashtag is that this hashtag is mentioned by the important people, important people in terms of it may have more than 1000 followers.",
                    "label": 0
                },
                {
                    "sent": "So in this case the stream coming from the Twitter stream, Twitter Stream API and tweets usually includes the user ID and the hashtag that user to it.",
                    "label": 0
                },
                {
                    "sent": "As the stream comes in, we in order to fulfill our first criteria.",
                    "label": 0
                },
                {
                    "sent": "We already have a window operation and this this window operation cashed data in the last minutes and this window is.",
                    "label": 0
                },
                {
                    "sent": "You really are sliding window that forgets to load this data in order to receive the new data.",
                    "label": 0
                },
                {
                    "sent": "So as the windows goes on, we can easily find out what which hashtags are mentioned more than 1000 times overtime.",
                    "label": 0
                },
                {
                    "sent": "Now the second part here we want to find those important users and in order to find those important users, we want to find the number of followers for certain user in order to get the number of followers we need to query our background data.",
                    "label": 0
                },
                {
                    "sent": "That is from Twitter search API which is a different API from the stream API.",
                    "label": 1
                },
                {
                    "sent": "The search API here serve as background knowledge data provider that provides us the user profile.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that for each user in our window, we generate a query and we send this query to our search API and the search API would give us the user profile as the background knowledge.",
                    "label": 0
                },
                {
                    "sent": "We then join the background knowledge together with our data industry and output it as the result.",
                    "label": 0
                },
                {
                    "sent": "Note that in each window we need to do this sending queries and then get user profile for each data in our window and we need to do this repeatedly for our user in our window.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From this use case, we observe that first assessing background knowledge is very expensive, is very costly.",
                    "label": 1
                },
                {
                    "sent": "Why be cause for our user in our window we need to send query to our background knowledge.",
                    "label": 0
                },
                {
                    "sent": "We are sending a lot of query to the background background knowledge provider and also since we have a continuous query the query runs like forever.",
                    "label": 0
                },
                {
                    "sent": "Therefore we might send too much too much query to our background knowledge provider.",
                    "label": 0
                },
                {
                    "sent": "A straightforward solution would be having a local cache that cash the user profile, but I work the local cache does not solve the problem completely, why?",
                    "label": 0
                },
                {
                    "sent": "Because our background knowledge can change overtime, right?",
                    "label": 0
                },
                {
                    "sent": "The number of followers may change overtime with the background knowledge change.",
                    "label": 0
                },
                {
                    "sent": "We need to update our local cache.",
                    "label": 0
                },
                {
                    "sent": "We need to maintain our local cache by accessing our original remote background knowledge.",
                    "label": 1
                },
                {
                    "sent": "So in this maintaining process we still need to access a lot of our search API of our remote sparkle endpoint therefore.",
                    "label": 0
                },
                {
                    "sent": "Our remote background knowledge provider you really have some kind of constraints on the access.",
                    "label": 0
                },
                {
                    "sent": "For example in case of Twitter, Twitter would have kind of rate limit.",
                    "label": 0
                },
                {
                    "sent": "That is, we cannot access modern a certain number of the API in a certain time.",
                    "label": 0
                },
                {
                    "sent": "Another kind of constraint may come from the query.",
                    "label": 0
                },
                {
                    "sent": "That is assuming we need to get our get our get, get the answer of our query in a very short time.",
                    "label": 0
                },
                {
                    "sent": "We assume a very short response time.",
                    "label": 0
                },
                {
                    "sent": "Therefore we cannot spend too much time assessing our background knowledge.",
                    "label": 0
                },
                {
                    "sent": "In this work we generate, we generalize those constraints as a budget, and we define budget as the number of successes per window that can be sent to our remote data provider.",
                    "label": 0
                },
                {
                    "sent": "And in this paper we study how to efficiently allocate those budget.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the problem is how can we allocate budget efficiently?",
                    "label": 1
                },
                {
                    "sent": "To answer this question, let's look at formally look.",
                    "label": 0
                },
                {
                    "sent": "Let's look formally our query.",
                    "label": 0
                },
                {
                    "sent": "We have a select query and it has two clauses.",
                    "label": 0
                },
                {
                    "sent": "First it has a window closes the window, classes supplied on some kind of string and this query a certain pattern over the stream.",
                    "label": 0
                },
                {
                    "sent": "The result of the window classes will be joined together with the service classes.",
                    "label": 0
                },
                {
                    "sent": "The service classes is supplied on the background knowledge and this query a certain kind of pattern.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The way we, the way we allocate budget efficiently, is that first we model our query by a bipartite graph and 2nd we exploit the bipartite graph for solutions.",
                    "label": 1
                },
                {
                    "sent": "So let's look at the first step.",
                    "label": 0
                },
                {
                    "sent": "How do we model our query as a bipartite graph?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, in the windows in the Windows side we have the stream and in the stream we have a window operation in the window operation we catch the three data element as well as three for the last minute.",
                    "label": 0
                },
                {
                    "sent": "In the service cloud side, we have a local cache that also cashed relevant data to the stream.",
                    "label": 1
                },
                {
                    "sent": "Besides the local cache, the service class also taking care of accessing remote background knowledge of updating those data in the local in the local cache.",
                    "label": 0
                },
                {
                    "sent": "So there is no money to manage relationship between the data in the stream and the data in the local cache.",
                    "label": 0
                },
                {
                    "sent": "Now imagine that the data in the stream here are those hashtags and the data in my local cache are the user profiles.",
                    "label": 0
                },
                {
                    "sent": "So each hashtags might be tweet by several users and each user might have several my mentioned several hashtags therefore destroying between the stream data and the local cache data naturally give us a bipartite graph.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, given a certain budget, let's say two, we only allowed to access our remote remote API twice, which which two out of the three data in the local cache I choose to send it to remote?",
                    "label": 0
                },
                {
                    "sent": "Is there question?",
                    "label": 0
                },
                {
                    "sent": "So Please note that.",
                    "label": 0
                },
                {
                    "sent": "Currently the data in our in our local cache we know for sure that they are expired data.",
                    "label": 0
                },
                {
                    "sent": "We know that they are not valid anymore.",
                    "label": 0
                },
                {
                    "sent": "This is be cause early data in the data in the local cache come with a time to life.",
                    "label": 0
                },
                {
                    "sent": "Come come with time to lifetime come with the expiration time.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So, given the problem here, we still need to ask ourselves one more.",
                    "label": 0
                },
                {
                    "sent": "One more question, what is our optimization goal and optimization goal actually depends in our query depends on what kind of query we have.",
                    "label": 0
                },
                {
                    "sent": "Let's look at our query again.",
                    "label": 0
                },
                {
                    "sent": "We have the service clouds and the service class can actually come in two kinds of classes.",
                    "label": 0
                },
                {
                    "sent": "The first class is is that the first of the service class having a basic graph pattern query and the second class is the service classes on.",
                    "label": 1
                },
                {
                    "sent": "Aggregate query, so let's look at these two cases individually.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first case, Windows Service classes, the BJP pad is a BDP query.",
                    "label": 0
                },
                {
                    "sent": "In this case we are interested in each individual pair of the join between stream data and the local cache data.",
                    "label": 0
                },
                {
                    "sent": "For this example, we would have 6 results in total as well.",
                    "label": 0
                },
                {
                    "sent": "Join with B1 and as to join with B1 and as to join with history etc.",
                    "label": 0
                },
                {
                    "sent": "And the goal here is that to maximize the number of edges that can be updated given the two budget given the two budget in our hand, we want to maximize the number of edges that can be updated.",
                    "label": 0
                },
                {
                    "sent": "So with such optimization going.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might you might?",
                    "label": 0
                },
                {
                    "sent": "Let's just try some alternatives.",
                    "label": 0
                },
                {
                    "sent": "First, we might choose to opt.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "B1B2, and in this case we would have total four updated edges and the number of total fresh result would be.",
                    "label": 0
                },
                {
                    "sent": "For another alternative we might choose to update.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "B1B3, and in this case we would have total 5 results.",
                    "label": 0
                },
                {
                    "sent": "Why we have 5 results?",
                    "label": 0
                },
                {
                    "sent": "Because B3 is shared between S2 and S3.",
                    "label": 0
                },
                {
                    "sent": "Updating Peachtree once we can actually get to refresh 2 fresh results, we can get actually one more result than our previous previous alternative.",
                    "label": 1
                },
                {
                    "sent": "So by looking at this by looking at this property graph, we can derive our first solution, that is, selectivity based maintenance for basic graph pattern query.",
                    "label": 0
                },
                {
                    "sent": "In this solution, we propose to select data in our local cache based on their degree based on their selectivity.",
                    "label": 1
                },
                {
                    "sent": "What we do is that we choose the ones that has the highest degree.",
                    "label": 0
                },
                {
                    "sent": "In this case, we first would select B1 to update because it's shared by most of the data in the stream and after we won we will choose B3 to update because it's shared by two of the data in my stream.",
                    "label": 0
                },
                {
                    "sent": "So that's so, that's for the.",
                    "label": 0
                },
                {
                    "sent": "Basic cross pattern query in the service.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the second car, now the second case in the service class, is an aggregate query.",
                    "label": 0
                },
                {
                    "sent": "In this case, the problem becomes much trickier, why?",
                    "label": 0
                },
                {
                    "sent": "Because in this case we only we would only have 3 results.",
                    "label": 0
                },
                {
                    "sent": "Let's take here as an example.",
                    "label": 0
                },
                {
                    "sent": "We are interested in as two and the sum of all is joint partner.",
                    "label": 0
                },
                {
                    "sent": "We are interested in the sum of B1B3.",
                    "label": 0
                },
                {
                    "sent": "This is corresponding to our use case.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine as two is a hashtag and we are interested in.",
                    "label": 0
                },
                {
                    "sent": "The total number of followers the user that has mentioned these hashtags, so the total number of followers might be on metric for evaluating how trendy #is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here the opposite.",
                    "label": 0
                },
                {
                    "sent": "The optimization goal is that we would like to maximize the number of stream elements whose join partners are out fresh.",
                    "label": 0
                },
                {
                    "sent": "Since because of because only when all the join partners are out fresh, we would have one correct result for our aggregate query.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with such a optimization goal in mind, let's again try some alternatives.",
                    "label": 0
                },
                {
                    "sent": "We still choose to update B1B2, and in this case we would only have 1 correct result.",
                    "label": 0
                },
                {
                    "sent": "Why be cause for the case of S2 one of its joint partner B 3 is not updated, it still is still not valid.",
                    "label": 0
                },
                {
                    "sent": "Therefore the aggregate result of B1 and B3 might be wrong.",
                    "label": 0
                },
                {
                    "sent": "Therefore we cannot count as two as a correct result.",
                    "label": 0
                },
                {
                    "sent": "The same also goes for S3.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, another alternative, if we choose to update B1B3.",
                    "label": 0
                },
                {
                    "sent": "In this case, our joint partner of B2 has been fresh.",
                    "label": 0
                },
                {
                    "sent": "Therefore we can count as two as an incorrect result, and in this case we spend our two update budget and get 2 fresh result.",
                    "label": 0
                },
                {
                    "sent": "In our paper, we model.",
                    "label": 0
                },
                {
                    "sent": "These problems are saying integer programming part and we as an integer programming problem and we actually show that this problem is more complicated than the classic knapsack problem, and it is NP hard.",
                    "label": 0
                },
                {
                    "sent": "Therefore, we proposed a greedy heuristic in this case, and the heuristic is that we choose the ones we choose the data first from the stream set we choose the one with the least degree.",
                    "label": 0
                },
                {
                    "sent": "We choose the ones with the.",
                    "label": 0
                },
                {
                    "sent": "That requires the lowest minimum effort to update.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a short summary for basic solutions, selectivity based maintenance for different kind of query will propose two different kind of solution.",
                    "label": 1
                },
                {
                    "sent": "But keep in mind that the current solution is only for the current window.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Next step, we proposed an improvement on this on this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ocean impact based maintenance.",
                    "label": 0
                },
                {
                    "sent": "In this impact based maintenance we would have, we would consider not only the data in the current window but also the data.",
                    "label": 1
                },
                {
                    "sent": "In the following week.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so let's see how we do that.",
                    "label": 0
                },
                {
                    "sent": "We are now trying to propose.",
                    "label": 0
                },
                {
                    "sent": "We are not trying to predict the future stream, but however, since we have the notion of sliding window, it will give us a partial view of our future.",
                    "label": 0
                },
                {
                    "sent": "Therefore, let's say at our current window we already sure that as two and S3 would be my next window and the data of at three would for sure be in being my system for the next 2 window and using such information we can we might actually want to update some other data in our local cache because.",
                    "label": 0
                },
                {
                    "sent": "Their effect would must would last longer.",
                    "label": 0
                },
                {
                    "sent": "There they would produce more results overtime since our query is reevaluated every window and they might produce results in every window.",
                    "label": 0
                },
                {
                    "sent": "So in our paper we we, we derive, we define the number of results in the current and future window's impact, and we give details of our how to derive this impact for both big query and aggregate query.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the last part of solution is a flexible budget allocation in this in this in this part of solution will not only consider data in the current window and the future window, but we also consider the budget in the in the current and future windows we allow to move budget around between Windows so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see up to here.",
                    "label": 0
                },
                {
                    "sent": "We assume a fixed budget for different windows.",
                    "label": 1
                },
                {
                    "sent": "Fixed budget equals 2.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But however, since we know some data would stay in my system longer and we also know that some data would expire in future.",
                    "label": 0
                },
                {
                    "sent": "Therefore it might make sense to save our current budget to use it in future, so that in future those data might produce more result.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one example would be see Roxy one budget from our current budget and use it in my next window.",
                    "label": 0
                },
                {
                    "sent": "The next question would be how much budget we should save for the future Windows, and we actually give details in our paper and.",
                    "label": 1
                },
                {
                    "sent": "To decide to win and how to decide how much budget we should save.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a short summary for solution from our use case we define our query and we used bipartite graph 2.",
                    "label": 0
                },
                {
                    "sent": "Two model of query and we propose three solution based on each other.",
                    "label": 0
                },
                {
                    "sent": "Selectivity based impact based, inflexible budget allocation.",
                    "label": 0
                },
                {
                    "sent": "The key point is that we need to spend budget on the ones that has the largest impact or windows.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No experiment, so we implement our algorithm in the state of RTSP engines.",
                    "label": 0
                },
                {
                    "sent": "This bar code and is available on GitHub and we test our algorithm with synthetic and real data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first experiment result will show is that we compare the fresh result ratio.",
                    "label": 0
                },
                {
                    "sent": "Fresh result ratio means the correct result or the total number of results there should be and we compare several algorithm.",
                    "label": 0
                },
                {
                    "sent": "We use random and are you least recently updated as the baseline and we and the selectivity based an maintenance based the algorithm we propose we vary the number of budget and 1st we can observe that SPM and IBM outperform our baselines consistently and also.",
                    "label": 0
                },
                {
                    "sent": "IBM favors favors limited budget, so when the budget is small, IBM actually outperform SPM alot.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the next experiment we show is by varying the graph density.",
                    "label": 0
                },
                {
                    "sent": "So the X axis here is the number of edges to a fully connected graph.",
                    "label": 1
                },
                {
                    "sent": "That is, we adding the edge to our graph.",
                    "label": 0
                },
                {
                    "sent": "So here we still observe that SBM IBM, outperform our two baselines and IBM actually favors the more dense graph.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the last set of experiment we show is to compare the flexible budget allocation with the ones without flexible budget allocation.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We increased the number of budget and we compared the accumulated outdated result that is the data we didn't go to update and we.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Imperative we show this accumulated outdated results over the course of experiment or cause of iteration and win.",
                    "label": 1
                },
                {
                    "sent": "The gap is larger.",
                    "label": 0
                },
                {
                    "sent": "We can see that FBA perform better than IBM.",
                    "label": 0
                },
                {
                    "sent": "This is because when the budget is large we have more gap too.",
                    "label": 0
                },
                {
                    "sent": "We have more flexibility to move.",
                    "label": 0
                },
                {
                    "sent": "Budget around.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a summary from our use case, we derive we formally defined our query and from our query we define we model query by bipartite graph and based on bipartite graph we propose our solution so.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's off my presentation.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "So if there's any question.",
                    "label": 0
                },
                {
                    "sent": "Yes, or just one question.",
                    "label": 0
                },
                {
                    "sent": "So one of the approaches that you have shown it takes into account though the window and the fact that you have some items that you can take advantage of in the future.",
                    "label": 0
                },
                {
                    "sent": "So have you played in your evaluation about with window sizes and slides?",
                    "label": 0
                },
                {
                    "sent": "Because I think this will, I mean, depending on the window size is on the slide you can have different results I guess yes.",
                    "label": 0
                },
                {
                    "sent": "So we actually have.",
                    "label": 0
                },
                {
                    "sent": "We actually had a few more experiments about varying the window size about.",
                    "label": 0
                },
                {
                    "sent": "Varying the stream rate in our paper, and so I guess some time is running out, so we will have there would be more details in our paper for the experiment.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "So you mentioned that you consider also the future window.",
                    "label": 0
                },
                {
                    "sent": "But how do we have access to the future window?",
                    "label": 0
                },
                {
                    "sent": "If so, actually don't access the future window since our window is sliding, so I know that some data will still stay in my next window.",
                    "label": 0
                },
                {
                    "sent": "For example, my data just arrived in my window OK. OK, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}