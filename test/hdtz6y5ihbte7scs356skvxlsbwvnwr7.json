{
    "id": "hdtz6y5ihbte7scs356skvxlsbwvnwr7",
    "title": "MultiBoost",
    "info": {
        "author": [
            "Bal\u00e1zs K\u00e9gl, Laboratoire de l Acc\u00e9l\u00e9rateur Lin\u00e9aire, University of Paris-Sud 11"
        ],
        "published": "July 20, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Software"
        ]
    },
    "url": "http://videolectures.net/icml2010_kegl_mubu/",
    "segmentation": [
        [
            "So my name is Blash Kegler, and my coauthors are normal casagranda who was a master student in Montreal.",
            "He started the project, but he's not on the project anymore.",
            "He works for last FM and the Robert who is a postdoc with me in Paris and he is the main developer at this point.",
            "So."
        ],
        [
            "Before I give some highlights of the software, I felt I had to give a position slide because we got this one from one of the reviewers.",
            "We got this sentence.",
            "I don't blame him because this is pretty much the reputation of other boost.",
            "That is a very simple algorithm.",
            "There is no.",
            "Thanks to implement it or you implement it for yourself now.",
            "Yes, so it is simple if you talk about binary boosted decision stumps.",
            "But I would still argue that an average biologist or chemist will not sit down and implement it.",
            "So for him, if it's not implemented, if you go to SVM because he can just download the software and use it.",
            "The other remark is that.",
            "Adaboost can do much more than binary adder.",
            "Boost binary classification.",
            "It can do cost sensitive multiclass and multilabel.",
            "Classification and if you go beyond decisions, times even the implementation of the base learning can be pretty cheeky.",
            "And if you go to Vecna and look at the multiclass Adaboost that's implemented in vodka, it's very, very suboptimal and it gives a quite bad reputation to other boost in my opinion."
        ],
        [
            "So just to flash you, this is a base learner.",
            "For nominal features you can say it's simple.",
            "Well, it's not quadratic programming, but there are some tricks.",
            "And the point here is that these chicks are never have never been published, so you have to discover them yourself if you."
        ],
        [
            "Implement it so.",
            "So what is cost sensitive multilabel multiclass classification where you have an input vector?",
            "The entries can be the real valued or nominal.",
            "You have a label vector over the label space.",
            "So each element can be binary plus or minus 1 + 4 means the observation belongs to the class minus one means it does not belong to the quest.",
            "So usually multi plus one over the labels are plus one.",
            "Others are minus one, but in multi label setup you can have several positive labels for the same example and wait it means.",
            "That you can define an initial.",
            "I call it initial weight because this is the same weight as using boosting, so the initial vector is comes from the user.",
            "It's a positive vector over the labels for each example, and what it expresses it how.",
            "Well, you want the classifier.",
            "Pointing to one of the classes or against one of the negative classes.",
            "So in classical multiclass this is set uniformly over the data points and among the classes you would set it would put half of the weight on the positive label and you would share the rest of the weight among the negative labels.",
            "But this is just one set up.",
            "If you have some prior knowledge about the cost, you can put it in.",
            "He"
        ],
        [
            "So once it's set up so the last slide comes from the users that this is what other boosts is doing.",
            "It learns a vector valued classification discriminant function and the cost it tries to minimizes this Hamming loss, so it's happy if the sign of the output element of the function agrees with the label which was in the label vector, and the higher the way, the more happy it is.",
            "So this is what other boost."
        ],
        [
            "Each learns to some of the.",
            "Features of our implementation.",
            "We have two strong learners.",
            "The important one is other boost damage, but we also implemented the shop here and Bradley's feature boost for comparison.",
            "And here are weak learners.",
            "So we have decision stumps for real valued features.",
            "For nominal features, we have selectors that are the usual weak learners use.",
            "Then we have this subset indicator over whose pseudocode I flashed on the second slide.",
            "For image input, we have Viola Jones heart filters.",
            "So these are the basic weak learners and then we have two kind of matter, weak learners.",
            "The decision trees which are visual.",
            "And this is a product which we introduced last year, I CMO.",
            "And then perhaps the most important point from an advanced user is that it's pretty easy to add new weak learners without touching the main boosting engine.",
            "So it's very modular."
        ],
        [
            "And some other technical features.",
            "We have this new version of accelerated training called Bandit boosting that we presented in the main conference.",
            "The code is in C++, it's multiplatform, so it compiles the Mac, Linux and Windows.",
            "The training and test data are in our format, so you can use your your vector files except for that we are supporting sparse Dayton label matrix.",
            "So we had to add some syntax to the original our format.",
            "The classifiers are saving XML we can read from the code, but you can also read it and you can also.",
            "Process this file with another software if you want.",
            "And in each iteration we now output certain statistics like training tester or another statistic that you want in a tab separated data file and to."
        ],
        [
            "Wish these are some highlights.",
            "Of some benchmark datasets and some.",
            "Classification challenges this was the latest one we just presented in the learning to Rank Challenge in another workshop.",
            "So this is thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my name is Blash Kegler, and my coauthors are normal casagranda who was a master student in Montreal.",
                    "label": 0
                },
                {
                    "sent": "He started the project, but he's not on the project anymore.",
                    "label": 0
                },
                {
                    "sent": "He works for last FM and the Robert who is a postdoc with me in Paris and he is the main developer at this point.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before I give some highlights of the software, I felt I had to give a position slide because we got this one from one of the reviewers.",
                    "label": 0
                },
                {
                    "sent": "We got this sentence.",
                    "label": 0
                },
                {
                    "sent": "I don't blame him because this is pretty much the reputation of other boost.",
                    "label": 0
                },
                {
                    "sent": "That is a very simple algorithm.",
                    "label": 1
                },
                {
                    "sent": "There is no.",
                    "label": 1
                },
                {
                    "sent": "Thanks to implement it or you implement it for yourself now.",
                    "label": 0
                },
                {
                    "sent": "Yes, so it is simple if you talk about binary boosted decision stumps.",
                    "label": 1
                },
                {
                    "sent": "But I would still argue that an average biologist or chemist will not sit down and implement it.",
                    "label": 1
                },
                {
                    "sent": "So for him, if it's not implemented, if you go to SVM because he can just download the software and use it.",
                    "label": 0
                },
                {
                    "sent": "The other remark is that.",
                    "label": 0
                },
                {
                    "sent": "Adaboost can do much more than binary adder.",
                    "label": 1
                },
                {
                    "sent": "Boost binary classification.",
                    "label": 0
                },
                {
                    "sent": "It can do cost sensitive multiclass and multilabel.",
                    "label": 0
                },
                {
                    "sent": "Classification and if you go beyond decisions, times even the implementation of the base learning can be pretty cheeky.",
                    "label": 0
                },
                {
                    "sent": "And if you go to Vecna and look at the multiclass Adaboost that's implemented in vodka, it's very, very suboptimal and it gives a quite bad reputation to other boost in my opinion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to flash you, this is a base learner.",
                    "label": 0
                },
                {
                    "sent": "For nominal features you can say it's simple.",
                    "label": 0
                },
                {
                    "sent": "Well, it's not quadratic programming, but there are some tricks.",
                    "label": 0
                },
                {
                    "sent": "And the point here is that these chicks are never have never been published, so you have to discover them yourself if you.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Implement it so.",
                    "label": 0
                },
                {
                    "sent": "So what is cost sensitive multilabel multiclass classification where you have an input vector?",
                    "label": 1
                },
                {
                    "sent": "The entries can be the real valued or nominal.",
                    "label": 0
                },
                {
                    "sent": "You have a label vector over the label space.",
                    "label": 0
                },
                {
                    "sent": "So each element can be binary plus or minus 1 + 4 means the observation belongs to the class minus one means it does not belong to the quest.",
                    "label": 0
                },
                {
                    "sent": "So usually multi plus one over the labels are plus one.",
                    "label": 0
                },
                {
                    "sent": "Others are minus one, but in multi label setup you can have several positive labels for the same example and wait it means.",
                    "label": 0
                },
                {
                    "sent": "That you can define an initial.",
                    "label": 1
                },
                {
                    "sent": "I call it initial weight because this is the same weight as using boosting, so the initial vector is comes from the user.",
                    "label": 0
                },
                {
                    "sent": "It's a positive vector over the labels for each example, and what it expresses it how.",
                    "label": 0
                },
                {
                    "sent": "Well, you want the classifier.",
                    "label": 0
                },
                {
                    "sent": "Pointing to one of the classes or against one of the negative classes.",
                    "label": 0
                },
                {
                    "sent": "So in classical multiclass this is set uniformly over the data points and among the classes you would set it would put half of the weight on the positive label and you would share the rest of the weight among the negative labels.",
                    "label": 0
                },
                {
                    "sent": "But this is just one set up.",
                    "label": 0
                },
                {
                    "sent": "If you have some prior knowledge about the cost, you can put it in.",
                    "label": 0
                },
                {
                    "sent": "He",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So once it's set up so the last slide comes from the users that this is what other boosts is doing.",
                    "label": 0
                },
                {
                    "sent": "It learns a vector valued classification discriminant function and the cost it tries to minimizes this Hamming loss, so it's happy if the sign of the output element of the function agrees with the label which was in the label vector, and the higher the way, the more happy it is.",
                    "label": 1
                },
                {
                    "sent": "So this is what other boost.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each learns to some of the.",
                    "label": 0
                },
                {
                    "sent": "Features of our implementation.",
                    "label": 0
                },
                {
                    "sent": "We have two strong learners.",
                    "label": 0
                },
                {
                    "sent": "The important one is other boost damage, but we also implemented the shop here and Bradley's feature boost for comparison.",
                    "label": 0
                },
                {
                    "sent": "And here are weak learners.",
                    "label": 0
                },
                {
                    "sent": "So we have decision stumps for real valued features.",
                    "label": 0
                },
                {
                    "sent": "For nominal features, we have selectors that are the usual weak learners use.",
                    "label": 1
                },
                {
                    "sent": "Then we have this subset indicator over whose pseudocode I flashed on the second slide.",
                    "label": 0
                },
                {
                    "sent": "For image input, we have Viola Jones heart filters.",
                    "label": 1
                },
                {
                    "sent": "So these are the basic weak learners and then we have two kind of matter, weak learners.",
                    "label": 0
                },
                {
                    "sent": "The decision trees which are visual.",
                    "label": 0
                },
                {
                    "sent": "And this is a product which we introduced last year, I CMO.",
                    "label": 0
                },
                {
                    "sent": "And then perhaps the most important point from an advanced user is that it's pretty easy to add new weak learners without touching the main boosting engine.",
                    "label": 1
                },
                {
                    "sent": "So it's very modular.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And some other technical features.",
                    "label": 0
                },
                {
                    "sent": "We have this new version of accelerated training called Bandit boosting that we presented in the main conference.",
                    "label": 0
                },
                {
                    "sent": "The code is in C++, it's multiplatform, so it compiles the Mac, Linux and Windows.",
                    "label": 0
                },
                {
                    "sent": "The training and test data are in our format, so you can use your your vector files except for that we are supporting sparse Dayton label matrix.",
                    "label": 1
                },
                {
                    "sent": "So we had to add some syntax to the original our format.",
                    "label": 1
                },
                {
                    "sent": "The classifiers are saving XML we can read from the code, but you can also read it and you can also.",
                    "label": 0
                },
                {
                    "sent": "Process this file with another software if you want.",
                    "label": 0
                },
                {
                    "sent": "And in each iteration we now output certain statistics like training tester or another statistic that you want in a tab separated data file and to.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wish these are some highlights.",
                    "label": 0
                },
                {
                    "sent": "Of some benchmark datasets and some.",
                    "label": 0
                },
                {
                    "sent": "Classification challenges this was the latest one we just presented in the learning to Rank Challenge in another workshop.",
                    "label": 1
                },
                {
                    "sent": "So this is thank you.",
                    "label": 0
                }
            ]
        }
    }
}