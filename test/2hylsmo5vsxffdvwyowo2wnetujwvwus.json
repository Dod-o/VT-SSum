{
    "id": "2hylsmo5vsxffdvwyowo2wnetujwvwus",
    "title": "Learning Representations for Automatic Colorization",
    "info": {
        "author": [
            "Gustav Larsson, Department of Computer Science, University of Chicago"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_larsson_automatic_colorization/",
    "segmentation": [
        [
            "OK, so this is work from TTI, Chicago together with Michael Moran, Greg Schechner, Ovich.",
            "OK, so let's try to define."
        ],
        [
            "In what colorization is so?",
            "Let's set up the task."
        ],
        [
            "If you open up this image in Photoshop, there's a button that says."
        ],
        [
            "Saturate and if you click it, it will sort of drain all the color from your image and you get a grayscale image.",
            "Now one definition of polarization could be the inverse."
        ],
        [
            "Function of this.",
            "So now we open up a grayscale image we hit."
        ],
        [
            "One that says colorized and we get back the original, the original meaning whatever we had that we desaturated.",
            "But this is an Impala."
        ],
        [
            "Simple problem and we might not have an original that was desaturated.",
            "It could be an original grayscale image.",
            "So."
        ],
        [
            "We could propose another definition that says, well, it's just.",
            "It just needs to be an inverse that is false."
        ],
        [
            "Foreign pleasing to human observer, so there's sort of some wiggle room in how we could interpret that.",
            "So."
        ],
        [
            "We're going to keep we're going to use both of these definitions.",
            "The first one we're going to use for training and quantitative evaluation, and the second one we're just going to keep in mind for qualitative evaluation."
        ],
        [
            "So before we go into automatic colorization, I thought we would try and Emanuel colorization first, so I opened up this image in Photoshop.",
            "I had never seen the color version of it.",
            "And so before I can start picking a color and putting it down, I have to."
        ],
        [
            "I see things like grass I identify."
        ],
        [
            "Things like trees and I."
        ],
        [
            "Know that the scene is a landscape scene, so I'm using all."
        ],
        [
            "These low level to high level cues to build the confidence to say this region should be green.",
            "OK so I continue and I."
        ],
        [
            "The Sky Blue Anne for the mountains."
        ],
        [
            "I sort of panicked and said, well, maybe they're Brown.",
            "OK, so this is clearly not Eva."
        ],
        [
            "Very high quality colorization and I'm not just trying to lower the bar here.",
            "I just wanted to see what I could do in as little time as possible and this was sort of my 15 second budget."
        ],
        [
            "Spending a little bit more time on it, I got this in three minutes, so that's still 3 minutes and it did require some Photoshop in some sort of artistic touches.",
            "So the prospects of being able to do this fully automatically with an algorithm in 100."
        ],
        [
            "SEC has clear economic wins."
        ],
        [
            "So the motivation of this work is primarily to colorize old black and white photographs and films, but there's a second motivate."
        ],
        [
            "Asian, which is we think this is a good proxy for visual understanding because you have to understand what's in the image to colorize it correctly and I'll come back to that at the at the end.",
            "So."
        ],
        [
            "Dramatic colorization, or colorization, has been a research field for about 15 years.",
            "Most previous methods have involved some level of user inputs, such as scribbles or selecting a reference image.",
            "The the more recent."
        ],
        [
            "The automatic prediction based models we saw first time last year two papers that I CV and then."
        ],
        [
            "This year we've seen one at SIGGRAPH and then yes."
        ],
        [
            "Today you saw one a great talk from UC Berkeley presented by Richard Young and then our work now, so how?"
        ],
        [
            "We're going to make this model well.",
            "It's going to be a convolutional neural network, and some of the design principles will be so."
        ],
        [
            "So we need semantic knowledge.",
            "If you see a grayscale image of a banana, you need to identify it as a banana and know that bananas are usually yellow, so we're going to start by leveraging an image."
        ],
        [
            "Task based classifier so it's been trained for classification and it has all these representations."
        ],
        [
            "Secondly, we want to be able to use both low level and high level cues just like I did in my manual colorization, so we're going to use a hyper."
        ],
        [
            "Call marketecture, that essentially concatenates all the layer for one spatial location.",
            "What this what this does?",
            "Is it sort of reduces the distance from the low level layers to the task so that they can be more immediately involved.",
            "So fine."
        ],
        [
            "Only we need to address the fact that colorization is not unique.",
            "OK, so you could have multiple reasonable colorizations of 1 pixel.",
            "So."
        ],
        [
            "That we're going to predict histograms so the histograms can capture multi modality.",
            "And the color space that we use is Hue and chroma, and lightness is sort of a pass through channel, so putting this all together."
        ],
        [
            "OK, so we first first we have to if we want to create an RGB image.",
            "We do have to sample or select one represent one color from the histogram.",
            "So for this we sort of we picked median for the Chrome on that worked well.",
            "We can pick medium for the Hue because it's circular and so we use the complex expectation for that.",
            "Anne this"
        ],
        [
            "Where we get.",
            "So we do this for every pixel and you can see that the our results are pretty close to the ground truth.",
            "So the way this is.",
            "So another thing we."
        ],
        [
            "To do with the rich representation of actually predicting histograms is we could say, well, we can introduce a global bias that says let's make this image more red or more blue.",
            "So."
        ],
        [
            "So.",
            "We can, we can say, OK, we want this to be red, but we can also say we want this to be blue."
        ],
        [
            "And you see that the skin color did not change because it had a more higher certainty in the model, so it had sort of a low entropy prediction."
        ],
        [
            "Here's another exam."
        ],
        [
            "Apple with.",
            "Four different."
        ],
        [
            "Colors of the tractor, but the grass is always green."
        ],
        [
            "So to summarize, the training, we started with an image not pre trained model that was trained for classification."
        ],
        [
            "We adapted to grayscale.",
            "Fine tune fine tune it for a little bit."
        ],
        [
            "And then we switched the task to colorization and we train it on no labeled data.",
            "So the way the."
        ],
        [
            "These things are usually trained is you create a fully convolutional or you run your network as a fully convolutional network and you get this really dense representation of hyper columns.",
            "Now this is a huge memory footprint.",
            "So one of our technical innovations is to use a sparse sampling of hyper columns."
        ],
        [
            "So we do by direct bilinear interpolation, so we don't need all the full representation of all hyper columns.",
            "And we found that since so many of the hyper columns in a single image are highly correlated, you don't lose much in training.",
            "So using this we can train a much larger images with comfortable batch sizes."
        ],
        [
            "And we had code available for Cafe in Tensorflow.",
            "This can be used for other image to image tasks.",
            "So I encourage you to check it out."
        ],
        [
            "So how do we do on colorization well?",
            "Compare comparing to the two ICD papers on quantitative measurements.",
            "So basically looking at how far away are we on a per pixel basis to the ground truth?",
            "We offer a pretty significant improvement over the state of the art.",
            "When it comes."
        ],
        [
            "To comparison with concurrent work, there are two papers that did comparisons.",
            "The first one I'm showing you as an archive paper.",
            "And.",
            "We do better, but to be fair, Jung at all from UC Berkeley, they did not emphasize this task.",
            "They looked at.",
            "User studies which we saw yesterday and they tested two models of their own and then our model and our model came in in between.",
            "So I think what's interesting here is that we're able to be very competitive on the quantitative measurements, but it doesn't seem that we're giving up user appeal, so we're able to do both of these tasks well.",
            "They also did an interesting thing which was to run the colorized images through a classifier, and on this we improve the accuracy the most.",
            "So."
        ],
        [
            "What does it look like?",
            "These are all images that were not seen during training in either of the stages classification or colorization.",
            "And."
        ],
        [
            "This is how they look colorized.",
            "So you can see it's pretty hard to tell these from actual color images."
        ],
        [
            "Couple more examples and notice that we can colorize things that are not necessarily image net classes, right?",
            "So for instance, the grass, the wood texture, all these things are not image in the classes, but we can still colorize them appropriately.",
            "Another interesting one is the top right corner here, where the actual leaf is red, but our model took a more conservative guess and said green."
        ],
        [
            "Even though we didn't adapt this explicitly to old black and white photographs, it still does pretty well."
        ],
        [
            "So just to manage your expectations, they don't all look this good.",
            "These are sort of a selection of very successful examples, and there are still many many failure cases such as inconsistent color for objects, color bleeding, various types of confusion.",
            "So."
        ],
        [
            "To come back to the second motivation, which was sort of colourization as a vehicle for self supervision.",
            "The first question we need to ask is can you train colorization from scratch?",
            "And that."
        ],
        [
            "Turns out you can do it pretty well.",
            "Actually you lose a little bit by not using an image not pre trained model, but it still works pretty well."
        ],
        [
            "Then we can.",
            "We can take this model and utilize it for another task such as semantic segmentation.",
            "So this is the task of essentially classification on a per pixel level.",
            "So each pixel needs to be labeled caraboat or anything.",
            "For 20 classes in background."
        ],
        [
            "And sorry if it's cut off a little bit.",
            "No, it's not.",
            "It's only on my screen.",
            "OK, very good so.",
            "If you train semantic segmentation from random initialization, you do really poorly.",
            "32.5 there and then.",
            "If you use an image net pre trained model, you get much better results.",
            "So how do we do initializing this with our colorized or colourization from scratch network well?"
        ],
        [
            "We found that we can more than halfway bridge this gap.",
            "And what I really want to highlight is the fact that the best results that use only the original data set is about 48% and the only thing we added was unlabeled data.",
            "But this is ongoing work and I think we can.",
            "We can push this further.",
            "So to sum."
        ],
        [
            "Nice, I presented a fully automatic colorization model with state of the art results.",
            "We present a an efficient way of training using sparse sampling of hyper columns and we also see this as a promising proxy task for visual learning.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is work from TTI, Chicago together with Michael Moran, Greg Schechner, Ovich.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's try to define.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In what colorization is so?",
                    "label": 0
                },
                {
                    "sent": "Let's set up the task.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you open up this image in Photoshop, there's a button that says.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Saturate and if you click it, it will sort of drain all the color from your image and you get a grayscale image.",
                    "label": 0
                },
                {
                    "sent": "Now one definition of polarization could be the inverse.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function of this.",
                    "label": 0
                },
                {
                    "sent": "So now we open up a grayscale image we hit.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One that says colorized and we get back the original, the original meaning whatever we had that we desaturated.",
                    "label": 0
                },
                {
                    "sent": "But this is an Impala.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple problem and we might not have an original that was desaturated.",
                    "label": 0
                },
                {
                    "sent": "It could be an original grayscale image.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We could propose another definition that says, well, it's just.",
                    "label": 0
                },
                {
                    "sent": "It just needs to be an inverse that is false.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Foreign pleasing to human observer, so there's sort of some wiggle room in how we could interpret that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going to keep we're going to use both of these definitions.",
                    "label": 0
                },
                {
                    "sent": "The first one we're going to use for training and quantitative evaluation, and the second one we're just going to keep in mind for qualitative evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before we go into automatic colorization, I thought we would try and Emanuel colorization first, so I opened up this image in Photoshop.",
                    "label": 1
                },
                {
                    "sent": "I had never seen the color version of it.",
                    "label": 0
                },
                {
                    "sent": "And so before I can start picking a color and putting it down, I have to.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I see things like grass I identify.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things like trees and I.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Know that the scene is a landscape scene, so I'm using all.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These low level to high level cues to build the confidence to say this region should be green.",
                    "label": 0
                },
                {
                    "sent": "OK so I continue and I.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Sky Blue Anne for the mountains.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I sort of panicked and said, well, maybe they're Brown.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is clearly not Eva.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very high quality colorization and I'm not just trying to lower the bar here.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to see what I could do in as little time as possible and this was sort of my 15 second budget.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spending a little bit more time on it, I got this in three minutes, so that's still 3 minutes and it did require some Photoshop in some sort of artistic touches.",
                    "label": 0
                },
                {
                    "sent": "So the prospects of being able to do this fully automatically with an algorithm in 100.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "SEC has clear economic wins.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the motivation of this work is primarily to colorize old black and white photographs and films, but there's a second motivate.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Asian, which is we think this is a good proxy for visual understanding because you have to understand what's in the image to colorize it correctly and I'll come back to that at the at the end.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dramatic colorization, or colorization, has been a research field for about 15 years.",
                    "label": 0
                },
                {
                    "sent": "Most previous methods have involved some level of user inputs, such as scribbles or selecting a reference image.",
                    "label": 0
                },
                {
                    "sent": "The the more recent.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The automatic prediction based models we saw first time last year two papers that I CV and then.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This year we've seen one at SIGGRAPH and then yes.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today you saw one a great talk from UC Berkeley presented by Richard Young and then our work now, so how?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going to make this model well.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a convolutional neural network, and some of the design principles will be so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we need semantic knowledge.",
                    "label": 0
                },
                {
                    "sent": "If you see a grayscale image of a banana, you need to identify it as a banana and know that bananas are usually yellow, so we're going to start by leveraging an image.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Task based classifier so it's been trained for classification and it has all these representations.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Secondly, we want to be able to use both low level and high level cues just like I did in my manual colorization, so we're going to use a hyper.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Call marketecture, that essentially concatenates all the layer for one spatial location.",
                    "label": 0
                },
                {
                    "sent": "What this what this does?",
                    "label": 0
                },
                {
                    "sent": "Is it sort of reduces the distance from the low level layers to the task so that they can be more immediately involved.",
                    "label": 0
                },
                {
                    "sent": "So fine.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only we need to address the fact that colorization is not unique.",
                    "label": 1
                },
                {
                    "sent": "OK, so you could have multiple reasonable colorizations of 1 pixel.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That we're going to predict histograms so the histograms can capture multi modality.",
                    "label": 0
                },
                {
                    "sent": "And the color space that we use is Hue and chroma, and lightness is sort of a pass through channel, so putting this all together.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we first first we have to if we want to create an RGB image.",
                    "label": 0
                },
                {
                    "sent": "We do have to sample or select one represent one color from the histogram.",
                    "label": 0
                },
                {
                    "sent": "So for this we sort of we picked median for the Chrome on that worked well.",
                    "label": 0
                },
                {
                    "sent": "We can pick medium for the Hue because it's circular and so we use the complex expectation for that.",
                    "label": 0
                },
                {
                    "sent": "Anne this",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where we get.",
                    "label": 0
                },
                {
                    "sent": "So we do this for every pixel and you can see that the our results are pretty close to the ground truth.",
                    "label": 0
                },
                {
                    "sent": "So the way this is.",
                    "label": 0
                },
                {
                    "sent": "So another thing we.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do with the rich representation of actually predicting histograms is we could say, well, we can introduce a global bias that says let's make this image more red or more blue.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can, we can say, OK, we want this to be red, but we can also say we want this to be blue.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you see that the skin color did not change because it had a more higher certainty in the model, so it had sort of a low entropy prediction.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another exam.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apple with.",
                    "label": 0
                },
                {
                    "sent": "Four different.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Colors of the tractor, but the grass is always green.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize, the training, we started with an image not pre trained model that was trained for classification.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We adapted to grayscale.",
                    "label": 0
                },
                {
                    "sent": "Fine tune fine tune it for a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we switched the task to colorization and we train it on no labeled data.",
                    "label": 0
                },
                {
                    "sent": "So the way the.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These things are usually trained is you create a fully convolutional or you run your network as a fully convolutional network and you get this really dense representation of hyper columns.",
                    "label": 1
                },
                {
                    "sent": "Now this is a huge memory footprint.",
                    "label": 0
                },
                {
                    "sent": "So one of our technical innovations is to use a sparse sampling of hyper columns.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we do by direct bilinear interpolation, so we don't need all the full representation of all hyper columns.",
                    "label": 0
                },
                {
                    "sent": "And we found that since so many of the hyper columns in a single image are highly correlated, you don't lose much in training.",
                    "label": 0
                },
                {
                    "sent": "So using this we can train a much larger images with comfortable batch sizes.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we had code available for Cafe in Tensorflow.",
                    "label": 1
                },
                {
                    "sent": "This can be used for other image to image tasks.",
                    "label": 0
                },
                {
                    "sent": "So I encourage you to check it out.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do on colorization well?",
                    "label": 0
                },
                {
                    "sent": "Compare comparing to the two ICD papers on quantitative measurements.",
                    "label": 0
                },
                {
                    "sent": "So basically looking at how far away are we on a per pixel basis to the ground truth?",
                    "label": 0
                },
                {
                    "sent": "We offer a pretty significant improvement over the state of the art.",
                    "label": 1
                },
                {
                    "sent": "When it comes.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To comparison with concurrent work, there are two papers that did comparisons.",
                    "label": 0
                },
                {
                    "sent": "The first one I'm showing you as an archive paper.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We do better, but to be fair, Jung at all from UC Berkeley, they did not emphasize this task.",
                    "label": 0
                },
                {
                    "sent": "They looked at.",
                    "label": 0
                },
                {
                    "sent": "User studies which we saw yesterday and they tested two models of their own and then our model and our model came in in between.",
                    "label": 0
                },
                {
                    "sent": "So I think what's interesting here is that we're able to be very competitive on the quantitative measurements, but it doesn't seem that we're giving up user appeal, so we're able to do both of these tasks well.",
                    "label": 0
                },
                {
                    "sent": "They also did an interesting thing which was to run the colorized images through a classifier, and on this we improve the accuracy the most.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What does it look like?",
                    "label": 0
                },
                {
                    "sent": "These are all images that were not seen during training in either of the stages classification or colorization.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is how they look colorized.",
                    "label": 0
                },
                {
                    "sent": "So you can see it's pretty hard to tell these from actual color images.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Couple more examples and notice that we can colorize things that are not necessarily image net classes, right?",
                    "label": 0
                },
                {
                    "sent": "So for instance, the grass, the wood texture, all these things are not image in the classes, but we can still colorize them appropriately.",
                    "label": 0
                },
                {
                    "sent": "Another interesting one is the top right corner here, where the actual leaf is red, but our model took a more conservative guess and said green.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even though we didn't adapt this explicitly to old black and white photographs, it still does pretty well.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to manage your expectations, they don't all look this good.",
                    "label": 0
                },
                {
                    "sent": "These are sort of a selection of very successful examples, and there are still many many failure cases such as inconsistent color for objects, color bleeding, various types of confusion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To come back to the second motivation, which was sort of colourization as a vehicle for self supervision.",
                    "label": 0
                },
                {
                    "sent": "The first question we need to ask is can you train colorization from scratch?",
                    "label": 1
                },
                {
                    "sent": "And that.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turns out you can do it pretty well.",
                    "label": 0
                },
                {
                    "sent": "Actually you lose a little bit by not using an image not pre trained model, but it still works pretty well.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we can.",
                    "label": 0
                },
                {
                    "sent": "We can take this model and utilize it for another task such as semantic segmentation.",
                    "label": 1
                },
                {
                    "sent": "So this is the task of essentially classification on a per pixel level.",
                    "label": 0
                },
                {
                    "sent": "So each pixel needs to be labeled caraboat or anything.",
                    "label": 0
                },
                {
                    "sent": "For 20 classes in background.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And sorry if it's cut off a little bit.",
                    "label": 0
                },
                {
                    "sent": "No, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's only on my screen.",
                    "label": 0
                },
                {
                    "sent": "OK, very good so.",
                    "label": 0
                },
                {
                    "sent": "If you train semantic segmentation from random initialization, you do really poorly.",
                    "label": 1
                },
                {
                    "sent": "32.5 there and then.",
                    "label": 0
                },
                {
                    "sent": "If you use an image net pre trained model, you get much better results.",
                    "label": 1
                },
                {
                    "sent": "So how do we do initializing this with our colorized or colourization from scratch network well?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We found that we can more than halfway bridge this gap.",
                    "label": 0
                },
                {
                    "sent": "And what I really want to highlight is the fact that the best results that use only the original data set is about 48% and the only thing we added was unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "But this is ongoing work and I think we can.",
                    "label": 0
                },
                {
                    "sent": "We can push this further.",
                    "label": 0
                },
                {
                    "sent": "So to sum.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nice, I presented a fully automatic colorization model with state of the art results.",
                    "label": 1
                },
                {
                    "sent": "We present a an efficient way of training using sparse sampling of hyper columns and we also see this as a promising proxy task for visual learning.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}