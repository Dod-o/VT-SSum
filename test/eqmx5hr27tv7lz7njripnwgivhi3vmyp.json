{
    "id": "eqmx5hr27tv7lz7njripnwgivhi3vmyp",
    "title": "Folks in Folksonomies: Social Link Prediction from Shared Metadata",
    "info": {
        "author": [
            "Filippo Menczer, School of Informatics and Computing, Indiana University"
        ],
        "published": "March 18, 2010",
        "recorded": "February 2010",
        "category": [
            "Top->Computers->Social Networking",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/wsdm2010_menczer_fif/",
    "segmentation": [
        [
            "So the last talk.",
            "See if please don't fall asleep yet.",
            "So I'm film answer from Indiana University and the work I'm presenting is done with my student Ben Martinez and also Rossano Ski Fenella from University of Torino Anna Lembaran Shiroka to from the ISI Foundation Interino also."
        ],
        [
            "Let me start with a quote from Dana Boyd on homophily and actually the previous at least two, if not three talks have talked about him."
        ],
        [
            "Hopefully people connect to people like themselves.",
            "What flows across the network flows through edges of similarity.",
            "In fact, actually the quote continues and it's kind of interesting.",
            "I interviewed gay men who thought friends there was a gay dating site because all they saw where other gay men and I interviewed teens who believe that everybody on Myspace was Christian because all the profiles they saw contain, biblical quotes, etc.",
            "So this idea of homophily is that we tend to connect socially with people who are like us as the previous."
        ],
        [
            "Speakers have talked about and that's what we explore in in in this work, and more quantitatively, the question that we ask is given to users.",
            "How does the alignment or the similarity between their tag vocabularies or other features?",
            "Related to the proximity in the social network, and there are two different directions of."
        ],
        [
            "Question one is.",
            "If you have two people that are friends like Angelina and myself here, can you then infer?"
        ],
        [
            "Right that they have interesting comment, for example, as measured through share tags, and this is actually related to the question that Alan."
        ],
        [
            "I was asking."
        ],
        [
            "Earlier in fact, he's done prior work on this question, and Conversely, if you know that two people, again Angelina or me, have similar interests, can you infer?"
        ],
        [
            "That they are likely to be friends or they are likely to be nearby in the in the social network, so will try to answer these two questions."
        ],
        [
            "To do that, we leverage a couple of datasets.",
            "One is based on Flickr and one is based on last FM.",
            "You can read the details on the paper as many others have talked about before.",
            "Flickr is a narrow folksonomy because people tend to only annotate their own objects, their own items or pictures.",
            "Whereas last FM is abroad Folksonomy because different people can tag the same artists or songs and albums etc.",
            "I also want to mention that we were able to make the our data set from last FM publicly available.",
            "That's the URL.",
            "If you want to play with it, or you can ask us later."
        ],
        [
            "So let me start with some measures of correlation between different measures of activity.",
            "So here we're looking at the degree of a user in the social network.",
            "Yeah, I forgot to mention that one of the well.",
            "The main reason why we looked at these two datasets is because these are cases and there are a few others as well in which you have both data about the social network, the social connections explicitly, as well as annotations.",
            "OK, so you can look at the degree, how many friends a person has.",
            "You can look at the NT number of tags, number of distinct tags that they use.",
            "You can look at a number of annotations or tag assignments.",
            "And you can look at how many groups of person belongs to and these measures are all correlated.",
            "That matrix there shows you the Pearson correlations.",
            "You could also look at it here as a function of the degree K as people who have more and more friends.",
            "They also tend to belong to more groups and they also tend to assign more tags and use more tags.",
            "So all these quantities are correlated with each other and this is going to be important to know later."
        ],
        [
            "Another thing to look at is mixing patterns and actually on this also Alan's done some work.",
            "So actually he Alan sorry he showed before that for example that in the social the social network is assorted.",
            "If that is if you plotted on the X axis the number of friends that you have and on the Y axis you look at for all the people that have a certain number of friends.",
            "What is the average number of friends of their friends?",
            "OK, that's the assortativity well and if you see that if this grows it means people with more friends tend to be friends with other people who also have more friends.",
            "And then I'm not going to go into the detail that red in the black are just tools like variations of the of the Flickr data set.",
            "In this particular case, you can read it in the paper, but actually we looked at other measures of activity and they also are sorted.",
            "It.",
            "For example, people who belong to more groups tend to be friends with other people who also belong to more groups and people who use more tags than to be friends with people who use more tags and people who do more tag assignments or annotations tend to be friends with people who do more annotations.",
            "So these mixing patterns.",
            "Actually are important because they paint how we're going to interpret any correlations that we observe.",
            "So I'm going to come back to this point later."
        ],
        [
            "Now to address the question about the relationship between lexical for example and or or topical similarity, the tags that people share or the groups that they share and their closeness is in the social network.",
            "We're going to focus on local alignment, local similarity.",
            "Actually, we know that for example, in Flickr.",
            "As I said, it's a.",
            "It's a narrow folksonomy.",
            "There isn't a global alignment, right?",
            "Taking two random people.",
            "The typical number of tags that they share is 0, the mode and the average is also small.",
            "Less than two, but we're not interested in that.",
            "We're interested in similarity between two people who are friends or who are friends of friends.",
            "So for example, let."
        ],
        [
            "Take Angelina and her friend.",
            "I don't know Beth, let's say, and then you can look at the items that they share.",
            "The tags that they share.",
            "These are like tag vectors where the size or the weight of A tag is the number of items that they have.",
            "Or pictures.",
            "In this case that they have annotated with that tag and you can see whether they have some in common.",
            "In this case they have many in common."
        ],
        [
            "So how do we measure the relationship between the social that you know, the nearness in the social network and the alignment?",
            "Well, it's actually very simple.",
            "You can take 2 random users.",
            "Me and Catherine here."
        ],
        [
            "And you can look at.",
            "You can do a breadth first search in the social network to see their distance.",
            "We have distance four 'cause my dad worked in the movies and."
        ],
        [
            "And then you can also look at there for example tag vectors if you want to measure similarity between lexical similarity for example.",
            "So you can do for example cosine similarity or sum."
        ],
        [
            "Either measure or in the case of groups you can look at topical similarity.",
            "OK."
        ],
        [
            "So you can do this and then you can ask the question, is there correlation right?",
            "If they are close?",
            "If their friends?",
            "Do they have tags in common for example?",
            "But this is where the issue of the correlations that I showed you earlier turn out to be important because.",
            "You might observe this kind of correlation even if they have nothing to do with the social network.",
            "Why?",
            "Well, because I told you that if you have a lot of friends, your friends will have a lot of friends.",
            "But I also told you that people who have a lot of friends also tend to, for example, use a lot of tags or belong to many groups and their friends also do.",
            "So typically you will find that people who are popular and who are active tend to also be similar, not because their friends, but simply because.",
            "Of the bias for popularity for popular people in popular tags.",
            "OK, so this is a global correlation.",
            "It has nothing to do with the locality.",
            "So how do we deal with that?",
            "We have to have a known model."
        ],
        [
            "So here's what we do.",
            "We take the social network.",
            "We maintain the social links.",
            "We don't do anything to them, but we also look at the annotations and we shuffle.",
            "We shuffle tags.",
            "OK, so the way that we shuffle tags, though, is in such a way that we maintain all the local properties.",
            "So we maintain the degree.",
            "I already said that we maintain the number of tags and a number of tag assignments for each user and the number of number of groups.",
            "So here, for example, let's take these two and you can see Angelina, for example, has.",
            "Two tags, their dog and cat and three tag assignments OK, and here 2 tags and two."
        ],
        [
            "Tag assignment and we can shuffle one of the tags and the result is that we still have the same number of unique tags up there, even though they're not the same ones.",
            "But there's still two tags and three tag assignments and two tags into tag assignment so we can keep shuffling.",
            "And So what we're doing is we're destroying all the local correlations, but we're maintaining all the global correlations, right?",
            "So whatever was the most popular tag is still going to be the most popular tag 'cause we don't throw tags away.",
            "We don't change any of this global distributions.",
            "Two people who are friends are going to still be friends.",
            "So if we still find a correlation now between the social distance and lexical, for example, similarity that has to be do with the spurious global correlations, it can't have anything to do with local alignment, right?",
            "OK, so now we can actually look."
        ],
        [
            "At the data."
        ],
        [
            "And it's not particularly surprising if you if you plot the distance on the X axis and some measure of similarity on the Y axis, you see that there is a correlation.",
            "For example, on the top there is a very silly measure of similarity, which is just it's called matching.",
            "It's just a number of shared tags.",
            "And you can see that if you're a distance one on the social network, you're going to share many more tags than if you're distance 234, etc.",
            "However, if you look at the shuffled network, you find the same.",
            "Almost right, so that means that most of those correlations that you see up on the top left or serious they have nothing to do with local alignment.",
            "But if you use a smarter similarity measure like cosine similarity, which is 1 on the bottom plot, then again you find a correlation for the real graph.",
            "But for the for the shuffle version, that kind of goes away.",
            "OK, so in this case what you can say is that there is there's actual log local lexical alignment.",
            "If you're using cosine similarity as a measure of it.",
            "In the case of Flicker, which is what this data is from.",
            "OK, so there's no global alignment, but there is definitely local alignment.",
            "OK, we've done the same with last FM.",
            "The results are very SIM."
        ],
        [
            "Here they are again, if you just use matching, you don't get very useful data.",
            "You just observe the global correlations.",
            "If use cosine similarity, it's not quite as strong as in the case of Flickr, but it's still there.",
            "There is an effect, and this you can look it up in the paper.",
            "It's just a different way to look at exactly the same thing by looking at the distributions instead of of distances for different sorry of similarities for different distances.",
            "Instead of looking similarity as a function of distance, it doesn't matter, it's basically tells you the same thing that there is this local."
        ],
        [
            "Lexical alignment.",
            "OK, so now that we know that.",
            "We can ask the other question, which is sort of the.",
            "So the complementary question to the one that Alan explored earlier, right?",
            "He said, well, can we infer tags by using the social network right?",
            "By looking at your neighbors?",
            "And here we want to do the opposite.",
            "Can we infer social connections by looking at the content by looking at your tags or or your groups, etc.",
            "So to explore this question we use the number of similarity measures that we developed in prior work, and these are basically information theoretic similarity.",
            "Measures that extend well known things like cosine similarity, Jaccard coefficient, mutual information, etc.",
            "And.",
            "There is another thing to keep in mind is that when you're trying to use this kind of well established similarity measures, but you're starting with the representation that is basically maker of triples or tensors because you have users, tags and resources you have to, you have to aggregate or project the data so you can do this in many different ways and in past work we looked at very different aggregation schemes.",
            "Here we focused on 2, one that we call distributional, which actually is exactly the same that is used in a paper that was presented yesterday.",
            "Entitled I tag you tag.",
            "Etc.",
            "So it's just basically what you would expect.",
            "You simply project on one dimension and so you end up with, let's say, user represented as a vector of, let's say tags or vector of songs, whatever.",
            "The other one is what we call collaborative aggregation, and again the details are in the paper 'cause I don't have time and we're all tired, but the idea there is it has two advantages.",
            "One is that it allows us to explore collaborative filtering.",
            "That's why we call it collaborative and the other one is that it allows to compute these similarities in incremental way.",
            "OK, so basically when a new user comes in and as new annotations, we don't have to recompute the similarity between all the other users.",
            "OK, we only need to update the similarity for that one user.",
            "OK, so we had previously studied these measures in the context of.",
            "Similarities between tags or similarity between resources.",
            "And now we wanted to look at whether that would be useful in the case of computing similarities between users so."
        ],
        [
            "Is new.",
            "Alright, so we could do this either with Flickr or or last FM, because in both cases we know what the social network is right?",
            "So we can make a prediction based on the content similarity, groups, tags, whatever and then we can see if we got it right.",
            "So you could think of it as classification or prediction depending on how you look at it.",
            "In fact, the results for Flickr and last FM are similar.",
            "However I'm going."
        ],
        [
            "Focus on the results from from last FM because there are more interesting for two reasons.",
            "One is that because the family is the family brought Folksonomy, the measures of similarity are more interesting than more rich, right?",
            "Because it's more likely that two people share.",
            "For example, a song but an artist.",
            "OK, so the measure of similarity are going to be a little bit more dense and as a result the result are a little bit more significant there.",
            "There's the differences are a little bit more strong, stronger, so it's easier to look at the results.",
            "The other, even more important reason for focusing on last FM is that we have a stronger baseline because last FM actually makes recommendations about.",
            "They call them neighbors.",
            "OK, so they look at where you listen to, right?",
            "If you look, listen to rock and roll, they say, oh look, you might want to be friend with Carlos here because he also listens to rock and roll.",
            "OK, so they look at the listening patterns, maybe same artist, say John Wras and they say, well, those are your potential neighbors so we can use that as a better baseline than just random.",
            "OK."
        ],
        [
            "So what do we do?",
            "Oh, let me just show you one of these similarity measures.",
            "I told you we used many.",
            "Let me just say a little bit about one.",
            "As an example, we call it maximum information path.",
            "It's actually an extension of something that was introduced several years ago.",
            "We call it Lynn.",
            "Similarity even introduced by Lynn, and in the case of a hierarchical network.",
            "OK, so if you have objects stored in the nodes of a tree, so basically in similarity looks at, compute the similarity by looking at the entropy or information of the lowest common ancestor node.",
            "OK, it's intuitive, and in the case of tags we generalize that we don't have a tree."
        ],
        [
            "Here, but we have tags so we could think of tags as if they were classes and so we could look at all the shared tags and we look at the most specific share tag.",
            "OK so."
        ],
        [
            "The formula looks like this and the idea is that you look at.",
            "Let's say that these two share a lot of tags and let's say that love is the most specific.",
            "So you take the tag that minimizes or maximizes the information, or minimizes the log odds of finding such A tag."
        ],
        [
            "OK, and then all the others I don't have time to go into because I'm already late, but you can find them in the paper.",
            "They're all extensions of familiar things like like I said, the only one we didn't put in the papers mutual information because it's very, very expensive to compute and we've already shown before that actually maximum information path does as well as."
        ],
        [
            "Information or better so remember that for each of the whole of these similarity we have four different versions.",
            "'cause we have two different ways to do the aggregation.",
            "And then once you decide OK, I'm going to do distribution aggregation.",
            "You still have to decide am I going to aggregate across items or across tags.",
            "So for example, let's say for distribution aggregation across items, that means that you're representing a user as a vector of tags.",
            "OK, where the weights are?",
            "You know how often those tags are used by the user.",
            "Then you could apply cosine and that would be the straightforward way, and this is."
        ],
        [
            "Miller for maximum information path.",
            "OK, so how do we evaluate this?",
            "Well, first we select a bunch of users and then.",
            "Hey, you can do this in many ways right?",
            "You could look at the ones that are most active.",
            "They do most annotation so random or most connected.",
            "Well, you're not going to be surprised when I tell you that most active is the one that works best, because that's where we have data, right?",
            "That's where were you?"
        ],
        [
            "In the annotations now, once you have the pairs you can rank them in the order of the similarity.",
            "You measure OK, so the one that has the highest similarity is going to be my first prediction, and then I'm going to check is it true or not?",
            "Is the social link there or not?",
            "And so you can measure true positive false positive build."
        ],
        [
            "Your OC curve, some previous talk already went into that, so I don't need to waste my time and you can compare to measures, for example by looking at the area under the arosi curve is one way, so bigger means better because you have more true positives with fewer false."
        ],
        [
            "OK, one caveat.",
            "OK problem is that both the neighborhood function that we use as a baseline and our own similarities are very sparse, right?",
            "Because we have to look at shared tags.",
            "So we had a lot of noise and relatively little signal.",
            "So to make this a little bit more amenable to amenable to analysis, we biased the way that we select these pairs and the way that we biased it is we biased in favor of neighbors.",
            "So in other words, if we're looking if we're looking at, let's say.",
            "Active users, we select pairs of users who are active and who are neighbors.",
            "Now, is it cheating?",
            "Yes it is cheating, but not in favor of our approach in favor of the baseline.",
            "Because if two people are friends for sure the neighborhood baseline is gonna know it.",
            "So for sure they're going to get the answer correct.",
            "The baseline is going to get the answer correct, whereas it might be that two people are actually friends and we correctly predict that, but they weren't listening to the same music, so it would look like we are wrong and the baseline is correct, even though it's the other way around.",
            "So it is a bias.",
            "We'd love to do without, and we're looking at ways to do without, but it is very fair.",
            "It's very conservative.",
            "If it favors an algorithm, it favors the baseline, not our algorithm all right now."
        ],
        [
            "That said, let's look at the results.",
            "Here are some arosi curves.",
            "Here you can see what happens when you use different ways to sample the users.",
            "Most active, most connected random, most active is the one where we get the best results.",
            "That's not surprising, 'cause that's where we have the annotation data, right?",
            "And then we can do and aggregations across items or across tags, and the best results are for active Now the curves there it's a little bit small, so let me read it to you.",
            "The blue line is the baseline the neighborhood, and then the other two lines.",
            "On top of that, our mutual information path.",
            "Sorry, maximum information path for the two different.",
            "Aggregation approach is distributed and collaborative aggregation, and you can see that they both do much better than the baseline.",
            "It turns out that actually information path is among the best measures under all conditions, so that's nice and so now let's compare that.",
            "Let's now focus.",
            "Sorry on most active and aggregation across items and compare the results with all the other similar."
        ],
        [
            "The measures, so we're now looking at the relative improvement in area under the RC curve compared to the neighborhood baseline.",
            "OK, so any positive number means that we outperform the baseline, and as you can see, almost all the numbers are around 2030%, so the results are very positive.",
            "Pretty much doesn't matter which measure you use.",
            "If you look at similar content, you're going to do better at predicting friendship then if you look at listening patterns, an MIP turns out to be one of the best ones."
        ],
        [
            "OK, so to summarize, two things right one is we looked at him awfully and we found that there is local alignment of tag usage for social for social neighbors and same for groups.",
            "I didn't show it for lack of time.",
            "So, but it is important to have the right null model, right?",
            "Because we could have found this and be and be wrong because we would have found that even if there wasn't such local alignment because of the of the global correlation, so that the proper new model is important and the second point is that now we can use similarity based on annotations by active users to as good predictor of social links better than the listening patterns.",
            "So this could be used for example to improve friend recommendations for example.",
            "Facebook should tell Angelina to befriend me right?",
            "That would be the right thing."
        ],
        [
            "OK, so since Carlos is waving his hand, I'm going to skip related work.",
            "I hope I don't offend anyone.",
            "For example, Alan has had looked at very similar questions in the past, and even today that builds on that.",
            "So there's several things."
        ],
        [
            "Look at, you can find them in the in the paper.",
            "Let me just close with a note on the future.",
            "We would like to do a longitudinal study to see whether you know is it the case that people are friends and therefore they start looking at similar things.",
            "Or is it the case that people have similar interests and a result of that they become friends?"
        ],
        [
            "Some work on evaluation.",
            "You can read it in the paper.",
            "I just want to conclude on one thing that I'm excited about.",
            "We're trying to build some games.",
            "As based on tag resource and user similarity to incentivize annotations and also to make social recommendations.",
            "So, for example, people may play finding related tags and by doing that we get annotations and we get information about relationships between tags, for example, or objects.",
            "But then we can also make recommendations.",
            "Oh, this other person you might be interested in befriending this person on Facebook because they have similar interests, or you might be interested in this photos on Flickr because these users use the same.",
            "Annotations for them and that kind of stuff.",
            "So this kind of exciting.",
            "We're playing with iPhone apps for that, and I'm out of."
        ],
        [
            "I'm so thank you very much.",
            "If there is a quick comment or question.",
            "OK, I guess everybody is tired tired, thank you.",
            "Thank you again and thanks all the speaker.",
            "Thanks guys."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last talk.",
                    "label": 0
                },
                {
                    "sent": "See if please don't fall asleep yet.",
                    "label": 0
                },
                {
                    "sent": "So I'm film answer from Indiana University and the work I'm presenting is done with my student Ben Martinez and also Rossano Ski Fenella from University of Torino Anna Lembaran Shiroka to from the ISI Foundation Interino also.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me start with a quote from Dana Boyd on homophily and actually the previous at least two, if not three talks have talked about him.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hopefully people connect to people like themselves.",
                    "label": 1
                },
                {
                    "sent": "What flows across the network flows through edges of similarity.",
                    "label": 1
                },
                {
                    "sent": "In fact, actually the quote continues and it's kind of interesting.",
                    "label": 0
                },
                {
                    "sent": "I interviewed gay men who thought friends there was a gay dating site because all they saw where other gay men and I interviewed teens who believe that everybody on Myspace was Christian because all the profiles they saw contain, biblical quotes, etc.",
                    "label": 1
                },
                {
                    "sent": "So this idea of homophily is that we tend to connect socially with people who are like us as the previous.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Speakers have talked about and that's what we explore in in in this work, and more quantitatively, the question that we ask is given to users.",
                    "label": 0
                },
                {
                    "sent": "How does the alignment or the similarity between their tag vocabularies or other features?",
                    "label": 1
                },
                {
                    "sent": "Related to the proximity in the social network, and there are two different directions of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question one is.",
                    "label": 0
                },
                {
                    "sent": "If you have two people that are friends like Angelina and myself here, can you then infer?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right that they have interesting comment, for example, as measured through share tags, and this is actually related to the question that Alan.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I was asking.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Earlier in fact, he's done prior work on this question, and Conversely, if you know that two people, again Angelina or me, have similar interests, can you infer?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That they are likely to be friends or they are likely to be nearby in the in the social network, so will try to answer these two questions.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do that, we leverage a couple of datasets.",
                    "label": 0
                },
                {
                    "sent": "One is based on Flickr and one is based on last FM.",
                    "label": 0
                },
                {
                    "sent": "You can read the details on the paper as many others have talked about before.",
                    "label": 0
                },
                {
                    "sent": "Flickr is a narrow folksonomy because people tend to only annotate their own objects, their own items or pictures.",
                    "label": 0
                },
                {
                    "sent": "Whereas last FM is abroad Folksonomy because different people can tag the same artists or songs and albums etc.",
                    "label": 0
                },
                {
                    "sent": "I also want to mention that we were able to make the our data set from last FM publicly available.",
                    "label": 0
                },
                {
                    "sent": "That's the URL.",
                    "label": 0
                },
                {
                    "sent": "If you want to play with it, or you can ask us later.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me start with some measures of correlation between different measures of activity.",
                    "label": 0
                },
                {
                    "sent": "So here we're looking at the degree of a user in the social network.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I forgot to mention that one of the well.",
                    "label": 0
                },
                {
                    "sent": "The main reason why we looked at these two datasets is because these are cases and there are a few others as well in which you have both data about the social network, the social connections explicitly, as well as annotations.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can look at the degree, how many friends a person has.",
                    "label": 0
                },
                {
                    "sent": "You can look at the NT number of tags, number of distinct tags that they use.",
                    "label": 0
                },
                {
                    "sent": "You can look at a number of annotations or tag assignments.",
                    "label": 0
                },
                {
                    "sent": "And you can look at how many groups of person belongs to and these measures are all correlated.",
                    "label": 0
                },
                {
                    "sent": "That matrix there shows you the Pearson correlations.",
                    "label": 0
                },
                {
                    "sent": "You could also look at it here as a function of the degree K as people who have more and more friends.",
                    "label": 0
                },
                {
                    "sent": "They also tend to belong to more groups and they also tend to assign more tags and use more tags.",
                    "label": 0
                },
                {
                    "sent": "So all these quantities are correlated with each other and this is going to be important to know later.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing to look at is mixing patterns and actually on this also Alan's done some work.",
                    "label": 0
                },
                {
                    "sent": "So actually he Alan sorry he showed before that for example that in the social the social network is assorted.",
                    "label": 0
                },
                {
                    "sent": "If that is if you plotted on the X axis the number of friends that you have and on the Y axis you look at for all the people that have a certain number of friends.",
                    "label": 0
                },
                {
                    "sent": "What is the average number of friends of their friends?",
                    "label": 0
                },
                {
                    "sent": "OK, that's the assortativity well and if you see that if this grows it means people with more friends tend to be friends with other people who also have more friends.",
                    "label": 0
                },
                {
                    "sent": "And then I'm not going to go into the detail that red in the black are just tools like variations of the of the Flickr data set.",
                    "label": 0
                },
                {
                    "sent": "In this particular case, you can read it in the paper, but actually we looked at other measures of activity and they also are sorted.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "For example, people who belong to more groups tend to be friends with other people who also belong to more groups and people who use more tags than to be friends with people who use more tags and people who do more tag assignments or annotations tend to be friends with people who do more annotations.",
                    "label": 0
                },
                {
                    "sent": "So these mixing patterns.",
                    "label": 0
                },
                {
                    "sent": "Actually are important because they paint how we're going to interpret any correlations that we observe.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to come back to this point later.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now to address the question about the relationship between lexical for example and or or topical similarity, the tags that people share or the groups that they share and their closeness is in the social network.",
                    "label": 0
                },
                {
                    "sent": "We're going to focus on local alignment, local similarity.",
                    "label": 1
                },
                {
                    "sent": "Actually, we know that for example, in Flickr.",
                    "label": 0
                },
                {
                    "sent": "As I said, it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a narrow folksonomy.",
                    "label": 0
                },
                {
                    "sent": "There isn't a global alignment, right?",
                    "label": 0
                },
                {
                    "sent": "Taking two random people.",
                    "label": 0
                },
                {
                    "sent": "The typical number of tags that they share is 0, the mode and the average is also small.",
                    "label": 0
                },
                {
                    "sent": "Less than two, but we're not interested in that.",
                    "label": 0
                },
                {
                    "sent": "We're interested in similarity between two people who are friends or who are friends of friends.",
                    "label": 0
                },
                {
                    "sent": "So for example, let.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take Angelina and her friend.",
                    "label": 0
                },
                {
                    "sent": "I don't know Beth, let's say, and then you can look at the items that they share.",
                    "label": 0
                },
                {
                    "sent": "The tags that they share.",
                    "label": 0
                },
                {
                    "sent": "These are like tag vectors where the size or the weight of A tag is the number of items that they have.",
                    "label": 0
                },
                {
                    "sent": "Or pictures.",
                    "label": 0
                },
                {
                    "sent": "In this case that they have annotated with that tag and you can see whether they have some in common.",
                    "label": 0
                },
                {
                    "sent": "In this case they have many in common.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we measure the relationship between the social that you know, the nearness in the social network and the alignment?",
                    "label": 0
                },
                {
                    "sent": "Well, it's actually very simple.",
                    "label": 0
                },
                {
                    "sent": "You can take 2 random users.",
                    "label": 0
                },
                {
                    "sent": "Me and Catherine here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can look at.",
                    "label": 0
                },
                {
                    "sent": "You can do a breadth first search in the social network to see their distance.",
                    "label": 0
                },
                {
                    "sent": "We have distance four 'cause my dad worked in the movies and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can also look at there for example tag vectors if you want to measure similarity between lexical similarity for example.",
                    "label": 0
                },
                {
                    "sent": "So you can do for example cosine similarity or sum.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either measure or in the case of groups you can look at topical similarity.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can do this and then you can ask the question, is there correlation right?",
                    "label": 0
                },
                {
                    "sent": "If they are close?",
                    "label": 0
                },
                {
                    "sent": "If their friends?",
                    "label": 0
                },
                {
                    "sent": "Do they have tags in common for example?",
                    "label": 0
                },
                {
                    "sent": "But this is where the issue of the correlations that I showed you earlier turn out to be important because.",
                    "label": 0
                },
                {
                    "sent": "You might observe this kind of correlation even if they have nothing to do with the social network.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Well, because I told you that if you have a lot of friends, your friends will have a lot of friends.",
                    "label": 0
                },
                {
                    "sent": "But I also told you that people who have a lot of friends also tend to, for example, use a lot of tags or belong to many groups and their friends also do.",
                    "label": 0
                },
                {
                    "sent": "So typically you will find that people who are popular and who are active tend to also be similar, not because their friends, but simply because.",
                    "label": 0
                },
                {
                    "sent": "Of the bias for popularity for popular people in popular tags.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a global correlation.",
                    "label": 0
                },
                {
                    "sent": "It has nothing to do with the locality.",
                    "label": 0
                },
                {
                    "sent": "So how do we deal with that?",
                    "label": 0
                },
                {
                    "sent": "We have to have a known model.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's what we do.",
                    "label": 0
                },
                {
                    "sent": "We take the social network.",
                    "label": 0
                },
                {
                    "sent": "We maintain the social links.",
                    "label": 0
                },
                {
                    "sent": "We don't do anything to them, but we also look at the annotations and we shuffle.",
                    "label": 0
                },
                {
                    "sent": "We shuffle tags.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way that we shuffle tags, though, is in such a way that we maintain all the local properties.",
                    "label": 1
                },
                {
                    "sent": "So we maintain the degree.",
                    "label": 0
                },
                {
                    "sent": "I already said that we maintain the number of tags and a number of tag assignments for each user and the number of number of groups.",
                    "label": 1
                },
                {
                    "sent": "So here, for example, let's take these two and you can see Angelina, for example, has.",
                    "label": 0
                },
                {
                    "sent": "Two tags, their dog and cat and three tag assignments OK, and here 2 tags and two.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tag assignment and we can shuffle one of the tags and the result is that we still have the same number of unique tags up there, even though they're not the same ones.",
                    "label": 0
                },
                {
                    "sent": "But there's still two tags and three tag assignments and two tags into tag assignment so we can keep shuffling.",
                    "label": 0
                },
                {
                    "sent": "And So what we're doing is we're destroying all the local correlations, but we're maintaining all the global correlations, right?",
                    "label": 0
                },
                {
                    "sent": "So whatever was the most popular tag is still going to be the most popular tag 'cause we don't throw tags away.",
                    "label": 0
                },
                {
                    "sent": "We don't change any of this global distributions.",
                    "label": 0
                },
                {
                    "sent": "Two people who are friends are going to still be friends.",
                    "label": 0
                },
                {
                    "sent": "So if we still find a correlation now between the social distance and lexical, for example, similarity that has to be do with the spurious global correlations, it can't have anything to do with local alignment, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so now we can actually look.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the data.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's not particularly surprising if you if you plot the distance on the X axis and some measure of similarity on the Y axis, you see that there is a correlation.",
                    "label": 0
                },
                {
                    "sent": "For example, on the top there is a very silly measure of similarity, which is just it's called matching.",
                    "label": 0
                },
                {
                    "sent": "It's just a number of shared tags.",
                    "label": 0
                },
                {
                    "sent": "And you can see that if you're a distance one on the social network, you're going to share many more tags than if you're distance 234, etc.",
                    "label": 0
                },
                {
                    "sent": "However, if you look at the shuffled network, you find the same.",
                    "label": 0
                },
                {
                    "sent": "Almost right, so that means that most of those correlations that you see up on the top left or serious they have nothing to do with local alignment.",
                    "label": 0
                },
                {
                    "sent": "But if you use a smarter similarity measure like cosine similarity, which is 1 on the bottom plot, then again you find a correlation for the real graph.",
                    "label": 0
                },
                {
                    "sent": "But for the for the shuffle version, that kind of goes away.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case what you can say is that there is there's actual log local lexical alignment.",
                    "label": 1
                },
                {
                    "sent": "If you're using cosine similarity as a measure of it.",
                    "label": 0
                },
                {
                    "sent": "In the case of Flicker, which is what this data is from.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's no global alignment, but there is definitely local alignment.",
                    "label": 0
                },
                {
                    "sent": "OK, we've done the same with last FM.",
                    "label": 0
                },
                {
                    "sent": "The results are very SIM.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here they are again, if you just use matching, you don't get very useful data.",
                    "label": 0
                },
                {
                    "sent": "You just observe the global correlations.",
                    "label": 0
                },
                {
                    "sent": "If use cosine similarity, it's not quite as strong as in the case of Flickr, but it's still there.",
                    "label": 0
                },
                {
                    "sent": "There is an effect, and this you can look it up in the paper.",
                    "label": 0
                },
                {
                    "sent": "It's just a different way to look at exactly the same thing by looking at the distributions instead of of distances for different sorry of similarities for different distances.",
                    "label": 0
                },
                {
                    "sent": "Instead of looking similarity as a function of distance, it doesn't matter, it's basically tells you the same thing that there is this local.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lexical alignment.",
                    "label": 0
                },
                {
                    "sent": "OK, so now that we know that.",
                    "label": 0
                },
                {
                    "sent": "We can ask the other question, which is sort of the.",
                    "label": 0
                },
                {
                    "sent": "So the complementary question to the one that Alan explored earlier, right?",
                    "label": 0
                },
                {
                    "sent": "He said, well, can we infer tags by using the social network right?",
                    "label": 0
                },
                {
                    "sent": "By looking at your neighbors?",
                    "label": 0
                },
                {
                    "sent": "And here we want to do the opposite.",
                    "label": 0
                },
                {
                    "sent": "Can we infer social connections by looking at the content by looking at your tags or or your groups, etc.",
                    "label": 0
                },
                {
                    "sent": "So to explore this question we use the number of similarity measures that we developed in prior work, and these are basically information theoretic similarity.",
                    "label": 0
                },
                {
                    "sent": "Measures that extend well known things like cosine similarity, Jaccard coefficient, mutual information, etc.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "There is another thing to keep in mind is that when you're trying to use this kind of well established similarity measures, but you're starting with the representation that is basically maker of triples or tensors because you have users, tags and resources you have to, you have to aggregate or project the data so you can do this in many different ways and in past work we looked at very different aggregation schemes.",
                    "label": 0
                },
                {
                    "sent": "Here we focused on 2, one that we call distributional, which actually is exactly the same that is used in a paper that was presented yesterday.",
                    "label": 0
                },
                {
                    "sent": "Entitled I tag you tag.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 0
                },
                {
                    "sent": "So it's just basically what you would expect.",
                    "label": 0
                },
                {
                    "sent": "You simply project on one dimension and so you end up with, let's say, user represented as a vector of, let's say tags or vector of songs, whatever.",
                    "label": 0
                },
                {
                    "sent": "The other one is what we call collaborative aggregation, and again the details are in the paper 'cause I don't have time and we're all tired, but the idea there is it has two advantages.",
                    "label": 0
                },
                {
                    "sent": "One is that it allows us to explore collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "That's why we call it collaborative and the other one is that it allows to compute these similarities in incremental way.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically when a new user comes in and as new annotations, we don't have to recompute the similarity between all the other users.",
                    "label": 0
                },
                {
                    "sent": "OK, we only need to update the similarity for that one user.",
                    "label": 0
                },
                {
                    "sent": "OK, so we had previously studied these measures in the context of.",
                    "label": 0
                },
                {
                    "sent": "Similarities between tags or similarity between resources.",
                    "label": 0
                },
                {
                    "sent": "And now we wanted to look at whether that would be useful in the case of computing similarities between users so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is new.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we could do this either with Flickr or or last FM, because in both cases we know what the social network is right?",
                    "label": 0
                },
                {
                    "sent": "So we can make a prediction based on the content similarity, groups, tags, whatever and then we can see if we got it right.",
                    "label": 0
                },
                {
                    "sent": "So you could think of it as classification or prediction depending on how you look at it.",
                    "label": 0
                },
                {
                    "sent": "In fact, the results for Flickr and last FM are similar.",
                    "label": 0
                },
                {
                    "sent": "However I'm going.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Focus on the results from from last FM because there are more interesting for two reasons.",
                    "label": 0
                },
                {
                    "sent": "One is that because the family is the family brought Folksonomy, the measures of similarity are more interesting than more rich, right?",
                    "label": 0
                },
                {
                    "sent": "Because it's more likely that two people share.",
                    "label": 0
                },
                {
                    "sent": "For example, a song but an artist.",
                    "label": 0
                },
                {
                    "sent": "OK, so the measure of similarity are going to be a little bit more dense and as a result the result are a little bit more significant there.",
                    "label": 0
                },
                {
                    "sent": "There's the differences are a little bit more strong, stronger, so it's easier to look at the results.",
                    "label": 0
                },
                {
                    "sent": "The other, even more important reason for focusing on last FM is that we have a stronger baseline because last FM actually makes recommendations about.",
                    "label": 0
                },
                {
                    "sent": "They call them neighbors.",
                    "label": 0
                },
                {
                    "sent": "OK, so they look at where you listen to, right?",
                    "label": 0
                },
                {
                    "sent": "If you look, listen to rock and roll, they say, oh look, you might want to be friend with Carlos here because he also listens to rock and roll.",
                    "label": 0
                },
                {
                    "sent": "OK, so they look at the listening patterns, maybe same artist, say John Wras and they say, well, those are your potential neighbors so we can use that as a better baseline than just random.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "Oh, let me just show you one of these similarity measures.",
                    "label": 0
                },
                {
                    "sent": "I told you we used many.",
                    "label": 0
                },
                {
                    "sent": "Let me just say a little bit about one.",
                    "label": 0
                },
                {
                    "sent": "As an example, we call it maximum information path.",
                    "label": 0
                },
                {
                    "sent": "It's actually an extension of something that was introduced several years ago.",
                    "label": 0
                },
                {
                    "sent": "We call it Lynn.",
                    "label": 0
                },
                {
                    "sent": "Similarity even introduced by Lynn, and in the case of a hierarchical network.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you have objects stored in the nodes of a tree, so basically in similarity looks at, compute the similarity by looking at the entropy or information of the lowest common ancestor node.",
                    "label": 0
                },
                {
                    "sent": "OK, it's intuitive, and in the case of tags we generalize that we don't have a tree.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, but we have tags so we could think of tags as if they were classes and so we could look at all the shared tags and we look at the most specific share tag.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The formula looks like this and the idea is that you look at.",
                    "label": 0
                },
                {
                    "sent": "Let's say that these two share a lot of tags and let's say that love is the most specific.",
                    "label": 0
                },
                {
                    "sent": "So you take the tag that minimizes or maximizes the information, or minimizes the log odds of finding such A tag.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then all the others I don't have time to go into because I'm already late, but you can find them in the paper.",
                    "label": 0
                },
                {
                    "sent": "They're all extensions of familiar things like like I said, the only one we didn't put in the papers mutual information because it's very, very expensive to compute and we've already shown before that actually maximum information path does as well as.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Information or better so remember that for each of the whole of these similarity we have four different versions.",
                    "label": 0
                },
                {
                    "sent": "'cause we have two different ways to do the aggregation.",
                    "label": 0
                },
                {
                    "sent": "And then once you decide OK, I'm going to do distribution aggregation.",
                    "label": 0
                },
                {
                    "sent": "You still have to decide am I going to aggregate across items or across tags.",
                    "label": 0
                },
                {
                    "sent": "So for example, let's say for distribution aggregation across items, that means that you're representing a user as a vector of tags.",
                    "label": 0
                },
                {
                    "sent": "OK, where the weights are?",
                    "label": 0
                },
                {
                    "sent": "You know how often those tags are used by the user.",
                    "label": 0
                },
                {
                    "sent": "Then you could apply cosine and that would be the straightforward way, and this is.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Miller for maximum information path.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we evaluate this?",
                    "label": 0
                },
                {
                    "sent": "Well, first we select a bunch of users and then.",
                    "label": 0
                },
                {
                    "sent": "Hey, you can do this in many ways right?",
                    "label": 0
                },
                {
                    "sent": "You could look at the ones that are most active.",
                    "label": 0
                },
                {
                    "sent": "They do most annotation so random or most connected.",
                    "label": 0
                },
                {
                    "sent": "Well, you're not going to be surprised when I tell you that most active is the one that works best, because that's where we have data, right?",
                    "label": 0
                },
                {
                    "sent": "That's where were you?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the annotations now, once you have the pairs you can rank them in the order of the similarity.",
                    "label": 0
                },
                {
                    "sent": "You measure OK, so the one that has the highest similarity is going to be my first prediction, and then I'm going to check is it true or not?",
                    "label": 0
                },
                {
                    "sent": "Is the social link there or not?",
                    "label": 0
                },
                {
                    "sent": "And so you can measure true positive false positive build.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your OC curve, some previous talk already went into that, so I don't need to waste my time and you can compare to measures, for example by looking at the area under the arosi curve is one way, so bigger means better because you have more true positives with fewer false.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, one caveat.",
                    "label": 0
                },
                {
                    "sent": "OK problem is that both the neighborhood function that we use as a baseline and our own similarities are very sparse, right?",
                    "label": 0
                },
                {
                    "sent": "Because we have to look at shared tags.",
                    "label": 0
                },
                {
                    "sent": "So we had a lot of noise and relatively little signal.",
                    "label": 0
                },
                {
                    "sent": "So to make this a little bit more amenable to amenable to analysis, we biased the way that we select these pairs and the way that we biased it is we biased in favor of neighbors.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if we're looking if we're looking at, let's say.",
                    "label": 0
                },
                {
                    "sent": "Active users, we select pairs of users who are active and who are neighbors.",
                    "label": 0
                },
                {
                    "sent": "Now, is it cheating?",
                    "label": 0
                },
                {
                    "sent": "Yes it is cheating, but not in favor of our approach in favor of the baseline.",
                    "label": 0
                },
                {
                    "sent": "Because if two people are friends for sure the neighborhood baseline is gonna know it.",
                    "label": 0
                },
                {
                    "sent": "So for sure they're going to get the answer correct.",
                    "label": 0
                },
                {
                    "sent": "The baseline is going to get the answer correct, whereas it might be that two people are actually friends and we correctly predict that, but they weren't listening to the same music, so it would look like we are wrong and the baseline is correct, even though it's the other way around.",
                    "label": 0
                },
                {
                    "sent": "So it is a bias.",
                    "label": 0
                },
                {
                    "sent": "We'd love to do without, and we're looking at ways to do without, but it is very fair.",
                    "label": 0
                },
                {
                    "sent": "It's very conservative.",
                    "label": 0
                },
                {
                    "sent": "If it favors an algorithm, it favors the baseline, not our algorithm all right now.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That said, let's look at the results.",
                    "label": 0
                },
                {
                    "sent": "Here are some arosi curves.",
                    "label": 0
                },
                {
                    "sent": "Here you can see what happens when you use different ways to sample the users.",
                    "label": 0
                },
                {
                    "sent": "Most active, most connected random, most active is the one where we get the best results.",
                    "label": 0
                },
                {
                    "sent": "That's not surprising, 'cause that's where we have the annotation data, right?",
                    "label": 0
                },
                {
                    "sent": "And then we can do and aggregations across items or across tags, and the best results are for active Now the curves there it's a little bit small, so let me read it to you.",
                    "label": 0
                },
                {
                    "sent": "The blue line is the baseline the neighborhood, and then the other two lines.",
                    "label": 0
                },
                {
                    "sent": "On top of that, our mutual information path.",
                    "label": 0
                },
                {
                    "sent": "Sorry, maximum information path for the two different.",
                    "label": 0
                },
                {
                    "sent": "Aggregation approach is distributed and collaborative aggregation, and you can see that they both do much better than the baseline.",
                    "label": 0
                },
                {
                    "sent": "It turns out that actually information path is among the best measures under all conditions, so that's nice and so now let's compare that.",
                    "label": 0
                },
                {
                    "sent": "Let's now focus.",
                    "label": 0
                },
                {
                    "sent": "Sorry on most active and aggregation across items and compare the results with all the other similar.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The measures, so we're now looking at the relative improvement in area under the RC curve compared to the neighborhood baseline.",
                    "label": 0
                },
                {
                    "sent": "OK, so any positive number means that we outperform the baseline, and as you can see, almost all the numbers are around 2030%, so the results are very positive.",
                    "label": 0
                },
                {
                    "sent": "Pretty much doesn't matter which measure you use.",
                    "label": 0
                },
                {
                    "sent": "If you look at similar content, you're going to do better at predicting friendship then if you look at listening patterns, an MIP turns out to be one of the best ones.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to summarize, two things right one is we looked at him awfully and we found that there is local alignment of tag usage for social for social neighbors and same for groups.",
                    "label": 0
                },
                {
                    "sent": "I didn't show it for lack of time.",
                    "label": 0
                },
                {
                    "sent": "So, but it is important to have the right null model, right?",
                    "label": 0
                },
                {
                    "sent": "Because we could have found this and be and be wrong because we would have found that even if there wasn't such local alignment because of the of the global correlation, so that the proper new model is important and the second point is that now we can use similarity based on annotations by active users to as good predictor of social links better than the listening patterns.",
                    "label": 1
                },
                {
                    "sent": "So this could be used for example to improve friend recommendations for example.",
                    "label": 0
                },
                {
                    "sent": "Facebook should tell Angelina to befriend me right?",
                    "label": 0
                },
                {
                    "sent": "That would be the right thing.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so since Carlos is waving his hand, I'm going to skip related work.",
                    "label": 0
                },
                {
                    "sent": "I hope I don't offend anyone.",
                    "label": 0
                },
                {
                    "sent": "For example, Alan has had looked at very similar questions in the past, and even today that builds on that.",
                    "label": 0
                },
                {
                    "sent": "So there's several things.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at, you can find them in the in the paper.",
                    "label": 0
                },
                {
                    "sent": "Let me just close with a note on the future.",
                    "label": 0
                },
                {
                    "sent": "We would like to do a longitudinal study to see whether you know is it the case that people are friends and therefore they start looking at similar things.",
                    "label": 0
                },
                {
                    "sent": "Or is it the case that people have similar interests and a result of that they become friends?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some work on evaluation.",
                    "label": 0
                },
                {
                    "sent": "You can read it in the paper.",
                    "label": 0
                },
                {
                    "sent": "I just want to conclude on one thing that I'm excited about.",
                    "label": 0
                },
                {
                    "sent": "We're trying to build some games.",
                    "label": 0
                },
                {
                    "sent": "As based on tag resource and user similarity to incentivize annotations and also to make social recommendations.",
                    "label": 0
                },
                {
                    "sent": "So, for example, people may play finding related tags and by doing that we get annotations and we get information about relationships between tags, for example, or objects.",
                    "label": 0
                },
                {
                    "sent": "But then we can also make recommendations.",
                    "label": 0
                },
                {
                    "sent": "Oh, this other person you might be interested in befriending this person on Facebook because they have similar interests, or you might be interested in this photos on Flickr because these users use the same.",
                    "label": 0
                },
                {
                    "sent": "Annotations for them and that kind of stuff.",
                    "label": 0
                },
                {
                    "sent": "So this kind of exciting.",
                    "label": 0
                },
                {
                    "sent": "We're playing with iPhone apps for that, and I'm out of.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm so thank you very much.",
                    "label": 0
                },
                {
                    "sent": "If there is a quick comment or question.",
                    "label": 0
                },
                {
                    "sent": "OK, I guess everybody is tired tired, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you again and thanks all the speaker.",
                    "label": 0
                },
                {
                    "sent": "Thanks guys.",
                    "label": 0
                }
            ]
        }
    }
}