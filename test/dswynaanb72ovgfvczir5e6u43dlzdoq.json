{
    "id": "dswynaanb72ovgfvczir5e6u43dlzdoq",
    "title": "Registration and Recognition for Robotics",
    "info": {
        "author": [
            "Kurt Konolige, Artificial Intelligence Center, SRI"
        ],
        "published": "Sept. 28, 2011",
        "recorded": "August 2011",
        "category": [
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/aaai2011_konolige_registration/",
    "segmentation": [
        [
            "So this is the title of my talk, but I thought I'd use this opportunity to go back a little bit and."
        ],
        [
            "See if this will work.",
            "Yeah, so actually.",
            "20 years ago I had another.",
            "My only other invited AAA I talk so it's a 20 year anniversary 1991 in Anaheim, CA and the talk was as Wolfram said, on logical AI.",
            "So I was doing belief and intentions for agents.",
            "Whoops, I didn't mean to do that, sorry, I'll get used to this in a second, and here's the kind of thing that I was actually talking about.",
            "I didn't there were no laptops back then.",
            "So I was using.",
            "Transparencies an I had transparencies full of things like this.",
            "It was a very interesting and engaging talk.",
            "So I will not recapitulate that talk.",
            "He ran.",
            "In fact I'm going to try to use very little text in this slide, so I have to talk."
        ],
        [
            "So I just thought I'd also take the opportunity to recap a little bit of what I had done.",
            "Like Wolfram, I kind of pivoted from logical AI, which was my thesis work in 1984.",
            "And then pivoted to robots around 1990.",
            "So I went back and I looked on Google Scholar at all the papers I had written, or at least a few of them that are cited still and divide it into five categories an by year published.",
            "And also by importance, namely the number of citations that the papers actually gotten.",
            "So from this whole decade, which is kind of a lost decade in some ways I was working on Nonmonotonic logic which is fine and I mean it's really coming into its own, but back then you know robots couldn't do very much.",
            "There is lot of low level work that still needed to be done on robots before you could do all the high level cognitive stuff.",
            "So right around the year in 1990 I started working with robotics and of course the very first thing that you would do with robots is try to.",
            "Do an architecture for making the robots do things.",
            "So I did a lot of architectural papers, but also realize that at the low level there was a lot of work to be done with robots in particular.",
            "Robots couldn't build Maps very easily, couldn't navigate very easily, so I worked very hard on slam simultaneous localization and mapping and also on some vision research because that's the primary sensor for robots.",
            "I think in the future also did some work on hardware 'cause I always like to like to build things.",
            "So it's kind of interesting.",
            "I guess my citations have gone down.",
            "Hopefully this will pick up as soon as the future comes, but almost no non monotonic work in the last decade and more concentration on the on the slam work envision."
        ],
        [
            "But I also had an entrepreneurial streak, so I like to build things an if I can to sell them.",
            "So I'm just going to review a little bit of that history.",
            "This is the flick flaky the robot.",
            "I didn't build this but it was built at Sri and I got to use it.",
            "We went to the first triple AI contest in 1992 in San Jose.",
            "That's actually a sun laptop on top of the flaky robot.",
            "One of the first laptops wait about 10 pounds.",
            "We did a demo with this guy how and although for Scientific American frontiers you can still probably find that on YouTube somewhere.",
            "And I realized that there weren't any robots that people could buy off the shelf.",
            "So I developed the Pioneer robot for my class at Stanford and then cofounded.",
            "Active media move, which turned into multiple mobile robots and Anne got acquired by Adept recently.",
            "I also built the erratic robot, which people tend to do crazy things with.",
            "You shouldn't do this to a robot.",
            "OK, put all sorts of things on it like that.",
            "It's going to fall over and unbalance.",
            "So that was that was a nice thing because it got the robots out there.",
            "I also did a lot of vision work.",
            "An out of that I started a little company called Very design that made stereo cameras an it's little known, but these stereo cameras are actually used by Google in there.",
            "Books project to figure out the curvature of pages on books as they as they read them.",
            "When I joined Willow Garage a few years back, I designed the stereo system for the head on the robots and because you couldn't see a blank areas like textureless tables and so forth.",
            "I designed a projector to project or paint a texture so the stereo could actually see it.",
            "Looks a little bit like the connect, so I almost made the connect at that point, but I knew that the Connect was coming along.",
            "I had seen some previews for it and this is way more expensive than the Connect, so unfortunately I just missed that boat.",
            "It would have been a nice one to actually find.",
            "We also done Slam work and there's now a commercial system called Cardo which also has an open source component so you can use Cardo that came out of my work at Sri and is being sold by Sri.",
            "And then my only consumer product is actually a combination of these two things of slamming the vision work and that's the Neato robot which will clean your house and keep track of where it is at the same time which is kind of neat.",
            "So I worked on the slam system for it and also this little sensor here for about $20 worth of parts.",
            "You get a nice laser distance sensor.",
            "Unfortunately, they won't sell that as a standalone for robotics, so I keep getting requests for that, but there's nothing I can do need to wants to sell vacuums and not help robotics all that much.",
            "OK, well that was kind of a history of the of the things I did.",
            "The takeaway message here is the research market isn't all that big, so if you really want to do something right for gamers, right?",
            "So the connect is used by gamers, so million of those.",
            "So anything you do in robotics make sure that gamers can use and I think you'll be OK."
        ],
        [
            "OK, so now the real talk registration for robotics.",
            "So what is registration itself?",
            "Well, in kind of the simplest form, it's the ability to take 2 views of the world with your sensors and combine them in a way that makes sense.",
            "So combine the coherently.",
            "An example of this, for instance, is if I'm looking at this table, I have one view of the table and then I turn and I get a different view of the table that overlaps.",
            "I want to be able to combine them so I can get a Fuller view of that table.",
            "Think about a robot actually doing that.",
            "Another example is here.",
            "I'm here.",
            "I am holding a key.",
            "I want to open a door, so I see the key in my hand.",
            "I see the keyhole.",
            "In the door and I want to be able to combine that information so I can actually stick that key in the keyhole and open open the door.",
            "Another example, there's an object on a table.",
            "I see that object.",
            "I want to be able to reach my hand out to the object and actually grab that object.",
            "These are all instances of registration of sensors to actuators or sensors to sensors, and it's pervades almost everything you do in robotics, so having algorithms that actually work well work fast in real time is a real important thing to have for robotics.",
            "And since vision is one of the most important senses for robots, I'll talk mostly about visual registration here, vision, not only from monocular sensors, but also from the recent depth sensors that have come out, namely the Connect or the Primesense sensor.",
            "OK, so there are."
        ],
        [
            "Major technical themes.",
            "I'd like to look at.",
            "One of them is how, given 2 images of the world, how do you actually go about matching those images, right?",
            "So I'll talk about ways of finding points and images and being able to recognize when those points occur in another image and then get a coherent set of matches between those images that can be used for registration.",
            "And I'll talk about some new methods to do that that are very quick and efficient."
        ],
        [
            "The second major theme is optimization, so here's an example of a 2D Carter set from MIT.",
            "A couple 100 yards long, and we have a lot of matches between the laser scans in these two sets.",
            "These are constraints.",
            "The red ones are ones that aren't satisfied very well, and now the idea is how can you take this set of constraints and get the optimal configuration for those laser scans, right?",
            "Do something like this and do it fairly efficiently so those are the two major technical themes.",
            "That will actually be talking about, but there are a couple other themes that I'll point out.",
            "Also, one is especially for robotics.",
            "You want to be able to do this in real time, right?",
            "So it's important not just to be able to do this, but to do it efficiently.",
            "You don't want to wait 10 minutes for something like this to happen, and the other thing the other theme is that's really important.",
            "Is open source the ability to take something like this and write your programs and distribute it to other people?",
            "Because it's been a real blocker.",
            "Every time I go to try to implement something.",
            "You know, I read a paper and I just I can't get the code if I can't get the code for that paper I have to re implement it and I'll point out some examples of where that's a curd and where it's blocked.",
            "A little bit progress in robotics.",
            "OK, so let's let's turn to the first theme which is matching features.",
            "You would think that this is a solved problem.",
            "People in vision have been working on it for over 30 years, but there's still a lot of a lot of stuff."
        ],
        [
            "But still, that can be done.",
            "So let's let's look in an example of this.",
            "Here are two images of the same thing, different scales, rotations, etc.",
            "Here's an interesting point.",
            "In one image, I think you can probably find that in the other image there it is, and what we'd like to be able to do is match those match those things.",
            "So how do we match key points like that?"
        ],
        [
            "Let's take a closer look at that.",
            "Alright, so I'll take two other images.",
            "These are again images of the same thing.",
            "Obviously the one on the right is a little bit blurred, different scale, different rotation.",
            "Take a key point there and look at it in a little more detail.",
            "That's what a little 32 by 32 or like a 16 by 16 block.",
            "Sorry around there that looks like here's another one right of exactly the same point in this new image.",
            "Now if you're just going to compare these two things in terms of their intensities, you're not going to do very well, right?",
            "They don't look anything like each other, so the whole idea behind matching is to get some notion of features where the feature for the left hand block and the feature for the right hand block actually Arkham Parable.",
            "And give you an idea that these are actually the same points, right?",
            "So how do we?"
        ],
        [
            "Go about doing that.",
            "Well, there's a well known method called sift Scale invariant feature transform that comes from David Lowe around the year 2000.",
            "His basic idea was to take the image Patch divided up into a series of cells and for each cells calculate a set of gradients.",
            "That is where the images change from dark to light.",
            "The little Red Arrows up there and then for those gradients in each cell you get a histogram.",
            "You divide those gradients into some course buckets, usually 8 buckets Purcell.",
            "And so you get a vector that consists of eight bins for each cell, 4 bytes to represent each bin, 16 cells, a vector of 256 bytes, and this vector you can use to compare against other features.",
            "And it does a pretty good job, except of course if you change scales or if you have image rotation right, so then it becomes a lot harder to actually compare these things.",
            "So let's if does is it says, well, I'll find the optimal scale and I'll find a rotation for each Patch an.",
            "I'll put those things in as part of the.",
            "Of the Patch information and that turned out to work pretty well.",
            "But there's still a problem.",
            "I mean, this isn't a very efficient way to go about it, and I'll talk about some timing statistics in just a minute.",
            "So more recently, in 2010 Michael Calendar came out with a much simpler feature called the Brief feature, and the idea is is dead simple here, you take.",
            "2 random points in your future Patch and you compare them.",
            "Is 1 brighter than the other?",
            "And if it is, you give a one.",
            "If it's not, you give a zero and you just keep doing this for loops for random points right?",
            "And you get a feature vector and it turns out 256 bits is a perfectly fine feature vector for comparison, 32 bytes, so almost a factor of almost an order of magnitude less size than the SIP feature.",
            "And it turns out that this also works surprisingly well and I'll show you how well it works in just a second.",
            "But you have the same problem with scale and image rotation.",
            "So more recently, folks at Willow Garage came up with the Orb feature, which takes scale.",
            "Also scale an rotation into account and gives a scale and rotation to to these features so they can be compared."
        ],
        [
            "Alright, here's an example of doing that kind of using orbon onto images, so the red points.",
            "The red circles are all of the distinctive key points that are found, and the green matches are the correct matches that have been found.",
            "So you take a key point in one image and you compare it to all the other key points in the other image and find the highest response using your feature.",
            "So you get a match for each keypoint and the ones that are actually correct or given by those green lines.",
            "And the way you find which ones are correct, I'll talk about a little later in the talk by using geometry.",
            "Here's another example from that picture I showed earlier.",
            "You can see that it does a pretty good job even through fairly large changes in scale.",
            "OK, how well?"
        ],
        [
            "Does it work compared to sift?",
            "Alright, so you'll have to read this graph a little bit.",
            "Sift is the red line so and this is an angle of rotation, so you take one image and you rotate the other image with respect to it.",
            "Just a standard test that you can do and sift does pretty well about 60% correct matches across images surf which is a speeded up version of Sift, does slightly worse, although it's faster.",
            "It turns out the brief feature the rotated brief feature, or actually does better than Sift.",
            "Even though it's a smaller feature, an much simpler feature to compute, so hopefully Orb will become the future of choice in the future."
        ],
        [
            "Just in terms of timing, so SIFT was in 1999.",
            "If you're going to extract on a current computer 2000 features, it will take you about 5 seconds to do that.",
            "Of course there are GPU versions of this that take a lot less, but I'm trying to compare just based on standard processors.",
            "Surf is a lot better over an order of magnitude that was 2006.",
            "Orb takes 19 milliseconds, right so?",
            "In the course of some 10 years or 12 years, we've got two orders of magnitude speedup and a better descriptor for matching, so we can even do things like implement this on a smartphone.",
            "An Ethan Rublee did this.",
            "You can now track things in the world on your on your smartphone as you go through.",
            "So the smartphone processors, of course, have gotten better, but you couldn't do this.",
            "There's no way you can do this with Sift or even surf.",
            "So the real time theme here is important.",
            "OK. Alright, so we've looked at matching visual features.",
            "And I've talked about finding a good set of matches because you're going to get some false positives in those matches.",
            "So how do you go about finding a coherent set of matches when you're matching 2 images?",
            "Well, that's a question of using geometry an.",
            "I'll look at a series of.",
            "Of geometric matches from very simple ones to more complicated ones.",
            "And here's where the geometry of registration comes into play.",
            "An for robotics, there are a lot of different kinds of geometry that we have to look at, and I'll try to give you an idea of the scale of the of the kinds of geometry that actually exists and then point out how they can all be put into one framework for doing general geometric work with these kinds of."
        ],
        [
            "Alright, here's the here's the first fairly simple geometric idea.",
            "You have two points of view.",
            "You're looking with the same camera, and you're just rotating that camera and two degrees of freedom, right?",
            "So you're getting different views of the world, and you have to put those views together, right?",
            "So again, you can do matches.",
            "You can find a set of matches for that and.",
            "Putting those matches together, you can say what the rotation of the cameras are with respect to each other.",
            "You can merge the images and you can form a Panorama right?",
            "So this is a fairly simple operation, 2 degrees of freedom and it's actually done in standard consumer cameras at this point, right?",
            "So you can buy cameras where you can do this kind of thing and it will actually work.",
            "This is the first simple kind of geometry, right?",
            "How do we represent that in a mathematical way?",
            "Well, given that this is AAA I of course we go to Bayesian representations.",
            "That's the obvious."
        ],
        [
            "The obvious way to do it, and I'll do it in a way that is getting more and more credence these days, which is factor graph.",
            "So instead of a base graph here I've drawn a factor graph.",
            "Where the view points P1 and P2 or the variables and the constraints, the different constraints that we get from matching points between those two viewpoints between the images are given by these functions that relate these two viewpoints and the basic idea is that when the two viewpoints are in alignment for a particular match right, the probability of that match is actually very high.",
            "OK, and what factor graphs do is they represent constraints.",
            "They represent a complex function which will eventually talk about as the probability function as a set of smaller factors that we've parceled out between these between these two variables, right?",
            "So you take a fairly complex function between these two variables and you factor it into a set of smaller functions, right?",
            "And I'll talk about the probability probabilistic effects of the factor graph once I get through all of the geometry and we'll see how to.",
            "Actually solve these kinds of graphs sufficiently, but take note of this graph and how simple it is.",
            "Just two variables and a bunch of constraints between those."
        ],
        [
            "Tables.",
            "OK, the next step up is to look at 3D points.",
            "So here you have two viewpoints, there's your.",
            "Connect sensor and you've taken 2 viewpoints of a scene and you have 3D point clouds with those with those viewpoints and you're trying to figure out how the viewpoints correspond so that you can merge those two sets of viewpoints right and?",
            "Now we don't have any distinctive points that were actually matching, so we're taking the 3D points 'cause the 3D points aren't quite as distinctive, and we're finding the nearest neighbor, and we're putting a constraint in between the nearest neighbor.",
            "So if you look at that, you can see that it found good nearest neighbors on the bottom on the floor.",
            "Not so good nearest neighbors between the top of the chair and the back of the wall, right?",
            "So we have some bad matches there, but.",
            "Using an optimization step, we can let me start that again.",
            "I'm not sure I we solve that using an optimization step.",
            "We can correspond those two and find a pretty good viewpoint and then get another set of matches.",
            "So we redo our matches at that point and now you can see that the back of the chair is fine.",
            "We get good matches, and then we iterate that procedure and we get a better match and we actually find the correct viewpoint where those two point clouds are merged very well, alright?",
            "And this is called the iterative closest point on the factor graph.",
            "For this, what do you think the factor graph for this actually looks like, right?"
        ],
        [
            "It looks exactly the same as the factor graph we had when we match visual key points in the planar homography case, right?",
            "So again, we just have two viewpoints, the the 3D points in the world are rigidly attached to those viewpoints, so each of those constraints is just a constraint between that viewpoint.",
            "And again, we're searching for the best configuration between those variables that satisfies all the constraints.",
            "OK, so so far we've just talked about registering viewpoints to each other, but, uh, more complicate."
        ],
        [
            "Added problem exists when you have two viewpoints and even though you have information about the distance of the points from each of those viewpoints, the 3D World points.",
            "That information can have errors in it, so you're trying to get a better idea of where 3D points in the world actually are.",
            "So the idea here is that you're adjusting not only your viewpoints with respect to each other, but you're trying to adjust where the points in the world are at the same time, so you have a much larger problem.",
            "Your number of variables increases because you're trying to optimize not only where viewpoints are, but where points in the world are.",
            "So if we start out by picking a set of points in the world, these red circles, right?",
            "We take two images and now we apply our matching algorithm.",
            "So here's a red image and a green image and you can see there are a set of matches between these points, not a very coherent set, right?",
            "Because there are some false matches there, so we applied geometric rules and we can eliminate most of those matches and just get a coherent set.",
            "Here's the two.",
            "Point clouds that we start out with and then by applying optimization based on the constraints that we find we can optimize not only where these two positions of the viewpoints are, but we can also optimize where these points in the world are out there right now.",
            "Unfortunately, those points are sparse, that is, we've done a pretty good job through triangulation between these two viewpoints of figuring out where these points in the world are.",
            "But there are other points that we haven't done as good a job of right 'cause.",
            "These are just points that are attached to the viewpoints, but we have no.",
            "Triangulation information to actually make a better idea or better estimate of where these points are in the world, and I'll return to this in just a second, but I just wanted to point out this this issue here, so we now have a sparse bundle adjustment where we're.",
            "We're optimizing the position of viewpoints and some points in the world, but a few points in the world.",
            "OK, what does the factor graph look like for this?",
            "Alright, so now."
        ],
        [
            "We've actually.",
            "Increase the number of variables instead of just having viewpoint variables.",
            "We also have point variables in the world and now the constraints are projection constraints between the points in the world and the actual viewpoint itself, and we try to optimize that those projections so that they correspond to our actual measurement and the probability function is now a bit more complicated.",
            "It's over all these variables, but again, it factors very nicely into these small probability functions and will be able to solve this efficiently.",
            "OK um.",
            "One of the advantages of looking at this as a factor graph is that we can add another constraints if we need to.",
            "So remember that the sparse registration that we did didn't work very well for all the points that we had in each of those dense viewpoints.",
            "So what we can do is we can take the AICP constraints that we just talked about an add them back into the factor graph, just throw it all into the same factor graph."
        ],
        [
            "Optimize it.",
            "So here again, is the original seen.",
            "The two viewpoints not very well optimized here.",
            "If we throw in the AICP constraints, we do a lot better.",
            "Still not perfect, but but not bad, right?",
            "So now instead of, I think there are about 17 points that we optimized.",
            "Here we have another thousand points that we threw in for AICP constraints and we get much better registration between these two points all throughout those dense point clouds."
        ],
        [
            "So by now you should be able to say what the factor graph looks like for this.",
            "OK, so we have both the projection constraints and we have GCP constraints.",
            "We have a more complicated factorization, but again we should be able to solve this fairly efficiently.",
            "Alright.",
            "Now, so far we've looked at 2 frames at a time, but there's no reason that we can add in more frames, right?",
            "So this is just a factor graph.",
            "We could just increase the factor graph.",
            "We could we could throw in more frames and we could optimize the whole thing."
        ],
        [
            "Once.",
            "So this is what we did with the short sequence from our PR2 robot.",
            "Here you can see that there are many frames.",
            "I think there are about 50 frames in this sequence an we're optimizing them all together so that we get a fairly good reconstruction here, with both AICP constraints and bundle adjusted visual constraints.",
            "You can see that there's a pretty this if you just look at this wall here.",
            "We get a very good reconstruction of this wall, even though it's seen by many different frames because we're optimizing all the constraints together.",
            "Right now.",
            "Even if all right, you have a very efficient optimization procedure if you keep doing this and you expand this to larger and larger environments eventually you're going to run into computational troubles, right?"
        ],
        [
            "And if you take an extreme, if you look at something like the photo tourism application that you can run at the Microsoft website, you can take thousands of camera poses, upload them to this website, wait about half a day.",
            "And then get back something if you're lucky.",
            "Alright, 'cause sometimes it doesn't work, looks like a very nice 3D reconstruction that again bundle adjusts where all of the cameras are and where the 3D points in the world are right.",
            "But as I said, it takes a long time an as you keep expanding your world, it's going to take longer and longer, so you need some way, especially in robotics to recover from this kind of optimization.",
            "And one way to to do that is, I think, a fairly natural way.",
            "If I'm in this room, right?",
            "And I'm looking around and, you know, I'm reconstructing the environment here.",
            "This 3D environment I'm not.",
            "I'm not remembering precisely what the 3D environment is out in the Hall or in the streets of San Francisco or back at my home in Menlo Park, or anything like this.",
            "I'm just concentrating on kind of a reconstruction bubble right here, and I have a vague idea of how it relates to geometrically to things outside the area."
        ],
        [
            "So one way to recover constant time and actually real time for these kinds of reconstructions is to just have this bubble in which you do precise reconstruction.",
            "So that's that's one window, and then have a window where you do a much coarser reconstruction around you.",
            "So this was some work done by how Kestros .1 of Andy Davidson students when he was an intern at Willow Garage.",
            "And here you can see a large scale reconstruction.",
            "This is speeded up a little, of course.",
            "Done it with an Oxford data set so around a court in Oxford.",
            "This is about 100 meters or so in diameter and you can see the bubble of points and constraints between poses between viewpoints right here, even when you close the loop, it incorporates information that it had previously, but it does that by keeping this small bubble around right so that anytime your local environment is, well reconstructed and you don't care as much about the larger environment around you.",
            "Alright, so that works pretty well, and in fact, if you have a small environment you can use this to do things like reconstruct objects, right?",
            "So here's an object modeling application where we're basically finding the poses around the object and then putting all of that together with the object OK.",
            "So.",
            "Now you can ask I guess, or I would be led to ask at this point.",
            "Is this the most complicated factor graph you can get?",
            "Alright, so is there anything else we could add to the factor graph to put in more constraints, do a better job etc etc Ann?",
            "The answer is yes.",
            "If you look at the examples I gave with the dense point clouds, remember we have nice sparse places where we have identified points and by triangulate Ng from the viewpoints we can actually pick out very precisely where they are in 3D, but the rest of the points, even though we're using AICP to get them close to each other right?",
            "There's still a lot of fuzz in how they look, so they're not.",
            "The sensors themselves are not very precise, and so instead of getting a nice smooth surface, you get a very bumpy surface.",
            "One way to deal with that is to use regularization methods.",
            "So the idea is that most surface is in the world are smooth.",
            "And you can apply a smoothness constraint to actually take out some."
        ],
        [
            "That bumpiness and this is very nice work from Michael Monkeys and Wolfram Burgard, Slab and Freiburg.",
            "Goes by a little quick, so I'll try to halt it at some point.",
            "Let me go back to that.",
            "OK hello, come on guy whoops.",
            "OK, alright, so here's the initial set of point clouds that you get from actually.",
            "Moving your camera around the object and also on top of the object so you can see inside and you can see that the surface is aren't actually all that good.",
            "There's a lot of error in that connect data in the depth, but if you apply a smoothness constraint that says these points next to each other should be on the same plane or surface or approximately planar surface and then you optimize that you can actually do pretty well in terms of getting a much better object model out of this right?",
            "So the results here are absolutely spectacular.",
            "You get these very nice smooth surface is from what were very bumpy surface is originally.",
            "Alright.",
            "So now you can ask what is the factor graph for this look?"
        ],
        [
            "An it looks somewhat the same as our previous factor graphs, except now you have constraints between the points out in the world, right?",
            "So and those constraints are regularization constraints that say points that are near each other in the world should probably lie on the same surface, the same smooth surface, right?",
            "And you have now a slightly more complicated probability function factor probability function.",
            "It turns out because of these constraints, there are a lot of them.",
            "Computationally, it's a lot harder to solve.",
            "And I hope to be able to point that out a little bit.",
            "OK um.",
            "So so far we've been talking about reconstruction, which is certainly one of the most important parts of registration.",
            "But there are other uses for registration behind besides this, so one of them is calibration an if any of you have worked with robots and sensors, you've done calibration and you know what?"
        ],
        [
            "Main calibration is right, so here's an example of bad calibration.",
            "Let's see if this will.",
            "If this will run.",
            "Come on.",
            "Oh, there it goes.",
            "OK so this is.",
            "I mean we're trying as best we can and eventually it'll put the plug into the socket.",
            "But here we have.",
            "We're looking at things with the camera and with the with the stereo sensor, we're finding the.",
            "The socket in the real world we know where the plug is in the arm, but our calibration of the arm parameters just isn't good enough to enable us to get the millimeter precision we need to stick that plug into the socket, right?",
            "So we have to try a few times to actually do that.",
            "Here's what it should look like.",
            "If it's well calibrated, this is so smooth I love this.",
            "Right?",
            "Hard to argue with that, right?",
            "OK, so that's a well calibrated robot like the well tempered claviere, right?",
            "Well calibrated robot should be able to do something like this.",
            "So how do we calibrate a robot?",
            "It turns out there was a large literature on calibration for robots, mostly dealing with industrial robots.",
            "Very little of it dealing with general sensors.",
            "Looking at general manipulators."
        ],
        [
            "So Vijay Pradeep at Willow Garage developed a bundle adjustment approach to sensor calibration sensor and actuator calibration.",
            "So here's a schematic diagram of the PR2 robot.",
            "You can go out and see one in the Hall.",
            "Later on it's got lots of sensors, about 7 different vision sensors plus laser tilting laser sensor.",
            "It's got lots of degrees of freedom in its arms right?",
            "And the idea is we want to calibrate together all of the sensors and all of the actuators so that the whole robot is actually calibrated and there was no.",
            "Procedure in the literature that would actually let us do this much less code for doing this, right?",
            "So you can read papers if there's no code, you still have to reimplement all that stuff."
        ],
        [
            "So our approach was basically.",
            "You use the same kind of factor graphs right to do this kind of calibration and the basic idea is that you find loops between targets in the real world and the sensors that you have.",
            "So here's the tilting laser sensor.",
            "The camera you look at a target in the real world, and this gives you a constraint among all of these things.",
            "Here's another constraint between the arm and the forearm camera in the arm.",
            "Here's a constraint between all of the arms, the forearm camera, and the right arm, and the target in the left arm.",
            "You collect a whole bunch of these.",
            "You throw them into a factor graph, you bundle, adjust it, and you get a calibration for your."
        ],
        [
            "How well does it work well?",
            "This is an example of the kind of output that you get.",
            "This is looking at errors from the point of view of the two stereo cameras.",
            "There's a wide angle stereo camera in their narrow angle stereo camera.",
            "One is blue, one is red.",
            "I forget which is which, but an uncalibrated robot, fresh out of the box has errors on the order of 1020 fifty pixels.",
            "In terms of where it thinks it sees the arm and where the arm actually is.",
            "When you calibrate the robot, those things not only have no bias, so there was a strong bias here, but the pixel errors are now much lower, so on the order of.",
            "A few pixels when you actually do that.",
            "OK, this is great, but it's still a pain to calibrate the robot an calibrations go away overtime right?",
            "Things get bumped, So what you'd really like to do is online calibration.",
            "An believe it or not, you can use factor graphs to do online caliber."
        ],
        [
            "So this is some work by Javier Romero, from KTH was an intern just this this spring at Willow Garage, and the basic idea is that you're matching a model of the arm, right?",
            "Two lines that you extract from the visual image, and you're trying to calibrate based on those lines and where you think the arm is.",
            "So here is two different viewpoints of that.",
            "You can see this.",
            "The arm moves around, so there's a constraint between the line that you extract in the image and where you expect that line to be based on a silhouette of the arm that you can compute using open GL type graphics.",
            "The one on the left.",
            "We're not using any depth information to try to constrain where the line is.",
            "The one on the right were actually using depth information, so this is new research, and it promises to let us do online calibration so that we can continuously calibrate where the arm is with respect to sensors.",
            "I think this is going to be extremely important in the future.",
            "This is this is going to be the way the robots will actually calibrate, so you won't have to take it out of the box and do a full calibration or anything like that.",
            "You'll just start right up and the robot will calibrate itself.",
            "Kind of like the way humans do, right?",
            "We're continuously calibrating where our arms are, and so forth, OK?",
            "So we've seen at least some uses of registration.",
            "There are some I can't even talk about here, 'cause I don't have enough time.",
            "For instance, object recognition and pose estimation for picking up objects, but I want to get to the other part of the technical talk here, which is how we do efficient optimization.",
            "So this is great factor graphs, bundle adjustment, efficient optimization of factor graphs.",
            "How do we actually do that?",
            "Especially when we have large number of variables?"
        ],
        [
            "Alright.",
            "So let's go back and look at a simple factor graph here with just the two variables in a set of constraints here and now, I have explicitly represented the probability as a factored set of probabilities, right?",
            "So there is a probability factor between these two between these two in between these two an the total probability is just.",
            "The product of all of those, all of those probabilities.",
            "Now the kind of inference that we want to do is we want to find the maximum likelihood right?",
            "So what's the position of P1 and P2 that leads to the largest probability here given our observations?",
            "So that's a maximum likelihood problem, and I'll phrase it this way.",
            "Find the minimum over all possible positions of our variables of the negative log of the probability right?",
            "So I've just changed it to a negative sign and I put a log in front of the probability WHI along in front of probability.",
            "Well that's the standard trick to convert from products to sums and sums are a heck of a lot easier to deal with, right?",
            "So now by substituting in the factors we have simply the argument of the sum of all of those which we consider as costs.",
            "And now a key step if you consider each of those probabilities each of the H is to be Gaussian.",
            "Alright, then you can reduce it even further to a standard least squares problem.",
            "That is, if each of the of the H is Gaussian, then the log of that Gaussian or the negative log of that Gaussian reduces to a quadratic function, where ZI right is the expected sensor.",
            "Reading that you get out given the positions of P1 and P2.",
            "That's what you expect to get out, so you have a way of calculating that and see I cap is the actual reading that you get, so this is an error.",
            "Right, it says if I met these two positions right, I expect to see you know my sensor reading for where this point is should be right here on my image.",
            "Oh, but my actual reading is over here and I get some error between it and now.",
            "I have a quadratic error form and this is just really a nonlinear least squares problem.",
            "It's nonlinear because this function is nonlinear, so we're going to have to iterate the linear problem to solve that.",
            "So let me go into just a little detail."
        ],
        [
            "But how you solve these kinds of problems?",
            "The generic way for is called sparse bundle adjustment.",
            "Just go over this briefly.",
            "Here's our error function or error equation.",
            "Again, where this is the expected value, so we have to be able to compute this, and this is the actual value that we see.",
            "We calculate jacobian's of the error function.",
            "So basically the change in the error when we change our when we change our variables evaluated at our initial value for those variables, and given those jacobian's we can form what's called the normal equation where we can update the variable.",
            "So if we solve this normal equation, we can update the variables X based on the errors that we actually see.",
            "Alright, so we've done a linear isation using the jacobian's.",
            "We now have a normal equation that we can solve and if you look at the form of that normal equation this particular factor JT J also an approximation of what's called the Hessian.",
            "If you look at that, it's sparse.",
            "That matrix is sparse if there's a constraint between two variables I&J right?",
            "Then there are factors in the in that matrix corresponding to those, but in for any set of variables.",
            "You know they're not going to be densely connected, so you get a very sparse, usually a very sparse matrix of this form, and we can take advantage of recent results.",
            "Fairly recent results in linear Algebra 2 to efficiently solve equations like this.",
            "And once we solve it, we can go back re linearize using the jacobian's, iterate again, and so forth till we get convergence.",
            "So just to give you an example of some of the timings, right?",
            "So this has been a real breakthrough in recent years, so there was a.",
            "There still is actually a an open source version of bundle adjustment, sparse bundle adjustment from Larocca Cenar jeros that has been used widely right so it was used in the Photosynth project that Microsoft did, and for a fairly large problem.",
            "Let's say one with about 2 million variables and 3 million constraints.",
            "It takes on the order of 16 minutes or so to actually solve that problem, right?",
            "That was as of 2004.",
            "Using more recent techniques in linear algebra, I was able to pull that down to just over 100 seconds so a couple minutes almost a factor of 10.",
            "And then even more recent results, unfortunately not mine.",
            "Brought that down by another factor of 10.",
            "It's using some very nice algorithmic tricks to make the convergence go faster, so over the course of six years or so, and by the way, I expect this to decrease another factor of 10, at least by the end of the year, because this is all done with single processors, but people are now starting to consider the case where you have multiple processors, or you were implementing this on the GPU, so I expect this to be done maybe in a second or so, at least by the end of the year, right?",
            "This is all very nice to give you an example of the kind of system we're talking about."
        ],
        [
            "This is the actual example that was used there, so this is some palazzo in Venice and these are all of the different cameras that were there and all of the points that were involved.",
            "So there were some 850 camera poses and 2/3 of a million points that are optimized simultaneously by these systems.",
            "Here's a little close up of that.",
            "You can see the fairly fine detail like these steps on the plot, so so very nice results there.",
            "OK.",
            "In fact, these things are so efficient that they make certain problems solved, so we used to worry about two DSLAM.",
            "So here's a here's an example from way back when when I first started doing loop closure with Stephen Goutman.",
            "Right, so I I don't know how we save this video, but somehow it was there.",
            "This is around the year 2000, so you're 2 robots.",
            "One makes a little map and the other is staying localized.",
            "Initan will now close the loop and the thing I want you to notice is when it does that loop closure.",
            "So this is real time, right?",
            "And?",
            "Of course computers were a little slower back then.",
            "And you can see that it takes a second or two to actually close that loop and top when it closes the loop.",
            "It just optimizes the whole thing and it's some 10s of matches, 10s of poses that are actually there.",
            "OK, fast."
        ],
        [
            "Forward to current times.",
            "This is an MIT data set with about 6000 poses every 10 poses.",
            "We do a complete optimization of the graph.",
            "This is running way faster than real time.",
            "Not only that, it's slower because of the graphics.",
            "It would be a lot faster than this.",
            "This is one of my favourites.",
            "If we just start at zero we can run the optimizer and actually reconstruct the whole graph from that.",
            "So these methods basically have solved at least two DSLAM with no problem.",
            "Alright, So what used to take us hundreds of seconds to do on these large graphs Now takes us less than.",
            "Less than a second.",
            "OK, so this is great news but.",
            "You ask, can I use this in my own research?",
            "Is it available?"
        ],
        [
            "Right, and I'm happy to report that yes, it is so one of the things that we're really committed to it will garage is getting open source stuff out there.",
            "And along with the folks at Freiburg, have actually spearheaded this effort.",
            "There's a general framework so G2O stands for general graph optimization.",
            "There's a general framework where you can solve these kinds of factor graphs very efficiently.",
            "That's out, there is open source.",
            "It's a.",
            "It's available as a package, and you can solve many different kinds of problems, including all of the ones that I actually showed you, right?",
            "So you can solve 2D problems, you can solve 3D problems you can solve.",
            "Bundle adjustment problems and vision right?",
            "This is all open available.",
            "Unfortunately.",
            "The Jiang results for are from Microsoft and are not available.",
            "In fact, I couldn't even get the data sets from them from Microsoft.",
            "Not to worry, we were re implementing those techniques and they also will be available in G2.",
            "Oh, so all of those.",
            "Speed UPS will be available.",
            "Whoops, I only have 5 minutes so I better hurry through some of this.",
            "I just want to point out some of the structure here.",
            "The only thing that users actually have to supply to make this stuff work is an error function and an update function and then G2O does all the rest and you can choose some nice things like which one your solver to use for your particular optimization and so forth.",
            "OK. Actually, I'm almost finished up, so that's pretty good.",
            "I realize I was I was coming to the end alright, so let me just summarize some of this.",
            "I've talked about registration and some of the techniques including matching points between images, which turns out to be a fundamental technique and something that we speed it up now so that you can do it in real time.",
            "I think one of the key techniques is the optimization.",
            "The fact that we have fast optimization means that we can do a lot of real time registration that we just couldn't do before and we were able to do things like calibrate your robot, keep track of the 3D environment.",
            "Build an app.",
            "Now navigate around the world.",
            "Make models of objects.",
            "Find those objects.",
            "Although I didn't really talk about that research and pick."
        ],
        [
            "Come up also so I'll end with this.",
            "Somewhat speeded up video of the.",
            "PR2 robot fetching beeran.",
            "In fact there is a.",
            "There's an actual demonstration of the PR 2 from several different labs out there in the foyer, so you can check for yourself about about the robot.",
            "Yeah, I know it's it's quite funny in a way, so let me make a few remarks since I still have a few minutes here and just kind of proselytise, especially for open source, I think open source is a wonderful way to push the field along.",
            "So I've been frustrated many times, especially in doing visual slam work because, you know, people do amazing work, amazing engineering, but it's not available and you have to recreate everything yourself, which holds things back tremendously.",
            "So currently.",
            "I don't know if you've seen the skeleton tracking for the connect.",
            "It's great work by Jamie Shotton from from Microsoft.",
            "There's a CPR paper.",
            "The code is not available so we have an intern working on reimplementing that code.",
            "Unfortunately, it's also patented, so even if you reimplement the code, it's not clear you can do all that much with it, but that's just a waste.",
            "I mean, why?",
            "Why do we have to spend that kind of intellectual effort to do something like that?",
            "It's just it just holds you back tremendously.",
            "So you know the push for open source I think is a really good one.",
            "I think we should continue continue to do that.",
            "The other thing I'd like to point out is a lot of the sensing problems.",
            "There's been tremendous work now, especially with optimization, so that we can solve a lot of these problems.",
            "There's a lot of engineering work left to do.",
            "Not quite as much scientific work.",
            "I think in this field.",
            "In fact, slam I would be happy to exit the slam area since I've been working on it for the last decade and a half.",
            "Or something like that, but I think the next big area is going to be in manipulation and sensing right?",
            "So how do you actually get the robot?",
            "So our current manipulation is very crude.",
            "It takes a long time to find to get a plan to actually grasp that object to grasp it well, to pick it up.",
            "It's hard to place objects down.",
            "You don't place them very well.",
            "I think that's going to be the next big area for breakthroughs, and I think a lot of people are going to be working on that now.",
            "I urge you to look at that.",
            "Well, maybe not this audience, because I'm not.",
            "I'm not sure how many roboticists there are actually in this audience, but I think once that problem gets solved, then a lot of the.",
            "Things that people here do care about, like higher level cognition are going to be a lot more easy to do task level.",
            "Objects are going to be a lot easier to do once that problem gets attacked, and pretty much solved.",
            "OK, I think that's about all I want to say.",
            "Thanks very much.",
            "Thank you, Kurt.",
            "Great talking great.",
            "That's just pressing for open source.",
            "I have a question about whether more should be done to do monocular processing of images to find things that are relevant to a robot like where the edges of doors are and things you might grab.",
            "And then you do the matching on those instead of trying to get a completely dense.",
            "Stereo map of everything.",
            "So you then project pictures from all all sorts of different views.",
            "My brain can't do that, I know, but I can very quick workout roughly how far things are in what direction they are, and I think that's because I know if I shut one eye, I go around saying lots and lots of stuff.",
            "Why can't we do that?",
            "Yeah, we can't do this right with one eye.",
            "It's kind of tough, right?",
            "So don't need that degree of precision for getting close to things and working at roughly where things are right.",
            "I know I've had to walk around with a Patch on one eye once for several hours, and that was quite illuminating, right?",
            "And I agree that's true.",
            "I mean, you can do a lot with monocular vision.",
            "I think that's good, but it's a handicap, right?",
            "So Slam work really took off.",
            "I mean, supposedly we could navigate with a with a single camera, but the slam work really took off when we finally had laser sensors and.",
            "I don't see any reason not to use sensors that help us as much as they can.",
            "I mean, we're not limited to using very simple sensors if we don't want to.",
            "I think I think that as the monocular vision.",
            "Research progressives will be able to use that more and more, but it's a lot more compute intensive also.",
            "So eventually I think that'll be much more easy to use.",
            "But for the current point, from practical point of view, using dense depth information looks like the way to go.",
            "Sorry, that's just a short answer on that.",
            "There's a lot more I could say.",
            "I have a much easier question.",
            "How did you select the points of interest to begin with?",
            "So that's key point selection and there's a lot of different ways to do that.",
            "As you might think that's been worked on for 30 years too, but again, there have been recent methods that have been pretty fast.",
            "Mostly you look for either blobs or corners.",
            "Corners.",
            "Is the Harris detector blobs, or things like Sift uses a blob detector, and most recently there's been a detector called fast from Drummond and Company.",
            "I think I can't remember actually who did that.",
            "And it just basically uses very simple decision trees to find corner like objects.",
            "There are problems with all of the keypoint detectors, and that's a frustrating engineering job to actually get that right, and there's a lot of stuff you could talk about there.",
            "Thank you.",
            "I actually have a question.",
            "I'm sorry, sorry.",
            "Can you say something about the?",
            "Environments where there are people and whether this is an issue or you're deliberately not considering it, or you mean dynamic things that might get in the way of reconstruction or registration and so forth.",
            "So a lot of these techniques are inherently robust to dynamic objects, as long as they don't.",
            "Take up most of your frame in some way, so the registration techniques get rid of false positives by using geometric checks, and I don't know if you remember from the Oxford scene, but there were people walking in there and the points on the people just got rejected because they weren't consistent with a rigid scene.",
            "It's a lot harder indoors because people tend to take up larger areas, so that's going to become a more important point.",
            "And people are going to have to work a little harder, harder to try to get rid of or track people so that they can get rid of.",
            "The people from the background scene and then actually start tracking them as some separate objects.",
            "Right, so there's been a lot of recent work in skeleton tracking, and I think that's going to be a very important research area, so if Jamie Shotton's work were available, we have a leg up already, but a lot of people are trying to re implement that and come up with really fast methods for doing skeleton tracking and keeping track of where humans are.",
            "I think that I think that's are super important area for people to work in for robotics until robots take over and they don't have to look at people anymore and then and then.",
            "Then we can forget about that.",
            "Thank you.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the title of my talk, but I thought I'd use this opportunity to go back a little bit and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See if this will work.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so actually.",
                    "label": 0
                },
                {
                    "sent": "20 years ago I had another.",
                    "label": 0
                },
                {
                    "sent": "My only other invited AAA I talk so it's a 20 year anniversary 1991 in Anaheim, CA and the talk was as Wolfram said, on logical AI.",
                    "label": 0
                },
                {
                    "sent": "So I was doing belief and intentions for agents.",
                    "label": 0
                },
                {
                    "sent": "Whoops, I didn't mean to do that, sorry, I'll get used to this in a second, and here's the kind of thing that I was actually talking about.",
                    "label": 0
                },
                {
                    "sent": "I didn't there were no laptops back then.",
                    "label": 0
                },
                {
                    "sent": "So I was using.",
                    "label": 0
                },
                {
                    "sent": "Transparencies an I had transparencies full of things like this.",
                    "label": 0
                },
                {
                    "sent": "It was a very interesting and engaging talk.",
                    "label": 0
                },
                {
                    "sent": "So I will not recapitulate that talk.",
                    "label": 0
                },
                {
                    "sent": "He ran.",
                    "label": 0
                },
                {
                    "sent": "In fact I'm going to try to use very little text in this slide, so I have to talk.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I just thought I'd also take the opportunity to recap a little bit of what I had done.",
                    "label": 0
                },
                {
                    "sent": "Like Wolfram, I kind of pivoted from logical AI, which was my thesis work in 1984.",
                    "label": 0
                },
                {
                    "sent": "And then pivoted to robots around 1990.",
                    "label": 0
                },
                {
                    "sent": "So I went back and I looked on Google Scholar at all the papers I had written, or at least a few of them that are cited still and divide it into five categories an by year published.",
                    "label": 0
                },
                {
                    "sent": "And also by importance, namely the number of citations that the papers actually gotten.",
                    "label": 0
                },
                {
                    "sent": "So from this whole decade, which is kind of a lost decade in some ways I was working on Nonmonotonic logic which is fine and I mean it's really coming into its own, but back then you know robots couldn't do very much.",
                    "label": 0
                },
                {
                    "sent": "There is lot of low level work that still needed to be done on robots before you could do all the high level cognitive stuff.",
                    "label": 0
                },
                {
                    "sent": "So right around the year in 1990 I started working with robotics and of course the very first thing that you would do with robots is try to.",
                    "label": 0
                },
                {
                    "sent": "Do an architecture for making the robots do things.",
                    "label": 0
                },
                {
                    "sent": "So I did a lot of architectural papers, but also realize that at the low level there was a lot of work to be done with robots in particular.",
                    "label": 0
                },
                {
                    "sent": "Robots couldn't build Maps very easily, couldn't navigate very easily, so I worked very hard on slam simultaneous localization and mapping and also on some vision research because that's the primary sensor for robots.",
                    "label": 0
                },
                {
                    "sent": "I think in the future also did some work on hardware 'cause I always like to like to build things.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of interesting.",
                    "label": 0
                },
                {
                    "sent": "I guess my citations have gone down.",
                    "label": 0
                },
                {
                    "sent": "Hopefully this will pick up as soon as the future comes, but almost no non monotonic work in the last decade and more concentration on the on the slam work envision.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I also had an entrepreneurial streak, so I like to build things an if I can to sell them.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to review a little bit of that history.",
                    "label": 0
                },
                {
                    "sent": "This is the flick flaky the robot.",
                    "label": 0
                },
                {
                    "sent": "I didn't build this but it was built at Sri and I got to use it.",
                    "label": 0
                },
                {
                    "sent": "We went to the first triple AI contest in 1992 in San Jose.",
                    "label": 0
                },
                {
                    "sent": "That's actually a sun laptop on top of the flaky robot.",
                    "label": 0
                },
                {
                    "sent": "One of the first laptops wait about 10 pounds.",
                    "label": 0
                },
                {
                    "sent": "We did a demo with this guy how and although for Scientific American frontiers you can still probably find that on YouTube somewhere.",
                    "label": 0
                },
                {
                    "sent": "And I realized that there weren't any robots that people could buy off the shelf.",
                    "label": 0
                },
                {
                    "sent": "So I developed the Pioneer robot for my class at Stanford and then cofounded.",
                    "label": 0
                },
                {
                    "sent": "Active media move, which turned into multiple mobile robots and Anne got acquired by Adept recently.",
                    "label": 0
                },
                {
                    "sent": "I also built the erratic robot, which people tend to do crazy things with.",
                    "label": 0
                },
                {
                    "sent": "You shouldn't do this to a robot.",
                    "label": 0
                },
                {
                    "sent": "OK, put all sorts of things on it like that.",
                    "label": 0
                },
                {
                    "sent": "It's going to fall over and unbalance.",
                    "label": 0
                },
                {
                    "sent": "So that was that was a nice thing because it got the robots out there.",
                    "label": 0
                },
                {
                    "sent": "I also did a lot of vision work.",
                    "label": 0
                },
                {
                    "sent": "An out of that I started a little company called Very design that made stereo cameras an it's little known, but these stereo cameras are actually used by Google in there.",
                    "label": 0
                },
                {
                    "sent": "Books project to figure out the curvature of pages on books as they as they read them.",
                    "label": 0
                },
                {
                    "sent": "When I joined Willow Garage a few years back, I designed the stereo system for the head on the robots and because you couldn't see a blank areas like textureless tables and so forth.",
                    "label": 0
                },
                {
                    "sent": "I designed a projector to project or paint a texture so the stereo could actually see it.",
                    "label": 0
                },
                {
                    "sent": "Looks a little bit like the connect, so I almost made the connect at that point, but I knew that the Connect was coming along.",
                    "label": 0
                },
                {
                    "sent": "I had seen some previews for it and this is way more expensive than the Connect, so unfortunately I just missed that boat.",
                    "label": 0
                },
                {
                    "sent": "It would have been a nice one to actually find.",
                    "label": 0
                },
                {
                    "sent": "We also done Slam work and there's now a commercial system called Cardo which also has an open source component so you can use Cardo that came out of my work at Sri and is being sold by Sri.",
                    "label": 0
                },
                {
                    "sent": "And then my only consumer product is actually a combination of these two things of slamming the vision work and that's the Neato robot which will clean your house and keep track of where it is at the same time which is kind of neat.",
                    "label": 0
                },
                {
                    "sent": "So I worked on the slam system for it and also this little sensor here for about $20 worth of parts.",
                    "label": 0
                },
                {
                    "sent": "You get a nice laser distance sensor.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, they won't sell that as a standalone for robotics, so I keep getting requests for that, but there's nothing I can do need to wants to sell vacuums and not help robotics all that much.",
                    "label": 0
                },
                {
                    "sent": "OK, well that was kind of a history of the of the things I did.",
                    "label": 0
                },
                {
                    "sent": "The takeaway message here is the research market isn't all that big, so if you really want to do something right for gamers, right?",
                    "label": 0
                },
                {
                    "sent": "So the connect is used by gamers, so million of those.",
                    "label": 0
                },
                {
                    "sent": "So anything you do in robotics make sure that gamers can use and I think you'll be OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now the real talk registration for robotics.",
                    "label": 0
                },
                {
                    "sent": "So what is registration itself?",
                    "label": 0
                },
                {
                    "sent": "Well, in kind of the simplest form, it's the ability to take 2 views of the world with your sensors and combine them in a way that makes sense.",
                    "label": 0
                },
                {
                    "sent": "So combine the coherently.",
                    "label": 0
                },
                {
                    "sent": "An example of this, for instance, is if I'm looking at this table, I have one view of the table and then I turn and I get a different view of the table that overlaps.",
                    "label": 0
                },
                {
                    "sent": "I want to be able to combine them so I can get a Fuller view of that table.",
                    "label": 0
                },
                {
                    "sent": "Think about a robot actually doing that.",
                    "label": 0
                },
                {
                    "sent": "Another example is here.",
                    "label": 0
                },
                {
                    "sent": "I'm here.",
                    "label": 0
                },
                {
                    "sent": "I am holding a key.",
                    "label": 0
                },
                {
                    "sent": "I want to open a door, so I see the key in my hand.",
                    "label": 0
                },
                {
                    "sent": "I see the keyhole.",
                    "label": 0
                },
                {
                    "sent": "In the door and I want to be able to combine that information so I can actually stick that key in the keyhole and open open the door.",
                    "label": 0
                },
                {
                    "sent": "Another example, there's an object on a table.",
                    "label": 0
                },
                {
                    "sent": "I see that object.",
                    "label": 0
                },
                {
                    "sent": "I want to be able to reach my hand out to the object and actually grab that object.",
                    "label": 0
                },
                {
                    "sent": "These are all instances of registration of sensors to actuators or sensors to sensors, and it's pervades almost everything you do in robotics, so having algorithms that actually work well work fast in real time is a real important thing to have for robotics.",
                    "label": 0
                },
                {
                    "sent": "And since vision is one of the most important senses for robots, I'll talk mostly about visual registration here, vision, not only from monocular sensors, but also from the recent depth sensors that have come out, namely the Connect or the Primesense sensor.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Major technical themes.",
                    "label": 0
                },
                {
                    "sent": "I'd like to look at.",
                    "label": 0
                },
                {
                    "sent": "One of them is how, given 2 images of the world, how do you actually go about matching those images, right?",
                    "label": 0
                },
                {
                    "sent": "So I'll talk about ways of finding points and images and being able to recognize when those points occur in another image and then get a coherent set of matches between those images that can be used for registration.",
                    "label": 0
                },
                {
                    "sent": "And I'll talk about some new methods to do that that are very quick and efficient.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second major theme is optimization, so here's an example of a 2D Carter set from MIT.",
                    "label": 0
                },
                {
                    "sent": "A couple 100 yards long, and we have a lot of matches between the laser scans in these two sets.",
                    "label": 0
                },
                {
                    "sent": "These are constraints.",
                    "label": 0
                },
                {
                    "sent": "The red ones are ones that aren't satisfied very well, and now the idea is how can you take this set of constraints and get the optimal configuration for those laser scans, right?",
                    "label": 0
                },
                {
                    "sent": "Do something like this and do it fairly efficiently so those are the two major technical themes.",
                    "label": 0
                },
                {
                    "sent": "That will actually be talking about, but there are a couple other themes that I'll point out.",
                    "label": 0
                },
                {
                    "sent": "Also, one is especially for robotics.",
                    "label": 0
                },
                {
                    "sent": "You want to be able to do this in real time, right?",
                    "label": 0
                },
                {
                    "sent": "So it's important not just to be able to do this, but to do it efficiently.",
                    "label": 0
                },
                {
                    "sent": "You don't want to wait 10 minutes for something like this to happen, and the other thing the other theme is that's really important.",
                    "label": 0
                },
                {
                    "sent": "Is open source the ability to take something like this and write your programs and distribute it to other people?",
                    "label": 0
                },
                {
                    "sent": "Because it's been a real blocker.",
                    "label": 0
                },
                {
                    "sent": "Every time I go to try to implement something.",
                    "label": 0
                },
                {
                    "sent": "You know, I read a paper and I just I can't get the code if I can't get the code for that paper I have to re implement it and I'll point out some examples of where that's a curd and where it's blocked.",
                    "label": 0
                },
                {
                    "sent": "A little bit progress in robotics.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's let's turn to the first theme which is matching features.",
                    "label": 0
                },
                {
                    "sent": "You would think that this is a solved problem.",
                    "label": 0
                },
                {
                    "sent": "People in vision have been working on it for over 30 years, but there's still a lot of a lot of stuff.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But still, that can be done.",
                    "label": 0
                },
                {
                    "sent": "So let's let's look in an example of this.",
                    "label": 0
                },
                {
                    "sent": "Here are two images of the same thing, different scales, rotations, etc.",
                    "label": 0
                },
                {
                    "sent": "Here's an interesting point.",
                    "label": 0
                },
                {
                    "sent": "In one image, I think you can probably find that in the other image there it is, and what we'd like to be able to do is match those match those things.",
                    "label": 0
                },
                {
                    "sent": "So how do we match key points like that?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's take a closer look at that.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'll take two other images.",
                    "label": 0
                },
                {
                    "sent": "These are again images of the same thing.",
                    "label": 0
                },
                {
                    "sent": "Obviously the one on the right is a little bit blurred, different scale, different rotation.",
                    "label": 0
                },
                {
                    "sent": "Take a key point there and look at it in a little more detail.",
                    "label": 0
                },
                {
                    "sent": "That's what a little 32 by 32 or like a 16 by 16 block.",
                    "label": 0
                },
                {
                    "sent": "Sorry around there that looks like here's another one right of exactly the same point in this new image.",
                    "label": 0
                },
                {
                    "sent": "Now if you're just going to compare these two things in terms of their intensities, you're not going to do very well, right?",
                    "label": 0
                },
                {
                    "sent": "They don't look anything like each other, so the whole idea behind matching is to get some notion of features where the feature for the left hand block and the feature for the right hand block actually Arkham Parable.",
                    "label": 0
                },
                {
                    "sent": "And give you an idea that these are actually the same points, right?",
                    "label": 0
                },
                {
                    "sent": "So how do we?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go about doing that.",
                    "label": 0
                },
                {
                    "sent": "Well, there's a well known method called sift Scale invariant feature transform that comes from David Lowe around the year 2000.",
                    "label": 0
                },
                {
                    "sent": "His basic idea was to take the image Patch divided up into a series of cells and for each cells calculate a set of gradients.",
                    "label": 0
                },
                {
                    "sent": "That is where the images change from dark to light.",
                    "label": 0
                },
                {
                    "sent": "The little Red Arrows up there and then for those gradients in each cell you get a histogram.",
                    "label": 0
                },
                {
                    "sent": "You divide those gradients into some course buckets, usually 8 buckets Purcell.",
                    "label": 0
                },
                {
                    "sent": "And so you get a vector that consists of eight bins for each cell, 4 bytes to represent each bin, 16 cells, a vector of 256 bytes, and this vector you can use to compare against other features.",
                    "label": 0
                },
                {
                    "sent": "And it does a pretty good job, except of course if you change scales or if you have image rotation right, so then it becomes a lot harder to actually compare these things.",
                    "label": 0
                },
                {
                    "sent": "So let's if does is it says, well, I'll find the optimal scale and I'll find a rotation for each Patch an.",
                    "label": 0
                },
                {
                    "sent": "I'll put those things in as part of the.",
                    "label": 0
                },
                {
                    "sent": "Of the Patch information and that turned out to work pretty well.",
                    "label": 0
                },
                {
                    "sent": "But there's still a problem.",
                    "label": 0
                },
                {
                    "sent": "I mean, this isn't a very efficient way to go about it, and I'll talk about some timing statistics in just a minute.",
                    "label": 0
                },
                {
                    "sent": "So more recently, in 2010 Michael Calendar came out with a much simpler feature called the Brief feature, and the idea is is dead simple here, you take.",
                    "label": 0
                },
                {
                    "sent": "2 random points in your future Patch and you compare them.",
                    "label": 0
                },
                {
                    "sent": "Is 1 brighter than the other?",
                    "label": 0
                },
                {
                    "sent": "And if it is, you give a one.",
                    "label": 0
                },
                {
                    "sent": "If it's not, you give a zero and you just keep doing this for loops for random points right?",
                    "label": 0
                },
                {
                    "sent": "And you get a feature vector and it turns out 256 bits is a perfectly fine feature vector for comparison, 32 bytes, so almost a factor of almost an order of magnitude less size than the SIP feature.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that this also works surprisingly well and I'll show you how well it works in just a second.",
                    "label": 0
                },
                {
                    "sent": "But you have the same problem with scale and image rotation.",
                    "label": 0
                },
                {
                    "sent": "So more recently, folks at Willow Garage came up with the Orb feature, which takes scale.",
                    "label": 0
                },
                {
                    "sent": "Also scale an rotation into account and gives a scale and rotation to to these features so they can be compared.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, here's an example of doing that kind of using orbon onto images, so the red points.",
                    "label": 0
                },
                {
                    "sent": "The red circles are all of the distinctive key points that are found, and the green matches are the correct matches that have been found.",
                    "label": 0
                },
                {
                    "sent": "So you take a key point in one image and you compare it to all the other key points in the other image and find the highest response using your feature.",
                    "label": 0
                },
                {
                    "sent": "So you get a match for each keypoint and the ones that are actually correct or given by those green lines.",
                    "label": 0
                },
                {
                    "sent": "And the way you find which ones are correct, I'll talk about a little later in the talk by using geometry.",
                    "label": 0
                },
                {
                    "sent": "Here's another example from that picture I showed earlier.",
                    "label": 0
                },
                {
                    "sent": "You can see that it does a pretty good job even through fairly large changes in scale.",
                    "label": 0
                },
                {
                    "sent": "OK, how well?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does it work compared to sift?",
                    "label": 0
                },
                {
                    "sent": "Alright, so you'll have to read this graph a little bit.",
                    "label": 0
                },
                {
                    "sent": "Sift is the red line so and this is an angle of rotation, so you take one image and you rotate the other image with respect to it.",
                    "label": 0
                },
                {
                    "sent": "Just a standard test that you can do and sift does pretty well about 60% correct matches across images surf which is a speeded up version of Sift, does slightly worse, although it's faster.",
                    "label": 0
                },
                {
                    "sent": "It turns out the brief feature the rotated brief feature, or actually does better than Sift.",
                    "label": 0
                },
                {
                    "sent": "Even though it's a smaller feature, an much simpler feature to compute, so hopefully Orb will become the future of choice in the future.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just in terms of timing, so SIFT was in 1999.",
                    "label": 0
                },
                {
                    "sent": "If you're going to extract on a current computer 2000 features, it will take you about 5 seconds to do that.",
                    "label": 1
                },
                {
                    "sent": "Of course there are GPU versions of this that take a lot less, but I'm trying to compare just based on standard processors.",
                    "label": 0
                },
                {
                    "sent": "Surf is a lot better over an order of magnitude that was 2006.",
                    "label": 0
                },
                {
                    "sent": "Orb takes 19 milliseconds, right so?",
                    "label": 0
                },
                {
                    "sent": "In the course of some 10 years or 12 years, we've got two orders of magnitude speedup and a better descriptor for matching, so we can even do things like implement this on a smartphone.",
                    "label": 0
                },
                {
                    "sent": "An Ethan Rublee did this.",
                    "label": 0
                },
                {
                    "sent": "You can now track things in the world on your on your smartphone as you go through.",
                    "label": 0
                },
                {
                    "sent": "So the smartphone processors, of course, have gotten better, but you couldn't do this.",
                    "label": 0
                },
                {
                    "sent": "There's no way you can do this with Sift or even surf.",
                    "label": 0
                },
                {
                    "sent": "So the real time theme here is important.",
                    "label": 0
                },
                {
                    "sent": "OK. Alright, so we've looked at matching visual features.",
                    "label": 0
                },
                {
                    "sent": "And I've talked about finding a good set of matches because you're going to get some false positives in those matches.",
                    "label": 0
                },
                {
                    "sent": "So how do you go about finding a coherent set of matches when you're matching 2 images?",
                    "label": 0
                },
                {
                    "sent": "Well, that's a question of using geometry an.",
                    "label": 0
                },
                {
                    "sent": "I'll look at a series of.",
                    "label": 0
                },
                {
                    "sent": "Of geometric matches from very simple ones to more complicated ones.",
                    "label": 0
                },
                {
                    "sent": "And here's where the geometry of registration comes into play.",
                    "label": 0
                },
                {
                    "sent": "An for robotics, there are a lot of different kinds of geometry that we have to look at, and I'll try to give you an idea of the scale of the of the kinds of geometry that actually exists and then point out how they can all be put into one framework for doing general geometric work with these kinds of.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, here's the here's the first fairly simple geometric idea.",
                    "label": 0
                },
                {
                    "sent": "You have two points of view.",
                    "label": 0
                },
                {
                    "sent": "You're looking with the same camera, and you're just rotating that camera and two degrees of freedom, right?",
                    "label": 0
                },
                {
                    "sent": "So you're getting different views of the world, and you have to put those views together, right?",
                    "label": 0
                },
                {
                    "sent": "So again, you can do matches.",
                    "label": 0
                },
                {
                    "sent": "You can find a set of matches for that and.",
                    "label": 0
                },
                {
                    "sent": "Putting those matches together, you can say what the rotation of the cameras are with respect to each other.",
                    "label": 0
                },
                {
                    "sent": "You can merge the images and you can form a Panorama right?",
                    "label": 0
                },
                {
                    "sent": "So this is a fairly simple operation, 2 degrees of freedom and it's actually done in standard consumer cameras at this point, right?",
                    "label": 0
                },
                {
                    "sent": "So you can buy cameras where you can do this kind of thing and it will actually work.",
                    "label": 0
                },
                {
                    "sent": "This is the first simple kind of geometry, right?",
                    "label": 0
                },
                {
                    "sent": "How do we represent that in a mathematical way?",
                    "label": 0
                },
                {
                    "sent": "Well, given that this is AAA I of course we go to Bayesian representations.",
                    "label": 0
                },
                {
                    "sent": "That's the obvious.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The obvious way to do it, and I'll do it in a way that is getting more and more credence these days, which is factor graph.",
                    "label": 0
                },
                {
                    "sent": "So instead of a base graph here I've drawn a factor graph.",
                    "label": 0
                },
                {
                    "sent": "Where the view points P1 and P2 or the variables and the constraints, the different constraints that we get from matching points between those two viewpoints between the images are given by these functions that relate these two viewpoints and the basic idea is that when the two viewpoints are in alignment for a particular match right, the probability of that match is actually very high.",
                    "label": 0
                },
                {
                    "sent": "OK, and what factor graphs do is they represent constraints.",
                    "label": 0
                },
                {
                    "sent": "They represent a complex function which will eventually talk about as the probability function as a set of smaller factors that we've parceled out between these between these two variables, right?",
                    "label": 0
                },
                {
                    "sent": "So you take a fairly complex function between these two variables and you factor it into a set of smaller functions, right?",
                    "label": 0
                },
                {
                    "sent": "And I'll talk about the probability probabilistic effects of the factor graph once I get through all of the geometry and we'll see how to.",
                    "label": 0
                },
                {
                    "sent": "Actually solve these kinds of graphs sufficiently, but take note of this graph and how simple it is.",
                    "label": 0
                },
                {
                    "sent": "Just two variables and a bunch of constraints between those.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tables.",
                    "label": 0
                },
                {
                    "sent": "OK, the next step up is to look at 3D points.",
                    "label": 0
                },
                {
                    "sent": "So here you have two viewpoints, there's your.",
                    "label": 0
                },
                {
                    "sent": "Connect sensor and you've taken 2 viewpoints of a scene and you have 3D point clouds with those with those viewpoints and you're trying to figure out how the viewpoints correspond so that you can merge those two sets of viewpoints right and?",
                    "label": 0
                },
                {
                    "sent": "Now we don't have any distinctive points that were actually matching, so we're taking the 3D points 'cause the 3D points aren't quite as distinctive, and we're finding the nearest neighbor, and we're putting a constraint in between the nearest neighbor.",
                    "label": 0
                },
                {
                    "sent": "So if you look at that, you can see that it found good nearest neighbors on the bottom on the floor.",
                    "label": 0
                },
                {
                    "sent": "Not so good nearest neighbors between the top of the chair and the back of the wall, right?",
                    "label": 0
                },
                {
                    "sent": "So we have some bad matches there, but.",
                    "label": 0
                },
                {
                    "sent": "Using an optimization step, we can let me start that again.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure I we solve that using an optimization step.",
                    "label": 0
                },
                {
                    "sent": "We can correspond those two and find a pretty good viewpoint and then get another set of matches.",
                    "label": 0
                },
                {
                    "sent": "So we redo our matches at that point and now you can see that the back of the chair is fine.",
                    "label": 0
                },
                {
                    "sent": "We get good matches, and then we iterate that procedure and we get a better match and we actually find the correct viewpoint where those two point clouds are merged very well, alright?",
                    "label": 0
                },
                {
                    "sent": "And this is called the iterative closest point on the factor graph.",
                    "label": 0
                },
                {
                    "sent": "For this, what do you think the factor graph for this actually looks like, right?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It looks exactly the same as the factor graph we had when we match visual key points in the planar homography case, right?",
                    "label": 0
                },
                {
                    "sent": "So again, we just have two viewpoints, the the 3D points in the world are rigidly attached to those viewpoints, so each of those constraints is just a constraint between that viewpoint.",
                    "label": 0
                },
                {
                    "sent": "And again, we're searching for the best configuration between those variables that satisfies all the constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, so so far we've just talked about registering viewpoints to each other, but, uh, more complicate.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Added problem exists when you have two viewpoints and even though you have information about the distance of the points from each of those viewpoints, the 3D World points.",
                    "label": 0
                },
                {
                    "sent": "That information can have errors in it, so you're trying to get a better idea of where 3D points in the world actually are.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that you're adjusting not only your viewpoints with respect to each other, but you're trying to adjust where the points in the world are at the same time, so you have a much larger problem.",
                    "label": 0
                },
                {
                    "sent": "Your number of variables increases because you're trying to optimize not only where viewpoints are, but where points in the world are.",
                    "label": 0
                },
                {
                    "sent": "So if we start out by picking a set of points in the world, these red circles, right?",
                    "label": 0
                },
                {
                    "sent": "We take two images and now we apply our matching algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here's a red image and a green image and you can see there are a set of matches between these points, not a very coherent set, right?",
                    "label": 0
                },
                {
                    "sent": "Because there are some false matches there, so we applied geometric rules and we can eliminate most of those matches and just get a coherent set.",
                    "label": 0
                },
                {
                    "sent": "Here's the two.",
                    "label": 0
                },
                {
                    "sent": "Point clouds that we start out with and then by applying optimization based on the constraints that we find we can optimize not only where these two positions of the viewpoints are, but we can also optimize where these points in the world are out there right now.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, those points are sparse, that is, we've done a pretty good job through triangulation between these two viewpoints of figuring out where these points in the world are.",
                    "label": 0
                },
                {
                    "sent": "But there are other points that we haven't done as good a job of right 'cause.",
                    "label": 0
                },
                {
                    "sent": "These are just points that are attached to the viewpoints, but we have no.",
                    "label": 0
                },
                {
                    "sent": "Triangulation information to actually make a better idea or better estimate of where these points are in the world, and I'll return to this in just a second, but I just wanted to point out this this issue here, so we now have a sparse bundle adjustment where we're.",
                    "label": 0
                },
                {
                    "sent": "We're optimizing the position of viewpoints and some points in the world, but a few points in the world.",
                    "label": 0
                },
                {
                    "sent": "OK, what does the factor graph look like for this?",
                    "label": 0
                },
                {
                    "sent": "Alright, so now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've actually.",
                    "label": 0
                },
                {
                    "sent": "Increase the number of variables instead of just having viewpoint variables.",
                    "label": 0
                },
                {
                    "sent": "We also have point variables in the world and now the constraints are projection constraints between the points in the world and the actual viewpoint itself, and we try to optimize that those projections so that they correspond to our actual measurement and the probability function is now a bit more complicated.",
                    "label": 0
                },
                {
                    "sent": "It's over all these variables, but again, it factors very nicely into these small probability functions and will be able to solve this efficiently.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "One of the advantages of looking at this as a factor graph is that we can add another constraints if we need to.",
                    "label": 0
                },
                {
                    "sent": "So remember that the sparse registration that we did didn't work very well for all the points that we had in each of those dense viewpoints.",
                    "label": 0
                },
                {
                    "sent": "So what we can do is we can take the AICP constraints that we just talked about an add them back into the factor graph, just throw it all into the same factor graph.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optimize it.",
                    "label": 0
                },
                {
                    "sent": "So here again, is the original seen.",
                    "label": 0
                },
                {
                    "sent": "The two viewpoints not very well optimized here.",
                    "label": 0
                },
                {
                    "sent": "If we throw in the AICP constraints, we do a lot better.",
                    "label": 0
                },
                {
                    "sent": "Still not perfect, but but not bad, right?",
                    "label": 0
                },
                {
                    "sent": "So now instead of, I think there are about 17 points that we optimized.",
                    "label": 0
                },
                {
                    "sent": "Here we have another thousand points that we threw in for AICP constraints and we get much better registration between these two points all throughout those dense point clouds.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So by now you should be able to say what the factor graph looks like for this.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have both the projection constraints and we have GCP constraints.",
                    "label": 0
                },
                {
                    "sent": "We have a more complicated factorization, but again we should be able to solve this fairly efficiently.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Now, so far we've looked at 2 frames at a time, but there's no reason that we can add in more frames, right?",
                    "label": 0
                },
                {
                    "sent": "So this is just a factor graph.",
                    "label": 0
                },
                {
                    "sent": "We could just increase the factor graph.",
                    "label": 0
                },
                {
                    "sent": "We could we could throw in more frames and we could optimize the whole thing.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once.",
                    "label": 0
                },
                {
                    "sent": "So this is what we did with the short sequence from our PR2 robot.",
                    "label": 0
                },
                {
                    "sent": "Here you can see that there are many frames.",
                    "label": 0
                },
                {
                    "sent": "I think there are about 50 frames in this sequence an we're optimizing them all together so that we get a fairly good reconstruction here, with both AICP constraints and bundle adjusted visual constraints.",
                    "label": 0
                },
                {
                    "sent": "You can see that there's a pretty this if you just look at this wall here.",
                    "label": 0
                },
                {
                    "sent": "We get a very good reconstruction of this wall, even though it's seen by many different frames because we're optimizing all the constraints together.",
                    "label": 0
                },
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "Even if all right, you have a very efficient optimization procedure if you keep doing this and you expand this to larger and larger environments eventually you're going to run into computational troubles, right?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if you take an extreme, if you look at something like the photo tourism application that you can run at the Microsoft website, you can take thousands of camera poses, upload them to this website, wait about half a day.",
                    "label": 1
                },
                {
                    "sent": "And then get back something if you're lucky.",
                    "label": 0
                },
                {
                    "sent": "Alright, 'cause sometimes it doesn't work, looks like a very nice 3D reconstruction that again bundle adjusts where all of the cameras are and where the 3D points in the world are right.",
                    "label": 0
                },
                {
                    "sent": "But as I said, it takes a long time an as you keep expanding your world, it's going to take longer and longer, so you need some way, especially in robotics to recover from this kind of optimization.",
                    "label": 0
                },
                {
                    "sent": "And one way to to do that is, I think, a fairly natural way.",
                    "label": 0
                },
                {
                    "sent": "If I'm in this room, right?",
                    "label": 0
                },
                {
                    "sent": "And I'm looking around and, you know, I'm reconstructing the environment here.",
                    "label": 0
                },
                {
                    "sent": "This 3D environment I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not remembering precisely what the 3D environment is out in the Hall or in the streets of San Francisco or back at my home in Menlo Park, or anything like this.",
                    "label": 0
                },
                {
                    "sent": "I'm just concentrating on kind of a reconstruction bubble right here, and I have a vague idea of how it relates to geometrically to things outside the area.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one way to recover constant time and actually real time for these kinds of reconstructions is to just have this bubble in which you do precise reconstruction.",
                    "label": 0
                },
                {
                    "sent": "So that's that's one window, and then have a window where you do a much coarser reconstruction around you.",
                    "label": 0
                },
                {
                    "sent": "So this was some work done by how Kestros .1 of Andy Davidson students when he was an intern at Willow Garage.",
                    "label": 0
                },
                {
                    "sent": "And here you can see a large scale reconstruction.",
                    "label": 0
                },
                {
                    "sent": "This is speeded up a little, of course.",
                    "label": 0
                },
                {
                    "sent": "Done it with an Oxford data set so around a court in Oxford.",
                    "label": 0
                },
                {
                    "sent": "This is about 100 meters or so in diameter and you can see the bubble of points and constraints between poses between viewpoints right here, even when you close the loop, it incorporates information that it had previously, but it does that by keeping this small bubble around right so that anytime your local environment is, well reconstructed and you don't care as much about the larger environment around you.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that works pretty well, and in fact, if you have a small environment you can use this to do things like reconstruct objects, right?",
                    "label": 0
                },
                {
                    "sent": "So here's an object modeling application where we're basically finding the poses around the object and then putting all of that together with the object OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now you can ask I guess, or I would be led to ask at this point.",
                    "label": 0
                },
                {
                    "sent": "Is this the most complicated factor graph you can get?",
                    "label": 0
                },
                {
                    "sent": "Alright, so is there anything else we could add to the factor graph to put in more constraints, do a better job etc etc Ann?",
                    "label": 0
                },
                {
                    "sent": "The answer is yes.",
                    "label": 0
                },
                {
                    "sent": "If you look at the examples I gave with the dense point clouds, remember we have nice sparse places where we have identified points and by triangulate Ng from the viewpoints we can actually pick out very precisely where they are in 3D, but the rest of the points, even though we're using AICP to get them close to each other right?",
                    "label": 0
                },
                {
                    "sent": "There's still a lot of fuzz in how they look, so they're not.",
                    "label": 0
                },
                {
                    "sent": "The sensors themselves are not very precise, and so instead of getting a nice smooth surface, you get a very bumpy surface.",
                    "label": 0
                },
                {
                    "sent": "One way to deal with that is to use regularization methods.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that most surface is in the world are smooth.",
                    "label": 0
                },
                {
                    "sent": "And you can apply a smoothness constraint to actually take out some.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That bumpiness and this is very nice work from Michael Monkeys and Wolfram Burgard, Slab and Freiburg.",
                    "label": 0
                },
                {
                    "sent": "Goes by a little quick, so I'll try to halt it at some point.",
                    "label": 0
                },
                {
                    "sent": "Let me go back to that.",
                    "label": 0
                },
                {
                    "sent": "OK hello, come on guy whoops.",
                    "label": 0
                },
                {
                    "sent": "OK, alright, so here's the initial set of point clouds that you get from actually.",
                    "label": 0
                },
                {
                    "sent": "Moving your camera around the object and also on top of the object so you can see inside and you can see that the surface is aren't actually all that good.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of error in that connect data in the depth, but if you apply a smoothness constraint that says these points next to each other should be on the same plane or surface or approximately planar surface and then you optimize that you can actually do pretty well in terms of getting a much better object model out of this right?",
                    "label": 0
                },
                {
                    "sent": "So the results here are absolutely spectacular.",
                    "label": 0
                },
                {
                    "sent": "You get these very nice smooth surface is from what were very bumpy surface is originally.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So now you can ask what is the factor graph for this look?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An it looks somewhat the same as our previous factor graphs, except now you have constraints between the points out in the world, right?",
                    "label": 0
                },
                {
                    "sent": "So and those constraints are regularization constraints that say points that are near each other in the world should probably lie on the same surface, the same smooth surface, right?",
                    "label": 0
                },
                {
                    "sent": "And you have now a slightly more complicated probability function factor probability function.",
                    "label": 0
                },
                {
                    "sent": "It turns out because of these constraints, there are a lot of them.",
                    "label": 0
                },
                {
                    "sent": "Computationally, it's a lot harder to solve.",
                    "label": 0
                },
                {
                    "sent": "And I hope to be able to point that out a little bit.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "So so far we've been talking about reconstruction, which is certainly one of the most important parts of registration.",
                    "label": 0
                },
                {
                    "sent": "But there are other uses for registration behind besides this, so one of them is calibration an if any of you have worked with robots and sensors, you've done calibration and you know what?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Main calibration is right, so here's an example of bad calibration.",
                    "label": 0
                },
                {
                    "sent": "Let's see if this will.",
                    "label": 0
                },
                {
                    "sent": "If this will run.",
                    "label": 0
                },
                {
                    "sent": "Come on.",
                    "label": 0
                },
                {
                    "sent": "Oh, there it goes.",
                    "label": 0
                },
                {
                    "sent": "OK so this is.",
                    "label": 0
                },
                {
                    "sent": "I mean we're trying as best we can and eventually it'll put the plug into the socket.",
                    "label": 0
                },
                {
                    "sent": "But here we have.",
                    "label": 0
                },
                {
                    "sent": "We're looking at things with the camera and with the with the stereo sensor, we're finding the.",
                    "label": 0
                },
                {
                    "sent": "The socket in the real world we know where the plug is in the arm, but our calibration of the arm parameters just isn't good enough to enable us to get the millimeter precision we need to stick that plug into the socket, right?",
                    "label": 0
                },
                {
                    "sent": "So we have to try a few times to actually do that.",
                    "label": 0
                },
                {
                    "sent": "Here's what it should look like.",
                    "label": 0
                },
                {
                    "sent": "If it's well calibrated, this is so smooth I love this.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Hard to argue with that, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a well calibrated robot like the well tempered claviere, right?",
                    "label": 0
                },
                {
                    "sent": "Well calibrated robot should be able to do something like this.",
                    "label": 0
                },
                {
                    "sent": "So how do we calibrate a robot?",
                    "label": 0
                },
                {
                    "sent": "It turns out there was a large literature on calibration for robots, mostly dealing with industrial robots.",
                    "label": 0
                },
                {
                    "sent": "Very little of it dealing with general sensors.",
                    "label": 0
                },
                {
                    "sent": "Looking at general manipulators.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Vijay Pradeep at Willow Garage developed a bundle adjustment approach to sensor calibration sensor and actuator calibration.",
                    "label": 0
                },
                {
                    "sent": "So here's a schematic diagram of the PR2 robot.",
                    "label": 0
                },
                {
                    "sent": "You can go out and see one in the Hall.",
                    "label": 0
                },
                {
                    "sent": "Later on it's got lots of sensors, about 7 different vision sensors plus laser tilting laser sensor.",
                    "label": 0
                },
                {
                    "sent": "It's got lots of degrees of freedom in its arms right?",
                    "label": 0
                },
                {
                    "sent": "And the idea is we want to calibrate together all of the sensors and all of the actuators so that the whole robot is actually calibrated and there was no.",
                    "label": 0
                },
                {
                    "sent": "Procedure in the literature that would actually let us do this much less code for doing this, right?",
                    "label": 0
                },
                {
                    "sent": "So you can read papers if there's no code, you still have to reimplement all that stuff.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our approach was basically.",
                    "label": 0
                },
                {
                    "sent": "You use the same kind of factor graphs right to do this kind of calibration and the basic idea is that you find loops between targets in the real world and the sensors that you have.",
                    "label": 0
                },
                {
                    "sent": "So here's the tilting laser sensor.",
                    "label": 0
                },
                {
                    "sent": "The camera you look at a target in the real world, and this gives you a constraint among all of these things.",
                    "label": 0
                },
                {
                    "sent": "Here's another constraint between the arm and the forearm camera in the arm.",
                    "label": 0
                },
                {
                    "sent": "Here's a constraint between all of the arms, the forearm camera, and the right arm, and the target in the left arm.",
                    "label": 0
                },
                {
                    "sent": "You collect a whole bunch of these.",
                    "label": 0
                },
                {
                    "sent": "You throw them into a factor graph, you bundle, adjust it, and you get a calibration for your.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How well does it work well?",
                    "label": 0
                },
                {
                    "sent": "This is an example of the kind of output that you get.",
                    "label": 0
                },
                {
                    "sent": "This is looking at errors from the point of view of the two stereo cameras.",
                    "label": 0
                },
                {
                    "sent": "There's a wide angle stereo camera in their narrow angle stereo camera.",
                    "label": 0
                },
                {
                    "sent": "One is blue, one is red.",
                    "label": 0
                },
                {
                    "sent": "I forget which is which, but an uncalibrated robot, fresh out of the box has errors on the order of 1020 fifty pixels.",
                    "label": 0
                },
                {
                    "sent": "In terms of where it thinks it sees the arm and where the arm actually is.",
                    "label": 0
                },
                {
                    "sent": "When you calibrate the robot, those things not only have no bias, so there was a strong bias here, but the pixel errors are now much lower, so on the order of.",
                    "label": 0
                },
                {
                    "sent": "A few pixels when you actually do that.",
                    "label": 0
                },
                {
                    "sent": "OK, this is great, but it's still a pain to calibrate the robot an calibrations go away overtime right?",
                    "label": 0
                },
                {
                    "sent": "Things get bumped, So what you'd really like to do is online calibration.",
                    "label": 0
                },
                {
                    "sent": "An believe it or not, you can use factor graphs to do online caliber.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is some work by Javier Romero, from KTH was an intern just this this spring at Willow Garage, and the basic idea is that you're matching a model of the arm, right?",
                    "label": 0
                },
                {
                    "sent": "Two lines that you extract from the visual image, and you're trying to calibrate based on those lines and where you think the arm is.",
                    "label": 0
                },
                {
                    "sent": "So here is two different viewpoints of that.",
                    "label": 0
                },
                {
                    "sent": "You can see this.",
                    "label": 0
                },
                {
                    "sent": "The arm moves around, so there's a constraint between the line that you extract in the image and where you expect that line to be based on a silhouette of the arm that you can compute using open GL type graphics.",
                    "label": 0
                },
                {
                    "sent": "The one on the left.",
                    "label": 0
                },
                {
                    "sent": "We're not using any depth information to try to constrain where the line is.",
                    "label": 0
                },
                {
                    "sent": "The one on the right were actually using depth information, so this is new research, and it promises to let us do online calibration so that we can continuously calibrate where the arm is with respect to sensors.",
                    "label": 0
                },
                {
                    "sent": "I think this is going to be extremely important in the future.",
                    "label": 0
                },
                {
                    "sent": "This is this is going to be the way the robots will actually calibrate, so you won't have to take it out of the box and do a full calibration or anything like that.",
                    "label": 0
                },
                {
                    "sent": "You'll just start right up and the robot will calibrate itself.",
                    "label": 0
                },
                {
                    "sent": "Kind of like the way humans do, right?",
                    "label": 0
                },
                {
                    "sent": "We're continuously calibrating where our arms are, and so forth, OK?",
                    "label": 0
                },
                {
                    "sent": "So we've seen at least some uses of registration.",
                    "label": 0
                },
                {
                    "sent": "There are some I can't even talk about here, 'cause I don't have enough time.",
                    "label": 0
                },
                {
                    "sent": "For instance, object recognition and pose estimation for picking up objects, but I want to get to the other part of the technical talk here, which is how we do efficient optimization.",
                    "label": 0
                },
                {
                    "sent": "So this is great factor graphs, bundle adjustment, efficient optimization of factor graphs.",
                    "label": 0
                },
                {
                    "sent": "How do we actually do that?",
                    "label": 0
                },
                {
                    "sent": "Especially when we have large number of variables?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So let's go back and look at a simple factor graph here with just the two variables in a set of constraints here and now, I have explicitly represented the probability as a factored set of probabilities, right?",
                    "label": 0
                },
                {
                    "sent": "So there is a probability factor between these two between these two in between these two an the total probability is just.",
                    "label": 0
                },
                {
                    "sent": "The product of all of those, all of those probabilities.",
                    "label": 0
                },
                {
                    "sent": "Now the kind of inference that we want to do is we want to find the maximum likelihood right?",
                    "label": 0
                },
                {
                    "sent": "So what's the position of P1 and P2 that leads to the largest probability here given our observations?",
                    "label": 0
                },
                {
                    "sent": "So that's a maximum likelihood problem, and I'll phrase it this way.",
                    "label": 0
                },
                {
                    "sent": "Find the minimum over all possible positions of our variables of the negative log of the probability right?",
                    "label": 0
                },
                {
                    "sent": "So I've just changed it to a negative sign and I put a log in front of the probability WHI along in front of probability.",
                    "label": 0
                },
                {
                    "sent": "Well that's the standard trick to convert from products to sums and sums are a heck of a lot easier to deal with, right?",
                    "label": 0
                },
                {
                    "sent": "So now by substituting in the factors we have simply the argument of the sum of all of those which we consider as costs.",
                    "label": 0
                },
                {
                    "sent": "And now a key step if you consider each of those probabilities each of the H is to be Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Alright, then you can reduce it even further to a standard least squares problem.",
                    "label": 0
                },
                {
                    "sent": "That is, if each of the of the H is Gaussian, then the log of that Gaussian or the negative log of that Gaussian reduces to a quadratic function, where ZI right is the expected sensor.",
                    "label": 0
                },
                {
                    "sent": "Reading that you get out given the positions of P1 and P2.",
                    "label": 0
                },
                {
                    "sent": "That's what you expect to get out, so you have a way of calculating that and see I cap is the actual reading that you get, so this is an error.",
                    "label": 0
                },
                {
                    "sent": "Right, it says if I met these two positions right, I expect to see you know my sensor reading for where this point is should be right here on my image.",
                    "label": 0
                },
                {
                    "sent": "Oh, but my actual reading is over here and I get some error between it and now.",
                    "label": 0
                },
                {
                    "sent": "I have a quadratic error form and this is just really a nonlinear least squares problem.",
                    "label": 0
                },
                {
                    "sent": "It's nonlinear because this function is nonlinear, so we're going to have to iterate the linear problem to solve that.",
                    "label": 0
                },
                {
                    "sent": "So let me go into just a little detail.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But how you solve these kinds of problems?",
                    "label": 0
                },
                {
                    "sent": "The generic way for is called sparse bundle adjustment.",
                    "label": 1
                },
                {
                    "sent": "Just go over this briefly.",
                    "label": 1
                },
                {
                    "sent": "Here's our error function or error equation.",
                    "label": 0
                },
                {
                    "sent": "Again, where this is the expected value, so we have to be able to compute this, and this is the actual value that we see.",
                    "label": 0
                },
                {
                    "sent": "We calculate jacobian's of the error function.",
                    "label": 0
                },
                {
                    "sent": "So basically the change in the error when we change our when we change our variables evaluated at our initial value for those variables, and given those jacobian's we can form what's called the normal equation where we can update the variable.",
                    "label": 0
                },
                {
                    "sent": "So if we solve this normal equation, we can update the variables X based on the errors that we actually see.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we've done a linear isation using the jacobian's.",
                    "label": 0
                },
                {
                    "sent": "We now have a normal equation that we can solve and if you look at the form of that normal equation this particular factor JT J also an approximation of what's called the Hessian.",
                    "label": 0
                },
                {
                    "sent": "If you look at that, it's sparse.",
                    "label": 0
                },
                {
                    "sent": "That matrix is sparse if there's a constraint between two variables I&J right?",
                    "label": 0
                },
                {
                    "sent": "Then there are factors in the in that matrix corresponding to those, but in for any set of variables.",
                    "label": 0
                },
                {
                    "sent": "You know they're not going to be densely connected, so you get a very sparse, usually a very sparse matrix of this form, and we can take advantage of recent results.",
                    "label": 0
                },
                {
                    "sent": "Fairly recent results in linear Algebra 2 to efficiently solve equations like this.",
                    "label": 0
                },
                {
                    "sent": "And once we solve it, we can go back re linearize using the jacobian's, iterate again, and so forth till we get convergence.",
                    "label": 0
                },
                {
                    "sent": "So just to give you an example of some of the timings, right?",
                    "label": 0
                },
                {
                    "sent": "So this has been a real breakthrough in recent years, so there was a.",
                    "label": 0
                },
                {
                    "sent": "There still is actually a an open source version of bundle adjustment, sparse bundle adjustment from Larocca Cenar jeros that has been used widely right so it was used in the Photosynth project that Microsoft did, and for a fairly large problem.",
                    "label": 0
                },
                {
                    "sent": "Let's say one with about 2 million variables and 3 million constraints.",
                    "label": 0
                },
                {
                    "sent": "It takes on the order of 16 minutes or so to actually solve that problem, right?",
                    "label": 0
                },
                {
                    "sent": "That was as of 2004.",
                    "label": 0
                },
                {
                    "sent": "Using more recent techniques in linear algebra, I was able to pull that down to just over 100 seconds so a couple minutes almost a factor of 10.",
                    "label": 0
                },
                {
                    "sent": "And then even more recent results, unfortunately not mine.",
                    "label": 0
                },
                {
                    "sent": "Brought that down by another factor of 10.",
                    "label": 0
                },
                {
                    "sent": "It's using some very nice algorithmic tricks to make the convergence go faster, so over the course of six years or so, and by the way, I expect this to decrease another factor of 10, at least by the end of the year, because this is all done with single processors, but people are now starting to consider the case where you have multiple processors, or you were implementing this on the GPU, so I expect this to be done maybe in a second or so, at least by the end of the year, right?",
                    "label": 0
                },
                {
                    "sent": "This is all very nice to give you an example of the kind of system we're talking about.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the actual example that was used there, so this is some palazzo in Venice and these are all of the different cameras that were there and all of the points that were involved.",
                    "label": 0
                },
                {
                    "sent": "So there were some 850 camera poses and 2/3 of a million points that are optimized simultaneously by these systems.",
                    "label": 1
                },
                {
                    "sent": "Here's a little close up of that.",
                    "label": 0
                },
                {
                    "sent": "You can see the fairly fine detail like these steps on the plot, so so very nice results there.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In fact, these things are so efficient that they make certain problems solved, so we used to worry about two DSLAM.",
                    "label": 0
                },
                {
                    "sent": "So here's a here's an example from way back when when I first started doing loop closure with Stephen Goutman.",
                    "label": 0
                },
                {
                    "sent": "Right, so I I don't know how we save this video, but somehow it was there.",
                    "label": 0
                },
                {
                    "sent": "This is around the year 2000, so you're 2 robots.",
                    "label": 0
                },
                {
                    "sent": "One makes a little map and the other is staying localized.",
                    "label": 0
                },
                {
                    "sent": "Initan will now close the loop and the thing I want you to notice is when it does that loop closure.",
                    "label": 0
                },
                {
                    "sent": "So this is real time, right?",
                    "label": 0
                },
                {
                    "sent": "And?",
                    "label": 0
                },
                {
                    "sent": "Of course computers were a little slower back then.",
                    "label": 0
                },
                {
                    "sent": "And you can see that it takes a second or two to actually close that loop and top when it closes the loop.",
                    "label": 0
                },
                {
                    "sent": "It just optimizes the whole thing and it's some 10s of matches, 10s of poses that are actually there.",
                    "label": 0
                },
                {
                    "sent": "OK, fast.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Forward to current times.",
                    "label": 0
                },
                {
                    "sent": "This is an MIT data set with about 6000 poses every 10 poses.",
                    "label": 0
                },
                {
                    "sent": "We do a complete optimization of the graph.",
                    "label": 0
                },
                {
                    "sent": "This is running way faster than real time.",
                    "label": 0
                },
                {
                    "sent": "Not only that, it's slower because of the graphics.",
                    "label": 0
                },
                {
                    "sent": "It would be a lot faster than this.",
                    "label": 0
                },
                {
                    "sent": "This is one of my favourites.",
                    "label": 0
                },
                {
                    "sent": "If we just start at zero we can run the optimizer and actually reconstruct the whole graph from that.",
                    "label": 0
                },
                {
                    "sent": "So these methods basically have solved at least two DSLAM with no problem.",
                    "label": 0
                },
                {
                    "sent": "Alright, So what used to take us hundreds of seconds to do on these large graphs Now takes us less than.",
                    "label": 0
                },
                {
                    "sent": "Less than a second.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is great news but.",
                    "label": 0
                },
                {
                    "sent": "You ask, can I use this in my own research?",
                    "label": 0
                },
                {
                    "sent": "Is it available?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, and I'm happy to report that yes, it is so one of the things that we're really committed to it will garage is getting open source stuff out there.",
                    "label": 0
                },
                {
                    "sent": "And along with the folks at Freiburg, have actually spearheaded this effort.",
                    "label": 0
                },
                {
                    "sent": "There's a general framework so G2O stands for general graph optimization.",
                    "label": 1
                },
                {
                    "sent": "There's a general framework where you can solve these kinds of factor graphs very efficiently.",
                    "label": 1
                },
                {
                    "sent": "That's out, there is open source.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "It's available as a package, and you can solve many different kinds of problems, including all of the ones that I actually showed you, right?",
                    "label": 0
                },
                {
                    "sent": "So you can solve 2D problems, you can solve 3D problems you can solve.",
                    "label": 0
                },
                {
                    "sent": "Bundle adjustment problems and vision right?",
                    "label": 0
                },
                {
                    "sent": "This is all open available.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately.",
                    "label": 0
                },
                {
                    "sent": "The Jiang results for are from Microsoft and are not available.",
                    "label": 0
                },
                {
                    "sent": "In fact, I couldn't even get the data sets from them from Microsoft.",
                    "label": 0
                },
                {
                    "sent": "Not to worry, we were re implementing those techniques and they also will be available in G2.",
                    "label": 0
                },
                {
                    "sent": "Oh, so all of those.",
                    "label": 0
                },
                {
                    "sent": "Speed UPS will be available.",
                    "label": 0
                },
                {
                    "sent": "Whoops, I only have 5 minutes so I better hurry through some of this.",
                    "label": 0
                },
                {
                    "sent": "I just want to point out some of the structure here.",
                    "label": 0
                },
                {
                    "sent": "The only thing that users actually have to supply to make this stuff work is an error function and an update function and then G2O does all the rest and you can choose some nice things like which one your solver to use for your particular optimization and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK. Actually, I'm almost finished up, so that's pretty good.",
                    "label": 0
                },
                {
                    "sent": "I realize I was I was coming to the end alright, so let me just summarize some of this.",
                    "label": 0
                },
                {
                    "sent": "I've talked about registration and some of the techniques including matching points between images, which turns out to be a fundamental technique and something that we speed it up now so that you can do it in real time.",
                    "label": 0
                },
                {
                    "sent": "I think one of the key techniques is the optimization.",
                    "label": 0
                },
                {
                    "sent": "The fact that we have fast optimization means that we can do a lot of real time registration that we just couldn't do before and we were able to do things like calibrate your robot, keep track of the 3D environment.",
                    "label": 0
                },
                {
                    "sent": "Build an app.",
                    "label": 0
                },
                {
                    "sent": "Now navigate around the world.",
                    "label": 0
                },
                {
                    "sent": "Make models of objects.",
                    "label": 0
                },
                {
                    "sent": "Find those objects.",
                    "label": 0
                },
                {
                    "sent": "Although I didn't really talk about that research and pick.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come up also so I'll end with this.",
                    "label": 0
                },
                {
                    "sent": "Somewhat speeded up video of the.",
                    "label": 0
                },
                {
                    "sent": "PR2 robot fetching beeran.",
                    "label": 0
                },
                {
                    "sent": "In fact there is a.",
                    "label": 0
                },
                {
                    "sent": "There's an actual demonstration of the PR 2 from several different labs out there in the foyer, so you can check for yourself about about the robot.",
                    "label": 1
                },
                {
                    "sent": "Yeah, I know it's it's quite funny in a way, so let me make a few remarks since I still have a few minutes here and just kind of proselytise, especially for open source, I think open source is a wonderful way to push the field along.",
                    "label": 0
                },
                {
                    "sent": "So I've been frustrated many times, especially in doing visual slam work because, you know, people do amazing work, amazing engineering, but it's not available and you have to recreate everything yourself, which holds things back tremendously.",
                    "label": 0
                },
                {
                    "sent": "So currently.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you've seen the skeleton tracking for the connect.",
                    "label": 0
                },
                {
                    "sent": "It's great work by Jamie Shotton from from Microsoft.",
                    "label": 0
                },
                {
                    "sent": "There's a CPR paper.",
                    "label": 0
                },
                {
                    "sent": "The code is not available so we have an intern working on reimplementing that code.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, it's also patented, so even if you reimplement the code, it's not clear you can do all that much with it, but that's just a waste.",
                    "label": 0
                },
                {
                    "sent": "I mean, why?",
                    "label": 0
                },
                {
                    "sent": "Why do we have to spend that kind of intellectual effort to do something like that?",
                    "label": 0
                },
                {
                    "sent": "It's just it just holds you back tremendously.",
                    "label": 0
                },
                {
                    "sent": "So you know the push for open source I think is a really good one.",
                    "label": 0
                },
                {
                    "sent": "I think we should continue continue to do that.",
                    "label": 0
                },
                {
                    "sent": "The other thing I'd like to point out is a lot of the sensing problems.",
                    "label": 0
                },
                {
                    "sent": "There's been tremendous work now, especially with optimization, so that we can solve a lot of these problems.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of engineering work left to do.",
                    "label": 0
                },
                {
                    "sent": "Not quite as much scientific work.",
                    "label": 0
                },
                {
                    "sent": "I think in this field.",
                    "label": 0
                },
                {
                    "sent": "In fact, slam I would be happy to exit the slam area since I've been working on it for the last decade and a half.",
                    "label": 0
                },
                {
                    "sent": "Or something like that, but I think the next big area is going to be in manipulation and sensing right?",
                    "label": 0
                },
                {
                    "sent": "So how do you actually get the robot?",
                    "label": 0
                },
                {
                    "sent": "So our current manipulation is very crude.",
                    "label": 0
                },
                {
                    "sent": "It takes a long time to find to get a plan to actually grasp that object to grasp it well, to pick it up.",
                    "label": 0
                },
                {
                    "sent": "It's hard to place objects down.",
                    "label": 0
                },
                {
                    "sent": "You don't place them very well.",
                    "label": 0
                },
                {
                    "sent": "I think that's going to be the next big area for breakthroughs, and I think a lot of people are going to be working on that now.",
                    "label": 0
                },
                {
                    "sent": "I urge you to look at that.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe not this audience, because I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how many roboticists there are actually in this audience, but I think once that problem gets solved, then a lot of the.",
                    "label": 0
                },
                {
                    "sent": "Things that people here do care about, like higher level cognition are going to be a lot more easy to do task level.",
                    "label": 0
                },
                {
                    "sent": "Objects are going to be a lot easier to do once that problem gets attacked, and pretty much solved.",
                    "label": 0
                },
                {
                    "sent": "OK, I think that's about all I want to say.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you, Kurt.",
                    "label": 0
                },
                {
                    "sent": "Great talking great.",
                    "label": 0
                },
                {
                    "sent": "That's just pressing for open source.",
                    "label": 0
                },
                {
                    "sent": "I have a question about whether more should be done to do monocular processing of images to find things that are relevant to a robot like where the edges of doors are and things you might grab.",
                    "label": 0
                },
                {
                    "sent": "And then you do the matching on those instead of trying to get a completely dense.",
                    "label": 0
                },
                {
                    "sent": "Stereo map of everything.",
                    "label": 0
                },
                {
                    "sent": "So you then project pictures from all all sorts of different views.",
                    "label": 0
                },
                {
                    "sent": "My brain can't do that, I know, but I can very quick workout roughly how far things are in what direction they are, and I think that's because I know if I shut one eye, I go around saying lots and lots of stuff.",
                    "label": 0
                },
                {
                    "sent": "Why can't we do that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, we can't do this right with one eye.",
                    "label": 0
                },
                {
                    "sent": "It's kind of tough, right?",
                    "label": 0
                },
                {
                    "sent": "So don't need that degree of precision for getting close to things and working at roughly where things are right.",
                    "label": 0
                },
                {
                    "sent": "I know I've had to walk around with a Patch on one eye once for several hours, and that was quite illuminating, right?",
                    "label": 0
                },
                {
                    "sent": "And I agree that's true.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can do a lot with monocular vision.",
                    "label": 0
                },
                {
                    "sent": "I think that's good, but it's a handicap, right?",
                    "label": 0
                },
                {
                    "sent": "So Slam work really took off.",
                    "label": 0
                },
                {
                    "sent": "I mean, supposedly we could navigate with a with a single camera, but the slam work really took off when we finally had laser sensors and.",
                    "label": 0
                },
                {
                    "sent": "I don't see any reason not to use sensors that help us as much as they can.",
                    "label": 0
                },
                {
                    "sent": "I mean, we're not limited to using very simple sensors if we don't want to.",
                    "label": 0
                },
                {
                    "sent": "I think I think that as the monocular vision.",
                    "label": 0
                },
                {
                    "sent": "Research progressives will be able to use that more and more, but it's a lot more compute intensive also.",
                    "label": 0
                },
                {
                    "sent": "So eventually I think that'll be much more easy to use.",
                    "label": 0
                },
                {
                    "sent": "But for the current point, from practical point of view, using dense depth information looks like the way to go.",
                    "label": 0
                },
                {
                    "sent": "Sorry, that's just a short answer on that.",
                    "label": 0
                },
                {
                    "sent": "There's a lot more I could say.",
                    "label": 0
                },
                {
                    "sent": "I have a much easier question.",
                    "label": 0
                },
                {
                    "sent": "How did you select the points of interest to begin with?",
                    "label": 0
                },
                {
                    "sent": "So that's key point selection and there's a lot of different ways to do that.",
                    "label": 0
                },
                {
                    "sent": "As you might think that's been worked on for 30 years too, but again, there have been recent methods that have been pretty fast.",
                    "label": 0
                },
                {
                    "sent": "Mostly you look for either blobs or corners.",
                    "label": 0
                },
                {
                    "sent": "Corners.",
                    "label": 0
                },
                {
                    "sent": "Is the Harris detector blobs, or things like Sift uses a blob detector, and most recently there's been a detector called fast from Drummond and Company.",
                    "label": 0
                },
                {
                    "sent": "I think I can't remember actually who did that.",
                    "label": 0
                },
                {
                    "sent": "And it just basically uses very simple decision trees to find corner like objects.",
                    "label": 0
                },
                {
                    "sent": "There are problems with all of the keypoint detectors, and that's a frustrating engineering job to actually get that right, and there's a lot of stuff you could talk about there.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I actually have a question.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, sorry.",
                    "label": 0
                },
                {
                    "sent": "Can you say something about the?",
                    "label": 0
                },
                {
                    "sent": "Environments where there are people and whether this is an issue or you're deliberately not considering it, or you mean dynamic things that might get in the way of reconstruction or registration and so forth.",
                    "label": 0
                },
                {
                    "sent": "So a lot of these techniques are inherently robust to dynamic objects, as long as they don't.",
                    "label": 0
                },
                {
                    "sent": "Take up most of your frame in some way, so the registration techniques get rid of false positives by using geometric checks, and I don't know if you remember from the Oxford scene, but there were people walking in there and the points on the people just got rejected because they weren't consistent with a rigid scene.",
                    "label": 0
                },
                {
                    "sent": "It's a lot harder indoors because people tend to take up larger areas, so that's going to become a more important point.",
                    "label": 0
                },
                {
                    "sent": "And people are going to have to work a little harder, harder to try to get rid of or track people so that they can get rid of.",
                    "label": 0
                },
                {
                    "sent": "The people from the background scene and then actually start tracking them as some separate objects.",
                    "label": 0
                },
                {
                    "sent": "Right, so there's been a lot of recent work in skeleton tracking, and I think that's going to be a very important research area, so if Jamie Shotton's work were available, we have a leg up already, but a lot of people are trying to re implement that and come up with really fast methods for doing skeleton tracking and keeping track of where humans are.",
                    "label": 0
                },
                {
                    "sent": "I think that I think that's are super important area for people to work in for robotics until robots take over and they don't have to look at people anymore and then and then.",
                    "label": 0
                },
                {
                    "sent": "Then we can forget about that.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}