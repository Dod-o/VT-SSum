{
    "id": "3ysm7gi7ot7z25lqmy33f5wx2voi4m5x",
    "title": "Semantic Graphs Derived from Triplets with Application in Document Summarization",
    "info": {
        "author": [
            "Delia Rusu, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Nov. 7, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework",
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Text Mining",
            "Top->Computer Science->Text Mining->Document Summarization",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd08_rusu_sgdt/",
    "segmentation": [
        [
            "So the next presentation is by Delia with soup and it's in the similar line as the previous one.",
            "It also deals with triples, but it goes on how do you generate semantic graphs out from 3 points?",
            "And how can you use that for document summarization?",
            "K thank you, good morning.",
            "So my name is Delia Russo and together with the blush Fortuna Junior and Michael globally we did an application called Semantic graphs derived from triplets and applied to summarizing documents."
        ],
        [
            "I will start with an overview of my presentation.",
            "So a short introduction, then a little bit about how the system pipeline looks like.",
            "An evaluation of the system and in the end there are going to be some conclusion."
        ],
        [
            "So for the introduction, if we have a given document, we perform a set of operations.",
            "The first one is to annotate named entities by named entities.",
            "I mean names of people, places and organisations.",
            "I'm going to explain exactly how how I'm doing this.",
            "Then we are going to extract triplets in the form subject, verb object the same as Lauren told you about.",
            "Then the next step would be to refine these three plots and to obtain a semantic representation.",
            "And in the in the form of a semantic graph.",
            "And as I said, as an application, we present a way to automatically summarize documents.",
            "Based on the semantic graphs we obtained at the previous."
        ],
        [
            "OK, now for the system pipeline.",
            "I'm going to further detail three aspects how to extract name entities and triplets.",
            "How to reach to semantic graphs and how to obtain the."
        ],
        [
            "Document summary OK. As I said, we start with a set of documents."
        ],
        [
            "Let's say we have this long document that we don't have time to."
        ],
        [
            "Just to give you an insight, it's about a raccoon who found its way to a hotel and they didn't know what to do with the recall."
        ],
        [
            "So we keep in mind this document."
        ],
        [
            "Now we want to extract named entity."
        ],
        [
            "These name entities are, as I said in the form of persons, locations and organisations you see highlighted with yellow persons with green locations and with blue organisations.",
            "In the app in the short text."
        ],
        [
            "Showing the slide."
        ],
        [
            "Further on we go to."
        ],
        [
            "Attracting triplets."
        ],
        [
            "OK, now here we have with yellow the subject with green the verb and with blue the object just examplify.",
            "For example hotel have right it's one of the treatments or animals.",
            "Arm something or raccoon causing start.",
            "These are just some examples from that."
        ],
        [
            "Here."
        ],
        [
            "OK. Next, we are going to."
        ],
        [
            "Read the semantic graph.",
            "So here it is.",
            "For example, we see that Alex this is the raccoon Alex presents.",
            "Danger was commissioned by the Hotel staff and has grown up to be a tourist attraction in the almost right of the graph.",
            "Like"
        ],
        [
            "OK."
        ],
        [
            "And as I mentioned, the last step would be to."
        ],
        [
            "Find document summary.",
            "So out of the.",
            "Out of the text we started from, we obtain a number of sentences.",
            "These we can choose how many sentences we wish the the summary to contain."
        ],
        [
            "OK. Now, a little bit of details about how to extract name entities and triplets.",
            "For name entities, again it's people, locations and organisations, and there are two ways to tackle this.",
            "One way would be if we already have the manually annotated using the Reuters data set and another way would be to do it using.",
            "What we did was using gate general architecture for text engineering.",
            "And for three plots we used one parser.",
            "This Stanford parser that generates a treebank output and from there we we extracted triplets using heuristics."
        ],
        [
            "OK, now for semantic graphs.",
            "Here we have a set of operations.",
            "First one would be correct for."
        ],
        [
            "Yes.",
            "What do we understand by this?",
            "If, for example, we have a person that appears in three different ways in our text, for example, our ego, Saatchi Saatchi, and Mr. Saatchi.",
            "Our method can deduce that that is about the same person and that is our ego Sachi."
        ],
        [
            "If we go a step further, we have to solve."
        ],
        [
            "Enough for us.",
            "We solve polynomial enough for us, meaning we find pronouns in the text and we want to match them with the person that that pronoun is referring to.",
            "For example, in the fragment here it's about Jill Gara, a chairman of DHL France, and then for the running the text we have that, he told Reuters something by telephone, so we can.",
            "We can show that he he the pronoun is actually refering to Jill Gara."
        ],
        [
            "OK about semantic normalization.",
            "This helps us building the graph.",
            "It makes it more compact and say we have two sets of triplets.",
            "For example, sediments assumed characteristics and Tokyo Bay built deposit.",
            "Now using word net we see that sediments and deposits belong to the same system and therefore we can merge these two three plugs.",
            "We merge the subject from the first triplet with the objects from the 2nd."
        ],
        [
            "And."
        ],
        [
            "In the end, we obtained the semantic graph.",
            "I showed you a while ago for the for the text with the."
        ],
        [
            "Cool.",
            "OK and finally in this part of the presentation I'm going to explain a little bit about how to obtain summaries.",
            "So we start with the original text and of course the associated."
        ],
        [
            "Semantic graph."
        ],
        [
            "Now we need to extract the set of features."
        ],
        [
            "These features are learning, Ristic document and graph features.",
            "If you wait for the next slide to come, then I will further detail what I mean by linguistic doc you."
        ],
        [
            "Mountain graph sutures.",
            "We see them."
        ],
        [
            "To the linear SVM we obtain a limb."
        ],
        [
            "Your model.",
            "And then the SVN gives us a score.",
            "Now we are going to obtain sentences with a higher score and we showed in the paper that.",
            "This sentence is with a higher score if we order them based on the score.",
            "These are good to go into the summer.",
            "That's how we can create document summaries of.",
            "N number of sentences.",
            "Because we take the topmost and.",
            "Based on this observation, topmost and center."
        ],
        [
            "From the original text."
        ],
        [
            "Now as I as I promised the extracted features.",
            "These are linguistic attributes, so for each triplet element, meaning each subject, verb, object, we extract a series of features.",
            "For example, the linguistic ones are the logical form tag, meaning if it's a subject, verb and object, the treebank tank, the treebank tags, this is the Brown tag.",
            "Then the part of speech.",
            "That's of linguistic, not how how deep it is in the in the parse tree and tags for named entities.",
            "For example, if it's a location.",
            "If it's a location, then if it's a city or a country, and so on.",
            "Now about document attributes.",
            "There are sentence related where is the sentence located within within the document or triplet related?",
            "How frequent is that three plot in in the centers or in the document and so on?",
            "And about graph attributes we have, we compute authoritie hub weight page rank, no degree size of connected component."
        ],
        [
            "And so.",
            "Here I showed the most important features, so the top are the object, the subject and the verb.",
            "Actually, the words representing the object, subject and verb, and then we have location of sentence in document and so on.",
            "This is a ranking based on information gain obtained with Becca."
        ],
        [
            "In this slide, we show a difference between human extracted document summary and an automatic document summary with bold and italic, I highlighted the sentences that are the same in each in the two in the two summaries, so there are in total 7 sentences in this document and four in the summer.",
            "Excuse me and four out of them match both in the human and in the automatic.",
            "Automatically created summary."
        ],
        [
            "OK, the next step would be to show some."
        ],
        [
            "Evaluation results.",
            "About gender retrieval, we compared our system with a baseline that associated masculine gender to all the name entities that were labeled as persons.",
            "Of course it's 100% for masculine, as you can see in the bottom left cell, but for feminine it doesn't.",
            "It doesn't give any.",
            "Any results?",
            "OK."
        ],
        [
            "For Coreference resolution, we compared our system with gate.",
            "It also gate also has disc reference resolver and our system did a little bit better than gate when solving coreference."
        ],
        [
            "For in a forum we had a random set of 77 documents and we compared the system with the baseline gender, meaning it takes the closest name entity.",
            "As a pronoun replacement, but it takes into account agenda.",
            "Or baseline, no gender.",
            "If we dis considered."
        ],
        [
            "Gender completely.",
            "And here are the results for he our system does does quite well compared to the baseline gender and baseline.",
            "No gender.",
            "For a day and I then we have the results and so on.",
            "So yeah, for the pronouns, we only select a subset of pronouns so we don't deal with exhaustively all problems.",
            "This is the subset he they, I, she who eat.",
            "And for other person for other pronouns who just.",
            "Label them as ever."
        ],
        [
            "And to conclude, evaluation about how we evaluated the document summaries that we obtained, we had two datasets that Duke 2002 datasets and do 2007 datasets associated to a specific task.",
            "The first one was to summarize a single newspaper article in the 2002, whereas in the Duke 2007 there were two tasks.",
            "We chose the update task and.",
            "We took a subset of this task mainly to summarize documents in a given cluster.",
            "Just to mention the training data used for the 2007 task was the data from 2002 and the 2007 main tasks, so this is the other task I was mention."
        ],
        [
            "King OK, these are the results for the 2002 task.",
            "This was compared to the results obtained in another paper presented by US cover.",
            "And you can see the results are quite similar."
        ],
        [
            "And for the 2007.",
            "We have a series of 25 systems that we compare the results with.",
            "And our system ranks 17 based on Rouge.",
            "Two evaluation results rushed.",
            "This Rouge is an automatic evaluator for summaries and two because it takes big RAM."
        ],
        [
            "And for another evaluation Rouge SUV for this time we again compare with other systems that participated in the task.",
            "OK."
        ],
        [
            "So to conclude, represented a way of generating semantic graphs based on the document and also an application to semantic graphs which is automatically generating summaries by extracting sentences from the original text as future work.",
            "This system can be integrated with, for example, online news crawlers or adding a complex ontology to it just to.",
            "I have a brother picture of.",
            "What kind of summer is because?"
        ],
        [
            "Update.",
            "OK, so that was my presentation.",
            "Thank you and if you have any questions or remarks or.",
            "Motivation so we only you had much less training data then yeah so.",
            "Both of us lots of trouble properties.",
            "We don't know exactly what the others used as training data.",
            "It doesn't say so we just had some available data from previous tasks.",
            "And.",
            "We said, OK, let's try with this and see what we see what we obtained.",
            "OK. Any other basically?",
            "You can't use your system without having a parser.",
            "Yeah, so this is what we are working on.",
            "We would like to know so my colleague who presented the presentation before.",
            "Is trying to see if indeed this parser is necessary or we can just use the tags and if we have this tagging from there we can extract triplets without having anything to do with the parser and so on.",
            "But this is just.",
            "Research so I can say for I can't say for sure if we definitely need the parser or if tagging is enough.",
            "In this case you have this logical.",
            "Something beautiful.",
            "Then you need the module that look attached those types.",
            "And yes, we need.",
            "We need tagging.",
            "We need tagging.",
            "Yeah, but so we don't have to do parsing in order to obtain these tags.",
            "We can just use a tagger and then we have the text.",
            "But we yeah.",
            "I get first day they take, they could take the document with text like work.",
            "Now it's alright this is not subject object.",
            "This is work now and then they would.",
            "They train SVM, and SVM tells them what is.",
            "The correct triple.",
            "So that was previously.",
            "Yeah, that was, that was.",
            "Presentation, it seems to me that they don't really need the party, but I'm not sure if this is, but yeah, this is.",
            "This is what.",
            "Statistical parsing.",
            "Yeah, so right now.",
            "Right now it's statistical parsing because of Stanford parser.",
            "OK, so the the parser used here is the same that previous presentation was showing in the results open.",
            "Now this is another part, so this is Stanford parser so.",
            "The other one was open and NP parser, so there were a series of parsers used and we just selected one of them to go forward and apply the whole pipeline for the because if that would be the same one from the results and previous presentation we could see how well that this context plus part of speech tagging in extracting triples compares with the parser without any learning.",
            "If it's compatible, then we could.",
            "Assume that it's really you can do without person, yeah, but we we can have a little bit of an idea because the output is quite similar, so both of them use these three bank representation.",
            "And aside from some very small differences, the output is essentially the same, so that's why I said that it might be the from what land is researching, we might end up to the conclusion that we don't really need the whole parsing because that's like takes time and it's like.",
            "The most most bottleneck.",
            "And can repeat the same summarization exactly just with other 3 + 3 plus which are learned from context and participate exactly and then see how the how, how well it works in the application of documents.",
            "Images should be very interesting.",
            "Also I guess languages yeah it will be faster because the the parser is actually the bottleneck.",
            "That makes it slower.",
            "Yeah, yeah.",
            "So we also had.",
            "I was at some conference or semantic there pretty simply and I had questions when I was discussing that work we have here.",
            "I had a question so it can be just, you know how fast is that?",
            "What is the?",
            "Yeah, you know what is the bottleneck?",
            "There can be just send you a bunch of sentences how quickly you can do summaries, how quickly you can give us graphs.",
            "So that would be useful.",
            "But the other thing that could be useful will have a presentation last presentation just before lunch is all this is all in English.",
            "So it's on having some other languages, and for Slovenian we have a part of speech tagger.",
            "And then we can do the next experiment would be also connected to that takes convenient text, take part of speech tagger for Sophia, and try this summer.",
            "Is there an yesterday there was on the conference there was creation, part of speech tagger.",
            "So the next step would be take.",
            "Things out of there and then trying on creation so to try to make this document summary language independent language independent.",
            "Language dependent part exactly what needs to be provided.",
            "Yeah, I just want to point out this document summarizes summarizer.",
            "Let's say you can give it a row text and it can show what I previously showed on the slides.",
            "So how to extract name entities like I already extracted them?",
            "Because it takes a little bit of time or how to get triplets out of the document, and finally, how to summarize the document and for a given document.",
            "The output the semantic graph would be something like this.",
            "You mentioned in your talking that you are marking only named entities or locations versus an open exactly.",
            "You have finer grain.",
            "Locations between something like cities.",
            "Yeah, I subdivide so for that information.",
            "Yeah from gate it has a set of gazetteers and.",
            "OK, slow.",
            "Get this low indeed.",
            "Yeah.",
            "No, no, actually actually.",
            "The parser is the bottleneck, it's.",
            "So this is yeah, gay.",
            "This Skype is quite fast compared to the parser.",
            "Yeah, parser is even slower.",
            "Mostly sorry just if the sentence is huge then it just.",
            "Yeah.",
            "Junkers are quite fast, yeah.",
            "Congressman information yeah.",
            "Something like another language is not English but Selena.",
            "Get information.",
            "Yep.",
            "It will be.",
            "Information that you can.",
            "Real life.",
            "?, thank you, say thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the next presentation is by Delia with soup and it's in the similar line as the previous one.",
                    "label": 0
                },
                {
                    "sent": "It also deals with triples, but it goes on how do you generate semantic graphs out from 3 points?",
                    "label": 0
                },
                {
                    "sent": "And how can you use that for document summarization?",
                    "label": 0
                },
                {
                    "sent": "K thank you, good morning.",
                    "label": 0
                },
                {
                    "sent": "So my name is Delia Russo and together with the blush Fortuna Junior and Michael globally we did an application called Semantic graphs derived from triplets and applied to summarizing documents.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will start with an overview of my presentation.",
                    "label": 0
                },
                {
                    "sent": "So a short introduction, then a little bit about how the system pipeline looks like.",
                    "label": 1
                },
                {
                    "sent": "An evaluation of the system and in the end there are going to be some conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the introduction, if we have a given document, we perform a set of operations.",
                    "label": 0
                },
                {
                    "sent": "The first one is to annotate named entities by named entities.",
                    "label": 1
                },
                {
                    "sent": "I mean names of people, places and organisations.",
                    "label": 1
                },
                {
                    "sent": "I'm going to explain exactly how how I'm doing this.",
                    "label": 0
                },
                {
                    "sent": "Then we are going to extract triplets in the form subject, verb object the same as Lauren told you about.",
                    "label": 1
                },
                {
                    "sent": "Then the next step would be to refine these three plots and to obtain a semantic representation.",
                    "label": 0
                },
                {
                    "sent": "And in the in the form of a semantic graph.",
                    "label": 1
                },
                {
                    "sent": "And as I said, as an application, we present a way to automatically summarize documents.",
                    "label": 0
                },
                {
                    "sent": "Based on the semantic graphs we obtained at the previous.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now for the system pipeline.",
                    "label": 1
                },
                {
                    "sent": "I'm going to further detail three aspects how to extract name entities and triplets.",
                    "label": 1
                },
                {
                    "sent": "How to reach to semantic graphs and how to obtain the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Document summary OK. As I said, we start with a set of documents.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say we have this long document that we don't have time to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to give you an insight, it's about a raccoon who found its way to a hotel and they didn't know what to do with the recall.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we keep in mind this document.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we want to extract named entity.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These name entities are, as I said in the form of persons, locations and organisations you see highlighted with yellow persons with green locations and with blue organisations.",
                    "label": 0
                },
                {
                    "sent": "In the app in the short text.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Showing the slide.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Further on we go to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Attracting triplets.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now here we have with yellow the subject with green the verb and with blue the object just examplify.",
                    "label": 0
                },
                {
                    "sent": "For example hotel have right it's one of the treatments or animals.",
                    "label": 0
                },
                {
                    "sent": "Arm something or raccoon causing start.",
                    "label": 0
                },
                {
                    "sent": "These are just some examples from that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Next, we are going to.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Read the semantic graph.",
                    "label": 0
                },
                {
                    "sent": "So here it is.",
                    "label": 0
                },
                {
                    "sent": "For example, we see that Alex this is the raccoon Alex presents.",
                    "label": 0
                },
                {
                    "sent": "Danger was commissioned by the Hotel staff and has grown up to be a tourist attraction in the almost right of the graph.",
                    "label": 0
                },
                {
                    "sent": "Like",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I mentioned, the last step would be to.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find document summary.",
                    "label": 0
                },
                {
                    "sent": "So out of the.",
                    "label": 0
                },
                {
                    "sent": "Out of the text we started from, we obtain a number of sentences.",
                    "label": 0
                },
                {
                    "sent": "These we can choose how many sentences we wish the the summary to contain.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Now, a little bit of details about how to extract name entities and triplets.",
                    "label": 0
                },
                {
                    "sent": "For name entities, again it's people, locations and organisations, and there are two ways to tackle this.",
                    "label": 0
                },
                {
                    "sent": "One way would be if we already have the manually annotated using the Reuters data set and another way would be to do it using.",
                    "label": 0
                },
                {
                    "sent": "What we did was using gate general architecture for text engineering.",
                    "label": 0
                },
                {
                    "sent": "And for three plots we used one parser.",
                    "label": 0
                },
                {
                    "sent": "This Stanford parser that generates a treebank output and from there we we extracted triplets using heuristics.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now for semantic graphs.",
                    "label": 0
                },
                {
                    "sent": "Here we have a set of operations.",
                    "label": 0
                },
                {
                    "sent": "First one would be correct for.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What do we understand by this?",
                    "label": 0
                },
                {
                    "sent": "If, for example, we have a person that appears in three different ways in our text, for example, our ego, Saatchi Saatchi, and Mr. Saatchi.",
                    "label": 0
                },
                {
                    "sent": "Our method can deduce that that is about the same person and that is our ego Sachi.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we go a step further, we have to solve.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Enough for us.",
                    "label": 0
                },
                {
                    "sent": "We solve polynomial enough for us, meaning we find pronouns in the text and we want to match them with the person that that pronoun is referring to.",
                    "label": 0
                },
                {
                    "sent": "For example, in the fragment here it's about Jill Gara, a chairman of DHL France, and then for the running the text we have that, he told Reuters something by telephone, so we can.",
                    "label": 0
                },
                {
                    "sent": "We can show that he he the pronoun is actually refering to Jill Gara.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK about semantic normalization.",
                    "label": 0
                },
                {
                    "sent": "This helps us building the graph.",
                    "label": 0
                },
                {
                    "sent": "It makes it more compact and say we have two sets of triplets.",
                    "label": 0
                },
                {
                    "sent": "For example, sediments assumed characteristics and Tokyo Bay built deposit.",
                    "label": 0
                },
                {
                    "sent": "Now using word net we see that sediments and deposits belong to the same system and therefore we can merge these two three plugs.",
                    "label": 0
                },
                {
                    "sent": "We merge the subject from the first triplet with the objects from the 2nd.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the end, we obtained the semantic graph.",
                    "label": 0
                },
                {
                    "sent": "I showed you a while ago for the for the text with the.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cool.",
                    "label": 0
                },
                {
                    "sent": "OK and finally in this part of the presentation I'm going to explain a little bit about how to obtain summaries.",
                    "label": 0
                },
                {
                    "sent": "So we start with the original text and of course the associated.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Semantic graph.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we need to extract the set of features.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These features are learning, Ristic document and graph features.",
                    "label": 0
                },
                {
                    "sent": "If you wait for the next slide to come, then I will further detail what I mean by linguistic doc you.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mountain graph sutures.",
                    "label": 0
                },
                {
                    "sent": "We see them.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the linear SVM we obtain a limb.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your model.",
                    "label": 0
                },
                {
                    "sent": "And then the SVN gives us a score.",
                    "label": 0
                },
                {
                    "sent": "Now we are going to obtain sentences with a higher score and we showed in the paper that.",
                    "label": 0
                },
                {
                    "sent": "This sentence is with a higher score if we order them based on the score.",
                    "label": 0
                },
                {
                    "sent": "These are good to go into the summer.",
                    "label": 0
                },
                {
                    "sent": "That's how we can create document summaries of.",
                    "label": 0
                },
                {
                    "sent": "N number of sentences.",
                    "label": 0
                },
                {
                    "sent": "Because we take the topmost and.",
                    "label": 0
                },
                {
                    "sent": "Based on this observation, topmost and center.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the original text.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now as I as I promised the extracted features.",
                    "label": 0
                },
                {
                    "sent": "These are linguistic attributes, so for each triplet element, meaning each subject, verb, object, we extract a series of features.",
                    "label": 1
                },
                {
                    "sent": "For example, the linguistic ones are the logical form tag, meaning if it's a subject, verb and object, the treebank tank, the treebank tags, this is the Brown tag.",
                    "label": 0
                },
                {
                    "sent": "Then the part of speech.",
                    "label": 0
                },
                {
                    "sent": "That's of linguistic, not how how deep it is in the in the parse tree and tags for named entities.",
                    "label": 0
                },
                {
                    "sent": "For example, if it's a location.",
                    "label": 0
                },
                {
                    "sent": "If it's a location, then if it's a city or a country, and so on.",
                    "label": 0
                },
                {
                    "sent": "Now about document attributes.",
                    "label": 0
                },
                {
                    "sent": "There are sentence related where is the sentence located within within the document or triplet related?",
                    "label": 0
                },
                {
                    "sent": "How frequent is that three plot in in the centers or in the document and so on?",
                    "label": 0
                },
                {
                    "sent": "And about graph attributes we have, we compute authoritie hub weight page rank, no degree size of connected component.",
                    "label": 1
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Here I showed the most important features, so the top are the object, the subject and the verb.",
                    "label": 0
                },
                {
                    "sent": "Actually, the words representing the object, subject and verb, and then we have location of sentence in document and so on.",
                    "label": 1
                },
                {
                    "sent": "This is a ranking based on information gain obtained with Becca.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this slide, we show a difference between human extracted document summary and an automatic document summary with bold and italic, I highlighted the sentences that are the same in each in the two in the two summaries, so there are in total 7 sentences in this document and four in the summer.",
                    "label": 0
                },
                {
                    "sent": "Excuse me and four out of them match both in the human and in the automatic.",
                    "label": 0
                },
                {
                    "sent": "Automatically created summary.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, the next step would be to show some.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evaluation results.",
                    "label": 0
                },
                {
                    "sent": "About gender retrieval, we compared our system with a baseline that associated masculine gender to all the name entities that were labeled as persons.",
                    "label": 1
                },
                {
                    "sent": "Of course it's 100% for masculine, as you can see in the bottom left cell, but for feminine it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't give any.",
                    "label": 0
                },
                {
                    "sent": "Any results?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For Coreference resolution, we compared our system with gate.",
                    "label": 0
                },
                {
                    "sent": "It also gate also has disc reference resolver and our system did a little bit better than gate when solving coreference.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For in a forum we had a random set of 77 documents and we compared the system with the baseline gender, meaning it takes the closest name entity.",
                    "label": 0
                },
                {
                    "sent": "As a pronoun replacement, but it takes into account agenda.",
                    "label": 0
                },
                {
                    "sent": "Or baseline, no gender.",
                    "label": 0
                },
                {
                    "sent": "If we dis considered.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gender completely.",
                    "label": 0
                },
                {
                    "sent": "And here are the results for he our system does does quite well compared to the baseline gender and baseline.",
                    "label": 0
                },
                {
                    "sent": "No gender.",
                    "label": 0
                },
                {
                    "sent": "For a day and I then we have the results and so on.",
                    "label": 0
                },
                {
                    "sent": "So yeah, for the pronouns, we only select a subset of pronouns so we don't deal with exhaustively all problems.",
                    "label": 0
                },
                {
                    "sent": "This is the subset he they, I, she who eat.",
                    "label": 0
                },
                {
                    "sent": "And for other person for other pronouns who just.",
                    "label": 0
                },
                {
                    "sent": "Label them as ever.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to conclude, evaluation about how we evaluated the document summaries that we obtained, we had two datasets that Duke 2002 datasets and do 2007 datasets associated to a specific task.",
                    "label": 0
                },
                {
                    "sent": "The first one was to summarize a single newspaper article in the 2002, whereas in the Duke 2007 there were two tasks.",
                    "label": 0
                },
                {
                    "sent": "We chose the update task and.",
                    "label": 0
                },
                {
                    "sent": "We took a subset of this task mainly to summarize documents in a given cluster.",
                    "label": 0
                },
                {
                    "sent": "Just to mention the training data used for the 2007 task was the data from 2002 and the 2007 main tasks, so this is the other task I was mention.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "King OK, these are the results for the 2002 task.",
                    "label": 0
                },
                {
                    "sent": "This was compared to the results obtained in another paper presented by US cover.",
                    "label": 0
                },
                {
                    "sent": "And you can see the results are quite similar.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the 2007.",
                    "label": 0
                },
                {
                    "sent": "We have a series of 25 systems that we compare the results with.",
                    "label": 0
                },
                {
                    "sent": "And our system ranks 17 based on Rouge.",
                    "label": 0
                },
                {
                    "sent": "Two evaluation results rushed.",
                    "label": 0
                },
                {
                    "sent": "This Rouge is an automatic evaluator for summaries and two because it takes big RAM.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for another evaluation Rouge SUV for this time we again compare with other systems that participated in the task.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude, represented a way of generating semantic graphs based on the document and also an application to semantic graphs which is automatically generating summaries by extracting sentences from the original text as future work.",
                    "label": 0
                },
                {
                    "sent": "This system can be integrated with, for example, online news crawlers or adding a complex ontology to it just to.",
                    "label": 0
                },
                {
                    "sent": "I have a brother picture of.",
                    "label": 0
                },
                {
                    "sent": "What kind of summer is because?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Update.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was my presentation.",
                    "label": 0
                },
                {
                    "sent": "Thank you and if you have any questions or remarks or.",
                    "label": 0
                },
                {
                    "sent": "Motivation so we only you had much less training data then yeah so.",
                    "label": 0
                },
                {
                    "sent": "Both of us lots of trouble properties.",
                    "label": 0
                },
                {
                    "sent": "We don't know exactly what the others used as training data.",
                    "label": 0
                },
                {
                    "sent": "It doesn't say so we just had some available data from previous tasks.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We said, OK, let's try with this and see what we see what we obtained.",
                    "label": 0
                },
                {
                    "sent": "OK. Any other basically?",
                    "label": 0
                },
                {
                    "sent": "You can't use your system without having a parser.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is what we are working on.",
                    "label": 0
                },
                {
                    "sent": "We would like to know so my colleague who presented the presentation before.",
                    "label": 0
                },
                {
                    "sent": "Is trying to see if indeed this parser is necessary or we can just use the tags and if we have this tagging from there we can extract triplets without having anything to do with the parser and so on.",
                    "label": 0
                },
                {
                    "sent": "But this is just.",
                    "label": 0
                },
                {
                    "sent": "Research so I can say for I can't say for sure if we definitely need the parser or if tagging is enough.",
                    "label": 0
                },
                {
                    "sent": "In this case you have this logical.",
                    "label": 0
                },
                {
                    "sent": "Something beautiful.",
                    "label": 0
                },
                {
                    "sent": "Then you need the module that look attached those types.",
                    "label": 0
                },
                {
                    "sent": "And yes, we need.",
                    "label": 0
                },
                {
                    "sent": "We need tagging.",
                    "label": 0
                },
                {
                    "sent": "We need tagging.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but so we don't have to do parsing in order to obtain these tags.",
                    "label": 0
                },
                {
                    "sent": "We can just use a tagger and then we have the text.",
                    "label": 0
                },
                {
                    "sent": "But we yeah.",
                    "label": 0
                },
                {
                    "sent": "I get first day they take, they could take the document with text like work.",
                    "label": 0
                },
                {
                    "sent": "Now it's alright this is not subject object.",
                    "label": 0
                },
                {
                    "sent": "This is work now and then they would.",
                    "label": 0
                },
                {
                    "sent": "They train SVM, and SVM tells them what is.",
                    "label": 0
                },
                {
                    "sent": "The correct triple.",
                    "label": 0
                },
                {
                    "sent": "So that was previously.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that was, that was.",
                    "label": 0
                },
                {
                    "sent": "Presentation, it seems to me that they don't really need the party, but I'm not sure if this is, but yeah, this is.",
                    "label": 0
                },
                {
                    "sent": "This is what.",
                    "label": 0
                },
                {
                    "sent": "Statistical parsing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so right now.",
                    "label": 0
                },
                {
                    "sent": "Right now it's statistical parsing because of Stanford parser.",
                    "label": 0
                },
                {
                    "sent": "OK, so the the parser used here is the same that previous presentation was showing in the results open.",
                    "label": 0
                },
                {
                    "sent": "Now this is another part, so this is Stanford parser so.",
                    "label": 0
                },
                {
                    "sent": "The other one was open and NP parser, so there were a series of parsers used and we just selected one of them to go forward and apply the whole pipeline for the because if that would be the same one from the results and previous presentation we could see how well that this context plus part of speech tagging in extracting triples compares with the parser without any learning.",
                    "label": 0
                },
                {
                    "sent": "If it's compatible, then we could.",
                    "label": 0
                },
                {
                    "sent": "Assume that it's really you can do without person, yeah, but we we can have a little bit of an idea because the output is quite similar, so both of them use these three bank representation.",
                    "label": 0
                },
                {
                    "sent": "And aside from some very small differences, the output is essentially the same, so that's why I said that it might be the from what land is researching, we might end up to the conclusion that we don't really need the whole parsing because that's like takes time and it's like.",
                    "label": 0
                },
                {
                    "sent": "The most most bottleneck.",
                    "label": 0
                },
                {
                    "sent": "And can repeat the same summarization exactly just with other 3 + 3 plus which are learned from context and participate exactly and then see how the how, how well it works in the application of documents.",
                    "label": 0
                },
                {
                    "sent": "Images should be very interesting.",
                    "label": 0
                },
                {
                    "sent": "Also I guess languages yeah it will be faster because the the parser is actually the bottleneck.",
                    "label": 0
                },
                {
                    "sent": "That makes it slower.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So we also had.",
                    "label": 0
                },
                {
                    "sent": "I was at some conference or semantic there pretty simply and I had questions when I was discussing that work we have here.",
                    "label": 0
                },
                {
                    "sent": "I had a question so it can be just, you know how fast is that?",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "Yeah, you know what is the bottleneck?",
                    "label": 0
                },
                {
                    "sent": "There can be just send you a bunch of sentences how quickly you can do summaries, how quickly you can give us graphs.",
                    "label": 0
                },
                {
                    "sent": "So that would be useful.",
                    "label": 0
                },
                {
                    "sent": "But the other thing that could be useful will have a presentation last presentation just before lunch is all this is all in English.",
                    "label": 0
                },
                {
                    "sent": "So it's on having some other languages, and for Slovenian we have a part of speech tagger.",
                    "label": 0
                },
                {
                    "sent": "And then we can do the next experiment would be also connected to that takes convenient text, take part of speech tagger for Sophia, and try this summer.",
                    "label": 0
                },
                {
                    "sent": "Is there an yesterday there was on the conference there was creation, part of speech tagger.",
                    "label": 0
                },
                {
                    "sent": "So the next step would be take.",
                    "label": 0
                },
                {
                    "sent": "Things out of there and then trying on creation so to try to make this document summary language independent language independent.",
                    "label": 1
                },
                {
                    "sent": "Language dependent part exactly what needs to be provided.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I just want to point out this document summarizes summarizer.",
                    "label": 0
                },
                {
                    "sent": "Let's say you can give it a row text and it can show what I previously showed on the slides.",
                    "label": 0
                },
                {
                    "sent": "So how to extract name entities like I already extracted them?",
                    "label": 0
                },
                {
                    "sent": "Because it takes a little bit of time or how to get triplets out of the document, and finally, how to summarize the document and for a given document.",
                    "label": 0
                },
                {
                    "sent": "The output the semantic graph would be something like this.",
                    "label": 1
                },
                {
                    "sent": "You mentioned in your talking that you are marking only named entities or locations versus an open exactly.",
                    "label": 0
                },
                {
                    "sent": "You have finer grain.",
                    "label": 0
                },
                {
                    "sent": "Locations between something like cities.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I subdivide so for that information.",
                    "label": 0
                },
                {
                    "sent": "Yeah from gate it has a set of gazetteers and.",
                    "label": 0
                },
                {
                    "sent": "OK, slow.",
                    "label": 0
                },
                {
                    "sent": "Get this low indeed.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "No, no, actually actually.",
                    "label": 0
                },
                {
                    "sent": "The parser is the bottleneck, it's.",
                    "label": 0
                },
                {
                    "sent": "So this is yeah, gay.",
                    "label": 0
                },
                {
                    "sent": "This Skype is quite fast compared to the parser.",
                    "label": 0
                },
                {
                    "sent": "Yeah, parser is even slower.",
                    "label": 0
                },
                {
                    "sent": "Mostly sorry just if the sentence is huge then it just.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Junkers are quite fast, yeah.",
                    "label": 0
                },
                {
                    "sent": "Congressman information yeah.",
                    "label": 0
                },
                {
                    "sent": "Something like another language is not English but Selena.",
                    "label": 0
                },
                {
                    "sent": "Get information.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "It will be.",
                    "label": 0
                },
                {
                    "sent": "Information that you can.",
                    "label": 0
                },
                {
                    "sent": "Real life.",
                    "label": 0
                },
                {
                    "sent": "?, thank you, say thank you.",
                    "label": 0
                }
            ]
        }
    }
}