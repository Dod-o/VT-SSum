{
    "id": "luydvcws4ly5j6rprjizexqq5f6yzxso",
    "title": "Optimization I",
    "info": {
        "author": [
            "Jimmy Ba, Department of Computer Science, University of Toronto"
        ],
        "published": "Oct. 11, 2018",
        "recorded": "July 2018",
        "category": [
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning"
        ]
    },
    "url": "http://videolectures.net/DLRLsummerschool2018_ba_optimization1/",
    "segmentation": [
        [
            "And then we're going to talk about how we can actually find better."
        ],
        [
            "Directions by taking consideration of the curvature informations from 2nd order statistics and in the end I'm going to talk about how we can design what I called up white box optimization algorithm that just doesn't only look at the creating information but also consider the computation graphs that use the computer gradient."
        ],
        [
            "OK, so so this is just a initial site for your networks just to make everything concrete, let's consider you know we have pairs of input output X&Y, draw from a training set of data points, right?",
            "So no network, surprised functional Maps that Maps the X to Y, parameterized by set of weights W, and in this talk we're going to consider Delta is drawing from this wave space of dimension.",
            "And once we have our prediction from the model, we can compute a loss function by comparing our prediction with the correct answer, right?",
            "So with this defined larger L under the current data points and the current weights.",
            "So, and we're gonna use this shorthand notation to denote the average loss for every data point.",
            "So we're just going to use the subscript under the loss function.",
            "Help particular points."
        ],
        [
            "So.",
            "Why is learning deep neural networks hard?",
            "So first of all, networks are not convex, right?",
            "So what is convex?",
            "So the notion of convexity comes from the state areas where you consider, well, you have sort of convex points.",
            "What that really means is you have if you draw a line between any of those two points gained a convex set the any points along the line should also fall into the same set, and in the second example on the right hand side that is an example of non convex set.",
            "Right, and how we generalize this notion through function real valued functions?",
            "Is our consider the two inputs to a function that Maps a vector to a real?",
            "Imagine that's a loss function.",
            "And convex function will have the property that the average of the data points is going to be higher than the functional form of the average point, right?",
            "So and the example of non convex function is the one on the right.",
            "So.",
            "So unfortunately, in deep learning our models and loss of extremely non convex so we have many local optimums and if you believe the.",
            "The urban myth.",
            "30 years ago we will think well if learning those new networks is just completely hopeless because you're going to stuck in those sub optimal points.",
            "Then we're going to see some expansion results to show how that's not the case, and we still don't really understand what's going on."
        ],
        [
            "The second point, that learning is very difficult is that neural networks are not very smooth.",
            "So we can probably quantify the smoothness through the notion of Lipschitz continuous.",
            "So the intuition behind the Lipschitz continuity is that you would like to bound the variability of a function.",
            "So thinking about like you know if the Lipschitz constant is small, then the function will not vary a lot an or in other words, the maybe you can think of locali the gradient of the function with respect to the input.",
            "In this case the parameters W is going to be very small, right?",
            "So if you move?",
            "The right hand side through the left side and take the input capital step between WW prime you'll get the gradient, so domains the normal gradient is bounded approximately and an example of non Lipschitz continuous function is the exponential function, right?",
            "So in your network, so you can imagine when you parameterise the variance of normal distribution, that's what that's a typical privatisation we use in.",
            "The model is very small.",
            "Encoders that actually introduced none left smoothness to our model.",
            "So you know a lot of new numbers we use in practice are actually very very much non smooth and another way to think about them is if you have a relative neural networks.",
            "Albert really blow up the weights in the first layer and by a factor of Alpha and then shrink the weights in the next layer by a factor of 1 over Alpha.",
            "Imagine there's no bias units on your networks.",
            "You still parameterized very much the same function.",
            "However, the gradient of the second layer is going to be now Alpha times larger than the previous previous prioritization, even though their parameters in exact same functional so.",
            "Yeah, so the new one.",
            "I was not very smooth.",
            "So the the Lipschitz constant, so, so yes.",
            "So you still have a concept, but then under different parameterisation, the constants different.",
            "Right?",
            "Even though the the parameterized function is exactly the same.",
            "Definition of.",
            "Sure, yes.",
            "Right, yeah, right.",
            "Um?"
        ],
        [
            "So and the Third Point, I'm just learning how it's difficult is because.",
            "The networks has millions of parameters, so if you think about the most recent widely used models in image recognitions, those multiply 5 million parameters in your neural machine translation.",
            "Those are models, typically in the order of hundreds millions of parameters and Alpha goes about 50 parameters.",
            "In my rough back to the envelope calculation.",
            "So not only the the objective function will optimize is not very nice and also the model has a lot of.",
            "Tunable knobs"
        ],
        [
            "So.",
            "How can we actually train on your network so in the.",
            "I just like to, you know, ask you guys to think about just simply thought process.",
            "So here I present an algorithm where we start with the neural networks that parameters by sort of weights and we generate a random vector called Delta W that can be drawn from a Gaussian distribution or something.",
            "So we're going to evaluate the neural network prediction after this perturbation over the entire training set.",
            "And then we're going to compute average loss.",
            "For the perturbed neural networks.",
            "An if the perturbed new hours loss is improved over the previous non preferred version, we're going to keep the perturbation.",
            "Otherwise we have discussed this perturbation.",
            "So the algorithm is very inefficient.",
            "However, we guarantee that every time we update, our weights were going to make an improvement on the last function.",
            "Um?"
        ],
        [
            "So how can we actually make this algorithm cited more practical?",
            "Um?",
            "We can think about, well, we're going to draw not just any random vector, but a random vector from a Gaussian distribution with zero main and with some traffic covariance matrix.",
            "And instead of discarding the data point that doesn't make any improvement, we're going to keep the data that we're going to keep the perturbation and add them to my weights, except which way they're going to be weighted by the negative of the loss function.",
            "So it's immediately.",
            "It's not very clear how this will converge and even decrease loss function overtime.",
            "However, you can derive this from the.",
            "Optimization point of view, which which is similar in spirit as reinforce algorithm.",
            "This is, it turns out to be giving you a unbiased estimate, although very noisy, of the underlying grading information."
        ],
        [
            "So we can probably improve this algorithm started even further.",
            "Where instead of just drawing a single data instead of updating our weights using a single perturbation.",
            "Now we can consider both the positive sign of the perturbation and also the negative part of perturbation.",
            "So if you look at this new update rule here.",
            "It actually looks a lot like some sort of finite difference.",
            "And so this can I give you some intuition.",
            "OK, maybe this album is going to be starting more efficient, because now we know.",
            "Well, given the both deposit perturbation and negative perturbation, how much my function is going to change and I'll probably give me a more accurate estimate of how I should improve the loss function with respect to the random perturbation direction.",
            "And now here we also just join with join M samples for the random perturbation.",
            "Break."
        ],
        [
            "So this kind of algorithm is often called, you know, have many names in reinforcement learning is called evolution strategy and also be called like 0 order method because doesn't use any written information order free methods.",
            "So to get intuition how this method actually work in practice?",
            "Well, first look at some of the set of experiments with that for actually one of our flip paper.",
            "So that was a paper we submit to die clear.",
            "So we run this algorithm on MNIST model was 500 hidden units each.",
            "There are two hidden layer.",
            "When comparing this with a just normal backpropagation algorithm that's highlighted in the red.",
            "Turned out that you know if we draw enough samples to estimate those gradients, we actually can get more or less the same convergence as a stochastic gradient descent methods, and this seems a bit counterintuitive.",
            "I'll explain more the technical details later, the convergence rate and things like that.",
            "But the takeaway message here is that we would think the random perturbation method may may seem a bit naive and impractical.",
            "But if you can draw for like 5000 data points, 5000 samples way estimating those derivative free methods and turned out it actually works quite well.",
            "So if I only look at this graph, it spelled misleading because the X axis is the number of updates that does not consider the computation time we used to estimate the update for those evolution strategy method versus the grand dissent.",
            "So now we can actually look into like a more QD examples to get more intuition of what's going on here."
        ],
        [
            "So in those new order method.",
            "Given the current parameters.",
            "W not what happened is that we're going to randomly sample a few points from the neighborhood under the current solution.",
            "And then we're going to use that to compute the aggregated search direction.",
            "Here the random perturbation draw from a random Gaussian from zooming.",
            "And if we look at the updates and we take the variance of the Gaussian to 0.",
            "What's happening here is that we actually derive the formula for directional gradient, so this actually give us the underlying intuition why those methods render perturbation method works is precisely because if this is just a.",
            "So Cassie approximation to the finite difference along the perturbation direction.",
            "So every perturbation you draw you just evaluating your greater direction projected to those perturbations.",
            "So if you intuitively if you join a probation that covers entire weight space, you'll probably get a pretty fairly accurate estimate.",
            "So again, you know you may imagine this can be fairly efficient with spectrum number of weights.",
            "The reason why is that in order to compute a full gradient, we actually need the orders of we need a linear number of directional gradient that's proportional to the number of weights we have in our network and network, typically in the orders and millions of parameters.",
            "So the question is that can we actually compute those search direction more efficiently than just searching for those directional gradients?"
        ],
        [
            "And this is a counterpoint of gradient descent and backpropagation.",
            "So you know in random search algorithms, computing the directional gradients require the forward problem in your networks.",
            "So if the network is very small, you may actually be able to get away with this computation.",
            "However, with large neural networks is very inefficient for even just do a forward problem for a lot of times.",
            "So back propagation, or you know any other programming algorithm to use to compute the gradients exactly in your networks does not suffer the same problem in any dissent.",
            "You can pay the full informations using back problem algorithms.",
            "Only in the orders of the number of parameters cubed so.",
            "So now we have actually a more efficient algorithm to obtain full grade information.",
            "Um?"
        ],
        [
            "So to justify this intuition why I want to follow in gradients, we can formulate the following optimization problem.",
            "So let's consider a small change to the ways that will minimize the average laws respect to the West back to the the small small perturbation we gotta do to the weights.",
            "So there's a type.",
            "I think there's a typo here.",
            "And to bother change, we're going to formulate this as certain internal space bounded by the Clinton norm of square depend on."
        ],
        [
            "Of epsilon and to derive the update rule what we can do is we first linearize loss function.",
            "And then we can solve for the Lagrangian to get an update.",
            "So this will actually give us the update rule for the parameter is proportional to the negative gradient direction, so that's exactly it follows our integration that if random search could work that follows gradient direction, then it seems like a pretty good update.",
            "Route rail neural networks and this exactly falls out of this simple framework."
        ],
        [
            "And it backed out through the examples.",
            "So if we follow the gradient descent out direction.",
            "What I mean is, is like in this 2D gonna follow the contour direction that's perpendicular vector direction that's perpendicular to the counter plots of this convex function.",
            "And we got there fine.",
            "The Lipschitz constant of itself of function but rather Lipschitz constant for gradient so.",
            "In order to bound the rate of change of how the rate of how losses decreases for the greatest algorithms.",
            "You can imagine we probably want to know something about the underlying loss.",
            "The curvatures of the loss function.",
            "So if the loss functions really stretched out, imagine we're probably going to take a lot of steps to actually converge to the local optimal.",
            "And here so we can actually use mathematical notion of Lipschitz constant for or in this case is literally just the largest eigenvalues of our hashing matrix in this convex function.",
            "So now assume convexity.",
            "The gradient will converge in the order of 1 / T. What that means is when I say the convergence rate is tog, I met the.",
            "The difference between the current loss and the.",
            "At the loss under the optimal parameters."
        ],
        [
            "So here in the previous example.",
            "You may believe that we need to win.",
            "Can these two pretty decent convergence rate.",
            "It would just make little bits exact moves and goes to the middle of the center of the convex function.",
            "However, if we structure the curvature that way is that can be very inefficient.",
            "So in this example, the gradient direction that we can evaluate exactly at this point is almost pointing perpendicular away from the local optimal that we actually would like to move towards.",
            "So, so this giving integration that you know just by doing Zigzag is probably not a very efficient algorithm.",
            "So what other things can we do to improve the efficiency of the gradient descent algorithm?"
        ],
        [
            "The first trick that you know has been building to most of the deep learning packages is to use momentums on our grading estimates.",
            "So the basic idea is that we would like to smooth out the gradients using a moving average, so we're going to keep a moving average with the gradient updates by considering the following updates.",
            "So we're going to have the patient M. That's the momentum of the velocity.",
            "Essentially just exponential moving average.",
            "And the final updates.",
            "That way we will make to the parameters of on your networks is just going to be the.",
            "The momentum of the velocity multiplied by the stepsize eater at each time step.",
            "Intuitively, what this album does is that.",
            "As we're keeping a momentum vector forward from the previous time step, every time we evaluate our gradient at the current parameters, we're going to get a small update to our 12 velocity or momentum.",
            "And then we're going to change our parameters with spectrum.",
            "The average change in the last, you know expansion moving time.",
            "And the correction to this algorithm that makes it more efficient is proposed by industrial.",
            "So the basic idea is that imagine you're doing momentum in a very.",
            "Yeah, very sharp Valley.",
            "And as the and then you just rolling the ball downwards into the Valley and as a ball pick up more more velocity at the bottom of the Valley.",
            "You can imagine some oscillation could happen because the initial losses could be too high, so the next show of integration is that we may actually be able to correct and improve the convergence of the momentum method.",
            "If we do a look ahead.",
            "So the only change we introduced to our algorithm is instead of computing the grades and current parameters, TT will be computing the gradient at the current parameter plus the update we were going to do if the gradient is 0.",
            "So just look at how to trick under.",
            "The complex assumption is able to and smoothness is able to obtain 1 / 2 square rate.",
            "The inclusion again is that if we only update compare the naive momentum versus natural momentum.",
            "As well, keep accumulating the same velocity.",
            "Because we're evaluating the greater updates in the normal momentum.",
            "At our current primer step, we may over estimate how much we will need to update our parameters wherein anacho the look ahead master tells you.",
            "Well if I'm going over look through what I'm going to do in the future.",
            "So I take a sneak peek into like what will be the future gradient direction.",
            "That seems to be able to help me to correct my overestimation of the search direction."
        ],
        [
            "And the second trick to make SGD more efficient while they're green isn't going to more efficient is through.",
            "So cash is sampling of the training data points.",
            "So in a previous I would talk about we have an average loss that defined as the per training example loss average across entire training, Sir.",
            "And to compute a gradient updates on the entire loss required to go through the entire training set of millions of images.",
            "So that seems very inefficient, so maybe we're able to get away with only a few data points during training.",
            "The reason why is because you know, imagine image that it's a lot of images are probably captures more less, same semantic.",
            "Meanings, and while we're learning at beginning of the training, will lighten your on your nose to learn at the low level feature detectors that will be ubiquitous, two different shapes and other things so.",
            "Learning at the beginning with just those couple of filters in the first couple layers in a compact.",
            "So maybe we're able to get away with by sampling being number of points.",
            "That's much smaller than a code number of training examples an.",
            "From the entire training set so.",
            "So now we can formulate this mini batch loss that's averaged across the data points, so at different iterations instead of computer gradient on entire.",
            "Data set were just kind of subsample a small Patch."
        ],
        [
            "Um?",
            "So now without losing much a generality, we can actually assume so strong come activity and.",
            "The the number of the number of data points in a batch equal to 1.",
            "We can probably derive some convergence rate, however the the the.",
            "Intuitively.",
            "Because the inherent noise inaugurating estimations when will batch sizes one.",
            "Even if we actually converge to two points as very closely to the global optimal in this convex function.",
            "But it will probably still jump around the local and never converge, so the additional assumption we have to make for the SGD algorithm converge is to decrease the learning rate as we're moving closer and closer to the optimal point, we would like the the amortized learning rate to smooth out the variance in our gradient estimate.",
            "And there's many different derivations for SGD to obtain one of square root of tiered rate.",
            "So that was a traditional classical rub cinnamon roll derivation and more recently under the convex online programming people derive the same rate by converting the online program into stochastic programming.",
            "So."
        ],
        [
            "So the leftover question here is that so now it seems that we're able to be valid, the gradients and more much more efficient algorithm with the full information we actually making progress over the random search at all.",
            "So turns out the result is yes, so the random search algorithm is.",
            "They showed earlier by estimating a directional gradient has a convergence rate of also 1 / sqrt T. However, it's multiplied by the dimensionality of weight space.",
            "So intuitively that makes sense as a model gets larger and larger.",
            "Actually need more samples too.",
            "Search over the entire space just by doing random samples."
        ],
        [
            "So.",
            "So.",
            "Um?",
            "We can look back at the current derivation that we have on the grandest algorithm.",
            "We start with the objective function.",
            "We have the would like to minimize the perturbed loss under the constraint of Euclidean distance.",
            "So that brings in the question of, well, maybe there's other search directions we can follow during learning instead of just using the grading information.",
            "So.",
            "One way to introduce those additional information is to change our constraints from the clinic distance to.",
            "Two other."
        ],
        [
            "Case so one examples of those algorithms, called natural gradient, was proposed by the Marry in 1998.",
            "Instead, consider clinic.",
            "There's some constraint in the perturbation.",
            "I'm already proposed to consider the.",
            "The changes in the predicted distributions at output on model."
        ],
        [
            "So.",
            "Um?",
            "Again, let's see if we can actually derive the natural gradient updates from this constraint formulation.",
            "And so now the constraint is imposed on the probability space of the model predicted distribution using a KL divergent.",
            "Or actually in fact any F divergences with surface.",
            "If you go through the same linearisation of our loss function.",
            "And take the 2nd order Taylor expansion around the current weights for constraint.",
            "We're able to turn the KL Divergent, so any F diverges into the form of the.",
            "He um.",
            "The.",
            "The norm of the perturbation under the Fisher Information matrix, where the F is defined as the expected value of the covariance well, is defined as the expected value of the outer product of our model gradient under its own predicted distribution.",
            "Or in other words, it's a covariance matrix."
        ],
        [
            "So.",
            "Again, an official information matrix.",
            "So just to get more understanding of what's going on here is that so emotional on your networks application, the output on your networks is formally as a probabilistic prediction, right in the image classification, we often consider the softmax in the output layer that induce a categorical distribution.",
            "In the regression task we also consider a Gaussian output distribution.",
            "So now given input instead of weights and the output distribution, we can just compute the log probability of my prediction under the data distribution.",
            "So the caveats for the station information matrix is that the expectation is taken under the joint distribution of the input data X.",
            "And also the current model predictive distribution.",
            "Why?",
            "Instead the ground truth data?"
        ],
        [
            "Um?",
            "A separate view of, like less algorithmic view but more intuitive view of the Fisher Information matrix as we can think about what's going on when we actually measure the KL divergent between the.",
            "Probably distributions.",
            "So in the clinical sense, we measure the distance between two neural networks by looking at how much the ways have changed in the outer space.",
            "However, that does not actually capture the actual change in the output of the neural networks.",
            "At the end of the day, we we're learning neural networks to map the input to a set of output.",
            "So the function of the underlying function mapping is what we really care about.",
            "The exact parametrisation is probably less important.",
            "However, because your network segment overparameterized there's lot of reprivatization under the same model, so would like to have a decent or action that directly moves in the output probability space of our model instead of the white space.",
            "Which is very cumbersome.",
            "So one intuition here is that you can imagine.",
            "Not a map where.",
            "The actual distance between the two ends of Antarctica.",
            "Is blown up out of proportion when we flatten everything out into outer space in the waste space.",
            "However, like although the weights can change significantly, the actual output of the function will only differ by a tiny bit in the actual sphere.",
            "So by using Fisher information matrix we can locally warp the we can consider locali the actual curvatures of our or the geometries of our statistical models at output layer, so we don't have, so we can actually make significant progress in away space instead of having to move move absolute space from outer space.",
            "So imagine SGD to move from one side of Antarctica here to the other side.",
            "What type entire map where the natural gradient would just take one step in this example?"
        ],
        [
            "So coming back to the.",
            "The example again in 2D.",
            "So.",
            "Not only the SGD search direction.",
            "Is inefficient due to the air conditioner curvature, but also doesn't matter yet, go ahead.",
            "Right, so you're saying like estimating the Fisher information matrix.",
            "So so we.",
            "In the 1998 paper official information, which we consider the American server, the actually expected value of.",
            "Exactly this matrix, instead of a stochastic estimation of the covariance matrix.",
            "And it goes through the algorithm to actually considers the Castle version of the curvature matrix.",
            "Um?",
            "So so so the so that researchers such directions inefficient due to the air condition curvature but also the.",
            "Even if we can get like infinite amount of data to estimate, the greater direction will still be crippled because the curvature problem."
        ],
        [
            "All in the natural gradient.",
            "By instead of just falling simply the gradient direction G. Here we multiplied by a precondition matrix F inverse, that's.",
            "Still able to take us almost a lot of shortest path in the Geocities space."
        ],
        [
            "So.",
            "Here we're left with the question of how can we actually find the best preconditioner matrix?",
            "So every considered the current derivations here we have our greatest sense that's derived from considering an identity.",
            "Curvature matrix.",
            "So where we consider all the search directions are equally good.",
            "Where in the natural gradient we consider the search direction that actually going to improve or changes.",
            "My models output prediction distribution.",
            "Turned out if we do any second of 2nd order approximations to our constraints, we're going to be left with a family of 2nd order approximation constraints, so that has the form of.",
            "We're going to multiply the random perturbation by the inverse of preconditioner under the norm of that particular preconditioner.",
            "So.",
            "This gives us the opportunity to think about how we actually going to define, or you can search for a better search direction.",
            "Yes.",
            "Right, so the ideal condition courage in this case, if we can look at this.",
            "Example here in 2D.",
            "So we notice that the.",
            "For this, like it's not exactly quadratic function, but assuming there's a quadratic function.",
            "On one side of the ellipse is very stretched out versus the other, so if it is a quadratic function, that means the ratio of the eigenvalues.",
            "Then it's gonna be blown out of proportion.",
            "So what that means is that now if I'm going to use an SGD algorithm, or like with any of sort of gradient descent 1st order method, what's going to happen is that choosing the learning rate for a constant learning rate for both parameters in this problem becomes really difficult, because if I'm going to make a very small learning right, I'm going to, the algorithm will not have this exact behavior, however, will move very very slowly moves towards the.",
            "Center of the optimal.",
            "An If I choose a large learning rate.",
            "I'm going to be suffering from making very counterproductive moves that's perpendicular to the center of the quadratic bowl.",
            "So that's why maybe so, the curvature of this.",
            "Function is your condition means like the ratio of the eigenvalues are.",
            "Ocean."
        ],
        [
            "Right, so so maybe one intuition on how to find a good precondition matrix A.",
            "Is to focus on, you know the weight space that hasn't been explored much so far from the previous updates.",
            "So then we can actually formulate the derivation of the precondition measures a.",
            "Through another matter optimization algorithm.",
            "So here we are considering to optimize the objective of the precondition matrix that multiply all the previous gradients we have evaluated so far in our optimization trajectory.",
            "Subject to the constraint that the trace of the OR the sum of the eigenvalues for this preconditioner or that race is bounded by mu and also the preconditioner is positive semidefinite.",
            "So if we solve this optimization problem.",
            "What we get is our preconditioners has to be proportional to the sum of the correlations of the gradients from all previous updates under the square root of.",
            "So so the.",
            "The algorithms, so this derivation actually gave us a new insight into albums like undergrad Adam.",
            "Or am I miss props where the updates?",
            "How we obtained can be considered as we would like to speed up learning along the directions where my previous gradient has not been moved along very much.",
            "Of course, this matrix a fear what will be the size of number of parameters by number of parameters in practice and not practical to compute so that inverse of the square root of matrix A.",
            "And.",
            "So most of the algorithms would consider a diagonal approximation to this.",
            "Some of the latest latest algorithms like there's a paper out of Princeton called GT that actually consider how we can actually solve this inverse square root problems in more efficient manners by shuffling.",
            "Take advantage of low rank and shuffling things around."
        ],
        [
            "And in terms of like how this algorithm works, is that.",
            "Normal SGD pass for this air condition problem.",
            "We will make a lot of counterproductive moves that towards the high eigenvalue directions.",
            "And yeah, moving very slowly along the lower directions.",
            "If so happened that our convex function here is actually aligned.",
            "Well, we can.",
            "Um?",
            "What we can draw intuition is that the along the large eigenvalue directions, our grade is going to have very high variance.",
            "Along this across many updates.",
            "A lot of smart like about directions.",
            "I'll just loss function are greater is going to have small variance."
        ],
        [
            "So this is precisely what Adam, an adequate does, is that we scale up the small variance weighting search directions, but and also scale down the high variance directions to speed up training.",
            "So after re adjusting the learning rate for each directions separately, so instead of using a single step size or learning rate for all parameters, Now here will be using a separate learning rate estimate that's computed over the variance of the gradient along that for the parameters over the past many parks."
        ],
        [
            "Um?",
            "So.",
            "However, if the problems that we're trying to solve but only optimization problem trying to solve is not actually aligned.",
            "The diagonal method is not going to help much in this case.",
            "We're still going to have very strong correlations among the two parameters here.",
            "So what we really need is a full covariance or some approximation to the full curvature matrix to correct for the correlations among our parameters.",
            "Um?"
        ],
        [
            "So.",
            "The problem, however, is the computer full covariance matrix.",
            "Again, to remind yourself is that the new networks with doing in practice actually have millions of parameters, so we're going to have a matrix of millions of millions entries to invert.",
            "That becomes very intractable, an almost impossible given even given many GPU hours.",
            "So in practice.",
            "You will imagine how do we actually solve all those problems, even though the optimization seems so difficult."
        ],
        [
            "So the trick that people applied in practice is that instead learning on a single machine that we gather data and compute the gradient estimates for under our current parameters.",
            "Would rather use parallelization over many machines to get a better estimation of our gradients.",
            "So it does seems under the latest trick like batch normalization.",
            "There's reprioritization off on your networks, just simply.",
            "Um, simply increasing the batch size.",
            "Would increase the performance of the convergence of the algorithms, right?",
            "So in this case we run some experiments.",
            "Um?",
            "An image net of of Google Net with batch size 256-1000 and 2000.",
            "Under the batch normalization.",
            "There are diminishing returns in those in those curves as we increase the batch size, so the access here I'm plotting is number training points.",
            "The algorithms consuming So what that means is.",
            "As we're getting better and better way to estimate our algorithm actually and now making proportion amount of progress to the computation resource we spend on them.",
            "So we're going to have this Commission return for our SGD algorithms even under the batch normalization."
        ],
        [
            "So.",
            "You know, just another plot to drive this point home.",
            "When we train those lights, data var resonates on a GPU's.",
            "Easy takes about like 7 days on.",
            "Seven days of computer computation time on EC2 with a P-100 GPU's an under rough calculation.",
            "If I translate access into US dollars, it's going to cost you about $800 to train those models.",
            "So.",
            "Is there anything we can do to speed up the training?",
            "Also take advantage of the integration we have drawn in the first part of the talk I.",
            "Using carbon form curvature information is great.",
            "But we need a more efficient way to utilize them instead of just doing diagonal approximations."
        ],
        [
            "So if you look at US capabilities of you know all the optimization are going to have talked about so far.",
            "I will categorize them as black box optimization algorithms.",
            "The reason why is because we only consider a loss function that Max Vector to a real value and then we compute the 1st order.",
            "You know great information or.",
            "You know 2nd order curvature informations by looking at the gradients themselves.",
            "In terms of scalability.",
            "As she scales really well where the model computation resources but does not scale well with our parameters and also your condition curvatures.",
            "For natural gradient.",
            "It has great promise of scale, well, with better gradient estimates and.",
            "If we can actually invert and compute the curvature information.",
            "However, it's very memory inefficient and also inverse becomes intractable."
        ],
        [
            "Right so.",
            "How can we do better?",
            "So here's a trick that we can actually looking at the actual computation graph of on your network and maybe we can take advantage of the peculiar way of gradient computation.",
            "Talk to our advantage so in a four pack of neural networks is that we're going to have an incoming signal.",
            "The activation of a in our neural network.",
            "That's being limited projected by a set of weights W. Um Ann, in a backward pass.",
            "We have to evaluate the popular with spec to the in your projection.",
            "The comparative of the loss function was back to the output of the linear projection.",
            "So the actual query and computation.",
            "Is the outer product of the activations with the partial derivatives that we back propagate through the network?",
            "And if we flatten out the greater matrix in layer, you didn't rewrite the degrading computation using the Chronicle notation.",
            "We're going to have the.",
            "Gradient the vectorized gradient.",
            "Offer layer.",
            "Um?",
            "Of the the the, the way single layer is equal to the Chronicle product of the activations and the partial derivatives that we backcrossed through."
        ],
        [
            "Just a quick reminder of what quantity of product is.",
            "So if you have two matrices A&B in this example, the Chronicle product is computed as you take in a second.",
            "The second matrix, B tiles in the space of matrix a scaled by the coefficients of matrix A.",
            "So if you have a 2 by 2.",
            "The quality product of 2 two by two matrices will result in a four by four matrix."
        ],
        [
            "So another way to think about Chronicle product is it's just a rank auto product in the in the tensor space.",
            "So effectively we start to notice that.",
            "The gradient.",
            "Of Los Angeles.",
            "Back to the West on a single data point has a rank one structure falling your network."
        ],
        [
            "So then we can rewrite the if the spatial information matrix was defined as the."
        ],
        [
            "Product of the gradients of unknown networks."
        ],
        [
            "By looking at a single layer, we can write the Fisher Information matrix as the outer product.",
            "Deactivations clinical product with the other product of the.",
            "Patrick Perative that we backcrossed through."
        ],
        [
            "So in the case back algorithm that was proposed by James Martin and Roger Girls back in 2015.",
            "The facial information matrix.",
            "After written in the Quantica factored form is further approximated by assuming statistical independence between the activations an.",
            "And the partial derivative.",
            "That way back back through.",
            "So this gave us a huge computational advantage.",
            "So you can imagine instead of having expectation outside of this clinical product of two matrices.",
            "Now we all we need to do, just estimate the expected value of each of the quality factors and then compute the aquatic products.",
            "So why is that a good idea?",
            "So the.",
            "The idea of Chronicle product.",
            "The inverse of aquatic products is the quality of product of the inverses.",
            "And also we are multiplying of vector with a matrix that has a chronic product structure.",
            "We can reshape the vectors into matrix form that multiply each of the factors independently of each other to the reshape gradient.",
            "So this because we made a very attractive for two to be used in natural gradient, because now we can just invert the covariance matrix of the activations and covariance matrix of the back propagate error independent of each other."
        ],
        [
            "So instead of.",
            "So just give you, I guess a inclusion for a typical MNIST model of two hidden layer without the hidden units the.",
            "The way matrix in the middle will have a 1 million parameters.",
            "So now if we have to do natural gradients for that middle layer, you would have to invert the matrix a million by million, where in the quantity of product fact because we approximate that as the covariance matrix of the activations which are just assaulted by thousand and covariance matrix of the back public error, which is another thought about the matrices.",
            "So in terms of communication is a lot more efficient.",
            "Then computing the exact natural gradient.",
            "And here we are not assuming any diagonal structures in the.",
            "In the in the in the Fisher estimate or the curvature estimate?",
            "And the.",
            "This.",
            "The key fact, however, is too expensive if you have to run this under a single machine.",
            "The reason why is even inverting a like 1000 by 1000 matrices could be taking like a fraction like hundreds of milliseconds.",
            "On a CPU that has to be communicated between different processes using a machine where.",
            "Where all the gradient computations are done on the GPU's.",
            "So to overcome the computation overhead that introduced by inverting the quality factors.",
            "So the we can repurpose the current distributed system.",
            "How we train now and your networks.",
            "By petition, those gradient workers that works on different mini batches into separate groups that computes the Chronicle vectors.",
            "That's being used to estimate the curvature matrix, and we have separate group of.",
            "Machines that compute the inverses of all those.",
            "Factors."
        ],
        [
            "So in practice.",
            "Um?",
            "You know the scientific question to ask is that?",
            "Well?",
            "Is this kind of distributed algorithm going to scale?",
            "It just as well as SGD, or is actually going to do better?",
            "So if we plot if we make overlay the Cape curves on top of SGD image net we notice is that photos models of millions of parameters.",
            "Under SGD would still have the diminishing return, but under the SAFE Act as we increase the batch size, the per training example progress we're making is actually more or less constant.",
            "So what that means is like if you can compute the very clean gradient using 2000 examples at each update you expect it to get twice as quiet, 2X amount of speedup if you compute the gradients using just one thousand data points.",
            "Um so.",
            "So so the so the K factor were.",
            "So more recently, I guess there's more.",
            "Algorithm that had been looking into how we can actually take advantage of the computation graphs of the neural networks.",
            "So in the.",
            "The shampoo paper from Princeton.",
            "Instead of going through all the details of how the new network actually compute the gradients.",
            "All shampoo algorithm does is we estimate, assuming the gradients of the parameters in the shape of a tensor and it will normalize or white and each of the issue of the tensor dimensions independently of each other using the covariance matrix with computer from a gradient estimate along that particular slice of that answer."
        ],
        [
            "So I think moving on from black box optimization to white box optimization is quite exciting.",
            "Progress that we're making here, and.",
            "So you know just going back to the center slides of this talk where all those underlying algorithms from their frameworks are derived from a single objective, which is, well, how should we find a better search direction to change the way soften your network?",
            "And.",
            "And under different constraints.",
            "Which arrive different flavors of the algorithms?",
            "And given more informations about the actual computation graph of underlying loss computation, we're able to derive more efficient algorithms to approximate the.",
            "The complication, the required complications for those curvature matrix.",
            "Yep.",
            "Like right?",
            "So it does not.",
            "So it gives comfort virtualization.",
            "It's in time slightly worse than SGD.",
            "Yes, and the way we suspect what happened there is because we're using the optimizer.",
            "That's a lot stronger and is able to find a more efficient search direction to SGD.",
            "The regularizers that the hyperparameter for the regularizers need to be tuned corresponding however, in the experiment we run with natural gradient.",
            "We use, we retain the same hyperparameters, SGD runs.",
            "So that was the conjecture down.",
            "Why did you like there still?",
            "Image net I believe there was a 2% gap between the natural gradient, an SGD on the top one prediction.",
            "Hey."
        ],
        [
            "So yeah, so this concludes my talk here, and you're more than welcome to ask more questions.",
            "Sure.",
            "To follow up on some jeans question, if you do a more noisy gradient estimation in the natural gradient, does that?",
            "Does it improve generalization?",
            "Um so.",
            "I believe there so the.",
            "So the result is mixed.",
            "We we have done very limited set of experiments using very small batch to estimate here gradients and using large batch to estimate the curvature information matrix and turned out.",
            "You can improve the generation by using a noisy gradient estimate.",
            "But the expense was so limited that I don't want to claim, yeah, overclaimed results.",
            "If I can, can I do a second question so there is a critical step in your derivation where you have the expectation first activation functions multiplied by the gradients.",
            "Yes, and then you separate them.",
            "Do you see cases where that that is not doing that?",
            "Not not valid, right?",
            "So?",
            "I guess in the intuition here is that well, if we consider the statistics among activations and positives or independent.",
            "What we're really saying is that now you can.",
            "Swap out the four pass activations.",
            "An if backdrop error signals among the training points.",
            "And the second is statistics are like, you know, independent from each other, so for.",
            "So for the 1st order information, that's certainly not true.",
            "The for the 1st order information that what I mean is that the domain of the forward activations under a data point versus the backdrop signal for is going to be very different across the training point.",
            "However, the second one is statistics.",
            "The covariance there's reason to believe well after neuron a particular neurons always useful to detect an edge in the image.",
            "You'll probably have a similar.",
            "The and then the.",
            "Other neurons in in the same layers that the tax slighted, like a couple of filters that's correlated.",
            "Then the correlation among the activations were still persist across the training points.",
            "But the actual numerical value themselves were probably not so, so under that assumption, I think is safe to assume the second sticks are independent.",
            "No thank you.",
            "Can you go back to the page before the thank you one?",
            "Page of the second last one.",
            "Yeah, so it seems like.",
            "All problems that you mentioned here are constrained optimization problems, but at least for gradient descent, are you really solving this problem or you know what artist?",
            "But the real problem that you are solving this if you like software is constrained optimization problem.",
            "You your step sizes might be.",
            "Determined by the algorithm instead of setting by hand.",
            "Right?",
            "Um, yes.",
            "So the.",
            "The practical, greater detail when they were used to train your networks, always assume a constant step size.",
            "Which is so different than, you know, if you like to converge on a convex problem, you probably want to step side that proportional to the square root of how many updates you have done so far.",
            "Um?",
            "But I guess it's hard to even.",
            "I guess it's so we probably want to define what we mean by solving the correct problem, like if the correct problem here means we actually decrease in the loss function at each time step.",
            "Like on average, then that's probably true.",
            "Um?",
            "And so even Goodfellow had a paper looking at those SGD ever going uphill during the course of optimizing it.",
            "Deep neural networks and turns out most of the time, it's always going downhill.",
            "So in that sense, we're probably solving the right objective function.",
            "Yeah, so for natural gradient are you penalized?",
            "This pal divergance in your objective?",
            "Or like practically, how do you do it right?",
            "So the proco algorithms for natural gradient will be taking your granny update?",
            "Multiply by the inverse of the Fisher information matrix so that that's the update comes from the.",
            "The Taylor Taylor expansions on the constraint and solve for the Lagrangian multiplier.",
            "And now you derive a close form update rule.",
            "Thank you.",
            "Thanks for the nice talk.",
            "I just want to follow up on the discussion that you're having.",
            "And touch on the more general question of optimization and realization which Sanjeev already talked about and I guess it's going to be maybe a theme today.",
            "Maybe?",
            "You don't want to have the loading rate and yield to zero.",
            "I mean, if you wanted to do purely optimization, that's what you would want to do, but.",
            "The the noise injected by the level of the running rate and the small batch size is having a positive impact on realization.",
            "In various ways that we are only starting to understand so.",
            "Can you comment on that?",
            "I mean it with respect what you've been talking about and the worst realization you obtained with K fact.",
            "Yes, so I think when.",
            "I guess my own personal view on optimization and realization is that when we drive the optimization algorithm is probably.",
            "It's probably a good idea.",
            "Just focus on the convergence rate of on the training set rather than thinking that's easier, right?",
            "It's much easier to make a case for the algorithm rather than because once we start to consider all the implicit regularization effect, for example coming from the noisy statistics estimate from batch normalization layers, constant step size.",
            "The non come back to the other problems and how they interact with constant step sides.",
            "Problem becomes.",
            "Harder to.",
            "To have a clean argument on which I want works better, because now you have two competing objective one is.",
            "That's what she learning, yes.",
            "So so my, I guess I don't have any like you know, theoretical proof or anything like that, but empirically it does.",
            "Seems like all the generalization gap we have seen by using a very strong optimizers.",
            "Natural gradient or?",
            "Hashing free methods can be partially solved by retrieving the regularization hyperparameters.",
            "So instead of using the exact same regularization hyperparameters as SGD.",
            "There will be like retune, or maybe you need other types of.",
            "I mean regularization.",
            "Maybe you need to inject noise in different ways, for example, and things like that, right, right so?",
            "I guess so.",
            "So the question is like, well, if we moving out to those technologies method that's you know, kind numerically sensitive that requires to use large batch to estimate those gradients.",
            "And doing in versus.",
            "We do lose some kind of Cassidy and stochastic cities in our models, right?",
            "Because now a batch is a lot bigger.",
            "If we believe the story that smaller batch is equivalent to three, large batch is equivalent to a small batch plus the.",
            "A noise that was second with statistics is proportional to the curvature of the Fisher Information matrix.",
            "Then we're certainly losing a lot of regularization here, however.",
            "In your networks we have.",
            "We can add in drop houses we can add in weight the case and so my personal view is that if we just reach you, all the hyperparameters for.",
            "But why hasn't it happened?",
            "I mean there are many researchers are trying to improve optimization methods for neural net and I think most of them understand that.",
            "So you're saying you didn't optimize the hyperparameters but you know.",
            "It's not that hard to do it.",
            "There's been a lot of works in the past.",
            "People have tried hard.",
            "Right, so I cannot comment on this image net.",
            "So so in.",
            "In Toronto, various students have tried to reproduce the larger generalization gap results by swapping out STD's with Adam or natural gradients.",
            "K fact natural gradient.",
            "What we found is at least once before 10.",
            "If you increase the weighted case and adding more dropouts.",
            "We always recover well as the same generation, so of course the training curve was suffer a bit would not get as impressive result as being the original optimization paper.",
            "But we do recover more or less the same generalization.",
            "So I have a counter question for you.",
            "Right?",
            "So like what?",
            "I guess, so for people who and students Ann writing, you know, algorithm papers for deep learning and machine learning.",
            "Where do we draw the boundary of?",
            "Here's an algorithm that minimize the training really well.",
            "Or here's an algorithm that does a bit of everything.",
            "I think we shouldn't try too hard to separate those two things because they they interact strongly.",
            "What we need to do is to understand that interaction.",
            "So if SGD somehow is helping generalization, we need to really get to the bottom of what is going on so that we can potentially use some of those principles with other like stronger optimization methods.",
            "But I think it's unavoidable that we will have these interactions between the optimization method, an indigenization effect, and so we can't.",
            "If we want to really do machine learning, we can't just do the optimization on its own.",
            "I mean, maybe it's a good first step from the point of view of research like OK, so here's an optimization at that.",
            "Which of these works on the nonconvex case?",
            "But to really make it useful for practitioners, we also need to study that the translation effect.",
            "And maybe how we need to address that?",
            "With those new algorithms.",
            "Right?",
            "Yeah, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we're going to talk about how we can actually find better.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Directions by taking consideration of the curvature informations from 2nd order statistics and in the end I'm going to talk about how we can design what I called up white box optimization algorithm that just doesn't only look at the creating information but also consider the computation graphs that use the computer gradient.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so this is just a initial site for your networks just to make everything concrete, let's consider you know we have pairs of input output X&Y, draw from a training set of data points, right?",
                    "label": 0
                },
                {
                    "sent": "So no network, surprised functional Maps that Maps the X to Y, parameterized by set of weights W, and in this talk we're going to consider Delta is drawing from this wave space of dimension.",
                    "label": 1
                },
                {
                    "sent": "And once we have our prediction from the model, we can compute a loss function by comparing our prediction with the correct answer, right?",
                    "label": 1
                },
                {
                    "sent": "So with this defined larger L under the current data points and the current weights.",
                    "label": 0
                },
                {
                    "sent": "So, and we're gonna use this shorthand notation to denote the average loss for every data point.",
                    "label": 0
                },
                {
                    "sent": "So we're just going to use the subscript under the loss function.",
                    "label": 0
                },
                {
                    "sent": "Help particular points.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Why is learning deep neural networks hard?",
                    "label": 1
                },
                {
                    "sent": "So first of all, networks are not convex, right?",
                    "label": 0
                },
                {
                    "sent": "So what is convex?",
                    "label": 0
                },
                {
                    "sent": "So the notion of convexity comes from the state areas where you consider, well, you have sort of convex points.",
                    "label": 0
                },
                {
                    "sent": "What that really means is you have if you draw a line between any of those two points gained a convex set the any points along the line should also fall into the same set, and in the second example on the right hand side that is an example of non convex set.",
                    "label": 0
                },
                {
                    "sent": "Right, and how we generalize this notion through function real valued functions?",
                    "label": 0
                },
                {
                    "sent": "Is our consider the two inputs to a function that Maps a vector to a real?",
                    "label": 0
                },
                {
                    "sent": "Imagine that's a loss function.",
                    "label": 0
                },
                {
                    "sent": "And convex function will have the property that the average of the data points is going to be higher than the functional form of the average point, right?",
                    "label": 0
                },
                {
                    "sent": "So and the example of non convex function is the one on the right.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So unfortunately, in deep learning our models and loss of extremely non convex so we have many local optimums and if you believe the.",
                    "label": 0
                },
                {
                    "sent": "The urban myth.",
                    "label": 0
                },
                {
                    "sent": "30 years ago we will think well if learning those new networks is just completely hopeless because you're going to stuck in those sub optimal points.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to see some expansion results to show how that's not the case, and we still don't really understand what's going on.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second point, that learning is very difficult is that neural networks are not very smooth.",
                    "label": 1
                },
                {
                    "sent": "So we can probably quantify the smoothness through the notion of Lipschitz continuous.",
                    "label": 0
                },
                {
                    "sent": "So the intuition behind the Lipschitz continuity is that you would like to bound the variability of a function.",
                    "label": 0
                },
                {
                    "sent": "So thinking about like you know if the Lipschitz constant is small, then the function will not vary a lot an or in other words, the maybe you can think of locali the gradient of the function with respect to the input.",
                    "label": 0
                },
                {
                    "sent": "In this case the parameters W is going to be very small, right?",
                    "label": 0
                },
                {
                    "sent": "So if you move?",
                    "label": 0
                },
                {
                    "sent": "The right hand side through the left side and take the input capital step between WW prime you'll get the gradient, so domains the normal gradient is bounded approximately and an example of non Lipschitz continuous function is the exponential function, right?",
                    "label": 0
                },
                {
                    "sent": "So in your network, so you can imagine when you parameterise the variance of normal distribution, that's what that's a typical privatisation we use in.",
                    "label": 0
                },
                {
                    "sent": "The model is very small.",
                    "label": 0
                },
                {
                    "sent": "Encoders that actually introduced none left smoothness to our model.",
                    "label": 0
                },
                {
                    "sent": "So you know a lot of new numbers we use in practice are actually very very much non smooth and another way to think about them is if you have a relative neural networks.",
                    "label": 0
                },
                {
                    "sent": "Albert really blow up the weights in the first layer and by a factor of Alpha and then shrink the weights in the next layer by a factor of 1 over Alpha.",
                    "label": 0
                },
                {
                    "sent": "Imagine there's no bias units on your networks.",
                    "label": 0
                },
                {
                    "sent": "You still parameterized very much the same function.",
                    "label": 0
                },
                {
                    "sent": "However, the gradient of the second layer is going to be now Alpha times larger than the previous previous prioritization, even though their parameters in exact same functional so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the new one.",
                    "label": 0
                },
                {
                    "sent": "I was not very smooth.",
                    "label": 1
                },
                {
                    "sent": "So the the Lipschitz constant, so, so yes.",
                    "label": 0
                },
                {
                    "sent": "So you still have a concept, but then under different parameterisation, the constants different.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Even though the the parameterized function is exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Definition of.",
                    "label": 0
                },
                {
                    "sent": "Sure, yes.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah, right.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So and the Third Point, I'm just learning how it's difficult is because.",
                    "label": 0
                },
                {
                    "sent": "The networks has millions of parameters, so if you think about the most recent widely used models in image recognitions, those multiply 5 million parameters in your neural machine translation.",
                    "label": 1
                },
                {
                    "sent": "Those are models, typically in the order of hundreds millions of parameters and Alpha goes about 50 parameters.",
                    "label": 0
                },
                {
                    "sent": "In my rough back to the envelope calculation.",
                    "label": 0
                },
                {
                    "sent": "So not only the the objective function will optimize is not very nice and also the model has a lot of.",
                    "label": 0
                },
                {
                    "sent": "Tunable knobs",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How can we actually train on your network so in the.",
                    "label": 0
                },
                {
                    "sent": "I just like to, you know, ask you guys to think about just simply thought process.",
                    "label": 0
                },
                {
                    "sent": "So here I present an algorithm where we start with the neural networks that parameters by sort of weights and we generate a random vector called Delta W that can be drawn from a Gaussian distribution or something.",
                    "label": 0
                },
                {
                    "sent": "So we're going to evaluate the neural network prediction after this perturbation over the entire training set.",
                    "label": 1
                },
                {
                    "sent": "And then we're going to compute average loss.",
                    "label": 1
                },
                {
                    "sent": "For the perturbed neural networks.",
                    "label": 0
                },
                {
                    "sent": "An if the perturbed new hours loss is improved over the previous non preferred version, we're going to keep the perturbation.",
                    "label": 1
                },
                {
                    "sent": "Otherwise we have discussed this perturbation.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is very inefficient.",
                    "label": 0
                },
                {
                    "sent": "However, we guarantee that every time we update, our weights were going to make an improvement on the last function.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can we actually make this algorithm cited more practical?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We can think about, well, we're going to draw not just any random vector, but a random vector from a Gaussian distribution with zero main and with some traffic covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "And instead of discarding the data point that doesn't make any improvement, we're going to keep the data that we're going to keep the perturbation and add them to my weights, except which way they're going to be weighted by the negative of the loss function.",
                    "label": 1
                },
                {
                    "sent": "So it's immediately.",
                    "label": 0
                },
                {
                    "sent": "It's not very clear how this will converge and even decrease loss function overtime.",
                    "label": 0
                },
                {
                    "sent": "However, you can derive this from the.",
                    "label": 0
                },
                {
                    "sent": "Optimization point of view, which which is similar in spirit as reinforce algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is, it turns out to be giving you a unbiased estimate, although very noisy, of the underlying grading information.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can probably improve this algorithm started even further.",
                    "label": 0
                },
                {
                    "sent": "Where instead of just drawing a single data instead of updating our weights using a single perturbation.",
                    "label": 0
                },
                {
                    "sent": "Now we can consider both the positive sign of the perturbation and also the negative part of perturbation.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this new update rule here.",
                    "label": 0
                },
                {
                    "sent": "It actually looks a lot like some sort of finite difference.",
                    "label": 0
                },
                {
                    "sent": "And so this can I give you some intuition.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe this album is going to be starting more efficient, because now we know.",
                    "label": 0
                },
                {
                    "sent": "Well, given the both deposit perturbation and negative perturbation, how much my function is going to change and I'll probably give me a more accurate estimate of how I should improve the loss function with respect to the random perturbation direction.",
                    "label": 0
                },
                {
                    "sent": "And now here we also just join with join M samples for the random perturbation.",
                    "label": 0
                },
                {
                    "sent": "Break.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this kind of algorithm is often called, you know, have many names in reinforcement learning is called evolution strategy and also be called like 0 order method because doesn't use any written information order free methods.",
                    "label": 0
                },
                {
                    "sent": "So to get intuition how this method actually work in practice?",
                    "label": 0
                },
                {
                    "sent": "Well, first look at some of the set of experiments with that for actually one of our flip paper.",
                    "label": 0
                },
                {
                    "sent": "So that was a paper we submit to die clear.",
                    "label": 0
                },
                {
                    "sent": "So we run this algorithm on MNIST model was 500 hidden units each.",
                    "label": 0
                },
                {
                    "sent": "There are two hidden layer.",
                    "label": 0
                },
                {
                    "sent": "When comparing this with a just normal backpropagation algorithm that's highlighted in the red.",
                    "label": 0
                },
                {
                    "sent": "Turned out that you know if we draw enough samples to estimate those gradients, we actually can get more or less the same convergence as a stochastic gradient descent methods, and this seems a bit counterintuitive.",
                    "label": 0
                },
                {
                    "sent": "I'll explain more the technical details later, the convergence rate and things like that.",
                    "label": 0
                },
                {
                    "sent": "But the takeaway message here is that we would think the random perturbation method may may seem a bit naive and impractical.",
                    "label": 0
                },
                {
                    "sent": "But if you can draw for like 5000 data points, 5000 samples way estimating those derivative free methods and turned out it actually works quite well.",
                    "label": 0
                },
                {
                    "sent": "So if I only look at this graph, it spelled misleading because the X axis is the number of updates that does not consider the computation time we used to estimate the update for those evolution strategy method versus the grand dissent.",
                    "label": 0
                },
                {
                    "sent": "So now we can actually look into like a more QD examples to get more intuition of what's going on here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in those new order method.",
                    "label": 0
                },
                {
                    "sent": "Given the current parameters.",
                    "label": 0
                },
                {
                    "sent": "W not what happened is that we're going to randomly sample a few points from the neighborhood under the current solution.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to use that to compute the aggregated search direction.",
                    "label": 0
                },
                {
                    "sent": "Here the random perturbation draw from a random Gaussian from zooming.",
                    "label": 0
                },
                {
                    "sent": "And if we look at the updates and we take the variance of the Gaussian to 0.",
                    "label": 0
                },
                {
                    "sent": "What's happening here is that we actually derive the formula for directional gradient, so this actually give us the underlying intuition why those methods render perturbation method works is precisely because if this is just a.",
                    "label": 0
                },
                {
                    "sent": "So Cassie approximation to the finite difference along the perturbation direction.",
                    "label": 0
                },
                {
                    "sent": "So every perturbation you draw you just evaluating your greater direction projected to those perturbations.",
                    "label": 0
                },
                {
                    "sent": "So if you intuitively if you join a probation that covers entire weight space, you'll probably get a pretty fairly accurate estimate.",
                    "label": 0
                },
                {
                    "sent": "So again, you know you may imagine this can be fairly efficient with spectrum number of weights.",
                    "label": 0
                },
                {
                    "sent": "The reason why is that in order to compute a full gradient, we actually need the orders of we need a linear number of directional gradient that's proportional to the number of weights we have in our network and network, typically in the orders and millions of parameters.",
                    "label": 0
                },
                {
                    "sent": "So the question is that can we actually compute those search direction more efficiently than just searching for those directional gradients?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is a counterpoint of gradient descent and backpropagation.",
                    "label": 0
                },
                {
                    "sent": "So you know in random search algorithms, computing the directional gradients require the forward problem in your networks.",
                    "label": 1
                },
                {
                    "sent": "So if the network is very small, you may actually be able to get away with this computation.",
                    "label": 0
                },
                {
                    "sent": "However, with large neural networks is very inefficient for even just do a forward problem for a lot of times.",
                    "label": 0
                },
                {
                    "sent": "So back propagation, or you know any other programming algorithm to use to compute the gradients exactly in your networks does not suffer the same problem in any dissent.",
                    "label": 0
                },
                {
                    "sent": "You can pay the full informations using back problem algorithms.",
                    "label": 0
                },
                {
                    "sent": "Only in the orders of the number of parameters cubed so.",
                    "label": 1
                },
                {
                    "sent": "So now we have actually a more efficient algorithm to obtain full grade information.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to justify this intuition why I want to follow in gradients, we can formulate the following optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So let's consider a small change to the ways that will minimize the average laws respect to the West back to the the small small perturbation we gotta do to the weights.",
                    "label": 0
                },
                {
                    "sent": "So there's a type.",
                    "label": 0
                },
                {
                    "sent": "I think there's a typo here.",
                    "label": 0
                },
                {
                    "sent": "And to bother change, we're going to formulate this as certain internal space bounded by the Clinton norm of square depend on.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of epsilon and to derive the update rule what we can do is we first linearize loss function.",
                    "label": 0
                },
                {
                    "sent": "And then we can solve for the Lagrangian to get an update.",
                    "label": 0
                },
                {
                    "sent": "So this will actually give us the update rule for the parameter is proportional to the negative gradient direction, so that's exactly it follows our integration that if random search could work that follows gradient direction, then it seems like a pretty good update.",
                    "label": 0
                },
                {
                    "sent": "Route rail neural networks and this exactly falls out of this simple framework.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it backed out through the examples.",
                    "label": 0
                },
                {
                    "sent": "So if we follow the gradient descent out direction.",
                    "label": 0
                },
                {
                    "sent": "What I mean is, is like in this 2D gonna follow the contour direction that's perpendicular vector direction that's perpendicular to the counter plots of this convex function.",
                    "label": 0
                },
                {
                    "sent": "And we got there fine.",
                    "label": 1
                },
                {
                    "sent": "The Lipschitz constant of itself of function but rather Lipschitz constant for gradient so.",
                    "label": 0
                },
                {
                    "sent": "In order to bound the rate of change of how the rate of how losses decreases for the greatest algorithms.",
                    "label": 0
                },
                {
                    "sent": "You can imagine we probably want to know something about the underlying loss.",
                    "label": 0
                },
                {
                    "sent": "The curvatures of the loss function.",
                    "label": 1
                },
                {
                    "sent": "So if the loss functions really stretched out, imagine we're probably going to take a lot of steps to actually converge to the local optimal.",
                    "label": 0
                },
                {
                    "sent": "And here so we can actually use mathematical notion of Lipschitz constant for or in this case is literally just the largest eigenvalues of our hashing matrix in this convex function.",
                    "label": 0
                },
                {
                    "sent": "So now assume convexity.",
                    "label": 0
                },
                {
                    "sent": "The gradient will converge in the order of 1 / T. What that means is when I say the convergence rate is tog, I met the.",
                    "label": 0
                },
                {
                    "sent": "The difference between the current loss and the.",
                    "label": 0
                },
                {
                    "sent": "At the loss under the optimal parameters.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here in the previous example.",
                    "label": 0
                },
                {
                    "sent": "You may believe that we need to win.",
                    "label": 0
                },
                {
                    "sent": "Can these two pretty decent convergence rate.",
                    "label": 0
                },
                {
                    "sent": "It would just make little bits exact moves and goes to the middle of the center of the convex function.",
                    "label": 0
                },
                {
                    "sent": "However, if we structure the curvature that way is that can be very inefficient.",
                    "label": 0
                },
                {
                    "sent": "So in this example, the gradient direction that we can evaluate exactly at this point is almost pointing perpendicular away from the local optimal that we actually would like to move towards.",
                    "label": 0
                },
                {
                    "sent": "So, so this giving integration that you know just by doing Zigzag is probably not a very efficient algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what other things can we do to improve the efficiency of the gradient descent algorithm?",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first trick that you know has been building to most of the deep learning packages is to use momentums on our grading estimates.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is that we would like to smooth out the gradients using a moving average, so we're going to keep a moving average with the gradient updates by considering the following updates.",
                    "label": 0
                },
                {
                    "sent": "So we're going to have the patient M. That's the momentum of the velocity.",
                    "label": 0
                },
                {
                    "sent": "Essentially just exponential moving average.",
                    "label": 0
                },
                {
                    "sent": "And the final updates.",
                    "label": 0
                },
                {
                    "sent": "That way we will make to the parameters of on your networks is just going to be the.",
                    "label": 0
                },
                {
                    "sent": "The momentum of the velocity multiplied by the stepsize eater at each time step.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, what this album does is that.",
                    "label": 0
                },
                {
                    "sent": "As we're keeping a momentum vector forward from the previous time step, every time we evaluate our gradient at the current parameters, we're going to get a small update to our 12 velocity or momentum.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to change our parameters with spectrum.",
                    "label": 0
                },
                {
                    "sent": "The average change in the last, you know expansion moving time.",
                    "label": 0
                },
                {
                    "sent": "And the correction to this algorithm that makes it more efficient is proposed by industrial.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is that imagine you're doing momentum in a very.",
                    "label": 0
                },
                {
                    "sent": "Yeah, very sharp Valley.",
                    "label": 0
                },
                {
                    "sent": "And as the and then you just rolling the ball downwards into the Valley and as a ball pick up more more velocity at the bottom of the Valley.",
                    "label": 0
                },
                {
                    "sent": "You can imagine some oscillation could happen because the initial losses could be too high, so the next show of integration is that we may actually be able to correct and improve the convergence of the momentum method.",
                    "label": 0
                },
                {
                    "sent": "If we do a look ahead.",
                    "label": 0
                },
                {
                    "sent": "So the only change we introduced to our algorithm is instead of computing the grades and current parameters, TT will be computing the gradient at the current parameter plus the update we were going to do if the gradient is 0.",
                    "label": 0
                },
                {
                    "sent": "So just look at how to trick under.",
                    "label": 1
                },
                {
                    "sent": "The complex assumption is able to and smoothness is able to obtain 1 / 2 square rate.",
                    "label": 0
                },
                {
                    "sent": "The inclusion again is that if we only update compare the naive momentum versus natural momentum.",
                    "label": 0
                },
                {
                    "sent": "As well, keep accumulating the same velocity.",
                    "label": 0
                },
                {
                    "sent": "Because we're evaluating the greater updates in the normal momentum.",
                    "label": 0
                },
                {
                    "sent": "At our current primer step, we may over estimate how much we will need to update our parameters wherein anacho the look ahead master tells you.",
                    "label": 0
                },
                {
                    "sent": "Well if I'm going over look through what I'm going to do in the future.",
                    "label": 0
                },
                {
                    "sent": "So I take a sneak peek into like what will be the future gradient direction.",
                    "label": 0
                },
                {
                    "sent": "That seems to be able to help me to correct my overestimation of the search direction.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the second trick to make SGD more efficient while they're green isn't going to more efficient is through.",
                    "label": 0
                },
                {
                    "sent": "So cash is sampling of the training data points.",
                    "label": 1
                },
                {
                    "sent": "So in a previous I would talk about we have an average loss that defined as the per training example loss average across entire training, Sir.",
                    "label": 1
                },
                {
                    "sent": "And to compute a gradient updates on the entire loss required to go through the entire training set of millions of images.",
                    "label": 0
                },
                {
                    "sent": "So that seems very inefficient, so maybe we're able to get away with only a few data points during training.",
                    "label": 0
                },
                {
                    "sent": "The reason why is because you know, imagine image that it's a lot of images are probably captures more less, same semantic.",
                    "label": 0
                },
                {
                    "sent": "Meanings, and while we're learning at beginning of the training, will lighten your on your nose to learn at the low level feature detectors that will be ubiquitous, two different shapes and other things so.",
                    "label": 0
                },
                {
                    "sent": "Learning at the beginning with just those couple of filters in the first couple layers in a compact.",
                    "label": 0
                },
                {
                    "sent": "So maybe we're able to get away with by sampling being number of points.",
                    "label": 0
                },
                {
                    "sent": "That's much smaller than a code number of training examples an.",
                    "label": 0
                },
                {
                    "sent": "From the entire training set so.",
                    "label": 0
                },
                {
                    "sent": "So now we can formulate this mini batch loss that's averaged across the data points, so at different iterations instead of computer gradient on entire.",
                    "label": 0
                },
                {
                    "sent": "Data set were just kind of subsample a small Patch.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So now without losing much a generality, we can actually assume so strong come activity and.",
                    "label": 0
                },
                {
                    "sent": "The the number of the number of data points in a batch equal to 1.",
                    "label": 0
                },
                {
                    "sent": "We can probably derive some convergence rate, however the the the.",
                    "label": 0
                },
                {
                    "sent": "Intuitively.",
                    "label": 0
                },
                {
                    "sent": "Because the inherent noise inaugurating estimations when will batch sizes one.",
                    "label": 0
                },
                {
                    "sent": "Even if we actually converge to two points as very closely to the global optimal in this convex function.",
                    "label": 0
                },
                {
                    "sent": "But it will probably still jump around the local and never converge, so the additional assumption we have to make for the SGD algorithm converge is to decrease the learning rate as we're moving closer and closer to the optimal point, we would like the the amortized learning rate to smooth out the variance in our gradient estimate.",
                    "label": 0
                },
                {
                    "sent": "And there's many different derivations for SGD to obtain one of square root of tiered rate.",
                    "label": 0
                },
                {
                    "sent": "So that was a traditional classical rub cinnamon roll derivation and more recently under the convex online programming people derive the same rate by converting the online program into stochastic programming.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the leftover question here is that so now it seems that we're able to be valid, the gradients and more much more efficient algorithm with the full information we actually making progress over the random search at all.",
                    "label": 0
                },
                {
                    "sent": "So turns out the result is yes, so the random search algorithm is.",
                    "label": 0
                },
                {
                    "sent": "They showed earlier by estimating a directional gradient has a convergence rate of also 1 / sqrt T. However, it's multiplied by the dimensionality of weight space.",
                    "label": 1
                },
                {
                    "sent": "So intuitively that makes sense as a model gets larger and larger.",
                    "label": 0
                },
                {
                    "sent": "Actually need more samples too.",
                    "label": 0
                },
                {
                    "sent": "Search over the entire space just by doing random samples.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We can look back at the current derivation that we have on the grandest algorithm.",
                    "label": 0
                },
                {
                    "sent": "We start with the objective function.",
                    "label": 0
                },
                {
                    "sent": "We have the would like to minimize the perturbed loss under the constraint of Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "So that brings in the question of, well, maybe there's other search directions we can follow during learning instead of just using the grading information.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One way to introduce those additional information is to change our constraints from the clinic distance to.",
                    "label": 0
                },
                {
                    "sent": "Two other.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Case so one examples of those algorithms, called natural gradient, was proposed by the Marry in 1998.",
                    "label": 1
                },
                {
                    "sent": "Instead, consider clinic.",
                    "label": 0
                },
                {
                    "sent": "There's some constraint in the perturbation.",
                    "label": 0
                },
                {
                    "sent": "I'm already proposed to consider the.",
                    "label": 0
                },
                {
                    "sent": "The changes in the predicted distributions at output on model.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Again, let's see if we can actually derive the natural gradient updates from this constraint formulation.",
                    "label": 1
                },
                {
                    "sent": "And so now the constraint is imposed on the probability space of the model predicted distribution using a KL divergent.",
                    "label": 0
                },
                {
                    "sent": "Or actually in fact any F divergences with surface.",
                    "label": 0
                },
                {
                    "sent": "If you go through the same linearisation of our loss function.",
                    "label": 0
                },
                {
                    "sent": "And take the 2nd order Taylor expansion around the current weights for constraint.",
                    "label": 0
                },
                {
                    "sent": "We're able to turn the KL Divergent, so any F diverges into the form of the.",
                    "label": 0
                },
                {
                    "sent": "He um.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The norm of the perturbation under the Fisher Information matrix, where the F is defined as the expected value of the covariance well, is defined as the expected value of the outer product of our model gradient under its own predicted distribution.",
                    "label": 0
                },
                {
                    "sent": "Or in other words, it's a covariance matrix.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Again, an official information matrix.",
                    "label": 0
                },
                {
                    "sent": "So just to get more understanding of what's going on here is that so emotional on your networks application, the output on your networks is formally as a probabilistic prediction, right in the image classification, we often consider the softmax in the output layer that induce a categorical distribution.",
                    "label": 0
                },
                {
                    "sent": "In the regression task we also consider a Gaussian output distribution.",
                    "label": 1
                },
                {
                    "sent": "So now given input instead of weights and the output distribution, we can just compute the log probability of my prediction under the data distribution.",
                    "label": 0
                },
                {
                    "sent": "So the caveats for the station information matrix is that the expectation is taken under the joint distribution of the input data X.",
                    "label": 0
                },
                {
                    "sent": "And also the current model predictive distribution.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Instead the ground truth data?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "A separate view of, like less algorithmic view but more intuitive view of the Fisher Information matrix as we can think about what's going on when we actually measure the KL divergent between the.",
                    "label": 1
                },
                {
                    "sent": "Probably distributions.",
                    "label": 0
                },
                {
                    "sent": "So in the clinical sense, we measure the distance between two neural networks by looking at how much the ways have changed in the outer space.",
                    "label": 0
                },
                {
                    "sent": "However, that does not actually capture the actual change in the output of the neural networks.",
                    "label": 0
                },
                {
                    "sent": "At the end of the day, we we're learning neural networks to map the input to a set of output.",
                    "label": 0
                },
                {
                    "sent": "So the function of the underlying function mapping is what we really care about.",
                    "label": 0
                },
                {
                    "sent": "The exact parametrisation is probably less important.",
                    "label": 0
                },
                {
                    "sent": "However, because your network segment overparameterized there's lot of reprivatization under the same model, so would like to have a decent or action that directly moves in the output probability space of our model instead of the white space.",
                    "label": 0
                },
                {
                    "sent": "Which is very cumbersome.",
                    "label": 0
                },
                {
                    "sent": "So one intuition here is that you can imagine.",
                    "label": 0
                },
                {
                    "sent": "Not a map where.",
                    "label": 0
                },
                {
                    "sent": "The actual distance between the two ends of Antarctica.",
                    "label": 0
                },
                {
                    "sent": "Is blown up out of proportion when we flatten everything out into outer space in the waste space.",
                    "label": 0
                },
                {
                    "sent": "However, like although the weights can change significantly, the actual output of the function will only differ by a tiny bit in the actual sphere.",
                    "label": 0
                },
                {
                    "sent": "So by using Fisher information matrix we can locally warp the we can consider locali the actual curvatures of our or the geometries of our statistical models at output layer, so we don't have, so we can actually make significant progress in away space instead of having to move move absolute space from outer space.",
                    "label": 0
                },
                {
                    "sent": "So imagine SGD to move from one side of Antarctica here to the other side.",
                    "label": 0
                },
                {
                    "sent": "What type entire map where the natural gradient would just take one step in this example?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So coming back to the.",
                    "label": 0
                },
                {
                    "sent": "The example again in 2D.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Not only the SGD search direction.",
                    "label": 0
                },
                {
                    "sent": "Is inefficient due to the air conditioner curvature, but also doesn't matter yet, go ahead.",
                    "label": 0
                },
                {
                    "sent": "Right, so you're saying like estimating the Fisher information matrix.",
                    "label": 1
                },
                {
                    "sent": "So so we.",
                    "label": 0
                },
                {
                    "sent": "In the 1998 paper official information, which we consider the American server, the actually expected value of.",
                    "label": 0
                },
                {
                    "sent": "Exactly this matrix, instead of a stochastic estimation of the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "And it goes through the algorithm to actually considers the Castle version of the curvature matrix.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So so so the so that researchers such directions inefficient due to the air condition curvature but also the.",
                    "label": 0
                },
                {
                    "sent": "Even if we can get like infinite amount of data to estimate, the greater direction will still be crippled because the curvature problem.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All in the natural gradient.",
                    "label": 1
                },
                {
                    "sent": "By instead of just falling simply the gradient direction G. Here we multiplied by a precondition matrix F inverse, that's.",
                    "label": 0
                },
                {
                    "sent": "Still able to take us almost a lot of shortest path in the Geocities space.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here we're left with the question of how can we actually find the best preconditioner matrix?",
                    "label": 1
                },
                {
                    "sent": "So every considered the current derivations here we have our greatest sense that's derived from considering an identity.",
                    "label": 0
                },
                {
                    "sent": "Curvature matrix.",
                    "label": 0
                },
                {
                    "sent": "So where we consider all the search directions are equally good.",
                    "label": 1
                },
                {
                    "sent": "Where in the natural gradient we consider the search direction that actually going to improve or changes.",
                    "label": 0
                },
                {
                    "sent": "My models output prediction distribution.",
                    "label": 0
                },
                {
                    "sent": "Turned out if we do any second of 2nd order approximations to our constraints, we're going to be left with a family of 2nd order approximation constraints, so that has the form of.",
                    "label": 0
                },
                {
                    "sent": "We're going to multiply the random perturbation by the inverse of preconditioner under the norm of that particular preconditioner.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This gives us the opportunity to think about how we actually going to define, or you can search for a better search direction.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Right, so the ideal condition courage in this case, if we can look at this.",
                    "label": 0
                },
                {
                    "sent": "Example here in 2D.",
                    "label": 0
                },
                {
                    "sent": "So we notice that the.",
                    "label": 0
                },
                {
                    "sent": "For this, like it's not exactly quadratic function, but assuming there's a quadratic function.",
                    "label": 0
                },
                {
                    "sent": "On one side of the ellipse is very stretched out versus the other, so if it is a quadratic function, that means the ratio of the eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Then it's gonna be blown out of proportion.",
                    "label": 0
                },
                {
                    "sent": "So what that means is that now if I'm going to use an SGD algorithm, or like with any of sort of gradient descent 1st order method, what's going to happen is that choosing the learning rate for a constant learning rate for both parameters in this problem becomes really difficult, because if I'm going to make a very small learning right, I'm going to, the algorithm will not have this exact behavior, however, will move very very slowly moves towards the.",
                    "label": 0
                },
                {
                    "sent": "Center of the optimal.",
                    "label": 0
                },
                {
                    "sent": "An If I choose a large learning rate.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be suffering from making very counterproductive moves that's perpendicular to the center of the quadratic bowl.",
                    "label": 0
                },
                {
                    "sent": "So that's why maybe so, the curvature of this.",
                    "label": 0
                },
                {
                    "sent": "Function is your condition means like the ratio of the eigenvalues are.",
                    "label": 0
                },
                {
                    "sent": "Ocean.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so so maybe one intuition on how to find a good precondition matrix A.",
                    "label": 0
                },
                {
                    "sent": "Is to focus on, you know the weight space that hasn't been explored much so far from the previous updates.",
                    "label": 0
                },
                {
                    "sent": "So then we can actually formulate the derivation of the precondition measures a.",
                    "label": 0
                },
                {
                    "sent": "Through another matter optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "So here we are considering to optimize the objective of the precondition matrix that multiply all the previous gradients we have evaluated so far in our optimization trajectory.",
                    "label": 0
                },
                {
                    "sent": "Subject to the constraint that the trace of the OR the sum of the eigenvalues for this preconditioner or that race is bounded by mu and also the preconditioner is positive semidefinite.",
                    "label": 0
                },
                {
                    "sent": "So if we solve this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "What we get is our preconditioners has to be proportional to the sum of the correlations of the gradients from all previous updates under the square root of.",
                    "label": 0
                },
                {
                    "sent": "So so the.",
                    "label": 0
                },
                {
                    "sent": "The algorithms, so this derivation actually gave us a new insight into albums like undergrad Adam.",
                    "label": 0
                },
                {
                    "sent": "Or am I miss props where the updates?",
                    "label": 0
                },
                {
                    "sent": "How we obtained can be considered as we would like to speed up learning along the directions where my previous gradient has not been moved along very much.",
                    "label": 0
                },
                {
                    "sent": "Of course, this matrix a fear what will be the size of number of parameters by number of parameters in practice and not practical to compute so that inverse of the square root of matrix A.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So most of the algorithms would consider a diagonal approximation to this.",
                    "label": 0
                },
                {
                    "sent": "Some of the latest latest algorithms like there's a paper out of Princeton called GT that actually consider how we can actually solve this inverse square root problems in more efficient manners by shuffling.",
                    "label": 0
                },
                {
                    "sent": "Take advantage of low rank and shuffling things around.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in terms of like how this algorithm works, is that.",
                    "label": 0
                },
                {
                    "sent": "Normal SGD pass for this air condition problem.",
                    "label": 0
                },
                {
                    "sent": "We will make a lot of counterproductive moves that towards the high eigenvalue directions.",
                    "label": 0
                },
                {
                    "sent": "And yeah, moving very slowly along the lower directions.",
                    "label": 0
                },
                {
                    "sent": "If so happened that our convex function here is actually aligned.",
                    "label": 0
                },
                {
                    "sent": "Well, we can.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What we can draw intuition is that the along the large eigenvalue directions, our grade is going to have very high variance.",
                    "label": 0
                },
                {
                    "sent": "Along this across many updates.",
                    "label": 0
                },
                {
                    "sent": "A lot of smart like about directions.",
                    "label": 0
                },
                {
                    "sent": "I'll just loss function are greater is going to have small variance.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is precisely what Adam, an adequate does, is that we scale up the small variance weighting search directions, but and also scale down the high variance directions to speed up training.",
                    "label": 0
                },
                {
                    "sent": "So after re adjusting the learning rate for each directions separately, so instead of using a single step size or learning rate for all parameters, Now here will be using a separate learning rate estimate that's computed over the variance of the gradient along that for the parameters over the past many parks.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "However, if the problems that we're trying to solve but only optimization problem trying to solve is not actually aligned.",
                    "label": 0
                },
                {
                    "sent": "The diagonal method is not going to help much in this case.",
                    "label": 0
                },
                {
                    "sent": "We're still going to have very strong correlations among the two parameters here.",
                    "label": 0
                },
                {
                    "sent": "So what we really need is a full covariance or some approximation to the full curvature matrix to correct for the correlations among our parameters.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The problem, however, is the computer full covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Again, to remind yourself is that the new networks with doing in practice actually have millions of parameters, so we're going to have a matrix of millions of millions entries to invert.",
                    "label": 0
                },
                {
                    "sent": "That becomes very intractable, an almost impossible given even given many GPU hours.",
                    "label": 0
                },
                {
                    "sent": "So in practice.",
                    "label": 0
                },
                {
                    "sent": "You will imagine how do we actually solve all those problems, even though the optimization seems so difficult.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the trick that people applied in practice is that instead learning on a single machine that we gather data and compute the gradient estimates for under our current parameters.",
                    "label": 1
                },
                {
                    "sent": "Would rather use parallelization over many machines to get a better estimation of our gradients.",
                    "label": 0
                },
                {
                    "sent": "So it does seems under the latest trick like batch normalization.",
                    "label": 0
                },
                {
                    "sent": "There's reprioritization off on your networks, just simply.",
                    "label": 1
                },
                {
                    "sent": "Um, simply increasing the batch size.",
                    "label": 0
                },
                {
                    "sent": "Would increase the performance of the convergence of the algorithms, right?",
                    "label": 0
                },
                {
                    "sent": "So in this case we run some experiments.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "An image net of of Google Net with batch size 256-1000 and 2000.",
                    "label": 0
                },
                {
                    "sent": "Under the batch normalization.",
                    "label": 0
                },
                {
                    "sent": "There are diminishing returns in those in those curves as we increase the batch size, so the access here I'm plotting is number training points.",
                    "label": 0
                },
                {
                    "sent": "The algorithms consuming So what that means is.",
                    "label": 0
                },
                {
                    "sent": "As we're getting better and better way to estimate our algorithm actually and now making proportion amount of progress to the computation resource we spend on them.",
                    "label": 0
                },
                {
                    "sent": "So we're going to have this Commission return for our SGD algorithms even under the batch normalization.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You know, just another plot to drive this point home.",
                    "label": 0
                },
                {
                    "sent": "When we train those lights, data var resonates on a GPU's.",
                    "label": 0
                },
                {
                    "sent": "Easy takes about like 7 days on.",
                    "label": 0
                },
                {
                    "sent": "Seven days of computer computation time on EC2 with a P-100 GPU's an under rough calculation.",
                    "label": 0
                },
                {
                    "sent": "If I translate access into US dollars, it's going to cost you about $800 to train those models.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Is there anything we can do to speed up the training?",
                    "label": 0
                },
                {
                    "sent": "Also take advantage of the integration we have drawn in the first part of the talk I.",
                    "label": 0
                },
                {
                    "sent": "Using carbon form curvature information is great.",
                    "label": 0
                },
                {
                    "sent": "But we need a more efficient way to utilize them instead of just doing diagonal approximations.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you look at US capabilities of you know all the optimization are going to have talked about so far.",
                    "label": 0
                },
                {
                    "sent": "I will categorize them as black box optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "The reason why is because we only consider a loss function that Max Vector to a real value and then we compute the 1st order.",
                    "label": 0
                },
                {
                    "sent": "You know great information or.",
                    "label": 0
                },
                {
                    "sent": "You know 2nd order curvature informations by looking at the gradients themselves.",
                    "label": 0
                },
                {
                    "sent": "In terms of scalability.",
                    "label": 0
                },
                {
                    "sent": "As she scales really well where the model computation resources but does not scale well with our parameters and also your condition curvatures.",
                    "label": 0
                },
                {
                    "sent": "For natural gradient.",
                    "label": 0
                },
                {
                    "sent": "It has great promise of scale, well, with better gradient estimates and.",
                    "label": 0
                },
                {
                    "sent": "If we can actually invert and compute the curvature information.",
                    "label": 0
                },
                {
                    "sent": "However, it's very memory inefficient and also inverse becomes intractable.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "How can we do better?",
                    "label": 0
                },
                {
                    "sent": "So here's a trick that we can actually looking at the actual computation graph of on your network and maybe we can take advantage of the peculiar way of gradient computation.",
                    "label": 0
                },
                {
                    "sent": "Talk to our advantage so in a four pack of neural networks is that we're going to have an incoming signal.",
                    "label": 0
                },
                {
                    "sent": "The activation of a in our neural network.",
                    "label": 0
                },
                {
                    "sent": "That's being limited projected by a set of weights W. Um Ann, in a backward pass.",
                    "label": 1
                },
                {
                    "sent": "We have to evaluate the popular with spec to the in your projection.",
                    "label": 0
                },
                {
                    "sent": "The comparative of the loss function was back to the output of the linear projection.",
                    "label": 0
                },
                {
                    "sent": "So the actual query and computation.",
                    "label": 0
                },
                {
                    "sent": "Is the outer product of the activations with the partial derivatives that we back propagate through the network?",
                    "label": 1
                },
                {
                    "sent": "And if we flatten out the greater matrix in layer, you didn't rewrite the degrading computation using the Chronicle notation.",
                    "label": 0
                },
                {
                    "sent": "We're going to have the.",
                    "label": 0
                },
                {
                    "sent": "Gradient the vectorized gradient.",
                    "label": 0
                },
                {
                    "sent": "Offer layer.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Of the the the, the way single layer is equal to the Chronicle product of the activations and the partial derivatives that we backcrossed through.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just a quick reminder of what quantity of product is.",
                    "label": 0
                },
                {
                    "sent": "So if you have two matrices A&B in this example, the Chronicle product is computed as you take in a second.",
                    "label": 0
                },
                {
                    "sent": "The second matrix, B tiles in the space of matrix a scaled by the coefficients of matrix A.",
                    "label": 0
                },
                {
                    "sent": "So if you have a 2 by 2.",
                    "label": 0
                },
                {
                    "sent": "The quality product of 2 two by two matrices will result in a four by four matrix.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So another way to think about Chronicle product is it's just a rank auto product in the in the tensor space.",
                    "label": 0
                },
                {
                    "sent": "So effectively we start to notice that.",
                    "label": 0
                },
                {
                    "sent": "The gradient.",
                    "label": 0
                },
                {
                    "sent": "Of Los Angeles.",
                    "label": 0
                },
                {
                    "sent": "Back to the West on a single data point has a rank one structure falling your network.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we can rewrite the if the spatial information matrix was defined as the.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Product of the gradients of unknown networks.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By looking at a single layer, we can write the Fisher Information matrix as the outer product.",
                    "label": 1
                },
                {
                    "sent": "Deactivations clinical product with the other product of the.",
                    "label": 0
                },
                {
                    "sent": "Patrick Perative that we backcrossed through.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the case back algorithm that was proposed by James Martin and Roger Girls back in 2015.",
                    "label": 0
                },
                {
                    "sent": "The facial information matrix.",
                    "label": 0
                },
                {
                    "sent": "After written in the Quantica factored form is further approximated by assuming statistical independence between the activations an.",
                    "label": 0
                },
                {
                    "sent": "And the partial derivative.",
                    "label": 0
                },
                {
                    "sent": "That way back back through.",
                    "label": 0
                },
                {
                    "sent": "So this gave us a huge computational advantage.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine instead of having expectation outside of this clinical product of two matrices.",
                    "label": 0
                },
                {
                    "sent": "Now we all we need to do, just estimate the expected value of each of the quality factors and then compute the aquatic products.",
                    "label": 0
                },
                {
                    "sent": "So why is that a good idea?",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "The idea of Chronicle product.",
                    "label": 0
                },
                {
                    "sent": "The inverse of aquatic products is the quality of product of the inverses.",
                    "label": 0
                },
                {
                    "sent": "And also we are multiplying of vector with a matrix that has a chronic product structure.",
                    "label": 0
                },
                {
                    "sent": "We can reshape the vectors into matrix form that multiply each of the factors independently of each other to the reshape gradient.",
                    "label": 0
                },
                {
                    "sent": "So this because we made a very attractive for two to be used in natural gradient, because now we can just invert the covariance matrix of the activations and covariance matrix of the back propagate error independent of each other.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So instead of.",
                    "label": 0
                },
                {
                    "sent": "So just give you, I guess a inclusion for a typical MNIST model of two hidden layer without the hidden units the.",
                    "label": 0
                },
                {
                    "sent": "The way matrix in the middle will have a 1 million parameters.",
                    "label": 0
                },
                {
                    "sent": "So now if we have to do natural gradients for that middle layer, you would have to invert the matrix a million by million, where in the quantity of product fact because we approximate that as the covariance matrix of the activations which are just assaulted by thousand and covariance matrix of the back public error, which is another thought about the matrices.",
                    "label": 0
                },
                {
                    "sent": "So in terms of communication is a lot more efficient.",
                    "label": 0
                },
                {
                    "sent": "Then computing the exact natural gradient.",
                    "label": 1
                },
                {
                    "sent": "And here we are not assuming any diagonal structures in the.",
                    "label": 0
                },
                {
                    "sent": "In the in the in the Fisher estimate or the curvature estimate?",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "The key fact, however, is too expensive if you have to run this under a single machine.",
                    "label": 0
                },
                {
                    "sent": "The reason why is even inverting a like 1000 by 1000 matrices could be taking like a fraction like hundreds of milliseconds.",
                    "label": 0
                },
                {
                    "sent": "On a CPU that has to be communicated between different processes using a machine where.",
                    "label": 0
                },
                {
                    "sent": "Where all the gradient computations are done on the GPU's.",
                    "label": 0
                },
                {
                    "sent": "So to overcome the computation overhead that introduced by inverting the quality factors.",
                    "label": 0
                },
                {
                    "sent": "So the we can repurpose the current distributed system.",
                    "label": 0
                },
                {
                    "sent": "How we train now and your networks.",
                    "label": 0
                },
                {
                    "sent": "By petition, those gradient workers that works on different mini batches into separate groups that computes the Chronicle vectors.",
                    "label": 0
                },
                {
                    "sent": "That's being used to estimate the curvature matrix, and we have separate group of.",
                    "label": 0
                },
                {
                    "sent": "Machines that compute the inverses of all those.",
                    "label": 0
                },
                {
                    "sent": "Factors.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in practice.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You know the scientific question to ask is that?",
                    "label": 0
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "Is this kind of distributed algorithm going to scale?",
                    "label": 0
                },
                {
                    "sent": "It just as well as SGD, or is actually going to do better?",
                    "label": 0
                },
                {
                    "sent": "So if we plot if we make overlay the Cape curves on top of SGD image net we notice is that photos models of millions of parameters.",
                    "label": 0
                },
                {
                    "sent": "Under SGD would still have the diminishing return, but under the SAFE Act as we increase the batch size, the per training example progress we're making is actually more or less constant.",
                    "label": 0
                },
                {
                    "sent": "So what that means is like if you can compute the very clean gradient using 2000 examples at each update you expect it to get twice as quiet, 2X amount of speedup if you compute the gradients using just one thousand data points.",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                },
                {
                    "sent": "So so the so the K factor were.",
                    "label": 0
                },
                {
                    "sent": "So more recently, I guess there's more.",
                    "label": 0
                },
                {
                    "sent": "Algorithm that had been looking into how we can actually take advantage of the computation graphs of the neural networks.",
                    "label": 0
                },
                {
                    "sent": "So in the.",
                    "label": 0
                },
                {
                    "sent": "The shampoo paper from Princeton.",
                    "label": 0
                },
                {
                    "sent": "Instead of going through all the details of how the new network actually compute the gradients.",
                    "label": 0
                },
                {
                    "sent": "All shampoo algorithm does is we estimate, assuming the gradients of the parameters in the shape of a tensor and it will normalize or white and each of the issue of the tensor dimensions independently of each other using the covariance matrix with computer from a gradient estimate along that particular slice of that answer.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I think moving on from black box optimization to white box optimization is quite exciting.",
                    "label": 0
                },
                {
                    "sent": "Progress that we're making here, and.",
                    "label": 0
                },
                {
                    "sent": "So you know just going back to the center slides of this talk where all those underlying algorithms from their frameworks are derived from a single objective, which is, well, how should we find a better search direction to change the way soften your network?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And under different constraints.",
                    "label": 0
                },
                {
                    "sent": "Which arrive different flavors of the algorithms?",
                    "label": 0
                },
                {
                    "sent": "And given more informations about the actual computation graph of underlying loss computation, we're able to derive more efficient algorithms to approximate the.",
                    "label": 0
                },
                {
                    "sent": "The complication, the required complications for those curvature matrix.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Like right?",
                    "label": 0
                },
                {
                    "sent": "So it does not.",
                    "label": 0
                },
                {
                    "sent": "So it gives comfort virtualization.",
                    "label": 0
                },
                {
                    "sent": "It's in time slightly worse than SGD.",
                    "label": 0
                },
                {
                    "sent": "Yes, and the way we suspect what happened there is because we're using the optimizer.",
                    "label": 0
                },
                {
                    "sent": "That's a lot stronger and is able to find a more efficient search direction to SGD.",
                    "label": 0
                },
                {
                    "sent": "The regularizers that the hyperparameter for the regularizers need to be tuned corresponding however, in the experiment we run with natural gradient.",
                    "label": 0
                },
                {
                    "sent": "We use, we retain the same hyperparameters, SGD runs.",
                    "label": 0
                },
                {
                    "sent": "So that was the conjecture down.",
                    "label": 0
                },
                {
                    "sent": "Why did you like there still?",
                    "label": 0
                },
                {
                    "sent": "Image net I believe there was a 2% gap between the natural gradient, an SGD on the top one prediction.",
                    "label": 1
                },
                {
                    "sent": "Hey.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So yeah, so this concludes my talk here, and you're more than welcome to ask more questions.",
                    "label": 0
                },
                {
                    "sent": "Sure.",
                    "label": 0
                },
                {
                    "sent": "To follow up on some jeans question, if you do a more noisy gradient estimation in the natural gradient, does that?",
                    "label": 0
                },
                {
                    "sent": "Does it improve generalization?",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                },
                {
                    "sent": "I believe there so the.",
                    "label": 0
                },
                {
                    "sent": "So the result is mixed.",
                    "label": 0
                },
                {
                    "sent": "We we have done very limited set of experiments using very small batch to estimate here gradients and using large batch to estimate the curvature information matrix and turned out.",
                    "label": 0
                },
                {
                    "sent": "You can improve the generation by using a noisy gradient estimate.",
                    "label": 0
                },
                {
                    "sent": "But the expense was so limited that I don't want to claim, yeah, overclaimed results.",
                    "label": 0
                },
                {
                    "sent": "If I can, can I do a second question so there is a critical step in your derivation where you have the expectation first activation functions multiplied by the gradients.",
                    "label": 0
                },
                {
                    "sent": "Yes, and then you separate them.",
                    "label": 0
                },
                {
                    "sent": "Do you see cases where that that is not doing that?",
                    "label": 0
                },
                {
                    "sent": "Not not valid, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "I guess in the intuition here is that well, if we consider the statistics among activations and positives or independent.",
                    "label": 0
                },
                {
                    "sent": "What we're really saying is that now you can.",
                    "label": 0
                },
                {
                    "sent": "Swap out the four pass activations.",
                    "label": 0
                },
                {
                    "sent": "An if backdrop error signals among the training points.",
                    "label": 0
                },
                {
                    "sent": "And the second is statistics are like, you know, independent from each other, so for.",
                    "label": 0
                },
                {
                    "sent": "So for the 1st order information, that's certainly not true.",
                    "label": 0
                },
                {
                    "sent": "The for the 1st order information that what I mean is that the domain of the forward activations under a data point versus the backdrop signal for is going to be very different across the training point.",
                    "label": 0
                },
                {
                    "sent": "However, the second one is statistics.",
                    "label": 0
                },
                {
                    "sent": "The covariance there's reason to believe well after neuron a particular neurons always useful to detect an edge in the image.",
                    "label": 0
                },
                {
                    "sent": "You'll probably have a similar.",
                    "label": 0
                },
                {
                    "sent": "The and then the.",
                    "label": 0
                },
                {
                    "sent": "Other neurons in in the same layers that the tax slighted, like a couple of filters that's correlated.",
                    "label": 0
                },
                {
                    "sent": "Then the correlation among the activations were still persist across the training points.",
                    "label": 0
                },
                {
                    "sent": "But the actual numerical value themselves were probably not so, so under that assumption, I think is safe to assume the second sticks are independent.",
                    "label": 0
                },
                {
                    "sent": "No thank you.",
                    "label": 0
                },
                {
                    "sent": "Can you go back to the page before the thank you one?",
                    "label": 0
                },
                {
                    "sent": "Page of the second last one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it seems like.",
                    "label": 0
                },
                {
                    "sent": "All problems that you mentioned here are constrained optimization problems, but at least for gradient descent, are you really solving this problem or you know what artist?",
                    "label": 0
                },
                {
                    "sent": "But the real problem that you are solving this if you like software is constrained optimization problem.",
                    "label": 0
                },
                {
                    "sent": "You your step sizes might be.",
                    "label": 0
                },
                {
                    "sent": "Determined by the algorithm instead of setting by hand.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Um, yes.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "The practical, greater detail when they were used to train your networks, always assume a constant step size.",
                    "label": 0
                },
                {
                    "sent": "Which is so different than, you know, if you like to converge on a convex problem, you probably want to step side that proportional to the square root of how many updates you have done so far.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But I guess it's hard to even.",
                    "label": 0
                },
                {
                    "sent": "I guess it's so we probably want to define what we mean by solving the correct problem, like if the correct problem here means we actually decrease in the loss function at each time step.",
                    "label": 0
                },
                {
                    "sent": "Like on average, then that's probably true.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so even Goodfellow had a paper looking at those SGD ever going uphill during the course of optimizing it.",
                    "label": 0
                },
                {
                    "sent": "Deep neural networks and turns out most of the time, it's always going downhill.",
                    "label": 0
                },
                {
                    "sent": "So in that sense, we're probably solving the right objective function.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so for natural gradient are you penalized?",
                    "label": 0
                },
                {
                    "sent": "This pal divergance in your objective?",
                    "label": 0
                },
                {
                    "sent": "Or like practically, how do you do it right?",
                    "label": 0
                },
                {
                    "sent": "So the proco algorithms for natural gradient will be taking your granny update?",
                    "label": 0
                },
                {
                    "sent": "Multiply by the inverse of the Fisher information matrix so that that's the update comes from the.",
                    "label": 0
                },
                {
                    "sent": "The Taylor Taylor expansions on the constraint and solve for the Lagrangian multiplier.",
                    "label": 0
                },
                {
                    "sent": "And now you derive a close form update rule.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the nice talk.",
                    "label": 0
                },
                {
                    "sent": "I just want to follow up on the discussion that you're having.",
                    "label": 0
                },
                {
                    "sent": "And touch on the more general question of optimization and realization which Sanjeev already talked about and I guess it's going to be maybe a theme today.",
                    "label": 0
                },
                {
                    "sent": "Maybe?",
                    "label": 0
                },
                {
                    "sent": "You don't want to have the loading rate and yield to zero.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you wanted to do purely optimization, that's what you would want to do, but.",
                    "label": 0
                },
                {
                    "sent": "The the noise injected by the level of the running rate and the small batch size is having a positive impact on realization.",
                    "label": 0
                },
                {
                    "sent": "In various ways that we are only starting to understand so.",
                    "label": 0
                },
                {
                    "sent": "Can you comment on that?",
                    "label": 0
                },
                {
                    "sent": "I mean it with respect what you've been talking about and the worst realization you obtained with K fact.",
                    "label": 0
                },
                {
                    "sent": "Yes, so I think when.",
                    "label": 0
                },
                {
                    "sent": "I guess my own personal view on optimization and realization is that when we drive the optimization algorithm is probably.",
                    "label": 0
                },
                {
                    "sent": "It's probably a good idea.",
                    "label": 0
                },
                {
                    "sent": "Just focus on the convergence rate of on the training set rather than thinking that's easier, right?",
                    "label": 0
                },
                {
                    "sent": "It's much easier to make a case for the algorithm rather than because once we start to consider all the implicit regularization effect, for example coming from the noisy statistics estimate from batch normalization layers, constant step size.",
                    "label": 0
                },
                {
                    "sent": "The non come back to the other problems and how they interact with constant step sides.",
                    "label": 0
                },
                {
                    "sent": "Problem becomes.",
                    "label": 0
                },
                {
                    "sent": "Harder to.",
                    "label": 0
                },
                {
                    "sent": "To have a clean argument on which I want works better, because now you have two competing objective one is.",
                    "label": 0
                },
                {
                    "sent": "That's what she learning, yes.",
                    "label": 0
                },
                {
                    "sent": "So so my, I guess I don't have any like you know, theoretical proof or anything like that, but empirically it does.",
                    "label": 0
                },
                {
                    "sent": "Seems like all the generalization gap we have seen by using a very strong optimizers.",
                    "label": 0
                },
                {
                    "sent": "Natural gradient or?",
                    "label": 0
                },
                {
                    "sent": "Hashing free methods can be partially solved by retrieving the regularization hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So instead of using the exact same regularization hyperparameters as SGD.",
                    "label": 0
                },
                {
                    "sent": "There will be like retune, or maybe you need other types of.",
                    "label": 0
                },
                {
                    "sent": "I mean regularization.",
                    "label": 0
                },
                {
                    "sent": "Maybe you need to inject noise in different ways, for example, and things like that, right, right so?",
                    "label": 0
                },
                {
                    "sent": "I guess so.",
                    "label": 0
                },
                {
                    "sent": "So the question is like, well, if we moving out to those technologies method that's you know, kind numerically sensitive that requires to use large batch to estimate those gradients.",
                    "label": 0
                },
                {
                    "sent": "And doing in versus.",
                    "label": 0
                },
                {
                    "sent": "We do lose some kind of Cassidy and stochastic cities in our models, right?",
                    "label": 0
                },
                {
                    "sent": "Because now a batch is a lot bigger.",
                    "label": 0
                },
                {
                    "sent": "If we believe the story that smaller batch is equivalent to three, large batch is equivalent to a small batch plus the.",
                    "label": 0
                },
                {
                    "sent": "A noise that was second with statistics is proportional to the curvature of the Fisher Information matrix.",
                    "label": 0
                },
                {
                    "sent": "Then we're certainly losing a lot of regularization here, however.",
                    "label": 0
                },
                {
                    "sent": "In your networks we have.",
                    "label": 0
                },
                {
                    "sent": "We can add in drop houses we can add in weight the case and so my personal view is that if we just reach you, all the hyperparameters for.",
                    "label": 0
                },
                {
                    "sent": "But why hasn't it happened?",
                    "label": 0
                },
                {
                    "sent": "I mean there are many researchers are trying to improve optimization methods for neural net and I think most of them understand that.",
                    "label": 0
                },
                {
                    "sent": "So you're saying you didn't optimize the hyperparameters but you know.",
                    "label": 0
                },
                {
                    "sent": "It's not that hard to do it.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of works in the past.",
                    "label": 0
                },
                {
                    "sent": "People have tried hard.",
                    "label": 0
                },
                {
                    "sent": "Right, so I cannot comment on this image net.",
                    "label": 0
                },
                {
                    "sent": "So so in.",
                    "label": 0
                },
                {
                    "sent": "In Toronto, various students have tried to reproduce the larger generalization gap results by swapping out STD's with Adam or natural gradients.",
                    "label": 0
                },
                {
                    "sent": "K fact natural gradient.",
                    "label": 0
                },
                {
                    "sent": "What we found is at least once before 10.",
                    "label": 0
                },
                {
                    "sent": "If you increase the weighted case and adding more dropouts.",
                    "label": 0
                },
                {
                    "sent": "We always recover well as the same generation, so of course the training curve was suffer a bit would not get as impressive result as being the original optimization paper.",
                    "label": 0
                },
                {
                    "sent": "But we do recover more or less the same generalization.",
                    "label": 0
                },
                {
                    "sent": "So I have a counter question for you.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So like what?",
                    "label": 0
                },
                {
                    "sent": "I guess, so for people who and students Ann writing, you know, algorithm papers for deep learning and machine learning.",
                    "label": 0
                },
                {
                    "sent": "Where do we draw the boundary of?",
                    "label": 0
                },
                {
                    "sent": "Here's an algorithm that minimize the training really well.",
                    "label": 0
                },
                {
                    "sent": "Or here's an algorithm that does a bit of everything.",
                    "label": 0
                },
                {
                    "sent": "I think we shouldn't try too hard to separate those two things because they they interact strongly.",
                    "label": 0
                },
                {
                    "sent": "What we need to do is to understand that interaction.",
                    "label": 0
                },
                {
                    "sent": "So if SGD somehow is helping generalization, we need to really get to the bottom of what is going on so that we can potentially use some of those principles with other like stronger optimization methods.",
                    "label": 0
                },
                {
                    "sent": "But I think it's unavoidable that we will have these interactions between the optimization method, an indigenization effect, and so we can't.",
                    "label": 0
                },
                {
                    "sent": "If we want to really do machine learning, we can't just do the optimization on its own.",
                    "label": 0
                },
                {
                    "sent": "I mean, maybe it's a good first step from the point of view of research like OK, so here's an optimization at that.",
                    "label": 0
                },
                {
                    "sent": "Which of these works on the nonconvex case?",
                    "label": 0
                },
                {
                    "sent": "But to really make it useful for practitioners, we also need to study that the translation effect.",
                    "label": 0
                },
                {
                    "sent": "And maybe how we need to address that?",
                    "label": 0
                },
                {
                    "sent": "With those new algorithms.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, thanks.",
                    "label": 0
                }
            ]
        }
    }
}