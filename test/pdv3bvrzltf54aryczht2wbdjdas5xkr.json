{
    "id": "pdv3bvrzltf54aryczht2wbdjdas5xkr",
    "title": "Finding, Assessing, and Integrating Statistical Sources for Data Mining",
    "info": {
        "author": [
            "Craig A. Knoblock, Information Sciences Institute (ISI), University of Southern California"
        ],
        "published": "July 15, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_knoblock_data_mining/",
    "segmentation": [
        [
            "OK, so I'm going to talk about this work we've been doing on finding, assessing and integrating statistical sources for data mining, and this is joint work with my colleagues Karen Becker and Judgy Town who are both visiting faculty members at USC and Shiva, giant Garin who's a master student at USC.",
            "So this is all work that was done at USC with all these people."
        ],
        [
            "OK, so by way of introduction here, there's a number of statistical data sets that are now available in the linked open data, and if you haven't seen recently, if you can see the link data cloud over there, which is from 2014, and I know you can actually see the sources here, but it's worth noting that this set of sources here, which is a huge part of the course part of the link data Cloud now, are all statistical sources, right?",
            "And so this is like a huge increase, something like 300% in the last sort of linked data cloud census, so.",
            "There's just a tremendous amount of sort of statistical data that's now being published in this cloud, which is great 'cause you can use it for doing all kinds of sort of interesting analysis.",
            "I mean, it's it's especially for doing sort of data mining knowledge discovery kind of stuff.",
            "It's a huge opportunity because there's so much data out there that comes from all different sources.",
            "The World Health Organization, the UN.",
            "I mean there's a whole variety of sources out there that are publishing this kind of statistical data.",
            "An one nice thing is that there's sort of an emerging sort of a capillary standard, which is the cube ontology that's that's come out is sort of ontology that everyone is using to actually publish statistical data.",
            "So you think, OK, great, we can really leverage all of this.",
            "Sort of all the data that's coming together.",
            "Plus this opportunity that people are actually modeling the data."
        ],
        [
            "With the Sammy domain ontology.",
            "OK, so you know if you look at sort of existing tools that's out there that people are using, so there are existing tools that basically support sort of querying and visualization of the data in cubes.",
            "Most of these systems assume that you've already identified what specific data set you're using, which cube data, which data sets that are actually given, and then the integration is pretty much left to you.",
            "The user to figure out how you're going to combine the data from these different sources.",
            "So our goal in this project.",
            "Is to essentially come up with mechanisms for both finding and integrating these datasets that contain compatible sort of data or compatible.",
            "We're calling indicators here and to do this requires sort of the data selection, meaning you have to find which sources contain information looking for as well as the preprocessing up the data to get into the form that you could actually then run some kind of data mining tool on top of it, OK?"
        ],
        [
            "So our motivating sort of scenario domain here is a domain called peacebuilding.",
            "The idea behind peacebuilding is unlike peacekeeping.",
            "The idea is to actually identify you know what's going on in different countries in the world.",
            "An address those issues that come up.",
            "These might be things like food insecurity or water problems, or any diseases, poverty and so on.",
            "So the idea is actually identify what specific aspects that are happening within the company within a given country that need to be addressed to sort of word off sort of conflicts.",
            "Finally, conflicts in the country.",
            "So one problem we were looking at is actually predicting what are called fragile state indicators.",
            "These are things like economic decline and these are influenced by things like inflation, gross domestic product, unemployment in a whole variety of features like this and the data that we need to do this is actually available so it's available in a number of these sort of open source portals.",
            "But the challenge I mean, these are sort of some of the different data sources here World Bank and FAO.",
            "But the problems here are.",
            "First, finding the specific information that you need to do these kinds of predictions actually understanding the data.",
            "So you need some kind of interpretation of it to make sense of it off, and you have to deal with sort of proprietary APIs and formats and then integrating the data across these different sources.",
            "Because if you want to run some kind of data mining algorithm on top of it, the data needs to be in some coherent format and you know today this is quite laborious time consuming and it's actually prone to error, right?",
            "Because if you're going to manually put all this stuff together you make."
        ],
        [
            "OK, so our approach that is to basically exploit the fact that the information much of this information is already been published in the link Data Cloud.",
            "So if we want to be able to combine information about economic decline, including all the different features here, and then typically what happens to these kinds of analysis, we want to do this typically by country.",
            "So you need you know you have some set of countries that you're interested in looking at and then also you have some particular sometime.",
            "And one of the nice things about the Cube ontology is that you can represent this multi mention this multidimensional data.",
            "Where you have the combination of the different attributes that you're looking at, combined with things like the countries in the years and so on."
        ],
        [
            "So the idea is to actually pull all this in."
        ],
        [
            "Nation together from the cube and then be able to run the data mining tools on top of it and then once once you pull the information together then you can run in through any of a variety of data mining algorithms, right?",
            "It might be R or rapidminer.",
            "Any of these different systems that are out there?"
        ],
        [
            "OK, so here's the overall approach that we're taking to this problem.",
            "So the idea is that we start with.",
            "We have the link data cloud here and we have some kind of wrappers for this and I'll come back and talk about these.",
            "Each of these steps in more detail, but just to give you a quick overview, the idea is that, well, you have these different steps here.",
            "First we need to find set an set of initial cube candidates.",
            "These are the.",
            "These are the cubes that actually contain the data that we're looking for.",
            "Once we have that, then we need to look at some kind of compatibility verification to make sure that the data across the different datasets that we're going to pull together actually has the same dimensions.",
            "You know, covers the same periods of time and so on.",
            "Then we have the essentially pull this information together, integrated in some way so that we could actually put it into a single format or organized into which a way that you can.",
            "You can run the algorithms on top of it, and then some sort of verification algorithms to actually ensure that the data isn't.",
            "Filled with no values in this kind of things."
        ],
        [
            "OK, so I'm going to walk through each of these different steps, but first I want to.",
            "I want to talk about what happens with actually using the Cuban practice, right?",
            "Because it seems nice.",
            "You know we have the same ontology.",
            "All the data is represented with respect to that, so we should just be able to use it, right?",
            "Well, it turns out that the cube covers quite nice and provides the standard concepts, but there are vastly different modeling styles that are actually being used with respect to the queue.",
            "So ideally when you're using the cube you supposed to use this data definition structure, which.",
            "Provide certain explicit definition of all the different measures and dimensions and so on that are actually used in the actual datasets.",
            "In practice, it's typically not the case right there, there's only a small percentage of the published sort of statistical datasets even using the cube that actually use this data definition structure.",
            "Sadly, so then it turns out that you have all these different datasets that are using the cube.",
            "Doing it in different ways, and typically what happens?",
            "You have these semantics that are associated at different levels and using different properties, right?",
            "So they may have.",
            "They may be using the cube at some level, but then they don't actually use all the properties that are actually defined in the cube, so you have these sort of explicit constructs in the cube that are supposed to be used, and oftentimes they're not, and what's typically happening is the same thing that you see in a lot of linked data, whereas people start with some data set and they just publish it with respect to the schema that they already have, right?",
            "And this is happening.",
            "There's this commonly used Reputation S DMX statistical data.",
            "Meta exchange, I forget exactly.",
            "It's statistical data and metadata exchange format that many of these datasets start out in and then what they do is they just map it directly into the cube without actually doing the mapping of all the individual features from that.",
            "So what you get is a whole variety of ways that the data actually gets represented, so it makes this problem a little bit more challenging."
        ],
        [
            "So let me walk through the steps that we take to essentially addressed this overall problem.",
            "So first we start out with the Cube catalog.",
            "This comes from sort of existing catalog of sort of end points that are available and what we do is we start with a set of of seed concept.",
            "So we essentially go and we search for these seat concepts and find those cubes that actually appear to contain the features that we're looking for, and they also have to find sort of the entities of interest.",
            "In this case, these are typically the countries that were looking for in the.",
            "Data sets and then the temple definition, which is the time period that we're actually interested in.",
            "Because you may have different cubes that are covering different time periods.",
            "And so you essentially search for these things in the cubes that are available in this catalog, and you find a set of candidate once these are."
        ],
        [
            "Then oh and then.",
            "We have to deal with the fact that the data is formatted in different ways and so we basically build wrappers which are essentially queries, sparkle queries to the different SPARQL endpoints to get the data out in some sort of standard format so we can build these wrappers in advance for the different cubes that we might want to use.",
            "And that helps us resolve some of the ways that the different properties are actually modeled across these."
        ],
        [
            "Thanks so finally, once you generate this set of candidates, we have to do some kind of compatibility verification.",
            "So this essentially gives us this set of indicators after we counted indicators.",
            "After we've done this search of the different cubes and pulled out the potential cubes that contain the data that we're looking for, and so we're essentially finding ones that actually match the combination of the indicators were searching for and the.",
            "Coverage in terms of countries in years in this case."
        ],
        [
            "So match here is essentially defined as this.",
            "They have to match in terms of the descriptions they have to match in terms of the countries and then match in terms of the dimension."
        ],
        [
            "Of years."
        ],
        [
            "OK, once we have this so once we get the data back and we've sent to identify those things, now we actually have to put it together in some way that we can actually then do some additional processing.",
            "So the processing we pull this all into rapidminer but we need to get the data in some form that can be used and so there's a couple of different kinds of of combinations we have here.",
            "We have two joins across the different indicators, so if I'm pulling information about GDP from one source and inflation from a different source, I need to pull that information together and then.",
            "You have some cubes that might be organized such that maybe you're interested in inflation and then one source might have the inflation organized simply as a different data set for each different year.",
            "So all of that has to be combined.",
            "And then finally in the last."
        ],
        [
            "We do some sanity checking where maybe we remove data that has a large number of empty values or and we can do sort of more advanced kinds of sanity checking that looks at things like you know whether or not the distributions are skewed on the data.",
            "OK, so."
        ],
        [
            "Quickly mentioned there's a variety of related work on this topic, so there's a number of sort of cube platforms, right.",
            "LD, two statistical Workbench Open cube OLAP for LD within all these systems, supports or the creation validation querying.",
            "And visualization of these different kinds of datasets.",
            "Other people using the cube for doing data mining on them.",
            "There's the LD extension for Rapidminer, which has a nice set of operators for integrating data with data and provide sort of Cuba travel operator.",
            "So we build on top of that work.",
            "There's some recent work by Jen Kranken and Shell on identifying relevant data in LD from seed concepts, so this similar to what we're doing here, except they don't actually deal with multidimensional data.",
            "So I would say that you know the work I'm describing here really compliments these work.",
            "In terms of the functionality being provided, so we're really focused on sort of the automatic discovery and integration of the data, and I think it complements very nicely some of the other work that's already."
        ],
        [
            "So just to wrap up here.",
            "So what we're working on is an approach to essentially finding and integrating these cube datasets from some set of initial seed concepts, so these are the essentially the initial types of things that you're looking for here, assessing their compatibility.",
            "So whether or not they actually covered the same time periods and regions that you're interested in, and then integrating them to generate some kind of data mining data set, then we can run additional.",
            "Data mining algorithms on top of so next steps in terms of what we're planning to do next, here is first automatic generation of the query wrapper.",
            "So 11 issue here is that right now we have to manually write the wrappers for the different formats and stuff, but we think that this is a task that that we can automate the generation of these types of rappers and then the second thing we're looking at is then actually exploiting this data for predicting the indicators, right?",
            "So if we want to predict these sort of fragile state indicators, we want to be able to pull the information together.",
            "From all these different datasets and then and then be able to come up with the actual predictions on the data.",
            "So that's really the main task that we started out with and then discovered that OK, we had to sort of solve this subproblem first, which is finding the data and getting it into the format that we could actually use it before we could get to the to the meat of the problem.",
            "So thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to talk about this work we've been doing on finding, assessing and integrating statistical sources for data mining, and this is joint work with my colleagues Karen Becker and Judgy Town who are both visiting faculty members at USC and Shiva, giant Garin who's a master student at USC.",
                    "label": 0
                },
                {
                    "sent": "So this is all work that was done at USC with all these people.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so by way of introduction here, there's a number of statistical data sets that are now available in the linked open data, and if you haven't seen recently, if you can see the link data cloud over there, which is from 2014, and I know you can actually see the sources here, but it's worth noting that this set of sources here, which is a huge part of the course part of the link data Cloud now, are all statistical sources, right?",
                    "label": 0
                },
                {
                    "sent": "And so this is like a huge increase, something like 300% in the last sort of linked data cloud census, so.",
                    "label": 1
                },
                {
                    "sent": "There's just a tremendous amount of sort of statistical data that's now being published in this cloud, which is great 'cause you can use it for doing all kinds of sort of interesting analysis.",
                    "label": 1
                },
                {
                    "sent": "I mean, it's it's especially for doing sort of data mining knowledge discovery kind of stuff.",
                    "label": 0
                },
                {
                    "sent": "It's a huge opportunity because there's so much data out there that comes from all different sources.",
                    "label": 1
                },
                {
                    "sent": "The World Health Organization, the UN.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a whole variety of sources out there that are publishing this kind of statistical data.",
                    "label": 0
                },
                {
                    "sent": "An one nice thing is that there's sort of an emerging sort of a capillary standard, which is the cube ontology that's that's come out is sort of ontology that everyone is using to actually publish statistical data.",
                    "label": 0
                },
                {
                    "sent": "So you think, OK, great, we can really leverage all of this.",
                    "label": 0
                },
                {
                    "sent": "Sort of all the data that's coming together.",
                    "label": 0
                },
                {
                    "sent": "Plus this opportunity that people are actually modeling the data.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With the Sammy domain ontology.",
                    "label": 0
                },
                {
                    "sent": "OK, so you know if you look at sort of existing tools that's out there that people are using, so there are existing tools that basically support sort of querying and visualization of the data in cubes.",
                    "label": 0
                },
                {
                    "sent": "Most of these systems assume that you've already identified what specific data set you're using, which cube data, which data sets that are actually given, and then the integration is pretty much left to you.",
                    "label": 0
                },
                {
                    "sent": "The user to figure out how you're going to combine the data from these different sources.",
                    "label": 0
                },
                {
                    "sent": "So our goal in this project.",
                    "label": 1
                },
                {
                    "sent": "Is to essentially come up with mechanisms for both finding and integrating these datasets that contain compatible sort of data or compatible.",
                    "label": 1
                },
                {
                    "sent": "We're calling indicators here and to do this requires sort of the data selection, meaning you have to find which sources contain information looking for as well as the preprocessing up the data to get into the form that you could actually then run some kind of data mining tool on top of it, OK?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our motivating sort of scenario domain here is a domain called peacebuilding.",
                    "label": 0
                },
                {
                    "sent": "The idea behind peacebuilding is unlike peacekeeping.",
                    "label": 0
                },
                {
                    "sent": "The idea is to actually identify you know what's going on in different countries in the world.",
                    "label": 0
                },
                {
                    "sent": "An address those issues that come up.",
                    "label": 0
                },
                {
                    "sent": "These might be things like food insecurity or water problems, or any diseases, poverty and so on.",
                    "label": 0
                },
                {
                    "sent": "So the idea is actually identify what specific aspects that are happening within the company within a given country that need to be addressed to sort of word off sort of conflicts.",
                    "label": 0
                },
                {
                    "sent": "Finally, conflicts in the country.",
                    "label": 0
                },
                {
                    "sent": "So one problem we were looking at is actually predicting what are called fragile state indicators.",
                    "label": 0
                },
                {
                    "sent": "These are things like economic decline and these are influenced by things like inflation, gross domestic product, unemployment in a whole variety of features like this and the data that we need to do this is actually available so it's available in a number of these sort of open source portals.",
                    "label": 0
                },
                {
                    "sent": "But the challenge I mean, these are sort of some of the different data sources here World Bank and FAO.",
                    "label": 0
                },
                {
                    "sent": "But the problems here are.",
                    "label": 0
                },
                {
                    "sent": "First, finding the specific information that you need to do these kinds of predictions actually understanding the data.",
                    "label": 0
                },
                {
                    "sent": "So you need some kind of interpretation of it to make sense of it off, and you have to deal with sort of proprietary APIs and formats and then integrating the data across these different sources.",
                    "label": 1
                },
                {
                    "sent": "Because if you want to run some kind of data mining algorithm on top of it, the data needs to be in some coherent format and you know today this is quite laborious time consuming and it's actually prone to error, right?",
                    "label": 0
                },
                {
                    "sent": "Because if you're going to manually put all this stuff together you make.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so our approach that is to basically exploit the fact that the information much of this information is already been published in the link Data Cloud.",
                    "label": 0
                },
                {
                    "sent": "So if we want to be able to combine information about economic decline, including all the different features here, and then typically what happens to these kinds of analysis, we want to do this typically by country.",
                    "label": 0
                },
                {
                    "sent": "So you need you know you have some set of countries that you're interested in looking at and then also you have some particular sometime.",
                    "label": 0
                },
                {
                    "sent": "And one of the nice things about the Cube ontology is that you can represent this multi mention this multidimensional data.",
                    "label": 0
                },
                {
                    "sent": "Where you have the combination of the different attributes that you're looking at, combined with things like the countries in the years and so on.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is to actually pull all this in.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation together from the cube and then be able to run the data mining tools on top of it and then once once you pull the information together then you can run in through any of a variety of data mining algorithms, right?",
                    "label": 0
                },
                {
                    "sent": "It might be R or rapidminer.",
                    "label": 0
                },
                {
                    "sent": "Any of these different systems that are out there?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's the overall approach that we're taking to this problem.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we start with.",
                    "label": 0
                },
                {
                    "sent": "We have the link data cloud here and we have some kind of wrappers for this and I'll come back and talk about these.",
                    "label": 0
                },
                {
                    "sent": "Each of these steps in more detail, but just to give you a quick overview, the idea is that, well, you have these different steps here.",
                    "label": 0
                },
                {
                    "sent": "First we need to find set an set of initial cube candidates.",
                    "label": 0
                },
                {
                    "sent": "These are the.",
                    "label": 0
                },
                {
                    "sent": "These are the cubes that actually contain the data that we're looking for.",
                    "label": 0
                },
                {
                    "sent": "Once we have that, then we need to look at some kind of compatibility verification to make sure that the data across the different datasets that we're going to pull together actually has the same dimensions.",
                    "label": 0
                },
                {
                    "sent": "You know, covers the same periods of time and so on.",
                    "label": 0
                },
                {
                    "sent": "Then we have the essentially pull this information together, integrated in some way so that we could actually put it into a single format or organized into which a way that you can.",
                    "label": 0
                },
                {
                    "sent": "You can run the algorithms on top of it, and then some sort of verification algorithms to actually ensure that the data isn't.",
                    "label": 0
                },
                {
                    "sent": "Filled with no values in this kind of things.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to walk through each of these different steps, but first I want to.",
                    "label": 0
                },
                {
                    "sent": "I want to talk about what happens with actually using the Cuban practice, right?",
                    "label": 0
                },
                {
                    "sent": "Because it seems nice.",
                    "label": 0
                },
                {
                    "sent": "You know we have the same ontology.",
                    "label": 0
                },
                {
                    "sent": "All the data is represented with respect to that, so we should just be able to use it, right?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that the cube covers quite nice and provides the standard concepts, but there are vastly different modeling styles that are actually being used with respect to the queue.",
                    "label": 0
                },
                {
                    "sent": "So ideally when you're using the cube you supposed to use this data definition structure, which.",
                    "label": 0
                },
                {
                    "sent": "Provide certain explicit definition of all the different measures and dimensions and so on that are actually used in the actual datasets.",
                    "label": 1
                },
                {
                    "sent": "In practice, it's typically not the case right there, there's only a small percentage of the published sort of statistical datasets even using the cube that actually use this data definition structure.",
                    "label": 0
                },
                {
                    "sent": "Sadly, so then it turns out that you have all these different datasets that are using the cube.",
                    "label": 0
                },
                {
                    "sent": "Doing it in different ways, and typically what happens?",
                    "label": 0
                },
                {
                    "sent": "You have these semantics that are associated at different levels and using different properties, right?",
                    "label": 1
                },
                {
                    "sent": "So they may have.",
                    "label": 0
                },
                {
                    "sent": "They may be using the cube at some level, but then they don't actually use all the properties that are actually defined in the cube, so you have these sort of explicit constructs in the cube that are supposed to be used, and oftentimes they're not, and what's typically happening is the same thing that you see in a lot of linked data, whereas people start with some data set and they just publish it with respect to the schema that they already have, right?",
                    "label": 0
                },
                {
                    "sent": "And this is happening.",
                    "label": 0
                },
                {
                    "sent": "There's this commonly used Reputation S DMX statistical data.",
                    "label": 0
                },
                {
                    "sent": "Meta exchange, I forget exactly.",
                    "label": 0
                },
                {
                    "sent": "It's statistical data and metadata exchange format that many of these datasets start out in and then what they do is they just map it directly into the cube without actually doing the mapping of all the individual features from that.",
                    "label": 0
                },
                {
                    "sent": "So what you get is a whole variety of ways that the data actually gets represented, so it makes this problem a little bit more challenging.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me walk through the steps that we take to essentially addressed this overall problem.",
                    "label": 0
                },
                {
                    "sent": "So first we start out with the Cube catalog.",
                    "label": 0
                },
                {
                    "sent": "This comes from sort of existing catalog of sort of end points that are available and what we do is we start with a set of of seed concept.",
                    "label": 0
                },
                {
                    "sent": "So we essentially go and we search for these seat concepts and find those cubes that actually appear to contain the features that we're looking for, and they also have to find sort of the entities of interest.",
                    "label": 1
                },
                {
                    "sent": "In this case, these are typically the countries that were looking for in the.",
                    "label": 0
                },
                {
                    "sent": "Data sets and then the temple definition, which is the time period that we're actually interested in.",
                    "label": 0
                },
                {
                    "sent": "Because you may have different cubes that are covering different time periods.",
                    "label": 0
                },
                {
                    "sent": "And so you essentially search for these things in the cubes that are available in this catalog, and you find a set of candidate once these are.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then oh and then.",
                    "label": 0
                },
                {
                    "sent": "We have to deal with the fact that the data is formatted in different ways and so we basically build wrappers which are essentially queries, sparkle queries to the different SPARQL endpoints to get the data out in some sort of standard format so we can build these wrappers in advance for the different cubes that we might want to use.",
                    "label": 1
                },
                {
                    "sent": "And that helps us resolve some of the ways that the different properties are actually modeled across these.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks so finally, once you generate this set of candidates, we have to do some kind of compatibility verification.",
                    "label": 0
                },
                {
                    "sent": "So this essentially gives us this set of indicators after we counted indicators.",
                    "label": 0
                },
                {
                    "sent": "After we've done this search of the different cubes and pulled out the potential cubes that contain the data that we're looking for, and so we're essentially finding ones that actually match the combination of the indicators were searching for and the.",
                    "label": 0
                },
                {
                    "sent": "Coverage in terms of countries in years in this case.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So match here is essentially defined as this.",
                    "label": 0
                },
                {
                    "sent": "They have to match in terms of the descriptions they have to match in terms of the countries and then match in terms of the dimension.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of years.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, once we have this so once we get the data back and we've sent to identify those things, now we actually have to put it together in some way that we can actually then do some additional processing.",
                    "label": 0
                },
                {
                    "sent": "So the processing we pull this all into rapidminer but we need to get the data in some form that can be used and so there's a couple of different kinds of of combinations we have here.",
                    "label": 0
                },
                {
                    "sent": "We have two joins across the different indicators, so if I'm pulling information about GDP from one source and inflation from a different source, I need to pull that information together and then.",
                    "label": 0
                },
                {
                    "sent": "You have some cubes that might be organized such that maybe you're interested in inflation and then one source might have the inflation organized simply as a different data set for each different year.",
                    "label": 0
                },
                {
                    "sent": "So all of that has to be combined.",
                    "label": 0
                },
                {
                    "sent": "And then finally in the last.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do some sanity checking where maybe we remove data that has a large number of empty values or and we can do sort of more advanced kinds of sanity checking that looks at things like you know whether or not the distributions are skewed on the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quickly mentioned there's a variety of related work on this topic, so there's a number of sort of cube platforms, right.",
                    "label": 0
                },
                {
                    "sent": "LD, two statistical Workbench Open cube OLAP for LD within all these systems, supports or the creation validation querying.",
                    "label": 1
                },
                {
                    "sent": "And visualization of these different kinds of datasets.",
                    "label": 0
                },
                {
                    "sent": "Other people using the cube for doing data mining on them.",
                    "label": 0
                },
                {
                    "sent": "There's the LD extension for Rapidminer, which has a nice set of operators for integrating data with data and provide sort of Cuba travel operator.",
                    "label": 1
                },
                {
                    "sent": "So we build on top of that work.",
                    "label": 1
                },
                {
                    "sent": "There's some recent work by Jen Kranken and Shell on identifying relevant data in LD from seed concepts, so this similar to what we're doing here, except they don't actually deal with multidimensional data.",
                    "label": 0
                },
                {
                    "sent": "So I would say that you know the work I'm describing here really compliments these work.",
                    "label": 0
                },
                {
                    "sent": "In terms of the functionality being provided, so we're really focused on sort of the automatic discovery and integration of the data, and I think it complements very nicely some of the other work that's already.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to wrap up here.",
                    "label": 0
                },
                {
                    "sent": "So what we're working on is an approach to essentially finding and integrating these cube datasets from some set of initial seed concepts, so these are the essentially the initial types of things that you're looking for here, assessing their compatibility.",
                    "label": 1
                },
                {
                    "sent": "So whether or not they actually covered the same time periods and regions that you're interested in, and then integrating them to generate some kind of data mining data set, then we can run additional.",
                    "label": 1
                },
                {
                    "sent": "Data mining algorithms on top of so next steps in terms of what we're planning to do next, here is first automatic generation of the query wrapper.",
                    "label": 0
                },
                {
                    "sent": "So 11 issue here is that right now we have to manually write the wrappers for the different formats and stuff, but we think that this is a task that that we can automate the generation of these types of rappers and then the second thing we're looking at is then actually exploiting this data for predicting the indicators, right?",
                    "label": 0
                },
                {
                    "sent": "So if we want to predict these sort of fragile state indicators, we want to be able to pull the information together.",
                    "label": 0
                },
                {
                    "sent": "From all these different datasets and then and then be able to come up with the actual predictions on the data.",
                    "label": 0
                },
                {
                    "sent": "So that's really the main task that we started out with and then discovered that OK, we had to sort of solve this subproblem first, which is finding the data and getting it into the format that we could actually use it before we could get to the to the meat of the problem.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        }
    }
}