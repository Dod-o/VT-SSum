{
    "id": "5d6zossafzifkezsr6z2zg4wgg2wreq3",
    "title": "Large Scale High-Precision Topic Modeling on Twitter",
    "info": {
        "author": [
            "Shuang-Hong Yang, Twitter, Inc."
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_yang_twitter/",
    "segmentation": [
        [
            "So my name is Sean Young.",
            "I'm from Twitter.",
            "This is joint work with my colleague Alec Andy at punk engine.",
            "So we present a topic modeling system deployed inside Twitter.",
            "So for every tweet sent on Twitter platform, we want to predict the top label for that tweet.",
            "So why is this interesting to us?",
            "Why is it interesting?",
            "US, particularly for Twitter, right?",
            "So this is interesting as this is important of.",
            "Actually it has a lot of use cases inside Twitter.",
            "For example, one use cases 12.",
            "The."
        ],
        [
            "Able to a mirror.",
            "For each topic marosa like consumption impression was a volume of that topic.",
            "At that time an overtime.",
            "What's the trend, right?",
            "So that's a very important use case.",
            "Another use cases.",
            "User interests normally."
        ],
        [
            "Hope this is a. OK, use user interest money right.",
            "So if we know.",
            "For each state, if we know the topic of this street, we can use a very simple, maybe MapReduce job.",
            "What's the number of tweets this user consumed and what's the number of tweets this user produced?",
            "And very easily we can project that data to extract a real time dynamic user interest model.",
            "So for example like this right so also?"
        ],
        [
            "Why more use cases?",
            "Topic channels if we can organize tweets into different verticals like this topic verticals that will help the user to have better consumption experience.",
            "And also personalization recommendation right?",
            "If we know what the."
        ],
        [
            "Topics that content and we know what the interest of user.",
            "We can connect the right content to the right user.",
            "And they are."
        ],
        [
            "And there are a lot of many other use cases, for example, as targeting newsfeeds, ranking CR Prediction, search index, alot of these use cases so.",
            "But because of these various of use cases."
        ],
        [
            "And also the potential of exposing is topic labels to our user.",
            "We have this quality requirement so particularly want have at least 90% precision.",
            "That means if we say these traces about sports, right?",
            "We can 90% of the time.",
            "We are correct, right?",
            "This is turned out to be a very.",
            "It's very challenging actually, because."
        ],
        [
            "Because of the nature of the Twitter data arrays, tweets are sparse bounded by 140 characters and on average it takes only like.",
            "Less than 10 unigrams.",
            "So how do you achieve 90% precision with only seven unigram?",
            "This is pre challenge.",
            "Also Twitter data is pretty noisy right?",
            "So it can contain plates contain any like substring right?",
            "And tweets out and figures right?",
            "Or lotteries about many topics.",
            "And some tweets are conversational.",
            "No topic at alright.",
            "And also it's dynamic.",
            "We have emergent events emerging.",
            "Hashtags right?",
            "It's very challenged.",
            "OK, so because of these challenges we find out."
        ],
        [
            "Some existing pretty standard approach off the shelf approach doesn't work.",
            "For example, LDA and its variance variance rate supervising.",
            "Ideally, this model is done work.",
            "Why it doesn't work?",
            "A couple reasons.",
            "One reason is for LDA, right?",
            "So this unsupervised model maybe 40% procedure is reasonable right?",
            "30% maximum for tweets but 90% procedure is too much, right?",
            "So far from our goal and also the LDA topic model if you want to align that topic to our.",
            "Yes, we want to organize trades to this predefined ontology.",
            "If you want to organize aligned at the unsurprised learning results to that predefined taxonomy, that's not trivial right.",
            "And also we want to improve the quality of our Top Model system overtime and LDA model does allow you to do that if you retrain model the topics we shuffle right, and if you add one new topics or the other topics we change also right?",
            "So and also.",
            "Public fare train.",
            "This is a pretty.",
            "Popular approach used to extract topics.",
            "So language model was talking filtering, but we found that this approach works for very semantically very focused topics like SF, MTA.",
            "These topics, but for generic topics it doesn't work well.",
            "Also I want to mention one more approach.",
            "Active learning right?",
            "So if you apply after active learning.",
            "First tweet topic understanding.",
            "That's also it's not going to work because tweets are sparse.",
            "Even you run this mini batch right of active learning, you collect like a couple of thousands by topic data.",
            "Because of sparsity, as we are not generated on the test data, we alright so OK.",
            "So we present a system called Job is system is deployed inside Twitter.",
            "It doing it predict topics for tweets on the 4th scale, Twitter data in real time or structure taxonomy about."
        ],
        [
            "350 topics and about 90 three procedure.",
            "93% procedure with 40% coverage.",
            "English tweets or or the English states actually so OK so how?"
        ],
        [
            "We did it right, so I want to give an overview of our approach.",
            "This is a collection of tech talk."
        ],
        [
            "Modern techniques, but I don't have time to go into all the details, but I want to give a brief overview.",
            "OK, this is a high level architecture.",
            "Our system.",
            "Basically we have the real time Twitter stream, right?",
            "So we have a training data collector module.",
            "Basically listen to their Twitter stream and click label data automatically at no cost and we have machine learning trainer system.",
            "Basically based on that.",
            "Collective training labeled data to produce machine learning models validated that model and diplay replicate to our data center, and then that pointer.",
            "Alright, so.",
            "OK, OK so.",
            "That topic classifier is basically was used together with our knowledge base knowledge base about the entities, knowledge base about the user, so all sorts of the knowledge we acquire too.",
            "Yeah, thank you.",
            "Thank you.",
            "To provide the final production target labels and we also have some other like feedback collection module, static diagnostic modules too.",
            "If we detect systematic mistakes and correct that mistake on the fly.",
            "OK so."
        ],
        [
            "I'll give a brief introduction to each other.",
            "Models first model is labeled data collection.",
            "So how do we collect label data at no cost so?",
            "So we basically designed this system this.",
            "This module basically consists of a couple of submodules first models.",
            "Labeling priors so priors noisy filters about each topic.",
            "So like user, so these priors to prefilter the top points and that noisy filter data is used by our data cleaning pipeline basic consists of called training and learning based on positive unlabeled data with PU learning module to produce high quality, positive and negative.",
            "Training data for our model training."
        ],
        [
            "OK, so once we have that labeled data, we basically launch machine learning model to produce models.",
            "This is pretty standard so tweets futurized and then.",
            "Feeding into our trainer to produce models is a pretty standard text classification systems I will skip."
        ],
        [
            "And also, as I mentioned, our taxonomy is a structure taxonomy.",
            "We have this segment depth in total 7 depth taxonomy, right?",
            "So how we also want to leverage that structured structure to improve the quality of our model.",
            "Yeah, so we basically use three approaches.",
            "We do data sharing, the labor propagation.",
            "We do private sharing cost sensitive learning.",
            "If you want to know more details, you can read the paper.",
            "And also so once we have all with all of this we can achieve about about maybe an average 60% procedure, but 90% precision is still far away to go.",
            "So how do we achieve that 90% percent?"
        ],
        [
            "So we have another model, cars, two stage training.",
            "Basically we have.",
            "A large amount of.",
            "Program collected noisy data from our training data collection program, but we also have a small we can afford with our budget.",
            "We can follow a small set of.",
            "Clean human labor data.",
            "Right, so if you change the model on each of these data set, it doesn't work, because this model is too noisy, right?",
            "60% procedure.",
            "This model is too sparse.",
            "It doesn't generalize well on our test data, so our combined this because of the dominance volume, right?",
            "So this would be like average out this signal here.",
            "So we use this two stage training.",
            "Basically train model based on this large volume data and use that as prior to train.",
            "Answer A small amount of data.",
            "OK."
        ],
        [
            "Also, we have diagnosis or corrective learning modules, basically to detect the to collect feedback from our user at no cost and identify systematic mistakes and correct it on the fly.",
            "So and also for some kind of tweets, it's very noisy.",
            "It's very hard to get it right."
        ],
        [
            "I see even impossible, right?",
            "So we want to we want to like waste our system latency on these streets multitude diseno rejection so.",
            "We have also model model.",
            "Calibration is basically estimate.",
            "The procedure must have a classifier to estimate the threshold at which threshold we can."
        ],
        [
            "OK, so we are."
        ],
        [
            "So, but places also is not only about text, it's also about a lot of other signals, right?",
            "So basically, based on the, we also derive signal."
        ],
        [
            "From URL author engagement Engagers and also entities and two is called integrative inference to get the final results.",
            "This is horses."
        ],
        [
            "This is the final system which brought our system which achieves 93% precision with 40% English coverage."
        ],
        [
            "So this is so.",
            "In summary, we present diploid system on large scale, high precision type of modeling and we present collection of topic modeling techniques to achieve that.",
            "93% or so if you are interested in our to know more details, you can come to our poster, read our paper.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So my name is Sean Young.",
                    "label": 0
                },
                {
                    "sent": "I'm from Twitter.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my colleague Alec Andy at punk engine.",
                    "label": 0
                },
                {
                    "sent": "So we present a topic modeling system deployed inside Twitter.",
                    "label": 1
                },
                {
                    "sent": "So for every tweet sent on Twitter platform, we want to predict the top label for that tweet.",
                    "label": 0
                },
                {
                    "sent": "So why is this interesting to us?",
                    "label": 0
                },
                {
                    "sent": "Why is it interesting?",
                    "label": 0
                },
                {
                    "sent": "US, particularly for Twitter, right?",
                    "label": 0
                },
                {
                    "sent": "So this is interesting as this is important of.",
                    "label": 0
                },
                {
                    "sent": "Actually it has a lot of use cases inside Twitter.",
                    "label": 0
                },
                {
                    "sent": "For example, one use cases 12.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Able to a mirror.",
                    "label": 0
                },
                {
                    "sent": "For each topic marosa like consumption impression was a volume of that topic.",
                    "label": 0
                },
                {
                    "sent": "At that time an overtime.",
                    "label": 0
                },
                {
                    "sent": "What's the trend, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a very important use case.",
                    "label": 0
                },
                {
                    "sent": "Another use cases.",
                    "label": 0
                },
                {
                    "sent": "User interests normally.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hope this is a. OK, use user interest money right.",
                    "label": 1
                },
                {
                    "sent": "So if we know.",
                    "label": 0
                },
                {
                    "sent": "For each state, if we know the topic of this street, we can use a very simple, maybe MapReduce job.",
                    "label": 0
                },
                {
                    "sent": "What's the number of tweets this user consumed and what's the number of tweets this user produced?",
                    "label": 0
                },
                {
                    "sent": "And very easily we can project that data to extract a real time dynamic user interest model.",
                    "label": 0
                },
                {
                    "sent": "So for example like this right so also?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why more use cases?",
                    "label": 0
                },
                {
                    "sent": "Topic channels if we can organize tweets into different verticals like this topic verticals that will help the user to have better consumption experience.",
                    "label": 1
                },
                {
                    "sent": "And also personalization recommendation right?",
                    "label": 1
                },
                {
                    "sent": "If we know what the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Topics that content and we know what the interest of user.",
                    "label": 0
                },
                {
                    "sent": "We can connect the right content to the right user.",
                    "label": 0
                },
                {
                    "sent": "And they are.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there are a lot of many other use cases, for example, as targeting newsfeeds, ranking CR Prediction, search index, alot of these use cases so.",
                    "label": 0
                },
                {
                    "sent": "But because of these various of use cases.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also the potential of exposing is topic labels to our user.",
                    "label": 0
                },
                {
                    "sent": "We have this quality requirement so particularly want have at least 90% precision.",
                    "label": 1
                },
                {
                    "sent": "That means if we say these traces about sports, right?",
                    "label": 0
                },
                {
                    "sent": "We can 90% of the time.",
                    "label": 0
                },
                {
                    "sent": "We are correct, right?",
                    "label": 0
                },
                {
                    "sent": "This is turned out to be a very.",
                    "label": 0
                },
                {
                    "sent": "It's very challenging actually, because.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because of the nature of the Twitter data arrays, tweets are sparse bounded by 140 characters and on average it takes only like.",
                    "label": 0
                },
                {
                    "sent": "Less than 10 unigrams.",
                    "label": 0
                },
                {
                    "sent": "So how do you achieve 90% precision with only seven unigram?",
                    "label": 1
                },
                {
                    "sent": "This is pre challenge.",
                    "label": 0
                },
                {
                    "sent": "Also Twitter data is pretty noisy right?",
                    "label": 0
                },
                {
                    "sent": "So it can contain plates contain any like substring right?",
                    "label": 1
                },
                {
                    "sent": "And tweets out and figures right?",
                    "label": 0
                },
                {
                    "sent": "Or lotteries about many topics.",
                    "label": 0
                },
                {
                    "sent": "And some tweets are conversational.",
                    "label": 0
                },
                {
                    "sent": "No topic at alright.",
                    "label": 0
                },
                {
                    "sent": "And also it's dynamic.",
                    "label": 0
                },
                {
                    "sent": "We have emergent events emerging.",
                    "label": 0
                },
                {
                    "sent": "Hashtags right?",
                    "label": 0
                },
                {
                    "sent": "It's very challenged.",
                    "label": 0
                },
                {
                    "sent": "OK, so because of these challenges we find out.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some existing pretty standard approach off the shelf approach doesn't work.",
                    "label": 0
                },
                {
                    "sent": "For example, LDA and its variance variance rate supervising.",
                    "label": 0
                },
                {
                    "sent": "Ideally, this model is done work.",
                    "label": 0
                },
                {
                    "sent": "Why it doesn't work?",
                    "label": 0
                },
                {
                    "sent": "A couple reasons.",
                    "label": 0
                },
                {
                    "sent": "One reason is for LDA, right?",
                    "label": 0
                },
                {
                    "sent": "So this unsupervised model maybe 40% procedure is reasonable right?",
                    "label": 0
                },
                {
                    "sent": "30% maximum for tweets but 90% procedure is too much, right?",
                    "label": 0
                },
                {
                    "sent": "So far from our goal and also the LDA topic model if you want to align that topic to our.",
                    "label": 1
                },
                {
                    "sent": "Yes, we want to organize trades to this predefined ontology.",
                    "label": 0
                },
                {
                    "sent": "If you want to organize aligned at the unsurprised learning results to that predefined taxonomy, that's not trivial right.",
                    "label": 1
                },
                {
                    "sent": "And also we want to improve the quality of our Top Model system overtime and LDA model does allow you to do that if you retrain model the topics we shuffle right, and if you add one new topics or the other topics we change also right?",
                    "label": 0
                },
                {
                    "sent": "So and also.",
                    "label": 0
                },
                {
                    "sent": "Public fare train.",
                    "label": 0
                },
                {
                    "sent": "This is a pretty.",
                    "label": 1
                },
                {
                    "sent": "Popular approach used to extract topics.",
                    "label": 0
                },
                {
                    "sent": "So language model was talking filtering, but we found that this approach works for very semantically very focused topics like SF, MTA.",
                    "label": 0
                },
                {
                    "sent": "These topics, but for generic topics it doesn't work well.",
                    "label": 0
                },
                {
                    "sent": "Also I want to mention one more approach.",
                    "label": 0
                },
                {
                    "sent": "Active learning right?",
                    "label": 0
                },
                {
                    "sent": "So if you apply after active learning.",
                    "label": 0
                },
                {
                    "sent": "First tweet topic understanding.",
                    "label": 0
                },
                {
                    "sent": "That's also it's not going to work because tweets are sparse.",
                    "label": 0
                },
                {
                    "sent": "Even you run this mini batch right of active learning, you collect like a couple of thousands by topic data.",
                    "label": 0
                },
                {
                    "sent": "Because of sparsity, as we are not generated on the test data, we alright so OK.",
                    "label": 0
                },
                {
                    "sent": "So we present a system called Job is system is deployed inside Twitter.",
                    "label": 0
                },
                {
                    "sent": "It doing it predict topics for tweets on the 4th scale, Twitter data in real time or structure taxonomy about.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "350 topics and about 90 three procedure.",
                    "label": 0
                },
                {
                    "sent": "93% procedure with 40% coverage.",
                    "label": 0
                },
                {
                    "sent": "English tweets or or the English states actually so OK so how?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We did it right, so I want to give an overview of our approach.",
                    "label": 0
                },
                {
                    "sent": "This is a collection of tech talk.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Modern techniques, but I don't have time to go into all the details, but I want to give a brief overview.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a high level architecture.",
                    "label": 0
                },
                {
                    "sent": "Our system.",
                    "label": 0
                },
                {
                    "sent": "Basically we have the real time Twitter stream, right?",
                    "label": 0
                },
                {
                    "sent": "So we have a training data collector module.",
                    "label": 0
                },
                {
                    "sent": "Basically listen to their Twitter stream and click label data automatically at no cost and we have machine learning trainer system.",
                    "label": 0
                },
                {
                    "sent": "Basically based on that.",
                    "label": 0
                },
                {
                    "sent": "Collective training labeled data to produce machine learning models validated that model and diplay replicate to our data center, and then that pointer.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "OK, OK so.",
                    "label": 0
                },
                {
                    "sent": "That topic classifier is basically was used together with our knowledge base knowledge base about the entities, knowledge base about the user, so all sorts of the knowledge we acquire too.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "To provide the final production target labels and we also have some other like feedback collection module, static diagnostic modules too.",
                    "label": 0
                },
                {
                    "sent": "If we detect systematic mistakes and correct that mistake on the fly.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll give a brief introduction to each other.",
                    "label": 0
                },
                {
                    "sent": "Models first model is labeled data collection.",
                    "label": 1
                },
                {
                    "sent": "So how do we collect label data at no cost so?",
                    "label": 0
                },
                {
                    "sent": "So we basically designed this system this.",
                    "label": 0
                },
                {
                    "sent": "This module basically consists of a couple of submodules first models.",
                    "label": 0
                },
                {
                    "sent": "Labeling priors so priors noisy filters about each topic.",
                    "label": 0
                },
                {
                    "sent": "So like user, so these priors to prefilter the top points and that noisy filter data is used by our data cleaning pipeline basic consists of called training and learning based on positive unlabeled data with PU learning module to produce high quality, positive and negative.",
                    "label": 0
                },
                {
                    "sent": "Training data for our model training.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so once we have that labeled data, we basically launch machine learning model to produce models.",
                    "label": 1
                },
                {
                    "sent": "This is pretty standard so tweets futurized and then.",
                    "label": 1
                },
                {
                    "sent": "Feeding into our trainer to produce models is a pretty standard text classification systems I will skip.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also, as I mentioned, our taxonomy is a structure taxonomy.",
                    "label": 0
                },
                {
                    "sent": "We have this segment depth in total 7 depth taxonomy, right?",
                    "label": 0
                },
                {
                    "sent": "So how we also want to leverage that structured structure to improve the quality of our model.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we basically use three approaches.",
                    "label": 0
                },
                {
                    "sent": "We do data sharing, the labor propagation.",
                    "label": 1
                },
                {
                    "sent": "We do private sharing cost sensitive learning.",
                    "label": 0
                },
                {
                    "sent": "If you want to know more details, you can read the paper.",
                    "label": 0
                },
                {
                    "sent": "And also so once we have all with all of this we can achieve about about maybe an average 60% procedure, but 90% precision is still far away to go.",
                    "label": 0
                },
                {
                    "sent": "So how do we achieve that 90% percent?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have another model, cars, two stage training.",
                    "label": 1
                },
                {
                    "sent": "Basically we have.",
                    "label": 0
                },
                {
                    "sent": "A large amount of.",
                    "label": 0
                },
                {
                    "sent": "Program collected noisy data from our training data collection program, but we also have a small we can afford with our budget.",
                    "label": 0
                },
                {
                    "sent": "We can follow a small set of.",
                    "label": 0
                },
                {
                    "sent": "Clean human labor data.",
                    "label": 0
                },
                {
                    "sent": "Right, so if you change the model on each of these data set, it doesn't work, because this model is too noisy, right?",
                    "label": 0
                },
                {
                    "sent": "60% procedure.",
                    "label": 0
                },
                {
                    "sent": "This model is too sparse.",
                    "label": 0
                },
                {
                    "sent": "It doesn't generalize well on our test data, so our combined this because of the dominance volume, right?",
                    "label": 0
                },
                {
                    "sent": "So this would be like average out this signal here.",
                    "label": 0
                },
                {
                    "sent": "So we use this two stage training.",
                    "label": 1
                },
                {
                    "sent": "Basically train model based on this large volume data and use that as prior to train.",
                    "label": 0
                },
                {
                    "sent": "Answer A small amount of data.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, we have diagnosis or corrective learning modules, basically to detect the to collect feedback from our user at no cost and identify systematic mistakes and correct it on the fly.",
                    "label": 1
                },
                {
                    "sent": "So and also for some kind of tweets, it's very noisy.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to get it right.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I see even impossible, right?",
                    "label": 0
                },
                {
                    "sent": "So we want to we want to like waste our system latency on these streets multitude diseno rejection so.",
                    "label": 0
                },
                {
                    "sent": "We have also model model.",
                    "label": 0
                },
                {
                    "sent": "Calibration is basically estimate.",
                    "label": 0
                },
                {
                    "sent": "The procedure must have a classifier to estimate the threshold at which threshold we can.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we are.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, but places also is not only about text, it's also about a lot of other signals, right?",
                    "label": 0
                },
                {
                    "sent": "So basically, based on the, we also derive signal.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From URL author engagement Engagers and also entities and two is called integrative inference to get the final results.",
                    "label": 0
                },
                {
                    "sent": "This is horses.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the final system which brought our system which achieves 93% precision with 40% English coverage.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is so.",
                    "label": 0
                },
                {
                    "sent": "In summary, we present diploid system on large scale, high precision type of modeling and we present collection of topic modeling techniques to achieve that.",
                    "label": 1
                },
                {
                    "sent": "93% or so if you are interested in our to know more details, you can come to our poster, read our paper.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}