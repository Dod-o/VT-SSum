{
    "id": "ifgs2y3ssshs3vzqctf2qmf7kaalc3im",
    "title": "On Discovering Relationships in Multi-Label Learning via Linked Open Data",
    "info": {
        "author": [
            "Eirini Papagiannopoulou, Department of Informatics, Aristotle University of Thessaloniki"
        ],
        "published": "July 15, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_papagiannopoulou_open_data/",
    "segmentation": [
        [
            "OK, I am meeting with blue and I will present you our work on discovering deterministic relationships in multi label learning via linked open Data Cloud.",
            "No."
        ],
        [
            "And let's make an overview of our work.",
            "So the main goal is to discover this deterministic relationships among labels, and I mean common parents among these labels.",
            "But there are also other types of relationships like mutual exclusion and parent child relationship among existing labels, but these two types.",
            "We are noting this work.",
            "But but is in our immediate plans.",
            "And how we have done this?",
            "And using linked open data Cloud and our motivation is to improve prediction accuracy over the multi label learning algorithms and of course to reduce inference complexity.",
            "But we will elaborate more in the future in this field."
        ],
        [
            "So if you think about multi label learning.",
            "And more specifically, for the datasets that deal with this field.",
            "It's instance of a data set has some attributes like this.",
            "And that is related to one or more binary target variables called labels.",
            "This is a sample.",
            "All sorts of data set."
        ],
        [
            "And I will present you our approach step by step.",
            "So the first step of our approach is that organization of our label of the label names of the data set.",
            "And the let me let me explain you in more detail what I mean in textual data sets, names of labels make on site with some names of attributes.",
            "So let's see here.",
            "The big tech data set example where the attribute model has the same name with the late model, the label model, and in order to distinguish these two cases.",
            "They may have just had a small trivial word like tag word in front of the label or at the end of the label name.",
            "So.",
            "And we would like to have the pure word of a label.",
            "So we tokenize with a standard set of delimiters.",
            "Each label name.",
            "This delimiter saradas_space separator, the period and talking that appear in our label names are removed.",
            "So Doug and Arthur will be removed and the rest of them are concatenated again with the space we can see here.",
            "An example of this process.",
            "So the landscape major after a becomes landscape nature."
        ],
        [
            "The second step of our approach is to look up its label name in Word Net.",
            "So if a word has multiple senses, we assume that the correct sense is the most frequent one according to Word Net, which is based on semantically tagged corpora.",
            "Let's see an example example.",
            "Trivia are trivial examples.",
            "Winter label has two senses according to Word Net.",
            "The first one is the call decision of the year.",
            "And it is the most frequent one.",
            "This is indicated by the number at the end of the sentence.",
            "And the the second one is spent the winter, of course.",
            "We choose the first one.",
            "The same holds for the summer label."
        ],
        [
            "In the third step of our approach, we take recursively hypernym, since it's of the determined sense up to the root of word net.",
            "So for the winter means with our time label, all these are the hypernym, since it's.",
            "It's again a trivial example in a hierarchy form, and the same holds for the other label."
        ],
        [
            "In the fourth step of our approach, we examine all pairs of labels.",
            "Which we which we managed to find in Word, net of course, and their common ancestors are used for expanding the original label space of the learning problem.",
            "But at this point we should notice that our our approach ignores some common patterns that appear at the top of the word hierarchy becausw.",
            "These are parents will be added for all label pairs and we think that they will bring no new information."
        ],
        [
            "OK, so finally we add these.",
            "Missional labels measure quantity, amount.",
            "And season, and we don't add these two.",
            "Come on parents because they are at the top of the world hierarchy."
        ],
        [
            "The last step is here.",
            "For every new label for its instance, if at least one of its children is 2, then the specific new label will be true.",
            "In all other cases, the label will be false, so.",
            "If winter is true in our example, or summer is true, then season will be true.",
            "Otherwise season will be false."
        ],
        [
            "This is the experiment setup we used calibrated label label ranking and linear support vector machines using the implementations of Mulan an waka, respectively.",
            "We experimented on six month labeled datasets that have labels with the clear meanings, not obscure names, split datasets in France.",
            "Tested with these percentages and we discuss our results in terms of mean average precision, an logarithm clause."
        ],
        [
            "We have two approaches, two versions of our approach.",
            "We apply our method in the original data and to the expanded label space using these versions.",
            "In the first version, we take into consideration hypernym, since it's of the determined sense of the label for up to two layers.",
            "I mean parents and grandparents, and we ignore the following 30 two senses, and in the second version we take into account hypernym seasons, since it's off the determined sense of the.",
            "Label for all layers up to the root of word net, and we ignore the five senses shown in red color."
        ],
        [
            "And these are the results show for the first version.",
            "We can see the number of additional labels.",
            "And the same for the second version in order to have an impression of increase over the number of labels and the number of labels per data set that we managed to find in Word net."
        ],
        [
            "So lot load 1 version leads to improvements for all datasets in logarithmic loss.",
            "Batting for datasets in the mean average precision there is a reduction in two datasets and load 2 version leads to improvements for all datasets, excepting much left 2011 and four, and improves mean average precision for three cases in the other three cases we have a reduction."
        ],
        [
            "These are our future work experiments using the lowest common subsume are, instead of all common parents for its pair of labels.",
            "Maybe we should add a criterion that determines whether or not to reject this list Commons of Schumer.",
            "We can exploit additional resources linked open data like this.",
            "It would be wise to make a general first check of all labels in order to detect the domain that they're referred to, and also we are able to select the appropriate sense of the labels based on this domain and not on the frequency given by Ornette.",
            "We can also discover additional types of relationships, like I said.",
            "In the end, the museum is light."
        ],
        [
            "Thank you for your patience."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I am meeting with blue and I will present you our work on discovering deterministic relationships in multi label learning via linked open Data Cloud.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let's make an overview of our work.",
                    "label": 0
                },
                {
                    "sent": "So the main goal is to discover this deterministic relationships among labels, and I mean common parents among these labels.",
                    "label": 1
                },
                {
                    "sent": "But there are also other types of relationships like mutual exclusion and parent child relationship among existing labels, but these two types.",
                    "label": 0
                },
                {
                    "sent": "We are noting this work.",
                    "label": 0
                },
                {
                    "sent": "But but is in our immediate plans.",
                    "label": 0
                },
                {
                    "sent": "And how we have done this?",
                    "label": 0
                },
                {
                    "sent": "And using linked open data Cloud and our motivation is to improve prediction accuracy over the multi label learning algorithms and of course to reduce inference complexity.",
                    "label": 1
                },
                {
                    "sent": "But we will elaborate more in the future in this field.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you think about multi label learning.",
                    "label": 0
                },
                {
                    "sent": "And more specifically, for the datasets that deal with this field.",
                    "label": 0
                },
                {
                    "sent": "It's instance of a data set has some attributes like this.",
                    "label": 0
                },
                {
                    "sent": "And that is related to one or more binary target variables called labels.",
                    "label": 0
                },
                {
                    "sent": "This is a sample.",
                    "label": 0
                },
                {
                    "sent": "All sorts of data set.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I will present you our approach step by step.",
                    "label": 1
                },
                {
                    "sent": "So the first step of our approach is that organization of our label of the label names of the data set.",
                    "label": 0
                },
                {
                    "sent": "And the let me let me explain you in more detail what I mean in textual data sets, names of labels make on site with some names of attributes.",
                    "label": 1
                },
                {
                    "sent": "So let's see here.",
                    "label": 0
                },
                {
                    "sent": "The big tech data set example where the attribute model has the same name with the late model, the label model, and in order to distinguish these two cases.",
                    "label": 0
                },
                {
                    "sent": "They may have just had a small trivial word like tag word in front of the label or at the end of the label name.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And we would like to have the pure word of a label.",
                    "label": 0
                },
                {
                    "sent": "So we tokenize with a standard set of delimiters.",
                    "label": 1
                },
                {
                    "sent": "Each label name.",
                    "label": 1
                },
                {
                    "sent": "This delimiter saradas_space separator, the period and talking that appear in our label names are removed.",
                    "label": 0
                },
                {
                    "sent": "So Doug and Arthur will be removed and the rest of them are concatenated again with the space we can see here.",
                    "label": 1
                },
                {
                    "sent": "An example of this process.",
                    "label": 0
                },
                {
                    "sent": "So the landscape major after a becomes landscape nature.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second step of our approach is to look up its label name in Word Net.",
                    "label": 0
                },
                {
                    "sent": "So if a word has multiple senses, we assume that the correct sense is the most frequent one according to Word Net, which is based on semantically tagged corpora.",
                    "label": 0
                },
                {
                    "sent": "Let's see an example example.",
                    "label": 0
                },
                {
                    "sent": "Trivia are trivial examples.",
                    "label": 0
                },
                {
                    "sent": "Winter label has two senses according to Word Net.",
                    "label": 0
                },
                {
                    "sent": "The first one is the call decision of the year.",
                    "label": 0
                },
                {
                    "sent": "And it is the most frequent one.",
                    "label": 0
                },
                {
                    "sent": "This is indicated by the number at the end of the sentence.",
                    "label": 0
                },
                {
                    "sent": "And the the second one is spent the winter, of course.",
                    "label": 0
                },
                {
                    "sent": "We choose the first one.",
                    "label": 0
                },
                {
                    "sent": "The same holds for the summer label.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the third step of our approach, we take recursively hypernym, since it's of the determined sense up to the root of word net.",
                    "label": 1
                },
                {
                    "sent": "So for the winter means with our time label, all these are the hypernym, since it's.",
                    "label": 0
                },
                {
                    "sent": "It's again a trivial example in a hierarchy form, and the same holds for the other label.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the fourth step of our approach, we examine all pairs of labels.",
                    "label": 1
                },
                {
                    "sent": "Which we which we managed to find in Word, net of course, and their common ancestors are used for expanding the original label space of the learning problem.",
                    "label": 1
                },
                {
                    "sent": "But at this point we should notice that our our approach ignores some common patterns that appear at the top of the word hierarchy becausw.",
                    "label": 0
                },
                {
                    "sent": "These are parents will be added for all label pairs and we think that they will bring no new information.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so finally we add these.",
                    "label": 0
                },
                {
                    "sent": "Missional labels measure quantity, amount.",
                    "label": 0
                },
                {
                    "sent": "And season, and we don't add these two.",
                    "label": 0
                },
                {
                    "sent": "Come on parents because they are at the top of the world hierarchy.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The last step is here.",
                    "label": 0
                },
                {
                    "sent": "For every new label for its instance, if at least one of its children is 2, then the specific new label will be true.",
                    "label": 0
                },
                {
                    "sent": "In all other cases, the label will be false, so.",
                    "label": 0
                },
                {
                    "sent": "If winter is true in our example, or summer is true, then season will be true.",
                    "label": 0
                },
                {
                    "sent": "Otherwise season will be false.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the experiment setup we used calibrated label label ranking and linear support vector machines using the implementations of Mulan an waka, respectively.",
                    "label": 0
                },
                {
                    "sent": "We experimented on six month labeled datasets that have labels with the clear meanings, not obscure names, split datasets in France.",
                    "label": 0
                },
                {
                    "sent": "Tested with these percentages and we discuss our results in terms of mean average precision, an logarithm clause.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have two approaches, two versions of our approach.",
                    "label": 0
                },
                {
                    "sent": "We apply our method in the original data and to the expanded label space using these versions.",
                    "label": 0
                },
                {
                    "sent": "In the first version, we take into consideration hypernym, since it's of the determined sense of the label for up to two layers.",
                    "label": 0
                },
                {
                    "sent": "I mean parents and grandparents, and we ignore the following 30 two senses, and in the second version we take into account hypernym seasons, since it's off the determined sense of the.",
                    "label": 0
                },
                {
                    "sent": "Label for all layers up to the root of word net, and we ignore the five senses shown in red color.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these are the results show for the first version.",
                    "label": 0
                },
                {
                    "sent": "We can see the number of additional labels.",
                    "label": 0
                },
                {
                    "sent": "And the same for the second version in order to have an impression of increase over the number of labels and the number of labels per data set that we managed to find in Word net.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So lot load 1 version leads to improvements for all datasets in logarithmic loss.",
                    "label": 0
                },
                {
                    "sent": "Batting for datasets in the mean average precision there is a reduction in two datasets and load 2 version leads to improvements for all datasets, excepting much left 2011 and four, and improves mean average precision for three cases in the other three cases we have a reduction.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are our future work experiments using the lowest common subsume are, instead of all common parents for its pair of labels.",
                    "label": 0
                },
                {
                    "sent": "Maybe we should add a criterion that determines whether or not to reject this list Commons of Schumer.",
                    "label": 0
                },
                {
                    "sent": "We can exploit additional resources linked open data like this.",
                    "label": 0
                },
                {
                    "sent": "It would be wise to make a general first check of all labels in order to detect the domain that they're referred to, and also we are able to select the appropriate sense of the labels based on this domain and not on the frequency given by Ornette.",
                    "label": 0
                },
                {
                    "sent": "We can also discover additional types of relationships, like I said.",
                    "label": 0
                },
                {
                    "sent": "In the end, the museum is light.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for your patience.",
                    "label": 0
                }
            ]
        }
    }
}