{
    "id": "54f2jepg3hjhiavck732rgokddsvthes",
    "title": "3D Morphable Model Construction for Robust Ear and Face Recognition",
    "info": {
        "author": [
            "John David Bustard, School of Electronics and Computer Science, University of Southampton"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_bustard_3dmm/",
    "segmentation": [
        [
            "Hello everyone, my name is John Bustard.",
            "I'm from the University of Southampton.",
            "My supervisor is Mark Nixon and today I'd like to present some progress in the field of morphable model construction."
        ],
        [
            "Now, as you may be aware, Morphable models were first introduced in 1999 by Volker Blanz and Thomas Vetter and a Seminole work at SIGGRAPH.",
            "They introduced an algorithm that, given a photograph, static image of a face with varying pose or lighting conditions, they could reconstruct the 3D surface of the face very accurately."
        ],
        [
            "The reason they could do this was because they had an accurate model of the three dimensional shape variation and color variation, and that's what a morphable model is now."
        ],
        [
            "It's 1999.",
            "There's been some progress in the development of different morphable model construction algorithms, but broadly, they consist of the following stages.",
            "First of all, a training set of range scans is acquired.",
            "And you can see here both color information and three dimensional information, usually with a laser scanner.",
            "Then these images are processed manually to remove occluding regions such as the hair or earrings and noise regions as well, and then a set of initializing feature points are identified manually."
        ],
        [
            "Now in the original work and optic flow algorithm was used to register very carefully, recorded and cleaned up head images.",
            "More recent work has tended to use an artist produced model.",
            "The advantages of this are that you can have more missing portions from your range scan and also in the model.",
            "You can adjust the resolution according to the detail of the features you can see here.",
            "The ear has more triangles associated with it.",
            "The first step then, is to rigidly align this artist produced mesh using the feature points with the range scan and then to deform with the feature points, and then using a nonrigid iterative closest point algorithm and various variations on that.",
            "You can then densely align the mesh to the range scan."
        ],
        [
            "Once you've completed that process for a set of heads, you basically have a dense registration across them.",
            "And you can perform principal component analysis on all the vertices connected concatenated together to get this an estimate for the space of human face shapes.",
            "You can repeat the same process with the texture which you can extract by inverse rendering onto the head surface.",
            "Now, this process, as you've seen in the first slide can produce very good."
        ],
        [
            "Results, but there are some areas for improvement.",
            "One of the first areas is that in existing work, the ear region tends not to be accurately modeled, and I don't know what you can see here from the diagrams.",
            "Often it's explicitly excluded because of its per convergence, and the reason that the mesh rarely converges accurately to the range scan is because of its self occluding structure, and because it's quite ornate, so be desirable to model that accurately.",
            "One of the reasons for this is that recent work is indicated that the ear contains significant biometric information.",
            "Indeed, at the same distance, under good conditions, both the ear and the face can produce equivalent recognition rates."
        ],
        [
            "The next area is to reduce the pre processing requirements to automate some of this removal of noise and occluders and to take a step towards the potential for the online learning of morphable models from much less constrained data.",
            "So it could be more widely applied.",
            "And finally."
        ],
        [
            "Existing work is come from the graphics community and a lot of the results are being demonstrated through these very impressive reconstructions, but it's desirable to have a more analytical basis for evaluating the fitting process and the resulting models."
        ],
        [
            "So first, when looking at the year modeling now a number of different strategies were approached here, one of which included fitting the contour regions of the ear.",
            "But in most cases the noise in the range scans were such that it was hard to get a good alignment, and so the key here is getting a good initialization that will converge.",
            "Now in the work presented here."
        ],
        [
            "The key was to identify a kind of minimal set of ear feature points to enable convergence.",
            "Now, of course, this process is still manual, more recent work not included in the paper involves the automatic identification of good points and the automatic detection of these points, but further analysis is necessary to do this.",
            "But to give you an indication of where it's going, it's to do with identifying feature points that are highly distinctive on a particular head surface and comparing them."
        ],
        [
            "The next stage is to look at the automated preprocessing.",
            "Now the key here is to reduce the overall time, so we don't want a long training period as well.",
            "So the way this proceeds is you start with the rigidly aligned head models and then you deform to the feature points.",
            "And then because you're using notice produced mesh, there's a texture mapping a kind of 2D mapping across the surface, and you find the closest mesh surface point for each range point, and this gives you a positioning of the points over that surface.",
            "That surface is then split into a set of regions overlapping regions, and the binary classifier trained for each region.",
            "These contribute votes to determine whether the surface region is likely to be skin.",
            "Are valid surface region or include are.",
            "The classifiers consist of Gaussian model and it's trained using spin image features across the head surface, so each range pixel is got a spin image associated with it.",
            "So then goes in models of both the positive and the negative spaces are calculated and this is using 30 training images.",
            "Then these samples are then run through that classifier and the false negative and false positive regions are identified.",
            "These are then subspaces are then calculated for these and within those regions of K nearest neighbors classifier is produced.",
            "This is a very fast process to train and produces reasonably accurate results."
        ],
        [
            "You can see here a bit of analysis of the results on the left.",
            "We've got some of the processed answers and on the right we see the percentage of the head surface because different regions of the head surface have got different accuracies of classification and what the pixel classification error is in each case.",
            "So although we're not getting perfect results here.",
            "The results are sufficient that by adding an outlier detection stage in the dense fitting stage, these outliers can be removed and these are detected by calculating the maximum absolute deviation of the distances of the surface points to the range match to the art mesh, and the intuition here is that basically the outliers are generally far further from the surface than the."
        ],
        [
            "Liars.",
            "Now finally, for the model analysis for the fitting analysis, the intuition here was that if you take multiple range scans of the same person and you fit the mesh to these scans, then if you're fitting process is converging accurately, you would expect the mesh model to be very similar to much more similar certainly than the fitted results for other heads, and this gives us a metric to determine how well our fitting process is converging.",
            "You can see here that number one.",
            "This represents the closest rank, so this is the L2 norm of the vectors of the fitted mesh positions.",
            "Once they've been rigidly aligned with one another and you see the other distances and in all cases the closest head mesh is the mesh of the same person."
        ],
        [
            "Finally, we want to evaluate the quality of the model that's being produced, and for this this two criteria.",
            "One is how well is the model.",
            "Generalizing to face is not within the training data and you can see here the effect of training, set size and the reduction in the reconstruction error associated with these knew fitting images.",
            "But that's not the only aspect of the model, because of course if we had a, you know a fully flexible mesh, it would be possible to to reconstruct any image.",
            "So what we want to do is we want to have a model which generalizes well but also doesn't generalize to shapes which are beyond the face set.",
            "So one way of getting a feel for this is to calculate a measurement for the overall space of variation of the model.",
            "And here we use the L2 norm.",
            "Of the eigenvectors.",
            "Sorry the eigen values and this gives us a sense of how large the model is and what you can see here is.",
            "This is continuing to rise even though the reconstruction error is not continuing to be reduced and this is an indication that there is noise in the model process and this noise is what we're starting to model and so further work indicates that use of, for example, robust PCA may be beneficial here in producing a more accurate.",
            "And tighter mesh head model."
        ],
        [
            "So in summary of presented, a first step towards very accurate ear modeling for face recognition for face and ear recognition, and hope that this will advance the recognition accuracy for robust face recognition introduced an automated preprocessing stage and indicated the beginnings of the fully automated morphable model construction process and finally presented a framework which evaluates both the convergence and the model.",
            "And resulting model and gives us a basis for evaluating the quality of individual training images, which will be very important if we want to move forwards to stage where we have online learning of morphable models, potentially of more genr."
        ],
        [
            "All objects.",
            "And like many of the presentations, the source code is available online.",
            "Thank you very much.",
            "Do you have any questions?",
            "Thank you.",
            "Questions.",
            "Have more questions.",
            "Work question for you.",
            "The other.",
            "An you developed at Southampton and model for year representation based on the flow field on the 2D images.",
            "Now you are adding a third dimension using 3D model.",
            "How do you rate the advantage of using a 3D as versus only two D texture data with the key importance with the 3D data is to achieve robustness across pose and lighting changes.",
            "Ideally we want a very robust recognition method.",
            "A possible application would be for example cameras in a doorway or something like that as a form of biometric input, and under these circumstances we can't guarantee the lighting changes and the post changes, and because of the self occluding nature of the ear, even relatively small post changes across the face can significantly change the signal associated with the ear, and that's why there's a concentration on 3D modeling now, OK. Other questions.",
            "OK, so thank you very much for your presentation."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is John Bustard.",
                    "label": 0
                },
                {
                    "sent": "I'm from the University of Southampton.",
                    "label": 0
                },
                {
                    "sent": "My supervisor is Mark Nixon and today I'd like to present some progress in the field of morphable model construction.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, as you may be aware, Morphable models were first introduced in 1999 by Volker Blanz and Thomas Vetter and a Seminole work at SIGGRAPH.",
                    "label": 0
                },
                {
                    "sent": "They introduced an algorithm that, given a photograph, static image of a face with varying pose or lighting conditions, they could reconstruct the 3D surface of the face very accurately.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason they could do this was because they had an accurate model of the three dimensional shape variation and color variation, and that's what a morphable model is now.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's 1999.",
                    "label": 0
                },
                {
                    "sent": "There's been some progress in the development of different morphable model construction algorithms, but broadly, they consist of the following stages.",
                    "label": 0
                },
                {
                    "sent": "First of all, a training set of range scans is acquired.",
                    "label": 0
                },
                {
                    "sent": "And you can see here both color information and three dimensional information, usually with a laser scanner.",
                    "label": 0
                },
                {
                    "sent": "Then these images are processed manually to remove occluding regions such as the hair or earrings and noise regions as well, and then a set of initializing feature points are identified manually.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in the original work and optic flow algorithm was used to register very carefully, recorded and cleaned up head images.",
                    "label": 0
                },
                {
                    "sent": "More recent work has tended to use an artist produced model.",
                    "label": 0
                },
                {
                    "sent": "The advantages of this are that you can have more missing portions from your range scan and also in the model.",
                    "label": 0
                },
                {
                    "sent": "You can adjust the resolution according to the detail of the features you can see here.",
                    "label": 0
                },
                {
                    "sent": "The ear has more triangles associated with it.",
                    "label": 0
                },
                {
                    "sent": "The first step then, is to rigidly align this artist produced mesh using the feature points with the range scan and then to deform with the feature points, and then using a nonrigid iterative closest point algorithm and various variations on that.",
                    "label": 0
                },
                {
                    "sent": "You can then densely align the mesh to the range scan.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once you've completed that process for a set of heads, you basically have a dense registration across them.",
                    "label": 0
                },
                {
                    "sent": "And you can perform principal component analysis on all the vertices connected concatenated together to get this an estimate for the space of human face shapes.",
                    "label": 0
                },
                {
                    "sent": "You can repeat the same process with the texture which you can extract by inverse rendering onto the head surface.",
                    "label": 0
                },
                {
                    "sent": "Now, this process, as you've seen in the first slide can produce very good.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Results, but there are some areas for improvement.",
                    "label": 0
                },
                {
                    "sent": "One of the first areas is that in existing work, the ear region tends not to be accurately modeled, and I don't know what you can see here from the diagrams.",
                    "label": 0
                },
                {
                    "sent": "Often it's explicitly excluded because of its per convergence, and the reason that the mesh rarely converges accurately to the range scan is because of its self occluding structure, and because it's quite ornate, so be desirable to model that accurately.",
                    "label": 0
                },
                {
                    "sent": "One of the reasons for this is that recent work is indicated that the ear contains significant biometric information.",
                    "label": 0
                },
                {
                    "sent": "Indeed, at the same distance, under good conditions, both the ear and the face can produce equivalent recognition rates.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next area is to reduce the pre processing requirements to automate some of this removal of noise and occluders and to take a step towards the potential for the online learning of morphable models from much less constrained data.",
                    "label": 0
                },
                {
                    "sent": "So it could be more widely applied.",
                    "label": 0
                },
                {
                    "sent": "And finally.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Existing work is come from the graphics community and a lot of the results are being demonstrated through these very impressive reconstructions, but it's desirable to have a more analytical basis for evaluating the fitting process and the resulting models.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first, when looking at the year modeling now a number of different strategies were approached here, one of which included fitting the contour regions of the ear.",
                    "label": 0
                },
                {
                    "sent": "But in most cases the noise in the range scans were such that it was hard to get a good alignment, and so the key here is getting a good initialization that will converge.",
                    "label": 0
                },
                {
                    "sent": "Now in the work presented here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The key was to identify a kind of minimal set of ear feature points to enable convergence.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, this process is still manual, more recent work not included in the paper involves the automatic identification of good points and the automatic detection of these points, but further analysis is necessary to do this.",
                    "label": 0
                },
                {
                    "sent": "But to give you an indication of where it's going, it's to do with identifying feature points that are highly distinctive on a particular head surface and comparing them.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next stage is to look at the automated preprocessing.",
                    "label": 0
                },
                {
                    "sent": "Now the key here is to reduce the overall time, so we don't want a long training period as well.",
                    "label": 0
                },
                {
                    "sent": "So the way this proceeds is you start with the rigidly aligned head models and then you deform to the feature points.",
                    "label": 0
                },
                {
                    "sent": "And then because you're using notice produced mesh, there's a texture mapping a kind of 2D mapping across the surface, and you find the closest mesh surface point for each range point, and this gives you a positioning of the points over that surface.",
                    "label": 0
                },
                {
                    "sent": "That surface is then split into a set of regions overlapping regions, and the binary classifier trained for each region.",
                    "label": 0
                },
                {
                    "sent": "These contribute votes to determine whether the surface region is likely to be skin.",
                    "label": 0
                },
                {
                    "sent": "Are valid surface region or include are.",
                    "label": 0
                },
                {
                    "sent": "The classifiers consist of Gaussian model and it's trained using spin image features across the head surface, so each range pixel is got a spin image associated with it.",
                    "label": 0
                },
                {
                    "sent": "So then goes in models of both the positive and the negative spaces are calculated and this is using 30 training images.",
                    "label": 0
                },
                {
                    "sent": "Then these samples are then run through that classifier and the false negative and false positive regions are identified.",
                    "label": 0
                },
                {
                    "sent": "These are then subspaces are then calculated for these and within those regions of K nearest neighbors classifier is produced.",
                    "label": 0
                },
                {
                    "sent": "This is a very fast process to train and produces reasonably accurate results.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see here a bit of analysis of the results on the left.",
                    "label": 0
                },
                {
                    "sent": "We've got some of the processed answers and on the right we see the percentage of the head surface because different regions of the head surface have got different accuracies of classification and what the pixel classification error is in each case.",
                    "label": 0
                },
                {
                    "sent": "So although we're not getting perfect results here.",
                    "label": 0
                },
                {
                    "sent": "The results are sufficient that by adding an outlier detection stage in the dense fitting stage, these outliers can be removed and these are detected by calculating the maximum absolute deviation of the distances of the surface points to the range match to the art mesh, and the intuition here is that basically the outliers are generally far further from the surface than the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Liars.",
                    "label": 0
                },
                {
                    "sent": "Now finally, for the model analysis for the fitting analysis, the intuition here was that if you take multiple range scans of the same person and you fit the mesh to these scans, then if you're fitting process is converging accurately, you would expect the mesh model to be very similar to much more similar certainly than the fitted results for other heads, and this gives us a metric to determine how well our fitting process is converging.",
                    "label": 0
                },
                {
                    "sent": "You can see here that number one.",
                    "label": 0
                },
                {
                    "sent": "This represents the closest rank, so this is the L2 norm of the vectors of the fitted mesh positions.",
                    "label": 0
                },
                {
                    "sent": "Once they've been rigidly aligned with one another and you see the other distances and in all cases the closest head mesh is the mesh of the same person.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, we want to evaluate the quality of the model that's being produced, and for this this two criteria.",
                    "label": 0
                },
                {
                    "sent": "One is how well is the model.",
                    "label": 1
                },
                {
                    "sent": "Generalizing to face is not within the training data and you can see here the effect of training, set size and the reduction in the reconstruction error associated with these knew fitting images.",
                    "label": 0
                },
                {
                    "sent": "But that's not the only aspect of the model, because of course if we had a, you know a fully flexible mesh, it would be possible to to reconstruct any image.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is we want to have a model which generalizes well but also doesn't generalize to shapes which are beyond the face set.",
                    "label": 0
                },
                {
                    "sent": "So one way of getting a feel for this is to calculate a measurement for the overall space of variation of the model.",
                    "label": 0
                },
                {
                    "sent": "And here we use the L2 norm.",
                    "label": 0
                },
                {
                    "sent": "Of the eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "Sorry the eigen values and this gives us a sense of how large the model is and what you can see here is.",
                    "label": 0
                },
                {
                    "sent": "This is continuing to rise even though the reconstruction error is not continuing to be reduced and this is an indication that there is noise in the model process and this noise is what we're starting to model and so further work indicates that use of, for example, robust PCA may be beneficial here in producing a more accurate.",
                    "label": 0
                },
                {
                    "sent": "And tighter mesh head model.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in summary of presented, a first step towards very accurate ear modeling for face recognition for face and ear recognition, and hope that this will advance the recognition accuracy for robust face recognition introduced an automated preprocessing stage and indicated the beginnings of the fully automated morphable model construction process and finally presented a framework which evaluates both the convergence and the model.",
                    "label": 0
                },
                {
                    "sent": "And resulting model and gives us a basis for evaluating the quality of individual training images, which will be very important if we want to move forwards to stage where we have online learning of morphable models, potentially of more genr.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All objects.",
                    "label": 0
                },
                {
                    "sent": "And like many of the presentations, the source code is available online.",
                    "label": 1
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Do you have any questions?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Have more questions.",
                    "label": 0
                },
                {
                    "sent": "Work question for you.",
                    "label": 0
                },
                {
                    "sent": "The other.",
                    "label": 0
                },
                {
                    "sent": "An you developed at Southampton and model for year representation based on the flow field on the 2D images.",
                    "label": 0
                },
                {
                    "sent": "Now you are adding a third dimension using 3D model.",
                    "label": 0
                },
                {
                    "sent": "How do you rate the advantage of using a 3D as versus only two D texture data with the key importance with the 3D data is to achieve robustness across pose and lighting changes.",
                    "label": 0
                },
                {
                    "sent": "Ideally we want a very robust recognition method.",
                    "label": 0
                },
                {
                    "sent": "A possible application would be for example cameras in a doorway or something like that as a form of biometric input, and under these circumstances we can't guarantee the lighting changes and the post changes, and because of the self occluding nature of the ear, even relatively small post changes across the face can significantly change the signal associated with the ear, and that's why there's a concentration on 3D modeling now, OK. Other questions.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you very much for your presentation.",
                    "label": 0
                }
            ]
        }
    }
}