{
    "id": "maziy2ic3kucdoryg2uk72d6dmsoollk",
    "title": "Mining complex dynamic data",
    "info": {
        "author": [
            "Grigoris Tsoumakas, Department of Informatics, Aristotle University of Thessaloniki",
            "Arthur Zimek, LMU Institut f\u00fcr Informatik, Ludwig-Maximilians Universit\u00e4t",
            "Myra Spiliopoulou, Faculty of Computer Science (FIN), University of Magdeburg",
            "Irene Ntoutsi, LMU Institut f\u00fcr Informatik, Ludwig-Maximilians Universit\u00e4t"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Data Mining->Temporal & Streams Mining"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_tutorial_mining/",
    "segmentation": [
        [
            "So hello everyone, and welcome to this tutorial on mining complex data.",
            "My name is Gregorio Marcus.",
            "I'm from the Irish, will converse with the seller, Nikki.",
            "And this is joint work with Professor Hans Peter Kriegel hearing it duty and tax for the mic from a little bit Maximilians University, Munich and to his professor, my last pill pull from my University of Magnum book in German."
        ],
        [
            "OK, so this is the structure of the tutorial.",
            "After the introduction, I will talk on multi label data, some basic concepts and then how we work with data structure multi label data.",
            "Then I threw in the rainy will focus on high dimensional data in dynamic environments initially after that, before the break will focus on static.",
            "Had a national data and after the break it really will continue with dynamic high dimensional data and in the end a mirror.",
            "We'll talk on my multi relation that data and data evolution."
        ],
        [
            "So just a few words about their presenters.",
            "Myra Speaker Pool is a professor of information systems in the Faculty of Computer Science and not a fun character.",
            "University Magnum book.",
            "Since that set of their knowledge Management Discovery group, this is the co-founder of Web Web KDD Workshop series and has Co.",
            "Organized this MLK Day 2006 Antenna DB 2008.",
            "So it has also been the tutorial code Zero, Five 6010 and workshop set of ICM 2011.",
            "I'm a lecturer in the Department of Formatics at the original investor seller Nikki and member of the Machine Learning and Knowledge Discovery Group, and my main interests are assembled learning and multilabel learn."
        ],
        [
            "You really do think that resume mic work at the database systems and data Manic group of Professors Hanspeter Cricket at the Ludwig Maximilians University in Munich.",
            "Hearing it is a postdoctoral researcher there, and also scholar for annual exam performed humbled foundation.",
            "And perhaps is there is the glue datamining covered dynamic data with a focus on high dimensional data accuracy scientific assistant there and he works in special in clustering and clustering high dimensional data.",
            "Unfortunately, Professor constricted cricket could not be with us.",
            "He had he still in Canada with will be publications there."
        ],
        [
            "So their motivation for this tutorial is that it's dual.",
            "Basically that in recent years we see more complex types of data like multi label data, multi relational data, high dimensional data.",
            "So we have for example social networks that require the combination of activity recordings, which content recommendation made any sense that required user ratings, customer transactions, item descriptions and so.",
            "And at the same time we have a data to become more dynamic, they are evolving and we have a streams of such complex types of data.",
            "So this is where we will focus on how to manage complex data insights, dynamic environments and how to build methods that adapt to these changes with the data."
        ],
        [
            "So in the second a block I will discuss.",
            "As I said, the mining of multi label data.",
            "So the first part I will just say some basic concepts from static static multi label data and then focus on streaming multi label data and some issues that arise there."
        ],
        [
            "In Block 3, Iranian doctors will discuss high dimensional data.",
            "As I said initially, Arthur will focus on static high dimension dementional data.",
            "Any will talk on dynamic environments and data streams and how we deal with high dimensional data there."
        ],
        [
            "And finally.",
            "Myra will talk on my multi relational data, the kind of that we see in a social network and there we have for example persons entities like persons, resources, opinions and relations between these entities like persons upload, download, annotated content and so on, replied to other persons.",
            "So we have all these relationships and we want to we will study and discuss how to how we can learn from such kind of data that are evolving and especially with the focus on.",
            "Business applications."
        ],
        [
            "OK, so."
        ],
        [
            "Let's start with a multi label data part.",
            "So what does it mean when we say multi label data?",
            "We can say that these are data with.",
            "Multiple binary target variables.",
            "With that we call labels or baby.",
            "With another interpretation, we can say that we have instances annotated with a subset of a fixed set of labels.",
            "So for example, if we have an article about the recent Fukushima accident, we could say that this kind of data.",
            "This document is annotated with labels like nuclear crisis as your perfect specific energy and environment.",
            "So what are the main issues here?",
            "Basically, that one is how to exploit label structure to improve their predicted performance.",
            "And when we say label structure we mean basically dependencies between the labels.",
            "And of course, how to scale up to a large label dimensions that exist in common applications."
        ],
        [
            "So multi label data have become ubiquitous these days.",
            "There are many, many, many applications.",
            "The most important one is automated or semi automated annotations of large databases of different types of objects.",
            "Text web Daytimers data, video, audio, even biology data and with the ultimate goal of being able to perform information retrieval from this database.",
            "But there are also more specialized applications like tax suggestion, quicker categorization, drug discovery and so."
        ],
        [
            "So let's say some basic concepts, or about learning from multi label data.",
            "So we have the dimensional input space and we have a set of Q labels that we will denote Langer 12, Lambda cube.",
            "And the multi label data set is basically pairs of this section wise.",
            "That where X.",
            "Is a subset of the in space?",
            "And why is the subset of the label space?"
        ],
        [
            "What can we do?",
            "What can we learn from South Sudan to date?",
            "One first, the classical task is classification.",
            "Some people actually think.",
            "That model able learning is all about multilevel classification, but we will see more tasks that we can do that we can learn from this type of data.",
            "So in classification we have for example, a set of labels like this one.",
            "And we want to output.",
            "We want to train a model that outputs the partition of this space of labels into a positive and the negative set relevant labels to the object and irrelevant labels without."
        ],
        [
            "We can also do ranking.",
            "So we can let models that rank the labels from the most relevant label to this object.",
            "Do they list one?",
            "Do the least relevant one.",
            "So again in this example you see we have the same 5 labels and we output the ranking of this label, so they label Lambda 3.",
            "Is the most relevant one, and label Lambda one is the least relevant today a new instance."
        ],
        [
            "We could also combine both tasks.",
            "So we could output both every partition and the ranking as you see here at the end.",
            "And they what what we should take care of is that this would be consistent.",
            "Meaning that we shouldn't have.",
            "Negative labels in higher rank from positive labels.",
            "OK, so this is this holds here where a Lambda one and Lambda four are the top of the rank."
        ],
        [
            "Finally.",
            "What other thing?",
            "Another thing that we can do is probabilistic investing in indexing, and this is particularly interesting information retrieval.",
            "So what we ultimately want to produce these probabilities of relevance for the new object to this one of the labels.",
            "OK, so we have this.",
            "In this example we will have this vector of probabilities.",
            "Of course, from this a it's richer information.",
            "We can go to a ranking.",
            "If we do tiebreaking it, we could even go to be partitions.",
            "If we threshold somehow the ranking."
        ],
        [
            "Matlab Lliving requires slightly different evaluation measures, so we could organize them.",
            "According to two dimensions we have measures that according to the way they are calculated, we can call them example based.",
            "So we calculate its measure for example and update these measures.",
            "This is like a loss function for example.",
            "And to make a connection with what we will see next.",
            "Of course, that's kind of measures are easily calculated in a in a streaming fashion, right?",
            "So there's no need to collect statistics.",
            "Label based the measures are calculated separately for its label.",
            "Again here, depending on the measure, we have some measures that can be calculated.",
            "In an online classroom, but there are also measures we will see next that we have problems calculating in a streaming fashion.",
            "I will save more than in the next slides and according to the output of the model, we can categorize measure measures to those working on the partitions on ranking sonar probabilities."
        ],
        [
            "So I don't want to spend a lot of time here, but just to give you an impression of the measures, so just a couple of additional notations notations, so the P is the set of the predicted labels, for instance XI and why I set of actual labels.",
            "So to two common measures.",
            "Is there subset accuracy or 0?",
            "One last basically for multi label data.",
            "So this is a strict measure that.",
            "Penalizes predictions that are not entirely correct and as expected.",
            "And they penalize hard this kind of predictions.",
            "How many glosser is another common measure with just calculates the differences between the two sets, the predicate and the actual label.",
            "The set of labels, how different they are.",
            "And we have also other measures."
        ],
        [
            "Measures are inspired from information retrieval.",
            "So we have a precision recall and F1 measure calculated that the prepaids example.",
            "There is of course some issues here.",
            "As for example, what happens if the prediction settle?",
            "The relevant set is empty, then we might run some into some problems, defining precision and recall.",
            "And then and then they mean, of course."
        ],
        [
            "As far as the ranking measures are concerned, we have measures like 1 error that evaluates how many times the Top Rank label is not in the set of relevant labels of the example.",
            "Cover, it's that the value is how many steps we have to go down to the ranking list of labels to find all relevant."
        ],
        [
            "Payments.",
            "And perhaps one most commonly used is the ranking loss.",
            "With the.",
            "For each pair of labels Landley and Lundeby.",
            "Where land lay is a relevant label in London Visa Irrelevant label for, for example, it counts how many times at Spurs have the wrong ranking, so Despite that.",
            "Lambda busy, relevant.",
            "It is higher in the ranking from Lambda."
        ],
        [
            "Now label based measures.",
            "We can basically calculate any measure that.",
            "Exists for binary classification and then somehow aggregate the results so there are two ways to do this aggregation.",
            "One is called micro averaging where this is just the mean of the of the binary measure overall labels.",
            "And my collaborating with the.",
            "Put chosen on labels into, let's say one big metal label and computes the metric ones.",
            "My Provident treats all labels are equally why Microgrids Inc favors.",
            "Frequent labels, so this is something to have in mind.",
            "Depending on the application.",
            "Which measure we would like to use?"
        ],
        [
            "And finally, as we said, we have the probabilities, we can have probability.",
            "So depending on when we have this kind of output we can obtain every partition.",
            "As I said through thresholding and then use ordinary example or label based binary measures.",
            "If we solve ties in probabilities, we can obtain a ranking and then apply the example based ranking measures.",
            "We could compute also vertical ranking, so ranking of the objects.",
            "And this this is of course what we want to do in information retrieval applications, But this is also the case where we have problems.",
            "If we want to calculate this in a streaming fashion so.",
            "You cannot because you need to have the objects ordered.",
            "You cannot wait forever.",
            "Maybe you could calculate such metrics over moving window for example, but it's not the same.",
            "And of course the same calls for a stressful independent evaluation like area under a rock or PR curve which need also to sort the objects."
        ],
        [
            "So now we're continue with some very basic approaches, and it is this kind of approaches that have been used in a data stream setting, so This is why I will mention.",
            "To help our discussion next.",
            "So when we talk about multi label learning algorithms we usually.",
            "Categorize them into.",
            "Groups their problem transformation algorithms that basically take them out, label data and problem and transform it into one or more single label or.",
            "Classification regression problems.",
            "And then we have the algorithms adaptation methods that take a particular belief and adapt it so that it can directly work with multi label data.",
            "So we will discuss such algorithms that have been used in streaming settings."
        ],
        [
            "So by now, relevance is a very basic, but yet still strong baseline approach in multi label learning kits.",
            "Equal to the one versus rest approach in multiclass classification.",
            "So what we do is learn one binary classifier for its label.",
            "OK, so for example, if we have this data set with four examples and four labels.",
            "We create as many datasets as the labels and learn a binary model for each one of them.",
            "Its complexity is linear with respect to their labels and the number of examples, but its main limitation that also criticizes the criticism of this method is that it does not take into consideration potential correlations between labels, and this is basically one of the main goals in multi label learning.",
            "How to take into account set dependence and improve their results."
        ],
        [
            "A second basic method is a.",
            "The label Powerset method, as it's often called so this basically transforms the multi label data into a multiclass.",
            "Single label classification problem.",
            "So you see here for example.",
            "Again we have the same data set and we construct a new data set to where we have just one class and the class values are basically the different combinations that appear in the training set, so.",
            "Here is just a binary representation of this combination, Lambda one and Lambda four and so.",
            "So we have four different combinations for different classes, and we learn a single label as an ordinary classification and multiclass classification.",
            "What is the problem with this?"
        ],
        [
            "Type of approach.",
            "The problem is that this number of different classes can become very large, so it is upper bounded by the number of.",
            "Examples or the number of possible combinations, so M or two to the power of Q.",
            "And it's usually much smaller in practice, but we still larger than Q we can."
        ],
        [
            "See here.",
            "And some datasets.",
            "Commonly used the number of examples, the number of labels and you see that typically, unless we have very very small number of labels, like in this case which is 6, then the bound is equal to the two to the power of 6.",
            "But in there in the rest of the cases.",
            "The bond is equal to the number of examples.",
            "Now the actual label sets.",
            "As more are smaller than that as I said, but still quite lads and you can see that in some datasets like this music data set that has a 600.",
            "Approximately labels.",
            "The number of different combinations is almost equal to the number of.",
            "Example, so it's in it's example.",
            "We see a different combination, so it's like we are trying then to learn a multiclass problem with 32,000 classes.",
            "And that's not the only problem.",
            "The problem is that we have only one example from each one of these.",
            "Us so.",
            "If we see also if we focus on one of these datasets, the medium a data set to discuss.",
            "6500 approximately labels it."
        ],
        [
            "At the.",
            "Here we see a log log graph of the appearances of the.",
            "Or feeds of their label set.",
            "So we see that from this 6500 labels it's 4000 here 4000 appear only once, so they are associated with just one example.",
            "And the 895.",
            "Label says from this 6500 appear only twice have only two examples, so.",
            "Really, this is the problem that you can not learn from so many few, so the social examples paper class.",
            "Apart from that."
        ],
        [
            "It has another problem that also is relevant to the streaming setting that it cannot predict answered label set, so it learns to predict only those labels that has it has seen in the training set.",
            "So when you have a stream of.",
            "Since later you imagine that new combinations will appear, and so that's an approach should be somehow adapted to handles this appearance of new labels.",
            "They had their."
        ],
        [
            "It's been some work that improves with basic approach.",
            "This is the proof sets approached by Riddle.",
            "And it has also been used in a streaming set setting.",
            "That's why I'm presenting it.",
            "So what this does too?",
            "And deal with the problems of the label Parset method is that it prunes those infrequent labels.",
            "It's so it runs away combinations that are.",
            "Very rare at introduces the examples that are so associated with those rare label sets, but it introduces them with.",
            "Frequent subsets of these labels, so this is done with two strategies with and we can see an exam."
        ],
        [
            "So we're back to this.",
            "Example with four labels and you can see the different label sets that exist now in a new different data set and these are sorted by frequency.",
            "So they are going has a parameter P. And it proves away.",
            "All labels said that are rarer than this parameter, so they lost.",
            "My nation will be pruned away.",
            "But the this information the instance language based information must be introduced.",
            "By assigning this examples to labels of subsets of these labels that are frequent.",
            "So let's see all these subsets of this.",
            "Rare labels it.",
            "Basically it's Lambda two Lambda free Land Lander, one Lambda 2.",
            "And with one strategy it sorts this.",
            "Subsets of this rare label label set according to their size.",
            "So this one has two labels, size of two.",
            "This has one and then Secondly sorts them by the number of examples associated with this label.",
            "So 16 and then has another parameter bit and says we will keep the top two, the top be enter introduce this.",
            "Examples with this now frequent label, so in order not to lose this information.",
            "And with another strategy.",
            "It sorts the subjects only based on size and select those that has the half size greater than a threshold, again with parameter P so it reintroduces the examples only with this label.",
            "So this is how this approach works.",
            "And this closes their problem.",
            "Transformation type of methods."
        ],
        [
            "Now as far as albums adaptation methods are concerned.",
            "Methods that are based on decision trees have been used for streaming data.",
            "And such methods are the multi labels for Wild Label version of the C 4.5 algorithm proposed by Clearing King in 2001, where the main concept here is that we change the definition of entropy.",
            "And basically just the sum of the binary entropies of the labels.",
            "If you see here.",
            "So.",
            "But you built in this way just one tree for all labels.",
            "And another.",
            "Well performing approach that also follows the Decision tree para banking is the predicted clattering trees.",
            "And one of the publications appearing is in Vincent Al.",
            "There the main issue the main concept is this algorithm is that.",
            "The best attribute in order to do the split is based on the notion of reduction of variance, and so you can.",
            "Basically, if you have a data set.",
            "If you are in a node in the tree and you have some data.",
            "What you do is calculate the average.",
            "Of the output space.",
            "So this is the.",
            "Let me know the output space there.",
            "The mean of their, let's say late 01 values for all the labels and then you calculate the distance of each one of the output page of this examples.",
            "Of the outer part of these examples with this mean, and of course the smaller they mean, the better the more homogeneous is the the node.",
            "So this is basically them.",
            "The decision tree approaches that.",
            "Work with multi label data."
        ],
        [
            "No, closing this part of static static multi level data.",
            "Just some pointers for further work for someone who is who is interested more so a survey and also an open source software that with implementations of several algorithms for data sets for you to play with."
        ],
        [
            "So.",
            "Now, what about the dynamic?",
            "Multilabel data so I will give some examples of really dynamic data in meaning that we have object evolution.",
            "We have also label evolution and we go well.",
            "We also have database tables for examples.",
            "In the code example in Wikipedia.",
            "The content of the articles can be updated the categories through the labels associated to documents in Wikipedia can be updated, and of course we have new articles being added or deleted.",
            "So another very interesting thing also that interests asking streaming scenarios is that there is no fixed set of categories, so users may add new category.",
            "So this is quite different from the usual static multi label data where the the number of categories were there.",
            "They go to fix.",
            "The labels are fixed.",
            "And also examples from health.",
            "Where, for example, a person may be suffering from one or more diseases, and these changes as time changes.",
            "So you have a database where the label civil and.",
            "New diseases may appear, or we may have an outbreak of existing ones, and so.",
            "So to the best of my knowledge, I haven't seen.",
            "Any work on dealing with this kind of evolutions with multi label data?",
            "But there is some work that we."
        ],
        [
            "Focus now on concerning streaming multi label data, so this is a similar case of dynamic data.",
            "So we have a stream of incoming labeled multi label examples so applications so you can imagine.",
            "Here are for example emails that person tags into multiple categories.",
            "We all do that.",
            "A news aggregator that gathers news and also this may be tagged with different labels and then generally web to content.",
            "Now in this, in this streaming scenario there of course the challenges of multi label learning remains, so we still must exploit the dependencies with between labels and we still must be must have efficient methods that scale to large number of labels.",
            "But we also inherit the Italians of string learning, so we also do must do incremental learning under constraints in time and memory.",
            "And of course we have to to deal with the problem of concept drift if we are discussing if we're dealing with valving.",
            "Label data of course.",
            "1 issue.",
            "Here is, is it the notion of concept drift in multi label diarize is the same.",
            "Is it different in this case?",
            "So we will talk a little bit of that in the next slide and some other issues that concern us here.",
            "Is how do we construct synthetic multi label data?",
            "Because this is always an issue even in.",
            "In less in single label, for example, within a strange with single day.",
            "With simple data like single label data.",
            "And of course, again, as I said, I mentioned that also before, how do we deal with an open ended label space?",
            "So we might have a stream of objects and no other evolution, but still, the label space might be evolving.",
            "So how do we also deal with that?"
        ],
        [
            "Now as far as a concept is concern in single label data in classification data we can say for example that the class priors might change overtime.",
            "All the way they classes.",
            "Let's say genetically examples also changes overtime, so the meaning of the concepts also change overtime.",
            "So what does it?",
            "What does conservative mean in multi label data?",
            "We may say we may look at it from the.",
            "Label part from their lip from the side of the labels and we can say that OK label priors also change overtime, but.",
            "There is a cut here to so that does all this do all these prior change at the same time?",
            "OK, this is an assumption often made in some of the.",
            "Approach is presented in variables.",
            "And then what about the combinations of labels the label set priors?",
            "OK, this may also change overtime.",
            "And the connection of the label sets with the data, which might also send, so it's a bit more complex and we have to take into account also this.",
            "These issues instead of just simply saying OK Multi label data, we just have changes in their labels."
        ],
        [
            "So one of the major issues here is how to create synthetic data.",
            "Synthetic label data streams.",
            "So what I would say, then we'll ask the question, why not use a real world data?",
            "And that's all there is, because there aren't any available.",
            "So.",
            "This is unfortunately true, with one exception of the Reuters corpus volume.",
            "The famous Reuters tax data set.",
            "That has timestamps and this kind of.",
            "A stream limited stream.",
            "But there's also the issues out there that at least from experiments that we have seen that there is no limit on some major concept Riddler.",
            "So going back to the that, there are not any data set available then one could say then why do we deal with this problem?",
            "OK, so if there are no real world data then why do you?",
            "Have to do work on this, but well, they think that's partly true in many problems, but the truth here is that it's very difficult to obtain.",
            "World stream data.",
            "The 1st place and also multi label String Theta is even harder so this may require access to operational systems and the tweaking.",
            "This may involve sensitive data and in fact I was discussing in last year's a female katebe conference with George Foreman from here Packard Labs and he has some very nice streaming multi label text data from the customer center and OK at least.",
            "I told him let's make a contest that silence.",
            "Let's organize that silence around this and.",
            "See you with my label method.",
            "Works well and so on, but he told me immediately that there are so many legal issues that we cannot get ahold of such data, so these are some reasons why real world not labeled letter not available.",
            "And of course, if you find real world data then what is concept drift in this data?",
            "So you may need a domain expert to explain where that risk happens and what exactly it means.",
            "OK, so some issues to consider here.",
            "From based on existing care work is that we have to ensure that the priorities of the labels and the dependencies between the labels.",
            "Follow that of real world multilabel data.",
            "And also we have of course to simulate concept drift whatever this means.",
            "As we said earlier.",
            "So let's take a look of.",
            "The label prior so insane."
        ],
        [
            "State diaper.",
            "So here I have two datasets, the call 500 data set is a music data set and the medium is a video data set.",
            "Call 500 + 374 labels on average.",
            "26 for example, and 500 examples and maybe only has 101 labels for another reason.",
            "Approximately 44,000 examples.",
            "And you see here.",
            "The distribution of the label Priors, which follows a kind of power law, so we have most of the label labels are really, really rare.",
            "So it's below 0.1 frequency.",
            "But you also have somewhere.",
            "Maybe one with a high frequency and the same approximately the same.",
            "We notice here in medium."
        ],
        [
            "And another two datasets.",
            "East is a biological.",
            "Data set with a few number of labels and we here we here notice that the distribution is slightly different, but in the end run textual data we see again that it has the same behavior.",
            "So most most of the labels are rare.",
            "Yes, when there are some.",
            "More frequently, one, so let's see now what the existing work of generating synthetic multi label data has done so far."
        ],
        [
            "So one of the approaches is that of Q ET al.",
            "There's an machine learning conference in 2009, So what they did there?",
            "They in order to introduce concept drift.",
            "They use the ideas that exist in single name label streams.",
            "So there we have a moving hyperplane to define changing binary concept.",
            "So now we have one moving hyperplane per label, yes but OK.",
            "But this means that all labels drift simultaneously then so is this realistic?",
            "Is this what happens?",
            "We expect to happening in real world model labeled data streams, some labels matrix, some others may not.",
            "You could set a different speed of drift to to simulate this.",
            "This was not done by the by the authors of course, and another issue is that the label priors that they used.",
            "It was Zero point 5 for all labels, so again something really different.",
            "And something that should be taken care of in each user works.",
            "This means that the average number of labels, for example, would be.",
            "Two, the number of labels divided by two, so half of the half of the labels, which is as we said in real world data as we saw before, it's quite unrealistic.",
            "And how did they introduce label dependencies?",
            "Basically, this was quite an ad hoc approach that does not scale.",
            "Manual introduction of this depends if this dependence just for for labels.",
            "So."
        ],
        [
            "A more advanced approach.",
            "Is that a very little and 2010?",
            "So there they did something better with the label priors.",
            "So we have a parameter said that controls the average number of labels bearing samples for example.",
            "So this could be set.",
            "Do a number that is small with respect to the number of labels.",
            "As we usually notice in real world data.",
            "But label priors this time was they were assigned randomly and then scaled to.",
            "Scale based on this red parameter scale too.",
            "Comply with that parameter, but again, this this would make a distribution different from what we have seen in before in the real world data.",
            "But still it's a step forward.",
            "In terms of dependencies.",
            "They create a cube IQ probability matrix.",
            "So in the beginning they just.",
            "Consider that all labels are independent from each other, and we're talking about unconditional dependence and independence, so we're not looking at the input space as the labels.",
            "And they overwrite some of these.",
            "Values to introduce dependencies, so this OK simulates somehow the dependencies we see in real world data, and then they use the bicycle to fit to fill in the rest of the matrix.",
            "So what is the idea?"
        ],
        [
            "The main idea to how to create them?",
            "The synthetic data set.",
            "It's actually basically, it actually is just a single binary.",
            "Then later, for binary classification problems underneath.",
            "And how does it work?",
            "The main idea is that labels and combinations of labels and labels that they are affected by one or more of the features, that is the basic idea.",
            "And how do they do that?",
            "They have an attribute mapping function.",
            "That Maps attributes.",
            "Two, the 2 / 2 most probably subsets of labels according to the probability to the prior probability.",
            "The probability matrix they define.",
            "So.",
            "OK, the idea is of course very nice, but one issue that we must consider is that this number of subsets is very small.",
            "So as we say, as we saw in the label Powersets approach, they combine the different combinations are usually.",
            "Too many, not half of the labels, so this approach kind of favors more.",
            "The prune sets approach that proves this.",
            "And infrequent labels like so.",
            "And it's not that realistic in the sense.",
            "We don't see so few label sets in real world data.",
            "OK, so then how does it work?",
            "First label is selected based on the prior probabilities and then more labels may be added may be added or not according to the matrix of the probability with the dependency probabilities.",
            "Then they generate one positive and one negative example from the single label binary generator that I told you.",
            "Then this is just a parameter of this method.",
            "You can use any generator that you would like for binary problems.",
            "And then for it's for.",
            "It's one of the features.",
            "If it affects the this combination or a subset of this combination according to the mapping function, then we add the positive example or the value of the positive example or the value of the negative one.",
            "So let's see that."
        ],
        [
            "This with an example.",
            "So here we have a 5 features.",
            "X165.",
            "We have how many labels?",
            "How many combinations?",
            "We have four combinations of labels, Lambda, one Lambda, two Lambda, three and this one.",
            "And then we start from the beginning.",
            "OK, this is the modular function they had, so if we had more features than we would see this iterate again and again.",
            "And since we have four label sets, how many labels we have?",
            "8 right, because we said that."
        ],
        [
            "Yeah, they take the half of the number of labels, most prob."
        ],
        [
            "Double subject so.",
            "Since we have four subsets, this means that we have four labels, 8 labels, but we only see three of these labels.",
            "Now we create the the new combination of labels based on the priors and the dependence matrix.",
            "This is the new label combinations, combinational Lambda one Lambda 3L1L3 here.",
            "And the.",
            "We notice that for the 1st.",
            "Attribute.",
            "This.",
            "Combine nation, OK, single label.",
            "But this is also a subset of the label, so it's acceptable.",
            "We see that it is a subset of this one, so this means that this since this feature affects this label, social effects this combination.",
            "So This is why we take the value of the positive example input here in the synthetic data.",
            "Inventory space office.",
            "Here we see a two and this is not here, so we take the value of the negative example and so on.",
            "So this is how this approach.",
            "This Nobel approach offering that all works.",
            "So what about concentrate?",
            "Where the user ideas from.",
            "The.",
            "From single label streams, basically so they have already developed an approach for.",
            "A creating custom drift by mixing different single label streams and the same can be applied.",
            "Of course for multi label streams.",
            "But again, what is the cats here?",
            "That this means that.",
            "All labels will drift simultaneously and again.",
            "Is that something that we expect in a realistic model able data stream?",
            "Probably not.",
            "And there is there.",
            "These are two different must be labeled streams, totally different.",
            "We expect the change would be quite radical."
        ],
        [
            "So that that was all about how to create synthetic multi label data.",
            "Basically we have these two up two main approaches and this is still an ongoing area.",
            "You know?",
            "What about learning approaches?",
            "The OK we have created the OR we have them streams of my label data.",
            "How do we learn?",
            "There is of course a lot of work on online learning and machine learning community, and we could apply that to strings, but we should also in addition.",
            "Sam thanks Ronald before adapting to drift and there is also.",
            "There's also a few works on directly working on Multi label data streams, so let's see.",
            "Did I say a few words about?"
        ],
        [
            "So one A1 online learning algorithm from 2003 that does ranking.",
            "It doesn't output since the math class multilayer perceptron algorithm by cramming Seager so this one maintains one linear perceptron per label, and the weights get updated when the ranking that is output by the by the perceptrons is wrong.",
            "And then according to the magnet they according to how many labels are ranked higher.",
            "How many positive labels are ranked higher than negative labels and the opposite the magnitude of change is according to that.",
            "And it also further depends on the what the actual loss was.",
            "So typical losses here used.",
            "Is there like the ranking close that we saw earlier at the beginning of the presentation?",
            "So things to point out for this algorithm is that it has if it performs better, it does better ranking compared to the binary relevance.",
            "The simple independent approach, it is linear with respect to the number of labels.",
            "But as I said, it cannot output partitions it it should.",
            "It would require some kind of restaurant service coding mechanism and probably one that adapts also that is also online."
        ],
        [
            "Some additional points that they interest.",
            "Asking this in the streaming scenario multi level data.",
            "It is that it can take into account new label.",
            "So for example, when a new label appears, we could just initialize the new person.",
            "So this is not something.",
            "Examined by the authors, but I'm just the.",
            "Discussing this opportunity here.",
            "Of course, there is no explicit causative handling, but however it could serve as a strong baseline in papers presenting multilabel data, stream algorithm and of course there are also some extensions that bring better performance, some pairwise approaches but to the expense of quadratic complexity with respect to the number of labels.",
            "So I'm not saying anything more on that."
        ],
        [
            "So one of the first.",
            "Papers discussing directly.",
            "Label data streams.",
            "Was that Q ET al approach this the same that we show before that also had an approach to create synthetic data.",
            "So how does it?",
            "How does it work?",
            "It partition the strings into chunks of equal size.",
            "Train multilabel classifier from it sank and keeps the last end tracks.",
            "So, given a new instance, it finds the game nearest neighbors in the latest in the latest rank, it computes the accuracy of the models in this nearest neighbors.",
            "And they usually says I waiting await with the voting process.",
            "So this is a typical approach, followed in a static and samples.",
            "So here is."
        ],
        [
            "Here is a.",
            "A paper by Zimbel Petal one year earlier.",
            "I have kept the previous light and only you see in red.",
            "The difference is so instead of single instead of multi level we have single label.",
            "And there there, instead of keeping the delvine thanks, they keep their best and tax based on Microsoft.",
            "It's basically the same algorithm.",
            "And what does this?"
        ],
        [
            "Tells us.",
            "Is that basically we can use state of the art and sample methods for like the approach of symbol or one at all.",
            "Anne and readily apply them to label data so we can train different models, different models, label models from different sites, and we readily can apply this approach to multi label data.",
            "Anne.",
            "Of course.",
            "This could be used as a baseline, and it's something that we should compare against.",
            "But again, such an approach assumes that if concept drift will happen, it will happen for all labels, because when you throw away a model you throw away the complete, more complete model affecting all labels not.",
            "One specific label, or a subset of the label, so again.",
            "We can borrow ideas from single label data label that what we should also take into account the issues that arise in specifically in multi label data."
        ],
        [
            "Another approach that was recently proposed is based on the is based on the halting tree, and this is a multi label version of this tree.",
            "So it combines the combines the tree of democracy and helping the carpeting.",
            "And the multi label Decision Tree that I showed you in the first part of this talk and what they also do.",
            "They also consider train training a model able learner at the leaves of this wedding tree, and in particular they argued for the Princess algorithm that I also showed you before.",
            "So we said of course that proof sets.",
            "In cats, the problems of their laborers pouched the algorithm so it cannot predict unseen labels, and it has to wait and see some labels that in order to be able to predict them.",
            "So this is usually treated by having a first period of let's say N examples.",
            "During which they consider only single labels and then they calculate the combination and start predicting also with kind of combinations."
        ],
        [
            "In addition, read Attalla explored and sample techniques.",
            "Existing assembly techniques for singulated illustrates such that they add Edwin bagging approach, so it's basically an online bagging approach that replaces model based on accuracy.",
            "Whenever this there is concept drift and this is monitored by Edwin algorithm.",
            "But again, here we have the same issue that all labels are causing did that.",
            "They should there since we have we throw away the complete model that we have the assumption that all labels def simultaneously and this is not so realistic.",
            "Another thing to point in this kind of approach and also other approaches that are based on examples.",
            "Is that the?",
            "If you want to, if we want to be able to output the partitions, then we somehow need to have a thresholding mechanism.",
            "Becauses assemblies give us votes and this is just the then the combination of votes of their average is just an American output.",
            "So you need some kind of thresholding and this thresholding needs to be also incremental.",
            "So what they what they did in their approach is to incrementally update, increase or increase the threshold.",
            "Based on the predicted partition, the size of the predicted partition, and what the actual one was.",
            "So if the output was three labels and the.",
            "The actual labels were for.",
            "For example, maybe they should lower the threshold to have a better recall.",
            "They lower the threshold to have better recall.",
            "I."
        ],
        [
            "There were, they they.",
            "Perform some experiments with several variations, so I don't want to."
        ],
        [
            "To go into the details.",
            "To save some time."
        ],
        [
            "I will just give you the results that compared to binary approaches and compared to the simple crafting Multi Label 3.",
            "Using the process algorithm, the lips at the leaves help.",
            "In real world data and also using this online bagging approach.",
            "Again, having the whole thing tree and proof sets algorithm at their lives also gave the best results in terms of 1 metric at least that I show you here, but also in others they have results with more measures.",
            "So this we can consider this as a state of the art method in this domain."
        ],
        [
            "Finally, quite recent method follows a different line of thinking.",
            "The multiple windows approach.",
            "In this years it's guy.",
            "It may, it looks at it looks the problem from a binary view and basically it maintains a fixed size.",
            "Moving Windows separately for its label and separately for the positive and negative examples of its label.",
            "So.",
            "This is done basically to deal with class imbalance.",
            "That is typically as we as we as we have seen, labels are quite rare and we have a class imbalance and through you have a single window.",
            "Then you are losing a lot of positive examples, so this is basically the main idea behind this this approach so it uses a KNN binary classifier on the Union of the positive and negative windows.",
            "And it has a problem like any binary approach, that it ignores correlations between labels.",
            "But this can be fixed by exploiting binary approaches that.",
            "Benefit from defenders from dependencies like from example.",
            "The sample of classifier chains approach.",
            "But the benefit is that we can deal with this issue of multiple concentrates, so as we as we focus separately on its label.",
            "So we can detect separately the drift at the label level.",
            "And of course they get take care of a glass."
        ],
        [
            "Balance.",
            "A few more words on this approach that there is no training involved as it used the cane and algorithm.",
            "And with every new example, it updates the positive and negative windows of its label that have a fixed size, and there's also space efficient implementation for setting examples between the positive and negative windows.",
            "And the prediction involves a nearest neighbor sets of the Union of positive and negative examples of its label.",
            "Again, there's an efficient implementation for this.",
            "And there since we have.",
            "A a number of neighbors and we get there.",
            "The average of their votes.",
            "Again, the output is in terms of is in America output, so we also have here.",
            "Enneagram mental thresholding technique to him too in order to be able to output to be partitions."
        ],
        [
            "This is basically an incremental version of an existing method for static method.",
            "They pick up method.",
            "So what it does is that every instance is it calculates the threshold that would most accurately approximate the observed frequency within that window of that label, and then this gets updated every N instances and quite good results have been noticed with this kind of online thresholding approach."
        ],
        [
            "So to conclude, my to conclude my part.",
            "We have discussed multilabel data.",
            "We see that this is a such data Arabic with this and.",
            "They are complex in the sense that the label space can be quite large, and of course the labels.",
            "It's also.",
            "And we need their techniques that exploit the structure of labels and deal scale to the large number of labels.",
            "In addition, when we move to streaming environments, we notice that we need techniques for incremental learning and also.",
            "We have time and memory constraints and we must deal with conservation.",
            "And particularly, things that must be notice in work in this area is how to create properly the synthetic data.",
            "How to adapt to the multi label version of concept drift and careful definition of this and also help you deal with class imbalance issues and also thresholding in order to obtain maybe partitions."
        ],
        [
            "So."
        ],
        [
            "So that."
        ],
        [
            "It would be the end to this."
        ],
        [
            "Block so thank you very much.",
            "So should we have questions now, OK?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everyone, and welcome to this tutorial on mining complex data.",
                    "label": 0
                },
                {
                    "sent": "My name is Gregorio Marcus.",
                    "label": 0
                },
                {
                    "sent": "I'm from the Irish, will converse with the seller, Nikki.",
                    "label": 0
                },
                {
                    "sent": "And this is joint work with Professor Hans Peter Kriegel hearing it duty and tax for the mic from a little bit Maximilians University, Munich and to his professor, my last pill pull from my University of Magnum book in German.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the structure of the tutorial.",
                    "label": 0
                },
                {
                    "sent": "After the introduction, I will talk on multi label data, some basic concepts and then how we work with data structure multi label data.",
                    "label": 0
                },
                {
                    "sent": "Then I threw in the rainy will focus on high dimensional data in dynamic environments initially after that, before the break will focus on static.",
                    "label": 0
                },
                {
                    "sent": "Had a national data and after the break it really will continue with dynamic high dimensional data and in the end a mirror.",
                    "label": 0
                },
                {
                    "sent": "We'll talk on my multi relation that data and data evolution.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just a few words about their presenters.",
                    "label": 0
                },
                {
                    "sent": "Myra Speaker Pool is a professor of information systems in the Faculty of Computer Science and not a fun character.",
                    "label": 1
                },
                {
                    "sent": "University Magnum book.",
                    "label": 0
                },
                {
                    "sent": "Since that set of their knowledge Management Discovery group, this is the co-founder of Web Web KDD Workshop series and has Co.",
                    "label": 0
                },
                {
                    "sent": "Organized this MLK Day 2006 Antenna DB 2008.",
                    "label": 0
                },
                {
                    "sent": "So it has also been the tutorial code Zero, Five 6010 and workshop set of ICM 2011.",
                    "label": 0
                },
                {
                    "sent": "I'm a lecturer in the Department of Formatics at the original investor seller Nikki and member of the Machine Learning and Knowledge Discovery Group, and my main interests are assembled learning and multilabel learn.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You really do think that resume mic work at the database systems and data Manic group of Professors Hanspeter Cricket at the Ludwig Maximilians University in Munich.",
                    "label": 1
                },
                {
                    "sent": "Hearing it is a postdoctoral researcher there, and also scholar for annual exam performed humbled foundation.",
                    "label": 1
                },
                {
                    "sent": "And perhaps is there is the glue datamining covered dynamic data with a focus on high dimensional data accuracy scientific assistant there and he works in special in clustering and clustering high dimensional data.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, Professor constricted cricket could not be with us.",
                    "label": 0
                },
                {
                    "sent": "He had he still in Canada with will be publications there.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So their motivation for this tutorial is that it's dual.",
                    "label": 1
                },
                {
                    "sent": "Basically that in recent years we see more complex types of data like multi label data, multi relational data, high dimensional data.",
                    "label": 0
                },
                {
                    "sent": "So we have for example social networks that require the combination of activity recordings, which content recommendation made any sense that required user ratings, customer transactions, item descriptions and so.",
                    "label": 1
                },
                {
                    "sent": "And at the same time we have a data to become more dynamic, they are evolving and we have a streams of such complex types of data.",
                    "label": 0
                },
                {
                    "sent": "So this is where we will focus on how to manage complex data insights, dynamic environments and how to build methods that adapt to these changes with the data.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the second a block I will discuss.",
                    "label": 1
                },
                {
                    "sent": "As I said, the mining of multi label data.",
                    "label": 0
                },
                {
                    "sent": "So the first part I will just say some basic concepts from static static multi label data and then focus on streaming multi label data and some issues that arise there.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In Block 3, Iranian doctors will discuss high dimensional data.",
                    "label": 1
                },
                {
                    "sent": "As I said initially, Arthur will focus on static high dimension dementional data.",
                    "label": 0
                },
                {
                    "sent": "Any will talk on dynamic environments and data streams and how we deal with high dimensional data there.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally.",
                    "label": 0
                },
                {
                    "sent": "Myra will talk on my multi relational data, the kind of that we see in a social network and there we have for example persons entities like persons, resources, opinions and relations between these entities like persons upload, download, annotated content and so on, replied to other persons.",
                    "label": 1
                },
                {
                    "sent": "So we have all these relationships and we want to we will study and discuss how to how we can learn from such kind of data that are evolving and especially with the focus on.",
                    "label": 0
                },
                {
                    "sent": "Business applications.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's start with a multi label data part.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean when we say multi label data?",
                    "label": 0
                },
                {
                    "sent": "We can say that these are data with.",
                    "label": 0
                },
                {
                    "sent": "Multiple binary target variables.",
                    "label": 0
                },
                {
                    "sent": "With that we call labels or baby.",
                    "label": 1
                },
                {
                    "sent": "With another interpretation, we can say that we have instances annotated with a subset of a fixed set of labels.",
                    "label": 1
                },
                {
                    "sent": "So for example, if we have an article about the recent Fukushima accident, we could say that this kind of data.",
                    "label": 0
                },
                {
                    "sent": "This document is annotated with labels like nuclear crisis as your perfect specific energy and environment.",
                    "label": 0
                },
                {
                    "sent": "So what are the main issues here?",
                    "label": 0
                },
                {
                    "sent": "Basically, that one is how to exploit label structure to improve their predicted performance.",
                    "label": 1
                },
                {
                    "sent": "And when we say label structure we mean basically dependencies between the labels.",
                    "label": 0
                },
                {
                    "sent": "And of course, how to scale up to a large label dimensions that exist in common applications.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So multi label data have become ubiquitous these days.",
                    "label": 0
                },
                {
                    "sent": "There are many, many, many applications.",
                    "label": 0
                },
                {
                    "sent": "The most important one is automated or semi automated annotations of large databases of different types of objects.",
                    "label": 1
                },
                {
                    "sent": "Text web Daytimers data, video, audio, even biology data and with the ultimate goal of being able to perform information retrieval from this database.",
                    "label": 0
                },
                {
                    "sent": "But there are also more specialized applications like tax suggestion, quicker categorization, drug discovery and so.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's say some basic concepts, or about learning from multi label data.",
                    "label": 0
                },
                {
                    "sent": "So we have the dimensional input space and we have a set of Q labels that we will denote Langer 12, Lambda cube.",
                    "label": 1
                },
                {
                    "sent": "And the multi label data set is basically pairs of this section wise.",
                    "label": 0
                },
                {
                    "sent": "That where X.",
                    "label": 0
                },
                {
                    "sent": "Is a subset of the in space?",
                    "label": 0
                },
                {
                    "sent": "And why is the subset of the label space?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "What can we learn from South Sudan to date?",
                    "label": 0
                },
                {
                    "sent": "One first, the classical task is classification.",
                    "label": 0
                },
                {
                    "sent": "Some people actually think.",
                    "label": 0
                },
                {
                    "sent": "That model able learning is all about multilevel classification, but we will see more tasks that we can do that we can learn from this type of data.",
                    "label": 0
                },
                {
                    "sent": "So in classification we have for example, a set of labels like this one.",
                    "label": 1
                },
                {
                    "sent": "And we want to output.",
                    "label": 0
                },
                {
                    "sent": "We want to train a model that outputs the partition of this space of labels into a positive and the negative set relevant labels to the object and irrelevant labels without.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also do ranking.",
                    "label": 0
                },
                {
                    "sent": "So we can let models that rank the labels from the most relevant label to this object.",
                    "label": 0
                },
                {
                    "sent": "Do they list one?",
                    "label": 0
                },
                {
                    "sent": "Do the least relevant one.",
                    "label": 0
                },
                {
                    "sent": "So again in this example you see we have the same 5 labels and we output the ranking of this label, so they label Lambda 3.",
                    "label": 0
                },
                {
                    "sent": "Is the most relevant one, and label Lambda one is the least relevant today a new instance.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We could also combine both tasks.",
                    "label": 0
                },
                {
                    "sent": "So we could output both every partition and the ranking as you see here at the end.",
                    "label": 0
                },
                {
                    "sent": "And they what what we should take care of is that this would be consistent.",
                    "label": 0
                },
                {
                    "sent": "Meaning that we shouldn't have.",
                    "label": 0
                },
                {
                    "sent": "Negative labels in higher rank from positive labels.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this holds here where a Lambda one and Lambda four are the top of the rank.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally.",
                    "label": 0
                },
                {
                    "sent": "What other thing?",
                    "label": 0
                },
                {
                    "sent": "Another thing that we can do is probabilistic investing in indexing, and this is particularly interesting information retrieval.",
                    "label": 0
                },
                {
                    "sent": "So what we ultimately want to produce these probabilities of relevance for the new object to this one of the labels.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have this.",
                    "label": 0
                },
                {
                    "sent": "In this example we will have this vector of probabilities.",
                    "label": 0
                },
                {
                    "sent": "Of course, from this a it's richer information.",
                    "label": 0
                },
                {
                    "sent": "We can go to a ranking.",
                    "label": 1
                },
                {
                    "sent": "If we do tiebreaking it, we could even go to be partitions.",
                    "label": 0
                },
                {
                    "sent": "If we threshold somehow the ranking.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Matlab Lliving requires slightly different evaluation measures, so we could organize them.",
                    "label": 1
                },
                {
                    "sent": "According to two dimensions we have measures that according to the way they are calculated, we can call them example based.",
                    "label": 0
                },
                {
                    "sent": "So we calculate its measure for example and update these measures.",
                    "label": 1
                },
                {
                    "sent": "This is like a loss function for example.",
                    "label": 0
                },
                {
                    "sent": "And to make a connection with what we will see next.",
                    "label": 0
                },
                {
                    "sent": "Of course, that's kind of measures are easily calculated in a in a streaming fashion, right?",
                    "label": 0
                },
                {
                    "sent": "So there's no need to collect statistics.",
                    "label": 0
                },
                {
                    "sent": "Label based the measures are calculated separately for its label.",
                    "label": 1
                },
                {
                    "sent": "Again here, depending on the measure, we have some measures that can be calculated.",
                    "label": 0
                },
                {
                    "sent": "In an online classroom, but there are also measures we will see next that we have problems calculating in a streaming fashion.",
                    "label": 0
                },
                {
                    "sent": "I will save more than in the next slides and according to the output of the model, we can categorize measure measures to those working on the partitions on ranking sonar probabilities.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I don't want to spend a lot of time here, but just to give you an impression of the measures, so just a couple of additional notations notations, so the P is the set of the predicted labels, for instance XI and why I set of actual labels.",
                    "label": 1
                },
                {
                    "sent": "So to two common measures.",
                    "label": 0
                },
                {
                    "sent": "Is there subset accuracy or 0?",
                    "label": 0
                },
                {
                    "sent": "One last basically for multi label data.",
                    "label": 0
                },
                {
                    "sent": "So this is a strict measure that.",
                    "label": 0
                },
                {
                    "sent": "Penalizes predictions that are not entirely correct and as expected.",
                    "label": 0
                },
                {
                    "sent": "And they penalize hard this kind of predictions.",
                    "label": 1
                },
                {
                    "sent": "How many glosser is another common measure with just calculates the differences between the two sets, the predicate and the actual label.",
                    "label": 0
                },
                {
                    "sent": "The set of labels, how different they are.",
                    "label": 0
                },
                {
                    "sent": "And we have also other measures.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measures are inspired from information retrieval.",
                    "label": 0
                },
                {
                    "sent": "So we have a precision recall and F1 measure calculated that the prepaids example.",
                    "label": 0
                },
                {
                    "sent": "There is of course some issues here.",
                    "label": 0
                },
                {
                    "sent": "As for example, what happens if the prediction settle?",
                    "label": 0
                },
                {
                    "sent": "The relevant set is empty, then we might run some into some problems, defining precision and recall.",
                    "label": 0
                },
                {
                    "sent": "And then and then they mean, of course.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As far as the ranking measures are concerned, we have measures like 1 error that evaluates how many times the Top Rank label is not in the set of relevant labels of the example.",
                    "label": 0
                },
                {
                    "sent": "Cover, it's that the value is how many steps we have to go down to the ranking list of labels to find all relevant.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Payments.",
                    "label": 0
                },
                {
                    "sent": "And perhaps one most commonly used is the ranking loss.",
                    "label": 1
                },
                {
                    "sent": "With the.",
                    "label": 0
                },
                {
                    "sent": "For each pair of labels Landley and Lundeby.",
                    "label": 1
                },
                {
                    "sent": "Where land lay is a relevant label in London Visa Irrelevant label for, for example, it counts how many times at Spurs have the wrong ranking, so Despite that.",
                    "label": 1
                },
                {
                    "sent": "Lambda busy, relevant.",
                    "label": 0
                },
                {
                    "sent": "It is higher in the ranking from Lambda.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now label based measures.",
                    "label": 0
                },
                {
                    "sent": "We can basically calculate any measure that.",
                    "label": 0
                },
                {
                    "sent": "Exists for binary classification and then somehow aggregate the results so there are two ways to do this aggregation.",
                    "label": 0
                },
                {
                    "sent": "One is called micro averaging where this is just the mean of the of the binary measure overall labels.",
                    "label": 0
                },
                {
                    "sent": "And my collaborating with the.",
                    "label": 0
                },
                {
                    "sent": "Put chosen on labels into, let's say one big metal label and computes the metric ones.",
                    "label": 0
                },
                {
                    "sent": "My Provident treats all labels are equally why Microgrids Inc favors.",
                    "label": 0
                },
                {
                    "sent": "Frequent labels, so this is something to have in mind.",
                    "label": 0
                },
                {
                    "sent": "Depending on the application.",
                    "label": 0
                },
                {
                    "sent": "Which measure we would like to use?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, as we said, we have the probabilities, we can have probability.",
                    "label": 0
                },
                {
                    "sent": "So depending on when we have this kind of output we can obtain every partition.",
                    "label": 0
                },
                {
                    "sent": "As I said through thresholding and then use ordinary example or label based binary measures.",
                    "label": 0
                },
                {
                    "sent": "If we solve ties in probabilities, we can obtain a ranking and then apply the example based ranking measures.",
                    "label": 0
                },
                {
                    "sent": "We could compute also vertical ranking, so ranking of the objects.",
                    "label": 0
                },
                {
                    "sent": "And this this is of course what we want to do in information retrieval applications, But this is also the case where we have problems.",
                    "label": 0
                },
                {
                    "sent": "If we want to calculate this in a streaming fashion so.",
                    "label": 0
                },
                {
                    "sent": "You cannot because you need to have the objects ordered.",
                    "label": 0
                },
                {
                    "sent": "You cannot wait forever.",
                    "label": 0
                },
                {
                    "sent": "Maybe you could calculate such metrics over moving window for example, but it's not the same.",
                    "label": 0
                },
                {
                    "sent": "And of course the same calls for a stressful independent evaluation like area under a rock or PR curve which need also to sort the objects.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we're continue with some very basic approaches, and it is this kind of approaches that have been used in a data stream setting, so This is why I will mention.",
                    "label": 1
                },
                {
                    "sent": "To help our discussion next.",
                    "label": 0
                },
                {
                    "sent": "So when we talk about multi label learning algorithms we usually.",
                    "label": 0
                },
                {
                    "sent": "Categorize them into.",
                    "label": 0
                },
                {
                    "sent": "Groups their problem transformation algorithms that basically take them out, label data and problem and transform it into one or more single label or.",
                    "label": 0
                },
                {
                    "sent": "Classification regression problems.",
                    "label": 0
                },
                {
                    "sent": "And then we have the algorithms adaptation methods that take a particular belief and adapt it so that it can directly work with multi label data.",
                    "label": 0
                },
                {
                    "sent": "So we will discuss such algorithms that have been used in streaming settings.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So by now, relevance is a very basic, but yet still strong baseline approach in multi label learning kits.",
                    "label": 0
                },
                {
                    "sent": "Equal to the one versus rest approach in multiclass classification.",
                    "label": 0
                },
                {
                    "sent": "So what we do is learn one binary classifier for its label.",
                    "label": 1
                },
                {
                    "sent": "OK, so for example, if we have this data set with four examples and four labels.",
                    "label": 1
                },
                {
                    "sent": "We create as many datasets as the labels and learn a binary model for each one of them.",
                    "label": 0
                },
                {
                    "sent": "Its complexity is linear with respect to their labels and the number of examples, but its main limitation that also criticizes the criticism of this method is that it does not take into consideration potential correlations between labels, and this is basically one of the main goals in multi label learning.",
                    "label": 0
                },
                {
                    "sent": "How to take into account set dependence and improve their results.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A second basic method is a.",
                    "label": 0
                },
                {
                    "sent": "The label Powerset method, as it's often called so this basically transforms the multi label data into a multiclass.",
                    "label": 0
                },
                {
                    "sent": "Single label classification problem.",
                    "label": 0
                },
                {
                    "sent": "So you see here for example.",
                    "label": 0
                },
                {
                    "sent": "Again we have the same data set and we construct a new data set to where we have just one class and the class values are basically the different combinations that appear in the training set, so.",
                    "label": 0
                },
                {
                    "sent": "Here is just a binary representation of this combination, Lambda one and Lambda four and so.",
                    "label": 0
                },
                {
                    "sent": "So we have four different combinations for different classes, and we learn a single label as an ordinary classification and multiclass classification.",
                    "label": 0
                },
                {
                    "sent": "What is the problem with this?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Type of approach.",
                    "label": 0
                },
                {
                    "sent": "The problem is that this number of different classes can become very large, so it is upper bounded by the number of.",
                    "label": 1
                },
                {
                    "sent": "Examples or the number of possible combinations, so M or two to the power of Q.",
                    "label": 1
                },
                {
                    "sent": "And it's usually much smaller in practice, but we still larger than Q we can.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See here.",
                    "label": 0
                },
                {
                    "sent": "And some datasets.",
                    "label": 0
                },
                {
                    "sent": "Commonly used the number of examples, the number of labels and you see that typically, unless we have very very small number of labels, like in this case which is 6, then the bound is equal to the two to the power of 6.",
                    "label": 0
                },
                {
                    "sent": "But in there in the rest of the cases.",
                    "label": 0
                },
                {
                    "sent": "The bond is equal to the number of examples.",
                    "label": 0
                },
                {
                    "sent": "Now the actual label sets.",
                    "label": 0
                },
                {
                    "sent": "As more are smaller than that as I said, but still quite lads and you can see that in some datasets like this music data set that has a 600.",
                    "label": 0
                },
                {
                    "sent": "Approximately labels.",
                    "label": 0
                },
                {
                    "sent": "The number of different combinations is almost equal to the number of.",
                    "label": 0
                },
                {
                    "sent": "Example, so it's in it's example.",
                    "label": 0
                },
                {
                    "sent": "We see a different combination, so it's like we are trying then to learn a multiclass problem with 32,000 classes.",
                    "label": 0
                },
                {
                    "sent": "And that's not the only problem.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we have only one example from each one of these.",
                    "label": 0
                },
                {
                    "sent": "Us so.",
                    "label": 0
                },
                {
                    "sent": "If we see also if we focus on one of these datasets, the medium a data set to discuss.",
                    "label": 0
                },
                {
                    "sent": "6500 approximately labels it.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the.",
                    "label": 0
                },
                {
                    "sent": "Here we see a log log graph of the appearances of the.",
                    "label": 0
                },
                {
                    "sent": "Or feeds of their label set.",
                    "label": 0
                },
                {
                    "sent": "So we see that from this 6500 labels it's 4000 here 4000 appear only once, so they are associated with just one example.",
                    "label": 0
                },
                {
                    "sent": "And the 895.",
                    "label": 0
                },
                {
                    "sent": "Label says from this 6500 appear only twice have only two examples, so.",
                    "label": 0
                },
                {
                    "sent": "Really, this is the problem that you can not learn from so many few, so the social examples paper class.",
                    "label": 0
                },
                {
                    "sent": "Apart from that.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It has another problem that also is relevant to the streaming setting that it cannot predict answered label set, so it learns to predict only those labels that has it has seen in the training set.",
                    "label": 1
                },
                {
                    "sent": "So when you have a stream of.",
                    "label": 0
                },
                {
                    "sent": "Since later you imagine that new combinations will appear, and so that's an approach should be somehow adapted to handles this appearance of new labels.",
                    "label": 0
                },
                {
                    "sent": "They had their.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's been some work that improves with basic approach.",
                    "label": 0
                },
                {
                    "sent": "This is the proof sets approached by Riddle.",
                    "label": 0
                },
                {
                    "sent": "And it has also been used in a streaming set setting.",
                    "label": 0
                },
                {
                    "sent": "That's why I'm presenting it.",
                    "label": 0
                },
                {
                    "sent": "So what this does too?",
                    "label": 0
                },
                {
                    "sent": "And deal with the problems of the label Parset method is that it prunes those infrequent labels.",
                    "label": 0
                },
                {
                    "sent": "It's so it runs away combinations that are.",
                    "label": 0
                },
                {
                    "sent": "Very rare at introduces the examples that are so associated with those rare label sets, but it introduces them with.",
                    "label": 0
                },
                {
                    "sent": "Frequent subsets of these labels, so this is done with two strategies with and we can see an exam.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're back to this.",
                    "label": 0
                },
                {
                    "sent": "Example with four labels and you can see the different label sets that exist now in a new different data set and these are sorted by frequency.",
                    "label": 0
                },
                {
                    "sent": "So they are going has a parameter P. And it proves away.",
                    "label": 0
                },
                {
                    "sent": "All labels said that are rarer than this parameter, so they lost.",
                    "label": 0
                },
                {
                    "sent": "My nation will be pruned away.",
                    "label": 0
                },
                {
                    "sent": "But the this information the instance language based information must be introduced.",
                    "label": 0
                },
                {
                    "sent": "By assigning this examples to labels of subsets of these labels that are frequent.",
                    "label": 0
                },
                {
                    "sent": "So let's see all these subsets of this.",
                    "label": 0
                },
                {
                    "sent": "Rare labels it.",
                    "label": 0
                },
                {
                    "sent": "Basically it's Lambda two Lambda free Land Lander, one Lambda 2.",
                    "label": 0
                },
                {
                    "sent": "And with one strategy it sorts this.",
                    "label": 0
                },
                {
                    "sent": "Subsets of this rare label label set according to their size.",
                    "label": 0
                },
                {
                    "sent": "So this one has two labels, size of two.",
                    "label": 0
                },
                {
                    "sent": "This has one and then Secondly sorts them by the number of examples associated with this label.",
                    "label": 0
                },
                {
                    "sent": "So 16 and then has another parameter bit and says we will keep the top two, the top be enter introduce this.",
                    "label": 0
                },
                {
                    "sent": "Examples with this now frequent label, so in order not to lose this information.",
                    "label": 0
                },
                {
                    "sent": "And with another strategy.",
                    "label": 0
                },
                {
                    "sent": "It sorts the subjects only based on size and select those that has the half size greater than a threshold, again with parameter P so it reintroduces the examples only with this label.",
                    "label": 0
                },
                {
                    "sent": "So this is how this approach works.",
                    "label": 0
                },
                {
                    "sent": "And this closes their problem.",
                    "label": 0
                },
                {
                    "sent": "Transformation type of methods.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now as far as albums adaptation methods are concerned.",
                    "label": 0
                },
                {
                    "sent": "Methods that are based on decision trees have been used for streaming data.",
                    "label": 0
                },
                {
                    "sent": "And such methods are the multi labels for Wild Label version of the C 4.5 algorithm proposed by Clearing King in 2001, where the main concept here is that we change the definition of entropy.",
                    "label": 0
                },
                {
                    "sent": "And basically just the sum of the binary entropies of the labels.",
                    "label": 0
                },
                {
                    "sent": "If you see here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But you built in this way just one tree for all labels.",
                    "label": 0
                },
                {
                    "sent": "And another.",
                    "label": 0
                },
                {
                    "sent": "Well performing approach that also follows the Decision tree para banking is the predicted clattering trees.",
                    "label": 0
                },
                {
                    "sent": "And one of the publications appearing is in Vincent Al.",
                    "label": 0
                },
                {
                    "sent": "There the main issue the main concept is this algorithm is that.",
                    "label": 0
                },
                {
                    "sent": "The best attribute in order to do the split is based on the notion of reduction of variance, and so you can.",
                    "label": 1
                },
                {
                    "sent": "Basically, if you have a data set.",
                    "label": 0
                },
                {
                    "sent": "If you are in a node in the tree and you have some data.",
                    "label": 0
                },
                {
                    "sent": "What you do is calculate the average.",
                    "label": 0
                },
                {
                    "sent": "Of the output space.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Let me know the output space there.",
                    "label": 0
                },
                {
                    "sent": "The mean of their, let's say late 01 values for all the labels and then you calculate the distance of each one of the output page of this examples.",
                    "label": 0
                },
                {
                    "sent": "Of the outer part of these examples with this mean, and of course the smaller they mean, the better the more homogeneous is the the node.",
                    "label": 0
                },
                {
                    "sent": "So this is basically them.",
                    "label": 0
                },
                {
                    "sent": "The decision tree approaches that.",
                    "label": 0
                },
                {
                    "sent": "Work with multi label data.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, closing this part of static static multi level data.",
                    "label": 0
                },
                {
                    "sent": "Just some pointers for further work for someone who is who is interested more so a survey and also an open source software that with implementations of several algorithms for data sets for you to play with.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now, what about the dynamic?",
                    "label": 0
                },
                {
                    "sent": "Multilabel data so I will give some examples of really dynamic data in meaning that we have object evolution.",
                    "label": 0
                },
                {
                    "sent": "We have also label evolution and we go well.",
                    "label": 0
                },
                {
                    "sent": "We also have database tables for examples.",
                    "label": 0
                },
                {
                    "sent": "In the code example in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "The content of the articles can be updated the categories through the labels associated to documents in Wikipedia can be updated, and of course we have new articles being added or deleted.",
                    "label": 0
                },
                {
                    "sent": "So another very interesting thing also that interests asking streaming scenarios is that there is no fixed set of categories, so users may add new category.",
                    "label": 1
                },
                {
                    "sent": "So this is quite different from the usual static multi label data where the the number of categories were there.",
                    "label": 0
                },
                {
                    "sent": "They go to fix.",
                    "label": 0
                },
                {
                    "sent": "The labels are fixed.",
                    "label": 0
                },
                {
                    "sent": "And also examples from health.",
                    "label": 0
                },
                {
                    "sent": "Where, for example, a person may be suffering from one or more diseases, and these changes as time changes.",
                    "label": 1
                },
                {
                    "sent": "So you have a database where the label civil and.",
                    "label": 0
                },
                {
                    "sent": "New diseases may appear, or we may have an outbreak of existing ones, and so.",
                    "label": 0
                },
                {
                    "sent": "So to the best of my knowledge, I haven't seen.",
                    "label": 0
                },
                {
                    "sent": "Any work on dealing with this kind of evolutions with multi label data?",
                    "label": 0
                },
                {
                    "sent": "But there is some work that we.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Focus now on concerning streaming multi label data, so this is a similar case of dynamic data.",
                    "label": 0
                },
                {
                    "sent": "So we have a stream of incoming labeled multi label examples so applications so you can imagine.",
                    "label": 0
                },
                {
                    "sent": "Here are for example emails that person tags into multiple categories.",
                    "label": 0
                },
                {
                    "sent": "We all do that.",
                    "label": 0
                },
                {
                    "sent": "A news aggregator that gathers news and also this may be tagged with different labels and then generally web to content.",
                    "label": 0
                },
                {
                    "sent": "Now in this, in this streaming scenario there of course the challenges of multi label learning remains, so we still must exploit the dependencies with between labels and we still must be must have efficient methods that scale to large number of labels.",
                    "label": 0
                },
                {
                    "sent": "But we also inherit the Italians of string learning, so we also do must do incremental learning under constraints in time and memory.",
                    "label": 1
                },
                {
                    "sent": "And of course we have to to deal with the problem of concept drift if we are discussing if we're dealing with valving.",
                    "label": 0
                },
                {
                    "sent": "Label data of course.",
                    "label": 0
                },
                {
                    "sent": "1 issue.",
                    "label": 1
                },
                {
                    "sent": "Here is, is it the notion of concept drift in multi label diarize is the same.",
                    "label": 0
                },
                {
                    "sent": "Is it different in this case?",
                    "label": 0
                },
                {
                    "sent": "So we will talk a little bit of that in the next slide and some other issues that concern us here.",
                    "label": 0
                },
                {
                    "sent": "Is how do we construct synthetic multi label data?",
                    "label": 1
                },
                {
                    "sent": "Because this is always an issue even in.",
                    "label": 0
                },
                {
                    "sent": "In less in single label, for example, within a strange with single day.",
                    "label": 0
                },
                {
                    "sent": "With simple data like single label data.",
                    "label": 0
                },
                {
                    "sent": "And of course, again, as I said, I mentioned that also before, how do we deal with an open ended label space?",
                    "label": 0
                },
                {
                    "sent": "So we might have a stream of objects and no other evolution, but still, the label space might be evolving.",
                    "label": 0
                },
                {
                    "sent": "So how do we also deal with that?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now as far as a concept is concern in single label data in classification data we can say for example that the class priors might change overtime.",
                    "label": 1
                },
                {
                    "sent": "All the way they classes.",
                    "label": 0
                },
                {
                    "sent": "Let's say genetically examples also changes overtime, so the meaning of the concepts also change overtime.",
                    "label": 0
                },
                {
                    "sent": "So what does it?",
                    "label": 0
                },
                {
                    "sent": "What does conservative mean in multi label data?",
                    "label": 0
                },
                {
                    "sent": "We may say we may look at it from the.",
                    "label": 0
                },
                {
                    "sent": "Label part from their lip from the side of the labels and we can say that OK label priors also change overtime, but.",
                    "label": 0
                },
                {
                    "sent": "There is a cut here to so that does all this do all these prior change at the same time?",
                    "label": 1
                },
                {
                    "sent": "OK, this is an assumption often made in some of the.",
                    "label": 0
                },
                {
                    "sent": "Approach is presented in variables.",
                    "label": 0
                },
                {
                    "sent": "And then what about the combinations of labels the label set priors?",
                    "label": 0
                },
                {
                    "sent": "OK, this may also change overtime.",
                    "label": 0
                },
                {
                    "sent": "And the connection of the label sets with the data, which might also send, so it's a bit more complex and we have to take into account also this.",
                    "label": 0
                },
                {
                    "sent": "These issues instead of just simply saying OK Multi label data, we just have changes in their labels.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the major issues here is how to create synthetic data.",
                    "label": 0
                },
                {
                    "sent": "Synthetic label data streams.",
                    "label": 0
                },
                {
                    "sent": "So what I would say, then we'll ask the question, why not use a real world data?",
                    "label": 1
                },
                {
                    "sent": "And that's all there is, because there aren't any available.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is unfortunately true, with one exception of the Reuters corpus volume.",
                    "label": 0
                },
                {
                    "sent": "The famous Reuters tax data set.",
                    "label": 0
                },
                {
                    "sent": "That has timestamps and this kind of.",
                    "label": 0
                },
                {
                    "sent": "A stream limited stream.",
                    "label": 0
                },
                {
                    "sent": "But there's also the issues out there that at least from experiments that we have seen that there is no limit on some major concept Riddler.",
                    "label": 0
                },
                {
                    "sent": "So going back to the that, there are not any data set available then one could say then why do we deal with this problem?",
                    "label": 0
                },
                {
                    "sent": "OK, so if there are no real world data then why do you?",
                    "label": 0
                },
                {
                    "sent": "Have to do work on this, but well, they think that's partly true in many problems, but the truth here is that it's very difficult to obtain.",
                    "label": 0
                },
                {
                    "sent": "World stream data.",
                    "label": 0
                },
                {
                    "sent": "The 1st place and also multi label String Theta is even harder so this may require access to operational systems and the tweaking.",
                    "label": 1
                },
                {
                    "sent": "This may involve sensitive data and in fact I was discussing in last year's a female katebe conference with George Foreman from here Packard Labs and he has some very nice streaming multi label text data from the customer center and OK at least.",
                    "label": 0
                },
                {
                    "sent": "I told him let's make a contest that silence.",
                    "label": 0
                },
                {
                    "sent": "Let's organize that silence around this and.",
                    "label": 0
                },
                {
                    "sent": "See you with my label method.",
                    "label": 0
                },
                {
                    "sent": "Works well and so on, but he told me immediately that there are so many legal issues that we cannot get ahold of such data, so these are some reasons why real world not labeled letter not available.",
                    "label": 0
                },
                {
                    "sent": "And of course, if you find real world data then what is concept drift in this data?",
                    "label": 1
                },
                {
                    "sent": "So you may need a domain expert to explain where that risk happens and what exactly it means.",
                    "label": 0
                },
                {
                    "sent": "OK, so some issues to consider here.",
                    "label": 1
                },
                {
                    "sent": "From based on existing care work is that we have to ensure that the priorities of the labels and the dependencies between the labels.",
                    "label": 0
                },
                {
                    "sent": "Follow that of real world multilabel data.",
                    "label": 0
                },
                {
                    "sent": "And also we have of course to simulate concept drift whatever this means.",
                    "label": 0
                },
                {
                    "sent": "As we said earlier.",
                    "label": 0
                },
                {
                    "sent": "So let's take a look of.",
                    "label": 0
                },
                {
                    "sent": "The label prior so insane.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "State diaper.",
                    "label": 0
                },
                {
                    "sent": "So here I have two datasets, the call 500 data set is a music data set and the medium is a video data set.",
                    "label": 0
                },
                {
                    "sent": "Call 500 + 374 labels on average.",
                    "label": 0
                },
                {
                    "sent": "26 for example, and 500 examples and maybe only has 101 labels for another reason.",
                    "label": 0
                },
                {
                    "sent": "Approximately 44,000 examples.",
                    "label": 0
                },
                {
                    "sent": "And you see here.",
                    "label": 0
                },
                {
                    "sent": "The distribution of the label Priors, which follows a kind of power law, so we have most of the label labels are really, really rare.",
                    "label": 0
                },
                {
                    "sent": "So it's below 0.1 frequency.",
                    "label": 0
                },
                {
                    "sent": "But you also have somewhere.",
                    "label": 0
                },
                {
                    "sent": "Maybe one with a high frequency and the same approximately the same.",
                    "label": 0
                },
                {
                    "sent": "We notice here in medium.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And another two datasets.",
                    "label": 0
                },
                {
                    "sent": "East is a biological.",
                    "label": 0
                },
                {
                    "sent": "Data set with a few number of labels and we here we here notice that the distribution is slightly different, but in the end run textual data we see again that it has the same behavior.",
                    "label": 0
                },
                {
                    "sent": "So most most of the labels are rare.",
                    "label": 0
                },
                {
                    "sent": "Yes, when there are some.",
                    "label": 0
                },
                {
                    "sent": "More frequently, one, so let's see now what the existing work of generating synthetic multi label data has done so far.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of the approaches is that of Q ET al.",
                    "label": 0
                },
                {
                    "sent": "There's an machine learning conference in 2009, So what they did there?",
                    "label": 0
                },
                {
                    "sent": "They in order to introduce concept drift.",
                    "label": 0
                },
                {
                    "sent": "They use the ideas that exist in single name label streams.",
                    "label": 0
                },
                {
                    "sent": "So there we have a moving hyperplane to define changing binary concept.",
                    "label": 0
                },
                {
                    "sent": "So now we have one moving hyperplane per label, yes but OK.",
                    "label": 1
                },
                {
                    "sent": "But this means that all labels drift simultaneously then so is this realistic?",
                    "label": 1
                },
                {
                    "sent": "Is this what happens?",
                    "label": 0
                },
                {
                    "sent": "We expect to happening in real world model labeled data streams, some labels matrix, some others may not.",
                    "label": 1
                },
                {
                    "sent": "You could set a different speed of drift to to simulate this.",
                    "label": 0
                },
                {
                    "sent": "This was not done by the by the authors of course, and another issue is that the label priors that they used.",
                    "label": 0
                },
                {
                    "sent": "It was Zero point 5 for all labels, so again something really different.",
                    "label": 0
                },
                {
                    "sent": "And something that should be taken care of in each user works.",
                    "label": 0
                },
                {
                    "sent": "This means that the average number of labels, for example, would be.",
                    "label": 1
                },
                {
                    "sent": "Two, the number of labels divided by two, so half of the half of the labels, which is as we said in real world data as we saw before, it's quite unrealistic.",
                    "label": 0
                },
                {
                    "sent": "And how did they introduce label dependencies?",
                    "label": 0
                },
                {
                    "sent": "Basically, this was quite an ad hoc approach that does not scale.",
                    "label": 0
                },
                {
                    "sent": "Manual introduction of this depends if this dependence just for for labels.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A more advanced approach.",
                    "label": 0
                },
                {
                    "sent": "Is that a very little and 2010?",
                    "label": 1
                },
                {
                    "sent": "So there they did something better with the label priors.",
                    "label": 0
                },
                {
                    "sent": "So we have a parameter said that controls the average number of labels bearing samples for example.",
                    "label": 1
                },
                {
                    "sent": "So this could be set.",
                    "label": 0
                },
                {
                    "sent": "Do a number that is small with respect to the number of labels.",
                    "label": 0
                },
                {
                    "sent": "As we usually notice in real world data.",
                    "label": 0
                },
                {
                    "sent": "But label priors this time was they were assigned randomly and then scaled to.",
                    "label": 0
                },
                {
                    "sent": "Scale based on this red parameter scale too.",
                    "label": 0
                },
                {
                    "sent": "Comply with that parameter, but again, this this would make a distribution different from what we have seen in before in the real world data.",
                    "label": 0
                },
                {
                    "sent": "But still it's a step forward.",
                    "label": 0
                },
                {
                    "sent": "In terms of dependencies.",
                    "label": 1
                },
                {
                    "sent": "They create a cube IQ probability matrix.",
                    "label": 0
                },
                {
                    "sent": "So in the beginning they just.",
                    "label": 0
                },
                {
                    "sent": "Consider that all labels are independent from each other, and we're talking about unconditional dependence and independence, so we're not looking at the input space as the labels.",
                    "label": 1
                },
                {
                    "sent": "And they overwrite some of these.",
                    "label": 0
                },
                {
                    "sent": "Values to introduce dependencies, so this OK simulates somehow the dependencies we see in real world data, and then they use the bicycle to fit to fill in the rest of the matrix.",
                    "label": 1
                },
                {
                    "sent": "So what is the idea?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main idea to how to create them?",
                    "label": 0
                },
                {
                    "sent": "The synthetic data set.",
                    "label": 0
                },
                {
                    "sent": "It's actually basically, it actually is just a single binary.",
                    "label": 0
                },
                {
                    "sent": "Then later, for binary classification problems underneath.",
                    "label": 0
                },
                {
                    "sent": "And how does it work?",
                    "label": 0
                },
                {
                    "sent": "The main idea is that labels and combinations of labels and labels that they are affected by one or more of the features, that is the basic idea.",
                    "label": 1
                },
                {
                    "sent": "And how do they do that?",
                    "label": 1
                },
                {
                    "sent": "They have an attribute mapping function.",
                    "label": 0
                },
                {
                    "sent": "That Maps attributes.",
                    "label": 0
                },
                {
                    "sent": "Two, the 2 / 2 most probably subsets of labels according to the probability to the prior probability.",
                    "label": 0
                },
                {
                    "sent": "The probability matrix they define.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, the idea is of course very nice, but one issue that we must consider is that this number of subsets is very small.",
                    "label": 0
                },
                {
                    "sent": "So as we say, as we saw in the label Powersets approach, they combine the different combinations are usually.",
                    "label": 1
                },
                {
                    "sent": "Too many, not half of the labels, so this approach kind of favors more.",
                    "label": 0
                },
                {
                    "sent": "The prune sets approach that proves this.",
                    "label": 0
                },
                {
                    "sent": "And infrequent labels like so.",
                    "label": 0
                },
                {
                    "sent": "And it's not that realistic in the sense.",
                    "label": 0
                },
                {
                    "sent": "We don't see so few label sets in real world data.",
                    "label": 0
                },
                {
                    "sent": "OK, so then how does it work?",
                    "label": 0
                },
                {
                    "sent": "First label is selected based on the prior probabilities and then more labels may be added may be added or not according to the matrix of the probability with the dependency probabilities.",
                    "label": 1
                },
                {
                    "sent": "Then they generate one positive and one negative example from the single label binary generator that I told you.",
                    "label": 0
                },
                {
                    "sent": "Then this is just a parameter of this method.",
                    "label": 0
                },
                {
                    "sent": "You can use any generator that you would like for binary problems.",
                    "label": 0
                },
                {
                    "sent": "And then for it's for.",
                    "label": 0
                },
                {
                    "sent": "It's one of the features.",
                    "label": 0
                },
                {
                    "sent": "If it affects the this combination or a subset of this combination according to the mapping function, then we add the positive example or the value of the positive example or the value of the negative one.",
                    "label": 1
                },
                {
                    "sent": "So let's see that.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This with an example.",
                    "label": 0
                },
                {
                    "sent": "So here we have a 5 features.",
                    "label": 0
                },
                {
                    "sent": "X165.",
                    "label": 0
                },
                {
                    "sent": "We have how many labels?",
                    "label": 0
                },
                {
                    "sent": "How many combinations?",
                    "label": 0
                },
                {
                    "sent": "We have four combinations of labels, Lambda, one Lambda, two Lambda, three and this one.",
                    "label": 0
                },
                {
                    "sent": "And then we start from the beginning.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the modular function they had, so if we had more features than we would see this iterate again and again.",
                    "label": 0
                },
                {
                    "sent": "And since we have four label sets, how many labels we have?",
                    "label": 0
                },
                {
                    "sent": "8 right, because we said that.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, they take the half of the number of labels, most prob.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Double subject so.",
                    "label": 0
                },
                {
                    "sent": "Since we have four subsets, this means that we have four labels, 8 labels, but we only see three of these labels.",
                    "label": 0
                },
                {
                    "sent": "Now we create the the new combination of labels based on the priors and the dependence matrix.",
                    "label": 0
                },
                {
                    "sent": "This is the new label combinations, combinational Lambda one Lambda 3L1L3 here.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "We notice that for the 1st.",
                    "label": 0
                },
                {
                    "sent": "Attribute.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Combine nation, OK, single label.",
                    "label": 0
                },
                {
                    "sent": "But this is also a subset of the label, so it's acceptable.",
                    "label": 0
                },
                {
                    "sent": "We see that it is a subset of this one, so this means that this since this feature affects this label, social effects this combination.",
                    "label": 0
                },
                {
                    "sent": "So This is why we take the value of the positive example input here in the synthetic data.",
                    "label": 0
                },
                {
                    "sent": "Inventory space office.",
                    "label": 0
                },
                {
                    "sent": "Here we see a two and this is not here, so we take the value of the negative example and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is how this approach.",
                    "label": 0
                },
                {
                    "sent": "This Nobel approach offering that all works.",
                    "label": 0
                },
                {
                    "sent": "So what about concentrate?",
                    "label": 0
                },
                {
                    "sent": "Where the user ideas from.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "From single label streams, basically so they have already developed an approach for.",
                    "label": 0
                },
                {
                    "sent": "A creating custom drift by mixing different single label streams and the same can be applied.",
                    "label": 0
                },
                {
                    "sent": "Of course for multi label streams.",
                    "label": 0
                },
                {
                    "sent": "But again, what is the cats here?",
                    "label": 0
                },
                {
                    "sent": "That this means that.",
                    "label": 0
                },
                {
                    "sent": "All labels will drift simultaneously and again.",
                    "label": 1
                },
                {
                    "sent": "Is that something that we expect in a realistic model able data stream?",
                    "label": 0
                },
                {
                    "sent": "Probably not.",
                    "label": 0
                },
                {
                    "sent": "And there is there.",
                    "label": 0
                },
                {
                    "sent": "These are two different must be labeled streams, totally different.",
                    "label": 0
                },
                {
                    "sent": "We expect the change would be quite radical.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that that was all about how to create synthetic multi label data.",
                    "label": 0
                },
                {
                    "sent": "Basically we have these two up two main approaches and this is still an ongoing area.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "What about learning approaches?",
                    "label": 0
                },
                {
                    "sent": "The OK we have created the OR we have them streams of my label data.",
                    "label": 0
                },
                {
                    "sent": "How do we learn?",
                    "label": 0
                },
                {
                    "sent": "There is of course a lot of work on online learning and machine learning community, and we could apply that to strings, but we should also in addition.",
                    "label": 0
                },
                {
                    "sent": "Sam thanks Ronald before adapting to drift and there is also.",
                    "label": 0
                },
                {
                    "sent": "There's also a few works on directly working on Multi label data streams, so let's see.",
                    "label": 0
                },
                {
                    "sent": "Did I say a few words about?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one A1 online learning algorithm from 2003 that does ranking.",
                    "label": 0
                },
                {
                    "sent": "It doesn't output since the math class multilayer perceptron algorithm by cramming Seager so this one maintains one linear perceptron per label, and the weights get updated when the ranking that is output by the by the perceptrons is wrong.",
                    "label": 1
                },
                {
                    "sent": "And then according to the magnet they according to how many labels are ranked higher.",
                    "label": 1
                },
                {
                    "sent": "How many positive labels are ranked higher than negative labels and the opposite the magnitude of change is according to that.",
                    "label": 0
                },
                {
                    "sent": "And it also further depends on the what the actual loss was.",
                    "label": 1
                },
                {
                    "sent": "So typical losses here used.",
                    "label": 1
                },
                {
                    "sent": "Is there like the ranking close that we saw earlier at the beginning of the presentation?",
                    "label": 0
                },
                {
                    "sent": "So things to point out for this algorithm is that it has if it performs better, it does better ranking compared to the binary relevance.",
                    "label": 0
                },
                {
                    "sent": "The simple independent approach, it is linear with respect to the number of labels.",
                    "label": 0
                },
                {
                    "sent": "But as I said, it cannot output partitions it it should.",
                    "label": 0
                },
                {
                    "sent": "It would require some kind of restaurant service coding mechanism and probably one that adapts also that is also online.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some additional points that they interest.",
                    "label": 1
                },
                {
                    "sent": "Asking this in the streaming scenario multi level data.",
                    "label": 0
                },
                {
                    "sent": "It is that it can take into account new label.",
                    "label": 0
                },
                {
                    "sent": "So for example, when a new label appears, we could just initialize the new person.",
                    "label": 1
                },
                {
                    "sent": "So this is not something.",
                    "label": 0
                },
                {
                    "sent": "Examined by the authors, but I'm just the.",
                    "label": 0
                },
                {
                    "sent": "Discussing this opportunity here.",
                    "label": 0
                },
                {
                    "sent": "Of course, there is no explicit causative handling, but however it could serve as a strong baseline in papers presenting multilabel data, stream algorithm and of course there are also some extensions that bring better performance, some pairwise approaches but to the expense of quadratic complexity with respect to the number of labels.",
                    "label": 1
                },
                {
                    "sent": "So I'm not saying anything more on that.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one of the first.",
                    "label": 0
                },
                {
                    "sent": "Papers discussing directly.",
                    "label": 0
                },
                {
                    "sent": "Label data streams.",
                    "label": 0
                },
                {
                    "sent": "Was that Q ET al approach this the same that we show before that also had an approach to create synthetic data.",
                    "label": 0
                },
                {
                    "sent": "So how does it?",
                    "label": 0
                },
                {
                    "sent": "How does it work?",
                    "label": 0
                },
                {
                    "sent": "It partition the strings into chunks of equal size.",
                    "label": 0
                },
                {
                    "sent": "Train multilabel classifier from it sank and keeps the last end tracks.",
                    "label": 0
                },
                {
                    "sent": "So, given a new instance, it finds the game nearest neighbors in the latest in the latest rank, it computes the accuracy of the models in this nearest neighbors.",
                    "label": 0
                },
                {
                    "sent": "And they usually says I waiting await with the voting process.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical approach, followed in a static and samples.",
                    "label": 0
                },
                {
                    "sent": "So here is.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is a.",
                    "label": 0
                },
                {
                    "sent": "A paper by Zimbel Petal one year earlier.",
                    "label": 0
                },
                {
                    "sent": "I have kept the previous light and only you see in red.",
                    "label": 0
                },
                {
                    "sent": "The difference is so instead of single instead of multi level we have single label.",
                    "label": 0
                },
                {
                    "sent": "And there there, instead of keeping the delvine thanks, they keep their best and tax based on Microsoft.",
                    "label": 0
                },
                {
                    "sent": "It's basically the same algorithm.",
                    "label": 0
                },
                {
                    "sent": "And what does this?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tells us.",
                    "label": 0
                },
                {
                    "sent": "Is that basically we can use state of the art and sample methods for like the approach of symbol or one at all.",
                    "label": 0
                },
                {
                    "sent": "Anne and readily apply them to label data so we can train different models, different models, label models from different sites, and we readily can apply this approach to multi label data.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "This could be used as a baseline, and it's something that we should compare against.",
                    "label": 0
                },
                {
                    "sent": "But again, such an approach assumes that if concept drift will happen, it will happen for all labels, because when you throw away a model you throw away the complete, more complete model affecting all labels not.",
                    "label": 1
                },
                {
                    "sent": "One specific label, or a subset of the label, so again.",
                    "label": 0
                },
                {
                    "sent": "We can borrow ideas from single label data label that what we should also take into account the issues that arise in specifically in multi label data.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another approach that was recently proposed is based on the is based on the halting tree, and this is a multi label version of this tree.",
                    "label": 0
                },
                {
                    "sent": "So it combines the combines the tree of democracy and helping the carpeting.",
                    "label": 1
                },
                {
                    "sent": "And the multi label Decision Tree that I showed you in the first part of this talk and what they also do.",
                    "label": 0
                },
                {
                    "sent": "They also consider train training a model able learner at the leaves of this wedding tree, and in particular they argued for the Princess algorithm that I also showed you before.",
                    "label": 1
                },
                {
                    "sent": "So we said of course that proof sets.",
                    "label": 0
                },
                {
                    "sent": "In cats, the problems of their laborers pouched the algorithm so it cannot predict unseen labels, and it has to wait and see some labels that in order to be able to predict them.",
                    "label": 1
                },
                {
                    "sent": "So this is usually treated by having a first period of let's say N examples.",
                    "label": 0
                },
                {
                    "sent": "During which they consider only single labels and then they calculate the combination and start predicting also with kind of combinations.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In addition, read Attalla explored and sample techniques.",
                    "label": 1
                },
                {
                    "sent": "Existing assembly techniques for singulated illustrates such that they add Edwin bagging approach, so it's basically an online bagging approach that replaces model based on accuracy.",
                    "label": 1
                },
                {
                    "sent": "Whenever this there is concept drift and this is monitored by Edwin algorithm.",
                    "label": 0
                },
                {
                    "sent": "But again, here we have the same issue that all labels are causing did that.",
                    "label": 0
                },
                {
                    "sent": "They should there since we have we throw away the complete model that we have the assumption that all labels def simultaneously and this is not so realistic.",
                    "label": 0
                },
                {
                    "sent": "Another thing to point in this kind of approach and also other approaches that are based on examples.",
                    "label": 0
                },
                {
                    "sent": "Is that the?",
                    "label": 0
                },
                {
                    "sent": "If you want to, if we want to be able to output the partitions, then we somehow need to have a thresholding mechanism.",
                    "label": 0
                },
                {
                    "sent": "Becauses assemblies give us votes and this is just the then the combination of votes of their average is just an American output.",
                    "label": 0
                },
                {
                    "sent": "So you need some kind of thresholding and this thresholding needs to be also incremental.",
                    "label": 0
                },
                {
                    "sent": "So what they what they did in their approach is to incrementally update, increase or increase the threshold.",
                    "label": 0
                },
                {
                    "sent": "Based on the predicted partition, the size of the predicted partition, and what the actual one was.",
                    "label": 1
                },
                {
                    "sent": "So if the output was three labels and the.",
                    "label": 0
                },
                {
                    "sent": "The actual labels were for.",
                    "label": 0
                },
                {
                    "sent": "For example, maybe they should lower the threshold to have a better recall.",
                    "label": 0
                },
                {
                    "sent": "They lower the threshold to have better recall.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There were, they they.",
                    "label": 0
                },
                {
                    "sent": "Perform some experiments with several variations, so I don't want to.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To go into the details.",
                    "label": 0
                },
                {
                    "sent": "To save some time.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will just give you the results that compared to binary approaches and compared to the simple crafting Multi Label 3.",
                    "label": 0
                },
                {
                    "sent": "Using the process algorithm, the lips at the leaves help.",
                    "label": 0
                },
                {
                    "sent": "In real world data and also using this online bagging approach.",
                    "label": 0
                },
                {
                    "sent": "Again, having the whole thing tree and proof sets algorithm at their lives also gave the best results in terms of 1 metric at least that I show you here, but also in others they have results with more measures.",
                    "label": 0
                },
                {
                    "sent": "So this we can consider this as a state of the art method in this domain.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, quite recent method follows a different line of thinking.",
                    "label": 0
                },
                {
                    "sent": "The multiple windows approach.",
                    "label": 0
                },
                {
                    "sent": "In this years it's guy.",
                    "label": 0
                },
                {
                    "sent": "It may, it looks at it looks the problem from a binary view and basically it maintains a fixed size.",
                    "label": 0
                },
                {
                    "sent": "Moving Windows separately for its label and separately for the positive and negative examples of its label.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is done basically to deal with class imbalance.",
                    "label": 0
                },
                {
                    "sent": "That is typically as we as we as we have seen, labels are quite rare and we have a class imbalance and through you have a single window.",
                    "label": 0
                },
                {
                    "sent": "Then you are losing a lot of positive examples, so this is basically the main idea behind this this approach so it uses a KNN binary classifier on the Union of the positive and negative windows.",
                    "label": 1
                },
                {
                    "sent": "And it has a problem like any binary approach, that it ignores correlations between labels.",
                    "label": 0
                },
                {
                    "sent": "But this can be fixed by exploiting binary approaches that.",
                    "label": 0
                },
                {
                    "sent": "Benefit from defenders from dependencies like from example.",
                    "label": 0
                },
                {
                    "sent": "The sample of classifier chains approach.",
                    "label": 0
                },
                {
                    "sent": "But the benefit is that we can deal with this issue of multiple concentrates, so as we as we focus separately on its label.",
                    "label": 0
                },
                {
                    "sent": "So we can detect separately the drift at the label level.",
                    "label": 0
                },
                {
                    "sent": "And of course they get take care of a glass.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Balance.",
                    "label": 0
                },
                {
                    "sent": "A few more words on this approach that there is no training involved as it used the cane and algorithm.",
                    "label": 0
                },
                {
                    "sent": "And with every new example, it updates the positive and negative windows of its label that have a fixed size, and there's also space efficient implementation for setting examples between the positive and negative windows.",
                    "label": 1
                },
                {
                    "sent": "And the prediction involves a nearest neighbor sets of the Union of positive and negative examples of its label.",
                    "label": 0
                },
                {
                    "sent": "Again, there's an efficient implementation for this.",
                    "label": 0
                },
                {
                    "sent": "And there since we have.",
                    "label": 0
                },
                {
                    "sent": "A a number of neighbors and we get there.",
                    "label": 0
                },
                {
                    "sent": "The average of their votes.",
                    "label": 0
                },
                {
                    "sent": "Again, the output is in terms of is in America output, so we also have here.",
                    "label": 0
                },
                {
                    "sent": "Enneagram mental thresholding technique to him too in order to be able to output to be partitions.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is basically an incremental version of an existing method for static method.",
                    "label": 0
                },
                {
                    "sent": "They pick up method.",
                    "label": 0
                },
                {
                    "sent": "So what it does is that every instance is it calculates the threshold that would most accurately approximate the observed frequency within that window of that label, and then this gets updated every N instances and quite good results have been noticed with this kind of online thresholding approach.",
                    "label": 1
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, my to conclude my part.",
                    "label": 0
                },
                {
                    "sent": "We have discussed multilabel data.",
                    "label": 1
                },
                {
                    "sent": "We see that this is a such data Arabic with this and.",
                    "label": 0
                },
                {
                    "sent": "They are complex in the sense that the label space can be quite large, and of course the labels.",
                    "label": 0
                },
                {
                    "sent": "It's also.",
                    "label": 0
                },
                {
                    "sent": "And we need their techniques that exploit the structure of labels and deal scale to the large number of labels.",
                    "label": 1
                },
                {
                    "sent": "In addition, when we move to streaming environments, we notice that we need techniques for incremental learning and also.",
                    "label": 0
                },
                {
                    "sent": "We have time and memory constraints and we must deal with conservation.",
                    "label": 0
                },
                {
                    "sent": "And particularly, things that must be notice in work in this area is how to create properly the synthetic data.",
                    "label": 0
                },
                {
                    "sent": "How to adapt to the multi label version of concept drift and careful definition of this and also help you deal with class imbalance issues and also thresholding in order to obtain maybe partitions.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It would be the end to this.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Block so thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So should we have questions now, OK?",
                    "label": 0
                }
            ]
        }
    }
}