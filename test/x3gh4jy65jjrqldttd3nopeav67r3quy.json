{
    "id": "x3gh4jy65jjrqldttd3nopeav67r3quy",
    "title": "FastInf",
    "info": {
        "author": [
            "Ariel Jaimovich, School of Computer Science and Engineering, The Hebrew University of Jerusalem"
        ],
        "published": "July 20, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/icml2010_jaimovich_fast/",
    "segmentation": [
        [
            "I'll be presenting at work about efficient approximate inference.",
            "It's a library we wrote together with the author Mashian McGraw and Galilee Dan.",
            "And.",
            "I was lucky."
        ],
        [
            "Have an introduction in the previous talk about probabilistic graphical models, so I won't go over it in detail though.",
            "I'll just say we're working with a generalization that covers both Bayesian networks and Markov random fields."
        ],
        [
            "In the form of factor graphs, where in this setting each run variable is depicted as a node and each factor is this rectangle and we."
        ],
        [
            "Have a parameterisation overreach?"
        ],
        [
            "The factors and this.",
            "In our case, we think of it to the table, but it can also be generalized as the previous speaker described.",
            "And the."
        ],
        [
            "I guess why?"
        ],
        [
            "The most famous and simple graphical model is in HMM, where you have some hidden Markov process overtime and some noisy observation over it, and in this case the.",
            "The."
        ],
        [
            "So we describe it in a factor graph, where again each of these is a random variable.",
            "Each of these is a.",
            "Factor."
        ],
        [
            "Or an?"
        ],
        [
            "Sorry."
        ],
        [
            "And the transition probabilities are assigned to these factors and the emission probabilities are assigned to this factor, so this is just a language we're dealing with."
        ],
        [
            "And the popular queries in graphical models are asking about marginal probabilities over sets of variables or estimating the likelihood of some evidence and then as again was described here.",
            "You sometimes want to find the most probable set of parameters given a set of observations over your model.",
            "And.",
            "Our motivation was different from the previous talk, since we wanted to consider models over 10th and hundred thousands of variables, so exact inference is infeasible and we."
        ],
        [
            "A.",
            "Concentrating on implementing approximate inference that will be very efficient and this can be roughly divided to two methods.",
            "One is sampling such as Gibbs sampling and the other is variation approximation such as a midfield and belief propagation.",
            "And."
        ],
        [
            "Motivation?",
            "Was actually coming from biological networks as I said over thousands of nodes here.",
            "And what we look for is such kind of local structures that appear over and over in the network, and we wanted to use them in order to efficiently represent such networks.",
            "And to do that we."
        ],
        [
            "Use the very elegant language of relational probabilistic graphical models, or in this case, instead of assigning a potential function potential function to each of the factors, you just use some set small set of parameters and then assign many factors to each of the parameters.",
            "So again, if we will."
        ],
        [
            "Come back to our hmm example.",
            "Then in this case, each of the transitions will have the same table of.",
            "Transition probabilities and each of their emissions will have again the same table, so we can have a very long Markov model with only two tables, so it's a very thin model.",
            "It has very small number of parameters and you can use it over a very large space and.",
            "As I said, we wanted to do it over a huge number."
        ],
        [
            "Variables, so we concentrated on efficiency and we built it.",
            "So we used a C++ programming language and we.",
            "Invested some time in order to come up with a very efficient representation of the base classes of the model, so all the tables and factors and variables are very thin in the representation.",
            "And we went to a.",
            "Look at all the calculations that were done over and over again in belief propagation and all kinds of methods, and we invested time in order to make their code very efficient.",
            "In addition, we tried to do it the the interface of the base class is as simple as we can, and at least the base classes are well documented.",
            "So if you want to extend them, I think it is very simple.",
            "And we wanted to enable usage both through the command line or API."
        ],
        [
            "And our library concentrates of on belief propagation, so this is the most rich set of functions we implement.",
            "So you do basic belief propagation and also many.",
            "Generalized BP, which is by now not very modern but very efficient and also the more recent works of Martin Wainwright, three weighted BP and other.",
            "I am or you are approximations.",
            "We also implemented some midfielder Gibbs sampling and other basic approximate inference methods and we have parameter estimation doing a maximum likelihood.",
            "Then we can also deal with the missing missing data using the EM algorithm.",
            "And then we have a partial computation which is like as I said, better for the base classes and more sparse for the.",
            "Implementation as you can imagine."
        ],
        [
            "So just.",
            "Simple comparison between other existing libraries.",
            "So this is our library fast enough.",
            "This is Linda, which is a very nice library done by Joris Mooij from Tubingen.",
            "Infer.net, which is not open source and done by Mika and this is a from a wise group.",
            "Which is also open source.",
            "So almost everybody does look belief propagation.",
            "We also implement some methods to do exact inference and generalize BP and.",
            "As I said, our motivation was dealing with their relational models, which is not taken care of in other languages."
        ],
        [
            "So we initially build this library.",
            "As I spoke with Danielle, yeah in the break like five years ago, four years ago to deal with a protein protein interaction networks and from then it was.",
            "Slowly but growing.",
            "And there it was, being used by a couple of groups listing in our surroundings for many applications, starting from improving approximate inference, methods to protein design and private image alignment, and also for vision problems.",
            "And when we saw it was starting to being used a lot and also getting a richer set of features, we decided to make it publicly available."
        ],
        [
            "And, uh, just we're so far we tried not to implement things that are already exists, so we're using boost libraries and the new scientific libraries in the linear linear programming krikkit from new and using a GPL license.",
            "I.",
            "So."
        ],
        [
            "Give a quick demo of what how it looks like.",
            "OK. An so maybe smaller.",
            "So as a if you just type the simple command you get this usage.",
            "Message and.",
            "Now we can use.",
            "Oh sorry, so I forgot.",
            "Maybe I should begin with this, I'm sorry.",
            "So we created this home page that has a.",
            "And the the home page with their documentation.",
            "So this is just a general description and you have also.",
            "Link to download the library along with some simple installation.",
            "And the installation procedure.",
            "And there is a set of examples which you can just get a feeling of how this works.",
            "So there's a set of commands which are you can see what they do and how to run them an if you don't have the GSL and GLC installed.",
            "So here is a basically the our Makefile also downloads and install them automatically, but if you want to do it manually can do it using this instructions.",
            "We also have a documentation of the.",
            "Using doxygen and we have written a niche small description of how we think.",
            "If you want to extend our library and build GNU GNU functions, then we describe the basic things you need to implement and what is important.",
            "For if you want to implement an inference methods or learning method, what you need to do.",
            "And we also have unit tests and more comprehensive tests, and this is a description of how to run them, so everything is in the web page.",
            "And this is just an example of if you search or if you just want to run inference.",
            "So let's do it on the grid.",
            "By the way, this is.",
            "So.",
            "This is how the input looks like.",
            "It's just a set of variables and the set of factors and then a set of.",
            "Probably of parameters.",
            "And this is how the evidence look like is just a set of assignments for each.",
            "This is a 2020 assignment for each of the variables in the grid.",
            "And I'm sorry.",
            "And this is so if you just want to do inference, you do this and then you get.",
            "The.",
            "If you want to to type the.",
            "Marginal probabilities and marginal probabilities over the variables.",
            "We can also.",
            "Print The belief over the factors and then you get for each factor the marginal probability.",
            "And you can also if you want.",
            "This is run simple BP if you want to run exact inference.",
            "This does the junction tree and this computes the exact probabilities.",
            "And if you want to also assign some kind of evidence, then you can use the evidence flag and give.",
            "That evidence file.",
            "So then for each evidence, it assigns the evidence, calculates the partition and the probability of the evidence.",
            "And we also have the basic class does.",
            "Learning and this is as before, it gives you the flags that you need to use, so you can use just input and the evidence and where to use the output file, and then you can just if you want to make sure it runs OK, then it runs a derivative test when it computes the derivative empirically and compares it to what the inference does.",
            "You can add simple regularization L1 or L2.",
            "And you can do a tweak all the parameters of the.",
            "Of the parameter estimation.",
            "So just a quick.",
            "Um?",
            "So here we have a couple of so take some time to collect all the evidence and then after a couple of seconds it should.",
            "Return.",
            "Yeah, there goes.",
            "So it shows you the improvement in the log likelihood, and if you want it can also drop the model into a file and you can use it again and again.",
            "You can use all of these commands either through the command line or using the API."
        ],
        [
            "So that's it.",
            "Just want to acknowledge again so this was done under the labs of their supervision of near and Daphne Kohler.",
            "So this second half left half is people that works in the Hebrew University.",
            "Right half is in Stanford.",
            "And Gal began in our lab in Hebrew and then moved to Stanford and came back.",
            "So he's kind of in the middle.",
            "So it's a giant effort, and as I said, many peoples are.",
            "Many people are using it by now and I hope the community will also find it useful tool.",
            "So that's it.",
            "Under functions you showed it.",
            "For instance, you bite it always three variables can.",
            "I would say by 100 variables.",
            "So obviously the larger the factor will be there less efficient inference, so that the computation the cost of the inference is exponential in the size of the factor.",
            "It's possible, but it will be less sufficient.",
            "Actually we doing.",
            "You can extend both the number so we don't have use users doing it with such large number of variables.",
            "What we do have is people using on a small like in the protein design problem.",
            "You have a small number of variables, but each of them with a very large cardinality, maybe 20 or 30 possibilities.",
            "And this again is increases the difficulty but but it's working so it takes a little more time, but it works.",
            "How much, how long does it take?",
            "Would it take them 400 variables for Andrew Garments for 100 variables is very quick, but we do 100,000 variables.",
            "Then it will take.",
            "Maybe if you just do inference then around 10:15 minutes.",
            "Problems like in computer vision, image segmentation.",
            "It is being used on large that it was that the our goal in designing it.",
            "So then let's speak again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll be presenting at work about efficient approximate inference.",
                    "label": 1
                },
                {
                    "sent": "It's a library we wrote together with the author Mashian McGraw and Galilee Dan.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I was lucky.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have an introduction in the previous talk about probabilistic graphical models, so I won't go over it in detail though.",
                    "label": 0
                },
                {
                    "sent": "I'll just say we're working with a generalization that covers both Bayesian networks and Markov random fields.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the form of factor graphs, where in this setting each run variable is depicted as a node and each factor is this rectangle and we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have a parameterisation overreach?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The factors and this.",
                    "label": 0
                },
                {
                    "sent": "In our case, we think of it to the table, but it can also be generalized as the previous speaker described.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I guess why?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The most famous and simple graphical model is in HMM, where you have some hidden Markov process overtime and some noisy observation over it, and in this case the.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we describe it in a factor graph, where again each of these is a random variable.",
                    "label": 0
                },
                {
                    "sent": "Each of these is a.",
                    "label": 0
                },
                {
                    "sent": "Factor.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or an?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the transition probabilities are assigned to these factors and the emission probabilities are assigned to this factor, so this is just a language we're dealing with.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the popular queries in graphical models are asking about marginal probabilities over sets of variables or estimating the likelihood of some evidence and then as again was described here.",
                    "label": 0
                },
                {
                    "sent": "You sometimes want to find the most probable set of parameters given a set of observations over your model.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Our motivation was different from the previous talk, since we wanted to consider models over 10th and hundred thousands of variables, so exact inference is infeasible and we.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "Concentrating on implementing approximate inference that will be very efficient and this can be roughly divided to two methods.",
                    "label": 0
                },
                {
                    "sent": "One is sampling such as Gibbs sampling and the other is variation approximation such as a midfield and belief propagation.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Motivation?",
                    "label": 0
                },
                {
                    "sent": "Was actually coming from biological networks as I said over thousands of nodes here.",
                    "label": 0
                },
                {
                    "sent": "And what we look for is such kind of local structures that appear over and over in the network, and we wanted to use them in order to efficiently represent such networks.",
                    "label": 0
                },
                {
                    "sent": "And to do that we.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use the very elegant language of relational probabilistic graphical models, or in this case, instead of assigning a potential function potential function to each of the factors, you just use some set small set of parameters and then assign many factors to each of the parameters.",
                    "label": 0
                },
                {
                    "sent": "So again, if we will.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come back to our hmm example.",
                    "label": 0
                },
                {
                    "sent": "Then in this case, each of the transitions will have the same table of.",
                    "label": 0
                },
                {
                    "sent": "Transition probabilities and each of their emissions will have again the same table, so we can have a very long Markov model with only two tables, so it's a very thin model.",
                    "label": 0
                },
                {
                    "sent": "It has very small number of parameters and you can use it over a very large space and.",
                    "label": 0
                },
                {
                    "sent": "As I said, we wanted to do it over a huge number.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Variables, so we concentrated on efficiency and we built it.",
                    "label": 0
                },
                {
                    "sent": "So we used a C++ programming language and we.",
                    "label": 0
                },
                {
                    "sent": "Invested some time in order to come up with a very efficient representation of the base classes of the model, so all the tables and factors and variables are very thin in the representation.",
                    "label": 0
                },
                {
                    "sent": "And we went to a.",
                    "label": 0
                },
                {
                    "sent": "Look at all the calculations that were done over and over again in belief propagation and all kinds of methods, and we invested time in order to make their code very efficient.",
                    "label": 0
                },
                {
                    "sent": "In addition, we tried to do it the the interface of the base class is as simple as we can, and at least the base classes are well documented.",
                    "label": 1
                },
                {
                    "sent": "So if you want to extend them, I think it is very simple.",
                    "label": 1
                },
                {
                    "sent": "And we wanted to enable usage both through the command line or API.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our library concentrates of on belief propagation, so this is the most rich set of functions we implement.",
                    "label": 0
                },
                {
                    "sent": "So you do basic belief propagation and also many.",
                    "label": 0
                },
                {
                    "sent": "Generalized BP, which is by now not very modern but very efficient and also the more recent works of Martin Wainwright, three weighted BP and other.",
                    "label": 0
                },
                {
                    "sent": "I am or you are approximations.",
                    "label": 0
                },
                {
                    "sent": "We also implemented some midfielder Gibbs sampling and other basic approximate inference methods and we have parameter estimation doing a maximum likelihood.",
                    "label": 1
                },
                {
                    "sent": "Then we can also deal with the missing missing data using the EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then we have a partial computation which is like as I said, better for the base classes and more sparse for the.",
                    "label": 0
                },
                {
                    "sent": "Implementation as you can imagine.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just.",
                    "label": 0
                },
                {
                    "sent": "Simple comparison between other existing libraries.",
                    "label": 0
                },
                {
                    "sent": "So this is our library fast enough.",
                    "label": 0
                },
                {
                    "sent": "This is Linda, which is a very nice library done by Joris Mooij from Tubingen.",
                    "label": 0
                },
                {
                    "sent": "Infer.net, which is not open source and done by Mika and this is a from a wise group.",
                    "label": 0
                },
                {
                    "sent": "Which is also open source.",
                    "label": 0
                },
                {
                    "sent": "So almost everybody does look belief propagation.",
                    "label": 0
                },
                {
                    "sent": "We also implement some methods to do exact inference and generalize BP and.",
                    "label": 0
                },
                {
                    "sent": "As I said, our motivation was dealing with their relational models, which is not taken care of in other languages.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we initially build this library.",
                    "label": 0
                },
                {
                    "sent": "As I spoke with Danielle, yeah in the break like five years ago, four years ago to deal with a protein protein interaction networks and from then it was.",
                    "label": 0
                },
                {
                    "sent": "Slowly but growing.",
                    "label": 0
                },
                {
                    "sent": "And there it was, being used by a couple of groups listing in our surroundings for many applications, starting from improving approximate inference, methods to protein design and private image alignment, and also for vision problems.",
                    "label": 1
                },
                {
                    "sent": "And when we saw it was starting to being used a lot and also getting a richer set of features, we decided to make it publicly available.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And, uh, just we're so far we tried not to implement things that are already exists, so we're using boost libraries and the new scientific libraries in the linear linear programming krikkit from new and using a GPL license.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give a quick demo of what how it looks like.",
                    "label": 0
                },
                {
                    "sent": "OK. An so maybe smaller.",
                    "label": 0
                },
                {
                    "sent": "So as a if you just type the simple command you get this usage.",
                    "label": 0
                },
                {
                    "sent": "Message and.",
                    "label": 0
                },
                {
                    "sent": "Now we can use.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, so I forgot.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should begin with this, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "So we created this home page that has a.",
                    "label": 0
                },
                {
                    "sent": "And the the home page with their documentation.",
                    "label": 0
                },
                {
                    "sent": "So this is just a general description and you have also.",
                    "label": 0
                },
                {
                    "sent": "Link to download the library along with some simple installation.",
                    "label": 0
                },
                {
                    "sent": "And the installation procedure.",
                    "label": 0
                },
                {
                    "sent": "And there is a set of examples which you can just get a feeling of how this works.",
                    "label": 0
                },
                {
                    "sent": "So there's a set of commands which are you can see what they do and how to run them an if you don't have the GSL and GLC installed.",
                    "label": 0
                },
                {
                    "sent": "So here is a basically the our Makefile also downloads and install them automatically, but if you want to do it manually can do it using this instructions.",
                    "label": 0
                },
                {
                    "sent": "We also have a documentation of the.",
                    "label": 0
                },
                {
                    "sent": "Using doxygen and we have written a niche small description of how we think.",
                    "label": 0
                },
                {
                    "sent": "If you want to extend our library and build GNU GNU functions, then we describe the basic things you need to implement and what is important.",
                    "label": 0
                },
                {
                    "sent": "For if you want to implement an inference methods or learning method, what you need to do.",
                    "label": 0
                },
                {
                    "sent": "And we also have unit tests and more comprehensive tests, and this is a description of how to run them, so everything is in the web page.",
                    "label": 0
                },
                {
                    "sent": "And this is just an example of if you search or if you just want to run inference.",
                    "label": 0
                },
                {
                    "sent": "So let's do it on the grid.",
                    "label": 0
                },
                {
                    "sent": "By the way, this is.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is how the input looks like.",
                    "label": 0
                },
                {
                    "sent": "It's just a set of variables and the set of factors and then a set of.",
                    "label": 0
                },
                {
                    "sent": "Probably of parameters.",
                    "label": 0
                },
                {
                    "sent": "And this is how the evidence look like is just a set of assignments for each.",
                    "label": 0
                },
                {
                    "sent": "This is a 2020 assignment for each of the variables in the grid.",
                    "label": 0
                },
                {
                    "sent": "And I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "And this is so if you just want to do inference, you do this and then you get.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "If you want to to type the.",
                    "label": 0
                },
                {
                    "sent": "Marginal probabilities and marginal probabilities over the variables.",
                    "label": 0
                },
                {
                    "sent": "We can also.",
                    "label": 0
                },
                {
                    "sent": "Print The belief over the factors and then you get for each factor the marginal probability.",
                    "label": 0
                },
                {
                    "sent": "And you can also if you want.",
                    "label": 0
                },
                {
                    "sent": "This is run simple BP if you want to run exact inference.",
                    "label": 0
                },
                {
                    "sent": "This does the junction tree and this computes the exact probabilities.",
                    "label": 0
                },
                {
                    "sent": "And if you want to also assign some kind of evidence, then you can use the evidence flag and give.",
                    "label": 0
                },
                {
                    "sent": "That evidence file.",
                    "label": 0
                },
                {
                    "sent": "So then for each evidence, it assigns the evidence, calculates the partition and the probability of the evidence.",
                    "label": 0
                },
                {
                    "sent": "And we also have the basic class does.",
                    "label": 0
                },
                {
                    "sent": "Learning and this is as before, it gives you the flags that you need to use, so you can use just input and the evidence and where to use the output file, and then you can just if you want to make sure it runs OK, then it runs a derivative test when it computes the derivative empirically and compares it to what the inference does.",
                    "label": 0
                },
                {
                    "sent": "You can add simple regularization L1 or L2.",
                    "label": 0
                },
                {
                    "sent": "And you can do a tweak all the parameters of the.",
                    "label": 0
                },
                {
                    "sent": "Of the parameter estimation.",
                    "label": 0
                },
                {
                    "sent": "So just a quick.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So here we have a couple of so take some time to collect all the evidence and then after a couple of seconds it should.",
                    "label": 0
                },
                {
                    "sent": "Return.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there goes.",
                    "label": 0
                },
                {
                    "sent": "So it shows you the improvement in the log likelihood, and if you want it can also drop the model into a file and you can use it again and again.",
                    "label": 0
                },
                {
                    "sent": "You can use all of these commands either through the command line or using the API.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Just want to acknowledge again so this was done under the labs of their supervision of near and Daphne Kohler.",
                    "label": 0
                },
                {
                    "sent": "So this second half left half is people that works in the Hebrew University.",
                    "label": 0
                },
                {
                    "sent": "Right half is in Stanford.",
                    "label": 0
                },
                {
                    "sent": "And Gal began in our lab in Hebrew and then moved to Stanford and came back.",
                    "label": 0
                },
                {
                    "sent": "So he's kind of in the middle.",
                    "label": 0
                },
                {
                    "sent": "So it's a giant effort, and as I said, many peoples are.",
                    "label": 0
                },
                {
                    "sent": "Many people are using it by now and I hope the community will also find it useful tool.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Under functions you showed it.",
                    "label": 0
                },
                {
                    "sent": "For instance, you bite it always three variables can.",
                    "label": 0
                },
                {
                    "sent": "I would say by 100 variables.",
                    "label": 0
                },
                {
                    "sent": "So obviously the larger the factor will be there less efficient inference, so that the computation the cost of the inference is exponential in the size of the factor.",
                    "label": 0
                },
                {
                    "sent": "It's possible, but it will be less sufficient.",
                    "label": 0
                },
                {
                    "sent": "Actually we doing.",
                    "label": 0
                },
                {
                    "sent": "You can extend both the number so we don't have use users doing it with such large number of variables.",
                    "label": 0
                },
                {
                    "sent": "What we do have is people using on a small like in the protein design problem.",
                    "label": 0
                },
                {
                    "sent": "You have a small number of variables, but each of them with a very large cardinality, maybe 20 or 30 possibilities.",
                    "label": 0
                },
                {
                    "sent": "And this again is increases the difficulty but but it's working so it takes a little more time, but it works.",
                    "label": 0
                },
                {
                    "sent": "How much, how long does it take?",
                    "label": 0
                },
                {
                    "sent": "Would it take them 400 variables for Andrew Garments for 100 variables is very quick, but we do 100,000 variables.",
                    "label": 0
                },
                {
                    "sent": "Then it will take.",
                    "label": 0
                },
                {
                    "sent": "Maybe if you just do inference then around 10:15 minutes.",
                    "label": 0
                },
                {
                    "sent": "Problems like in computer vision, image segmentation.",
                    "label": 0
                },
                {
                    "sent": "It is being used on large that it was that the our goal in designing it.",
                    "label": 0
                },
                {
                    "sent": "So then let's speak again.",
                    "label": 0
                }
            ]
        }
    }
}