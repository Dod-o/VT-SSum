{
    "id": "fvxg27ygfon4c2kewwdg2m4cmych7sho",
    "title": "Algorithms for Lipschitz Learning on Graphs",
    "info": {
        "author": [
            "Sushant Sachdeva, Department of Computer Science, Yale University"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_sachdeva_lipschitz_learning/",
    "segmentation": [
        [
            "I'm going to be talking about Lipschitz learning on graphs.",
            "This is joint work with Rasps, King and no problem and then experiment.",
            "OK, so now that it's time for US elect."
        ],
        [
            "Chens assume you are one of the Facebook campaign managers for some presidential candidate.",
            "And you get to pull some of them.",
            "You get to pull some of the Facebook users and you get to know their political inclinations, right?",
            "You should think of political inclination as being a real number between zero and one telling you how Democrat or Republican they are, right?",
            "And given this graph structure and your original values, you'd like to predict the inclination of the rest of the users.",
            "Yeah, your key insight is that people are like their friends really, right?",
            "So political inclination."
        ],
        [
            "Is smooth on this graph.",
            "Right, so we're looking for methods for smooth learning on graphs.",
            "We'd like these methods to be theoretically interesting, efficiently computable.",
            "Ideally nice table if you really want to use them, and the cherry on top would be if they really work in practice right?",
            "In this talk, I'll present one such method and hope to present some evidence to convince you that they satisfy these requirements.",
            "OK, so let's set."
        ],
        [
            "Power problem.",
            "We have a graph on N vertices."
        ],
        [
            "I'm edges and edges have non negative length.",
            "And for now, we'll deal with undirected graphs, right?"
        ],
        [
            "And a subset of these which we call as terminals, have real valued labels associated with them.",
            "Right and the Subs?"
        ],
        [
            "Along with the label."
        ],
        [
            "We refer to as a partial labeling.",
            "Great, so given a partial a partial assignment, we want now labels on all the vertices with two requirements.",
            "One we want to we want the new labels to W2 agree with the original partial assignment and two we'd like W to be smooth on this graph.",
            "Right, so that's a broad goal, we're looking."
        ],
        [
            "For a smooth extension of E, whereby an extension, I mean the final labels you compute agree with the original partial assignment.",
            "Is there a ground truth know so so there can be lots of reasonable answers and the question is what kind of answers would do well in practice, right?",
            "So?",
            "So of course I've not defined what is smooth and let me do that.",
            "So here's our notion of smooth.",
            "So for that let me define for every edge and a set of an assignment W. Let me define the gradient on the edge, so the gradient on the edge XY is WX minus Wii upon length of XY.",
            "So it's the rate of change of your labels along the edge XY.",
            "Right, you should think of gradient as a vector with one entry for every edge in the graph.",
            "Right, here's our here's the 1st."
        ],
        [
            "Attempt at a smooth extension.",
            "Let me call you the in minimizer, so the goal is just to seek an extension that minimizes.",
            "The Infinity gradient of the vector Infinity norm of the gradient vector right which is equal to minimizing the maximum rate of change across the edges.",
            "And you should think of this as the Lipschitz constant of your assignment.",
            "Right, so that's the first item, but it turns out that the infinite it's a first natural term, but it doesn't even have enough structure to define it uniquely for exam."
        ],
        [
            "Well, consider this simple.",
            "Simple 5 cycle with two labels, one and minus one.",
            "The best lip just concerned achievable is 1 here where, which means that the label on the left hand side should be 0 whereas the labels on the right hand side can take a lot of values and still have Lipschitz constant one.",
            "Right, so let's try to mend this.",
            "So let's propose our extension, which so let me let's just go back a step back a second.",
            "How did we define the Infinity minimizer?",
            "We said so let me."
        ],
        [
            "Let me propose the extension that we study.",
            "So amongst all so this is still the Infinity minimizers amongst all extensions we picked.",
            "The ones that minimize the largest gradient, right?",
            "This is the set of all Infinity minimizers.",
            "But this is not unique, so let's not stop here.",
            "Let's pick the set that minimizes the second largest gradient amongst these.",
            "Right and then the third largest gradient amongst these, and so on.",
            "OK. Let me let me convince you.",
            "After that let me define it and convince you that it's interesting.",
            "OK, so we call this."
        ],
        [
            "The Lex minimizer.",
            "And because we are minimizing the gradient in the lexicographic node.",
            "Right, and here's the first sanity check, the lexicographic minimum."
        ],
        [
            "This is unique, right?",
            "And and on the."
        ],
        [
            "Sample before now you must assign labels to the right inside so that all the edges get equal gradient.",
            "Right, so that's one now."
        ],
        [
            "To make the connection and try to convince you it's interesting, let me just step back and if you remember Dan Spielman, stock from 2 days ago, we are not the first people to study this question of smooth extensions.",
            "In fact, a Seminole paper of zoo Ghahremani Lafferty proposed that we should look at the two minimizer, right?",
            "So you look at the extension of your partial labeling that minimizes the sums of squares of gradients on the edges right from a physical perspective, this seems a very natural extension to look at an in fact, as pointed out.",
            "And then stock that you can compute these really fast by using Laplacian solver.",
            "But soon after they came out with this with this proposal."
        ],
        [
            "It was realized that in fact, on very natural instances they don't behave very well.",
            "So here's here's a theorem.",
            "Do not learn others.",
            "They said, just consider simple geometric graphs with a few labels.",
            "And what we could do with what they proved was that as you increase the amount of unlabeled data.",
            "The two minimizer collapses to a constant.",
            "OK, let me demonstrate that with a simple example, so we'll just consider this really toy example.",
            "It's a simple to degrade, and we have two labels or one and a -- 1 opposite corner.",
            "And we consider increasing sizes of the grids.",
            "So here's how the two.",
            "Let's see how the two minimizer performs on these so."
        ],
        [
            "Top, that's a 5 by 5 grid and on the vertical axis you see the interpolated values right?",
            "That seems sort of reasonable, but once you increase the size a lot, most of the values flatten out and are really close to 0, right?",
            "That's not, it's not a very meaningful extension of the kind of labels, particularly if you come at it from the manifold hypothesis that your function is smooth.",
            "And here's how the Lex minimizer does it perfectly interpolates on the grid independent of the size.",
            "Right, so of course this was a toy example, but I hope this shows you that it has an advantage compared to the L2 minimizer which has been studied and used a lot.",
            "So given the DL2 minimizer doesn't work, people have proposed other smoother extensions."
        ],
        [
            "In fact, Alamgir and others proposed.",
            "Oh, why not consider the P minimizer where P is something larger than two.",
            "So now you minimize.",
            "Now you look at extension that minimizes the P norm of the gradient vector, and they proved that.",
            "In fact, if you pick be somewhat large, then they don't flatten out, unlike the L2 minimizer.",
            "But one key disadvantage here already is that these are really costly to compute compared to the L2 minimizer.",
            "So."
        ],
        [
            "Let's talk of computing these.",
            "If you told Hillary that you can compute them as a limit of convex program, she won't be happy.",
            "So we're going to do it much faster."
        ],
        [
            "So let me just give you one definition.",
            "And so here.",
            "So you are given a graph and the partial labeling.",
            "I want to define the gradient of a partial labeling with respect to a pair of terminals.",
            "OK, so given two terminals X&Y, define the gradient of V with respect to X&Y's V, X -- Y upon the distance between X&Y, where the distance is the shortest part distance given by the edge lengths in the graph.",
            "Right, so for example, in this graph effects and why I had had labels one and minus one, the gradient between them is 1 big cause the shortest length path is.",
            "Shortest path has led through right, but what's the connection?",
            "Two to the minimizers that we're studying before.",
            "Here's here's a simple homework.",
            "The Lipschitz constant of the Infinity minimizer, which is the best... concerned achievable, is in fact equal to the maximum grade terminal gradient over maximum overall terminals.",
            "And this is just a strong LP duality statement.",
            "Right, so the steepest terminal pair is intimately connected to the Infinity minimizer.",
            "Right, let me so this motivates an intermediate problem that I'm going to define."
        ],
        [
            "So given a graph and a partial labeling, you want to find a terminal pair XY, which maximizes the gradient of the XY.",
            "Right, and we prove a structural result that says that we can in order to compute the Lex minimizer, it suppose it suffices to make any calls to finding the steepest terminal pair.",
            "And we also prove that if you just want one Infinity minimizer, it suffices just to make a single call.",
            "And to computing the steepest terminal pair.",
            "Right, so this is now.",
            "This is the intermediate problem we'll study.",
            "Given these structural results.",
            "Right, so that's your goal.",
            "Given a graph and the partial labeling, you want to find the steepest terminal pair.",
            "So let's make a first attempt.",
            "So remember the gradient was difference in voltage is divided by the length.",
            "If you knew divided by the distance, sorry if you knew all pairwise distances, then you can find the steepest terminal pair easily."
        ],
        [
            "And we can compute all pairwise distances in end time, and this trivially gives you an MN squared algorithm for computing the.",
            "Let's minimize, right?",
            "That's the best known before, and in this result we show that you can actually compute the CPS terminal pair in linear time, and this gives you an EM algorithm for computing Lex and similarly linear time algorithm for computing an Infinity minimizer.",
            "OK so I don't have time to go into the details of the algorithm, But let me try to give you a puzzle to convince you that it's somewhat surprising, at least to us.",
            "It was surprising when we so just consider."
        ],
        [
            "This extremely simple case it's a star graph, so you have one labeled terminal in the middle.",
            "Do you there and you have end leaves?",
            "Each of them have labels and the edges have non unit lens.",
            "They have general length you within just this graph you want to find the steepest terminal pair you want to find the XY that maximizes the difference in the voltages divided by the length of the path between.",
            "Right and we claim we can actually do this in linear time, Owen.",
            "And we think it's a we think it's somewhat surprising because, well, at first there are.",
            "There are N choose two pairs, so that's that's a trivial algorithm.",
            "But I think it's a nice challenge problem in an undergrad algorithm scores, and I recommend you try it.",
            "So OK, so I'll leave you with that.",
            "Let me go back to further results here."
        ],
        [
            "Something again we already found surprising that the whole theory and algorithms extend very naturally to directed graphs, just as it is.",
            "Why is it surprising?",
            "Is because all the algorithms for L2 have no known analogues for directed graphs.",
            "And just to do it formally, the definition now is that you only measure gradients along the direction of the edge, which means you threshold the gradient below at 0 right, and you want to minimize this new vector positive gradient in the lexicographic ordering is no longer unique.",
            "Nevertheless, we can actually still compute it in the same claimed running times as before, and also similarly for an Infinity minimizer undirected graphs.",
            "OK, so that's for the algorithms.",
            "If you really want to use these things in practice, you want to know how do they behave with respect to noise.",
            "Right, so here's the first question."
        ],
        [
            "What if your original labels are noisy?"
        ],
        [
            "We in fact proved that if your original labels are off by at most an epsilon.",
            "Then the final labels predicted by the Lex minimizer are off by at most epsilon.",
            "Right in some sense, at least in the Infinity norm, that's the strongest kind of noise stability you can expect, so it's really stable.",
            "But if you do know there is noise, how do you account for it?",
            "You often resort to regularization.",
            "So let me define this version of L1 regularizer."
        ],
        [
            "Suppose you knew the edge lengths are off and you pick a budget B.",
            "Right, given a budget B, you want to find you want to change the add lines up to a budget be and still find the best solution.",
            "Be sure that in fact you can do this in M to the three half time.",
            "And this is an algorithm that builds on interior point methods and fast Laplacian solvers.",
            "If you remember dance talk, it's.",
            "So the complication here now is that these systems are not as simple.",
            "You actually don't directly get Laplacian system and the the way to see that is that in fact the program you're solving has a variable for every edge, right?",
            "Because you're allowed to change all the edge lengths so the systems are more complicated.",
            "But we still show how to solve them fast.",
            "Right?"
        ],
        [
            "'cause here's one more is another version of regularization.",
            "What if I tell you you can throw away K of the labels?",
            "Right, so you could control wiki of the labels and you are still.",
            "You still want to find the best possible solution.",
            "We show that you can perform outlier removal.",
            "This question LOL0 regularization in polynomial time.",
            "Remember K can be linear in N, so this is sort of surprising because most of these sparse problems are hard.",
            "In fact, the same version of the problem for the L2 minimizer is NP hard.",
            "If you wanted to do outlier removal for the best L2 version, that's NP hard.",
            "OK, so that's for regularization at least.",
            "At least we're convinced it's it's pretty good theory to start to see how this actually behaves in practice."
        ],
        [
            "And let me show you how this does so, but for experiments you need fast code and if you told me you're implementing an algorithm, I'd be pretty very of running it on."
        ],
        [
            "Element, but the advantage here is that Lex actually really has a lot more structure, more certainly a lot more than I've been able to cover here, but a lot more than you can hear it.",
            "We know theoretically how to exploit so, but we can exploit it for faster code.",
            "So we have a code that's posted currently already on GitHub, which is theoretically correct, but it runs really much faster in practice than they claimed them in time.",
            "And how fast we can run on graphs with millions of edges in under 2 minutes.",
            "And this is just on a just on a laptop, not even on a cluster.",
            "And we have test."
        ],
        [
            "Did this on really several families of different kinds of graphs, and it seems to run really fast.",
            "So now I'll show you the results of one of these experiments, which where we use this card which is detecting web spam.",
            "So what's what's the question we have?",
            "We have a directed graph where every node represents a hub, which is a collection of web pages.",
            "Think of Google, Facebook, New York Times, and a directed edge represents hyperlinks.",
            "So if pages from one hub, .2 pages to another hub, we give a directory.",
            "A subset of these are labeled as trusted.",
            "Think of nytimes.",
            "And a subset of them are labeled as spammy.",
            "Think of I am the Nigerian Prince, but what you want to do is you want to exploit the structure of this graph and these original labels in order to predict which of these hubs are likely to be spam.",
            "Right, that's a challenge.",
            "So and how do we exploit the structure of the graph?",
            "So suppose Nytimes link to your page.",
            "You are likely to be a trusted party.",
            "That's what we're going to use an if you linked to a spam page, you're likely to be spam yourself, right?",
            "And remember, see that this is.",
            "The asymmetry is key here, so this will not really work with the undirected graph.",
            "A directed graph is crucial here.",
            "So how do?"
        ],
        [
            "How do we use our methods?",
            "We label the original samples with trust values.",
            "1 means trusted, zero is untrusted, and we use legs to extend the trust values to the rest of the graph.",
            "And now you simply pick a threshold and label everything below the threshold as spam.",
            "Right, so how does this play?"
        ],
        [
            "Here's the precision recall graph.",
            "If you don't know what that is, let me let me tell you.",
            "So we as we change the threshold, we get different points on this graph on the X axis, we plot the fraction of all spam pages flagged.",
            "So this is we remember we know the ground truth, so we know what are all the spam pages.",
            "We've only picked the sample of them to actually see the experiment, and we plot the fraction of spam pages that you flagged so far, and the X axis and the Y axis is your accuracy.",
            "How many of them did you actually get correct and an ideal algorithm would be right up there 100% all along.",
            "Our algorithm is shown in in red, which achieves 90% accuracy until about 40% precision and it handsomely beats L2 and random walk based method which is shown as a comparison in in blue.",
            "Well."
        ],
        [
            "So now let me just let me quickly conclude.",
            "We suggest proposing the Lexan Infinity minimizers.",
            "For graph inference we show how to compute them quickly.",
            "We show that noise stable, and you can in fact regularize efficiently.",
            "But we think there is still a lot more to explore and a lot of interesting questions around.",
            "Really, the biggest.",
            "The biggest question here is can we prove theoretical learning guarantees right in really in terms of learning learning theory, can we propose?",
            "Can we really look for more interesting datasets where this?",
            "This would be a good fit.",
            "Remember this is really regression.",
            "This is not classification, even though the experiment was classification, the right the right choice of data set would be a regression data set.",
            "But, and we're still looking for a good suggestion and I'll end there.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to be talking about Lipschitz learning on graphs.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with Rasps, King and no problem and then experiment.",
                    "label": 0
                },
                {
                    "sent": "OK, so now that it's time for US elect.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Chens assume you are one of the Facebook campaign managers for some presidential candidate.",
                    "label": 0
                },
                {
                    "sent": "And you get to pull some of them.",
                    "label": 0
                },
                {
                    "sent": "You get to pull some of the Facebook users and you get to know their political inclinations, right?",
                    "label": 0
                },
                {
                    "sent": "You should think of political inclination as being a real number between zero and one telling you how Democrat or Republican they are, right?",
                    "label": 0
                },
                {
                    "sent": "And given this graph structure and your original values, you'd like to predict the inclination of the rest of the users.",
                    "label": 0
                },
                {
                    "sent": "Yeah, your key insight is that people are like their friends really, right?",
                    "label": 0
                },
                {
                    "sent": "So political inclination.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is smooth on this graph.",
                    "label": 0
                },
                {
                    "sent": "Right, so we're looking for methods for smooth learning on graphs.",
                    "label": 1
                },
                {
                    "sent": "We'd like these methods to be theoretically interesting, efficiently computable.",
                    "label": 0
                },
                {
                    "sent": "Ideally nice table if you really want to use them, and the cherry on top would be if they really work in practice right?",
                    "label": 0
                },
                {
                    "sent": "In this talk, I'll present one such method and hope to present some evidence to convince you that they satisfy these requirements.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's set.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Power problem.",
                    "label": 0
                },
                {
                    "sent": "We have a graph on N vertices.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm edges and edges have non negative length.",
                    "label": 0
                },
                {
                    "sent": "And for now, we'll deal with undirected graphs, right?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a subset of these which we call as terminals, have real valued labels associated with them.",
                    "label": 0
                },
                {
                    "sent": "Right and the Subs?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Along with the label.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We refer to as a partial labeling.",
                    "label": 0
                },
                {
                    "sent": "Great, so given a partial a partial assignment, we want now labels on all the vertices with two requirements.",
                    "label": 0
                },
                {
                    "sent": "One we want to we want the new labels to W2 agree with the original partial assignment and two we'd like W to be smooth on this graph.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's a broad goal, we're looking.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For a smooth extension of E, whereby an extension, I mean the final labels you compute agree with the original partial assignment.",
                    "label": 1
                },
                {
                    "sent": "Is there a ground truth know so so there can be lots of reasonable answers and the question is what kind of answers would do well in practice, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 1
                },
                {
                    "sent": "So of course I've not defined what is smooth and let me do that.",
                    "label": 0
                },
                {
                    "sent": "So here's our notion of smooth.",
                    "label": 0
                },
                {
                    "sent": "So for that let me define for every edge and a set of an assignment W. Let me define the gradient on the edge, so the gradient on the edge XY is WX minus Wii upon length of XY.",
                    "label": 0
                },
                {
                    "sent": "So it's the rate of change of your labels along the edge XY.",
                    "label": 0
                },
                {
                    "sent": "Right, you should think of gradient as a vector with one entry for every edge in the graph.",
                    "label": 0
                },
                {
                    "sent": "Right, here's our here's the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Attempt at a smooth extension.",
                    "label": 0
                },
                {
                    "sent": "Let me call you the in minimizer, so the goal is just to seek an extension that minimizes.",
                    "label": 0
                },
                {
                    "sent": "The Infinity gradient of the vector Infinity norm of the gradient vector right which is equal to minimizing the maximum rate of change across the edges.",
                    "label": 0
                },
                {
                    "sent": "And you should think of this as the Lipschitz constant of your assignment.",
                    "label": 1
                },
                {
                    "sent": "Right, so that's the first item, but it turns out that the infinite it's a first natural term, but it doesn't even have enough structure to define it uniquely for exam.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, consider this simple.",
                    "label": 0
                },
                {
                    "sent": "Simple 5 cycle with two labels, one and minus one.",
                    "label": 0
                },
                {
                    "sent": "The best lip just concerned achievable is 1 here where, which means that the label on the left hand side should be 0 whereas the labels on the right hand side can take a lot of values and still have Lipschitz constant one.",
                    "label": 0
                },
                {
                    "sent": "Right, so let's try to mend this.",
                    "label": 0
                },
                {
                    "sent": "So let's propose our extension, which so let me let's just go back a step back a second.",
                    "label": 0
                },
                {
                    "sent": "How did we define the Infinity minimizer?",
                    "label": 0
                },
                {
                    "sent": "We said so let me.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me propose the extension that we study.",
                    "label": 0
                },
                {
                    "sent": "So amongst all so this is still the Infinity minimizers amongst all extensions we picked.",
                    "label": 0
                },
                {
                    "sent": "The ones that minimize the largest gradient, right?",
                    "label": 1
                },
                {
                    "sent": "This is the set of all Infinity minimizers.",
                    "label": 0
                },
                {
                    "sent": "But this is not unique, so let's not stop here.",
                    "label": 1
                },
                {
                    "sent": "Let's pick the set that minimizes the second largest gradient amongst these.",
                    "label": 0
                },
                {
                    "sent": "Right and then the third largest gradient amongst these, and so on.",
                    "label": 1
                },
                {
                    "sent": "OK. Let me let me convince you.",
                    "label": 0
                },
                {
                    "sent": "After that let me define it and convince you that it's interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, so we call this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Lex minimizer.",
                    "label": 0
                },
                {
                    "sent": "And because we are minimizing the gradient in the lexicographic node.",
                    "label": 0
                },
                {
                    "sent": "Right, and here's the first sanity check, the lexicographic minimum.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is unique, right?",
                    "label": 0
                },
                {
                    "sent": "And and on the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample before now you must assign labels to the right inside so that all the edges get equal gradient.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's one now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To make the connection and try to convince you it's interesting, let me just step back and if you remember Dan Spielman, stock from 2 days ago, we are not the first people to study this question of smooth extensions.",
                    "label": 0
                },
                {
                    "sent": "In fact, a Seminole paper of zoo Ghahremani Lafferty proposed that we should look at the two minimizer, right?",
                    "label": 0
                },
                {
                    "sent": "So you look at the extension of your partial labeling that minimizes the sums of squares of gradients on the edges right from a physical perspective, this seems a very natural extension to look at an in fact, as pointed out.",
                    "label": 0
                },
                {
                    "sent": "And then stock that you can compute these really fast by using Laplacian solver.",
                    "label": 0
                },
                {
                    "sent": "But soon after they came out with this with this proposal.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It was realized that in fact, on very natural instances they don't behave very well.",
                    "label": 0
                },
                {
                    "sent": "So here's here's a theorem.",
                    "label": 0
                },
                {
                    "sent": "Do not learn others.",
                    "label": 0
                },
                {
                    "sent": "They said, just consider simple geometric graphs with a few labels.",
                    "label": 1
                },
                {
                    "sent": "And what we could do with what they proved was that as you increase the amount of unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "The two minimizer collapses to a constant.",
                    "label": 1
                },
                {
                    "sent": "OK, let me demonstrate that with a simple example, so we'll just consider this really toy example.",
                    "label": 0
                },
                {
                    "sent": "It's a simple to degrade, and we have two labels or one and a -- 1 opposite corner.",
                    "label": 0
                },
                {
                    "sent": "And we consider increasing sizes of the grids.",
                    "label": 0
                },
                {
                    "sent": "So here's how the two.",
                    "label": 0
                },
                {
                    "sent": "Let's see how the two minimizer performs on these so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Top, that's a 5 by 5 grid and on the vertical axis you see the interpolated values right?",
                    "label": 0
                },
                {
                    "sent": "That seems sort of reasonable, but once you increase the size a lot, most of the values flatten out and are really close to 0, right?",
                    "label": 0
                },
                {
                    "sent": "That's not, it's not a very meaningful extension of the kind of labels, particularly if you come at it from the manifold hypothesis that your function is smooth.",
                    "label": 0
                },
                {
                    "sent": "And here's how the Lex minimizer does it perfectly interpolates on the grid independent of the size.",
                    "label": 0
                },
                {
                    "sent": "Right, so of course this was a toy example, but I hope this shows you that it has an advantage compared to the L2 minimizer which has been studied and used a lot.",
                    "label": 0
                },
                {
                    "sent": "So given the DL2 minimizer doesn't work, people have proposed other smoother extensions.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, Alamgir and others proposed.",
                    "label": 0
                },
                {
                    "sent": "Oh, why not consider the P minimizer where P is something larger than two.",
                    "label": 0
                },
                {
                    "sent": "So now you minimize.",
                    "label": 0
                },
                {
                    "sent": "Now you look at extension that minimizes the P norm of the gradient vector, and they proved that.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you pick be somewhat large, then they don't flatten out, unlike the L2 minimizer.",
                    "label": 0
                },
                {
                    "sent": "But one key disadvantage here already is that these are really costly to compute compared to the L2 minimizer.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's talk of computing these.",
                    "label": 0
                },
                {
                    "sent": "If you told Hillary that you can compute them as a limit of convex program, she won't be happy.",
                    "label": 0
                },
                {
                    "sent": "So we're going to do it much faster.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me just give you one definition.",
                    "label": 0
                },
                {
                    "sent": "And so here.",
                    "label": 0
                },
                {
                    "sent": "So you are given a graph and the partial labeling.",
                    "label": 0
                },
                {
                    "sent": "I want to define the gradient of a partial labeling with respect to a pair of terminals.",
                    "label": 0
                },
                {
                    "sent": "OK, so given two terminals X&Y, define the gradient of V with respect to X&Y's V, X -- Y upon the distance between X&Y, where the distance is the shortest part distance given by the edge lengths in the graph.",
                    "label": 1
                },
                {
                    "sent": "Right, so for example, in this graph effects and why I had had labels one and minus one, the gradient between them is 1 big cause the shortest length path is.",
                    "label": 0
                },
                {
                    "sent": "Shortest path has led through right, but what's the connection?",
                    "label": 0
                },
                {
                    "sent": "Two to the minimizers that we're studying before.",
                    "label": 0
                },
                {
                    "sent": "Here's here's a simple homework.",
                    "label": 0
                },
                {
                    "sent": "The Lipschitz constant of the Infinity minimizer, which is the best... concerned achievable, is in fact equal to the maximum grade terminal gradient over maximum overall terminals.",
                    "label": 0
                },
                {
                    "sent": "And this is just a strong LP duality statement.",
                    "label": 0
                },
                {
                    "sent": "Right, so the steepest terminal pair is intimately connected to the Infinity minimizer.",
                    "label": 0
                },
                {
                    "sent": "Right, let me so this motivates an intermediate problem that I'm going to define.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So given a graph and a partial labeling, you want to find a terminal pair XY, which maximizes the gradient of the XY.",
                    "label": 1
                },
                {
                    "sent": "Right, and we prove a structural result that says that we can in order to compute the Lex minimizer, it suppose it suffices to make any calls to finding the steepest terminal pair.",
                    "label": 0
                },
                {
                    "sent": "And we also prove that if you just want one Infinity minimizer, it suffices just to make a single call.",
                    "label": 1
                },
                {
                    "sent": "And to computing the steepest terminal pair.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is now.",
                    "label": 0
                },
                {
                    "sent": "This is the intermediate problem we'll study.",
                    "label": 0
                },
                {
                    "sent": "Given these structural results.",
                    "label": 1
                },
                {
                    "sent": "Right, so that's your goal.",
                    "label": 0
                },
                {
                    "sent": "Given a graph and the partial labeling, you want to find the steepest terminal pair.",
                    "label": 0
                },
                {
                    "sent": "So let's make a first attempt.",
                    "label": 0
                },
                {
                    "sent": "So remember the gradient was difference in voltage is divided by the length.",
                    "label": 0
                },
                {
                    "sent": "If you knew divided by the distance, sorry if you knew all pairwise distances, then you can find the steepest terminal pair easily.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we can compute all pairwise distances in end time, and this trivially gives you an MN squared algorithm for computing the.",
                    "label": 0
                },
                {
                    "sent": "Let's minimize, right?",
                    "label": 0
                },
                {
                    "sent": "That's the best known before, and in this result we show that you can actually compute the CPS terminal pair in linear time, and this gives you an EM algorithm for computing Lex and similarly linear time algorithm for computing an Infinity minimizer.",
                    "label": 1
                },
                {
                    "sent": "OK so I don't have time to go into the details of the algorithm, But let me try to give you a puzzle to convince you that it's somewhat surprising, at least to us.",
                    "label": 0
                },
                {
                    "sent": "It was surprising when we so just consider.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This extremely simple case it's a star graph, so you have one labeled terminal in the middle.",
                    "label": 1
                },
                {
                    "sent": "Do you there and you have end leaves?",
                    "label": 0
                },
                {
                    "sent": "Each of them have labels and the edges have non unit lens.",
                    "label": 0
                },
                {
                    "sent": "They have general length you within just this graph you want to find the steepest terminal pair you want to find the XY that maximizes the difference in the voltages divided by the length of the path between.",
                    "label": 0
                },
                {
                    "sent": "Right and we claim we can actually do this in linear time, Owen.",
                    "label": 0
                },
                {
                    "sent": "And we think it's a we think it's somewhat surprising because, well, at first there are.",
                    "label": 0
                },
                {
                    "sent": "There are N choose two pairs, so that's that's a trivial algorithm.",
                    "label": 0
                },
                {
                    "sent": "But I think it's a nice challenge problem in an undergrad algorithm scores, and I recommend you try it.",
                    "label": 0
                },
                {
                    "sent": "So OK, so I'll leave you with that.",
                    "label": 0
                },
                {
                    "sent": "Let me go back to further results here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something again we already found surprising that the whole theory and algorithms extend very naturally to directed graphs, just as it is.",
                    "label": 1
                },
                {
                    "sent": "Why is it surprising?",
                    "label": 1
                },
                {
                    "sent": "Is because all the algorithms for L2 have no known analogues for directed graphs.",
                    "label": 0
                },
                {
                    "sent": "And just to do it formally, the definition now is that you only measure gradients along the direction of the edge, which means you threshold the gradient below at 0 right, and you want to minimize this new vector positive gradient in the lexicographic ordering is no longer unique.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, we can actually still compute it in the same claimed running times as before, and also similarly for an Infinity minimizer undirected graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's for the algorithms.",
                    "label": 0
                },
                {
                    "sent": "If you really want to use these things in practice, you want to know how do they behave with respect to noise.",
                    "label": 0
                },
                {
                    "sent": "Right, so here's the first question.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What if your original labels are noisy?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We in fact proved that if your original labels are off by at most an epsilon.",
                    "label": 1
                },
                {
                    "sent": "Then the final labels predicted by the Lex minimizer are off by at most epsilon.",
                    "label": 0
                },
                {
                    "sent": "Right in some sense, at least in the Infinity norm, that's the strongest kind of noise stability you can expect, so it's really stable.",
                    "label": 0
                },
                {
                    "sent": "But if you do know there is noise, how do you account for it?",
                    "label": 0
                },
                {
                    "sent": "You often resort to regularization.",
                    "label": 0
                },
                {
                    "sent": "So let me define this version of L1 regularizer.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suppose you knew the edge lengths are off and you pick a budget B.",
                    "label": 0
                },
                {
                    "sent": "Right, given a budget B, you want to find you want to change the add lines up to a budget be and still find the best solution.",
                    "label": 0
                },
                {
                    "sent": "Be sure that in fact you can do this in M to the three half time.",
                    "label": 0
                },
                {
                    "sent": "And this is an algorithm that builds on interior point methods and fast Laplacian solvers.",
                    "label": 1
                },
                {
                    "sent": "If you remember dance talk, it's.",
                    "label": 0
                },
                {
                    "sent": "So the complication here now is that these systems are not as simple.",
                    "label": 0
                },
                {
                    "sent": "You actually don't directly get Laplacian system and the the way to see that is that in fact the program you're solving has a variable for every edge, right?",
                    "label": 0
                },
                {
                    "sent": "Because you're allowed to change all the edge lengths so the systems are more complicated.",
                    "label": 0
                },
                {
                    "sent": "But we still show how to solve them fast.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause here's one more is another version of regularization.",
                    "label": 0
                },
                {
                    "sent": "What if I tell you you can throw away K of the labels?",
                    "label": 0
                },
                {
                    "sent": "Right, so you could control wiki of the labels and you are still.",
                    "label": 0
                },
                {
                    "sent": "You still want to find the best possible solution.",
                    "label": 1
                },
                {
                    "sent": "We show that you can perform outlier removal.",
                    "label": 1
                },
                {
                    "sent": "This question LOL0 regularization in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "Remember K can be linear in N, so this is sort of surprising because most of these sparse problems are hard.",
                    "label": 1
                },
                {
                    "sent": "In fact, the same version of the problem for the L2 minimizer is NP hard.",
                    "label": 0
                },
                {
                    "sent": "If you wanted to do outlier removal for the best L2 version, that's NP hard.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's for regularization at least.",
                    "label": 0
                },
                {
                    "sent": "At least we're convinced it's it's pretty good theory to start to see how this actually behaves in practice.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let me show you how this does so, but for experiments you need fast code and if you told me you're implementing an algorithm, I'd be pretty very of running it on.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Element, but the advantage here is that Lex actually really has a lot more structure, more certainly a lot more than I've been able to cover here, but a lot more than you can hear it.",
                    "label": 1
                },
                {
                    "sent": "We know theoretically how to exploit so, but we can exploit it for faster code.",
                    "label": 1
                },
                {
                    "sent": "So we have a code that's posted currently already on GitHub, which is theoretically correct, but it runs really much faster in practice than they claimed them in time.",
                    "label": 0
                },
                {
                    "sent": "And how fast we can run on graphs with millions of edges in under 2 minutes.",
                    "label": 0
                },
                {
                    "sent": "And this is just on a just on a laptop, not even on a cluster.",
                    "label": 0
                },
                {
                    "sent": "And we have test.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did this on really several families of different kinds of graphs, and it seems to run really fast.",
                    "label": 0
                },
                {
                    "sent": "So now I'll show you the results of one of these experiments, which where we use this card which is detecting web spam.",
                    "label": 0
                },
                {
                    "sent": "So what's what's the question we have?",
                    "label": 0
                },
                {
                    "sent": "We have a directed graph where every node represents a hub, which is a collection of web pages.",
                    "label": 0
                },
                {
                    "sent": "Think of Google, Facebook, New York Times, and a directed edge represents hyperlinks.",
                    "label": 0
                },
                {
                    "sent": "So if pages from one hub, .2 pages to another hub, we give a directory.",
                    "label": 0
                },
                {
                    "sent": "A subset of these are labeled as trusted.",
                    "label": 0
                },
                {
                    "sent": "Think of nytimes.",
                    "label": 0
                },
                {
                    "sent": "And a subset of them are labeled as spammy.",
                    "label": 0
                },
                {
                    "sent": "Think of I am the Nigerian Prince, but what you want to do is you want to exploit the structure of this graph and these original labels in order to predict which of these hubs are likely to be spam.",
                    "label": 0
                },
                {
                    "sent": "Right, that's a challenge.",
                    "label": 0
                },
                {
                    "sent": "So and how do we exploit the structure of the graph?",
                    "label": 0
                },
                {
                    "sent": "So suppose Nytimes link to your page.",
                    "label": 0
                },
                {
                    "sent": "You are likely to be a trusted party.",
                    "label": 0
                },
                {
                    "sent": "That's what we're going to use an if you linked to a spam page, you're likely to be spam yourself, right?",
                    "label": 0
                },
                {
                    "sent": "And remember, see that this is.",
                    "label": 0
                },
                {
                    "sent": "The asymmetry is key here, so this will not really work with the undirected graph.",
                    "label": 0
                },
                {
                    "sent": "A directed graph is crucial here.",
                    "label": 0
                },
                {
                    "sent": "So how do?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we use our methods?",
                    "label": 0
                },
                {
                    "sent": "We label the original samples with trust values.",
                    "label": 1
                },
                {
                    "sent": "1 means trusted, zero is untrusted, and we use legs to extend the trust values to the rest of the graph.",
                    "label": 1
                },
                {
                    "sent": "And now you simply pick a threshold and label everything below the threshold as spam.",
                    "label": 0
                },
                {
                    "sent": "Right, so how does this play?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's the precision recall graph.",
                    "label": 0
                },
                {
                    "sent": "If you don't know what that is, let me let me tell you.",
                    "label": 0
                },
                {
                    "sent": "So we as we change the threshold, we get different points on this graph on the X axis, we plot the fraction of all spam pages flagged.",
                    "label": 1
                },
                {
                    "sent": "So this is we remember we know the ground truth, so we know what are all the spam pages.",
                    "label": 0
                },
                {
                    "sent": "We've only picked the sample of them to actually see the experiment, and we plot the fraction of spam pages that you flagged so far, and the X axis and the Y axis is your accuracy.",
                    "label": 0
                },
                {
                    "sent": "How many of them did you actually get correct and an ideal algorithm would be right up there 100% all along.",
                    "label": 0
                },
                {
                    "sent": "Our algorithm is shown in in red, which achieves 90% accuracy until about 40% precision and it handsomely beats L2 and random walk based method which is shown as a comparison in in blue.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let me just let me quickly conclude.",
                    "label": 0
                },
                {
                    "sent": "We suggest proposing the Lexan Infinity minimizers.",
                    "label": 0
                },
                {
                    "sent": "For graph inference we show how to compute them quickly.",
                    "label": 1
                },
                {
                    "sent": "We show that noise stable, and you can in fact regularize efficiently.",
                    "label": 0
                },
                {
                    "sent": "But we think there is still a lot more to explore and a lot of interesting questions around.",
                    "label": 0
                },
                {
                    "sent": "Really, the biggest.",
                    "label": 0
                },
                {
                    "sent": "The biggest question here is can we prove theoretical learning guarantees right in really in terms of learning learning theory, can we propose?",
                    "label": 1
                },
                {
                    "sent": "Can we really look for more interesting datasets where this?",
                    "label": 0
                },
                {
                    "sent": "This would be a good fit.",
                    "label": 0
                },
                {
                    "sent": "Remember this is really regression.",
                    "label": 0
                },
                {
                    "sent": "This is not classification, even though the experiment was classification, the right the right choice of data set would be a regression data set.",
                    "label": 0
                },
                {
                    "sent": "But, and we're still looking for a good suggestion and I'll end there.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}