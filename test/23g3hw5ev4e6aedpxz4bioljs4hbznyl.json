{
    "id": "23g3hw5ev4e6aedpxz4bioljs4hbznyl",
    "title": "Variational Inference over Combinatorial Spaces",
    "info": {
        "author": [
            "Alexandre Bouchard-C\u00f4t\u00e9, Department of Statistics, University of British Columbia"
        ],
        "published": "March 25, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/nips2010_bouchard_cote_vic/",
    "segmentation": [
        [
            "So here we're concerned with inference problems where the goal is to some rather than maximize.",
            "For example, to compute expectations or the data likelihood.",
            "So let's start by looking at two types of difficulties that you might encounter when computing this sum.",
            "So in the first type on the left, the support of the function F to sum over is simple, But the structure of the sufficient statistics and uses a large tree width.",
            "In this talk or in this work, we focus on a second type of difficulty, where not the difficulties come from the support or the base measure being defined on a complicated combinatorial space S. So this includes examples such as summing over matchings, amilton circuits, poset dinner, azatian plane partitions, and so on.",
            "Let's see where we are."
        ],
        [
            "I thought fitzen.",
            "So in this table I show some frameworks that can be used by practitioners to derive inference algorithms without too much pain.",
            "For MCMC approximation, for example, gives can be for.",
            "Used for the first type of inference problems an one can back off to Metro policies.",
            "Things in the case of summing overcome natural spaces.",
            "Now for variational approach approximations.",
            "There are many options available for large tree with situation, but not for coming natural spaces, and that's where our contribution fits a simple but general assumption called measure factorization that makes it easy to apply variational inference to combinatorial problems.",
            "A measure of factorization is decomposition of the intractable space S into an intersection of factors.",
            "SI shown in green here.",
            "Even though the S eyes are larger, it's often possible to find a decomposition such that the sum is tractable on each SI.",
            "So in the paper we show, our variational method can be used to approximate the intersection from the knowledge of the sum for each factor.",
            "So let's look."
        ],
        [
            "At some example, starting with something simple.",
            "Suppose we want to sum over perfect bipartite matching between A&B.",
            "In this case, the factorization is simply the set of functions from A to B on one hand, and from B2A on the other end.",
            "So on each of these factors the sum can be computed easily.",
            "So we're done.",
            "At the bottom I saw a more complicated example involving linearization of partial orders.",
            "We show in the paper that there's a measure of factorization and use by a forest cover of on the hesi diagram in this case.",
            "So we also applied our framework to protein multiple sequence alignment."
        ],
        [
            "Where the problem is to sum over K part.",
            "K partite matchings satisfying the constraints shown here.",
            "In this case, there are too many factors and factorization and this motivated a generalization of our assumption where the intersection is only required to cover S. So we characterize the consequences of this generalization an got state of the art results on multiple sequence alignment.",
            "If you understood, become our poster at T 74.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we're concerned with inference problems where the goal is to some rather than maximize.",
                    "label": 0
                },
                {
                    "sent": "For example, to compute expectations or the data likelihood.",
                    "label": 0
                },
                {
                    "sent": "So let's start by looking at two types of difficulties that you might encounter when computing this sum.",
                    "label": 0
                },
                {
                    "sent": "So in the first type on the left, the support of the function F to sum over is simple, But the structure of the sufficient statistics and uses a large tree width.",
                    "label": 0
                },
                {
                    "sent": "In this talk or in this work, we focus on a second type of difficulty, where not the difficulties come from the support or the base measure being defined on a complicated combinatorial space S. So this includes examples such as summing over matchings, amilton circuits, poset dinner, azatian plane partitions, and so on.",
                    "label": 1
                },
                {
                    "sent": "Let's see where we are.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I thought fitzen.",
                    "label": 0
                },
                {
                    "sent": "So in this table I show some frameworks that can be used by practitioners to derive inference algorithms without too much pain.",
                    "label": 0
                },
                {
                    "sent": "For MCMC approximation, for example, gives can be for.",
                    "label": 0
                },
                {
                    "sent": "Used for the first type of inference problems an one can back off to Metro policies.",
                    "label": 0
                },
                {
                    "sent": "Things in the case of summing overcome natural spaces.",
                    "label": 0
                },
                {
                    "sent": "Now for variational approach approximations.",
                    "label": 0
                },
                {
                    "sent": "There are many options available for large tree with situation, but not for coming natural spaces, and that's where our contribution fits a simple but general assumption called measure factorization that makes it easy to apply variational inference to combinatorial problems.",
                    "label": 0
                },
                {
                    "sent": "A measure of factorization is decomposition of the intractable space S into an intersection of factors.",
                    "label": 0
                },
                {
                    "sent": "SI shown in green here.",
                    "label": 0
                },
                {
                    "sent": "Even though the S eyes are larger, it's often possible to find a decomposition such that the sum is tractable on each SI.",
                    "label": 1
                },
                {
                    "sent": "So in the paper we show, our variational method can be used to approximate the intersection from the knowledge of the sum for each factor.",
                    "label": 0
                },
                {
                    "sent": "So let's look.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At some example, starting with something simple.",
                    "label": 0
                },
                {
                    "sent": "Suppose we want to sum over perfect bipartite matching between A&B.",
                    "label": 0
                },
                {
                    "sent": "In this case, the factorization is simply the set of functions from A to B on one hand, and from B2A on the other end.",
                    "label": 0
                },
                {
                    "sent": "So on each of these factors the sum can be computed easily.",
                    "label": 0
                },
                {
                    "sent": "So we're done.",
                    "label": 0
                },
                {
                    "sent": "At the bottom I saw a more complicated example involving linearization of partial orders.",
                    "label": 0
                },
                {
                    "sent": "We show in the paper that there's a measure of factorization and use by a forest cover of on the hesi diagram in this case.",
                    "label": 0
                },
                {
                    "sent": "So we also applied our framework to protein multiple sequence alignment.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where the problem is to sum over K part.",
                    "label": 0
                },
                {
                    "sent": "K partite matchings satisfying the constraints shown here.",
                    "label": 0
                },
                {
                    "sent": "In this case, there are too many factors and factorization and this motivated a generalization of our assumption where the intersection is only required to cover S. So we characterize the consequences of this generalization an got state of the art results on multiple sequence alignment.",
                    "label": 1
                },
                {
                    "sent": "If you understood, become our poster at T 74.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}