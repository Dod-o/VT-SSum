{
    "id": "dshsqw6m4v3f275nre4kgp5knof7fsnh",
    "title": "Exploiting Information Extraction, Reasoning and Machine Learning for Relation Prediction",
    "info": {
        "author": [
            "Xueyan Jiang, Ludwig-Maximilians Universit\u00e4t"
        ],
        "published": "July 4, 2012",
        "recorded": "May 2012",
        "category": [
            "Top->Computer Science->Information Extraction",
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Logic",
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Semantic Web->Ontologies"
        ]
    },
    "url": "http://videolectures.net/eswc2012_jiang_relation_prediction/",
    "segmentation": [
        [
            "So I would like to briefly go through the contents of this graph."
        ],
        [
            "And this graph mainly describe two writers.",
            "One is greater, the others come from the links.",
            "We can get information that has the type of a German writer and greater Bond in Frankfurt, Frankfurt, located in Germany.",
            "The information for Kamaile is.",
            "Come up with bonding OnStar, OnStar located in Germany.",
            "And there's some also additional property values for those two writers, like Good has the born year 1949 and also literal of the introduction for greater.",
            "Additionally, we can see that there's two URL links to describe, and Germany.",
            "And we assume that.",
            "Is all the entities or class and property values, unknowns in this RDF graph.",
            "So there are if we have N nodes in an RDF graph, then there's a possible N * N relations between the nodes.",
            "What we?"
        ],
        [
            "We are interested in is too.",
            "Except the known relations we want to predict a confidence value for those unknown relations.",
            "For example, here we would like to know if Caramail also born in also has the type of a German writer.",
            "Before we go to our."
        ],
        [
            "Framework we would like to have an insight about the RDF graph to see what kind of knowledge source we can use.",
            "The first is.",
            "Knowledge base which includes existing triples and the new triples derived from deductive reasoning.",
            "Example in this graph is we know that God born in Frankfurt and Frankfurt located in Germany.",
            "We can derive a GNU relation between greater and Germany that while the simple go reasoning.",
            "Another knowledge source is the unstructured contextual info."
        ],
        [
            "Nation which can be from the free text of wiki page pages and web pages, or the literals in the property values.",
            "We shown in this graph has the introduction and those literals in the property value of introduction can be used as an structural contextual information.",
            "And outside the RDF graph we can find some free text which is linked to the URL and this free test can also be used.",
            "For making the confidence values for the possible relations.",
            "So two.",
            "Now we already explored all the possible knowledge sources around an even outside the RDF graph.",
            "We want to do is of course make use of all the possible resources an now we first have a look at some common approach."
        ],
        [
            "Is that make use of the unstructured information and knowledge base for relation prediction?",
            "The first one is information extraction, which.",
            "Extracts express the the information from the free text.",
            "And then give confidence value about the truth of the relations.",
            "There are some common IE system like.",
            "Process file the NLP is simply search the free text and find the relevant sentence and then extract the structure data out of the unstructured information.",
            "For example, before we wanted to know if Kamaile has the type of German writer, we can just search some free text and see if we can find some.",
            "Terms of words that fixed this statement and then we can, based on the confidence of the NLP tool to derive a confidence value of the truth of the statement.",
            "Another kind of AI system is reveur classifier based on the back of words or N grams and then give and predict how likely the relations is.",
            "The second approach for relation prediction is deductive reasoning, which apply a set of assumes.",
            "The existing relations.",
            "And derive knew relations as I explained before.",
            "There's a simple example.",
            "In the knowledge base part.",
            "And the.",
            "All the items for deductive reasoning generalize from some facts and then.",
            "Limitaciones, we can't generalize everything, so deductive reasoning can only derive a subset of the unknown relations, and it's difficult to deal with uncertainty with deductive reasoning.",
            "But things deductive reasoning.",
            "Derive the results from some facts so it's more reliable.",
            "1/3 common approach for relation prediction is machine learning.",
            "Which learns the underlying statistical structure of the known relations and then found the correlation between the known relations and the unknown relations.",
            "And in this way it can express statistical dependencies between relations and handle the incomplete data.",
            "So our goal is to combine all these three common approaches."
        ],
        [
            "To make use of all the knowledge sources, including the context info, the unstructured information, and the knowledge base.",
            "And we used an IE system to exploit the unstructured information and use deductive reasoning to exploit the knowledge base.",
            "And then we build a machine learning model on top to exploit the statistical dependencies among all the knowledge sources.",
            "Now let's go to the framework before I explain it."
        ],
        [
            "Framework I briefly.",
            "Summarized how it worked.",
            "First we we build a matrix to represent the RDF graph and then we used an IE system to extract information structure information.",
            "And give the confidence value of the unknown relations and fill it to the metrics we built for the IDF graph.",
            "After the E step, we apply the deductive reasoning step, which is independent of the the IE step for the deductive reasoning step.",
            "We derive as possible as gnu triples from the known triples.",
            "And then after this independent, these two independent steps, we combine them by a simple rule.",
            "So based on the basic metrics we built for the original RDF graph, we already filled in some more entries from the IE system and deductive reasoning system.",
            "But this system hasn't explored the statistical dependencies of the IE system, and deductive reasoning system.",
            "Therefore we build a machine learning model on top of it.",
            "Which is.",
            "Probably listed latent factor model.",
            "And is in fact a probabilistic model, but it's related to matrix factorization.",
            "So we factorize the metrics we derive from the eastep and the deductive reasoning step, and then we complete metrics.",
            "So for each of after completion, the metrics is complete full, we can derive all the confidence values for the possible triples.",
            "Now let's go to the detail of the framework.",
            "First, is the matrix representation for the RDF graph we."
        ],
        [
            "Construct the matrix X from the RDF graph, where each row represents the subject in which column represents predicate object pair.",
            "And we fill in the entry."
        ],
        [
            "As with one where each entry corresponds to a link in the RDF graph.",
            "For example, let's have a look at the entry one with purple background.",
            "It represents the link in the added RDF graph.",
            "That good is the type of German writer.",
            "And the entry one with Orange background represents the fact the link in the IDF graph that get a born year 1949.",
            "Of course we will not directly use the year as a feature in the metrics because that's too specific.",
            "We generalize it to 18th century.",
            "An after building the basic metrics, we started to fill."
        ],
        [
            "In the metrics, the first step is the IE step.",
            "In principle, any AI system can be used.",
            "We don't specify any specialized system, but in our experiment we build a classifier to predict the confidence value of the unknown relations.",
            "So we extract the wiki pages.",
            "The free text from the wiki pages about good Camel, an also German writer, Ann French writer, American writer.",
            "We put all these words.",
            "Into the classifier an learn a model and predict.",
            "The confidence value.",
            "About how, how likely that go to."
        ],
        [
            "Is the French writer or, with the German writer?",
            "So this is the first step, IE step and the second step."
        ],
        [
            "But completely independent of the first step is deductive reasoning step.",
            "When we build a basic metrics, we already fill in the entries that is corresponding to a triple in RDF graph.",
            "So what we need to do now is since the eastep is independent of the deductive reasoning step, we now go back to the basic metrics, but we want to derive more.",
            "And triples based on the existing triples.",
            "Let's have a look at the.",
            "Orange so let's have a look at the entries with green background, which indicates good born in Frankfurt and Frankfurt, located in Germany.",
            "From this we apply the go reasoning and we derive a new triple or."
        ],
        [
            "Elation that Gator born in Germany.",
            "And things."
        ],
        [
            "So don't be ducted reasoning step.",
            "We only add one entry and the entry is we added is not related to the entries that we wanted to know about the writers nationality.",
            "So after the deductive reason is that we did we derive these metrics.",
            "Many zeros and only one of the known triple.",
            "To summarize, the first 2 steps we can see that the first matrix is."
        ],
        [
            "What we got from the Eastep and the second metrics is what we got from the deductive reasoning step an we simply apply a rule to combine them.",
            "The rule is just pick the most confident one.",
            "This is simple, but it makes sense because it will keep the one from the deductive reasoning which is quite reliable.",
            "And if the deductive reasoning cannot give us any information, we can supplement it from the IE system.",
            "So two, now we already fill in the information that we can get from the.",
            "IE system and deductive reasoning.",
            "But we haven't exploit a statistical dependency."
        ],
        [
            "Between the different knowledge sources, because IE system is exploits the unstructured information and deductive reasoning exploit the knowledge based source.",
            "So we need to build a probabilistic model on top to exploit the dependencies.",
            "Of these two.",
            "Different approaches.",
            "The idea is we map.",
            "The confidence value that the relation is true given the IE system and the deductive reasoning to continuous continuous value F. Using.",
            "The inverse of a symbolic function, which is very simple function that the original confidence value has the value between zero and one.",
            "And now we met it too and.",
            "F which has a value from negative infinite to positive infinite.",
            "This can be the value generated from a noisy standard Gaussian distribution.",
            "Therefore, we need to have cleaning version of F to get the cleaning version of F. We first assume that for each subject entity, we introduce low dimension.",
            "No latent variable hi, which follows the.",
            "Standard Gaussian distribution and then for each subject entity EI, an Alpha is generated and Alpha is the linear combination of the low dimensional latent variable hi.",
            "And it's also the cleaning version of F. And this probably listed model is related to matrix factorization and the solution for Alpha is maximized if we calculate it in this way and I'm not going to go into the."
        ],
        [
            "Tell if someone is interesting, can have a look at our paper.",
            "And this Alpha is related to the subject entity I.",
            "And remind that before we map the confidence value.",
            "Of confidence value.",
            "Of the truth of the statement given the IE system and deductive reasoning via inverse of Sigma.",
            "So now we need to change transform back to get a value that fits to the range between zero and one and then this value is exactly the confidence value of the truth of the statement given IE system and deductive reasoning and machine learning.",
            "So we nicely solve all solve the relation prediction problem in one model.",
            "Simple and effective.",
            "Now we evaluate our method with two experiments.",
            "The first experiment is done on the."
        ],
        [
            "In disease data set, the target is forgiven.",
            "Genes.",
            "We would like to.",
            "Recommend the disease that is most likely related to these jeans and this task makes sense for the medical diagnosis because the relations between genes and disease always very complicated and hard to express by simple logical expression and our method can predict any confidence value for the possible relations.",
            "So we just use our model to evaluate this.",
            "And the data is from the link open data more in detail is the link life data and bio two RDF data.",
            "There we extract more than 2000 genes and more than 300 diseases.",
            "And we built three models.",
            "The first one is the IE system.",
            "The IE system is built based on only the literals from the property values like the comments of the disease or jeans and the nodes of the disease origins.",
            "And the Y system here is quite poor as we can see and then we build another model, the machine learning model which only use the known relations between genes and disease and this model is still not good enough.",
            "And then we simply add the IE system to the machine learning like what we did before.",
            "But here we don't have deductive reasoning because because we don't have the background knowledge.",
            "And then we found after we combine them, we got a 5% improvement.",
            "And this result is competitive to a state of art, gene disease relationship discovery tool called top gene suit.",
            "And second experiment is done on YAGO two data.",
            "And our target is."
        ],
        [
            "To predict the writer's nationality.",
            "So we built 5 models.",
            "First one is machine learning model.",
            "We only use.",
            "The writers as the subject and then use the countries.",
            "As the object and then we based on this a relation relationships metrics we.",
            "We learn the machine learning model and then predict the confidence value of the truth of the relations.",
            "And this is also related to to the subgraph I shown before.",
            "And we can see that the machine learning model is quite poor and.",
            "Um?",
            "The next model is the IE system, which is quite strong.",
            "The reason is as before, for the machine learning model, we only use the writer and their nationality and also the birthplace.",
            "But the birthplace has is not has not so strong correlation to the nationality of the writer because someone can be born in one place and later became a writer in another place.",
            "And this information can only be.",
            "Retrieve by ID system because most likely in the wiki page we it's written that this author when he was young his.",
            "So.",
            "He's somewhere in in one country and later he became a writer in another country.",
            "Also, there's another problem that is not.",
            "One writer is not assigned to 1 country.",
            "Some writers can have more than one nationalities.",
            "In this case we can only get the information from the IE system.",
            "So I hear is very strong, but.",
            "And we have a false model.",
            "The machine learning aggregating with.",
            "The country of the birth place.",
            "While the gear reasoning and this performance already.",
            "Better than the pure machine learning model.",
            "And finally, the combination of or as we propose is the best.",
            "This experiment nicely show that our framework that combine all the knowledge source sources works.",
            "So to conclude, we."
        ],
        [
            "First, explore that all the possible knowledge sources around an incentive graph, and we also exploit the possible approaches for relation prediction.",
            "And then we just combine all of these and use the IE to exploit the unstructured information.",
            "Use deductive reasoning to exploit the systematic knowledge and use machine learning to exploit the statistical patterns on top.",
            "And this model is very efficient because it's a one step model, we just put everything in as a pre processing an from the IE system and deductive reasoning and then we just factorize the metrics.",
            "And then everything is done.",
            "That's all, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I would like to briefly go through the contents of this graph.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this graph mainly describe two writers.",
                    "label": 0
                },
                {
                    "sent": "One is greater, the others come from the links.",
                    "label": 0
                },
                {
                    "sent": "We can get information that has the type of a German writer and greater Bond in Frankfurt, Frankfurt, located in Germany.",
                    "label": 0
                },
                {
                    "sent": "The information for Kamaile is.",
                    "label": 0
                },
                {
                    "sent": "Come up with bonding OnStar, OnStar located in Germany.",
                    "label": 0
                },
                {
                    "sent": "And there's some also additional property values for those two writers, like Good has the born year 1949 and also literal of the introduction for greater.",
                    "label": 0
                },
                {
                    "sent": "Additionally, we can see that there's two URL links to describe, and Germany.",
                    "label": 0
                },
                {
                    "sent": "And we assume that.",
                    "label": 0
                },
                {
                    "sent": "Is all the entities or class and property values, unknowns in this RDF graph.",
                    "label": 1
                },
                {
                    "sent": "So there are if we have N nodes in an RDF graph, then there's a possible N * N relations between the nodes.",
                    "label": 0
                },
                {
                    "sent": "What we?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are interested in is too.",
                    "label": 0
                },
                {
                    "sent": "Except the known relations we want to predict a confidence value for those unknown relations.",
                    "label": 0
                },
                {
                    "sent": "For example, here we would like to know if Caramail also born in also has the type of a German writer.",
                    "label": 0
                },
                {
                    "sent": "Before we go to our.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Framework we would like to have an insight about the RDF graph to see what kind of knowledge source we can use.",
                    "label": 0
                },
                {
                    "sent": "The first is.",
                    "label": 0
                },
                {
                    "sent": "Knowledge base which includes existing triples and the new triples derived from deductive reasoning.",
                    "label": 1
                },
                {
                    "sent": "Example in this graph is we know that God born in Frankfurt and Frankfurt located in Germany.",
                    "label": 0
                },
                {
                    "sent": "We can derive a GNU relation between greater and Germany that while the simple go reasoning.",
                    "label": 0
                },
                {
                    "sent": "Another knowledge source is the unstructured contextual info.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation which can be from the free text of wiki page pages and web pages, or the literals in the property values.",
                    "label": 1
                },
                {
                    "sent": "We shown in this graph has the introduction and those literals in the property value of introduction can be used as an structural contextual information.",
                    "label": 0
                },
                {
                    "sent": "And outside the RDF graph we can find some free text which is linked to the URL and this free test can also be used.",
                    "label": 0
                },
                {
                    "sent": "For making the confidence values for the possible relations.",
                    "label": 0
                },
                {
                    "sent": "So two.",
                    "label": 0
                },
                {
                    "sent": "Now we already explored all the possible knowledge sources around an even outside the RDF graph.",
                    "label": 0
                },
                {
                    "sent": "We want to do is of course make use of all the possible resources an now we first have a look at some common approach.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that make use of the unstructured information and knowledge base for relation prediction?",
                    "label": 0
                },
                {
                    "sent": "The first one is information extraction, which.",
                    "label": 1
                },
                {
                    "sent": "Extracts express the the information from the free text.",
                    "label": 0
                },
                {
                    "sent": "And then give confidence value about the truth of the relations.",
                    "label": 0
                },
                {
                    "sent": "There are some common IE system like.",
                    "label": 0
                },
                {
                    "sent": "Process file the NLP is simply search the free text and find the relevant sentence and then extract the structure data out of the unstructured information.",
                    "label": 0
                },
                {
                    "sent": "For example, before we wanted to know if Kamaile has the type of German writer, we can just search some free text and see if we can find some.",
                    "label": 0
                },
                {
                    "sent": "Terms of words that fixed this statement and then we can, based on the confidence of the NLP tool to derive a confidence value of the truth of the statement.",
                    "label": 0
                },
                {
                    "sent": "Another kind of AI system is reveur classifier based on the back of words or N grams and then give and predict how likely the relations is.",
                    "label": 0
                },
                {
                    "sent": "The second approach for relation prediction is deductive reasoning, which apply a set of assumes.",
                    "label": 1
                },
                {
                    "sent": "The existing relations.",
                    "label": 0
                },
                {
                    "sent": "And derive knew relations as I explained before.",
                    "label": 0
                },
                {
                    "sent": "There's a simple example.",
                    "label": 0
                },
                {
                    "sent": "In the knowledge base part.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "All the items for deductive reasoning generalize from some facts and then.",
                    "label": 0
                },
                {
                    "sent": "Limitaciones, we can't generalize everything, so deductive reasoning can only derive a subset of the unknown relations, and it's difficult to deal with uncertainty with deductive reasoning.",
                    "label": 1
                },
                {
                    "sent": "But things deductive reasoning.",
                    "label": 0
                },
                {
                    "sent": "Derive the results from some facts so it's more reliable.",
                    "label": 0
                },
                {
                    "sent": "1/3 common approach for relation prediction is machine learning.",
                    "label": 0
                },
                {
                    "sent": "Which learns the underlying statistical structure of the known relations and then found the correlation between the known relations and the unknown relations.",
                    "label": 1
                },
                {
                    "sent": "And in this way it can express statistical dependencies between relations and handle the incomplete data.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to combine all these three common approaches.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To make use of all the knowledge sources, including the context info, the unstructured information, and the knowledge base.",
                    "label": 1
                },
                {
                    "sent": "And we used an IE system to exploit the unstructured information and use deductive reasoning to exploit the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "And then we build a machine learning model on top to exploit the statistical dependencies among all the knowledge sources.",
                    "label": 0
                },
                {
                    "sent": "Now let's go to the framework before I explain it.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Framework I briefly.",
                    "label": 0
                },
                {
                    "sent": "Summarized how it worked.",
                    "label": 0
                },
                {
                    "sent": "First we we build a matrix to represent the RDF graph and then we used an IE system to extract information structure information.",
                    "label": 0
                },
                {
                    "sent": "And give the confidence value of the unknown relations and fill it to the metrics we built for the IDF graph.",
                    "label": 0
                },
                {
                    "sent": "After the E step, we apply the deductive reasoning step, which is independent of the the IE step for the deductive reasoning step.",
                    "label": 0
                },
                {
                    "sent": "We derive as possible as gnu triples from the known triples.",
                    "label": 0
                },
                {
                    "sent": "And then after this independent, these two independent steps, we combine them by a simple rule.",
                    "label": 0
                },
                {
                    "sent": "So based on the basic metrics we built for the original RDF graph, we already filled in some more entries from the IE system and deductive reasoning system.",
                    "label": 0
                },
                {
                    "sent": "But this system hasn't explored the statistical dependencies of the IE system, and deductive reasoning system.",
                    "label": 0
                },
                {
                    "sent": "Therefore we build a machine learning model on top of it.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Probably listed latent factor model.",
                    "label": 1
                },
                {
                    "sent": "And is in fact a probabilistic model, but it's related to matrix factorization.",
                    "label": 1
                },
                {
                    "sent": "So we factorize the metrics we derive from the eastep and the deductive reasoning step, and then we complete metrics.",
                    "label": 0
                },
                {
                    "sent": "So for each of after completion, the metrics is complete full, we can derive all the confidence values for the possible triples.",
                    "label": 0
                },
                {
                    "sent": "Now let's go to the detail of the framework.",
                    "label": 0
                },
                {
                    "sent": "First, is the matrix representation for the RDF graph we.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Construct the matrix X from the RDF graph, where each row represents the subject in which column represents predicate object pair.",
                    "label": 0
                },
                {
                    "sent": "And we fill in the entry.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As with one where each entry corresponds to a link in the RDF graph.",
                    "label": 1
                },
                {
                    "sent": "For example, let's have a look at the entry one with purple background.",
                    "label": 0
                },
                {
                    "sent": "It represents the link in the added RDF graph.",
                    "label": 0
                },
                {
                    "sent": "That good is the type of German writer.",
                    "label": 0
                },
                {
                    "sent": "And the entry one with Orange background represents the fact the link in the IDF graph that get a born year 1949.",
                    "label": 0
                },
                {
                    "sent": "Of course we will not directly use the year as a feature in the metrics because that's too specific.",
                    "label": 0
                },
                {
                    "sent": "We generalize it to 18th century.",
                    "label": 0
                },
                {
                    "sent": "An after building the basic metrics, we started to fill.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the metrics, the first step is the IE step.",
                    "label": 0
                },
                {
                    "sent": "In principle, any AI system can be used.",
                    "label": 1
                },
                {
                    "sent": "We don't specify any specialized system, but in our experiment we build a classifier to predict the confidence value of the unknown relations.",
                    "label": 0
                },
                {
                    "sent": "So we extract the wiki pages.",
                    "label": 0
                },
                {
                    "sent": "The free text from the wiki pages about good Camel, an also German writer, Ann French writer, American writer.",
                    "label": 0
                },
                {
                    "sent": "We put all these words.",
                    "label": 0
                },
                {
                    "sent": "Into the classifier an learn a model and predict.",
                    "label": 0
                },
                {
                    "sent": "The confidence value.",
                    "label": 0
                },
                {
                    "sent": "About how, how likely that go to.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the French writer or, with the German writer?",
                    "label": 0
                },
                {
                    "sent": "So this is the first step, IE step and the second step.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But completely independent of the first step is deductive reasoning step.",
                    "label": 0
                },
                {
                    "sent": "When we build a basic metrics, we already fill in the entries that is corresponding to a triple in RDF graph.",
                    "label": 0
                },
                {
                    "sent": "So what we need to do now is since the eastep is independent of the deductive reasoning step, we now go back to the basic metrics, but we want to derive more.",
                    "label": 0
                },
                {
                    "sent": "And triples based on the existing triples.",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at the.",
                    "label": 0
                },
                {
                    "sent": "Orange so let's have a look at the entries with green background, which indicates good born in Frankfurt and Frankfurt, located in Germany.",
                    "label": 0
                },
                {
                    "sent": "From this we apply the go reasoning and we derive a new triple or.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elation that Gator born in Germany.",
                    "label": 0
                },
                {
                    "sent": "And things.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So don't be ducted reasoning step.",
                    "label": 0
                },
                {
                    "sent": "We only add one entry and the entry is we added is not related to the entries that we wanted to know about the writers nationality.",
                    "label": 0
                },
                {
                    "sent": "So after the deductive reason is that we did we derive these metrics.",
                    "label": 0
                },
                {
                    "sent": "Many zeros and only one of the known triple.",
                    "label": 0
                },
                {
                    "sent": "To summarize, the first 2 steps we can see that the first matrix is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we got from the Eastep and the second metrics is what we got from the deductive reasoning step an we simply apply a rule to combine them.",
                    "label": 0
                },
                {
                    "sent": "The rule is just pick the most confident one.",
                    "label": 0
                },
                {
                    "sent": "This is simple, but it makes sense because it will keep the one from the deductive reasoning which is quite reliable.",
                    "label": 0
                },
                {
                    "sent": "And if the deductive reasoning cannot give us any information, we can supplement it from the IE system.",
                    "label": 0
                },
                {
                    "sent": "So two, now we already fill in the information that we can get from the.",
                    "label": 0
                },
                {
                    "sent": "IE system and deductive reasoning.",
                    "label": 0
                },
                {
                    "sent": "But we haven't exploit a statistical dependency.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Between the different knowledge sources, because IE system is exploits the unstructured information and deductive reasoning exploit the knowledge based source.",
                    "label": 0
                },
                {
                    "sent": "So we need to build a probabilistic model on top to exploit the dependencies.",
                    "label": 0
                },
                {
                    "sent": "Of these two.",
                    "label": 0
                },
                {
                    "sent": "Different approaches.",
                    "label": 0
                },
                {
                    "sent": "The idea is we map.",
                    "label": 0
                },
                {
                    "sent": "The confidence value that the relation is true given the IE system and the deductive reasoning to continuous continuous value F. Using.",
                    "label": 0
                },
                {
                    "sent": "The inverse of a symbolic function, which is very simple function that the original confidence value has the value between zero and one.",
                    "label": 0
                },
                {
                    "sent": "And now we met it too and.",
                    "label": 0
                },
                {
                    "sent": "F which has a value from negative infinite to positive infinite.",
                    "label": 0
                },
                {
                    "sent": "This can be the value generated from a noisy standard Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "Therefore, we need to have cleaning version of F to get the cleaning version of F. We first assume that for each subject entity, we introduce low dimension.",
                    "label": 1
                },
                {
                    "sent": "No latent variable hi, which follows the.",
                    "label": 0
                },
                {
                    "sent": "Standard Gaussian distribution and then for each subject entity EI, an Alpha is generated and Alpha is the linear combination of the low dimensional latent variable hi.",
                    "label": 1
                },
                {
                    "sent": "And it's also the cleaning version of F. And this probably listed model is related to matrix factorization and the solution for Alpha is maximized if we calculate it in this way and I'm not going to go into the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tell if someone is interesting, can have a look at our paper.",
                    "label": 0
                },
                {
                    "sent": "And this Alpha is related to the subject entity I.",
                    "label": 0
                },
                {
                    "sent": "And remind that before we map the confidence value.",
                    "label": 0
                },
                {
                    "sent": "Of confidence value.",
                    "label": 0
                },
                {
                    "sent": "Of the truth of the statement given the IE system and deductive reasoning via inverse of Sigma.",
                    "label": 0
                },
                {
                    "sent": "So now we need to change transform back to get a value that fits to the range between zero and one and then this value is exactly the confidence value of the truth of the statement given IE system and deductive reasoning and machine learning.",
                    "label": 0
                },
                {
                    "sent": "So we nicely solve all solve the relation prediction problem in one model.",
                    "label": 0
                },
                {
                    "sent": "Simple and effective.",
                    "label": 0
                },
                {
                    "sent": "Now we evaluate our method with two experiments.",
                    "label": 0
                },
                {
                    "sent": "The first experiment is done on the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In disease data set, the target is forgiven.",
                    "label": 0
                },
                {
                    "sent": "Genes.",
                    "label": 0
                },
                {
                    "sent": "We would like to.",
                    "label": 0
                },
                {
                    "sent": "Recommend the disease that is most likely related to these jeans and this task makes sense for the medical diagnosis because the relations between genes and disease always very complicated and hard to express by simple logical expression and our method can predict any confidence value for the possible relations.",
                    "label": 0
                },
                {
                    "sent": "So we just use our model to evaluate this.",
                    "label": 0
                },
                {
                    "sent": "And the data is from the link open data more in detail is the link life data and bio two RDF data.",
                    "label": 1
                },
                {
                    "sent": "There we extract more than 2000 genes and more than 300 diseases.",
                    "label": 0
                },
                {
                    "sent": "And we built three models.",
                    "label": 0
                },
                {
                    "sent": "The first one is the IE system.",
                    "label": 0
                },
                {
                    "sent": "The IE system is built based on only the literals from the property values like the comments of the disease or jeans and the nodes of the disease origins.",
                    "label": 0
                },
                {
                    "sent": "And the Y system here is quite poor as we can see and then we build another model, the machine learning model which only use the known relations between genes and disease and this model is still not good enough.",
                    "label": 0
                },
                {
                    "sent": "And then we simply add the IE system to the machine learning like what we did before.",
                    "label": 0
                },
                {
                    "sent": "But here we don't have deductive reasoning because because we don't have the background knowledge.",
                    "label": 0
                },
                {
                    "sent": "And then we found after we combine them, we got a 5% improvement.",
                    "label": 0
                },
                {
                    "sent": "And this result is competitive to a state of art, gene disease relationship discovery tool called top gene suit.",
                    "label": 0
                },
                {
                    "sent": "And second experiment is done on YAGO two data.",
                    "label": 0
                },
                {
                    "sent": "And our target is.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To predict the writer's nationality.",
                    "label": 0
                },
                {
                    "sent": "So we built 5 models.",
                    "label": 0
                },
                {
                    "sent": "First one is machine learning model.",
                    "label": 0
                },
                {
                    "sent": "We only use.",
                    "label": 0
                },
                {
                    "sent": "The writers as the subject and then use the countries.",
                    "label": 0
                },
                {
                    "sent": "As the object and then we based on this a relation relationships metrics we.",
                    "label": 0
                },
                {
                    "sent": "We learn the machine learning model and then predict the confidence value of the truth of the relations.",
                    "label": 0
                },
                {
                    "sent": "And this is also related to to the subgraph I shown before.",
                    "label": 0
                },
                {
                    "sent": "And we can see that the machine learning model is quite poor and.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The next model is the IE system, which is quite strong.",
                    "label": 0
                },
                {
                    "sent": "The reason is as before, for the machine learning model, we only use the writer and their nationality and also the birthplace.",
                    "label": 0
                },
                {
                    "sent": "But the birthplace has is not has not so strong correlation to the nationality of the writer because someone can be born in one place and later became a writer in another place.",
                    "label": 0
                },
                {
                    "sent": "And this information can only be.",
                    "label": 0
                },
                {
                    "sent": "Retrieve by ID system because most likely in the wiki page we it's written that this author when he was young his.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "He's somewhere in in one country and later he became a writer in another country.",
                    "label": 0
                },
                {
                    "sent": "Also, there's another problem that is not.",
                    "label": 0
                },
                {
                    "sent": "One writer is not assigned to 1 country.",
                    "label": 0
                },
                {
                    "sent": "Some writers can have more than one nationalities.",
                    "label": 0
                },
                {
                    "sent": "In this case we can only get the information from the IE system.",
                    "label": 0
                },
                {
                    "sent": "So I hear is very strong, but.",
                    "label": 0
                },
                {
                    "sent": "And we have a false model.",
                    "label": 0
                },
                {
                    "sent": "The machine learning aggregating with.",
                    "label": 0
                },
                {
                    "sent": "The country of the birth place.",
                    "label": 1
                },
                {
                    "sent": "While the gear reasoning and this performance already.",
                    "label": 0
                },
                {
                    "sent": "Better than the pure machine learning model.",
                    "label": 0
                },
                {
                    "sent": "And finally, the combination of or as we propose is the best.",
                    "label": 0
                },
                {
                    "sent": "This experiment nicely show that our framework that combine all the knowledge source sources works.",
                    "label": 0
                },
                {
                    "sent": "So to conclude, we.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, explore that all the possible knowledge sources around an incentive graph, and we also exploit the possible approaches for relation prediction.",
                    "label": 0
                },
                {
                    "sent": "And then we just combine all of these and use the IE to exploit the unstructured information.",
                    "label": 1
                },
                {
                    "sent": "Use deductive reasoning to exploit the systematic knowledge and use machine learning to exploit the statistical patterns on top.",
                    "label": 0
                },
                {
                    "sent": "And this model is very efficient because it's a one step model, we just put everything in as a pre processing an from the IE system and deductive reasoning and then we just factorize the metrics.",
                    "label": 0
                },
                {
                    "sent": "And then everything is done.",
                    "label": 0
                },
                {
                    "sent": "That's all, thanks.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}