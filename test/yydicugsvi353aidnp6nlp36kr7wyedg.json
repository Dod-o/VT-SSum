{
    "id": "yydicugsvi353aidnp6nlp36kr7wyedg",
    "title": "Multistream Recognition of Dialogue Acts in Meetings",
    "info": {
        "author": [
            "Alfred Dielmann, University of Edinburgh"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "May 2006",
        "category": [
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/mlmi06_dielmann_mrdam/",
    "segmentation": [
        [
            "Well, in this talk we will propose a framework for the automatic recognition of Dialogue Act in Natural Multi Party meetings.",
            "First of all, we will define the delegate recognition task.",
            "We will give a brief description of the meeting data corpus that we use in."
        ],
        [
            "In this work, and we will provide an overview of the Dialogue Act recognition system and it's."
        ],
        [
            "Components.",
            "Moreover, we will discuss some experimental results.",
            "Delegates are really useful to extract information from the discourse structure.",
            "Of multi party meetings and they can be used in many other research areas like automatic meeting face detection or automatic summarization or topic detection and the overall aim is to provide the system for the automatic meetings structure and to facilitate."
        ],
        [
            "Meeting browsing.",
            "Dialogue acts are the building blocks of a conversation.",
            "Since they reflect the function that utterances serving and discourse, and they can be.",
            "Annotated with several different coding schemes that can be targeted on on different aspects of their conversational process.",
            "Or they can simply define different number of the labels."
        ],
        [
            "Here we use the exhibiting corpus, which is a terror genius set of of.",
            "Of meetings, both in terms of content and structure, and it's fully annotated in term of dialogue.",
            "Act for using the meeting Recorder Dialogue Scheme, which unfortunately leads to more than 2000 unique gay labels, which means that the distribution is really imbalanced.",
            "Hopefully EXE provides also a set of.",
            "Automatic mappings from this full set of annotation to some."
        ],
        [
            "Reduce site.",
            "We use a one of these mapping which leads to 5 Broadway Hockey goalies.",
            "Like statements, questions Backchannel fillers and disruption, an.",
            "The distribution of these classes are.",
            "Steely imbalance, but this situation it's much better than using the full are the annotation scheme statements are the most frequent via units and back channel are the shortest one.",
            "In order to have.",
            "Hey compatible compatible result.",
            "We used the same data said subdivision used by hand and colleagues.",
            "Then we used 51 meetings for training, 11 for development and 11 for testing purposes."
        ],
        [
            "We are interested in a joint approach in which we perform dialogue segmentation and classification.",
            "Currently in single step instead of doing it sequentially.",
            "We use the generative approach in which he then dialogue acts, generate a responsible for sequence of words.",
            "And our system is based on a on a turning ball statistical model ADB and which is used to integrate and coordinate.",
            "Some other subsystem like factor language model which is used to model word sequence of words in the units an we also use the discourse model which is a trigram language model built on sequences of the labels and a set of six word related continuous features which are mainly used."
        ],
        [
            "Used for segmentation.",
            "This is a.",
            "Inform the slide show the information flow in our system.",
            "The multi Channel audio recordings are used to extract 6 continued work related features and also to field an automatic speech recognizer which will provide transcriptions.",
            "And the transcription are used by the factor language models and work.",
            "Temporal boundaries are used by the feature extraction block as mentioned before.",
            "The discourse model is still doing training on the sequence of the labels.",
            "Both of the models in the future are integrated by the DBN infrastructure, which will provide the sequence of the segments an their corresponding."
        ],
        [
            "Billings the tagging it's performing tirolian lexical features they on on.",
            "Yeah on the lexical information using the factor language model and the discourse smaller whatever the segmentation.",
            "It's mainly based on on.",
            "Word related fee on word elated features."
        ],
        [
            "We performed some experiments using both their reference transcription and also using the output of automatic speech recognition.",
            "Our goal is to estimate the degradation of using an imperfect transcription into the recognition output.",
            "We use the transcription provided by the Army ASR team, which is a baseline system for the corpus and entirely trained on exceed data by using a cross fold validation technique.",
            "They were rate is about 29% which is.",
            "Well, it's good for our experiment."
        ],
        [
            "The feature are extracted from roll your recording.",
            "We extracted Peach using SPS algorithm.",
            "We extracted the energy and we normalize it by using the typical energy for each term, work length and posed interworld.",
            "Posed variations are estimated from the temporal boundaries of world which are.",
            "Provided by the ASR output or by force alignment of reference transcription against the audio recordings and they were relevansi.",
            "It's the ratio between the local term frequency and the absolute term frequency and is close to 1 four."
        ],
        [
            "In most relevant words, we use the factor language model to map.",
            "Sequence of words into dialogue acts and this kind of language model is the generalization of standard language model in which words are replaced by bundles of bundles of words and feature which are used, usually referred as factors.",
            "Practically everything can be considered as a fact or stuff like part of speech tags, the work themselves, or even morphological classes, the unit, and so the goal is like in standard language modeling is to factorize the joint probability associated to a sentence.",
            "Now the factorization will be made in in terms of factor related conditional probabilities.",
            "Yeah."
        ],
        [
            "In order to compare different factor language models, we use a simplified date tagging task.",
            "And we integrate a simple DNA daggering to sin and took it.",
            "And in this table there.",
            "The result achieved using our best FL and model and 3D fan testing condition using a model train arrive and Sentinel reference trained on reference in testing on the ASR and trained and tested on ASR."
        ],
        [
            "We enough.",
            "In fact our language model.",
            "There are three degree of freedom it's possible to to play with the factors and we tried to be many different factors like of course the Dialogue Act labels, but also meeting types.",
            "The relative position of words into sentences, powerful speech labels, worse times and so on.",
            "It's also possible to play with the factorisation and here there are few.",
            "Example of this and also it is possible to choose proper discount discounting strategy.",
            "Anne.",
            "This is shows just as an example of.",
            "So few of."
        ],
        [
            "Another that we tried.",
            "The Libyans are.",
            "Are directed probabilistic graphical models which use nodes to represent the random variables and direct parks in order to represent their conditional independences.",
            "Sorry this one where BS where DPS are the extension of BS.",
            "In order to process data sequences or time series.",
            "In practice these as BN for each temporal slice and the slices are connected together with some.",
            "Parks.",
            "Switching the BSR.",
            "Filter extension of deviance, which are able to change their topology in according to the state of some internal variables which are referred as switching nodes."
        ],
        [
            "In this model in in this study we used.",
            "A switching Debian model which is based on two different working condition.",
            "Did this node called DA Boundary detector which switch between these two operative states in?",
            "And to each operative condition corresponda models tapology.",
            "This one, which is operate within the units and it assumes that the the word sequence it's it's part of single day unit and it takes care of updating the joint sentence probability estimates by using the FLM.",
            "It also takes care of updating some deterministic variable which are used by the LM.",
            "The rest of the.",
            "The frustra"
        ],
        [
            "The second.",
            "Operative State is the one in which.",
            "A boundary between two different.",
            "You need to gear units is likely to be to be present.",
            "In this case, the model will take care of.",
            "Managing their transition between the two different units integrate by integrating the discourse model probability and it takes care of updating the DNA recognition history, and it also takes care of.",
            "Starting the evaluation of a new set of the importances.",
            "This state of DDA mandaree detector is estimated doing both the operative."
        ],
        [
            "As you can see in this picture.",
            "It's estimate, sorry, it's estimated.",
            "From the work related continuous features through a Gaussian mixture model, but is also related to.",
            "The.",
            "We were relative position in the sentence and is also related to the DNA recognition history.",
            "As you can see, both within and.",
            "I don't know what happened with this one.",
            "If you can see the estimation of the PDA.",
            "In the same we both doing the.",
            "Topology which is used within the units and the.",
            "The cross boundary topology.",
            "Anne."
        ],
        [
            "If that.",
            "The.",
            "The evaluation of Dialogue Act tagging straightforward because it's possible to estimate the to count the number of correctly recognized the units.",
            "The same cannot be said about segmentation and recognition of dialogue act.",
            "First segmentation, we used since it is possible to define different kind of evaluation matrix in here for segmentation we use the nice sentence like unit metric which is practically the sum of of the.",
            "Is the boundaries and false alarms?",
            "Score against the reference du means for recognition we used the extended version of Nice to see you with the added condition that recognized the.",
            "Segments must also the.",
            "Have a label that matched the reference transcription.",
            "We also use this acid like metric with, which is practically the word error rate used in speech recognition, with were replaced by the unit.",
            "An alien metric weave.",
            "We take into account the percentage of correctly classified words, but ignoring completely the."
        ],
        [
            "The boundaries.",
            "These are the result for the day packing task.",
            "We use the model shown before.",
            "And we imposed the ground through segmentation by forcing the boundary detector node.",
            "And as you can see there.",
            "The tagging results are improved by about 5% if compared with the previous result on the on the FLM.",
            "Evaluation and they are.",
            "Anyway, better than doing the tagging by chance or by chance and.",
            "Providing and drawing the the unit and according to the prior distribution or.",
            "Labeling everything as a statement since statement are their most frequent units.",
            "The second table shows the.",
            "The nice issue.",
            "Automatic segmentation results which are close to the state of the art in the reference transcription in the experiment made on reference transcriptions, we can say that.",
            "The the the interval poses played a key role in the automatic."
        ],
        [
            "Segmentation.",
            "These are the results on on the recognition task.",
            "And the all the metrics show a consistent behavior and the.",
            "Most impor aging results are the one on ASR output.",
            "In particular, the system trained on ASR and tested on ASR work works better than the one train or reference transcription and tested on ASR.",
            "We policy parries because of mismatch between the two Dictionary of the recognizer and of the automatic of the reference transcriptions at work leave."
        ],
        [
            "To conclude, we have addressed the task of the automatic recognition of five brodier categories, make proposing a switch in Debian based approach which is used to integrate.",
            "And I further genius set of technologies like like factor language models and continuous features.",
            "This graphical approach encouraged the reuse of common resources and the joint approach operating on a wide search space make possible.",
            "To achieve better result if compared with the sequential approach."
        ],
        [
            "About the result, we can say that there is still a gap between the DNA tagging perform using factor language model.",
            "An approach is like my maximum entropy classification.",
            "About the.",
            "The recognition result we have.",
            "Decent low recognition, error rate.",
            "In particular, we have good recognition with the ASR output, in which 29% of word error rate leads to less than 10% in degradation in the derecognition output.",
            "We are currently working on on the Army meeting corpus using 17 D 8 classes instead of five.",
            "We are still working on the.",
            "Factor language model and we are expecting to integrate some multimodal features into the DNA recognition process.",
            "Moreover, our plan is to integrate the automatic derecognition output into other.",
            "Research areas like the automatic detection of meeting action or in the automatic summarization of meetings, that's all.",
            "Christian."
        ],
        [
            "So it is kind of interesting that that you get better, read less degradation when you have ASR input.",
            "Have you at all looked at the error patterns by looking at the confusion matrices to see if the patterns are the same across?",
            "Was two kinds of inputs?",
            "Transcripts versus So what kind of error patterns are you seeing?",
            "Not not this kind of error pattern, but usability having done it, confuse ability matrix.",
            "Another confuse ability.",
            "Matrices similar confuse ability of what you mean of the different.",
            "So the errors, right, right when you have an error, you're recognizing either something is amount of that or is one of the other dial.",
            "Again did not do it in the test, but I notice that, but I think it would be interesting to look at that yeah?",
            "The computer matrices, but it would be interesting if the patterns were similar across is you often do see that some of those other methods are so much tuning on the words.",
            "If you missed the word then you're just not going to get it.",
            "Author notices that, for example, in the in the reference transcription, maybe they are worldly like transcription, but in the in the ASR dictionary translation is not there and there is trans transcript, but it's likely that they recognized tend to miss recognize transcription with transcript.",
            "And maybe this done is not so important for a statistical approach in which we are.",
            "We don't care about the meaning of words, they are just symbols.",
            "But it's my theory.",
            "I'm talking about statistical approaches and they still have a degradation when it's a much bigger degradation.",
            "When you go to ASR input.",
            "All your pictures are word features, right?",
            "So, for example, sentence boundary detection, Yahoo system.",
            "You basically look at reference transcripts versus ASR input.",
            "You take a big hit, especially on the word error on the word features.",
            "You're making a lot more mistakes due to the word features.",
            "Probably model helps a little bit to make up for it.",
            "These feel a significant gap within reference, transcription and ASR.",
            "What seems to work better in when they say it was an advantage of your system that you are taking, that you are more robust ASR error?",
            "And yet you're using all word features, but it's just curious to me because I think more more systems take the big hit weather when there were only features an ASR input.",
            "But anyway, something about that muscle.",
            "The next question.",
            "As you proposed, joint segmentation and classification of dialogue acts, and you're such a comprehensive system.",
            "Did you also try to 1st segment and then classify in order to show that the joint approach actually is better than the sequential approach?",
            "No, I didn't write.",
            "No.",
            "And then the second question would be about the error metrics.",
            "I'm slightly confused about joint error metrics.",
            "I I did some of the work as if you look at the classification of Dialogue Act, it seems to be extremely important to get the beginning at both the beginning and the end right in segmentation in order to reliably classify and the metrics I see here, they don't pay attention to boundaries except for the newest one that actually looks with boundaries.",
            "But this is kind of local so.",
            "If you have a correct boundary in one place, it does not take into account if the beginning of that dialogue act was also correctly segmented or not OK. More results are using those other metrics.",
            "I remove them.",
            "OK.",
            "Thank you.",
            "An email sent this by Mr on your side.",
            "You said that you are normalizing the duration between words in your feature extraction system.",
            "That component I'm just curious, how do you normalize the durations between words?",
            "What is the normalization that you're using?",
            "When the the word lanther.",
            "It normalized by the the typical duration for for that term.",
            "For example, if we spoke a word, I don't know the word transcription, it will be.",
            "Normalized by the usual length of the word transcription, it's OK.",
            "I actually what I was asking about is I got the impression that one of your features was deposit duration between words.",
            "OK, no, they are not normalized.",
            "They're just pre scaling for practical reasons.",
            "Alright, thank you.",
            "Actually wondering what the point is of finding these dialogue, acts, statements, questions and filled pauses.",
            "I cannot imagine myself looking for those in a meeting as opposed to things like draw vessel, discourse styles and things like that.",
            "We had to study close these couple of years ago.",
            "Did this on meeting records and found actually things like usual listen.",
            "So I'm quite helpful but dialogue acts but not particularly.",
            "I don't image indirectly used tool to be honest.",
            "But maybe they can be helpful to to improve language modeling for ASR or to improve summarization.",
            "And maybe they can also correlate with something more high level like meeting phases.",
            "But anyway, it's.",
            "I agree that having for example in meeting browser we've highlighted segments of statement questions.",
            "It's is not so useful then.",
            "So.",
            "It's just a brick in the the the.",
            "System for the automatic meeting structure in math.",
            "So some product, not a final user.",
            "My question is that you do the the 70s and the recognitions meeting but actually do not use any feature across speakers such as in a meeting.",
            "I'm manager said before meeting.",
            "Do you have any concerns or questions?",
            "So this is a question and then several participants will give the questions.",
            "So if you can use such information the feature set.",
            "Probably don't get your waist, but you are saying that the feature extracted for all the participants.",
            "Yes, he yes.",
            "Well we are.",
            "We we we working on this stream of war and we we.",
            "It's like if we merged together.",
            "The transcription just won.",
            "Three more sentences.",
            "And anyway, it's part of the.",
            "Desegmentation and I don't know.",
            "I'm asking if you have sickle on using cross speaker cross channel features actually collected at dialogue content such as sort of the telephone as much as you like using hopefully lower cost.",
            "Because you do not use any cross channel information.",
            "No.",
            "With something like an easy try.",
            "Yeah.",
            "OK central, once again office.",
            "We had."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, in this talk we will propose a framework for the automatic recognition of Dialogue Act in Natural Multi Party meetings.",
                    "label": 1
                },
                {
                    "sent": "First of all, we will define the delegate recognition task.",
                    "label": 0
                },
                {
                    "sent": "We will give a brief description of the meeting data corpus that we use in.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this work, and we will provide an overview of the Dialogue Act recognition system and it's.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Components.",
                    "label": 0
                },
                {
                    "sent": "Moreover, we will discuss some experimental results.",
                    "label": 0
                },
                {
                    "sent": "Delegates are really useful to extract information from the discourse structure.",
                    "label": 0
                },
                {
                    "sent": "Of multi party meetings and they can be used in many other research areas like automatic meeting face detection or automatic summarization or topic detection and the overall aim is to provide the system for the automatic meetings structure and to facilitate.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Meeting browsing.",
                    "label": 0
                },
                {
                    "sent": "Dialogue acts are the building blocks of a conversation.",
                    "label": 1
                },
                {
                    "sent": "Since they reflect the function that utterances serving and discourse, and they can be.",
                    "label": 1
                },
                {
                    "sent": "Annotated with several different coding schemes that can be targeted on on different aspects of their conversational process.",
                    "label": 0
                },
                {
                    "sent": "Or they can simply define different number of the labels.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we use the exhibiting corpus, which is a terror genius set of of.",
                    "label": 0
                },
                {
                    "sent": "Of meetings, both in terms of content and structure, and it's fully annotated in term of dialogue.",
                    "label": 1
                },
                {
                    "sent": "Act for using the meeting Recorder Dialogue Scheme, which unfortunately leads to more than 2000 unique gay labels, which means that the distribution is really imbalanced.",
                    "label": 1
                },
                {
                    "sent": "Hopefully EXE provides also a set of.",
                    "label": 0
                },
                {
                    "sent": "Automatic mappings from this full set of annotation to some.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reduce site.",
                    "label": 0
                },
                {
                    "sent": "We use a one of these mapping which leads to 5 Broadway Hockey goalies.",
                    "label": 0
                },
                {
                    "sent": "Like statements, questions Backchannel fillers and disruption, an.",
                    "label": 0
                },
                {
                    "sent": "The distribution of these classes are.",
                    "label": 0
                },
                {
                    "sent": "Steely imbalance, but this situation it's much better than using the full are the annotation scheme statements are the most frequent via units and back channel are the shortest one.",
                    "label": 0
                },
                {
                    "sent": "In order to have.",
                    "label": 0
                },
                {
                    "sent": "Hey compatible compatible result.",
                    "label": 0
                },
                {
                    "sent": "We used the same data said subdivision used by hand and colleagues.",
                    "label": 0
                },
                {
                    "sent": "Then we used 51 meetings for training, 11 for development and 11 for testing purposes.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are interested in a joint approach in which we perform dialogue segmentation and classification.",
                    "label": 1
                },
                {
                    "sent": "Currently in single step instead of doing it sequentially.",
                    "label": 1
                },
                {
                    "sent": "We use the generative approach in which he then dialogue acts, generate a responsible for sequence of words.",
                    "label": 0
                },
                {
                    "sent": "And our system is based on a on a turning ball statistical model ADB and which is used to integrate and coordinate.",
                    "label": 0
                },
                {
                    "sent": "Some other subsystem like factor language model which is used to model word sequence of words in the units an we also use the discourse model which is a trigram language model built on sequences of the labels and a set of six word related continuous features which are mainly used.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Used for segmentation.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "Inform the slide show the information flow in our system.",
                    "label": 0
                },
                {
                    "sent": "The multi Channel audio recordings are used to extract 6 continued work related features and also to field an automatic speech recognizer which will provide transcriptions.",
                    "label": 1
                },
                {
                    "sent": "And the transcription are used by the factor language models and work.",
                    "label": 1
                },
                {
                    "sent": "Temporal boundaries are used by the feature extraction block as mentioned before.",
                    "label": 0
                },
                {
                    "sent": "The discourse model is still doing training on the sequence of the labels.",
                    "label": 0
                },
                {
                    "sent": "Both of the models in the future are integrated by the DBN infrastructure, which will provide the sequence of the segments an their corresponding.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Billings the tagging it's performing tirolian lexical features they on on.",
                    "label": 0
                },
                {
                    "sent": "Yeah on the lexical information using the factor language model and the discourse smaller whatever the segmentation.",
                    "label": 0
                },
                {
                    "sent": "It's mainly based on on.",
                    "label": 0
                },
                {
                    "sent": "Word related fee on word elated features.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We performed some experiments using both their reference transcription and also using the output of automatic speech recognition.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to estimate the degradation of using an imperfect transcription into the recognition output.",
                    "label": 1
                },
                {
                    "sent": "We use the transcription provided by the Army ASR team, which is a baseline system for the corpus and entirely trained on exceed data by using a cross fold validation technique.",
                    "label": 0
                },
                {
                    "sent": "They were rate is about 29% which is.",
                    "label": 0
                },
                {
                    "sent": "Well, it's good for our experiment.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The feature are extracted from roll your recording.",
                    "label": 0
                },
                {
                    "sent": "We extracted Peach using SPS algorithm.",
                    "label": 0
                },
                {
                    "sent": "We extracted the energy and we normalize it by using the typical energy for each term, work length and posed interworld.",
                    "label": 0
                },
                {
                    "sent": "Posed variations are estimated from the temporal boundaries of world which are.",
                    "label": 0
                },
                {
                    "sent": "Provided by the ASR output or by force alignment of reference transcription against the audio recordings and they were relevansi.",
                    "label": 0
                },
                {
                    "sent": "It's the ratio between the local term frequency and the absolute term frequency and is close to 1 four.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In most relevant words, we use the factor language model to map.",
                    "label": 0
                },
                {
                    "sent": "Sequence of words into dialogue acts and this kind of language model is the generalization of standard language model in which words are replaced by bundles of bundles of words and feature which are used, usually referred as factors.",
                    "label": 0
                },
                {
                    "sent": "Practically everything can be considered as a fact or stuff like part of speech tags, the work themselves, or even morphological classes, the unit, and so the goal is like in standard language modeling is to factorize the joint probability associated to a sentence.",
                    "label": 1
                },
                {
                    "sent": "Now the factorization will be made in in terms of factor related conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to compare different factor language models, we use a simplified date tagging task.",
                    "label": 1
                },
                {
                    "sent": "And we integrate a simple DNA daggering to sin and took it.",
                    "label": 1
                },
                {
                    "sent": "And in this table there.",
                    "label": 0
                },
                {
                    "sent": "The result achieved using our best FL and model and 3D fan testing condition using a model train arrive and Sentinel reference trained on reference in testing on the ASR and trained and tested on ASR.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We enough.",
                    "label": 0
                },
                {
                    "sent": "In fact our language model.",
                    "label": 0
                },
                {
                    "sent": "There are three degree of freedom it's possible to to play with the factors and we tried to be many different factors like of course the Dialogue Act labels, but also meeting types.",
                    "label": 0
                },
                {
                    "sent": "The relative position of words into sentences, powerful speech labels, worse times and so on.",
                    "label": 0
                },
                {
                    "sent": "It's also possible to play with the factorisation and here there are few.",
                    "label": 0
                },
                {
                    "sent": "Example of this and also it is possible to choose proper discount discounting strategy.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This is shows just as an example of.",
                    "label": 0
                },
                {
                    "sent": "So few of.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another that we tried.",
                    "label": 0
                },
                {
                    "sent": "The Libyans are.",
                    "label": 0
                },
                {
                    "sent": "Are directed probabilistic graphical models which use nodes to represent the random variables and direct parks in order to represent their conditional independences.",
                    "label": 1
                },
                {
                    "sent": "Sorry this one where BS where DPS are the extension of BS.",
                    "label": 1
                },
                {
                    "sent": "In order to process data sequences or time series.",
                    "label": 0
                },
                {
                    "sent": "In practice these as BN for each temporal slice and the slices are connected together with some.",
                    "label": 0
                },
                {
                    "sent": "Parks.",
                    "label": 0
                },
                {
                    "sent": "Switching the BSR.",
                    "label": 0
                },
                {
                    "sent": "Filter extension of deviance, which are able to change their topology in according to the state of some internal variables which are referred as switching nodes.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this model in in this study we used.",
                    "label": 0
                },
                {
                    "sent": "A switching Debian model which is based on two different working condition.",
                    "label": 0
                },
                {
                    "sent": "Did this node called DA Boundary detector which switch between these two operative states in?",
                    "label": 1
                },
                {
                    "sent": "And to each operative condition corresponda models tapology.",
                    "label": 0
                },
                {
                    "sent": "This one, which is operate within the units and it assumes that the the word sequence it's it's part of single day unit and it takes care of updating the joint sentence probability estimates by using the FLM.",
                    "label": 1
                },
                {
                    "sent": "It also takes care of updating some deterministic variable which are used by the LM.",
                    "label": 0
                },
                {
                    "sent": "The rest of the.",
                    "label": 0
                },
                {
                    "sent": "The frustra",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second.",
                    "label": 0
                },
                {
                    "sent": "Operative State is the one in which.",
                    "label": 1
                },
                {
                    "sent": "A boundary between two different.",
                    "label": 0
                },
                {
                    "sent": "You need to gear units is likely to be to be present.",
                    "label": 1
                },
                {
                    "sent": "In this case, the model will take care of.",
                    "label": 1
                },
                {
                    "sent": "Managing their transition between the two different units integrate by integrating the discourse model probability and it takes care of updating the DNA recognition history, and it also takes care of.",
                    "label": 1
                },
                {
                    "sent": "Starting the evaluation of a new set of the importances.",
                    "label": 0
                },
                {
                    "sent": "This state of DDA mandaree detector is estimated doing both the operative.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you can see in this picture.",
                    "label": 0
                },
                {
                    "sent": "It's estimate, sorry, it's estimated.",
                    "label": 0
                },
                {
                    "sent": "From the work related continuous features through a Gaussian mixture model, but is also related to.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "We were relative position in the sentence and is also related to the DNA recognition history.",
                    "label": 0
                },
                {
                    "sent": "As you can see, both within and.",
                    "label": 0
                },
                {
                    "sent": "I don't know what happened with this one.",
                    "label": 0
                },
                {
                    "sent": "If you can see the estimation of the PDA.",
                    "label": 0
                },
                {
                    "sent": "In the same we both doing the.",
                    "label": 0
                },
                {
                    "sent": "Topology which is used within the units and the.",
                    "label": 0
                },
                {
                    "sent": "The cross boundary topology.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If that.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The evaluation of Dialogue Act tagging straightforward because it's possible to estimate the to count the number of correctly recognized the units.",
                    "label": 0
                },
                {
                    "sent": "The same cannot be said about segmentation and recognition of dialogue act.",
                    "label": 0
                },
                {
                    "sent": "First segmentation, we used since it is possible to define different kind of evaluation matrix in here for segmentation we use the nice sentence like unit metric which is practically the sum of of the.",
                    "label": 0
                },
                {
                    "sent": "Is the boundaries and false alarms?",
                    "label": 1
                },
                {
                    "sent": "Score against the reference du means for recognition we used the extended version of Nice to see you with the added condition that recognized the.",
                    "label": 0
                },
                {
                    "sent": "Segments must also the.",
                    "label": 0
                },
                {
                    "sent": "Have a label that matched the reference transcription.",
                    "label": 0
                },
                {
                    "sent": "We also use this acid like metric with, which is practically the word error rate used in speech recognition, with were replaced by the unit.",
                    "label": 1
                },
                {
                    "sent": "An alien metric weave.",
                    "label": 1
                },
                {
                    "sent": "We take into account the percentage of correctly classified words, but ignoring completely the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The boundaries.",
                    "label": 0
                },
                {
                    "sent": "These are the result for the day packing task.",
                    "label": 0
                },
                {
                    "sent": "We use the model shown before.",
                    "label": 0
                },
                {
                    "sent": "And we imposed the ground through segmentation by forcing the boundary detector node.",
                    "label": 1
                },
                {
                    "sent": "And as you can see there.",
                    "label": 0
                },
                {
                    "sent": "The tagging results are improved by about 5% if compared with the previous result on the on the FLM.",
                    "label": 0
                },
                {
                    "sent": "Evaluation and they are.",
                    "label": 1
                },
                {
                    "sent": "Anyway, better than doing the tagging by chance or by chance and.",
                    "label": 1
                },
                {
                    "sent": "Providing and drawing the the unit and according to the prior distribution or.",
                    "label": 0
                },
                {
                    "sent": "Labeling everything as a statement since statement are their most frequent units.",
                    "label": 0
                },
                {
                    "sent": "The second table shows the.",
                    "label": 0
                },
                {
                    "sent": "The nice issue.",
                    "label": 0
                },
                {
                    "sent": "Automatic segmentation results which are close to the state of the art in the reference transcription in the experiment made on reference transcriptions, we can say that.",
                    "label": 1
                },
                {
                    "sent": "The the the interval poses played a key role in the automatic.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Segmentation.",
                    "label": 0
                },
                {
                    "sent": "These are the results on on the recognition task.",
                    "label": 0
                },
                {
                    "sent": "And the all the metrics show a consistent behavior and the.",
                    "label": 0
                },
                {
                    "sent": "Most impor aging results are the one on ASR output.",
                    "label": 0
                },
                {
                    "sent": "In particular, the system trained on ASR and tested on ASR work works better than the one train or reference transcription and tested on ASR.",
                    "label": 1
                },
                {
                    "sent": "We policy parries because of mismatch between the two Dictionary of the recognizer and of the automatic of the reference transcriptions at work leave.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To conclude, we have addressed the task of the automatic recognition of five brodier categories, make proposing a switch in Debian based approach which is used to integrate.",
                    "label": 1
                },
                {
                    "sent": "And I further genius set of technologies like like factor language models and continuous features.",
                    "label": 1
                },
                {
                    "sent": "This graphical approach encouraged the reuse of common resources and the joint approach operating on a wide search space make possible.",
                    "label": 1
                },
                {
                    "sent": "To achieve better result if compared with the sequential approach.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About the result, we can say that there is still a gap between the DNA tagging perform using factor language model.",
                    "label": 0
                },
                {
                    "sent": "An approach is like my maximum entropy classification.",
                    "label": 0
                },
                {
                    "sent": "About the.",
                    "label": 0
                },
                {
                    "sent": "The recognition result we have.",
                    "label": 0
                },
                {
                    "sent": "Decent low recognition, error rate.",
                    "label": 0
                },
                {
                    "sent": "In particular, we have good recognition with the ASR output, in which 29% of word error rate leads to less than 10% in degradation in the derecognition output.",
                    "label": 1
                },
                {
                    "sent": "We are currently working on on the Army meeting corpus using 17 D 8 classes instead of five.",
                    "label": 0
                },
                {
                    "sent": "We are still working on the.",
                    "label": 0
                },
                {
                    "sent": "Factor language model and we are expecting to integrate some multimodal features into the DNA recognition process.",
                    "label": 0
                },
                {
                    "sent": "Moreover, our plan is to integrate the automatic derecognition output into other.",
                    "label": 0
                },
                {
                    "sent": "Research areas like the automatic detection of meeting action or in the automatic summarization of meetings, that's all.",
                    "label": 0
                },
                {
                    "sent": "Christian.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it is kind of interesting that that you get better, read less degradation when you have ASR input.",
                    "label": 0
                },
                {
                    "sent": "Have you at all looked at the error patterns by looking at the confusion matrices to see if the patterns are the same across?",
                    "label": 0
                },
                {
                    "sent": "Was two kinds of inputs?",
                    "label": 0
                },
                {
                    "sent": "Transcripts versus So what kind of error patterns are you seeing?",
                    "label": 0
                },
                {
                    "sent": "Not not this kind of error pattern, but usability having done it, confuse ability matrix.",
                    "label": 0
                },
                {
                    "sent": "Another confuse ability.",
                    "label": 0
                },
                {
                    "sent": "Matrices similar confuse ability of what you mean of the different.",
                    "label": 0
                },
                {
                    "sent": "So the errors, right, right when you have an error, you're recognizing either something is amount of that or is one of the other dial.",
                    "label": 0
                },
                {
                    "sent": "Again did not do it in the test, but I notice that, but I think it would be interesting to look at that yeah?",
                    "label": 0
                },
                {
                    "sent": "The computer matrices, but it would be interesting if the patterns were similar across is you often do see that some of those other methods are so much tuning on the words.",
                    "label": 0
                },
                {
                    "sent": "If you missed the word then you're just not going to get it.",
                    "label": 0
                },
                {
                    "sent": "Author notices that, for example, in the in the reference transcription, maybe they are worldly like transcription, but in the in the ASR dictionary translation is not there and there is trans transcript, but it's likely that they recognized tend to miss recognize transcription with transcript.",
                    "label": 0
                },
                {
                    "sent": "And maybe this done is not so important for a statistical approach in which we are.",
                    "label": 0
                },
                {
                    "sent": "We don't care about the meaning of words, they are just symbols.",
                    "label": 0
                },
                {
                    "sent": "But it's my theory.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about statistical approaches and they still have a degradation when it's a much bigger degradation.",
                    "label": 0
                },
                {
                    "sent": "When you go to ASR input.",
                    "label": 0
                },
                {
                    "sent": "All your pictures are word features, right?",
                    "label": 0
                },
                {
                    "sent": "So, for example, sentence boundary detection, Yahoo system.",
                    "label": 0
                },
                {
                    "sent": "You basically look at reference transcripts versus ASR input.",
                    "label": 0
                },
                {
                    "sent": "You take a big hit, especially on the word error on the word features.",
                    "label": 0
                },
                {
                    "sent": "You're making a lot more mistakes due to the word features.",
                    "label": 0
                },
                {
                    "sent": "Probably model helps a little bit to make up for it.",
                    "label": 0
                },
                {
                    "sent": "These feel a significant gap within reference, transcription and ASR.",
                    "label": 0
                },
                {
                    "sent": "What seems to work better in when they say it was an advantage of your system that you are taking, that you are more robust ASR error?",
                    "label": 0
                },
                {
                    "sent": "And yet you're using all word features, but it's just curious to me because I think more more systems take the big hit weather when there were only features an ASR input.",
                    "label": 0
                },
                {
                    "sent": "But anyway, something about that muscle.",
                    "label": 0
                },
                {
                    "sent": "The next question.",
                    "label": 0
                },
                {
                    "sent": "As you proposed, joint segmentation and classification of dialogue acts, and you're such a comprehensive system.",
                    "label": 0
                },
                {
                    "sent": "Did you also try to 1st segment and then classify in order to show that the joint approach actually is better than the sequential approach?",
                    "label": 0
                },
                {
                    "sent": "No, I didn't write.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "And then the second question would be about the error metrics.",
                    "label": 0
                },
                {
                    "sent": "I'm slightly confused about joint error metrics.",
                    "label": 0
                },
                {
                    "sent": "I I did some of the work as if you look at the classification of Dialogue Act, it seems to be extremely important to get the beginning at both the beginning and the end right in segmentation in order to reliably classify and the metrics I see here, they don't pay attention to boundaries except for the newest one that actually looks with boundaries.",
                    "label": 0
                },
                {
                    "sent": "But this is kind of local so.",
                    "label": 0
                },
                {
                    "sent": "If you have a correct boundary in one place, it does not take into account if the beginning of that dialogue act was also correctly segmented or not OK. More results are using those other metrics.",
                    "label": 0
                },
                {
                    "sent": "I remove them.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "An email sent this by Mr on your side.",
                    "label": 0
                },
                {
                    "sent": "You said that you are normalizing the duration between words in your feature extraction system.",
                    "label": 0
                },
                {
                    "sent": "That component I'm just curious, how do you normalize the durations between words?",
                    "label": 0
                },
                {
                    "sent": "What is the normalization that you're using?",
                    "label": 0
                },
                {
                    "sent": "When the the word lanther.",
                    "label": 0
                },
                {
                    "sent": "It normalized by the the typical duration for for that term.",
                    "label": 0
                },
                {
                    "sent": "For example, if we spoke a word, I don't know the word transcription, it will be.",
                    "label": 0
                },
                {
                    "sent": "Normalized by the usual length of the word transcription, it's OK.",
                    "label": 0
                },
                {
                    "sent": "I actually what I was asking about is I got the impression that one of your features was deposit duration between words.",
                    "label": 0
                },
                {
                    "sent": "OK, no, they are not normalized.",
                    "label": 0
                },
                {
                    "sent": "They're just pre scaling for practical reasons.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you.",
                    "label": 0
                },
                {
                    "sent": "Actually wondering what the point is of finding these dialogue, acts, statements, questions and filled pauses.",
                    "label": 0
                },
                {
                    "sent": "I cannot imagine myself looking for those in a meeting as opposed to things like draw vessel, discourse styles and things like that.",
                    "label": 0
                },
                {
                    "sent": "We had to study close these couple of years ago.",
                    "label": 0
                },
                {
                    "sent": "Did this on meeting records and found actually things like usual listen.",
                    "label": 0
                },
                {
                    "sent": "So I'm quite helpful but dialogue acts but not particularly.",
                    "label": 0
                },
                {
                    "sent": "I don't image indirectly used tool to be honest.",
                    "label": 0
                },
                {
                    "sent": "But maybe they can be helpful to to improve language modeling for ASR or to improve summarization.",
                    "label": 0
                },
                {
                    "sent": "And maybe they can also correlate with something more high level like meeting phases.",
                    "label": 0
                },
                {
                    "sent": "But anyway, it's.",
                    "label": 0
                },
                {
                    "sent": "I agree that having for example in meeting browser we've highlighted segments of statement questions.",
                    "label": 0
                },
                {
                    "sent": "It's is not so useful then.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's just a brick in the the the.",
                    "label": 0
                },
                {
                    "sent": "System for the automatic meeting structure in math.",
                    "label": 0
                },
                {
                    "sent": "So some product, not a final user.",
                    "label": 0
                },
                {
                    "sent": "My question is that you do the the 70s and the recognitions meeting but actually do not use any feature across speakers such as in a meeting.",
                    "label": 0
                },
                {
                    "sent": "I'm manager said before meeting.",
                    "label": 0
                },
                {
                    "sent": "Do you have any concerns or questions?",
                    "label": 0
                },
                {
                    "sent": "So this is a question and then several participants will give the questions.",
                    "label": 0
                },
                {
                    "sent": "So if you can use such information the feature set.",
                    "label": 0
                },
                {
                    "sent": "Probably don't get your waist, but you are saying that the feature extracted for all the participants.",
                    "label": 0
                },
                {
                    "sent": "Yes, he yes.",
                    "label": 0
                },
                {
                    "sent": "Well we are.",
                    "label": 0
                },
                {
                    "sent": "We we we working on this stream of war and we we.",
                    "label": 0
                },
                {
                    "sent": "It's like if we merged together.",
                    "label": 0
                },
                {
                    "sent": "The transcription just won.",
                    "label": 0
                },
                {
                    "sent": "Three more sentences.",
                    "label": 0
                },
                {
                    "sent": "And anyway, it's part of the.",
                    "label": 0
                },
                {
                    "sent": "Desegmentation and I don't know.",
                    "label": 0
                },
                {
                    "sent": "I'm asking if you have sickle on using cross speaker cross channel features actually collected at dialogue content such as sort of the telephone as much as you like using hopefully lower cost.",
                    "label": 0
                },
                {
                    "sent": "Because you do not use any cross channel information.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "With something like an easy try.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK central, once again office.",
                    "label": 0
                },
                {
                    "sent": "We had.",
                    "label": 0
                }
            ]
        }
    }
}