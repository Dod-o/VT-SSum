{
    "id": "bkltb4fhr2jkgspb7yswpmdmka65nuvg",
    "title": "Gaussian process regression bootstrapping",
    "info": {
        "author": [
            "Paul Kirk, Centre for Bioinformatics, Imperial College London"
        ],
        "published": "April 16, 2009",
        "recorded": "April 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/licsb09_kirk_gprb/",
    "segmentation": [
        [
            "Next week is Falkirk from local person.",
            "Here in college is going to talk to us about Gaussian process regression bootstrapping.",
            "OK, so I'm going to talk about a method that we use in order to look into the effect of noise in time course data upon the conclusions and inferences that we draw from those data and the method that I'm going to talk about is a bootstrapping approach in which we use Gaussian process regression so you capture the dependence between data points at different times."
        ],
        [
            "So going to start by talking through an example which will hopefully motivate some of the things that I'm going to be talking about.",
            "So suppose we have a mechanistic parametric model M which predicts the values of responses Y1 and Y2 at time T given some vector of parameters Theta.",
            "Then suppose further that we observe some data as shown by these red points here."
        ],
        [
            "And then we go ahead and we find an estimate of the model parameters by, for example, minimizing the sum of squared distances between our models predictions and the data that we've observed."
        ],
        [
            "So the question we're interested in is what if we observe slightly?"
        ],
        [
            "Current data.",
            "For example, suppose we observe these blue points here, which are not a million miles away from the red points."
        ],
        [
            "Would we expect to obtain a similar estimate of the parameters?",
            "And so our overall aims at kind of get feeling as to how much we can rely upon the results that we infer from these highly noisy time courses and the reason why this is of interest is that biological data are highly noisy and so we would expect that repetitions of our experiments would give rise to a slightly different and possibly Berry different datasets, and so we'd like to know if the things that we infer from each of those datasets would be approximately the same.",
            "We hope, of course, that would be the case, and if that isn't the case, then perhaps we need to consider making sure that our experimental methods minimize the noise as much as possible, or if we are unable to do that, then perhaps we need to make sure that when we do infer things from these data, we make sure that our inferred quantities have appropriately large parameter confidence intervals associated with them.",
            "Now, in order to investigate this, I'm going to need to generate lots of datasets in order to see how inference is changed in light of slightly different observed data.",
            "And of course, in order to generate new datasets, one approach I might concede."
        ],
        [
            "It is.",
            "The bootstrap and the Bootstrap is a statistical resampling technique which can be used to assess properties of quantities or statistics that we infer from a set of data."
        ],
        [
            "And the main ingredient that we require is an approximating distribution, from which we can draw new data samples."
        ],
        [
            "Ideally, of course we wouldn't need such an approximating distribution at all.",
            "We would just repeat the experiment time and time again, and for each one of our repetitions we would infer the quantity of interest, and then we'd see how that quantity changed over all of our repetitions.",
            "In practice, of course, that's generally not feasible because of reasons of time and cost."
        ],
        [
            "So one statistical alternative is the nonparametric job in which we sample repeatedly from sample repeatedly with replacement from our original datasets.",
            "However, the time course data this is quite hard to do because there are typically few data points at each time point.",
            "We typically happy replicates, so it's very hard to apply, particularly without destroying the dependence of the data upon time."
        ],
        [
            "Another alternative then is the parametric bootstrap, in which we first bit a parametric probability model to the data, and then we draw samples from that probability model and it's this kind of approach that we're interested in here.",
            "And of course, given that we are interested in this kind of approach, the first question we have to ask is how could we fit such a parametric probability model to our time course?",
            "Now, when thinking about fitting probability models, time cool stator parts first thing."
        ],
        [
            "Speaking some lines is regression.",
            "Now we have here a fairly standard regression model in which we assume that the observables Y just composed of two parts, an underlying true function which has been corrupted by some noise, and we make the simplifying assumption that the noise is univariate, normal distributed, and Furthermore that the variances that univariate normal is constant with time.",
            "And so if we were adopting a traditional regression approach, we would now consider how can we choose our F and what we would typically do is choose some parametric form as in the case for, for example, simple linear regression.",
            "However, we would like as much as possible for the data speak for themselves, so we don't want to impose too hard constraint by our choice of F, and in fact we seek a probabilistic approach.",
            "See modeling the uncertainty in the head and the way in which we do this is to make use of the framework of Gaussian process with."
        ],
        [
            "Action.",
            "Now, Gaussian process regression proceeds by first placing a Gaussian process prior over the unknown function F. And all this means is that given any finite collection of function outputs, we assume that that finite collection is jointly distributed according to multivariate Gaussian.",
            "And since we have to do this for any finite collection, we have to specify a mean function.",
            "An OK variance function which tell us how to get out the mean vectors and covariance matrices for each such distribution.",
            "And it's through the choice of these mean functions and covariance functions that were able to express prior belief about the nature of function F. So in particular, we can express simple things such as the idea that data which are close together more strongly dependent from one another, and data which are far apart."
        ],
        [
            "Since we defining a prior, we would hope that appan observing some data.",
            "We could update that prior in order to obtain a posterior and for Gaussian processes, regression, particularly when we assume a Gaussian noise model as we have done, this turns out to be relatively straightforward.",
            "And this is GC noise.",
            "Properties of multivariate Gaussian distributions, which tell us that the joint probability distribution of any finite collection of the function outputs conditioned on the observed data is again multivariate Gaussian.",
            "And so we're able to go from a Gaussian process prior with mean function M and covariance function K. So Gaussian process posterior with a different mean function covariance function, which we can write in terms of M&K with the dependence on the data included."
        ],
        [
            "So we've just stated that we can use the machinery of Gaussian process regression in order to obtain a Gaussian process posterior over these function values.",
            "But of course what we're really interested in is obtaining some parametric probability distribution from which we can draw these bootstrap samples.",
            "Now guys, Gaussian prices posterior tells us that any finite collection of these function values is distributed according to multivariate Gaussian.",
            "So in particular, the functions the function evaluated at the time points of which we've made observations are distributed according to multivariate Gaussian.",
            "And since we can write Y of T or observables as F of T plus Gaussian noise, it follows that Y evaluated at each of the time points at which we made observations is also distributed according to multivariate Gaussian, whose mean vector and covariance matrix we can write down.",
            "This means that we have what we needed.",
            "We have a parametric probability model for our time course data.",
            "And we can use that in order to obtain brute shot samples by simply drawing from a multivariate Gaussian."
        ],
        [
            "So, just to recap, the steps in this process.",
            "Then we start off with some observed data timecourse data as shown here."
        ],
        [
            "We then fit a Gaussian process regressor in order to find the Gaussian process posterior."
        ],
        [
            "And this gives us automatically atmospheric Gaussian, from which we can draw new data."
        ],
        [
            "Sets in order to obtain a bootstrap sample."
        ],
        [
            "Switch about these blue dots show us.",
            "And then having obtained a large number of these bootstrapped datasets, what we do is we each one of them infer our parameter or statistic of interest, and then we look at the distribution of that parameter statistic across all of the bootstrap data."
        ],
        [
            "Now he knows that illustrates how this may be used in going to consider a particular example.",
            "An example I'm going to consider is the Jack, Two Stat 5 signaling pathway, which describes how the binding of epochs, the EPO receptor EPO R triggers this signal, which is then transduced to the sound nucleus.",
            "And the way this happens is that EPO binds to the Preceptor, which activates Jack Switcher, bounces cytoplasmic cementing of the EPO are.",
            "Upon this happening, the Jacks is unable to phosphorylate the cytoplasmic domain of the receptor, which allows stat 5 proteins to bind to the receptor where they can then be also related by the Jackson selves.",
            "And once that happens, the stat 5 molecules are able to bind to one another.",
            "Dimerized relocates the nucleus where they're able to act as transcription factors."
        ],
        [
            "Now in 2003, Swami ET.",
            "Al.",
            "Suggested a number of ordinary differential equation models for this signaling pathway, of which this is 1 here, and I'm not going to go through the details, but the important thing to realize is that there are a number of unknown parameters in this and that we have to estimate these from two time courses time courses for Y1 and Y2, which just represents the total amount of phosphorylated stat five in the cytoplasm and the total amount of phosphorylated stat.",
            "Live in the cytoplasm and in the nucleus."
        ],
        [
            "And so initially all we did was we took one of the data sets, the original authors, and we used a an optimization routine in order to minimize the distances between the function outputs between the model outputs and the observed data, and in so doing we obtained a set of parameter estimates for this data set.",
            "Which is shown here.",
            "And the figures here just so show the original data together with the model fitted using these parameter values.",
            "We then go ahead and apply our bootstrapping approach to the data in order to generate 1000 Bootstrap data samples, and for each one of those data samples, we perform the same procedure procedure, an estimate the parameters.",
            "And then we're interested in looking at the distribution of those parameters across the bootstrap samples."
        ],
        [
            "The marginals of which these histograms illustrate.",
            "And so the black dashed vertical line in each one of these histograms.",
            "Illustrates the actual parameter estimate those obtained from the original datasets, and we can see that the parameter estimates obtained across all of the boot camp datasets are in general centered around the estimate obtained from the original set.",
            "In general, that's true, but in a small number, approximately 2% of cases we obtained quite a different parameter estimate, and they're quite easy to distinguish because the R3, the parameter R3, has a value of five in these estimates compared to the value of about .25 in all of the other parameter estimates.",
            "Now initially thought that perhaps this was spurious results, and maybe there was something going wrong with our parameter inference.",
            "But we re ran our optimization program many times and we always came up with the same set of parameter estimates from these particular Supercenter bootstrap samples."
        ],
        [
            "And just to convince you parts yet further that these are reasonable parameter estimates, the blue lines here show the bits given by the parameter estimates obtained from this small.",
            "So 2% of bootstrap samples, whereas the red line shows the original fits given by the original parameter estimates.",
            "And in fact, we can see that the blue lines are very similar to the red line, and in fact.",
            "Furthermore, the case of white.",
            "See the blue lines actually provide, on average is slightly better, fits the original data."
        ],
        [
            "So we've demonstrated then that Gaussian process regression can be used as a means to obtain a probability distribution from which we can draw bootstrap data samples and thereby bootstrap time course data.",
            "We applied this to a model of the Jack T Stat 5 signaling pathway.",
            "And we were able to identify a second set of parameters in addition to the first set they were identified from the original data.",
            "Otherwise, however, the parameter estimates were relatively stable, but it just goes to show that you should probably take into account the effects of noise in your data when you're inferring these parameters, and you should assign confidence intervals appropriately.",
            "One other thing that this possibly suggests is that instead of just obtaining a single parameter estimates, it might be better to obtain a whole posterior over them.",
            "Adopt A Bayesian approach, and that way hopefully you would avoid just missing some nearby plausible parameter estimates.",
            "Finally, just to say we did also consider the inference of gene networks from gene expression timecourse data.",
            "And we found that they were very variable across all of our bootstrap datasets.",
            "And the reason for this is nothing to do with the methods themselves, but it's just because the data that we were dealing with has such a high level of noise that there's a large degree of variability within the bootstrapped data.",
            "But in any event, since that represents the realistic level of noise in the data, it suggests that when people report these gene networks, they should make sure that they assign as they say.",
            "Large confidence intervals to what they're saying.",
            "Overall then, this just illustrates the importance of considering the effects of noise, whether using this method or some other."
        ],
        [
            "Method.",
            "So just some quick thank yous to my supervisors, Michael Stump and Sylvia Richardson, so the rest of this junk group answer my sponsors, the Welcome Trust.",
            "Thank you.",
            "Quit.",
            "We thought about your data was quite heavily samples.",
            "You have multiple endpoints.",
            "Who gave me the time?",
            "And have you?",
            "How many time points do you need for your computer?",
            "Good questions first one.",
            "So the reason that I only sampled data at the point where I actually had the time was because the error in the predictions at those points are minimal, and so I figured that this would be sort of kindest to the methods that I was testing, so it was just a very conservative way of approaching problem, but there's no.",
            "There's no reason why you couldn't obtain data points at other times.",
            "The second question was how many time points do you think you need?",
            "That's a good question, but.",
            "The question is not only you know how many points do we need to fit our regressive in order to get good bootstrap.",
            "Also, how many points do you need in the first place in order to infer the things that you're interested?",
            "So I think that provided you have enough time points that you can make a reasonable goal of, say, inferring the parameters of your model, you would expect these hopefully be able to infer be able to put their aggressor as well.",
            "When is good for Billy Billy for more criticism from 3?",
            "Population.",
            "So implicitly, as part of the process of fitting the GP regressor, the noise in the data is estimated.",
            "So there are two.",
            "There are actually two sources of variability in when facing the Gaussian process regressor.",
            "There's the variability in the unknown function, and there's also the variability.",
            "Joyce Justa noise in the data and the variability in the function is what you're modeling, and the noise is something that you're trying to estimate as you're fitting your aggressor.",
            "One last?",
            "Understand your sampling.",
            "Functions from the posterior induced by the Yep.",
            "Christina used to get point estimate or speak up from your other one for the money, yeah?",
            "Bootstrapping.",
            "Getting some Monte Carlo estimate or before speeding off speaker given the original data behind.",
            "So I'm wondering if you were just to take a standard Bayesian sampling or posterior over fetal parameters.",
            "Marginal stability combined be exactly the same as what we get from using your new stuff.",
            "I mean should be because the empty groups marketing and possibly.",
            "But of course that's dependent on the 1st place on what prize you place when performing your Bayesian inference.",
            "So depending on what you choose, I think you could end up setting with very similar answers.",
            "121 stop.",
            "You certainly hope for something very simple.",
            "Yes, yes.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next week is Falkirk from local person.",
                    "label": 0
                },
                {
                    "sent": "Here in college is going to talk to us about Gaussian process regression bootstrapping.",
                    "label": 1
                },
                {
                    "sent": "OK, so I'm going to talk about a method that we use in order to look into the effect of noise in time course data upon the conclusions and inferences that we draw from those data and the method that I'm going to talk about is a bootstrapping approach in which we use Gaussian process regression so you capture the dependence between data points at different times.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So going to start by talking through an example which will hopefully motivate some of the things that I'm going to be talking about.",
                    "label": 0
                },
                {
                    "sent": "So suppose we have a mechanistic parametric model M which predicts the values of responses Y1 and Y2 at time T given some vector of parameters Theta.",
                    "label": 1
                },
                {
                    "sent": "Then suppose further that we observe some data as shown by these red points here.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we go ahead and we find an estimate of the model parameters by, for example, minimizing the sum of squared distances between our models predictions and the data that we've observed.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the question we're interested in is what if we observe slightly?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Current data.",
                    "label": 0
                },
                {
                    "sent": "For example, suppose we observe these blue points here, which are not a million miles away from the red points.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Would we expect to obtain a similar estimate of the parameters?",
                    "label": 1
                },
                {
                    "sent": "And so our overall aims at kind of get feeling as to how much we can rely upon the results that we infer from these highly noisy time courses and the reason why this is of interest is that biological data are highly noisy and so we would expect that repetitions of our experiments would give rise to a slightly different and possibly Berry different datasets, and so we'd like to know if the things that we infer from each of those datasets would be approximately the same.",
                    "label": 0
                },
                {
                    "sent": "We hope, of course, that would be the case, and if that isn't the case, then perhaps we need to consider making sure that our experimental methods minimize the noise as much as possible, or if we are unable to do that, then perhaps we need to make sure that when we do infer things from these data, we make sure that our inferred quantities have appropriately large parameter confidence intervals associated with them.",
                    "label": 0
                },
                {
                    "sent": "Now, in order to investigate this, I'm going to need to generate lots of datasets in order to see how inference is changed in light of slightly different observed data.",
                    "label": 0
                },
                {
                    "sent": "And of course, in order to generate new datasets, one approach I might concede.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "The bootstrap and the Bootstrap is a statistical resampling technique which can be used to assess properties of quantities or statistics that we infer from a set of data.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the main ingredient that we require is an approximating distribution, from which we can draw new data samples.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ideally, of course we wouldn't need such an approximating distribution at all.",
                    "label": 1
                },
                {
                    "sent": "We would just repeat the experiment time and time again, and for each one of our repetitions we would infer the quantity of interest, and then we'd see how that quantity changed over all of our repetitions.",
                    "label": 1
                },
                {
                    "sent": "In practice, of course, that's generally not feasible because of reasons of time and cost.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one statistical alternative is the nonparametric job in which we sample repeatedly from sample repeatedly with replacement from our original datasets.",
                    "label": 1
                },
                {
                    "sent": "However, the time course data this is quite hard to do because there are typically few data points at each time point.",
                    "label": 0
                },
                {
                    "sent": "We typically happy replicates, so it's very hard to apply, particularly without destroying the dependence of the data upon time.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another alternative then is the parametric bootstrap, in which we first bit a parametric probability model to the data, and then we draw samples from that probability model and it's this kind of approach that we're interested in here.",
                    "label": 1
                },
                {
                    "sent": "And of course, given that we are interested in this kind of approach, the first question we have to ask is how could we fit such a parametric probability model to our time course?",
                    "label": 1
                },
                {
                    "sent": "Now, when thinking about fitting probability models, time cool stator parts first thing.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speaking some lines is regression.",
                    "label": 0
                },
                {
                    "sent": "Now we have here a fairly standard regression model in which we assume that the observables Y just composed of two parts, an underlying true function which has been corrupted by some noise, and we make the simplifying assumption that the noise is univariate, normal distributed, and Furthermore that the variances that univariate normal is constant with time.",
                    "label": 0
                },
                {
                    "sent": "And so if we were adopting a traditional regression approach, we would now consider how can we choose our F and what we would typically do is choose some parametric form as in the case for, for example, simple linear regression.",
                    "label": 0
                },
                {
                    "sent": "However, we would like as much as possible for the data speak for themselves, so we don't want to impose too hard constraint by our choice of F, and in fact we seek a probabilistic approach.",
                    "label": 0
                },
                {
                    "sent": "See modeling the uncertainty in the head and the way in which we do this is to make use of the framework of Gaussian process with.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Action.",
                    "label": 0
                },
                {
                    "sent": "Now, Gaussian process regression proceeds by first placing a Gaussian process prior over the unknown function F. And all this means is that given any finite collection of function outputs, we assume that that finite collection is jointly distributed according to multivariate Gaussian.",
                    "label": 1
                },
                {
                    "sent": "And since we have to do this for any finite collection, we have to specify a mean function.",
                    "label": 0
                },
                {
                    "sent": "An OK variance function which tell us how to get out the mean vectors and covariance matrices for each such distribution.",
                    "label": 0
                },
                {
                    "sent": "And it's through the choice of these mean functions and covariance functions that were able to express prior belief about the nature of function F. So in particular, we can express simple things such as the idea that data which are close together more strongly dependent from one another, and data which are far apart.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Since we defining a prior, we would hope that appan observing some data.",
                    "label": 0
                },
                {
                    "sent": "We could update that prior in order to obtain a posterior and for Gaussian processes, regression, particularly when we assume a Gaussian noise model as we have done, this turns out to be relatively straightforward.",
                    "label": 0
                },
                {
                    "sent": "And this is GC noise.",
                    "label": 0
                },
                {
                    "sent": "Properties of multivariate Gaussian distributions, which tell us that the joint probability distribution of any finite collection of the function outputs conditioned on the observed data is again multivariate Gaussian.",
                    "label": 1
                },
                {
                    "sent": "And so we're able to go from a Gaussian process prior with mean function M and covariance function K. So Gaussian process posterior with a different mean function covariance function, which we can write in terms of M&K with the dependence on the data included.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we've just stated that we can use the machinery of Gaussian process regression in order to obtain a Gaussian process posterior over these function values.",
                    "label": 0
                },
                {
                    "sent": "But of course what we're really interested in is obtaining some parametric probability distribution from which we can draw these bootstrap samples.",
                    "label": 0
                },
                {
                    "sent": "Now guys, Gaussian prices posterior tells us that any finite collection of these function values is distributed according to multivariate Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So in particular, the functions the function evaluated at the time points of which we've made observations are distributed according to multivariate Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And since we can write Y of T or observables as F of T plus Gaussian noise, it follows that Y evaluated at each of the time points at which we made observations is also distributed according to multivariate Gaussian, whose mean vector and covariance matrix we can write down.",
                    "label": 0
                },
                {
                    "sent": "This means that we have what we needed.",
                    "label": 0
                },
                {
                    "sent": "We have a parametric probability model for our time course data.",
                    "label": 1
                },
                {
                    "sent": "And we can use that in order to obtain brute shot samples by simply drawing from a multivariate Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, just to recap, the steps in this process.",
                    "label": 0
                },
                {
                    "sent": "Then we start off with some observed data timecourse data as shown here.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then fit a Gaussian process regressor in order to find the Gaussian process posterior.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this gives us automatically atmospheric Gaussian, from which we can draw new data.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sets in order to obtain a bootstrap sample.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Switch about these blue dots show us.",
                    "label": 0
                },
                {
                    "sent": "And then having obtained a large number of these bootstrapped datasets, what we do is we each one of them infer our parameter or statistic of interest, and then we look at the distribution of that parameter statistic across all of the bootstrap data.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now he knows that illustrates how this may be used in going to consider a particular example.",
                    "label": 0
                },
                {
                    "sent": "An example I'm going to consider is the Jack, Two Stat 5 signaling pathway, which describes how the binding of epochs, the EPO receptor EPO R triggers this signal, which is then transduced to the sound nucleus.",
                    "label": 0
                },
                {
                    "sent": "And the way this happens is that EPO binds to the Preceptor, which activates Jack Switcher, bounces cytoplasmic cementing of the EPO are.",
                    "label": 0
                },
                {
                    "sent": "Upon this happening, the Jacks is unable to phosphorylate the cytoplasmic domain of the receptor, which allows stat 5 proteins to bind to the receptor where they can then be also related by the Jackson selves.",
                    "label": 0
                },
                {
                    "sent": "And once that happens, the stat 5 molecules are able to bind to one another.",
                    "label": 0
                },
                {
                    "sent": "Dimerized relocates the nucleus where they're able to act as transcription factors.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in 2003, Swami ET.",
                    "label": 0
                },
                {
                    "sent": "Al.",
                    "label": 0
                },
                {
                    "sent": "Suggested a number of ordinary differential equation models for this signaling pathway, of which this is 1 here, and I'm not going to go through the details, but the important thing to realize is that there are a number of unknown parameters in this and that we have to estimate these from two time courses time courses for Y1 and Y2, which just represents the total amount of phosphorylated stat five in the cytoplasm and the total amount of phosphorylated stat.",
                    "label": 0
                },
                {
                    "sent": "Live in the cytoplasm and in the nucleus.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so initially all we did was we took one of the data sets, the original authors, and we used a an optimization routine in order to minimize the distances between the function outputs between the model outputs and the observed data, and in so doing we obtained a set of parameter estimates for this data set.",
                    "label": 0
                },
                {
                    "sent": "Which is shown here.",
                    "label": 0
                },
                {
                    "sent": "And the figures here just so show the original data together with the model fitted using these parameter values.",
                    "label": 0
                },
                {
                    "sent": "We then go ahead and apply our bootstrapping approach to the data in order to generate 1000 Bootstrap data samples, and for each one of those data samples, we perform the same procedure procedure, an estimate the parameters.",
                    "label": 0
                },
                {
                    "sent": "And then we're interested in looking at the distribution of those parameters across the bootstrap samples.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The marginals of which these histograms illustrate.",
                    "label": 0
                },
                {
                    "sent": "And so the black dashed vertical line in each one of these histograms.",
                    "label": 0
                },
                {
                    "sent": "Illustrates the actual parameter estimate those obtained from the original datasets, and we can see that the parameter estimates obtained across all of the boot camp datasets are in general centered around the estimate obtained from the original set.",
                    "label": 0
                },
                {
                    "sent": "In general, that's true, but in a small number, approximately 2% of cases we obtained quite a different parameter estimate, and they're quite easy to distinguish because the R3, the parameter R3, has a value of five in these estimates compared to the value of about .25 in all of the other parameter estimates.",
                    "label": 0
                },
                {
                    "sent": "Now initially thought that perhaps this was spurious results, and maybe there was something going wrong with our parameter inference.",
                    "label": 0
                },
                {
                    "sent": "But we re ran our optimization program many times and we always came up with the same set of parameter estimates from these particular Supercenter bootstrap samples.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just to convince you parts yet further that these are reasonable parameter estimates, the blue lines here show the bits given by the parameter estimates obtained from this small.",
                    "label": 0
                },
                {
                    "sent": "So 2% of bootstrap samples, whereas the red line shows the original fits given by the original parameter estimates.",
                    "label": 0
                },
                {
                    "sent": "And in fact, we can see that the blue lines are very similar to the red line, and in fact.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, the case of white.",
                    "label": 0
                },
                {
                    "sent": "See the blue lines actually provide, on average is slightly better, fits the original data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we've demonstrated then that Gaussian process regression can be used as a means to obtain a probability distribution from which we can draw bootstrap data samples and thereby bootstrap time course data.",
                    "label": 0
                },
                {
                    "sent": "We applied this to a model of the Jack T Stat 5 signaling pathway.",
                    "label": 0
                },
                {
                    "sent": "And we were able to identify a second set of parameters in addition to the first set they were identified from the original data.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, however, the parameter estimates were relatively stable, but it just goes to show that you should probably take into account the effects of noise in your data when you're inferring these parameters, and you should assign confidence intervals appropriately.",
                    "label": 0
                },
                {
                    "sent": "One other thing that this possibly suggests is that instead of just obtaining a single parameter estimates, it might be better to obtain a whole posterior over them.",
                    "label": 0
                },
                {
                    "sent": "Adopt A Bayesian approach, and that way hopefully you would avoid just missing some nearby plausible parameter estimates.",
                    "label": 1
                },
                {
                    "sent": "Finally, just to say we did also consider the inference of gene networks from gene expression timecourse data.",
                    "label": 0
                },
                {
                    "sent": "And we found that they were very variable across all of our bootstrap datasets.",
                    "label": 0
                },
                {
                    "sent": "And the reason for this is nothing to do with the methods themselves, but it's just because the data that we were dealing with has such a high level of noise that there's a large degree of variability within the bootstrapped data.",
                    "label": 0
                },
                {
                    "sent": "But in any event, since that represents the realistic level of noise in the data, it suggests that when people report these gene networks, they should make sure that they assign as they say.",
                    "label": 1
                },
                {
                    "sent": "Large confidence intervals to what they're saying.",
                    "label": 0
                },
                {
                    "sent": "Overall then, this just illustrates the importance of considering the effects of noise, whether using this method or some other.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Method.",
                    "label": 0
                },
                {
                    "sent": "So just some quick thank yous to my supervisors, Michael Stump and Sylvia Richardson, so the rest of this junk group answer my sponsors, the Welcome Trust.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Quit.",
                    "label": 0
                },
                {
                    "sent": "We thought about your data was quite heavily samples.",
                    "label": 0
                },
                {
                    "sent": "You have multiple endpoints.",
                    "label": 0
                },
                {
                    "sent": "Who gave me the time?",
                    "label": 0
                },
                {
                    "sent": "And have you?",
                    "label": 0
                },
                {
                    "sent": "How many time points do you need for your computer?",
                    "label": 0
                },
                {
                    "sent": "Good questions first one.",
                    "label": 0
                },
                {
                    "sent": "So the reason that I only sampled data at the point where I actually had the time was because the error in the predictions at those points are minimal, and so I figured that this would be sort of kindest to the methods that I was testing, so it was just a very conservative way of approaching problem, but there's no.",
                    "label": 0
                },
                {
                    "sent": "There's no reason why you couldn't obtain data points at other times.",
                    "label": 0
                },
                {
                    "sent": "The second question was how many time points do you think you need?",
                    "label": 0
                },
                {
                    "sent": "That's a good question, but.",
                    "label": 0
                },
                {
                    "sent": "The question is not only you know how many points do we need to fit our regressive in order to get good bootstrap.",
                    "label": 0
                },
                {
                    "sent": "Also, how many points do you need in the first place in order to infer the things that you're interested?",
                    "label": 0
                },
                {
                    "sent": "So I think that provided you have enough time points that you can make a reasonable goal of, say, inferring the parameters of your model, you would expect these hopefully be able to infer be able to put their aggressor as well.",
                    "label": 0
                },
                {
                    "sent": "When is good for Billy Billy for more criticism from 3?",
                    "label": 0
                },
                {
                    "sent": "Population.",
                    "label": 0
                },
                {
                    "sent": "So implicitly, as part of the process of fitting the GP regressor, the noise in the data is estimated.",
                    "label": 0
                },
                {
                    "sent": "So there are two.",
                    "label": 0
                },
                {
                    "sent": "There are actually two sources of variability in when facing the Gaussian process regressor.",
                    "label": 0
                },
                {
                    "sent": "There's the variability in the unknown function, and there's also the variability.",
                    "label": 0
                },
                {
                    "sent": "Joyce Justa noise in the data and the variability in the function is what you're modeling, and the noise is something that you're trying to estimate as you're fitting your aggressor.",
                    "label": 0
                },
                {
                    "sent": "One last?",
                    "label": 0
                },
                {
                    "sent": "Understand your sampling.",
                    "label": 0
                },
                {
                    "sent": "Functions from the posterior induced by the Yep.",
                    "label": 0
                },
                {
                    "sent": "Christina used to get point estimate or speak up from your other one for the money, yeah?",
                    "label": 0
                },
                {
                    "sent": "Bootstrapping.",
                    "label": 0
                },
                {
                    "sent": "Getting some Monte Carlo estimate or before speeding off speaker given the original data behind.",
                    "label": 0
                },
                {
                    "sent": "So I'm wondering if you were just to take a standard Bayesian sampling or posterior over fetal parameters.",
                    "label": 0
                },
                {
                    "sent": "Marginal stability combined be exactly the same as what we get from using your new stuff.",
                    "label": 0
                },
                {
                    "sent": "I mean should be because the empty groups marketing and possibly.",
                    "label": 0
                },
                {
                    "sent": "But of course that's dependent on the 1st place on what prize you place when performing your Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "So depending on what you choose, I think you could end up setting with very similar answers.",
                    "label": 0
                },
                {
                    "sent": "121 stop.",
                    "label": 0
                },
                {
                    "sent": "You certainly hope for something very simple.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}