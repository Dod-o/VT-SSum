{
    "id": "icfepu6r4l4ba357v5d24pqkmxs44min",
    "title": "Probabilistic inference methods in robotics-filling the gap between high-level reasoning and low-level motion control",
    "info": {
        "author": [
            "Marc Toussaint, Machine Learning and Intelligent Data Analysis Group, TU Berlin"
        ],
        "published": "Feb. 7, 2008",
        "recorded": "January 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Robotics",
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/psm08_toussaint_pim/",
    "segmentation": [
        [
            "Yeah, so my name is Marcus and I just started a group in Berlin actually which is part of the Machine Learning Group of class Robert Miller and this group is concerned with actually combining or trying to combine machine learning techniques and robotics techniques.",
            "So this talk shall be about using probabilistic inference methods in robe."
        ],
        [
            "And I'd like to start first with this little picture here.",
            "So if you go to a typical robotics conference and I rose in this case and you just browse through the proceedings of the conference and see what kind of what kind of fields or what kind of topics there is on such a conference.",
            "And so the first.",
            "I mean simply, what you see is that there is a whole lot of different diverse errors in robotics, and it turns out that one reason why robotics is such a.",
            "Daunting enterprise is that actually you need to integrate all of these things in order to build already, you know a functioning system."
        ],
        [
            "Actually, if you talk to some of these people, some robotics is people.",
            "They said that the actual problem of robotic, like the real problem of robotics is the integration.",
            "Now, if you think about what might be reasons for this being so difficult, so why is it so difficult in this integration?",
            "Well, a lot of these fields.",
            "They use different methods and that's one thing, but they also use different representations in some sense.",
            "So for instance, the kind of representations that you might use on this.",
            "Like what I want to focus on on this level here, which my."
        ],
        [
            "Be about reinforcement learning or artificial intelligence?",
            "Imitation learning.",
            "They tend to be, you know, symbolic or.",
            "Maybe at least discrete or representable as Markov decision process, whereas the kind of representations that the core engineering roboticists use here for trajectory planning or grass planning or so on, they're just really disjoint so.",
            "I don't want to go much further into the general discussion, but focus on 2.",
            "Two errors in particular, and this is, you know this part here.",
            "Reasoning democratization processes on one hand, but also reasoning about motions trajectories in these kind of things.",
            "So the question I'm asking is, can I use a common framework?",
            "A single theory for both of these so that?"
        ],
        [
            "No idea I'm following is actually quite a simple one and should be completely obvious to all of you in general.",
            "So the idea is that you can understand the problem of motion control and planning as a problem of inferring the posterior of unknown variables conditioned on available information.",
            "Now, what is a bit different in flavor here is just.",
            "There is not many people who have considered as the unknown variables the decisions you make in future or the control signals that you want to do.",
            "You want to limit or a whole motion so or trajectories and on the other hand, as thinking as the available information, not the data that we have, but the kind of constraints or goals or rewards that are.",
            "So what is going to happen here is that I'm proposing to compute posterior distributions over things like motions or over behaviors conditioned on goals today wanna reach?",
            "OK, so do you."
        ],
        [
            "Outline of the talk is pretty short, and it's only 30 minute talk, so I'm first going to give some background.",
            "Which is some previous work for mine developing this theory of using probabilistic inference for solving Markov decision process.",
            "And in the second part actually the main part of the talk.",
            "I want to introduce this.",
            "New approach of using Bayesian or probabilistic inference techniques.",
            "Specifically in robotics.",
            "So really on the low level motor control and motion controller."
        ],
        [
            "I'm.",
            "OK, maybe you thought that this you know idea, reasoning about actions is not really new at all.",
            "It's so straightforward in some sense, and so no surprise that it also has some history and.",
            "So what I list here is specifically some history of work that was trying to explicitly translate the problem of solving a Markov decision process into a problem of probabilistic inference, and there is some of the work which says that from complexity point of view it's kind of obvious that they are equivalent.",
            "Would raise a lot of attention.",
            "Is this work by Attias who in his title actually also says, you know, planning by probabilistic inference, and he proposed a method using probabilistic inference techniques for solving Markov decision processes, but it turns out that it's not really generating optimal policies.",
            "Um?",
            "So you did the policy study, compute with these techniques are not equivalent to what you know.",
            "Reinforcement learning people compute by Bellman equations and things like that.",
            "There has been some other work using the idea of reasoning about actions like reasoning about the action of another person, recognizing his policy and other work.",
            "Then why Miss Romo name?",
            "Then there is the work that I did that I'm going to talk about in a second and some follow up work on this work.",
            "So I'm briefly going to report on these results here that we published by Signal 206."
        ],
        [
            "The general setup is that we were concerned about Markov decision processes and one way to define democratization process is by setting up this dynamic Bayesian network where you have a stage random variable and an action random variable, and both together just unroll as a Markov process where the next stage depends on previous state and the action that was chosen.",
            "Then there is also policy here which you can interpret as a parameter of the dynamic Bayesian network and there is also random variables which are the rewards which you.",
            "Receive at every time step.",
            "Now the problem by definition, like in reinforcement learning, is find a parameter that is final policy which maximizes this expected future return."
        ],
        [
            "And what I'm asking is, can I translate this into like load maximization problem and into the first thought you might have is shouldn't be to difficult by just reinterpreting rewards.",
            "This likelihoods, if you try, but then you turn, it turns out that it's bit tricky, because actually what you want to maximize here is this expectation over weighted sum of these things and.",
            "Further, what you want to maximize here is some kind of an infinite horizon problem.",
            "So what we came up with is that we actually were introducing a mixture of Markov decision processes where the mixture waiting so or the mixture coefficients exactly mimic these discounted waiting."
        ],
        [
            "So I just really briefly go over this.",
            "This is just a picture of what you might conceive as this mixture.",
            "So what you formally introduce is marketization process for for every possible finite length, and each of these Markov decision process only models you know the reward that you receive after two times set or after exactly time steps.",
            "And it turns out that we can show that the maximizing the likelihood in this mixture of final plat MDP is exactly.",
            "Maximizing this is equivalent to maximizing the expected future return in an original Markov decision process.",
            "I don't go into further details of the proof, but the point is now that we've translated that."
        ],
        [
            "Problem of planning into a problem of likelihood maximization, which means that now we can use an EM algorithm to actually compute an optimal policy, and the core part of the TM is obviously in the step.",
            "Which is you can use in simple cases just exact inference like forward, backward kind of algorithms.",
            "And it turns out that for exact inference and simple Markov decision process what this eastep does is very closely related to normal policy evaluation and the M step interns is very closely related to policy update.",
            "Well, the point is obviously that we've translated the the problem.",
            "Now two different framework to a different view on finding optimal policies.",
            "The point is that.",
            "Inference also works on structured representations, right?",
            "So you can now quite easily generalize this whole approach to learning policies.",
            "Also for structured representations of worlds or structured representations of the whole process one."
        ],
        [
            "Example is actually partially observable Markov decision process and I just put this here as an example.",
            "So again, partially observable Markov decision process can also be formalized as a palm DP.",
            "Sorry, as a dynamic vision network and you have to introduce some kind of latent memory or some kind of I don't know finite state machine or something as a model of the agent, and you can again use inference in order to compute optimal policies.",
            "OK, so the."
        ],
        [
            "The message of this, like introductory part, is basically just saying that palm DP scan solving problems can be reformulated slightly maximization problem and Interestingly now you can use all kinds of inference techniques that are around approximate or loopy BP or whatever for computing optimal policies."
        ],
        [
            "Um, so let's move onto the actually the main.",
            "The main part that I want to talk about, which is really robotics.",
            "So the question is, can we take this idea that I've just presented and use similar ideas also for generating motion and and planning in robotics?",
            "Um?",
            "So I'm not sure how many people are like experts in robotics.",
            "That's why I thought I started with really like one of the most basic things in Robotics Studio might find in every textbook.",
            "So considered the following problem, which is standard problem in robotics.",
            "You have some some robot which has which is in state Q and the state Q usually is defined by all the angles of the joints of the robot.",
            "So like for my own body, it would be all the angles of all the joints that have also."
        ],
        [
            "Unlike an end effector variable, which is typically something like the position of the hand or finger tip, so it could be a 3 dimensional variable, and let's also assume for the moment that we have exact exact knowledge of the kinematic mapping mapping from the joint configuration of the robot to the end effector position and also its derivative.",
            "Here, like the most basic problem in redundant robotic control, is the question.",
            "Given that you want to move your finger tip in a bit in a certain direction or with a certain velocity.",
            "How do you move your joints accordingly, right?",
            "It's almost trivial to solve this and here like on the left part is a solution given that you know how you want to move your finger tip like velocity of X, how you project it back into the more higher dimensional movement of the joint vector.",
            "You just use absolute inverse of this linearisation here.",
            "It turns out well, this is a definition of the pseudoinverse.",
            "It turns out that there's like infinitely many you can parameterise member some regularization matrix.",
            "Anyhow.",
            "Further you can if you want to, you can impose an additional movement which is called a nullspace movement.",
            "So even if you want to keep your fingertip fixed, for instance, you can do some non space movements and these movements can be generated by this age.",
            "Anyway, so this is like one of the most basic control schemes in robotics.",
            "And the question I want to ask is."
        ],
        [
            "Can I translate this into you know, can I have a different perspective on this?",
            "More bashan perspective?",
            "And it turns out that it's really simple to actually reproduce exactly that control law from a patient perspective.",
            "Assume that we know the current state of the robot, so it's posture assumed that we also know where the end effector should be in the next time step.",
            "And what we want to infer or what we do not know is what should be the corresponding pose in the next time step in order to reach that position of the other factor.",
            "So I could come up with these kind of priors.",
            "So let me say I have a prior that I'm lazy about moving, so I don't want to move much my joints.",
            "So I have this like Gaussian prior, but the movements of the joints with some variance matrix W and also.",
            "I include my knowledge about the kinematics as I did before, so I assume that you know the dependency between the end effector position in a joint state is just given by my kinematics and maybe some noise, so maybe I have some measuring noises.",
            "OK computer posterior over this unknown variable."
        ],
        [
            "The posturing, next time step, and it's all just Gaussian.",
            "You linearize this at some point maybe, and what you come up with is the posterior that is shown here in this slide, and in particular, this posterior can be approximated by Gaussian, which has like mean the MLP.",
            "Now, if you take the limit of this kinematic noise C being zero, you reproduce reproduce exactly the classical control law, right?",
            "And if you Interestingly also if you include some kind of.",
            "In your prior of movement, if you include some kind of asymmetry so you have a certain preference of movement and this is the ages exactly produces them.",
            "What is classically called in our space movement."
        ],
        [
            "Called the same thing.",
            "Also works for.",
            "Dynamic control and the picture is just a bit different here that now we try to infer really control signal, which might be torques or any kind of other control signal.",
            "I don't go into detail, but the same thing again.",
            "We can reproduce the classical results as a limit of the Beijing view."
        ],
        [
            "The point again is OK.",
            "Classical control can also be reinterpreted, observation, inference, and so finally I want to go beyond all these things."
        ],
        [
            "And move to something where we actually get to new algorithms and new new things.",
            "So what we've been talking about was motion control, where we considered one time step and I said just doing inference about this here reproduces control loss."
        ],
        [
            "But obviously we've got inference techniques also overtime.",
            "So we can now think what if you try to infer the posterior overall trajectory's of robot conditioned on where we want to see the end effector at some time, and conditioned on the initial state.",
            "Um?"
        ],
        [
            "I mean, I guess the general approach is clear, so I don't really have to define or introduce anymore theory, and it's actually quite straightforward to now implement this and show it at some experiments.",
            "So one of the experiments that we did is we considered like an upper body which had 13 degrees of freedom and we can see."
        ],
        [
            "Just as I was talking before the joint state was 13 dimensional, we just considered the right hand position as the end effector, and we also considered a certain collision.",
            "Um?"
        ],
        [
            "So we had an additional binary variable which sort of indicated whether the robot collided with any of its surrounding objects.",
            "The kind of scenario that we were thinking about can be translated into this dynamic Bayesian network, so this is one of the key things.",
            "So this scenario that you're confronted with or did you want to solve, you just formulate this, or reformulate this in terms of a dynamic vision network, which is actually quite straightforward, so consider this.",
            "Dynamic Bayesian network, or I've wrote it here, is a factor graph where again we have the same kind or very similar kind of priors as we had before.",
            "Like here we have a factor which just implements the laziness of our movement.",
            "Here we have a factor which just implements the kinematics.",
            "Here again, we have a factor which implements the laziness of the end effect movement, and here we have a factor which implements the probability of colliding.",
            "When I do a certain effect movement.",
            "So once this is formulated as this kind of factor graph, what we can do, we can just use inference techniques and."
        ],
        [
            "In our case we use."
        ],
        [
            "We believe propagation with Gaussian belief states, so again discussing belief states where approximation because actually the dependencies are partly nonlinear.",
            "And.",
            "The scenario that we were investigating was to simulate it.",
            "Upper body of human with table obstacle on top.",
            "Let me make this bit."
        ],
        [
            "Larger on the next slide, so this was actually the.",
            "The upper body that we were simulating this is the obstacle.",
            "Maybe?",
            "Let's look at this picture here and this is the posterior movement or this.",
            "This is the posterior over the trajectory conditioned on no collusion and with the.",
            "With the priors that I that I mentioned, these are just different intermediate snapshots, so this is the initial state.",
            "This might be the posterior of the state after I don't know tense time steps or something.",
            "Actually, this ellipsoid which is here illustrated is supposed to illustrate the Gaussian.",
            "The posterior for the Gaussian of the end effector position.",
            "So these ellipsoids illustrate the Gaussian form of the posterior.",
            "OK, so this is 1 example.",
            "Let me show you another example."
        ],
        [
            "Now let's consider a complete simulated human with 39 degrees of freedom."
        ],
        [
            "And in this case, let's assume that there is lots and lots of possible constraints of motion that you might want to consider.",
            "So one constraint of motion is again the desired motion of the end effector position, another one is again the collision with objects, another one is that this time the whole body is also supposed to keep balance and another one is that the that you should stay far away from joint limits, which I called your comfortableness.",
            "And.",
            "Again."
        ],
        [
            "The coupling videos between these random variables can be represented by a factor graph like this, where all of these you know these task variables, here called are now coupled by some factor to the joint state.",
            "Again, we have this transition prior, which is just the laziness of movement and again basically the rest of is inference.",
            "So we could just take any kind of inference package that we have.",
            "In this case we implement it again using.",
            "Loopy belief propagation with Gaussian belief representations.",
            "Which actually is only just a fancy way too."
        ],
        [
            "Two for this.",
            "So if you want to use more classical terms, you could also call it an iterated extended common smoother.",
            "It has to be iterated just because loops.",
            "Because the linearizations are some of these dependencies are nonlinear and linear relations and change depending on the posterior.",
            "So this is fine situated.",
            "Um?"
        ],
        [
            "So this is actually an illustration of the results, so the upper body that we were simulating is this human and initially it was just standing upright and upright posture.",
            "There was a goal constraint at the end effector that the end effector position should be at this black dot.",
            "Here this is like a marking of the target below this strange kind of table, huge obstacle.",
            "And as you can see here from this starting with this normal posture, he has to reach this end.",
            "And position while keeping balance while not colliding with the obstacle and while reaching while reaching the goal.",
            "Just curious an illustration of the.",
            "Works Cool, here's an illustration of the.",
            "Of the inference procedure.",
            "So this what you see here is like not online, but recorded diesel forward and backward passes.",
            "These are exactly what you know from Markov processes like forward and backward passes and what you see illustrated.",
            "Here is the maximum of the current belief, and you know the belief gets better and better after while.",
            "Um?",
            "I guess it so takes about.",
            "I don't know.",
            "Maybe 3 forward backward passes in order to converge and yield this movement as the Max maximum probable posterior motion which is coherent with all constraints that we said.",
            "OK. Um?",
            "So in terms of computational efficiency, it turns out that it's actually really computationally efficient, so the normal forward path.",
            "So the first probabilistic forward path has just exactly the same computational cost as a normal reactive controller.",
            "That is, as a normal, like inverse kinematics controller, and the backwards pass just doubles this cost, and then if you like, do a forward, backward and forward path.",
            "So this is what I mean here by doing 1 1/2 iterations.",
            "The quality of the trajectory actually becomes almost optimal already, so the quality can be measured in terms of the length of the trajectory, and it can also be measured in terms of the violation of constraints and just by doing this simple forward, backward forward probabilistic smoothing, you get quite a good trajectory already.",
            "What I like about this example is that it's sort of really pinpointing this idea of using this idea of Bayesian inference to compute the posterior of emotions, which is coherent with all these constraints.",
            "So it's like like beige and Fusion, but here not."
        ],
        [
            "About sensors, but about actions or both motions.",
            "I think this is what I just put here in this slide.",
            "Um?",
            "If I have a bit of time, actually I show you another movie and I must admit so.",
            "This is not using exactly the techniques that have presented so actually it's fake that I present this movie here currently, but it's using similar techniques, but which are based on gradient descents actually are not on proper inference because implementing proper inference would have been too expensive.",
            "So this is some work that I've done together with Honda and it's going to repeat in a second.",
            "I'm going to explain a bit more.",
            "So we were trying to generate movements again, which are coherent with constraints like having no conditions and stuff.",
            "What you see here is that we use an internal simulation in order to optimize the trajectory and this optimization procedure you could just we're looking at these green balls moving a bit.",
            "This was exactly the online movie of the optimization procedure.",
            "It takes about a second for these kinds of movies.",
            "And, um.",
            "It's kind of slow in the movie.",
            "If you look at the fingertip of it, you see that there is some pointy thing at the fingertip.",
            "OK, I think actually that's enough.",
            "So the point is it's similar problems over here is another movie and.",
            "We used I mean the same objectives, the same objective functions, but we didn't actually use probabilistic inference, but a cheaper gradient way to compute these posteriors, and again for all of these movements it took about a second to generate these solutions."
        ],
        [
            "OK, as a summary.",
            "So I've been talking about planning in market decision process in the introduction, and I've been talking about generating motion and robotic control in this main part in later part and at the point is that.",
            "I like this view that all of them can be can be seen as a problem of inference, inferring posteriors of emotions, or over actions and.",
            "So what is?"
        ],
        [
            "What is maybe a bit different to the standard idea of fusing orb Asian Fusion instead here what we're using is actually a goal, so constraints rather than censor information as it is usually done.",
            "What is nice?",
            "Obviously about approaches that it's now a new application for machine learning, right?",
            "So all the guys, all the people that work on inference techniques about approximate inference techniques, variational and they all now invited actually to run their stuff on robotics.",
            "And some people start doing this like none of the fighters which I'm working on and I find this quite exciting.",
            "Actually to get all these people perhaps working on robotics now.",
            "Another thing what I like about is that.",
            "So you could say that what we found here is one single computational principle which works equally on sensor.",
            "As we all know, you know based methods for sensor interpreting or sensor processing for motor.",
            "As I have to steer presented and also for high level reasoning like in math decision process.",
            "And now if you think about back to this one thing I mentioned in the introduction is 1 one.",
            "Difficulty in integrating all these things."
        ],
        [
            "Yeah, it's different methods, but it's also different representations.",
            "It's bit far fetched, but the I mean the dream would be that you actually buy buy, buy, basing.",
            "All of these approaches some similar kinds of representations that you eventually will be able to connect them up so to have maybe a joint model really join dynamic Bayesian model which includes both like abstract states, discrete states for more abstract reasoning, and on lower level like continuous variables in final final.",
            "Time scale variables for reasoning about emotions.",
            "Also, obviously it's quite nice to see that maybe machine learning approaches sort of could eventually.",
            "You know, contribute to all of these approaches.",
            "They have needed so far for audio processing or vision processing.",
            "Also for simultaneous localization and mapping Sebastian Trueness.",
            "Emphasizing this all the time.",
            "Now I'm I'm pushing this idea of using machine learning methods.",
            "Also, you know, on a low level grasping and trajectory planning and so on, so maybe that's the way to go.",
            "OK, thank."
        ],
        [
            "Retention.",
            "Questions."
        ],
        [
            "Movie practical question.",
            "This robot actually.",
            "So this was completely trained stuff, but the all these movements on this video.",
            "What do you mean by trained?",
            "So that's all these joints were ran by.",
            "Mystical model sense.",
            "Oh, so the knowledge that we assumed is to have complete knowledge of the kinematics just was not learned anything.",
            "We seem to have this and we also actually assumed to have knowledge about the configuration of the environment.",
            "So Fortunately we didn't have to fiddle with like vision, vision algorithms who would sort of infer back, but the position of the table and things like this is.",
            "The generation of the motion itself and was only a problem of inference.",
            "So there's still some background knowledge, definitely, definitely.",
            "I mean, since we're not most of us, I guess from robotics, so this kind of sure information is also interesting, yeah?",
            "OK OK thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so my name is Marcus and I just started a group in Berlin actually which is part of the Machine Learning Group of class Robert Miller and this group is concerned with actually combining or trying to combine machine learning techniques and robotics techniques.",
                    "label": 0
                },
                {
                    "sent": "So this talk shall be about using probabilistic inference methods in robe.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'd like to start first with this little picture here.",
                    "label": 0
                },
                {
                    "sent": "So if you go to a typical robotics conference and I rose in this case and you just browse through the proceedings of the conference and see what kind of what kind of fields or what kind of topics there is on such a conference.",
                    "label": 0
                },
                {
                    "sent": "And so the first.",
                    "label": 0
                },
                {
                    "sent": "I mean simply, what you see is that there is a whole lot of different diverse errors in robotics, and it turns out that one reason why robotics is such a.",
                    "label": 0
                },
                {
                    "sent": "Daunting enterprise is that actually you need to integrate all of these things in order to build already, you know a functioning system.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, if you talk to some of these people, some robotics is people.",
                    "label": 0
                },
                {
                    "sent": "They said that the actual problem of robotic, like the real problem of robotics is the integration.",
                    "label": 1
                },
                {
                    "sent": "Now, if you think about what might be reasons for this being so difficult, so why is it so difficult in this integration?",
                    "label": 0
                },
                {
                    "sent": "Well, a lot of these fields.",
                    "label": 0
                },
                {
                    "sent": "They use different methods and that's one thing, but they also use different representations in some sense.",
                    "label": 0
                },
                {
                    "sent": "So for instance, the kind of representations that you might use on this.",
                    "label": 0
                },
                {
                    "sent": "Like what I want to focus on on this level here, which my.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be about reinforcement learning or artificial intelligence?",
                    "label": 0
                },
                {
                    "sent": "Imitation learning.",
                    "label": 0
                },
                {
                    "sent": "They tend to be, you know, symbolic or.",
                    "label": 0
                },
                {
                    "sent": "Maybe at least discrete or representable as Markov decision process, whereas the kind of representations that the core engineering roboticists use here for trajectory planning or grass planning or so on, they're just really disjoint so.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go much further into the general discussion, but focus on 2.",
                    "label": 0
                },
                {
                    "sent": "Two errors in particular, and this is, you know this part here.",
                    "label": 0
                },
                {
                    "sent": "Reasoning democratization processes on one hand, but also reasoning about motions trajectories in these kind of things.",
                    "label": 0
                },
                {
                    "sent": "So the question I'm asking is, can I use a common framework?",
                    "label": 0
                },
                {
                    "sent": "A single theory for both of these so that?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No idea I'm following is actually quite a simple one and should be completely obvious to all of you in general.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that you can understand the problem of motion control and planning as a problem of inferring the posterior of unknown variables conditioned on available information.",
                    "label": 1
                },
                {
                    "sent": "Now, what is a bit different in flavor here is just.",
                    "label": 0
                },
                {
                    "sent": "There is not many people who have considered as the unknown variables the decisions you make in future or the control signals that you want to do.",
                    "label": 0
                },
                {
                    "sent": "You want to limit or a whole motion so or trajectories and on the other hand, as thinking as the available information, not the data that we have, but the kind of constraints or goals or rewards that are.",
                    "label": 0
                },
                {
                    "sent": "So what is going to happen here is that I'm proposing to compute posterior distributions over things like motions or over behaviors conditioned on goals today wanna reach?",
                    "label": 0
                },
                {
                    "sent": "OK, so do you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Outline of the talk is pretty short, and it's only 30 minute talk, so I'm first going to give some background.",
                    "label": 0
                },
                {
                    "sent": "Which is some previous work for mine developing this theory of using probabilistic inference for solving Markov decision process.",
                    "label": 1
                },
                {
                    "sent": "And in the second part actually the main part of the talk.",
                    "label": 0
                },
                {
                    "sent": "I want to introduce this.",
                    "label": 0
                },
                {
                    "sent": "New approach of using Bayesian or probabilistic inference techniques.",
                    "label": 0
                },
                {
                    "sent": "Specifically in robotics.",
                    "label": 1
                },
                {
                    "sent": "So really on the low level motor control and motion controller.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe you thought that this you know idea, reasoning about actions is not really new at all.",
                    "label": 0
                },
                {
                    "sent": "It's so straightforward in some sense, and so no surprise that it also has some history and.",
                    "label": 0
                },
                {
                    "sent": "So what I list here is specifically some history of work that was trying to explicitly translate the problem of solving a Markov decision process into a problem of probabilistic inference, and there is some of the work which says that from complexity point of view it's kind of obvious that they are equivalent.",
                    "label": 0
                },
                {
                    "sent": "Would raise a lot of attention.",
                    "label": 0
                },
                {
                    "sent": "Is this work by Attias who in his title actually also says, you know, planning by probabilistic inference, and he proposed a method using probabilistic inference techniques for solving Markov decision processes, but it turns out that it's not really generating optimal policies.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So you did the policy study, compute with these techniques are not equivalent to what you know.",
                    "label": 0
                },
                {
                    "sent": "Reinforcement learning people compute by Bellman equations and things like that.",
                    "label": 0
                },
                {
                    "sent": "There has been some other work using the idea of reasoning about actions like reasoning about the action of another person, recognizing his policy and other work.",
                    "label": 0
                },
                {
                    "sent": "Then why Miss Romo name?",
                    "label": 0
                },
                {
                    "sent": "Then there is the work that I did that I'm going to talk about in a second and some follow up work on this work.",
                    "label": 0
                },
                {
                    "sent": "So I'm briefly going to report on these results here that we published by Signal 206.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The general setup is that we were concerned about Markov decision processes and one way to define democratization process is by setting up this dynamic Bayesian network where you have a stage random variable and an action random variable, and both together just unroll as a Markov process where the next stage depends on previous state and the action that was chosen.",
                    "label": 0
                },
                {
                    "sent": "Then there is also policy here which you can interpret as a parameter of the dynamic Bayesian network and there is also random variables which are the rewards which you.",
                    "label": 0
                },
                {
                    "sent": "Receive at every time step.",
                    "label": 0
                },
                {
                    "sent": "Now the problem by definition, like in reinforcement learning, is find a parameter that is final policy which maximizes this expected future return.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what I'm asking is, can I translate this into like load maximization problem and into the first thought you might have is shouldn't be to difficult by just reinterpreting rewards.",
                    "label": 0
                },
                {
                    "sent": "This likelihoods, if you try, but then you turn, it turns out that it's bit tricky, because actually what you want to maximize here is this expectation over weighted sum of these things and.",
                    "label": 0
                },
                {
                    "sent": "Further, what you want to maximize here is some kind of an infinite horizon problem.",
                    "label": 0
                },
                {
                    "sent": "So what we came up with is that we actually were introducing a mixture of Markov decision processes where the mixture waiting so or the mixture coefficients exactly mimic these discounted waiting.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I just really briefly go over this.",
                    "label": 0
                },
                {
                    "sent": "This is just a picture of what you might conceive as this mixture.",
                    "label": 0
                },
                {
                    "sent": "So what you formally introduce is marketization process for for every possible finite length, and each of these Markov decision process only models you know the reward that you receive after two times set or after exactly time steps.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that we can show that the maximizing the likelihood in this mixture of final plat MDP is exactly.",
                    "label": 1
                },
                {
                    "sent": "Maximizing this is equivalent to maximizing the expected future return in an original Markov decision process.",
                    "label": 1
                },
                {
                    "sent": "I don't go into further details of the proof, but the point is now that we've translated that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem of planning into a problem of likelihood maximization, which means that now we can use an EM algorithm to actually compute an optimal policy, and the core part of the TM is obviously in the step.",
                    "label": 1
                },
                {
                    "sent": "Which is you can use in simple cases just exact inference like forward, backward kind of algorithms.",
                    "label": 1
                },
                {
                    "sent": "And it turns out that for exact inference and simple Markov decision process what this eastep does is very closely related to normal policy evaluation and the M step interns is very closely related to policy update.",
                    "label": 0
                },
                {
                    "sent": "Well, the point is obviously that we've translated the the problem.",
                    "label": 0
                },
                {
                    "sent": "Now two different framework to a different view on finding optimal policies.",
                    "label": 0
                },
                {
                    "sent": "The point is that.",
                    "label": 0
                },
                {
                    "sent": "Inference also works on structured representations, right?",
                    "label": 0
                },
                {
                    "sent": "So you can now quite easily generalize this whole approach to learning policies.",
                    "label": 0
                },
                {
                    "sent": "Also for structured representations of worlds or structured representations of the whole process one.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example is actually partially observable Markov decision process and I just put this here as an example.",
                    "label": 0
                },
                {
                    "sent": "So again, partially observable Markov decision process can also be formalized as a palm DP.",
                    "label": 0
                },
                {
                    "sent": "Sorry, as a dynamic vision network and you have to introduce some kind of latent memory or some kind of I don't know finite state machine or something as a model of the agent, and you can again use inference in order to compute optimal policies.",
                    "label": 0
                },
                {
                    "sent": "OK, so the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The message of this, like introductory part, is basically just saying that palm DP scan solving problems can be reformulated slightly maximization problem and Interestingly now you can use all kinds of inference techniques that are around approximate or loopy BP or whatever for computing optimal policies.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, so let's move onto the actually the main.",
                    "label": 0
                },
                {
                    "sent": "The main part that I want to talk about, which is really robotics.",
                    "label": 0
                },
                {
                    "sent": "So the question is, can we take this idea that I've just presented and use similar ideas also for generating motion and and planning in robotics?",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So I'm not sure how many people are like experts in robotics.",
                    "label": 0
                },
                {
                    "sent": "That's why I thought I started with really like one of the most basic things in Robotics Studio might find in every textbook.",
                    "label": 0
                },
                {
                    "sent": "So considered the following problem, which is standard problem in robotics.",
                    "label": 0
                },
                {
                    "sent": "You have some some robot which has which is in state Q and the state Q usually is defined by all the angles of the joints of the robot.",
                    "label": 0
                },
                {
                    "sent": "So like for my own body, it would be all the angles of all the joints that have also.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unlike an end effector variable, which is typically something like the position of the hand or finger tip, so it could be a 3 dimensional variable, and let's also assume for the moment that we have exact exact knowledge of the kinematic mapping mapping from the joint configuration of the robot to the end effector position and also its derivative.",
                    "label": 0
                },
                {
                    "sent": "Here, like the most basic problem in redundant robotic control, is the question.",
                    "label": 0
                },
                {
                    "sent": "Given that you want to move your finger tip in a bit in a certain direction or with a certain velocity.",
                    "label": 0
                },
                {
                    "sent": "How do you move your joints accordingly, right?",
                    "label": 0
                },
                {
                    "sent": "It's almost trivial to solve this and here like on the left part is a solution given that you know how you want to move your finger tip like velocity of X, how you project it back into the more higher dimensional movement of the joint vector.",
                    "label": 0
                },
                {
                    "sent": "You just use absolute inverse of this linearisation here.",
                    "label": 0
                },
                {
                    "sent": "It turns out well, this is a definition of the pseudoinverse.",
                    "label": 0
                },
                {
                    "sent": "It turns out that there's like infinitely many you can parameterise member some regularization matrix.",
                    "label": 0
                },
                {
                    "sent": "Anyhow.",
                    "label": 0
                },
                {
                    "sent": "Further you can if you want to, you can impose an additional movement which is called a nullspace movement.",
                    "label": 0
                },
                {
                    "sent": "So even if you want to keep your fingertip fixed, for instance, you can do some non space movements and these movements can be generated by this age.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so this is like one of the most basic control schemes in robotics.",
                    "label": 0
                },
                {
                    "sent": "And the question I want to ask is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can I translate this into you know, can I have a different perspective on this?",
                    "label": 0
                },
                {
                    "sent": "More bashan perspective?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that it's really simple to actually reproduce exactly that control law from a patient perspective.",
                    "label": 0
                },
                {
                    "sent": "Assume that we know the current state of the robot, so it's posture assumed that we also know where the end effector should be in the next time step.",
                    "label": 0
                },
                {
                    "sent": "And what we want to infer or what we do not know is what should be the corresponding pose in the next time step in order to reach that position of the other factor.",
                    "label": 0
                },
                {
                    "sent": "So I could come up with these kind of priors.",
                    "label": 0
                },
                {
                    "sent": "So let me say I have a prior that I'm lazy about moving, so I don't want to move much my joints.",
                    "label": 0
                },
                {
                    "sent": "So I have this like Gaussian prior, but the movements of the joints with some variance matrix W and also.",
                    "label": 0
                },
                {
                    "sent": "I include my knowledge about the kinematics as I did before, so I assume that you know the dependency between the end effector position in a joint state is just given by my kinematics and maybe some noise, so maybe I have some measuring noises.",
                    "label": 0
                },
                {
                    "sent": "OK computer posterior over this unknown variable.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The posturing, next time step, and it's all just Gaussian.",
                    "label": 0
                },
                {
                    "sent": "You linearize this at some point maybe, and what you come up with is the posterior that is shown here in this slide, and in particular, this posterior can be approximated by Gaussian, which has like mean the MLP.",
                    "label": 0
                },
                {
                    "sent": "Now, if you take the limit of this kinematic noise C being zero, you reproduce reproduce exactly the classical control law, right?",
                    "label": 0
                },
                {
                    "sent": "And if you Interestingly also if you include some kind of.",
                    "label": 0
                },
                {
                    "sent": "In your prior of movement, if you include some kind of asymmetry so you have a certain preference of movement and this is the ages exactly produces them.",
                    "label": 0
                },
                {
                    "sent": "What is classically called in our space movement.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Called the same thing.",
                    "label": 0
                },
                {
                    "sent": "Also works for.",
                    "label": 0
                },
                {
                    "sent": "Dynamic control and the picture is just a bit different here that now we try to infer really control signal, which might be torques or any kind of other control signal.",
                    "label": 0
                },
                {
                    "sent": "I don't go into detail, but the same thing again.",
                    "label": 0
                },
                {
                    "sent": "We can reproduce the classical results as a limit of the Beijing view.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The point again is OK.",
                    "label": 0
                },
                {
                    "sent": "Classical control can also be reinterpreted, observation, inference, and so finally I want to go beyond all these things.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And move to something where we actually get to new algorithms and new new things.",
                    "label": 0
                },
                {
                    "sent": "So what we've been talking about was motion control, where we considered one time step and I said just doing inference about this here reproduces control loss.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But obviously we've got inference techniques also overtime.",
                    "label": 0
                },
                {
                    "sent": "So we can now think what if you try to infer the posterior overall trajectory's of robot conditioned on where we want to see the end effector at some time, and conditioned on the initial state.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, I guess the general approach is clear, so I don't really have to define or introduce anymore theory, and it's actually quite straightforward to now implement this and show it at some experiments.",
                    "label": 0
                },
                {
                    "sent": "So one of the experiments that we did is we considered like an upper body which had 13 degrees of freedom and we can see.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just as I was talking before the joint state was 13 dimensional, we just considered the right hand position as the end effector, and we also considered a certain collision.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we had an additional binary variable which sort of indicated whether the robot collided with any of its surrounding objects.",
                    "label": 0
                },
                {
                    "sent": "The kind of scenario that we were thinking about can be translated into this dynamic Bayesian network, so this is one of the key things.",
                    "label": 0
                },
                {
                    "sent": "So this scenario that you're confronted with or did you want to solve, you just formulate this, or reformulate this in terms of a dynamic vision network, which is actually quite straightforward, so consider this.",
                    "label": 0
                },
                {
                    "sent": "Dynamic Bayesian network, or I've wrote it here, is a factor graph where again we have the same kind or very similar kind of priors as we had before.",
                    "label": 0
                },
                {
                    "sent": "Like here we have a factor which just implements the laziness of our movement.",
                    "label": 0
                },
                {
                    "sent": "Here we have a factor which just implements the kinematics.",
                    "label": 0
                },
                {
                    "sent": "Here again, we have a factor which implements the laziness of the end effect movement, and here we have a factor which implements the probability of colliding.",
                    "label": 0
                },
                {
                    "sent": "When I do a certain effect movement.",
                    "label": 0
                },
                {
                    "sent": "So once this is formulated as this kind of factor graph, what we can do, we can just use inference techniques and.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our case we use.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We believe propagation with Gaussian belief states, so again discussing belief states where approximation because actually the dependencies are partly nonlinear.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The scenario that we were investigating was to simulate it.",
                    "label": 0
                },
                {
                    "sent": "Upper body of human with table obstacle on top.",
                    "label": 0
                },
                {
                    "sent": "Let me make this bit.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Larger on the next slide, so this was actually the.",
                    "label": 0
                },
                {
                    "sent": "The upper body that we were simulating this is the obstacle.",
                    "label": 0
                },
                {
                    "sent": "Maybe?",
                    "label": 0
                },
                {
                    "sent": "Let's look at this picture here and this is the posterior movement or this.",
                    "label": 0
                },
                {
                    "sent": "This is the posterior over the trajectory conditioned on no collusion and with the.",
                    "label": 0
                },
                {
                    "sent": "With the priors that I that I mentioned, these are just different intermediate snapshots, so this is the initial state.",
                    "label": 0
                },
                {
                    "sent": "This might be the posterior of the state after I don't know tense time steps or something.",
                    "label": 0
                },
                {
                    "sent": "Actually, this ellipsoid which is here illustrated is supposed to illustrate the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The posterior for the Gaussian of the end effector position.",
                    "label": 0
                },
                {
                    "sent": "So these ellipsoids illustrate the Gaussian form of the posterior.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is 1 example.",
                    "label": 0
                },
                {
                    "sent": "Let me show you another example.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's consider a complete simulated human with 39 degrees of freedom.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this case, let's assume that there is lots and lots of possible constraints of motion that you might want to consider.",
                    "label": 0
                },
                {
                    "sent": "So one constraint of motion is again the desired motion of the end effector position, another one is again the collision with objects, another one is that this time the whole body is also supposed to keep balance and another one is that the that you should stay far away from joint limits, which I called your comfortableness.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The coupling videos between these random variables can be represented by a factor graph like this, where all of these you know these task variables, here called are now coupled by some factor to the joint state.",
                    "label": 0
                },
                {
                    "sent": "Again, we have this transition prior, which is just the laziness of movement and again basically the rest of is inference.",
                    "label": 0
                },
                {
                    "sent": "So we could just take any kind of inference package that we have.",
                    "label": 0
                },
                {
                    "sent": "In this case we implement it again using.",
                    "label": 0
                },
                {
                    "sent": "Loopy belief propagation with Gaussian belief representations.",
                    "label": 0
                },
                {
                    "sent": "Which actually is only just a fancy way too.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two for this.",
                    "label": 0
                },
                {
                    "sent": "So if you want to use more classical terms, you could also call it an iterated extended common smoother.",
                    "label": 0
                },
                {
                    "sent": "It has to be iterated just because loops.",
                    "label": 0
                },
                {
                    "sent": "Because the linearizations are some of these dependencies are nonlinear and linear relations and change depending on the posterior.",
                    "label": 0
                },
                {
                    "sent": "So this is fine situated.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is actually an illustration of the results, so the upper body that we were simulating is this human and initially it was just standing upright and upright posture.",
                    "label": 0
                },
                {
                    "sent": "There was a goal constraint at the end effector that the end effector position should be at this black dot.",
                    "label": 0
                },
                {
                    "sent": "Here this is like a marking of the target below this strange kind of table, huge obstacle.",
                    "label": 0
                },
                {
                    "sent": "And as you can see here from this starting with this normal posture, he has to reach this end.",
                    "label": 0
                },
                {
                    "sent": "And position while keeping balance while not colliding with the obstacle and while reaching while reaching the goal.",
                    "label": 0
                },
                {
                    "sent": "Just curious an illustration of the.",
                    "label": 0
                },
                {
                    "sent": "Works Cool, here's an illustration of the.",
                    "label": 0
                },
                {
                    "sent": "Of the inference procedure.",
                    "label": 0
                },
                {
                    "sent": "So this what you see here is like not online, but recorded diesel forward and backward passes.",
                    "label": 0
                },
                {
                    "sent": "These are exactly what you know from Markov processes like forward and backward passes and what you see illustrated.",
                    "label": 0
                },
                {
                    "sent": "Here is the maximum of the current belief, and you know the belief gets better and better after while.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I guess it so takes about.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Maybe 3 forward backward passes in order to converge and yield this movement as the Max maximum probable posterior motion which is coherent with all constraints that we said.",
                    "label": 0
                },
                {
                    "sent": "OK. Um?",
                    "label": 0
                },
                {
                    "sent": "So in terms of computational efficiency, it turns out that it's actually really computationally efficient, so the normal forward path.",
                    "label": 0
                },
                {
                    "sent": "So the first probabilistic forward path has just exactly the same computational cost as a normal reactive controller.",
                    "label": 0
                },
                {
                    "sent": "That is, as a normal, like inverse kinematics controller, and the backwards pass just doubles this cost, and then if you like, do a forward, backward and forward path.",
                    "label": 0
                },
                {
                    "sent": "So this is what I mean here by doing 1 1/2 iterations.",
                    "label": 0
                },
                {
                    "sent": "The quality of the trajectory actually becomes almost optimal already, so the quality can be measured in terms of the length of the trajectory, and it can also be measured in terms of the violation of constraints and just by doing this simple forward, backward forward probabilistic smoothing, you get quite a good trajectory already.",
                    "label": 0
                },
                {
                    "sent": "What I like about this example is that it's sort of really pinpointing this idea of using this idea of Bayesian inference to compute the posterior of emotions, which is coherent with all these constraints.",
                    "label": 0
                },
                {
                    "sent": "So it's like like beige and Fusion, but here not.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About sensors, but about actions or both motions.",
                    "label": 0
                },
                {
                    "sent": "I think this is what I just put here in this slide.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "If I have a bit of time, actually I show you another movie and I must admit so.",
                    "label": 0
                },
                {
                    "sent": "This is not using exactly the techniques that have presented so actually it's fake that I present this movie here currently, but it's using similar techniques, but which are based on gradient descents actually are not on proper inference because implementing proper inference would have been too expensive.",
                    "label": 0
                },
                {
                    "sent": "So this is some work that I've done together with Honda and it's going to repeat in a second.",
                    "label": 1
                },
                {
                    "sent": "I'm going to explain a bit more.",
                    "label": 0
                },
                {
                    "sent": "So we were trying to generate movements again, which are coherent with constraints like having no conditions and stuff.",
                    "label": 0
                },
                {
                    "sent": "What you see here is that we use an internal simulation in order to optimize the trajectory and this optimization procedure you could just we're looking at these green balls moving a bit.",
                    "label": 0
                },
                {
                    "sent": "This was exactly the online movie of the optimization procedure.",
                    "label": 0
                },
                {
                    "sent": "It takes about a second for these kinds of movies.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "It's kind of slow in the movie.",
                    "label": 0
                },
                {
                    "sent": "If you look at the fingertip of it, you see that there is some pointy thing at the fingertip.",
                    "label": 0
                },
                {
                    "sent": "OK, I think actually that's enough.",
                    "label": 0
                },
                {
                    "sent": "So the point is it's similar problems over here is another movie and.",
                    "label": 0
                },
                {
                    "sent": "We used I mean the same objectives, the same objective functions, but we didn't actually use probabilistic inference, but a cheaper gradient way to compute these posteriors, and again for all of these movements it took about a second to generate these solutions.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, as a summary.",
                    "label": 0
                },
                {
                    "sent": "So I've been talking about planning in market decision process in the introduction, and I've been talking about generating motion and robotic control in this main part in later part and at the point is that.",
                    "label": 1
                },
                {
                    "sent": "I like this view that all of them can be can be seen as a problem of inference, inferring posteriors of emotions, or over actions and.",
                    "label": 1
                },
                {
                    "sent": "So what is?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is maybe a bit different to the standard idea of fusing orb Asian Fusion instead here what we're using is actually a goal, so constraints rather than censor information as it is usually done.",
                    "label": 0
                },
                {
                    "sent": "What is nice?",
                    "label": 0
                },
                {
                    "sent": "Obviously about approaches that it's now a new application for machine learning, right?",
                    "label": 0
                },
                {
                    "sent": "So all the guys, all the people that work on inference techniques about approximate inference techniques, variational and they all now invited actually to run their stuff on robotics.",
                    "label": 0
                },
                {
                    "sent": "And some people start doing this like none of the fighters which I'm working on and I find this quite exciting.",
                    "label": 0
                },
                {
                    "sent": "Actually to get all these people perhaps working on robotics now.",
                    "label": 0
                },
                {
                    "sent": "Another thing what I like about is that.",
                    "label": 0
                },
                {
                    "sent": "So you could say that what we found here is one single computational principle which works equally on sensor.",
                    "label": 0
                },
                {
                    "sent": "As we all know, you know based methods for sensor interpreting or sensor processing for motor.",
                    "label": 0
                },
                {
                    "sent": "As I have to steer presented and also for high level reasoning like in math decision process.",
                    "label": 0
                },
                {
                    "sent": "And now if you think about back to this one thing I mentioned in the introduction is 1 one.",
                    "label": 0
                },
                {
                    "sent": "Difficulty in integrating all these things.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, it's different methods, but it's also different representations.",
                    "label": 0
                },
                {
                    "sent": "It's bit far fetched, but the I mean the dream would be that you actually buy buy, buy, basing.",
                    "label": 0
                },
                {
                    "sent": "All of these approaches some similar kinds of representations that you eventually will be able to connect them up so to have maybe a joint model really join dynamic Bayesian model which includes both like abstract states, discrete states for more abstract reasoning, and on lower level like continuous variables in final final.",
                    "label": 0
                },
                {
                    "sent": "Time scale variables for reasoning about emotions.",
                    "label": 0
                },
                {
                    "sent": "Also, obviously it's quite nice to see that maybe machine learning approaches sort of could eventually.",
                    "label": 0
                },
                {
                    "sent": "You know, contribute to all of these approaches.",
                    "label": 0
                },
                {
                    "sent": "They have needed so far for audio processing or vision processing.",
                    "label": 0
                },
                {
                    "sent": "Also for simultaneous localization and mapping Sebastian Trueness.",
                    "label": 0
                },
                {
                    "sent": "Emphasizing this all the time.",
                    "label": 0
                },
                {
                    "sent": "Now I'm I'm pushing this idea of using machine learning methods.",
                    "label": 0
                },
                {
                    "sent": "Also, you know, on a low level grasping and trajectory planning and so on, so maybe that's the way to go.",
                    "label": 0
                },
                {
                    "sent": "OK, thank.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Retention.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Movie practical question.",
                    "label": 0
                },
                {
                    "sent": "This robot actually.",
                    "label": 0
                },
                {
                    "sent": "So this was completely trained stuff, but the all these movements on this video.",
                    "label": 0
                },
                {
                    "sent": "What do you mean by trained?",
                    "label": 0
                },
                {
                    "sent": "So that's all these joints were ran by.",
                    "label": 0
                },
                {
                    "sent": "Mystical model sense.",
                    "label": 0
                },
                {
                    "sent": "Oh, so the knowledge that we assumed is to have complete knowledge of the kinematics just was not learned anything.",
                    "label": 0
                },
                {
                    "sent": "We seem to have this and we also actually assumed to have knowledge about the configuration of the environment.",
                    "label": 0
                },
                {
                    "sent": "So Fortunately we didn't have to fiddle with like vision, vision algorithms who would sort of infer back, but the position of the table and things like this is.",
                    "label": 0
                },
                {
                    "sent": "The generation of the motion itself and was only a problem of inference.",
                    "label": 0
                },
                {
                    "sent": "So there's still some background knowledge, definitely, definitely.",
                    "label": 0
                },
                {
                    "sent": "I mean, since we're not most of us, I guess from robotics, so this kind of sure information is also interesting, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK OK thanks.",
                    "label": 0
                }
            ]
        }
    }
}