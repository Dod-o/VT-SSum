{
    "id": "dos2ojnqd5wjfhu2ymew6enwl3fh4fiw",
    "title": "PAC-Bayes Analysis: Background and Applications",
    "info": {
        "author": [
            "John Shawe-Taylor, Centre for Computational Statistics and Machine Learning, University College London"
        ],
        "published": "July 30, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/mlss09us_shawe-taylor_pacbaba/",
    "segmentation": [
        [
            "But then I'll talk about some work following on from that with Amaran and Emilio, and then finally some more recent work with Cedric, Ash Ambo, Matthew Higgs, and Manfred Opper.",
            "Actually I should have David Hardoon as well on that list, sorry.",
            "So I say the the aim.",
            "I think of this talk is to show give you a little bit of that sort of perspective of how the generalization bound that I mentioned this morning is is created.",
            "I wanted to do that in the context of linking kernel methods a bit with the Gaussian.",
            "Process modeling and Bayesian view of learning.",
            "And then also talk about the flexibility of the method in terms of showing how it can be applied to some new.",
            "Into new applications so that hopefully gives."
        ],
        [
            "Summary So I'll give you the pack based framework just mentioned.",
            "The core result propagation support vector machines are then mentioned the new application to maximum entropy classification and to Gaussian processes and dynamic."
        ],
        [
            "Systems modeling, so this is just the summary of the."
        ],
        [
            "Sections.",
            "OK, so just a general perspective.",
            "First about general.",
            "The aim of theories.",
            "It's to capture sort of the elements that enable an understanding and analysis of different phenomena.",
            "So there's no right theory, or you know wrong theory really.",
            "Maybe some wrong theories, but.",
            "Every theory can come with different.",
            "Strengths and can tell us different.",
            "Highlight different aspects of the phenomenon we're trying to study and I think in machine learning there are two."
        ],
        [
            "Particular theories that have been quite prominent one is the Bayesian approach and the other is this frequentist one and PAC Bayes sort of ties these two together, so it's quite a nice chance to kind of review a bit of both and see how."
        ],
        [
            "They fit together in support so they make different assumptions and have different range of applicability.",
            "Zan range of result."
        ],
        [
            "The Bayesian approach takes a slightly more detailed probabilistic predictions."
        ],
        [
            "And.",
            "The frequentist has the advantage of making less assumptions, so it only makes an idea independent, identically distributed assumption about the distribution.",
            "I'll mention a bit more about."
        ],
        [
            "The assumptions are.",
            "So just a bit of historical perspective.",
            "The frequentist approach was pioneered in Russia by vapnik and driven kiss.",
            "I think it's fair to say though I'm sure you know it was studied in other areas as well."
        ],
        [
            "In machine learning it came into the West through, well, not from them independently by Leslie Valiant who you heard earlier this afternoon and under the name of probably approximately correct learning, which I think he alluded to as well in his talk."
        ],
        [
            "So typical results state that with high probability, at least one minus Delta, which is where the probably comes from.",
            "Any classifier from a hypothesis class which has low training error will have low generalization error.",
            "In other words, is approximately correct, so it's probably approximately correct in the sense of probably over the generation of the sample.",
            "And approximately correct in terms of the performance on a."
        ],
        [
            "Test point.",
            "In some sense you can see it a bit like a statistical test.",
            "The probably the Delta is the sort of confidence or the you know the significance value of the test.",
            "So you know your inferences made with that confidence.",
            "1 minus Delta from the data.",
            "Of course, you're because it's an IID sample.",
            "You might just have been really, really unlucky with the data you saw and so tough you'd learn something that was irrelevant.",
            "Um?",
            "And the."
        ],
        [
            "Support vector machines were bound within this using something called the Luckiness framework.",
            "It back by myself and Bob Williamson, Peter Bartlett and Martin Anthony."
        ],
        [
            "In 1998 so the Bayesian approach derives from Bayes theorem and the way it works is to assume a prior distribution over the functions that you think will arise as a result of your learning.",
            "So these could be regressives or classifiers.",
            "So you sort of put out there before you start a kind of prior belief of the likelihood.",
            "So distribution over possible functions and then you observe some data.",
            "And you make an assumption about the data that the actual label or output real value in the regression case has been corrupted by specific type of noise.",
            "So it might be a Gaussian random variable or a binary random flip which you are assuming you know.",
            "So you assume.",
            "Firstly, you know that prior distribution over the functions and you assume you know what noise will be added to your.",
            "Output of the training data and therefore you're able to update your belief in the different functions that might have arisen because you can workout the likelihood that a function would have given those outputs that you observed on that training data.",
            "So you can actually generate a posterior distribution of now your updated likelihood of the functions."
        ],
        [
            "In your class.",
            "So this is the posterior distribution, and if you're a a good Bayesian, you'll classify according to the expected classification or progress according to the expected output of that classifier of that function.",
            "And this is the best strategy given that your prior assumption of your prior distribution is correct and your noise model.",
            "Um?",
            "So it's a very nice framework and it also allows you to do things like estimate the variance of your estimation of your prediction and so on, and one of the."
        ],
        [
            "Things it allows you to do is to estimate the evidence for a model, which is basically this the likelihood of having seen the data you observed in the model, taking into account your posterior distribution and and so on all of your updated probabilities you can integrate over that and give you a likelihood of the data in that model.",
            "And this was was mentioned early on by David Mackay as possibly something that could be used both for model selection and for predicting the accuracy of a classifier.",
            "In the classification case, if you are assuming zero noise, in other words, the labels are always correct.",
            "Then the evidence corresponds to the volume of version space.",
            "This is the sort of probability prior probability of the classifiers that actually get all of the training data right, sometimes referred to as version space.",
            "I'll show a diagram in a minute."
        ],
        [
            "So Gaussian process is for regression of sort of a very classic case of this where all of the.",
            "Updating the probability can be done exactly because they are Gaussian distributions for the prior and the noise."
        ],
        [
            "Oh so here is A is a sort of case of a version space, so I imagine this is the space of weight vectors.",
            "Maybe in a long linear function and these are the weights that give output 0 for example X2.",
            "This is the path of weights that give output 0 for X1.",
            "So on one side of this line, correct classification on the other side incorrect.",
            "Similarly here and X3 and X4.",
            "And this is the region which correct classification occurs, and so this is the version space that I referred to in the volume of this region would be the evidence for the model in this case of zero noise."
        ],
        [
            "OK, so the question of linking evidence and generalization was, as I mentioned, a moment ago, hypothesized by Mackay and."
        ],
        [
            "Actually, Bob Williams and I looked at this and and had an estimator for kind of.",
            "A classifier that was taken as the center."
        ],
        [
            "Of the ball.",
            "Here in the center of version space and basically relied on the volume of the ball that could be fit into that."
        ],
        [
            "Region."
        ],
        [
            "So it it sort of looked at the volume, but only of an inscribed sphere, and it included a dependence on the dimension."
        ],
        [
            "It also used that Luckiness framework I mentioned.",
            "A moment ago.",
            "So it.",
            "It didn't.",
            "It sort of was interesting in the sense that it broke then sort of understood bounds on generalization, which were based on the VC dimension.",
            "The VC dimension here."
        ],
        [
            "Could be very high.",
            "So the PAC Bayes theorem sort of takes this idea a bit quite a lot further, it takes the idea of somehow relating the taking into account the number of all the volume of classifiers that are doing well on your data and not just selecting a single classifier and saying I'll go with it.",
            "So it's trying to sort of infer from that.",
            "Volume or family of classifiers that are doing well but you're actually in a benign or better situation than you would be if you were just finding."
        ],
        [
            "A good classifier.",
            "So there was a.",
            "Improve proof and bound due to Matthias Seeger in 2002, with an application to Gaussian processes."
        ],
        [
            "And then addressing process regression, I should sorry a classification and then an application to SVM that I'm going to talk about that."
        ],
        [
            "Did with John Langford and there's an excellent tutorial in J Miller bye bye."
        ],
        [
            "Jaune OK so how does it work so it works if the setup is in some ways quite similar to the Bayesian setup you assume you have a prior distribution over the class of classifiers and you have a posterior distribution but."
        ],
        [
            "But the distribution must be chosen before learning.",
            "And the bound will hold for all choices of the distribution.",
            "Q But so the Q doesn't have to be this Bayesian posterior distribution that you've used some noise model to justify.",
            "You can choose whatever you like.",
            "Ask you.",
            "And P doesn't have to be in a."
        ],
        [
            "Recents accurate, you know you don't have to believe P if you like, so there's a problem for the Bayesian approach, in that there's a.",
            "How do you actually justify P?",
            "It's very difficult to give that prior distribution a kind of a status that is rigorous in any sense, so this approach actually avoids that, because it simply says the bound holds, provided you choose P before you see the data.",
            "Now, if you choose a good P, you'll get a good bound.",
            "If you choose a bad P, you get a bad bound.",
            "Tough cookies, but it's still true either way, so that the status of the bound does not depend on the accuracy of P, But the quality of the bound does.",
            "So this is a slightly different tack or different take if you like."
        ],
        [
            "From the Bayesian.",
            "So it is a frequentist style bound, so we have to assume a priori unknown distribution on the input space that's generating our training data and generating our test data.",
            "And we assume that the."
        ],
        [
            "Training sample is generated ID according to that distribution."
        ],
        [
            "And the measure of generalization is just going to be the misclassification probability of a classifier in that true distribution.",
            "So a random test point, the probability is misclassified."
        ],
        [
            "An empirical, of course, is just the empirical measured error on the training set, so all learning theory is about relating these two and getting as tighter bound as possible between them and in a way that in somehow makes advantage of benign situations that you observe from your training.",
            "So you're hoping that you know apriori you may not be able to say a lot, but after training you observe a large margin, or you observe some benign situation.",
            "And you can infer that this and this are much closer than they might have been in the worst case, so this sense they're kind of distribution dependent or or sort of taking into account properties of the distribution that actually take you away from a worst case pack."
        ],
        [
            "Sound.",
            "So the results actually here is concerned with the performance of a randomized classifier will come back to how you then translate that across to a support vector machine, which of course is a deterministic classifier, But the bound itself looks at a distribution Q the posterior and looks at the choosing C according to Q and then returning the classification due to that due by that classify."
        ],
        [
            "And we are interested in the expected value of that classification error of that randomly drawn.",
            "Point, sorry, randomly drawn classifier.",
            "And of course, again, what we're interested in is getting a tight as possible relationship between the empirical version of that and the true version of that."
        ],
        [
            "Error rate.",
            "Now you might say what you should do is the posterior average.",
            "That's what I said Bayesians like to do.",
            "In other words, take the average vote of the classifiers in the posterior distribution and use that as your classification rather than just pick a random classifier and classify with that.",
            "But we can actually upper bound this error by twice the error that we're measuring.",
            "In the in the bound, now that Factor 2 looks like bad news.",
            "It shouldn't really be there.",
            "In fact, we might expect this to be smaller than this, but unfortunately this is well.",
            "John was and I were looking at trying to reduce it somewhat, but at the moment this seems easiest just to leave that two in there.",
            "Sorry.",
            "Cutie."
        ],
        [
            "Was the error of this randomized classifier where you choose C according to Q and then measure the error rate of that classifier on a randomly generated test point?"
        ],
        [
            "OK.",
            "So, so we would expect this to be at least as good as this, but you know probably better.",
            "But anyway, the bound actually works the other way around, so in fact this is going to be what we actually.",
            "This will correspond.",
            "This classifier will correspond to the support vector machine.",
            "The fixed center actually corresponds to the same classification as the average because of the choice of distribution we take.",
            "So in fact this will be also the bound twice.",
            "QD will be the bound on the support vector machine.",
            "That we actually use."
        ],
        [
            "OK, so this is the form of the band.",
            "Basically it looks at.",
            "The.",
            "Error rate of the empirical classifier and the error rate of the true answer of the true data than you test points and measures a difference between them by the KL divergences between the distributions that you get if you consider these as distributions on zero and plus one.",
            "So what I mean by that is think of plus one indicating making an error and zero indicating you didn't make an error.",
            "Then an error rate.",
            "Here this is just a number.",
            "You think of this as QD, and this is 1 -- Q D and there's a corresponding distribution Q had of S and 1 -- Q head of S, and this is the KL divergent between those two distributions, so it's Q had S times log you out of their server.",
            "QQ D + 1 -- Q out of S log 1 minus QoS over 1 minus QD, but it's just think of it as just a measure of distance between 2 numbers in our case and what we're saying is.",
            "This is our empirical estimate of the error.",
            "We're interested in this quantity and the difference between them is bounded.",
            "If we can also bound this right hand side by something that's not too big.",
            "And the right hand side involves the KL divergent between the prior distribution and the posterior distribution that we chose over our classifiers.",
            "So what we're saying is, there's a tension here between choosing Q to not move too far from the prior, but move far enough to bring the empirical error down.",
            "So we're trying to trade making this small with not making this too big.",
            "And obviously there's an optimal point at which we can set Q and remember we are allowed to choose Q after we've seen the data, so we can post hoc fixed Q to actually minimize the corresponding bound on QD.",
            "Of course we may, in in the case of support vector machines, will choose a particular form of Q, so we'll only optimize over a attractable form of Q.",
            "But in general you could optimize over any distribution Q.",
            "So this is of course the KL divergent between.",
            "Now, I'm not going to go into the details of the proof or any of the.",
            "The components because I wanted to talk mainly about the application of this theorem.",
            "But what I will do is just show initially a very simple application to give you a flavor of how how this works in practice."
        ],
        [
            "And it will be a case of a finite set of functions where we define a prior distribution over those functions.",
            "So P1 for H1 up to PN for HN.",
            "And we're going to assume that the posterior is concentrated on a single function, so we're just going to choose a single function.",
            "So now if you just look at the."
        ],
        [
            "Form of the bound your KL divergent's has a single all of Q weighted on a single function, so this KL will just be minus log.",
            "The prior of that function.",
            "And."
        ],
        [
            "So if we just.",
            "Read that off.",
            "That's minus log Pi here and here.",
            "We have the empirical error because there isn't any stochasticity.",
            "Now it's just the empirical error that chosen function and the true error of that vote chosen function, so this."
        ],
        [
            "She is a standard.",
            "Pretty close to a standard result for finite classes, so slight refinement because you get this KL divergent, which actually is a slightly tighter regime between sort of interpolating between low error and high error regimes and, but here there's also a slight loss in this night extra log term here, but it's just as an illustration to show you an example of applying it."
        ],
        [
            "So OK, what I want to do now is is just take you through the support vector to link back to this morning application."
        ],
        [
            "And then talk."
        ],
        [
            "Briefly about learn."
        ],
        [
            "In the prior and some results to show you how tight this bound can be, because I think there's a.",
            "You know, sort of assumption that most bounds are very, very weak, and I think you know it's quite.",
            "Encouraging to see some bounds that are not not far from from.",
            "Actually, you know, giving infant interesting information about the."
        ],
        [
            "Performance.",
            "So the prior and posterior, both to chosen to be Gaussians with unit variance.",
            "So it's a very simple choice.",
            "Actually, the prior is the same as the Gaussian as the Bayesians would choose for doing Gaussian process regression, but the posterior is different because they would obviously in their case it wouldn't be a Gaussian distribution, it would be an intractable distribution if you were to do the exact posterior for four.",
            "You know a general classification noise model."
        ],
        [
            "So the price."
        ],
        [
            "Very centered at the origin and the posterior is centered at some scaling of the weight vector that the classifier we're considering.",
            "So think of this is just a support vector weight vector in the feature space and scaled normalized to unit vector and then scaled by this factor mu.",
            "So the only thing we're going to change in the posterior in our optimization is going to be the scaling mu.",
            "Yeah he."
        ],
        [
            "OK, so here's the prior at."
        ],
        [
            "The origin here is the weight vector corresponding to the support vector."
        ],
        [
            "Sheen."
        ],
        [
            "Some factor mu and the posterior of."
        ],
        [
            "Did at that point.",
            "So here's the bound, and let's just take you through what the corresponding components become in this situation.",
            "So this is the true error, it's."
        ],
        [
            "The true error of the stochastic classifier remember."
        ],
        [
            "So I already mentioned the SVM actually corresponds to this averaged classifier becausw.",
            "If you take the average classifier.",
            "The classification of a point will, if you look at the points that classify A and input positively or negatively, they will be split by a hyperplane in the white space, and if the weight of this empirical classifier is more than half in favor of plus one, then that hyperplane must go in such a way that the center of the sphere is classifying plus one, and so if we take the center of the sphere is our.",
            "Support vector machine.",
            "It agrees with the majority.",
            "It's simply that there's a hyperplane that splits this spherical Gaussian, and if the center is classified one way, then the majority of the.",
            "Weight of the classifiers will classify the same way, so this is the.",
            "Um?",
            "This agrees with the."
        ],
        [
            "Support vector machine and so, as I indicated before, we can bound it by twice this measured quantity here in the in the performance.",
            "OK, so that's that's the."
        ],
        [
            "The true error, the empirical error.",
            "This is the error of."
        ],
        [
            "Stochastic classifier on the training data.",
            "Now it's possible to actually calculate this exactly because they are Gaussian distributions."
        ],
        [
            "And you end up with the expected value of this function here applied to mu scaled margin we."
        ],
        [
            "The margin is normalized by the weight vector and by the norm of the input.",
            "And this function here the F2."
        ],
        [
            "But as I mentioned this morning, is this inverse ERF function, so we sort of suffer less and less losses.",
            "Our margin gets larger, suffer .5 loss if we're exactly on the boundary of misclassification, and then suffer increasing loss up 2 + .1 if we go misclassified.",
            "So that's the we can compute this exactly using this properties from the support vector output."
        ],
        [
            "The KLA this is."
        ],
        [
            "Again, very easy to compute the."
        ],
        [
            "Prior centered at the origin, posterior centered Gaussian distance."
        ],
        [
            "MU and the measure is just mu squared over 2."
        ],
        [
            "And."
        ],
        [
            "Finally, the Delta is just the confidence."
        ],
        [
            "As I mentioned, the bound holds with probability 1 minus Delta."
        ],
        [
            "Over the training set."
        ],
        [
            "So if we optimize mu, basically if we can write the bound as I indicated this morning in the following way, it's twice the minimum overview of this KL inverse where I just use that to denote the maximum value of P. That's consistent with the bound where the Q is the empirical error.",
            "That's this one and the A.",
            "Is this right hand side of the PAC Bayes bound and what I've mentioned before?",
            "We're choosing new to trade off.",
            "Mu will tend to push up the margins.",
            "Here make this smaller.",
            "But we'll pay a penalty here in making this larger, and so we need to trade those two to optimize the bound."
        ],
        [
            "And as I said this morning, again, this is the corresponding optimization that you get for the support vector machine."
        ],
        [
            "Where I've gained you can't see it, but there's the sort of translation of that inverse ERF function from to this.",
            "Hinge loss"
        ],
        [
            "Function.",
            "OK, so before I show you some sort of bound values, I just want to briefly mention this idea of learning the prior so the idea is that the bound depends on the distance between."
        ],
        [
            "And posterior, maybe we could do a better bound if we actually used part of."
        ],
        [
            "Data to learn the prior and then."
        ],
        [
            "Introduced that learned prior in."
        ],
        [
            "So the bound and computed the stochastic error just on the remaining data, so we actually would significantly reduce the sort of cost the KL.",
            "Determine the right hand side at the expense of a slightly lower value."
        ],
        [
            "Of the of the number of training examples.",
            "So if we do that, we actually can see that we're actually managing to reduce the bound.",
            "This is the vanilla PAC Bayes bound.",
            "This is using that prior trick with, I think 20% of the training data used to learn the prior and the remainder remainder to to estimate the bound were able to get a somewhat tighter performance."
        ],
        [
            "But this also suggests that we could also do cross validation.",
            "Sorry model selection using the bound.",
            "Notice that these bound values are."
        ],
        [
            "Sorry, the bound values here are non trivial, but still you know reasonably large, but they may still indicate the right form of model selection in terms of deciding, say whether to use different parameters C or different kernel widths."
        ],
        [
            "And so on.",
            "So if you do that, you can use the pack SVM to do model selection.",
            "The prior bound that I mentioned, or just 10 fold cross validation and OK 10 fold cross validation is still winning, but these are giving a reasonable run for their money.",
            "On average, in some cases they do a bit better, but in some cases they do quite a bit worse.",
            "So.",
            "There's a tradeoff here."
        ],
        [
            "But you can also use the idea of the prior to actually trained on the second part to optimize the bounds.",
            "You can actually improve the bound still further than what I did up until now was just use the same support vector weight on the in estimating the bound, but you could actually train it on the second half of the data, and that's known as the prior SVM and that actually brings down the model selection to win within .001.",
            "Of the of the.",
            "Crossword cross validation."
        ],
        [
            "And the bound values are really getting quite tight with this particular with this Eater prior approach.",
            "So just to give you a flavor of the kind of things that go on with that approach to bounding.",
            "OK, So what I'd like to do now is move on to these new applications of the."
        ],
        [
            "PAC Bayes bound and the first one I'd like to talk briefly about, is this maximum entropy idea?",
            "So here we're assuming we're learning a linear function of the of some features as a classifier.",
            "An will assume that the one norm bound on the on the weight vector.",
            "So the sum of the components in the weight vector sums.",
            "Sorry, the absolute value of the components in the way vector sums to one or at most one."
        ],
        [
            "And we'd like to have a posterior distribution in such a way that we can bound the probability of misclassification of this function or a function from this class by at most twice the the stochastic error rate of that posterior distribution.",
            "Fred, I've used a slight change of notation.",
            "I'm using E sub Q for what I used to be a Q sub DDD before.",
            "So this is the error rate in the true distribution.",
            "Sorry in this cast.",
            "The true error rate in the stochastic distribution, and I use E hat here."
        ],
        [
            "For the stochastic error rate, which was previously QS apologies for that change of notation.",
            "I think this is slightly better.",
            "I say slightly more readable.",
            "So anyway, what I what we need is to be able to relate the true error that we're interested in of the fixed classifier to some twice the stochastic error as we had with the support vector machine where remember, the stochastic error is going to be the error of Q&A classifier Q drawn according to this distribution posterior distribution Q.",
            "And then we need to also estimate the empirical value of that error on the training set.",
            "OK, So what I'm going to show you now is a is a distribution queue that satisfies well, show will show you satisfies this property and actually motivates a particular type of regularization.",
            "That's very different from what we've seen, so I mean, I'm not sure this is in itself a very useful thing to do, but I just wanted to.",
            "Illustrate that.",
            "You know the idea of Regularising according to say, two norms or one norms is just one way of regularising.",
            "There are other ways of doing it.",
            "When shouldn't be, you know, fixed on just using that particular approach.",
            "It may be that in different learning scenarios are different.",
            "Regularizer may be more appropriate and more useful and will see here a very different regularize actually performs really quite well in comparison with other method."
        ],
        [
            "So.",
            "So here the regularizer will come straight from the PAC Bayes bound.",
            "So what we actually look at is the following as our randomized classifier.",
            "We simply.",
            "I want to have a random weight vector which will be chosen and then will use that to classify the the example and will also choose a random threshold."
        ],
        [
            "And the way we choose a weight vector is simply as a unit vector.",
            "With the I TH unit vector is chosen with probability proportional to the weight.",
            "Remember the sum of the weights was equal to 1, so we can view them as a probability distribution.",
            "So we can select the the unit vector with that probability and we just give it the sign of the Wii.",
            "So the Wii was positive.",
            "We choose the unit vector is positive, otherwise as negative.",
            "So these actually.",
            "What is this classifier going to do is just going to look at a single feature?",
            "And it's going to classify according to that feature with the fee to the offset being a uniform in the interval minus 1 + 1.",
            "And that's our stochastic classifier.",
            "But of course the choice is made with a waiting that's proportional to the weight size of that weight in the in the total weight vector that we're interested in."
        ],
        [
            "OK, so there's a proposition which basically shows that the probability that the randomized castec classifier misclassify's is equal to .5 times.",
            "This is not a less than or equal.",
            "This is actually an equality 1 minus the margin of that weight vector.",
            "So the misclassification is directly related to the margin of the."
        ],
        [
            "Sophian, the proof is quite straightforward.",
            "I won't go through it, but it's just a five line proof, basically moving the probabilities through and turning them back into weightings, and then combining to get the.",
            "The classification."
        ],
        [
            "So there's a nice corollary, which is exactly what we wanted that the probability of misclassification according to the randomized classifier is sorry that room is classification of the function is at most twice the randomized classifier, and that again just follows from the probability that this randomized classifier is greater than .5 means."
        ],
        [
            "Because we have this issue."
        ],
        [
            "Policy here.",
            "That this is a misclassification."
        ],
        [
            "OK."
        ],
        [
            "So that is the property we wanted, so we can read off from the bound.",
            "Misclassification rate for."
        ],
        [
            "Not true.",
            "Thing so now plugging in we we can get a pack based bound but we just need to define."
        ],
        [
            "The prior will that just will be uniform on the unit vectors plus and minus one.",
            "Lost my CJ.",
            "And so the if."
        ],
        [
            "We do that the KL divergent between the prime posteriors, just the log of two N minus the entropy of the of the weight vector, and So what?",
            "Now we're being told is we we need to actually minimize the entropy of the weight vector in and set that against minimizing the empirical error.",
            "So it's a different regularization that we would normally expect.",
            "So for instance, the normal one norm would say make as many weights equal to 0 as possible.",
            "This is saying keep the weights.",
            "Is non zero as possible as spread out as possible?",
            "The one that you pay least for is just having a uniform weight vector, so it's almost like the opposite way round to what you would normally expect."
        ],
        [
            "So it."
        ],
        [
            "Suggests that we optimize.",
            "There is a slight problem that this empirical error is too large.",
            "Because this is a very weak margin."
        ],
        [
            "Because it's just a linear function, but there's a way."
        ],
        [
            "To crank this up, we basically just do a T fold sample as opposed to a single sample and then take a vote over those T fold samples.",
            "And that means that we kind of turn that linear function into a sort of a more.",
            "Steepe which emphasizes the margin function, so we're able to generate margins from smaller.",
            "You know, effect from smaller margins and the."
        ],
        [
            "Empirical error now can be estimated in this way, so it gives a sigmoid like loss as a function of the mark."
        ],
        [
            "And.",
            "And the corresponding cost is just a T fold sampling.",
            "So AT times the.",
            "The KL divergent's."
        ],
        [
            "So it's applied that T factor so it behaves very much like an inverse margin.",
            "There's sort of a margin thing in here.",
            "Anna margin effect on the, so it's a bit like armune what we had before mu T cranks up this, but we pay a cost here.",
            "Oh sorry, we pay a benefit.",
            "We better benefit here so we pay a cost here and get a benefit."
        ],
        [
            "Here.",
            "OK, so we now can you know, crank the handle?",
            "There's an optimization we should solve and this is it.",
            "We maximize, minimize this.",
            "What is the the minus the entropy relative to some margin which we're trying to maximize, and we're allowing some slack variables?"
        ],
        [
            "So it's a very sort of similar idea to the SVM root."
        ],
        [
            "And.",
            "If we solve that, the dual optimization turns out to be the following, where we end up with a gain a sparse set of Alpha vectors, but they actually allow us to compute something which then is passed through an exponential function to give us this weight vector.",
            "So this is a.",
            "This is some vector of values here, which are X.",
            "We apply the exponential to it to get the the corresponding weight vector."
        ],
        [
            "So it's similar to the SVM but with an exponent."
        ],
        [
            "Function we do still get."
        ],
        [
            "At Jewel sparsity and Coordinatewise descent seems to work very, very well as you would with a sort of classical."
        ],
        [
            "SPM this is the effect of the value of T. You can see the bound drops to some low value for a sensible intermediate value of T and then increases."
        ],
        [
            "And these are some errors just to show that the thing works.",
            "So here's the bound.",
            "And here's the error and and the SVM error.",
            "So for various sort of simple datasets.",
            "But we're matching some of the SVM performance in this linear function.",
            "Setting so just it's an illustration of a very different approach to learning that can come."
        ],
        [
            "Out directly from the bound.",
            "OK, the other thing I wanted to mention and this ties back to the Bayesian approach to learning is this bounds on Gaussian process regression.",
            "So trying to now apply these bounds for actually estimating regression performance.",
            "And actually do it for the kosher Bayesian approach now.",
            "So actually doing the proper Bayesian prior and the proper Bayesian noise model so.",
            "The."
        ],
        [
            "The idea of the Bayesian approach is that the kernel now characterizes the prior over the function functions, and it is actually the covariance of the expected correlation between the outputs of the functions on those two points.",
            "When you take that average over the prior distribution.",
            "And the prior is, as I said before, taken to be a Gaussian unit variance centered at the origin in the feature space.",
            "If you just plug crank the handle, you can check that indeed.",
            "In that case the covariance is the kernel function."
        ],
        [
            "You would expect.",
            "In the the noise model that corrupts the output is taken to be additive, Gaussian noise, and so the posterior is also a Gaussian process, so it's another Gaussian, but now it's no longer a spherically symmetrical Gaussian.",
            "It has a genuine covariance, and if you workout the KL divergent but."
        ],
        [
            "In prior and posterior you end up with this expression here, so this is the KL that you need to plug into the bound.",
            "I don't want to go into detail, but the are.",
            "Here is a Cholesky decomposition of the kernel matrix, so this is the kernel matrix K. Here Sigma is the noise that you assume in the noise model, and so there are various components, so you can compute this again.",
            "You know this won't scale to very very large datasets, but it's easy to compute for small."
        ],
        [
            "OK, so now how would you use the PAC Bayes theorem here where you need to create some classifiers?",
            "And indexed by the real value functions."
        ],
        [
            "So the way in which we did it was to consider basically tubes around the OR or intervals around the output, and so we're saying that the classifier H sub F of epsilon, which corresponds to an underlying linear function F classify as XY as output one if y -- F of X is within epsilon.",
            "In other words, it's sort of saying if I'm within epsilon of the correct output.",
            "I'm OK, I gotta, I gotta, uh, one you know, think of this as a reward.",
            "Otherwise I get 0.",
            "And so."
        ],
        [
            "In this case, we can compute the expected value of H, epsilon of F under the posterior function, and here it is, where M of X is the mean of the posterior via vexes it's variance, which you can compute exactly in this Gaussian process formulation.",
            "So we can actually compute this on the on the sample, so we can get an empirical estimate of it, and we can use it also as our test.",
            "On a."
        ],
        [
            "At this point so.",
            "Actually, we would also like to get a lower bound on this quantity, which is basically the.",
            "Is the posterior distribution over our output value for a given input X?",
            "So if we see an input X or test point X, we can estimate its mean and variance, and so this is its probability of the actual output we observe in that distribution.",
            "So what we're saying by getting a lower bound on that is saying how accurately our model of the output actually captures the data.",
            "So we're giving some reliable estimate of those.",
            "If you like measures that the Bayesian can give based on his assumptions, we're now actually be able to give them some sort of substance and say look they do hold with high probability in this case.",
            "There is an extra term that comes in here, so if we plug that in, we actually get an estimate.",
            "A lower bound on this quantity, which is the what I just mentioned plus this sort of error term and this is lower bounded by the Cal to the minus one of that empirical quantity that I described on the previous slide and the D, which is that KL Divergent which was on the two slides back and we can plug all these in an get that lower bound.",
            "So we're able to like verify with the frequentist style bound the accuracy of the Bayesian inference.",
            "So I think you know this is a quite a nice thing to try and do, because OK, in the Gaussian process case you could say that on fairly firm ground, because they're actually once you've made the assumption of the prior distribution and the noise model, at least the inference is exact.",
            "Of course, you could ask argue that you know where do they get those assumptions from.",
            "But as soon as you go to anything that isn't a tractable inference, then you're typically making approximations in the inference step as well.",
            "So you're making an assumption about the prior assumption about the noise model.",
            "An approximation in the inference, and then hoping people will believe what you come out with at the end.",
            "So what I'm hoping from this.",
            "Well, what we can do with this approach is also place bounds in those cases where you don't have, you know you aren't doing the you're doing approximate inference and you.",
            "Actually end up with a posterior that isn't the correct posterior."
        ],
        [
            "But this is for the case of the Gaussian process case where you do have the exact posterior.",
            "This is the KL bound and this is the test performance and you can see there are not a million miles away for three datasets.",
            "Is the robot arm problem first Boston housing and the Forest fire problem?",
            "This was an example where we did use a non Gaussian noise model so that the posterior was not a Gaussian distribution, but we use what's called variational.",
            "Inference, which approximates that posterior distribution with a Gaussian and then you could get a bound on that performance as well, and an estimate of it.",
            "So again, it was able to give realistic lower bounds on that performance.",
            "So I think you know in that sense, this is, I feel, you know, breaking new ground in terms of understanding and justifying what Bayesians are able to infer when they apply."
        ],
        [
            "Methods this is also a plot to show the form of the bound as you vary the noise level eater and this is the test bound and this is the PAC Bayes bound.",
            "So the test set performance in the PAC Bayes bound and you can see again their tracking very closely, but also the form seems to be matched very well in these cases.",
            "This is with different levels of noise model and this is with the.",
            "Varying the level of the epsilon width that I mentioned that the you know you consider you you've actually been accurate.",
            "So as epsilon grows, of course the accuracy gets more get higher, but the found is able to track very closely.",
            "What's happening?"
        ],
        [
            "This is with the Laplacian noise, the non Gaussian noise and again similar patterns are merging with a very different structure to them.",
            "So it seems you might even be able to detect which noise model was more appropriate in a particular application.",
            "These are these are toy datasets."
        ],
        [
            "But so this is for real datasets and they seem to be again following reasonably accurately the test, the bound and the test perform."
        ],
        [
            "So we're taking the next final thing.",
            "I want to talk just very briefly about, is taking this one stage further where we actually have a more complex again, it still Bayesian inference, but it's inference over dynamical systems.",
            "So here we actually have a prior that's defined by a non Gaussian process which is specified by a nonlinear stochastic differential equation.",
            "So you have a linear stochastic differential equation.",
            "The distribution of paths that are generated by that equation are a Gaussian process.",
            "But if you have a nonlinear, then the paths distribution is is is not.",
            "A Gaussian process.",
            "So in order to do inference in this model, you now have a problem that you don't actually have a prior that's Gaussian.",
            "So what I described before we had a prior Gaussian but not a Gaussian noise model, and we did approximate inference.",
            "Here you've got a prior that's not Gaussian.",
            "We're going to assume Gaussian noise model.",
            "And again, we're going to have approximate inference through a variational approximation, and the way we do the variational approximation."
        ],
        [
            "And is so this is just to say that it's equivalent to a sort of limit of a discrete update equations."
        ],
        [
            "So we do the approximation."
        ],
        [
            "Is through a approximating posterior through a time varying linear stochastic differential equation.",
            "As I said, the using a time varying means that you're using a linear stochastic differential equation means that the posterior will therefore be a Gaussian.",
            "And because you're measuring the KL between Q&P, you can actually estimate that, because this is a Gaussian distribution.",
            "So what you're going to do is learn the parameters of this linear stochastic differential equation in order to minimize this KL divergent between prior and posterior and that will be the learning process.",
            "And now you can then apply the kind of backbase bounding to say how good your fit is with that."
        ],
        [
            "Cdata so."
        ],
        [
            "So this is the.",
            "Then right on Nikodym derivative of the distributions posterior and prior for choices of prior drift nonlinear drift and the linear and this is the form it takes.",
            "This is what you need to integrate over the."
        ],
        [
            "Sorry, the expected value of that you need to integrate over the path over the time from T0 to T final where this.",
            "Averaging is over this posterior Gaussian distribution.",
            "So this is the thing you need to actually compute for your Cal in the bow."
        ],
        [
            "And.",
            "And I'm not going to go into the details, but you can actually."
        ],
        [
            "Do these computations and you know it's solving some ODS."
        ],
        [
            "Board and so on.",
            "So don't worry about it, it's."
        ],
        [
            "It can be done and so."
        ],
        [
            "So if you now take the same tactic that I did before in terms of the converting to classifiers, you take a path and convert it to a classifier by saying an observation at time T is going to be given a tick if it's within epsilon of the expected observation at that time, where H is the observation operator.",
            "So this is within epsilon of the observation you would expect along that path at that time.",
            "And so this turns it again into a classifier.",
            "Again, you can do an impera."
        ],
        [
            "Call estimate of that.",
            "And the."
        ],
        [
            "Posterior distribution over the pass can give you a posterior estimate of the expected value of this empirically on your training data."
        ],
        [
            "OK, so."
        ],
        [
            "So you can plug that all together and you end up with the.",
            "This was the KL I mentioned that you need to incorp."
        ],
        [
            "Great, this is the empirical estimate."
        ],
        [
            "And for Sister versus, if sufficiently small values of epsilon, this becomes something like your expected fit with your exactly as we had before the expected fit of your observation with your posterior distribution.",
            "So what's your lower bounding is your expected fit that your observation will have to your posterior distribution?",
            "There's a few factors that."
        ],
        [
            "Don't want to go into an the this is the true true error and the empirical you can estimate from the training data.",
            "So you're going to lower bound again, this expected fit."
        ],
        [
            "And again, we need to play that trick of taking multiple samples again, because a single sample the epsilon gets has to be too big for the in order to get significant."
        ],
        [
            "Values so we can take."
        ],
        [
            "That multiple sampling trick of taking a set of K paths, and we say one if you're within epsilon of one of those K paths."
        ],
        [
            "And again, you can get this come in to give you a stronger lower bound."
        ],
        [
            "And anyway, putting it all together, I've skipped rather fast over this, but you gotta lower bound in of this expected sort of fit to the distribution in terms of its empirical value, and this integrated KL that I mentioned, which is the KL divergent between this non Gaussian prior and Gaussian posterior."
        ],
        [
            "And this is sort of the kind of fit you get with the Lorenz attractor."
        ],
        [
            "Unfortunately, the bound in this."
        ],
        [
            "This is rather weak, so the bound the best bound we could get with .00 four with the true fit being .128.",
            "This is remember a lower bound so.",
            "Still work to do here, but I think you know the idea that you can actually get rigorous bounds for something as complex as a dynamical process approximation using this kind of approach, I think is as a nice.",
            "Sort of way to try and go."
        ],
        [
            "OK, so basically just to summarize overview."
        ],
        [
            "Theory main result."
        ],
        [
            "Application of the bound.",
            "The performance of SVM and hopefully demonstrated that the new bound can be tighter using a prior."
        ],
        [
            "It's gives you low cost model selection, which is almost as good as cross."
        ],
        [
            "Elevation extended to maximum entry."
        ],
        [
            "P and we also consider this Gaussian process lower bounding the accuracy."
        ],
        [
            "The estimator and applied it to this dynamical systems case."
        ],
        [
            "Where the prior is a nonlinear defined by a nonlinear disgusted."
        ],
        [
            "Differential equation and we use this very variational approximation with a posterior which is a Gaussian process defined by a time varying linear SDE.",
            "OK, thanks.",
            "So we have time for a few questions.",
            "Did you characterize?",
            "Maybe give it some nature potato?",
            "Which method works best?",
            "What is that scar?",
            "Well.",
            "When you say which method you mean.",
            "OK, OK. Well, I think yeah, I think that is an art form at the moment.",
            "Actually, to be honest, I mean what one would hope is that as these methods of analyzing the performance get more refined, we can use them to guide actual choices in algorithms.",
            "You know, for instance, what noise model would be best for that data?",
            "You know how to actually do the inference?",
            "Is this type of inference more accurate?",
            "Is this prior a better one?",
            "I mean obviously not over every possible prior, but over a sort of.",
            "You know, you might have a family of priors you're going to consider, and the one that you could generate.",
            "The tightest bound for would be arguably the one you should use.",
            "Data status.",
            "Water bottle outside disassemble Galaxy.",
            "That you mean the distribution generating the data?",
            "Well, then I mean all of this analysis is is sort of distribution independent in some sense?",
            "OK, the way the distribution enters is through your observation of empirical quantities, so we don't make any assumptions, and that's in a sense, the strength I think.",
            "So.",
            "I mean, I should say that for Bayesians they don't make assumptions about the input distribution, they just make assumptions about the corruption of the noise on the thing.",
            "So they also.",
            "Quite strongly, but I think that mean in the beauty of this is that we're hopefully giving you some some bounds that you know people can use to guide.",
            "As you suggested, you know practical decisions in actually analyzing data.",
            "Yep.",
            "Work on statistic.",
            "Different locations of the extended state taxes.",
            "You have been sent.",
            "See mistake, you see.",
            "Well here I was.",
            "I was only observing linear operators on the state."
        ],
        [
            "Um?",
            "So the observations were some linear operator on the state rather than the actual true state, but I wouldn't want to go beyond that at the moment.",
            "I don't think that would be pretty hard.",
            "Um?",
            "Is my guess, and I mean I'm assuming I sort of know the form of the equation.",
            "So then you know the inference of, say parameters of the equation can be done in the Bayesian framework.",
            "You can do, you know, sort of evidence for different parameter settings and try and optimize those, but getting bounds for that would be.",
            "You know, probably quite difficult, I think.",
            "Yes, yes, absolutely yeah.",
            "And and the noise matrix as well, right?",
            "Sorry yeah.",
            "Fire.",
            "College.",
            "So, so you're saying the the Gaussian process prior has some parameters in it?",
            "You could do.",
            "Yeah, I don't see why not.",
            "Absolutely yeah.",
            "I mean, that's like your hyperparameters in.",
            "I mean, if you're doing it Gaussian inference, you could use evidence to set those parameters if you wanted to sort of, you know, just treat them as a model selection, but you could certainly do it by for a finite set of possibilities by cross validation.",
            "Absolutely, yeah, yeah.",
            "And I mean, you could use the kind of techniques here to say, OK, I've got a finite set again, I could just apply my bound, you know, finite number of times and choose the one which gave me the best performance.",
            "As as a way of doing model selection, how good it would be, don't know.",
            "You know, that's.",
            "Could be.",
            "Yeah, I mean it's a little crunchy because you have to sort of run.",
            "I mean what one would really like is to get the bound into the algorithm itself, so it just optimizes, you know, as with the SVM you've got the bound on the support vector machine and the actual algorithm directly optimizes it.",
            "But here you know you probably be doing running it with different parameter settings and sort of then measuring and just.",
            "That's what we were doing with the.",
            "Comparing with cross validation.",
            "OK, but that will close this session.",
            "Let's thank the speaker and we'll move to our next talk."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But then I'll talk about some work following on from that with Amaran and Emilio, and then finally some more recent work with Cedric, Ash Ambo, Matthew Higgs, and Manfred Opper.",
                    "label": 1
                },
                {
                    "sent": "Actually I should have David Hardoon as well on that list, sorry.",
                    "label": 0
                },
                {
                    "sent": "So I say the the aim.",
                    "label": 0
                },
                {
                    "sent": "I think of this talk is to show give you a little bit of that sort of perspective of how the generalization bound that I mentioned this morning is is created.",
                    "label": 0
                },
                {
                    "sent": "I wanted to do that in the context of linking kernel methods a bit with the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Process modeling and Bayesian view of learning.",
                    "label": 0
                },
                {
                    "sent": "And then also talk about the flexibility of the method in terms of showing how it can be applied to some new.",
                    "label": 0
                },
                {
                    "sent": "Into new applications so that hopefully gives.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Summary So I'll give you the pack based framework just mentioned.",
                    "label": 0
                },
                {
                    "sent": "The core result propagation support vector machines are then mentioned the new application to maximum entropy classification and to Gaussian processes and dynamic.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Systems modeling, so this is just the summary of the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sections.",
                    "label": 0
                },
                {
                    "sent": "OK, so just a general perspective.",
                    "label": 0
                },
                {
                    "sent": "First about general.",
                    "label": 0
                },
                {
                    "sent": "The aim of theories.",
                    "label": 0
                },
                {
                    "sent": "It's to capture sort of the elements that enable an understanding and analysis of different phenomena.",
                    "label": 1
                },
                {
                    "sent": "So there's no right theory, or you know wrong theory really.",
                    "label": 0
                },
                {
                    "sent": "Maybe some wrong theories, but.",
                    "label": 0
                },
                {
                    "sent": "Every theory can come with different.",
                    "label": 0
                },
                {
                    "sent": "Strengths and can tell us different.",
                    "label": 0
                },
                {
                    "sent": "Highlight different aspects of the phenomenon we're trying to study and I think in machine learning there are two.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particular theories that have been quite prominent one is the Bayesian approach and the other is this frequentist one and PAC Bayes sort of ties these two together, so it's quite a nice chance to kind of review a bit of both and see how.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They fit together in support so they make different assumptions and have different range of applicability.",
                    "label": 0
                },
                {
                    "sent": "Zan range of result.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Bayesian approach takes a slightly more detailed probabilistic predictions.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The frequentist has the advantage of making less assumptions, so it only makes an idea independent, identically distributed assumption about the distribution.",
                    "label": 0
                },
                {
                    "sent": "I'll mention a bit more about.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The assumptions are.",
                    "label": 0
                },
                {
                    "sent": "So just a bit of historical perspective.",
                    "label": 0
                },
                {
                    "sent": "The frequentist approach was pioneered in Russia by vapnik and driven kiss.",
                    "label": 1
                },
                {
                    "sent": "I think it's fair to say though I'm sure you know it was studied in other areas as well.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In machine learning it came into the West through, well, not from them independently by Leslie Valiant who you heard earlier this afternoon and under the name of probably approximately correct learning, which I think he alluded to as well in his talk.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So typical results state that with high probability, at least one minus Delta, which is where the probably comes from.",
                    "label": 1
                },
                {
                    "sent": "Any classifier from a hypothesis class which has low training error will have low generalization error.",
                    "label": 1
                },
                {
                    "sent": "In other words, is approximately correct, so it's probably approximately correct in the sense of probably over the generation of the sample.",
                    "label": 0
                },
                {
                    "sent": "And approximately correct in terms of the performance on a.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Test point.",
                    "label": 0
                },
                {
                    "sent": "In some sense you can see it a bit like a statistical test.",
                    "label": 0
                },
                {
                    "sent": "The probably the Delta is the sort of confidence or the you know the significance value of the test.",
                    "label": 0
                },
                {
                    "sent": "So you know your inferences made with that confidence.",
                    "label": 0
                },
                {
                    "sent": "1 minus Delta from the data.",
                    "label": 0
                },
                {
                    "sent": "Of course, you're because it's an IID sample.",
                    "label": 0
                },
                {
                    "sent": "You might just have been really, really unlucky with the data you saw and so tough you'd learn something that was irrelevant.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Support vector machines were bound within this using something called the Luckiness framework.",
                    "label": 0
                },
                {
                    "sent": "It back by myself and Bob Williamson, Peter Bartlett and Martin Anthony.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In 1998 so the Bayesian approach derives from Bayes theorem and the way it works is to assume a prior distribution over the functions that you think will arise as a result of your learning.",
                    "label": 1
                },
                {
                    "sent": "So these could be regressives or classifiers.",
                    "label": 0
                },
                {
                    "sent": "So you sort of put out there before you start a kind of prior belief of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "So distribution over possible functions and then you observe some data.",
                    "label": 0
                },
                {
                    "sent": "And you make an assumption about the data that the actual label or output real value in the regression case has been corrupted by specific type of noise.",
                    "label": 0
                },
                {
                    "sent": "So it might be a Gaussian random variable or a binary random flip which you are assuming you know.",
                    "label": 0
                },
                {
                    "sent": "So you assume.",
                    "label": 0
                },
                {
                    "sent": "Firstly, you know that prior distribution over the functions and you assume you know what noise will be added to your.",
                    "label": 0
                },
                {
                    "sent": "Output of the training data and therefore you're able to update your belief in the different functions that might have arisen because you can workout the likelihood that a function would have given those outputs that you observed on that training data.",
                    "label": 0
                },
                {
                    "sent": "So you can actually generate a posterior distribution of now your updated likelihood of the functions.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In your class.",
                    "label": 0
                },
                {
                    "sent": "So this is the posterior distribution, and if you're a a good Bayesian, you'll classify according to the expected classification or progress according to the expected output of that classifier of that function.",
                    "label": 1
                },
                {
                    "sent": "And this is the best strategy given that your prior assumption of your prior distribution is correct and your noise model.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So it's a very nice framework and it also allows you to do things like estimate the variance of your estimation of your prediction and so on, and one of the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things it allows you to do is to estimate the evidence for a model, which is basically this the likelihood of having seen the data you observed in the model, taking into account your posterior distribution and and so on all of your updated probabilities you can integrate over that and give you a likelihood of the data in that model.",
                    "label": 1
                },
                {
                    "sent": "And this was was mentioned early on by David Mackay as possibly something that could be used both for model selection and for predicting the accuracy of a classifier.",
                    "label": 0
                },
                {
                    "sent": "In the classification case, if you are assuming zero noise, in other words, the labels are always correct.",
                    "label": 1
                },
                {
                    "sent": "Then the evidence corresponds to the volume of version space.",
                    "label": 0
                },
                {
                    "sent": "This is the sort of probability prior probability of the classifiers that actually get all of the training data right, sometimes referred to as version space.",
                    "label": 0
                },
                {
                    "sent": "I'll show a diagram in a minute.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Gaussian process is for regression of sort of a very classic case of this where all of the.",
                    "label": 0
                },
                {
                    "sent": "Updating the probability can be done exactly because they are Gaussian distributions for the prior and the noise.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh so here is A is a sort of case of a version space, so I imagine this is the space of weight vectors.",
                    "label": 0
                },
                {
                    "sent": "Maybe in a long linear function and these are the weights that give output 0 for example X2.",
                    "label": 0
                },
                {
                    "sent": "This is the path of weights that give output 0 for X1.",
                    "label": 0
                },
                {
                    "sent": "So on one side of this line, correct classification on the other side incorrect.",
                    "label": 0
                },
                {
                    "sent": "Similarly here and X3 and X4.",
                    "label": 0
                },
                {
                    "sent": "And this is the region which correct classification occurs, and so this is the version space that I referred to in the volume of this region would be the evidence for the model in this case of zero noise.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the question of linking evidence and generalization was, as I mentioned, a moment ago, hypothesized by Mackay and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, Bob Williams and I looked at this and and had an estimator for kind of.",
                    "label": 0
                },
                {
                    "sent": "A classifier that was taken as the center.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the ball.",
                    "label": 0
                },
                {
                    "sent": "Here in the center of version space and basically relied on the volume of the ball that could be fit into that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Region.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it it sort of looked at the volume, but only of an inscribed sphere, and it included a dependence on the dimension.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It also used that Luckiness framework I mentioned.",
                    "label": 0
                },
                {
                    "sent": "A moment ago.",
                    "label": 0
                },
                {
                    "sent": "So it.",
                    "label": 0
                },
                {
                    "sent": "It didn't.",
                    "label": 0
                },
                {
                    "sent": "It sort of was interesting in the sense that it broke then sort of understood bounds on generalization, which were based on the VC dimension.",
                    "label": 0
                },
                {
                    "sent": "The VC dimension here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Could be very high.",
                    "label": 0
                },
                {
                    "sent": "So the PAC Bayes theorem sort of takes this idea a bit quite a lot further, it takes the idea of somehow relating the taking into account the number of all the volume of classifiers that are doing well on your data and not just selecting a single classifier and saying I'll go with it.",
                    "label": 0
                },
                {
                    "sent": "So it's trying to sort of infer from that.",
                    "label": 0
                },
                {
                    "sent": "Volume or family of classifiers that are doing well but you're actually in a benign or better situation than you would be if you were just finding.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A good classifier.",
                    "label": 0
                },
                {
                    "sent": "So there was a.",
                    "label": 0
                },
                {
                    "sent": "Improve proof and bound due to Matthias Seeger in 2002, with an application to Gaussian processes.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then addressing process regression, I should sorry a classification and then an application to SVM that I'm going to talk about that.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did with John Langford and there's an excellent tutorial in J Miller bye bye.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jaune OK so how does it work so it works if the setup is in some ways quite similar to the Bayesian setup you assume you have a prior distribution over the class of classifiers and you have a posterior distribution but.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the distribution must be chosen before learning.",
                    "label": 1
                },
                {
                    "sent": "And the bound will hold for all choices of the distribution.",
                    "label": 0
                },
                {
                    "sent": "Q But so the Q doesn't have to be this Bayesian posterior distribution that you've used some noise model to justify.",
                    "label": 0
                },
                {
                    "sent": "You can choose whatever you like.",
                    "label": 0
                },
                {
                    "sent": "Ask you.",
                    "label": 0
                },
                {
                    "sent": "And P doesn't have to be in a.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Recents accurate, you know you don't have to believe P if you like, so there's a problem for the Bayesian approach, in that there's a.",
                    "label": 0
                },
                {
                    "sent": "How do you actually justify P?",
                    "label": 0
                },
                {
                    "sent": "It's very difficult to give that prior distribution a kind of a status that is rigorous in any sense, so this approach actually avoids that, because it simply says the bound holds, provided you choose P before you see the data.",
                    "label": 0
                },
                {
                    "sent": "Now, if you choose a good P, you'll get a good bound.",
                    "label": 0
                },
                {
                    "sent": "If you choose a bad P, you get a bad bound.",
                    "label": 0
                },
                {
                    "sent": "Tough cookies, but it's still true either way, so that the status of the bound does not depend on the accuracy of P, But the quality of the bound does.",
                    "label": 1
                },
                {
                    "sent": "So this is a slightly different tack or different take if you like.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the Bayesian.",
                    "label": 0
                },
                {
                    "sent": "So it is a frequentist style bound, so we have to assume a priori unknown distribution on the input space that's generating our training data and generating our test data.",
                    "label": 0
                },
                {
                    "sent": "And we assume that the.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training sample is generated ID according to that distribution.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the measure of generalization is just going to be the misclassification probability of a classifier in that true distribution.",
                    "label": 0
                },
                {
                    "sent": "So a random test point, the probability is misclassified.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An empirical, of course, is just the empirical measured error on the training set, so all learning theory is about relating these two and getting as tighter bound as possible between them and in a way that in somehow makes advantage of benign situations that you observe from your training.",
                    "label": 0
                },
                {
                    "sent": "So you're hoping that you know apriori you may not be able to say a lot, but after training you observe a large margin, or you observe some benign situation.",
                    "label": 0
                },
                {
                    "sent": "And you can infer that this and this are much closer than they might have been in the worst case, so this sense they're kind of distribution dependent or or sort of taking into account properties of the distribution that actually take you away from a worst case pack.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sound.",
                    "label": 0
                },
                {
                    "sent": "So the results actually here is concerned with the performance of a randomized classifier will come back to how you then translate that across to a support vector machine, which of course is a deterministic classifier, But the bound itself looks at a distribution Q the posterior and looks at the choosing C according to Q and then returning the classification due to that due by that classify.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we are interested in the expected value of that classification error of that randomly drawn.",
                    "label": 1
                },
                {
                    "sent": "Point, sorry, randomly drawn classifier.",
                    "label": 0
                },
                {
                    "sent": "And of course, again, what we're interested in is getting a tight as possible relationship between the empirical version of that and the true version of that.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Error rate.",
                    "label": 0
                },
                {
                    "sent": "Now you might say what you should do is the posterior average.",
                    "label": 1
                },
                {
                    "sent": "That's what I said Bayesians like to do.",
                    "label": 0
                },
                {
                    "sent": "In other words, take the average vote of the classifiers in the posterior distribution and use that as your classification rather than just pick a random classifier and classify with that.",
                    "label": 1
                },
                {
                    "sent": "But we can actually upper bound this error by twice the error that we're measuring.",
                    "label": 0
                },
                {
                    "sent": "In the in the bound, now that Factor 2 looks like bad news.",
                    "label": 0
                },
                {
                    "sent": "It shouldn't really be there.",
                    "label": 0
                },
                {
                    "sent": "In fact, we might expect this to be smaller than this, but unfortunately this is well.",
                    "label": 0
                },
                {
                    "sent": "John was and I were looking at trying to reduce it somewhat, but at the moment this seems easiest just to leave that two in there.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Cutie.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Was the error of this randomized classifier where you choose C according to Q and then measure the error rate of that classifier on a randomly generated test point?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, so we would expect this to be at least as good as this, but you know probably better.",
                    "label": 0
                },
                {
                    "sent": "But anyway, the bound actually works the other way around, so in fact this is going to be what we actually.",
                    "label": 0
                },
                {
                    "sent": "This will correspond.",
                    "label": 0
                },
                {
                    "sent": "This classifier will correspond to the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "The fixed center actually corresponds to the same classification as the average because of the choice of distribution we take.",
                    "label": 0
                },
                {
                    "sent": "So in fact this will be also the bound twice.",
                    "label": 0
                },
                {
                    "sent": "QD will be the bound on the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "That we actually use.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the form of the band.",
                    "label": 0
                },
                {
                    "sent": "Basically it looks at.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Error rate of the empirical classifier and the error rate of the true answer of the true data than you test points and measures a difference between them by the KL divergences between the distributions that you get if you consider these as distributions on zero and plus one.",
                    "label": 0
                },
                {
                    "sent": "So what I mean by that is think of plus one indicating making an error and zero indicating you didn't make an error.",
                    "label": 0
                },
                {
                    "sent": "Then an error rate.",
                    "label": 0
                },
                {
                    "sent": "Here this is just a number.",
                    "label": 0
                },
                {
                    "sent": "You think of this as QD, and this is 1 -- Q D and there's a corresponding distribution Q had of S and 1 -- Q head of S, and this is the KL divergent between those two distributions, so it's Q had S times log you out of their server.",
                    "label": 0
                },
                {
                    "sent": "QQ D + 1 -- Q out of S log 1 minus QoS over 1 minus QD, but it's just think of it as just a measure of distance between 2 numbers in our case and what we're saying is.",
                    "label": 0
                },
                {
                    "sent": "This is our empirical estimate of the error.",
                    "label": 0
                },
                {
                    "sent": "We're interested in this quantity and the difference between them is bounded.",
                    "label": 0
                },
                {
                    "sent": "If we can also bound this right hand side by something that's not too big.",
                    "label": 0
                },
                {
                    "sent": "And the right hand side involves the KL divergent between the prior distribution and the posterior distribution that we chose over our classifiers.",
                    "label": 0
                },
                {
                    "sent": "So what we're saying is, there's a tension here between choosing Q to not move too far from the prior, but move far enough to bring the empirical error down.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to trade making this small with not making this too big.",
                    "label": 0
                },
                {
                    "sent": "And obviously there's an optimal point at which we can set Q and remember we are allowed to choose Q after we've seen the data, so we can post hoc fixed Q to actually minimize the corresponding bound on QD.",
                    "label": 0
                },
                {
                    "sent": "Of course we may, in in the case of support vector machines, will choose a particular form of Q, so we'll only optimize over a attractable form of Q.",
                    "label": 0
                },
                {
                    "sent": "But in general you could optimize over any distribution Q.",
                    "label": 0
                },
                {
                    "sent": "So this is of course the KL divergent between.",
                    "label": 0
                },
                {
                    "sent": "Now, I'm not going to go into the details of the proof or any of the.",
                    "label": 0
                },
                {
                    "sent": "The components because I wanted to talk mainly about the application of this theorem.",
                    "label": 0
                },
                {
                    "sent": "But what I will do is just show initially a very simple application to give you a flavor of how how this works in practice.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it will be a case of a finite set of functions where we define a prior distribution over those functions.",
                    "label": 0
                },
                {
                    "sent": "So P1 for H1 up to PN for HN.",
                    "label": 0
                },
                {
                    "sent": "And we're going to assume that the posterior is concentrated on a single function, so we're just going to choose a single function.",
                    "label": 0
                },
                {
                    "sent": "So now if you just look at the.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Form of the bound your KL divergent's has a single all of Q weighted on a single function, so this KL will just be minus log.",
                    "label": 0
                },
                {
                    "sent": "The prior of that function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we just.",
                    "label": 0
                },
                {
                    "sent": "Read that off.",
                    "label": 0
                },
                {
                    "sent": "That's minus log Pi here and here.",
                    "label": 0
                },
                {
                    "sent": "We have the empirical error because there isn't any stochasticity.",
                    "label": 0
                },
                {
                    "sent": "Now it's just the empirical error that chosen function and the true error of that vote chosen function, so this.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She is a standard.",
                    "label": 0
                },
                {
                    "sent": "Pretty close to a standard result for finite classes, so slight refinement because you get this KL divergent, which actually is a slightly tighter regime between sort of interpolating between low error and high error regimes and, but here there's also a slight loss in this night extra log term here, but it's just as an illustration to show you an example of applying it.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, what I want to do now is is just take you through the support vector to link back to this morning application.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then talk.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Briefly about learn.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the prior and some results to show you how tight this bound can be, because I think there's a.",
                    "label": 1
                },
                {
                    "sent": "You know, sort of assumption that most bounds are very, very weak, and I think you know it's quite.",
                    "label": 0
                },
                {
                    "sent": "Encouraging to see some bounds that are not not far from from.",
                    "label": 0
                },
                {
                    "sent": "Actually, you know, giving infant interesting information about the.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Performance.",
                    "label": 0
                },
                {
                    "sent": "So the prior and posterior, both to chosen to be Gaussians with unit variance.",
                    "label": 0
                },
                {
                    "sent": "So it's a very simple choice.",
                    "label": 0
                },
                {
                    "sent": "Actually, the prior is the same as the Gaussian as the Bayesians would choose for doing Gaussian process regression, but the posterior is different because they would obviously in their case it wouldn't be a Gaussian distribution, it would be an intractable distribution if you were to do the exact posterior for four.",
                    "label": 0
                },
                {
                    "sent": "You know a general classification noise model.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the price.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very centered at the origin and the posterior is centered at some scaling of the weight vector that the classifier we're considering.",
                    "label": 1
                },
                {
                    "sent": "So think of this is just a support vector weight vector in the feature space and scaled normalized to unit vector and then scaled by this factor mu.",
                    "label": 0
                },
                {
                    "sent": "So the only thing we're going to change in the posterior in our optimization is going to be the scaling mu.",
                    "label": 0
                },
                {
                    "sent": "Yeah he.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's the prior at.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The origin here is the weight vector corresponding to the support vector.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sheen.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some factor mu and the posterior of.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Did at that point.",
                    "label": 0
                },
                {
                    "sent": "So here's the bound, and let's just take you through what the corresponding components become in this situation.",
                    "label": 0
                },
                {
                    "sent": "So this is the true error, it's.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The true error of the stochastic classifier remember.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I already mentioned the SVM actually corresponds to this averaged classifier becausw.",
                    "label": 1
                },
                {
                    "sent": "If you take the average classifier.",
                    "label": 0
                },
                {
                    "sent": "The classification of a point will, if you look at the points that classify A and input positively or negatively, they will be split by a hyperplane in the white space, and if the weight of this empirical classifier is more than half in favor of plus one, then that hyperplane must go in such a way that the center of the sphere is classifying plus one, and so if we take the center of the sphere is our.",
                    "label": 0
                },
                {
                    "sent": "Support vector machine.",
                    "label": 0
                },
                {
                    "sent": "It agrees with the majority.",
                    "label": 1
                },
                {
                    "sent": "It's simply that there's a hyperplane that splits this spherical Gaussian, and if the center is classified one way, then the majority of the.",
                    "label": 0
                },
                {
                    "sent": "Weight of the classifiers will classify the same way, so this is the.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This agrees with the.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Support vector machine and so, as I indicated before, we can bound it by twice this measured quantity here in the in the performance.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's the.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The true error, the empirical error.",
                    "label": 0
                },
                {
                    "sent": "This is the error of.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stochastic classifier on the training data.",
                    "label": 0
                },
                {
                    "sent": "Now it's possible to actually calculate this exactly because they are Gaussian distributions.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you end up with the expected value of this function here applied to mu scaled margin we.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The margin is normalized by the weight vector and by the norm of the input.",
                    "label": 0
                },
                {
                    "sent": "And this function here the F2.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But as I mentioned this morning, is this inverse ERF function, so we sort of suffer less and less losses.",
                    "label": 0
                },
                {
                    "sent": "Our margin gets larger, suffer .5 loss if we're exactly on the boundary of misclassification, and then suffer increasing loss up 2 + .1 if we go misclassified.",
                    "label": 0
                },
                {
                    "sent": "So that's the we can compute this exactly using this properties from the support vector output.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The KLA this is.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, very easy to compute the.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior centered at the origin, posterior centered Gaussian distance.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "MU and the measure is just mu squared over 2.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, the Delta is just the confidence.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I mentioned, the bound holds with probability 1 minus Delta.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over the training set.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we optimize mu, basically if we can write the bound as I indicated this morning in the following way, it's twice the minimum overview of this KL inverse where I just use that to denote the maximum value of P. That's consistent with the bound where the Q is the empirical error.",
                    "label": 1
                },
                {
                    "sent": "That's this one and the A.",
                    "label": 1
                },
                {
                    "sent": "Is this right hand side of the PAC Bayes bound and what I've mentioned before?",
                    "label": 0
                },
                {
                    "sent": "We're choosing new to trade off.",
                    "label": 0
                },
                {
                    "sent": "Mu will tend to push up the margins.",
                    "label": 0
                },
                {
                    "sent": "Here make this smaller.",
                    "label": 0
                },
                {
                    "sent": "But we'll pay a penalty here in making this larger, and so we need to trade those two to optimize the bound.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as I said this morning, again, this is the corresponding optimization that you get for the support vector machine.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where I've gained you can't see it, but there's the sort of translation of that inverse ERF function from to this.",
                    "label": 0
                },
                {
                    "sent": "Hinge loss",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "OK, so before I show you some sort of bound values, I just want to briefly mention this idea of learning the prior so the idea is that the bound depends on the distance between.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And posterior, maybe we could do a better bound if we actually used part of.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data to learn the prior and then.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Introduced that learned prior in.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the bound and computed the stochastic error just on the remaining data, so we actually would significantly reduce the sort of cost the KL.",
                    "label": 0
                },
                {
                    "sent": "Determine the right hand side at the expense of a slightly lower value.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the of the number of training examples.",
                    "label": 0
                },
                {
                    "sent": "So if we do that, we actually can see that we're actually managing to reduce the bound.",
                    "label": 0
                },
                {
                    "sent": "This is the vanilla PAC Bayes bound.",
                    "label": 0
                },
                {
                    "sent": "This is using that prior trick with, I think 20% of the training data used to learn the prior and the remainder remainder to to estimate the bound were able to get a somewhat tighter performance.",
                    "label": 1
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this also suggests that we could also do cross validation.",
                    "label": 0
                },
                {
                    "sent": "Sorry model selection using the bound.",
                    "label": 0
                },
                {
                    "sent": "Notice that these bound values are.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, the bound values here are non trivial, but still you know reasonably large, but they may still indicate the right form of model selection in terms of deciding, say whether to use different parameters C or different kernel widths.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So if you do that, you can use the pack SVM to do model selection.",
                    "label": 0
                },
                {
                    "sent": "The prior bound that I mentioned, or just 10 fold cross validation and OK 10 fold cross validation is still winning, but these are giving a reasonable run for their money.",
                    "label": 0
                },
                {
                    "sent": "On average, in some cases they do a bit better, but in some cases they do quite a bit worse.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's a tradeoff here.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you can also use the idea of the prior to actually trained on the second part to optimize the bounds.",
                    "label": 0
                },
                {
                    "sent": "You can actually improve the bound still further than what I did up until now was just use the same support vector weight on the in estimating the bound, but you could actually train it on the second half of the data, and that's known as the prior SVM and that actually brings down the model selection to win within .001.",
                    "label": 0
                },
                {
                    "sent": "Of the of the.",
                    "label": 0
                },
                {
                    "sent": "Crossword cross validation.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the bound values are really getting quite tight with this particular with this Eater prior approach.",
                    "label": 0
                },
                {
                    "sent": "So just to give you a flavor of the kind of things that go on with that approach to bounding.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'd like to do now is move on to these new applications of the.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "PAC Bayes bound and the first one I'd like to talk briefly about, is this maximum entropy idea?",
                    "label": 0
                },
                {
                    "sent": "So here we're assuming we're learning a linear function of the of some features as a classifier.",
                    "label": 0
                },
                {
                    "sent": "An will assume that the one norm bound on the on the weight vector.",
                    "label": 0
                },
                {
                    "sent": "So the sum of the components in the weight vector sums.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the absolute value of the components in the way vector sums to one or at most one.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we'd like to have a posterior distribution in such a way that we can bound the probability of misclassification of this function or a function from this class by at most twice the the stochastic error rate of that posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Fred, I've used a slight change of notation.",
                    "label": 0
                },
                {
                    "sent": "I'm using E sub Q for what I used to be a Q sub DDD before.",
                    "label": 0
                },
                {
                    "sent": "So this is the error rate in the true distribution.",
                    "label": 0
                },
                {
                    "sent": "Sorry in this cast.",
                    "label": 0
                },
                {
                    "sent": "The true error rate in the stochastic distribution, and I use E hat here.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the stochastic error rate, which was previously QS apologies for that change of notation.",
                    "label": 0
                },
                {
                    "sent": "I think this is slightly better.",
                    "label": 0
                },
                {
                    "sent": "I say slightly more readable.",
                    "label": 0
                },
                {
                    "sent": "So anyway, what I what we need is to be able to relate the true error that we're interested in of the fixed classifier to some twice the stochastic error as we had with the support vector machine where remember, the stochastic error is going to be the error of Q&A classifier Q drawn according to this distribution posterior distribution Q.",
                    "label": 0
                },
                {
                    "sent": "And then we need to also estimate the empirical value of that error on the training set.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'm going to show you now is a is a distribution queue that satisfies well, show will show you satisfies this property and actually motivates a particular type of regularization.",
                    "label": 0
                },
                {
                    "sent": "That's very different from what we've seen, so I mean, I'm not sure this is in itself a very useful thing to do, but I just wanted to.",
                    "label": 0
                },
                {
                    "sent": "Illustrate that.",
                    "label": 0
                },
                {
                    "sent": "You know the idea of Regularising according to say, two norms or one norms is just one way of regularising.",
                    "label": 0
                },
                {
                    "sent": "There are other ways of doing it.",
                    "label": 0
                },
                {
                    "sent": "When shouldn't be, you know, fixed on just using that particular approach.",
                    "label": 0
                },
                {
                    "sent": "It may be that in different learning scenarios are different.",
                    "label": 0
                },
                {
                    "sent": "Regularizer may be more appropriate and more useful and will see here a very different regularize actually performs really quite well in comparison with other method.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So here the regularizer will come straight from the PAC Bayes bound.",
                    "label": 0
                },
                {
                    "sent": "So what we actually look at is the following as our randomized classifier.",
                    "label": 0
                },
                {
                    "sent": "We simply.",
                    "label": 0
                },
                {
                    "sent": "I want to have a random weight vector which will be chosen and then will use that to classify the the example and will also choose a random threshold.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the way we choose a weight vector is simply as a unit vector.",
                    "label": 0
                },
                {
                    "sent": "With the I TH unit vector is chosen with probability proportional to the weight.",
                    "label": 0
                },
                {
                    "sent": "Remember the sum of the weights was equal to 1, so we can view them as a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "So we can select the the unit vector with that probability and we just give it the sign of the Wii.",
                    "label": 0
                },
                {
                    "sent": "So the Wii was positive.",
                    "label": 0
                },
                {
                    "sent": "We choose the unit vector is positive, otherwise as negative.",
                    "label": 0
                },
                {
                    "sent": "So these actually.",
                    "label": 0
                },
                {
                    "sent": "What is this classifier going to do is just going to look at a single feature?",
                    "label": 0
                },
                {
                    "sent": "And it's going to classify according to that feature with the fee to the offset being a uniform in the interval minus 1 + 1.",
                    "label": 0
                },
                {
                    "sent": "And that's our stochastic classifier.",
                    "label": 0
                },
                {
                    "sent": "But of course the choice is made with a waiting that's proportional to the weight size of that weight in the in the total weight vector that we're interested in.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there's a proposition which basically shows that the probability that the randomized castec classifier misclassify's is equal to .5 times.",
                    "label": 0
                },
                {
                    "sent": "This is not a less than or equal.",
                    "label": 0
                },
                {
                    "sent": "This is actually an equality 1 minus the margin of that weight vector.",
                    "label": 0
                },
                {
                    "sent": "So the misclassification is directly related to the margin of the.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sophian, the proof is quite straightforward.",
                    "label": 0
                },
                {
                    "sent": "I won't go through it, but it's just a five line proof, basically moving the probabilities through and turning them back into weightings, and then combining to get the.",
                    "label": 0
                },
                {
                    "sent": "The classification.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there's a nice corollary, which is exactly what we wanted that the probability of misclassification according to the randomized classifier is sorry that room is classification of the function is at most twice the randomized classifier, and that again just follows from the probability that this randomized classifier is greater than .5 means.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because we have this issue.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Policy here.",
                    "label": 0
                },
                {
                    "sent": "That this is a misclassification.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that is the property we wanted, so we can read off from the bound.",
                    "label": 0
                },
                {
                    "sent": "Misclassification rate for.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not true.",
                    "label": 0
                },
                {
                    "sent": "Thing so now plugging in we we can get a pack based bound but we just need to define.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The prior will that just will be uniform on the unit vectors plus and minus one.",
                    "label": 0
                },
                {
                    "sent": "Lost my CJ.",
                    "label": 0
                },
                {
                    "sent": "And so the if.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do that the KL divergent between the prime posteriors, just the log of two N minus the entropy of the of the weight vector, and So what?",
                    "label": 0
                },
                {
                    "sent": "Now we're being told is we we need to actually minimize the entropy of the weight vector in and set that against minimizing the empirical error.",
                    "label": 0
                },
                {
                    "sent": "So it's a different regularization that we would normally expect.",
                    "label": 0
                },
                {
                    "sent": "So for instance, the normal one norm would say make as many weights equal to 0 as possible.",
                    "label": 0
                },
                {
                    "sent": "This is saying keep the weights.",
                    "label": 0
                },
                {
                    "sent": "Is non zero as possible as spread out as possible?",
                    "label": 0
                },
                {
                    "sent": "The one that you pay least for is just having a uniform weight vector, so it's almost like the opposite way round to what you would normally expect.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suggests that we optimize.",
                    "label": 0
                },
                {
                    "sent": "There is a slight problem that this empirical error is too large.",
                    "label": 0
                },
                {
                    "sent": "Because this is a very weak margin.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because it's just a linear function, but there's a way.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To crank this up, we basically just do a T fold sample as opposed to a single sample and then take a vote over those T fold samples.",
                    "label": 0
                },
                {
                    "sent": "And that means that we kind of turn that linear function into a sort of a more.",
                    "label": 0
                },
                {
                    "sent": "Steepe which emphasizes the margin function, so we're able to generate margins from smaller.",
                    "label": 0
                },
                {
                    "sent": "You know, effect from smaller margins and the.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Empirical error now can be estimated in this way, so it gives a sigmoid like loss as a function of the mark.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And the corresponding cost is just a T fold sampling.",
                    "label": 0
                },
                {
                    "sent": "So AT times the.",
                    "label": 0
                },
                {
                    "sent": "The KL divergent's.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's applied that T factor so it behaves very much like an inverse margin.",
                    "label": 0
                },
                {
                    "sent": "There's sort of a margin thing in here.",
                    "label": 0
                },
                {
                    "sent": "Anna margin effect on the, so it's a bit like armune what we had before mu T cranks up this, but we pay a cost here.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, we pay a benefit.",
                    "label": 0
                },
                {
                    "sent": "We better benefit here so we pay a cost here and get a benefit.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "OK, so we now can you know, crank the handle?",
                    "label": 0
                },
                {
                    "sent": "There's an optimization we should solve and this is it.",
                    "label": 0
                },
                {
                    "sent": "We maximize, minimize this.",
                    "label": 0
                },
                {
                    "sent": "What is the the minus the entropy relative to some margin which we're trying to maximize, and we're allowing some slack variables?",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's a very sort of similar idea to the SVM root.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If we solve that, the dual optimization turns out to be the following, where we end up with a gain a sparse set of Alpha vectors, but they actually allow us to compute something which then is passed through an exponential function to give us this weight vector.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                },
                {
                    "sent": "This is some vector of values here, which are X.",
                    "label": 0
                },
                {
                    "sent": "We apply the exponential to it to get the the corresponding weight vector.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's similar to the SVM but with an exponent.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function we do still get.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At Jewel sparsity and Coordinatewise descent seems to work very, very well as you would with a sort of classical.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "SPM this is the effect of the value of T. You can see the bound drops to some low value for a sensible intermediate value of T and then increases.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And these are some errors just to show that the thing works.",
                    "label": 0
                },
                {
                    "sent": "So here's the bound.",
                    "label": 0
                },
                {
                    "sent": "And here's the error and and the SVM error.",
                    "label": 0
                },
                {
                    "sent": "So for various sort of simple datasets.",
                    "label": 0
                },
                {
                    "sent": "But we're matching some of the SVM performance in this linear function.",
                    "label": 0
                },
                {
                    "sent": "Setting so just it's an illustration of a very different approach to learning that can come.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out directly from the bound.",
                    "label": 0
                },
                {
                    "sent": "OK, the other thing I wanted to mention and this ties back to the Bayesian approach to learning is this bounds on Gaussian process regression.",
                    "label": 0
                },
                {
                    "sent": "So trying to now apply these bounds for actually estimating regression performance.",
                    "label": 0
                },
                {
                    "sent": "And actually do it for the kosher Bayesian approach now.",
                    "label": 0
                },
                {
                    "sent": "So actually doing the proper Bayesian prior and the proper Bayesian noise model so.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea of the Bayesian approach is that the kernel now characterizes the prior over the function functions, and it is actually the covariance of the expected correlation between the outputs of the functions on those two points.",
                    "label": 0
                },
                {
                    "sent": "When you take that average over the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "And the prior is, as I said before, taken to be a Gaussian unit variance centered at the origin in the feature space.",
                    "label": 0
                },
                {
                    "sent": "If you just plug crank the handle, you can check that indeed.",
                    "label": 0
                },
                {
                    "sent": "In that case the covariance is the kernel function.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You would expect.",
                    "label": 0
                },
                {
                    "sent": "In the the noise model that corrupts the output is taken to be additive, Gaussian noise, and so the posterior is also a Gaussian process, so it's another Gaussian, but now it's no longer a spherically symmetrical Gaussian.",
                    "label": 1
                },
                {
                    "sent": "It has a genuine covariance, and if you workout the KL divergent but.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In prior and posterior you end up with this expression here, so this is the KL that you need to plug into the bound.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into detail, but the are.",
                    "label": 0
                },
                {
                    "sent": "Here is a Cholesky decomposition of the kernel matrix, so this is the kernel matrix K. Here Sigma is the noise that you assume in the noise model, and so there are various components, so you can compute this again.",
                    "label": 1
                },
                {
                    "sent": "You know this won't scale to very very large datasets, but it's easy to compute for small.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now how would you use the PAC Bayes theorem here where you need to create some classifiers?",
                    "label": 0
                },
                {
                    "sent": "And indexed by the real value functions.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way in which we did it was to consider basically tubes around the OR or intervals around the output, and so we're saying that the classifier H sub F of epsilon, which corresponds to an underlying linear function F classify as XY as output one if y -- F of X is within epsilon.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's sort of saying if I'm within epsilon of the correct output.",
                    "label": 0
                },
                {
                    "sent": "I'm OK, I gotta, I gotta, uh, one you know, think of this as a reward.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I get 0.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, we can compute the expected value of H, epsilon of F under the posterior function, and here it is, where M of X is the mean of the posterior via vexes it's variance, which you can compute exactly in this Gaussian process formulation.",
                    "label": 1
                },
                {
                    "sent": "So we can actually compute this on the on the sample, so we can get an empirical estimate of it, and we can use it also as our test.",
                    "label": 0
                },
                {
                    "sent": "On a.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At this point so.",
                    "label": 0
                },
                {
                    "sent": "Actually, we would also like to get a lower bound on this quantity, which is basically the.",
                    "label": 0
                },
                {
                    "sent": "Is the posterior distribution over our output value for a given input X?",
                    "label": 0
                },
                {
                    "sent": "So if we see an input X or test point X, we can estimate its mean and variance, and so this is its probability of the actual output we observe in that distribution.",
                    "label": 0
                },
                {
                    "sent": "So what we're saying by getting a lower bound on that is saying how accurately our model of the output actually captures the data.",
                    "label": 0
                },
                {
                    "sent": "So we're giving some reliable estimate of those.",
                    "label": 0
                },
                {
                    "sent": "If you like measures that the Bayesian can give based on his assumptions, we're now actually be able to give them some sort of substance and say look they do hold with high probability in this case.",
                    "label": 0
                },
                {
                    "sent": "There is an extra term that comes in here, so if we plug that in, we actually get an estimate.",
                    "label": 0
                },
                {
                    "sent": "A lower bound on this quantity, which is the what I just mentioned plus this sort of error term and this is lower bounded by the Cal to the minus one of that empirical quantity that I described on the previous slide and the D, which is that KL Divergent which was on the two slides back and we can plug all these in an get that lower bound.",
                    "label": 0
                },
                {
                    "sent": "So we're able to like verify with the frequentist style bound the accuracy of the Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "So I think you know this is a quite a nice thing to try and do, because OK, in the Gaussian process case you could say that on fairly firm ground, because they're actually once you've made the assumption of the prior distribution and the noise model, at least the inference is exact.",
                    "label": 0
                },
                {
                    "sent": "Of course, you could ask argue that you know where do they get those assumptions from.",
                    "label": 0
                },
                {
                    "sent": "But as soon as you go to anything that isn't a tractable inference, then you're typically making approximations in the inference step as well.",
                    "label": 0
                },
                {
                    "sent": "So you're making an assumption about the prior assumption about the noise model.",
                    "label": 0
                },
                {
                    "sent": "An approximation in the inference, and then hoping people will believe what you come out with at the end.",
                    "label": 0
                },
                {
                    "sent": "So what I'm hoping from this.",
                    "label": 0
                },
                {
                    "sent": "Well, what we can do with this approach is also place bounds in those cases where you don't have, you know you aren't doing the you're doing approximate inference and you.",
                    "label": 0
                },
                {
                    "sent": "Actually end up with a posterior that isn't the correct posterior.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this is for the case of the Gaussian process case where you do have the exact posterior.",
                    "label": 0
                },
                {
                    "sent": "This is the KL bound and this is the test performance and you can see there are not a million miles away for three datasets.",
                    "label": 0
                },
                {
                    "sent": "Is the robot arm problem first Boston housing and the Forest fire problem?",
                    "label": 0
                },
                {
                    "sent": "This was an example where we did use a non Gaussian noise model so that the posterior was not a Gaussian distribution, but we use what's called variational.",
                    "label": 0
                },
                {
                    "sent": "Inference, which approximates that posterior distribution with a Gaussian and then you could get a bound on that performance as well, and an estimate of it.",
                    "label": 0
                },
                {
                    "sent": "So again, it was able to give realistic lower bounds on that performance.",
                    "label": 0
                },
                {
                    "sent": "So I think you know in that sense, this is, I feel, you know, breaking new ground in terms of understanding and justifying what Bayesians are able to infer when they apply.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods this is also a plot to show the form of the bound as you vary the noise level eater and this is the test bound and this is the PAC Bayes bound.",
                    "label": 0
                },
                {
                    "sent": "So the test set performance in the PAC Bayes bound and you can see again their tracking very closely, but also the form seems to be matched very well in these cases.",
                    "label": 0
                },
                {
                    "sent": "This is with different levels of noise model and this is with the.",
                    "label": 0
                },
                {
                    "sent": "Varying the level of the epsilon width that I mentioned that the you know you consider you you've actually been accurate.",
                    "label": 0
                },
                {
                    "sent": "So as epsilon grows, of course the accuracy gets more get higher, but the found is able to track very closely.",
                    "label": 0
                },
                {
                    "sent": "What's happening?",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is with the Laplacian noise, the non Gaussian noise and again similar patterns are merging with a very different structure to them.",
                    "label": 0
                },
                {
                    "sent": "So it seems you might even be able to detect which noise model was more appropriate in a particular application.",
                    "label": 0
                },
                {
                    "sent": "These are these are toy datasets.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But so this is for real datasets and they seem to be again following reasonably accurately the test, the bound and the test perform.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're taking the next final thing.",
                    "label": 0
                },
                {
                    "sent": "I want to talk just very briefly about, is taking this one stage further where we actually have a more complex again, it still Bayesian inference, but it's inference over dynamical systems.",
                    "label": 0
                },
                {
                    "sent": "So here we actually have a prior that's defined by a non Gaussian process which is specified by a nonlinear stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "So you have a linear stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "The distribution of paths that are generated by that equation are a Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "But if you have a nonlinear, then the paths distribution is is is not.",
                    "label": 0
                },
                {
                    "sent": "A Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So in order to do inference in this model, you now have a problem that you don't actually have a prior that's Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So what I described before we had a prior Gaussian but not a Gaussian noise model, and we did approximate inference.",
                    "label": 0
                },
                {
                    "sent": "Here you've got a prior that's not Gaussian.",
                    "label": 0
                },
                {
                    "sent": "We're going to assume Gaussian noise model.",
                    "label": 0
                },
                {
                    "sent": "And again, we're going to have approximate inference through a variational approximation, and the way we do the variational approximation.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And is so this is just to say that it's equivalent to a sort of limit of a discrete update equations.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we do the approximation.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is through a approximating posterior through a time varying linear stochastic differential equation.",
                    "label": 1
                },
                {
                    "sent": "As I said, the using a time varying means that you're using a linear stochastic differential equation means that the posterior will therefore be a Gaussian.",
                    "label": 1
                },
                {
                    "sent": "And because you're measuring the KL between Q&P, you can actually estimate that, because this is a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So what you're going to do is learn the parameters of this linear stochastic differential equation in order to minimize this KL divergent between prior and posterior and that will be the learning process.",
                    "label": 0
                },
                {
                    "sent": "And now you can then apply the kind of backbase bounding to say how good your fit is with that.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cdata so.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Then right on Nikodym derivative of the distributions posterior and prior for choices of prior drift nonlinear drift and the linear and this is the form it takes.",
                    "label": 0
                },
                {
                    "sent": "This is what you need to integrate over the.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry, the expected value of that you need to integrate over the path over the time from T0 to T final where this.",
                    "label": 0
                },
                {
                    "sent": "Averaging is over this posterior Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is the thing you need to actually compute for your Cal in the bow.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And I'm not going to go into the details, but you can actually.",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do these computations and you know it's solving some ODS.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Board and so on.",
                    "label": 0
                },
                {
                    "sent": "So don't worry about it, it's.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can be done and so.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you now take the same tactic that I did before in terms of the converting to classifiers, you take a path and convert it to a classifier by saying an observation at time T is going to be given a tick if it's within epsilon of the expected observation at that time, where H is the observation operator.",
                    "label": 0
                },
                {
                    "sent": "So this is within epsilon of the observation you would expect along that path at that time.",
                    "label": 0
                },
                {
                    "sent": "And so this turns it again into a classifier.",
                    "label": 0
                },
                {
                    "sent": "Again, you can do an impera.",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Call estimate of that.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Posterior distribution over the pass can give you a posterior estimate of the expected value of this empirically on your training data.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_144": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can plug that all together and you end up with the.",
                    "label": 0
                },
                {
                    "sent": "This was the KL I mentioned that you need to incorp.",
                    "label": 0
                }
            ]
        },
        "clip_145": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Great, this is the empirical estimate.",
                    "label": 0
                }
            ]
        },
        "clip_146": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for Sister versus, if sufficiently small values of epsilon, this becomes something like your expected fit with your exactly as we had before the expected fit of your observation with your posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So what's your lower bounding is your expected fit that your observation will have to your posterior distribution?",
                    "label": 0
                },
                {
                    "sent": "There's a few factors that.",
                    "label": 0
                }
            ]
        },
        "clip_147": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't want to go into an the this is the true true error and the empirical you can estimate from the training data.",
                    "label": 0
                },
                {
                    "sent": "So you're going to lower bound again, this expected fit.",
                    "label": 0
                }
            ]
        },
        "clip_148": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, we need to play that trick of taking multiple samples again, because a single sample the epsilon gets has to be too big for the in order to get significant.",
                    "label": 0
                }
            ]
        },
        "clip_149": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Values so we can take.",
                    "label": 0
                }
            ]
        },
        "clip_150": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That multiple sampling trick of taking a set of K paths, and we say one if you're within epsilon of one of those K paths.",
                    "label": 0
                }
            ]
        },
        "clip_151": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, you can get this come in to give you a stronger lower bound.",
                    "label": 0
                }
            ]
        },
        "clip_152": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And anyway, putting it all together, I've skipped rather fast over this, but you gotta lower bound in of this expected sort of fit to the distribution in terms of its empirical value, and this integrated KL that I mentioned, which is the KL divergent between this non Gaussian prior and Gaussian posterior.",
                    "label": 0
                }
            ]
        },
        "clip_153": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is sort of the kind of fit you get with the Lorenz attractor.",
                    "label": 0
                }
            ]
        },
        "clip_154": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unfortunately, the bound in this.",
                    "label": 0
                }
            ]
        },
        "clip_155": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is rather weak, so the bound the best bound we could get with .00 four with the true fit being .128.",
                    "label": 0
                },
                {
                    "sent": "This is remember a lower bound so.",
                    "label": 0
                },
                {
                    "sent": "Still work to do here, but I think you know the idea that you can actually get rigorous bounds for something as complex as a dynamical process approximation using this kind of approach, I think is as a nice.",
                    "label": 0
                },
                {
                    "sent": "Sort of way to try and go.",
                    "label": 0
                }
            ]
        },
        "clip_156": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so basically just to summarize overview.",
                    "label": 0
                }
            ]
        },
        "clip_157": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Theory main result.",
                    "label": 0
                }
            ]
        },
        "clip_158": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Application of the bound.",
                    "label": 0
                },
                {
                    "sent": "The performance of SVM and hopefully demonstrated that the new bound can be tighter using a prior.",
                    "label": 0
                }
            ]
        },
        "clip_159": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's gives you low cost model selection, which is almost as good as cross.",
                    "label": 0
                }
            ]
        },
        "clip_160": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elevation extended to maximum entry.",
                    "label": 0
                }
            ]
        },
        "clip_161": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "P and we also consider this Gaussian process lower bounding the accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_162": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The estimator and applied it to this dynamical systems case.",
                    "label": 0
                }
            ]
        },
        "clip_163": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where the prior is a nonlinear defined by a nonlinear disgusted.",
                    "label": 0
                }
            ]
        },
        "clip_164": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Differential equation and we use this very variational approximation with a posterior which is a Gaussian process defined by a time varying linear SDE.",
                    "label": 1
                },
                {
                    "sent": "OK, thanks.",
                    "label": 0
                },
                {
                    "sent": "So we have time for a few questions.",
                    "label": 0
                },
                {
                    "sent": "Did you characterize?",
                    "label": 0
                },
                {
                    "sent": "Maybe give it some nature potato?",
                    "label": 0
                },
                {
                    "sent": "Which method works best?",
                    "label": 0
                },
                {
                    "sent": "What is that scar?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "When you say which method you mean.",
                    "label": 0
                },
                {
                    "sent": "OK, OK. Well, I think yeah, I think that is an art form at the moment.",
                    "label": 0
                },
                {
                    "sent": "Actually, to be honest, I mean what one would hope is that as these methods of analyzing the performance get more refined, we can use them to guide actual choices in algorithms.",
                    "label": 0
                },
                {
                    "sent": "You know, for instance, what noise model would be best for that data?",
                    "label": 0
                },
                {
                    "sent": "You know how to actually do the inference?",
                    "label": 0
                },
                {
                    "sent": "Is this type of inference more accurate?",
                    "label": 0
                },
                {
                    "sent": "Is this prior a better one?",
                    "label": 0
                },
                {
                    "sent": "I mean obviously not over every possible prior, but over a sort of.",
                    "label": 0
                },
                {
                    "sent": "You know, you might have a family of priors you're going to consider, and the one that you could generate.",
                    "label": 0
                },
                {
                    "sent": "The tightest bound for would be arguably the one you should use.",
                    "label": 0
                },
                {
                    "sent": "Data status.",
                    "label": 0
                },
                {
                    "sent": "Water bottle outside disassemble Galaxy.",
                    "label": 0
                },
                {
                    "sent": "That you mean the distribution generating the data?",
                    "label": 0
                },
                {
                    "sent": "Well, then I mean all of this analysis is is sort of distribution independent in some sense?",
                    "label": 0
                },
                {
                    "sent": "OK, the way the distribution enters is through your observation of empirical quantities, so we don't make any assumptions, and that's in a sense, the strength I think.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I mean, I should say that for Bayesians they don't make assumptions about the input distribution, they just make assumptions about the corruption of the noise on the thing.",
                    "label": 0
                },
                {
                    "sent": "So they also.",
                    "label": 0
                },
                {
                    "sent": "Quite strongly, but I think that mean in the beauty of this is that we're hopefully giving you some some bounds that you know people can use to guide.",
                    "label": 0
                },
                {
                    "sent": "As you suggested, you know practical decisions in actually analyzing data.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Work on statistic.",
                    "label": 0
                },
                {
                    "sent": "Different locations of the extended state taxes.",
                    "label": 0
                },
                {
                    "sent": "You have been sent.",
                    "label": 0
                },
                {
                    "sent": "See mistake, you see.",
                    "label": 0
                },
                {
                    "sent": "Well here I was.",
                    "label": 0
                },
                {
                    "sent": "I was only observing linear operators on the state.",
                    "label": 0
                }
            ]
        },
        "clip_165": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the observations were some linear operator on the state rather than the actual true state, but I wouldn't want to go beyond that at the moment.",
                    "label": 0
                },
                {
                    "sent": "I don't think that would be pretty hard.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Is my guess, and I mean I'm assuming I sort of know the form of the equation.",
                    "label": 0
                },
                {
                    "sent": "So then you know the inference of, say parameters of the equation can be done in the Bayesian framework.",
                    "label": 0
                },
                {
                    "sent": "You can do, you know, sort of evidence for different parameter settings and try and optimize those, but getting bounds for that would be.",
                    "label": 0
                },
                {
                    "sent": "You know, probably quite difficult, I think.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, absolutely yeah.",
                    "label": 0
                },
                {
                    "sent": "And and the noise matrix as well, right?",
                    "label": 0
                },
                {
                    "sent": "Sorry yeah.",
                    "label": 0
                },
                {
                    "sent": "Fire.",
                    "label": 0
                },
                {
                    "sent": "College.",
                    "label": 0
                },
                {
                    "sent": "So, so you're saying the the Gaussian process prior has some parameters in it?",
                    "label": 0
                },
                {
                    "sent": "You could do.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't see why not.",
                    "label": 0
                },
                {
                    "sent": "Absolutely yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's like your hyperparameters in.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you're doing it Gaussian inference, you could use evidence to set those parameters if you wanted to sort of, you know, just treat them as a model selection, but you could certainly do it by for a finite set of possibilities by cross validation.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "And I mean, you could use the kind of techniques here to say, OK, I've got a finite set again, I could just apply my bound, you know, finite number of times and choose the one which gave me the best performance.",
                    "label": 0
                },
                {
                    "sent": "As as a way of doing model selection, how good it would be, don't know.",
                    "label": 0
                },
                {
                    "sent": "You know, that's.",
                    "label": 0
                },
                {
                    "sent": "Could be.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean it's a little crunchy because you have to sort of run.",
                    "label": 0
                },
                {
                    "sent": "I mean what one would really like is to get the bound into the algorithm itself, so it just optimizes, you know, as with the SVM you've got the bound on the support vector machine and the actual algorithm directly optimizes it.",
                    "label": 0
                },
                {
                    "sent": "But here you know you probably be doing running it with different parameter settings and sort of then measuring and just.",
                    "label": 0
                },
                {
                    "sent": "That's what we were doing with the.",
                    "label": 0
                },
                {
                    "sent": "Comparing with cross validation.",
                    "label": 0
                },
                {
                    "sent": "OK, but that will close this session.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker and we'll move to our next talk.",
                    "label": 0
                }
            ]
        }
    }
}