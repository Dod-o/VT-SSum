{
    "id": "5t5a4y7d35yw2zmdhvyxzm3tnkqwclew",
    "title": "Information-theoretic bounds on learning network dynamics",
    "info": {
        "author": [
            "Andrea Montanari, Department of Electrical Engineering, Stanford University"
        ],
        "published": "March 7, 2016",
        "recorded": "December 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Physics->Statistical Physics"
        ]
    },
    "url": "http://videolectures.net/netadis2015_montanari_network_dynamics/",
    "segmentation": [
        [
            "So this is actually based on joint work with the Rosie Benton Mortes Ibrahimi and she said gave talk about first part of this work in the morning.",
            "So I'm left.",
            "So I'll do the leftovers.",
            "Uh."
        ],
        [
            "So the general question is, say that every dynamical system and they observe it for some interval of time, and then I want to reconstruct the dynamics of the system.",
            "The underlying loads that through this system and how long should I keep looking at this system before before I can actually learn it reliable?",
            "And and what I focus on is really.",
            "Information theoretic tools for getting lower bounds just said this morning.",
            "Talked about one type of system that is linear as these mostly and how to recover this with convex optimization methods so it's more achievability result here I'm trying to look a little bit converses and explain how you prove that you cannot do it unless you wait for last time and I will try to be tutorial since this is kind of an interdisciplinary workshop with physicist etc.",
            "I'll try to not assume any basically any information theory background and explain the idea that come from information theory for doing this kind of of lower bounds.",
            "So those of you that are expert in these again excuse."
        ],
        [
            "So this is the plan.",
            "I'll describe the general approach and then some simple example and then a more advanced application.",
            "This is really what we did with with Jose Morteza and you know there is a lot of space for improvement.",
            "Really here we we really did something basic."
        ],
        [
            "OK."
        ],
        [
            "What is the general approach?",
            "So let's set up some notation.",
            "So generally the way the way you set up in this thing, you have some parameter space.",
            "This is all possible dynamics scribbled possible dynamically, generate and say that you have a family of probability distribution.",
            "This can be whatever dynamic process that are parameterized by this lower case data and then then what you want to come up is an estimator.",
            "So these are probability distribution on a common space calligraphic X.",
            "And what you do is that you observe some data X and you want to come up with an estimator that is a mapping from the data to the parameter space.",
            "OK, and and what.",
            "I'll talk about.",
            "OK, so there are many ways to characterize what is the quality of an estimator, but something that people like some people like is the minimax risk.",
            "So what does it mean?",
            "So I focused on this for simplicity.",
            "You look at the probability.",
            "So here my space will be discreet for simplicity.",
            "And so the minimax sticks is the probability that Tita hat your estimator is not equal to the ground truth maximised.",
            "Overall Tita in the parameter space and minimize overall the estimators.",
            "OK, so this is the optimum that you can opt to achieve error problem in error probability in the worst possible case there is lots of reasons to be creative about this metric, but I will stick to this.",
            "There's a long history."
        ],
        [
            "OK, so so information theory, so OK, so let's let's be simple.",
            "We have to start from the entropy.",
            "The entropy of probability distribution of a random variable is just some over X of P of X log X.",
            "Something that I will need is the conditional entropy.",
            "So this is something that physicist know and something that fixes don't always noise, which is the conditional entropy is just the expectation of log of P of X given Y.",
            "So as entropy describe the uncertainty about X, the conditional entropy says the uncertainty about tax after observed Y. OK."
        ],
        [
            "OK, so this is 1 slide.",
            "All you need to know about information theory.",
            "Now basically 80% of proofs information to use couple of things.",
            "One is OK now little bit more, but OK, I'm overstating, but one is the chain rule.",
            "The entropy of X&Y is the entropy of Y plus the entropy of X given Y, which makes beautiful sense.",
            "The uncertainty about two things is the uncertainty about the first plus the uncertainty about the second.",
            "Given that you observe first, this is one reason why this is very powerful and the other that comes from first is subadditivity.",
            "Or our joint empty of X&Y is upper bounded by the sum of the entropy of X plus the entropy of Y with equality final if they are independent, so this follows from the 1st oh.",
            "Follows from the 1st.",
            "Just by recognizing or by proving that the entropy of X given Y is less than the entropy of X, this is called the data processing.",
            "Inequality sometimes, so if you have your your observer, why you reduce the uncertainty about tax?",
            "OK, these are the two important.",
            "The two things that I will use.",
            "OK."
        ],
        [
            "OK.",
            "So now how do I lower bound using information theory desirer probability?",
            "OK, so this is very nice idea.",
            "It's very simple, but very nice idea.",
            "The maximum of the error probability of.",
            "Yeah, over any parameter Tita is lower bounded.",
            "So what I do is that I invented prior I invent.",
            "I'll take out of my prior P. OK, and for any prior the maximum error probability is less than the expected error probability, so this gives a lower bound.",
            "Of course, the integral of a function is less than.",
            "Why one reason why is beautiful is that you know if you're a.",
            "If you have some in their problem, MA Bayesian or I'm a frequentist that tells you that you don't need to decide, you can do Bayesian work and get.",
            "Lower bound on frequentist stuff and this is what has been done forever, by the way.",
            "So this is this definition of this.",
            "Now once you have, you are in this.",
            "Yeah, Bayesian worth.",
            "This is an inequality that I will not prove, but is 2 lines funnest inequality is is 50 years old.",
            "The probability that you get it wrong.",
            "Is lower bounded by the uncertain T as quantified by the conditional entropy divided by logarithm of the cardinality of this of this parameter space.",
            "This is the simplest filing quality, so if they have a lot of uncertainty, if I have more bits, we see example.",
            "If I love a lot of uncertainty, I cannot estimate data reliably.",
            "OK, so this in particular, if you put these two together implies that the minimax risk is lower bounded by.",
            "Again, the conditional entropy.",
            "This minus one you have to put it there to make it through, but it doesn't really count is upper bounded by this ratio."
        ],
        [
            "OK, so I'll do some simple example just to show."
        ],
        [
            "So that this makes sense.",
            "Simplest example, say that you want to.",
            "Your parents are spaces of size 2 to them, so you want to learn if data is 1232 to the Emma and what they observe our ID.",
            "Are iid random variable.",
            "Conditional on Tita that have this distribution is simply X is equal to Tita.",
            "With probability 1 -- P times you know this stuff and it's different from Tita with probability POK.",
            "So with priority 1 -- P observed the truth and what priority P observe something else so I.",
            "And I'm known object that takes 2 to the N values and I observe it with probability 1 -- P and with probability P observed just pure noise.",
            "How many time?",
            "Do I have to observe this so this is a dynamical system?",
            "How many, how long could we have to observe it in such a way to figure out what what data is?",
            "Well, you need Emma bits to the end waving argument is you need.",
            "I'm a bit to specify Tita.",
            "Each time I will.",
            "I will have an observational guard there a constant number of bits, so probably have to observe it for time proportional to M and this is what you can prove with this with this inequality.",
            "So what you do is that you choose P this prior to be uniform.",
            "There is no particular reason for this but."
        ],
        [
            "Makes things easy.",
            "Now you have to compute the entropy of Theta under this prior.",
            "While the entropy under the uniform priors just log off the sides.",
            "And then what you do you want to compute the conditional entropy.",
            "So you do training rule.",
            "Here is the joint entropy minus the entropy of X.",
            "You do another chain rule, so you get the entropy effects given Theta minus the entropy of data.",
            "Once you do the chain rule, this is conditioned.",
            "These are conditionally independent given Theta, so they're entropy is equal to the sum of the entropies.",
            "And now I use the subadditivity design.",
            "Therapy is less than the sum of the entropy, so this gives a lower bound.",
            "Now this is stationary so these things are all the same so you get T and they put a minus and I wrote this in such a way to get something that is positive.",
            "Right?",
            "So at the end of the day.",
            "What they get is that this conditional entropy is lower bounded by.",
            "Tee times something M -- T times something.",
            "So I want this entropy to go to 0.",
            "So I want T to be at least M divided by this object.",
            "So this is how the proof works."
        ],
        [
            "This simple example.",
            "So we use our lower bound.",
            "You get this, you subtract it.",
            "You use the bound that we used, so you get 1 -- T overtime.",
            "So your your error probability of all lower bound goes linearly to 0.",
            "This is you can neglect and gets to 0.",
            "OK, so this tells you that the minimax error probability is basically at least 1/2 unless they observe M minus this.",
            "This guy number sample.",
            "So this quantity really conveys you how much bits of information is each of observation give you.",
            "And so, in fact, it is a name.",
            "It's the mutual information you get.",
            "Log of Theta divided mutual information."
        ],
        [
            "So this is my toy example.",
            "And this is the interpretation I need to accumulate this many bits and each observation gives me.",
            "So this is really elementary.",
            "But this probably you know if you never heard about this, this is the interesting part of the talk.",
            "Now I'll do a less elementary stuff and."
        ],
        [
            "So let me do another simple example that is a little bit more dynamical.",
            "Say that you have now a linear.",
            "So this is auto regressive process X at time T + 1 is a coefficient times X * T type plus plus noise.",
            "So this is kind of a run.",
            "Script version of the artery limbic process if you want data is a coefficient that I want to learn.",
            "OK, so it's a number belong, some some finite sets in 01.",
            "Assume that this is Gaussian.",
            "Once these are Gaussian, these are also Gaussian with mean zero variance one, but they are dependent."
        ],
        [
            "OK, so these are for instance 5 realizations of this process with different choices of parameter and what the task is.",
            "You have to distinguish between these five given a finite observation time.",
            "Here it's very difficult to distinguish them.",
            "They look all the same."
        ],
        [
            "Here I observed them a bit long."
        ],
        [
            "They look all the same.",
            "And here perhaps they start looking a little bit different."
        ],
        [
            "And here they look a little bit different.",
            "In particular, the one below's are a bit smoother, so they have more memory."
        ],
        [
            "OK, and the proof here goes in the same way.",
            "If you want to apply fun in this case.",
            "What you do is the same you write this conditional entropy as the entropy of Tita plus the.",
            "Conditional of X given Theta minus the entropy of X, Now I have to right lower case here because this is differential entropy.",
            "Because variables are continuous, then I do exactly the same.",
            "Here I write this.",
            "With the chain rule are now since this is a Markov process I need these are not independent, but I can only condition on the last step.",
            "Now this is not the Markov process, so I need to condition over all previous times.",
            "But I still get a lower bound, so chain rule you can repeat it many times, so you get entropy given all the past.",
            "But now you get your lower bound if you forget about the past and you just put last step.",
            "OK, so in the end you get the entropy by stationarity minus time times this quantity and also this quantity is.",
            "As a name, this is the mutual information between Titan XD given the previous step.",
            "So in other words.",
            "Yeah.",
            "Anyhow, so so you don't need that.",
            "No uncle, if you don't condition conditional on Tita you have a Markov process, but if it's unconditional average revert it is not able to process because there is a common memory that is used to the theater.",
            "Thank you for the question.",
            "OK, so we have a mistake here.",
            "I mean we have we lose something in this bound."
        ],
        [
            "OK, so if you were about things you know just this gives me the following trivia.",
            "Very easy lemma the number of time.",
            "The length I have to observe this process is the number of bits.",
            "Then I need to specify my parameter divided by information that I gained at each time, and you notice that this in this case, unless in the IID process what happens is not what shows up is not the mutual information, but is mutual information.",
            "Given the past somehow this is in some sense the new information, so this quantity is a name.",
            "Is the condition military information tells you how how much information goes between these two.",
            "If you admit that this is given, this is known.",
            "And it makes a lot of sense, right?",
            "So as you see, these methods give very interpretable bounds.",
            "OK, now this is OK process keep.",
            "This is not very interesting.",
            "You can bound this Eve."
        ],
        [
            "In this case, and if you do some crude bound on the mutual information, you get that the number of observation is at least log of the size of the alphabet of the parameter space divided by the expectation of log of 1 / T to.",
            "So this was a very.",
            "It was a very crude.",
            "Was a very crude calculation in which we lost a lot of terms, but still this capture something in particular.",
            "The minimum time that I have to observe blows up goes to Infinity.",
            "When Tita goes to one teaser random variable.",
            "But suppose that this random variable are some bounded support between zero and one.",
            "It goes to 01 Infinity.",
            "When the log the argument of blog goes to one and they're gonna log, will goes to one.",
            "When Peter goes to one.",
            "And this makes sense, because when Peter goes to one, what you're having is no memory, so you have a.",
            "A bunch of independent random variables and they're all Gaussian.",
            "The distribute the marginal distribution is always normal 01 OK, so this is similar to in a sense.",
            "What you are asking me for help in this case.",
            "You cannot learn dynamics because you know already what is the stationary distribution and the interval of time was was big enough.",
            "Alright, this should blow up.",
            "Also, when Peter goes to 0, but it doesn't because it's a bad bound."
        ],
        [
            "OK, so let me let me discuss a little bit or a more advanced application.",
            "Should go to Infinity only.",
            "Also went into goes to 0 because when Tita goes to zero the process evolves very slowly right?",
            "So you would expect that you have to wait sometime.",
            "OK, I'm not sure about that."
        ],
        [
            "OK, so the more advanced application is this one.",
            "This is what we actually looked at in the paper, so this is a paper few years ago 1012, but it's a stochastic differential equation, so X here is a vector in D dimension.",
            "And evolves in this way the activities some force that depend on X and or some parameter Teeter.",
            "So this is a drift term that is parameterized by Tita.",
            "Plus white noise.",
            "So this is D dimensional white noise.",
            "With this covariance structure.",
            "So this is Delta correlated white noise.",
            "So for each T to hear the drift coefficient is a function from reals to the D2 real today."
        ],
        [
            "OK, so so just to make an example, especially example of the outlook here in using gauge for something different, sorry.",
            "So this is not entropy.",
            "This is some dystonia.",
            "OK, but an example of this that fits in this framework are basically.",
            "Most of physics, right?",
            "Physics is what is the exit equals minus gradient of some potential plus white noise.",
            "This is Langevin equation.",
            "And for instance, you can put a spin model in this framework you put, you know quadratic term that depends on Theta IJZXJ.",
            "So this is an exchange term.",
            "Plus a potential that that's whatever you want.",
            "OK, and here you get the dynamics.",
            "That is some term that is separable plus the evolution of excise influenced by all the other position J."
        ],
        [
            "OK, so when if you repeat the same analysis here.",
            "OK, the first step, just you do find inequality.",
            "What you get is that the number of time I have to observe is at least the log data divided by the mutual information divided by T. So X0T is the whole trajectory between time and time, time zero and times T right?",
            "So this is a trivial thing is just taking five inequality and the T here simplifies by T and this inequality is only telling you that the mutual information is to be bigger than the number of bits that you don't know.",
            "But now to put it in, this can be put in a nice form if you use this result by Duncan and Kadota Zach ions.",
            "If that tells you that if you have any, OK, this was a result about mutual information in channels with feedback, but you can basically think this problem as a channel with feedback where it transmits Tita and you observe this stochastic process basically and what this with these people showed.",
            "Is that the mutual information is equal to the integral of the conditional variance of F given X?",
            "Zero T. So this is basically instantaneously in between time T and times DT.",
            "This is the additional mutual information.",
            "Is the expectation of the conditional variance of F given the past?",
            "So this is similar to this conditional mutual information that I've wrote before.",
            "If time T, there is a lot of variability in F. Given the past that I'm gaining a lot of information, this makes sense.",
            "So this is the interpretation that I just mentioned.",
            "Fine."
        ],
        [
            "OK, so from this just substituted.",
            "OK we have a more complicated theorem than this, but if you substitute and you do something simple in a stationary process you get this very simple formula that the number station so all times are equal.",
            "So this conditional variance is always the same.",
            "It's very simple theorem that tell you that you have to observe at least log the size of the parameter space divided by the expectation of the conditional variance.",
            "Pops OK, so now this I claim that is something that you can formula that is.",
            "Neat enough that you can apply in specific cases and what we did is really apply."
        ],
        [
            "In specific cases, and I'll describe this results next.",
            "OK, the first case, that.",
            "OK, so I don't know if I look more than one actually look only at one case I think.",
            "So the case that we looked at is the linear stochastic differential equation.",
            "So the problem here in applying this formula is really."
        ],
        [
            "That you want to.",
            "You need to compute this OK for applying this formula you need to compute the expectation of the conditional variance of the force given the past.",
            "OK, so for this you need to get a handle on what is the stationary distribution and you need to get a handle on computing this conditional value.",
            "So OK, so yeah.",
            "In this case, you have.",
            "Yeah, so yeah, so we get.",
            "You can get the fertile lower bound so the variance decreases in few condition and more stuff.",
            "Alright, so instead if instead of conditioning all the past.",
            "I condition only on time T, for instance.",
            "OK, so actually OK.",
            "So this formula.",
            "OK, so I'm making here actually.",
            "OK, let's so if I condition only on time, so this should be minus Infinity actually.",
            "So if I condition only on this guy on time T alright, smaller interval of time, I will get a further lower bound.",
            "So you can get further lower bounds.",
            "That is what we were doing before.",
            "If you remember before we had this conditional entropy, an ex given all the past and what I did is just go to lower bound by discarding all the past except the last point.",
            "So if it's convenient.",
            "You can just replace this by just time T, so this becomes physics term purely static calculation one.",
            "Once you make that.",
            "So if you know if you can do your static calculations then you can compute this lower bound."
        ],
        [
            "OK. OK, so So what we did is really compute this only for linear SD.",
            "So for instance this type of SD in which you have the X in DTS minus X + a metrics times X plus.",
            "Brownian motion about this white noise an A is the adjacency matrix of a graph.",
            "OK, so you can think of it, it's zero 1 + -- 1 metric, so you can think of it as describing a graph is not a symmetric graph, so a is not equal A transpose and is signed.",
            "So you can have excitatory and inhibitory kind of interactions in this graph.",
            "So this was not motivated by anything else.",
            "Other than it was simple to do so, we assume that this graph is bounded degree K and one thing that is important of was important.",
            "Assuming for doing calculations was having a lower bound on this.",
            "This is basically is telling you that.",
            "So this is the minimum eigenvalue of the identity's minus mu way.",
            "This is the symmetrized of a, so it's a plus a transpose divided by two.",
            "And this you can think of it as a time scale of the system itself.",
            "Quickly the system relax is to its stationary distribution.",
            "OK, so This is why I give the name 1 / 2 to this quantity.",
            "OK, so you need some assumption of this type that the system mixes rapidly, probably to get that you converge to equilibrium.",
            "This specific assumption is actually stronger than what you would like to to assume, but OK, this is was the first mistake of the proof."
        ],
        [
            "It's not antisymmetric, it's neither symmetric nor antisymmetric, but this assumption in the."
        ],
        [
            "Assumption what matters is only the symmetrized part.",
            "It can be anything.",
            "It's a directed graph.",
            "Not because you can have edge IG and Ji if you have both of them for recharge then the graph the metrics will be symmetric.",
            "Edge height no.",
            "It's a directed graph so edge IJ is a different thing from Edge Ji.",
            "So an edge is a pair of vertices, it's an ordered pair of vertices in directed graph.",
            "So I J&JI are not the same thing.",
            "Sorry, something with.",
            "I need not to point.",
            "OK, OK this.",
            "OK, this is I didn't do a. I didn't think I needed the plot, but this is a plot of a graph that is."
        ],
        [
            "OK. OK, So what we prove is the following.",
            "Applying just this lemma to this case, the time that you need to observe this thing is some function of the degree.",
            "Times.",
            "Oh one over mu.",
            "So what is mu?",
            "did I define it?",
            "What did they find it?",
            "Mu is this object right?",
            "So?",
            "Plus one over mu.",
            "Or the maximum of one over mu.",
            "An overview squared times log P. So this is a very crude bound, but it gets some important features and it could be improved and you are welcome to improve it, but keep some important feature.",
            "For instance, if you think of the degree as bounded, this scales only logarithmically with the number of vertices of the graph, which makes sense because the log of the number of graphs over.",
            "P vertices with bounded degree K scales only logarithmically with the number of of vertices and then you have this explodes with mu and this makes sense becausw.",
            "Becauses Mu goes to 0.",
            "The signal that is related to the metric becomes weaker and weaker, so you need to observe the system longer and longer and it also explored with this store, which is some kind of equality or relaxation time or mixing time, which makes sense.",
            "You have to wait long enough to see the system mixing.",
            "OK, and I think there Jose in the morning talked about the fact that in this model, on a slightly marginal is model using just regularize maximum likelihood.",
            "So this is a least squares plus L1 regularization.",
            "You can achieve this lower bound module or ugly factors.",
            "At least you can achieve the right scaling in P."
        ],
        [
            "OK. OK so some brief conclu."
        ],
        [
            "Ocean OK, I think that the topic of this workshop is interesting.",
            "OK, I shouldn't.",
            "Yeah, I think that there is a lot of interesting things to be done here.",
            "It's largely open and and you know information theory provides a useful way to get.",
            "Meaningful over bound.",
            "That's all, thank you, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is actually based on joint work with the Rosie Benton Mortes Ibrahimi and she said gave talk about first part of this work in the morning.",
                    "label": 0
                },
                {
                    "sent": "So I'm left.",
                    "label": 0
                },
                {
                    "sent": "So I'll do the leftovers.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the general question is, say that every dynamical system and they observe it for some interval of time, and then I want to reconstruct the dynamics of the system.",
                    "label": 0
                },
                {
                    "sent": "The underlying loads that through this system and how long should I keep looking at this system before before I can actually learn it reliable?",
                    "label": 1
                },
                {
                    "sent": "And and what I focus on is really.",
                    "label": 0
                },
                {
                    "sent": "Information theoretic tools for getting lower bounds just said this morning.",
                    "label": 0
                },
                {
                    "sent": "Talked about one type of system that is linear as these mostly and how to recover this with convex optimization methods so it's more achievability result here I'm trying to look a little bit converses and explain how you prove that you cannot do it unless you wait for last time and I will try to be tutorial since this is kind of an interdisciplinary workshop with physicist etc.",
                    "label": 0
                },
                {
                    "sent": "I'll try to not assume any basically any information theory background and explain the idea that come from information theory for doing this kind of of lower bounds.",
                    "label": 0
                },
                {
                    "sent": "So those of you that are expert in these again excuse.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the plan.",
                    "label": 0
                },
                {
                    "sent": "I'll describe the general approach and then some simple example and then a more advanced application.",
                    "label": 0
                },
                {
                    "sent": "This is really what we did with with Jose Morteza and you know there is a lot of space for improvement.",
                    "label": 0
                },
                {
                    "sent": "Really here we we really did something basic.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is the general approach?",
                    "label": 0
                },
                {
                    "sent": "So let's set up some notation.",
                    "label": 0
                },
                {
                    "sent": "So generally the way the way you set up in this thing, you have some parameter space.",
                    "label": 0
                },
                {
                    "sent": "This is all possible dynamics scribbled possible dynamically, generate and say that you have a family of probability distribution.",
                    "label": 1
                },
                {
                    "sent": "This can be whatever dynamic process that are parameterized by this lower case data and then then what you want to come up is an estimator.",
                    "label": 0
                },
                {
                    "sent": "So these are probability distribution on a common space calligraphic X.",
                    "label": 0
                },
                {
                    "sent": "And what you do is that you observe some data X and you want to come up with an estimator that is a mapping from the data to the parameter space.",
                    "label": 0
                },
                {
                    "sent": "OK, and and what.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are many ways to characterize what is the quality of an estimator, but something that people like some people like is the minimax risk.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "So I focused on this for simplicity.",
                    "label": 0
                },
                {
                    "sent": "You look at the probability.",
                    "label": 0
                },
                {
                    "sent": "So here my space will be discreet for simplicity.",
                    "label": 0
                },
                {
                    "sent": "And so the minimax sticks is the probability that Tita hat your estimator is not equal to the ground truth maximised.",
                    "label": 1
                },
                {
                    "sent": "Overall Tita in the parameter space and minimize overall the estimators.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the optimum that you can opt to achieve error problem in error probability in the worst possible case there is lots of reasons to be creative about this metric, but I will stick to this.",
                    "label": 0
                },
                {
                    "sent": "There's a long history.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so information theory, so OK, so let's let's be simple.",
                    "label": 1
                },
                {
                    "sent": "We have to start from the entropy.",
                    "label": 1
                },
                {
                    "sent": "The entropy of probability distribution of a random variable is just some over X of P of X log X.",
                    "label": 0
                },
                {
                    "sent": "Something that I will need is the conditional entropy.",
                    "label": 1
                },
                {
                    "sent": "So this is something that physicist know and something that fixes don't always noise, which is the conditional entropy is just the expectation of log of P of X given Y.",
                    "label": 0
                },
                {
                    "sent": "So as entropy describe the uncertainty about X, the conditional entropy says the uncertainty about tax after observed Y. OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is 1 slide.",
                    "label": 0
                },
                {
                    "sent": "All you need to know about information theory.",
                    "label": 1
                },
                {
                    "sent": "Now basically 80% of proofs information to use couple of things.",
                    "label": 1
                },
                {
                    "sent": "One is OK now little bit more, but OK, I'm overstating, but one is the chain rule.",
                    "label": 0
                },
                {
                    "sent": "The entropy of X&Y is the entropy of Y plus the entropy of X given Y, which makes beautiful sense.",
                    "label": 0
                },
                {
                    "sent": "The uncertainty about two things is the uncertainty about the first plus the uncertainty about the second.",
                    "label": 0
                },
                {
                    "sent": "Given that you observe first, this is one reason why this is very powerful and the other that comes from first is subadditivity.",
                    "label": 0
                },
                {
                    "sent": "Or our joint empty of X&Y is upper bounded by the sum of the entropy of X plus the entropy of Y with equality final if they are independent, so this follows from the 1st oh.",
                    "label": 0
                },
                {
                    "sent": "Follows from the 1st.",
                    "label": 0
                },
                {
                    "sent": "Just by recognizing or by proving that the entropy of X given Y is less than the entropy of X, this is called the data processing.",
                    "label": 0
                },
                {
                    "sent": "Inequality sometimes, so if you have your your observer, why you reduce the uncertainty about tax?",
                    "label": 0
                },
                {
                    "sent": "OK, these are the two important.",
                    "label": 0
                },
                {
                    "sent": "The two things that I will use.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now how do I lower bound using information theory desirer probability?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is very nice idea.",
                    "label": 0
                },
                {
                    "sent": "It's very simple, but very nice idea.",
                    "label": 0
                },
                {
                    "sent": "The maximum of the error probability of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, over any parameter Tita is lower bounded.",
                    "label": 0
                },
                {
                    "sent": "So what I do is that I invented prior I invent.",
                    "label": 0
                },
                {
                    "sent": "I'll take out of my prior P. OK, and for any prior the maximum error probability is less than the expected error probability, so this gives a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Of course, the integral of a function is less than.",
                    "label": 0
                },
                {
                    "sent": "Why one reason why is beautiful is that you know if you're a.",
                    "label": 0
                },
                {
                    "sent": "If you have some in their problem, MA Bayesian or I'm a frequentist that tells you that you don't need to decide, you can do Bayesian work and get.",
                    "label": 0
                },
                {
                    "sent": "Lower bound on frequentist stuff and this is what has been done forever, by the way.",
                    "label": 0
                },
                {
                    "sent": "So this is this definition of this.",
                    "label": 0
                },
                {
                    "sent": "Now once you have, you are in this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Bayesian worth.",
                    "label": 0
                },
                {
                    "sent": "This is an inequality that I will not prove, but is 2 lines funnest inequality is is 50 years old.",
                    "label": 0
                },
                {
                    "sent": "The probability that you get it wrong.",
                    "label": 0
                },
                {
                    "sent": "Is lower bounded by the uncertain T as quantified by the conditional entropy divided by logarithm of the cardinality of this of this parameter space.",
                    "label": 0
                },
                {
                    "sent": "This is the simplest filing quality, so if they have a lot of uncertainty, if I have more bits, we see example.",
                    "label": 0
                },
                {
                    "sent": "If I love a lot of uncertainty, I cannot estimate data reliably.",
                    "label": 0
                },
                {
                    "sent": "OK, so this in particular, if you put these two together implies that the minimax risk is lower bounded by.",
                    "label": 0
                },
                {
                    "sent": "Again, the conditional entropy.",
                    "label": 0
                },
                {
                    "sent": "This minus one you have to put it there to make it through, but it doesn't really count is upper bounded by this ratio.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'll do some simple example just to show.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that this makes sense.",
                    "label": 0
                },
                {
                    "sent": "Simplest example, say that you want to.",
                    "label": 0
                },
                {
                    "sent": "Your parents are spaces of size 2 to them, so you want to learn if data is 1232 to the Emma and what they observe our ID.",
                    "label": 0
                },
                {
                    "sent": "Are iid random variable.",
                    "label": 0
                },
                {
                    "sent": "Conditional on Tita that have this distribution is simply X is equal to Tita.",
                    "label": 0
                },
                {
                    "sent": "With probability 1 -- P times you know this stuff and it's different from Tita with probability POK.",
                    "label": 0
                },
                {
                    "sent": "So with priority 1 -- P observed the truth and what priority P observe something else so I.",
                    "label": 0
                },
                {
                    "sent": "And I'm known object that takes 2 to the N values and I observe it with probability 1 -- P and with probability P observed just pure noise.",
                    "label": 0
                },
                {
                    "sent": "How many time?",
                    "label": 0
                },
                {
                    "sent": "Do I have to observe this so this is a dynamical system?",
                    "label": 0
                },
                {
                    "sent": "How many, how long could we have to observe it in such a way to figure out what what data is?",
                    "label": 0
                },
                {
                    "sent": "Well, you need Emma bits to the end waving argument is you need.",
                    "label": 0
                },
                {
                    "sent": "I'm a bit to specify Tita.",
                    "label": 0
                },
                {
                    "sent": "Each time I will.",
                    "label": 0
                },
                {
                    "sent": "I will have an observational guard there a constant number of bits, so probably have to observe it for time proportional to M and this is what you can prove with this with this inequality.",
                    "label": 0
                },
                {
                    "sent": "So what you do is that you choose P this prior to be uniform.",
                    "label": 0
                },
                {
                    "sent": "There is no particular reason for this but.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Makes things easy.",
                    "label": 0
                },
                {
                    "sent": "Now you have to compute the entropy of Theta under this prior.",
                    "label": 0
                },
                {
                    "sent": "While the entropy under the uniform priors just log off the sides.",
                    "label": 0
                },
                {
                    "sent": "And then what you do you want to compute the conditional entropy.",
                    "label": 1
                },
                {
                    "sent": "So you do training rule.",
                    "label": 0
                },
                {
                    "sent": "Here is the joint entropy minus the entropy of X.",
                    "label": 1
                },
                {
                    "sent": "You do another chain rule, so you get the entropy effects given Theta minus the entropy of data.",
                    "label": 1
                },
                {
                    "sent": "Once you do the chain rule, this is conditioned.",
                    "label": 0
                },
                {
                    "sent": "These are conditionally independent given Theta, so they're entropy is equal to the sum of the entropies.",
                    "label": 0
                },
                {
                    "sent": "And now I use the subadditivity design.",
                    "label": 0
                },
                {
                    "sent": "Therapy is less than the sum of the entropy, so this gives a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Now this is stationary so these things are all the same so you get T and they put a minus and I wrote this in such a way to get something that is positive.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So at the end of the day.",
                    "label": 0
                },
                {
                    "sent": "What they get is that this conditional entropy is lower bounded by.",
                    "label": 0
                },
                {
                    "sent": "Tee times something M -- T times something.",
                    "label": 0
                },
                {
                    "sent": "So I want this entropy to go to 0.",
                    "label": 0
                },
                {
                    "sent": "So I want T to be at least M divided by this object.",
                    "label": 0
                },
                {
                    "sent": "So this is how the proof works.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This simple example.",
                    "label": 0
                },
                {
                    "sent": "So we use our lower bound.",
                    "label": 0
                },
                {
                    "sent": "You get this, you subtract it.",
                    "label": 0
                },
                {
                    "sent": "You use the bound that we used, so you get 1 -- T overtime.",
                    "label": 1
                },
                {
                    "sent": "So your your error probability of all lower bound goes linearly to 0.",
                    "label": 0
                },
                {
                    "sent": "This is you can neglect and gets to 0.",
                    "label": 0
                },
                {
                    "sent": "OK, so this tells you that the minimax error probability is basically at least 1/2 unless they observe M minus this.",
                    "label": 1
                },
                {
                    "sent": "This guy number sample.",
                    "label": 0
                },
                {
                    "sent": "So this quantity really conveys you how much bits of information is each of observation give you.",
                    "label": 0
                },
                {
                    "sent": "And so, in fact, it is a name.",
                    "label": 0
                },
                {
                    "sent": "It's the mutual information you get.",
                    "label": 0
                },
                {
                    "sent": "Log of Theta divided mutual information.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is my toy example.",
                    "label": 0
                },
                {
                    "sent": "And this is the interpretation I need to accumulate this many bits and each observation gives me.",
                    "label": 1
                },
                {
                    "sent": "So this is really elementary.",
                    "label": 0
                },
                {
                    "sent": "But this probably you know if you never heard about this, this is the interesting part of the talk.",
                    "label": 0
                },
                {
                    "sent": "Now I'll do a less elementary stuff and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me do another simple example that is a little bit more dynamical.",
                    "label": 0
                },
                {
                    "sent": "Say that you have now a linear.",
                    "label": 0
                },
                {
                    "sent": "So this is auto regressive process X at time T + 1 is a coefficient times X * T type plus plus noise.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a run.",
                    "label": 0
                },
                {
                    "sent": "Script version of the artery limbic process if you want data is a coefficient that I want to learn.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a number belong, some some finite sets in 01.",
                    "label": 0
                },
                {
                    "sent": "Assume that this is Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Once these are Gaussian, these are also Gaussian with mean zero variance one, but they are dependent.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so these are for instance 5 realizations of this process with different choices of parameter and what the task is.",
                    "label": 0
                },
                {
                    "sent": "You have to distinguish between these five given a finite observation time.",
                    "label": 0
                },
                {
                    "sent": "Here it's very difficult to distinguish them.",
                    "label": 0
                },
                {
                    "sent": "They look all the same.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I observed them a bit long.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They look all the same.",
                    "label": 0
                },
                {
                    "sent": "And here perhaps they start looking a little bit different.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here they look a little bit different.",
                    "label": 0
                },
                {
                    "sent": "In particular, the one below's are a bit smoother, so they have more memory.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and the proof here goes in the same way.",
                    "label": 0
                },
                {
                    "sent": "If you want to apply fun in this case.",
                    "label": 0
                },
                {
                    "sent": "What you do is the same you write this conditional entropy as the entropy of Tita plus the.",
                    "label": 0
                },
                {
                    "sent": "Conditional of X given Theta minus the entropy of X, Now I have to right lower case here because this is differential entropy.",
                    "label": 0
                },
                {
                    "sent": "Because variables are continuous, then I do exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Here I write this.",
                    "label": 0
                },
                {
                    "sent": "With the chain rule are now since this is a Markov process I need these are not independent, but I can only condition on the last step.",
                    "label": 0
                },
                {
                    "sent": "Now this is not the Markov process, so I need to condition over all previous times.",
                    "label": 0
                },
                {
                    "sent": "But I still get a lower bound, so chain rule you can repeat it many times, so you get entropy given all the past.",
                    "label": 0
                },
                {
                    "sent": "But now you get your lower bound if you forget about the past and you just put last step.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the end you get the entropy by stationarity minus time times this quantity and also this quantity is.",
                    "label": 0
                },
                {
                    "sent": "As a name, this is the mutual information between Titan XD given the previous step.",
                    "label": 0
                },
                {
                    "sent": "So in other words.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Anyhow, so so you don't need that.",
                    "label": 0
                },
                {
                    "sent": "No uncle, if you don't condition conditional on Tita you have a Markov process, but if it's unconditional average revert it is not able to process because there is a common memory that is used to the theater.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the question.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a mistake here.",
                    "label": 0
                },
                {
                    "sent": "I mean we have we lose something in this bound.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so if you were about things you know just this gives me the following trivia.",
                    "label": 0
                },
                {
                    "sent": "Very easy lemma the number of time.",
                    "label": 0
                },
                {
                    "sent": "The length I have to observe this process is the number of bits.",
                    "label": 0
                },
                {
                    "sent": "Then I need to specify my parameter divided by information that I gained at each time, and you notice that this in this case, unless in the IID process what happens is not what shows up is not the mutual information, but is mutual information.",
                    "label": 0
                },
                {
                    "sent": "Given the past somehow this is in some sense the new information, so this quantity is a name.",
                    "label": 1
                },
                {
                    "sent": "Is the condition military information tells you how how much information goes between these two.",
                    "label": 0
                },
                {
                    "sent": "If you admit that this is given, this is known.",
                    "label": 0
                },
                {
                    "sent": "And it makes a lot of sense, right?",
                    "label": 0
                },
                {
                    "sent": "So as you see, these methods give very interpretable bounds.",
                    "label": 0
                },
                {
                    "sent": "OK, now this is OK process keep.",
                    "label": 0
                },
                {
                    "sent": "This is not very interesting.",
                    "label": 0
                },
                {
                    "sent": "You can bound this Eve.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, and if you do some crude bound on the mutual information, you get that the number of observation is at least log of the size of the alphabet of the parameter space divided by the expectation of log of 1 / T to.",
                    "label": 0
                },
                {
                    "sent": "So this was a very.",
                    "label": 0
                },
                {
                    "sent": "It was a very crude.",
                    "label": 0
                },
                {
                    "sent": "Was a very crude calculation in which we lost a lot of terms, but still this capture something in particular.",
                    "label": 0
                },
                {
                    "sent": "The minimum time that I have to observe blows up goes to Infinity.",
                    "label": 1
                },
                {
                    "sent": "When Tita goes to one teaser random variable.",
                    "label": 0
                },
                {
                    "sent": "But suppose that this random variable are some bounded support between zero and one.",
                    "label": 0
                },
                {
                    "sent": "It goes to 01 Infinity.",
                    "label": 0
                },
                {
                    "sent": "When the log the argument of blog goes to one and they're gonna log, will goes to one.",
                    "label": 0
                },
                {
                    "sent": "When Peter goes to one.",
                    "label": 0
                },
                {
                    "sent": "And this makes sense, because when Peter goes to one, what you're having is no memory, so you have a.",
                    "label": 0
                },
                {
                    "sent": "A bunch of independent random variables and they're all Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The distribute the marginal distribution is always normal 01 OK, so this is similar to in a sense.",
                    "label": 0
                },
                {
                    "sent": "What you are asking me for help in this case.",
                    "label": 0
                },
                {
                    "sent": "You cannot learn dynamics because you know already what is the stationary distribution and the interval of time was was big enough.",
                    "label": 0
                },
                {
                    "sent": "Alright, this should blow up.",
                    "label": 1
                },
                {
                    "sent": "Also, when Peter goes to 0, but it doesn't because it's a bad bound.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me let me discuss a little bit or a more advanced application.",
                    "label": 1
                },
                {
                    "sent": "Should go to Infinity only.",
                    "label": 0
                },
                {
                    "sent": "Also went into goes to 0 because when Tita goes to zero the process evolves very slowly right?",
                    "label": 0
                },
                {
                    "sent": "So you would expect that you have to wait sometime.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm not sure about that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the more advanced application is this one.",
                    "label": 0
                },
                {
                    "sent": "This is what we actually looked at in the paper, so this is a paper few years ago 1012, but it's a stochastic differential equation, so X here is a vector in D dimension.",
                    "label": 0
                },
                {
                    "sent": "And evolves in this way the activities some force that depend on X and or some parameter Teeter.",
                    "label": 0
                },
                {
                    "sent": "So this is a drift term that is parameterized by Tita.",
                    "label": 0
                },
                {
                    "sent": "Plus white noise.",
                    "label": 0
                },
                {
                    "sent": "So this is D dimensional white noise.",
                    "label": 1
                },
                {
                    "sent": "With this covariance structure.",
                    "label": 0
                },
                {
                    "sent": "So this is Delta correlated white noise.",
                    "label": 1
                },
                {
                    "sent": "So for each T to hear the drift coefficient is a function from reals to the D2 real today.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so so just to make an example, especially example of the outlook here in using gauge for something different, sorry.",
                    "label": 0
                },
                {
                    "sent": "So this is not entropy.",
                    "label": 0
                },
                {
                    "sent": "This is some dystonia.",
                    "label": 0
                },
                {
                    "sent": "OK, but an example of this that fits in this framework are basically.",
                    "label": 0
                },
                {
                    "sent": "Most of physics, right?",
                    "label": 0
                },
                {
                    "sent": "Physics is what is the exit equals minus gradient of some potential plus white noise.",
                    "label": 0
                },
                {
                    "sent": "This is Langevin equation.",
                    "label": 0
                },
                {
                    "sent": "And for instance, you can put a spin model in this framework you put, you know quadratic term that depends on Theta IJZXJ.",
                    "label": 0
                },
                {
                    "sent": "So this is an exchange term.",
                    "label": 0
                },
                {
                    "sent": "Plus a potential that that's whatever you want.",
                    "label": 0
                },
                {
                    "sent": "OK, and here you get the dynamics.",
                    "label": 0
                },
                {
                    "sent": "That is some term that is separable plus the evolution of excise influenced by all the other position J.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so when if you repeat the same analysis here.",
                    "label": 0
                },
                {
                    "sent": "OK, the first step, just you do find inequality.",
                    "label": 0
                },
                {
                    "sent": "What you get is that the number of time I have to observe is at least the log data divided by the mutual information divided by T. So X0T is the whole trajectory between time and time, time zero and times T right?",
                    "label": 0
                },
                {
                    "sent": "So this is a trivial thing is just taking five inequality and the T here simplifies by T and this inequality is only telling you that the mutual information is to be bigger than the number of bits that you don't know.",
                    "label": 0
                },
                {
                    "sent": "But now to put it in, this can be put in a nice form if you use this result by Duncan and Kadota Zach ions.",
                    "label": 0
                },
                {
                    "sent": "If that tells you that if you have any, OK, this was a result about mutual information in channels with feedback, but you can basically think this problem as a channel with feedback where it transmits Tita and you observe this stochastic process basically and what this with these people showed.",
                    "label": 0
                },
                {
                    "sent": "Is that the mutual information is equal to the integral of the conditional variance of F given X?",
                    "label": 0
                },
                {
                    "sent": "Zero T. So this is basically instantaneously in between time T and times DT.",
                    "label": 0
                },
                {
                    "sent": "This is the additional mutual information.",
                    "label": 0
                },
                {
                    "sent": "Is the expectation of the conditional variance of F given the past?",
                    "label": 0
                },
                {
                    "sent": "So this is similar to this conditional mutual information that I've wrote before.",
                    "label": 0
                },
                {
                    "sent": "If time T, there is a lot of variability in F. Given the past that I'm gaining a lot of information, this makes sense.",
                    "label": 0
                },
                {
                    "sent": "So this is the interpretation that I just mentioned.",
                    "label": 0
                },
                {
                    "sent": "Fine.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so from this just substituted.",
                    "label": 0
                },
                {
                    "sent": "OK we have a more complicated theorem than this, but if you substitute and you do something simple in a stationary process you get this very simple formula that the number station so all times are equal.",
                    "label": 0
                },
                {
                    "sent": "So this conditional variance is always the same.",
                    "label": 0
                },
                {
                    "sent": "It's very simple theorem that tell you that you have to observe at least log the size of the parameter space divided by the expectation of the conditional variance.",
                    "label": 0
                },
                {
                    "sent": "Pops OK, so now this I claim that is something that you can formula that is.",
                    "label": 0
                },
                {
                    "sent": "Neat enough that you can apply in specific cases and what we did is really apply.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In specific cases, and I'll describe this results next.",
                    "label": 0
                },
                {
                    "sent": "OK, the first case, that.",
                    "label": 0
                },
                {
                    "sent": "OK, so I don't know if I look more than one actually look only at one case I think.",
                    "label": 0
                },
                {
                    "sent": "So the case that we looked at is the linear stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "So the problem here in applying this formula is really.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That you want to.",
                    "label": 0
                },
                {
                    "sent": "You need to compute this OK for applying this formula you need to compute the expectation of the conditional variance of the force given the past.",
                    "label": 0
                },
                {
                    "sent": "OK, so for this you need to get a handle on what is the stationary distribution and you need to get a handle on computing this conditional value.",
                    "label": 0
                },
                {
                    "sent": "So OK, so yeah.",
                    "label": 0
                },
                {
                    "sent": "In this case, you have.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah, so we get.",
                    "label": 0
                },
                {
                    "sent": "You can get the fertile lower bound so the variance decreases in few condition and more stuff.",
                    "label": 0
                },
                {
                    "sent": "Alright, so instead if instead of conditioning all the past.",
                    "label": 0
                },
                {
                    "sent": "I condition only on time T, for instance.",
                    "label": 0
                },
                {
                    "sent": "OK, so actually OK.",
                    "label": 0
                },
                {
                    "sent": "So this formula.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm making here actually.",
                    "label": 0
                },
                {
                    "sent": "OK, let's so if I condition only on time, so this should be minus Infinity actually.",
                    "label": 0
                },
                {
                    "sent": "So if I condition only on this guy on time T alright, smaller interval of time, I will get a further lower bound.",
                    "label": 0
                },
                {
                    "sent": "So you can get further lower bounds.",
                    "label": 0
                },
                {
                    "sent": "That is what we were doing before.",
                    "label": 0
                },
                {
                    "sent": "If you remember before we had this conditional entropy, an ex given all the past and what I did is just go to lower bound by discarding all the past except the last point.",
                    "label": 0
                },
                {
                    "sent": "So if it's convenient.",
                    "label": 0
                },
                {
                    "sent": "You can just replace this by just time T, so this becomes physics term purely static calculation one.",
                    "label": 0
                },
                {
                    "sent": "Once you make that.",
                    "label": 0
                },
                {
                    "sent": "So if you know if you can do your static calculations then you can compute this lower bound.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, so So what we did is really compute this only for linear SD.",
                    "label": 0
                },
                {
                    "sent": "So for instance this type of SD in which you have the X in DTS minus X + a metrics times X plus.",
                    "label": 0
                },
                {
                    "sent": "Brownian motion about this white noise an A is the adjacency matrix of a graph.",
                    "label": 1
                },
                {
                    "sent": "OK, so you can think of it, it's zero 1 + -- 1 metric, so you can think of it as describing a graph is not a symmetric graph, so a is not equal A transpose and is signed.",
                    "label": 0
                },
                {
                    "sent": "So you can have excitatory and inhibitory kind of interactions in this graph.",
                    "label": 0
                },
                {
                    "sent": "So this was not motivated by anything else.",
                    "label": 0
                },
                {
                    "sent": "Other than it was simple to do so, we assume that this graph is bounded degree K and one thing that is important of was important.",
                    "label": 0
                },
                {
                    "sent": "Assuming for doing calculations was having a lower bound on this.",
                    "label": 0
                },
                {
                    "sent": "This is basically is telling you that.",
                    "label": 0
                },
                {
                    "sent": "So this is the minimum eigenvalue of the identity's minus mu way.",
                    "label": 0
                },
                {
                    "sent": "This is the symmetrized of a, so it's a plus a transpose divided by two.",
                    "label": 0
                },
                {
                    "sent": "And this you can think of it as a time scale of the system itself.",
                    "label": 0
                },
                {
                    "sent": "Quickly the system relax is to its stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so This is why I give the name 1 / 2 to this quantity.",
                    "label": 0
                },
                {
                    "sent": "OK, so you need some assumption of this type that the system mixes rapidly, probably to get that you converge to equilibrium.",
                    "label": 0
                },
                {
                    "sent": "This specific assumption is actually stronger than what you would like to to assume, but OK, this is was the first mistake of the proof.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not antisymmetric, it's neither symmetric nor antisymmetric, but this assumption in the.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assumption what matters is only the symmetrized part.",
                    "label": 0
                },
                {
                    "sent": "It can be anything.",
                    "label": 0
                },
                {
                    "sent": "It's a directed graph.",
                    "label": 0
                },
                {
                    "sent": "Not because you can have edge IG and Ji if you have both of them for recharge then the graph the metrics will be symmetric.",
                    "label": 0
                },
                {
                    "sent": "Edge height no.",
                    "label": 0
                },
                {
                    "sent": "It's a directed graph so edge IJ is a different thing from Edge Ji.",
                    "label": 1
                },
                {
                    "sent": "So an edge is a pair of vertices, it's an ordered pair of vertices in directed graph.",
                    "label": 0
                },
                {
                    "sent": "So I J&JI are not the same thing.",
                    "label": 0
                },
                {
                    "sent": "Sorry, something with.",
                    "label": 0
                },
                {
                    "sent": "I need not to point.",
                    "label": 0
                },
                {
                    "sent": "OK, OK this.",
                    "label": 1
                },
                {
                    "sent": "OK, this is I didn't do a. I didn't think I needed the plot, but this is a plot of a graph that is.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, So what we prove is the following.",
                    "label": 0
                },
                {
                    "sent": "Applying just this lemma to this case, the time that you need to observe this thing is some function of the degree.",
                    "label": 0
                },
                {
                    "sent": "Times.",
                    "label": 0
                },
                {
                    "sent": "Oh one over mu.",
                    "label": 0
                },
                {
                    "sent": "So what is mu?",
                    "label": 0
                },
                {
                    "sent": "did I define it?",
                    "label": 0
                },
                {
                    "sent": "What did they find it?",
                    "label": 0
                },
                {
                    "sent": "Mu is this object right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "Plus one over mu.",
                    "label": 0
                },
                {
                    "sent": "Or the maximum of one over mu.",
                    "label": 0
                },
                {
                    "sent": "An overview squared times log P. So this is a very crude bound, but it gets some important features and it could be improved and you are welcome to improve it, but keep some important feature.",
                    "label": 0
                },
                {
                    "sent": "For instance, if you think of the degree as bounded, this scales only logarithmically with the number of vertices of the graph, which makes sense because the log of the number of graphs over.",
                    "label": 0
                },
                {
                    "sent": "P vertices with bounded degree K scales only logarithmically with the number of of vertices and then you have this explodes with mu and this makes sense becausw.",
                    "label": 0
                },
                {
                    "sent": "Becauses Mu goes to 0.",
                    "label": 0
                },
                {
                    "sent": "The signal that is related to the metric becomes weaker and weaker, so you need to observe the system longer and longer and it also explored with this store, which is some kind of equality or relaxation time or mixing time, which makes sense.",
                    "label": 0
                },
                {
                    "sent": "You have to wait long enough to see the system mixing.",
                    "label": 0
                },
                {
                    "sent": "OK, and I think there Jose in the morning talked about the fact that in this model, on a slightly marginal is model using just regularize maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "So this is a least squares plus L1 regularization.",
                    "label": 0
                },
                {
                    "sent": "You can achieve this lower bound module or ugly factors.",
                    "label": 0
                },
                {
                    "sent": "At least you can achieve the right scaling in P.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. OK so some brief conclu.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ocean OK, I think that the topic of this workshop is interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, I shouldn't.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think that there is a lot of interesting things to be done here.",
                    "label": 0
                },
                {
                    "sent": "It's largely open and and you know information theory provides a useful way to get.",
                    "label": 0
                },
                {
                    "sent": "Meaningful over bound.",
                    "label": 0
                },
                {
                    "sent": "That's all, thank you, thank you.",
                    "label": 0
                }
            ]
        }
    }
}