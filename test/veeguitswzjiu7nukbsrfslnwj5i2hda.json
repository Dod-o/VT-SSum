{
    "id": "veeguitswzjiu7nukbsrfslnwj5i2hda",
    "title": "Implementing the \"Wisdom of the Crowd\"",
    "info": {
        "author": [
            "Yishay Mansour, Blavatnik School of Computer Science, Tel Aviv University"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Crowdsourcing",
            "Top->Computer Science->Logic"
        ]
    },
    "url": "http://videolectures.net/colt2014_mansour_implementing/",
    "segmentation": [
        [
            "So today I'm going to talk about implementing the wisdom of the crowd.",
            "This is sort of a work which is in between game theory, computer science, more more.",
            "We will fit.",
            "Twist probably told the game theorists over two quarters, Elon Kramer and multi Perry.",
            "One is an economist, one is a former finance Department.",
            "And sort of the end of this claim.",
            "But I want to say is that I decided, sort of.",
            "I'm not going to give any proof, so I try to keep it in the high level and intuitive level.",
            "Anyone who would like to know more is more than welcome to us questions later."
        ],
        [
            "So it is sort of the starting point of of where we started this research.",
            "So many things there's like there is.",
            "There is a tendency to believe the transparency is what we should have.",
            "Like we started looking at the report cards report court system today exist for many things in healthcare and education, probably with professors.",
            "Get the student reviews getting published.",
            "And and there is the real reason why it exists, because people believe that if we publish it, it will be transparent if people will see it, it will improve the quality and it really needs to be.",
            "This is one side of it and the other side of it is to provide information to other people who come.",
            "Like anything which which involves people, which it becomes a game in gaming, the system in report cards is an issue.",
            "For example, if you look at healthcare, then it's very good that hospitals have to report sort of.",
            "How successful their operations are?",
            "What's the death rate in a heart transplant?",
            "But what you do find out very fast is that they're trying to game the system.",
            "How do they gain the system?",
            "They would opt in order to get the easier cases and try to avoid the hard cases.",
            "This is 1 example."
        ],
        [
            "Here is another example so.",
            "I sort of assume how many people here use TripAdvisor way.",
            "OK, that's very good cloud, so I don't need to really introduce the trip adviser to you.",
            "So tribute to visors like recommendation site.",
            "Most people, a few that are using it as sort of slightly unaware, sorta fulfill twist with really exist in the way that we all use it when you come to Barcelona, there are too many hotels you have.",
            "There are too many restaurants when you need to go out for dinner, you're not going to go over all of them somehow.",
            "What trip adviser has they have?",
            "Sort of an algorithm with sort of.",
            "Gives you a number people can understand the single number, so it gives the ranking between the different hotels between the different restaurants and this is the popularity index.",
            "With TripAdvisor it gives you.",
            "If you look if you look even slightly that you see it's not the average of what people reported, so the popularity index is a proprietary algorithm.",
            "So just to be fair, I have no idea how exactly they do it, but it's also a self reinforcing algorithm, so if you look on research with people did in hotels, so the difference between being rated number 10 or #20 amounts to something like 10%.",
            "In the in the hotel bookings that you're going to get, so it's very significant amount for the hotel, but also to sell something which is self reinforcing.",
            "If you take a small restaurant which is just opened and got a few good reviews and you push it up, you're very likely as the trip adviser website you're going to get more reviews for that restaurant, so in fact you can.",
            "You need to think that there is some exploration versus exploitation issue.",
            "We should go here in.",
            "Into here because somehow you do want to to elicit information from the people.",
            "And here is sort of."
        ],
        [
            "The most convincing example, and for this example we even have a video of the CEO saying it so ways used to be an Israeli startup.",
            "Now it got bought by Google.",
            "If you months ago and what it does is a real time navigation recommendation.",
            "So basically you get into your car, you take your smartphone, turn it on and it gives you sort of the recommendation of how to drive home.",
            "And it's based on real time information that it gets from other user.",
            "Basically we are the traffic jam.",
            "How?",
            "How are you is the best way to drive?",
            "Now here is the real dilemma.",
            "From time to time they need to send people on route routes that we have no idea whether they are good or bad.",
            "Because they need to do the exploration.",
            "And in the seal just said, OK, we do it.",
            "There is no choice, right?",
            "Someone needs for the better good to stand on the fence so people will be able to walk over.",
            "So.",
            "And when you think about it, it makes sense.",
            "Like someone needs to do this exploration.",
            "Of course, if you see that your navigation system is always sending you on very long route, you're not going to use it.",
            "In fact, what I suspect is that you have such a high sort of noise right in the navigation system.",
            "In any case, that even if we just look at the time in which it didn't predict correctly, most of those times are not due to the fact that they're doing exploration.",
            "Most of those times, because traffic conditions change from the time you.",
            "You sort of started driving to the time that you got to the place.",
            "And intuitively, so people would be people are willing to use this system and the reason why they are winning is because most of the time that would get good recommendation.",
            "So this."
        ],
        [
            "Leaves is what I want to talk today, so I would like to talk about agents with need to select between a few alternative fuel ternative's could be hotels like in the TripAdvisor case, traffic routes like in the ways example doctors like in report cards.",
            "So this is sort of the issue.",
            "Will assume that they have sort of known prior about the success.",
            "So if you are driving every day from work to home, you have a very good prior.",
            "How much time each route is going to take, but the variance is what you would really like to to to know.",
            "We will have multiple agents without arriving in each one wouldn't just need to make one decision.",
            "Each one is just taking one route.",
            "Still, at home and the individual edges, of course, strategic in the sense you would like to get faster, you're not really into trying to exploring.",
            "So you would be willing to take the advice of the system if you think that this is the best thing that you can do.",
            "So the point of perspective, it will be trying to look for it is from the planner perspective is the one which is sort of controlling the information we would like to learn how to really to implement such a system.",
            "So the goal of the planner is that everyone would be better off, right is the goal of a planner with everyone would get as fast as they can home, but he's looking at the sum of things and therefore there is tension between what he wants and what the individual people want.",
            "You can think about the planner as a regulator or SoC when you're thinking about report card, but in many cases you can think that maximizing the user satisfaction even for.",
            "Bill Wolfe site like trip adviser.",
            "This is the real goal.",
            "So."
        ],
        [
            "The main issue here is that agency will have a dual role they're both producing and consuming information.",
            "They are consuming information and then through this consumption.",
            "They are getting their utility, but also while they are consuming their producing new information that will help the GNU users that are going to come along."
        ],
        [
            "So what is?",
            "So the main research question that I would sort of schedule days.",
            "How does the optimal Planner policy should look like?",
            "So what is so first of all?",
            "What is linear control?",
            "So really, what he control, he controls the information.",
            "He can sort of decide what he can tell about the other users about what he knows.",
            "We're going to talk with no more money incentives.",
            "You can extend the result to monitor incentives.",
            "I doubt if I do it at the end.",
            "What the planet would like to do?",
            "He would like to induce exploration.",
            "He would like that at the end to guarantee that everyone is doing the better alternative.",
            "What would look at would look sort of.",
            "OK, so our goal is to find the optimal policy and will also try to measure how good is the optimal policy.",
            "What do I mean by?",
            "How good is the optimal policy?",
            "How far is it from from a setting in which we knew everything?",
            "So what is very great of the optimal policy in this setting?",
            "And it can rebound the cost of exploration in some sense."
        ],
        [
            "OK, let me do it D2.",
            "Trying to connect with what I'm going to talk today with a few themes that is very familiar to this community.",
            "So assume that multi armed bandit sort of.",
            "After seeing glasses session of an hour and a half, most people know what's multi armed.",
            "Bandit is a very simple decision theoretic model.",
            "We have multiple independent action and we have the real uncertainties regarding the reward.",
            "The main issues is that there is a repeated interaction between selecting the action and relegating the reward.",
            "And the main focus is with tradeoff between the exploration and exploitation.",
            "So this is sort of a places which will be in some sense similar."
        ],
        [
            "So when you think about multi Arm Bandit is really there to two things, I think the cold community is almost all on the right hand side of the slide.",
            "There is a Bayesian sighting in which we assume it prior over rewards and given the power of the rewards there are optimal algorithm like the Gittins index for the discounted return there is that your serial setting in which we are all interested in worst case bounds.",
            "Worst case with would hold true for any reward sequence that we're going to observe.",
            "And we measure the regret is with difference between the best action and the online performance and the goal is to get the varnishing regret varnishing as a function of the number of time steps."
        ],
        [
            "OK.",
            "So now let's sort of contrast where where I'm going to talk today versus the classical setting.",
            "So in the classical setting, the wave and certainty regarding rewards, right?",
            "This is the main uncertainty in this drastic setting.",
            "It comes from the distributions in that your server setting is because we don't know what the remaining reward sequences.",
            "But we do have certainty about something we do have certainty when we perform an action, it's going to get performed.",
            "In our setting there is sort of like another uncertain T. We haven't certainty regarding rewards is before, but we also have uncertainty about the execution of an action, because in some sense what I said is that yes, we can recommend you how to to drive home, but you then we'll look at the routing.",
            "Sometimes when I use Waze and says it doesn't make sense and I just don't take that route right?",
            "So we can recommend things, but you can't force things to happen, so we cannot force exploration, so will need sort of power somehow too.",
            "Induce exploration without focusing it."
        ],
        [
            "So why is all this interesting?",
            "So this is sort of a more personal perspective.",
            "Why is it interesting to me?",
            "So I think includes, do you think incentives to the basic tradeoff between exploration and exploitation is something that I find very interesting?",
            "And I think it's it could be a very fruitful, even especially for this community to think, sort of along those lines.",
            "Adding a third dimension to the classical tradeoffs in which incentives.",
            "Basically, if you think about the machine right, there are no incentives.",
            "But if you think about trying to implement the multi arm bent on on humans, you should think that incentives would come here in one way or another.",
            "So in this talk I'm going to.",
            "Let's talk about action control about strategic agents in a related work with Nikolaj is a, Bianchi and.",
            "And Fabrizio Germano, which is sort of.",
            "For a long time we're playing around.",
            "We never thought of God to write it up, but here is sort of the gust of ideas.",
            "So I think the motivation is only the strongest thing that we can see.",
            "Think about the classical expert advice, so the classical expert advice is a basic assumption in the beginning.",
            "The experts really want to give the information right.",
            "Experts do not have incentives.",
            "Let's think about life.",
            "So sometimes it's true expert do not have incentives, but in many settings experts do have incentives.",
            "Anyone who sort of four rented or bought an apartment recently.",
            "He knows that real estate agents do have incentives.",
            "That incentives are not aligned with your incentives and not with the seller incentive, right?",
            "They want to add a deal to go through somehow.",
            "Coming from Israel Army Generals Army generals also usually have incentives like they're more likely to think that there is a solution using the army.",
            "If you think about this life right, it's not a joke.",
            "Where I come from, it's not, it's not OK. Criminal trials in the US think about juries.",
            "People on Julie's many times have incentives.",
            "Incentives is not that tight so everyone wanted.",
            "If someone did, the crime should go to jail and if he didn't do anything he should go free.",
            "But the title between false positive and false negative is very different for different people.",
            "Alright, so when you set up a Julie, you need to be aware that this is this is an issue.",
            "OK.",
            "So what could be a research agenda here?",
            "And this is what we try to do.",
            "So you would like to be biased there.",
            "The experts.",
            "Somehow you would like to be able to get a better prediction even when the experts are biased.",
            "Get better tradition and more reliable one, OK?",
            "So.",
            "The good news is I think it's a very good motivation.",
            "The bad news, but I don't have too much to say about it, at least now.",
            "So now we can sort of go and continue, sort of."
        ],
        [
            "Along Villa, so now I'm going to sort of before I can sort of say the result even I want to sort of set up the model.",
            "So what is the model?",
            "So I'm going to have a very simplistic setting in this simplistic setting.",
            "We just have two action for each agent.",
            "Each agent has changes to choose between two alternatives.",
            "You can think of between.",
            "Selecting between two medical treatments, right?",
            "Each action has a fixed but unknown reward.",
            "So once we realized in action we know sort of.",
            "What is reward is and we will.",
            "We are going to do it in a Bayesian setting.",
            "We will have a prior over the rewards.",
            "It's well known everyone knows it and just for simplicity, let's assume that action one is a priority, the better one.",
            "We will have a stream of agents T agents.",
            "They will arrive one after the other sequentially.",
            "And each one knows his place in the order so I know that I'm the first one, the second guide knows it is the second guy, etc.",
            "Each agent will get a single chance to select an action and get the reward of the action that is selected.",
            "We'll assume that the agents are risk neutral.",
            "Basically they just would like to maximize the expectation of the of of the reward that they're going to get.",
            "So in some sense, we are fixing the averages.",
            "The agents what are going to do?",
            "Is it?",
            "They get some information during the process given all the information they receive, they can compute some posterior and they're going to choose a better action according to their posterior.",
            "So the agents of two armed bandits, but they are fixed by saying that they maximize their utility."
        ],
        [
            "The main issue is sort of how to elicit things from those simply to arm bands, so we'd be looking at the plan so the planner is the one which would like to plan for.",
            "So the planner really controls the information and you would like to maximize the expected some of payoff.",
            "So he's like maximizing the social welfare.",
            "The agents of incentive compatible in the sense that they are going to do whatever is in their best interest and where.",
            "If they said no payments for now, we can sort of relax it later.",
            "And it's not that important.",
            "So what can the action plan or do so the planner can sort of tell a story to each one of the agents so he's the real estate agent and it says a very long story to tell about what happened in previously right and then sort of the agent does what he does and the planner observes the outcome.",
            "So now we have iteration.",
            "Each time the plan of sort of gives a message to the next agent and then the the agency is done going to do the action with sort of maximizes its own utility.",
            "In order to complete it into a game theoretic setting, we do assume that the agents know the plan of policy.",
            "So in some sense the planner cannot lie in the usual sense, right?",
            "So I know that if you plan, it told me to do action one, it's really big 'cause he observed AB&C in his code and this is sort of why he's recommending it.",
            "So, so in the sense the agents, when they come to make their decision, their decision is based also on the plane of policy on how to give the recommendation, and the goal is.",
            "To maximize the sum of the payoff, this is the plan or goal, right?",
            "So this is a social welfare maximization."
        ],
        [
            "OK.",
            "So that also.",
            "So, so I'm going to mainly discuss private recommendation for this.",
            "I'm going to derive an optimal policy.",
            "The exact optimal policy, and in addition to being exactly optimal, it will also had good performance in the sense that the total regret that you and care is only constant depends on the prior, and there's no dependent on the number of agents that show up.",
            "Blue flame going through later today to mention some other models.",
            "So when you don't know your place in the line or the inventor is money or there is more information over and accommodation are sort of observed by everyone who asks, but the main sort of what I think I'm going to talk about is a private recommendation and the fact that in this case we can sort of implement the optimal social welfare with relatively low cost."
        ],
        [
            "OK so before going on.",
            "I'm going to speak about a related, probably unrelated work and later, as explained to me, why is it unrelated and the main reason is because I think it's very interesting for those of you unfamiliar with it.",
            "So this is information cascading.",
            "So what happens in Informacion cascading?",
            "So we think that there are two bins.",
            "I hope you can see the color.",
            "This is red and this is green.",
            "And you know that in the Bender of either 2 green balls in three Red Bulls.",
            "02 red balls and three green balls.",
            "By probability 1/2 it's this one probability.",
            "1/2 is this one, and some of.",
            "You would like to know which case it is."
        ],
        [
            "So what happens is, is the following sort of scenario."
        ],
        [
            "This guy comes."
        ],
        [
            "He put in his hand into his hand into the bin and pulls out the board and now he needs to predict he needs to predict whether there are more red balls or more green balls.",
            "So OK, so first guys, very easy, right?",
            "He's so Red Bull more likely.",
            "That is that."
        ],
        [
            "Majorities, red, so he's saying red.",
            "Now they say."
        ],
        [
            "Second guy comes and he pulls another book."
        ],
        [
            "So if he pulls the green ball, let's assume that if he pulls the green Bolton is gone."
        ],
        [
            "To say Green Solid trust himself more than the first guy.",
            "Mike"
        ],
        [
            "Without death."
        ],
        [
            "If it sees a Red Bull now, now is even more confident.",
            "The majority is red."
        ],
        [
            "He's going to say right away.",
            "The things becomes interesting with third."
        ],
        [
            "The third guy comes up."
        ],
        [
            "And he's seeing a green ball.",
            "What should he say?",
            "OK, so now this in some sense you know that the first guy said red, so it means that is so bad he is known as the second guy, said red.",
            "So it means that is so red he's so green, but two Reds versus 1 green."
        ],
        [
            "He's going to say red.",
            "So what is there to form this point on?",
            "Everyone is going to say read."
        ],
        [
            "Right, so so it means that there is a constant probability.",
            "It's not that tiny.",
            "That if we have a huge number of people, it doesn't make any difference.",
            "They're all going to say the same.",
            "They're all going to be included, correct?",
            "And if they all said the signal with overwhelming probability.",
            "We would have known the correct answer, so some information doesn't aggregate here.",
            "So so now I want to sort of to explain why doesn't happen in our setting, hope."
        ],
        [
            "I'm not confusing you too much, so here is sort of our setting.",
            "Describe pictures so.",
            "So the teacher here is the planner and what the planner."
        ],
        [
            "Is doing is agents of coming one by one in."
        ],
        [
            "But the teacher is sort of giving recommendation.",
            "A private recommendation.",
            "Oh you, you should do it."
        ],
        [
            "Now the agent gets to choose whether to push the green button or the red button."
        ],
        [
            "And after the agent pushed the button.",
            "He gets the reward.",
            "The planner observes a reward and the age."
        ],
        [
            "Go walks away so I'm like in the in formation cascading.",
            "He really, the planner has all the information.",
            "He is the one that aggregates information and he is one that discloses information and therefore sort of there isn't any real issue of cascading of information because the information is sort of channeled.",
            "Four through this planet.",
            "OK."
        ],
        [
            "So now we want to start the describing our results in model so.",
            "So let's start with a few simple observation, right?",
            "So once, so since the planner controls information, the simplest policy is not to give any information.",
            "If we don't give any information, everyone is going to do the better or your reaction.",
            "Basically no, no exploracion.",
            "OK, this doesn't look good."
        ],
        [
            "The other extreme.",
            "Is full in formation so full in formation.",
            "Still unclaimed, it's very easy to see, will have limited exploration.",
            "Alright, so let's do very."
        ],
        [
            "Simple example, suppose there's two options.",
            "The first action is uniform between minus one and +2, and the second option is uniform fitting minus two and plus two now."
        ],
        [
            "Now.",
            "If the first agent observes a value which is known negative, it's strictly positive everyone is going to do the first action right?",
            "Although there is a fair chance of the second option is still better.",
            "Alright, so.",
            "So full information is not doing what we would like it and it is doing something that you would observe.",
            "Also in practice, I think it causes people to be more conservative.",
            "It causes people sort of to rely more on on what what is out there and not to try to do to explore new things.",
            "But but if there are 100 people you want one of them to try the second a action because the second suppose the first action is 0.5.",
            "The second action says still is a good probability to being above 0.5.",
            "Right?",
            "The agents are coming 1 by 1.",
            "The first agent is going to do the yellow action.",
            "Supposedly he observes 0.5 now in the full information, the planner is just telling everyone what the first agent received, so it tells everyone you know the yellow action would give you 0.5 every time you push the yellow action you get 0.5.",
            "So from that point on the planner cannot convince anyone to do the blue action.",
            "Although if there are many people you would like to someone to.",
            "Try the yellow action.",
            "You do have a probability of 1 / 8.",
            "I think that the blue action is better, so you would like someone to try the blue action.",
            "But if you're doing full information, you're not going to get anyone to agree to do it."
        ],
        [
            "OK, before describing the result of.",
            "We do need some technical condition and I sort of ascribe it would impossibility result.",
            "So in some sense.",
            "We cannot always guarantee exploration, and here is when we cannot suppose that sort of action one has a predefined payoff which is deterministic.",
            "In action, Two has a lower expectation.",
            "But there's sample ability of being better in sample building of being worse in some sense.",
            "In this setting, the planner doesn't have any information you can sell to the agents, right?",
            "Becausw.",
            "Every agents know that all the engines before we would prefer the action one right.",
            "The first active agent do action one, the second agent, regardless of what the planner tells him he knows what the plan of saw, and therefore he also do action one.",
            "The third editing sort of so.",
            "Everyone is going to do action one in this case, you plan or doesn't have any influence.",
            "So the really mild assumption which we need to do is to require that there is some probability that the first action is works in the expectation of the second action.",
            "So incense the planner there is away some scenario in which the planner can convince you to do the second action.",
            "OK, so not willing to do the proof, but sort of if I did it for four, it's easier to think about full support for both action and no mask on.",
            "OK.",
            "So here's how the algorithm is going to look."
        ],
        [
            "For the first agent, we don't have much of an influence is going to do the first action.",
            "We're going to observe this reward for the second agent in Incels.",
            "For each edge it will have a threshold, and once the reward is.",
            "Below the flesh is OK.",
            "If we already know the better action, we always recommend the better action.",
            "If we observed only action once so far, then we have a threshold.",
            "Depending on the value that we observe for action one, and this is sort of how are we splitting the exploration between the different agents, so agent is going to be the one to explore action too if he.",
            "He's the first one to have this hold for him, and then we're going to recommend from action to otherwise action one right?",
            "So in some sense, we are recommending action one until a certain agent, then a certain agent is going to be the first one who is going to be recommend to do action to and following him?",
            "Everyone is going to do the better action.",
            "In a few properties, sort of, the optimal policy is going to be.",
            "Recommendations are going to be sufficient.",
            "Essentially, I'm going to talk about it later.",
            "It is revelation principle, right?",
            "Sort of.",
            "I don't need to sort of tell you anything about the past.",
            "It's enough that tell you which actually is better for you to do.",
            "The constraints of in the for the agents between the two actions are going to be tight.",
            "This is also sort of fairly intuitive if since we want to maximize the exploration, will make it in such a way that a the agent doesn't care whether he does.",
            "Action one or Action 2 and it will generally explore low values before- in.",
            "Surreal intuition is really coming from the fact that.",
            "The agent doesn't know why we recommended action to deal with it.",
            "Did it come from here or did it come from here?",
            "OK.",
            "So now this sort of to make sure that everyone sort of in line with what I'm going to do is in it."
        ],
        [
            "Sample and I think through this example, the entire sort of algorithm would become fairly simple and obvious, right?",
            "So let's do concrete example, right?",
            "The first action is uniform between minus one and five, so it has a positive average value.",
            "The second action is uniform between minus five and plus five, so zero expectation and think that the number of edges is huge.",
            "So if you don't need to think about sort of effect of a small number of agents.",
            "So this is sort of the picture that we start with.",
            "So now we full conspiracy here like agents, one will choose the yellow action.",
            "And now agents two will choose the blue action only for the yellow action is negative.",
            "This is sort of what I already showed you.",
            "So let's see how.",
            "How can we solve this?",
            "How can we overcome this problem?",
            "How can we get convince sort of the second agents to do more exploration so?"
        ],
        [
            "Is one way of doing it.",
            "What?",
            "This same picture.",
            "So rather than telling the second agent the outcome of the first agent.",
            "Let's just indicate that the reward is below 1.",
            "Just telling the Daily World is below one don't end.",
            "This is 0.5 or minus 0.5.",
            "So now when when you convey the information that the reward of the first action is below 1.",
            "The second agent is indifferent between doing action one and two.",
            "Both have expectation 0, so let's say it does what we ask him to.",
            "OK.",
            "So we were able to induce more exploration by doing a partial revelation, so this outcome is more efficient than the full transparency one, and we got more exploration for the second agent.",
            "But now how can we do better right?",
            "So now the third agent will come right over the third agent.",
            "We need sort of to have a different story.",
            "OK, four."
        ],
        [
            "Found agents.",
            "OK. Now now we can sort of user information that the 2nd and just give us.",
            "So now we have two cases in which we can sort of try to convince this third agent.",
            "One case is sort of maybe the second agent already did action too.",
            "And then in which case we will be recommending the better action.",
            "And it could be that.",
            "The first award was too high.",
            "So the first one is above 1.",
            "So now we can sort of stress starting stretch it so it's clear that the third agent would love to do action too in case one and would not like to do it in case 2.",
            "But now we can sort of stretch eggs until to the point in which he is indifferent.",
            "And if you run, do the calculation.",
            "In this example you get 3 point something, and then in a sense.",
            "You do in this example you do Agent 4.",
            "And in the magical way, under after agent for your guarantee to cover all the exploration and therefore agents.",
            "5 in order always going to do the better option.",
            "So in a sense.",
            "Your entire regret is built on a constant number of agents that happened in the beginning.",
            "OK."
        ],
        [
            "Faith is doing sort of a short overview, sort of what is involved in this.",
            "Solution, so the basic properties.",
            "So first I said recommendations are always sufficient and the way you can think about it is I can send you a message and ask and then given this measure you compute the posterior and given the posterior you do better action.",
            "But if you know my policy and you know that I can sort of do this for you right rather than sending you a message, I'll take the message we want to send.",
            "You compute the posterior and just tell you the outcome.",
            "So therefore I can always rely only on recommendations.",
            "The second."
        ],
        [
            "Salvation is that the optimal policies is a partition policy sort of partition policy.",
            "In this, in the following sense, it recommends to the first agent always the first action, because this is the only thing that he is going to do.",
            "If both actions are sampled, is going to always recommend the better one, and so now the only thing is when are you going to ask the first guy to try the second action?",
            "So essentially you're going to have a partition.",
            "Depending on the values of the 1st.",
            "Of the first the action, sometimes you have, say, agent for those value for Engine 3 doesn't have to be continuous like this is Agent 40 might.",
            "This might be again agent for maybe no exploration here Agent 5 in Soto."
        ],
        [
            "And what you need to keep usually need to keep track of 2 two constraints like you want it when you recommend action to it is better to do action too.",
            "And when you recommend action One, it is better to do action one.",
            "Someone in this setting it's sufficient to look only on action too.",
            "'cause action one is a priority better and so intuitively, although you need to prove it every time you recommend action one the edges is like it's in some way to follow it because.",
            "It's also the operator we think, So what you needed to make sure is that when you recommend action Two, it's really.",
            "Better for the agent to follow the recommendation, because this is the worst uproar reaction."
        ],
        [
            "OK.",
            "So OK, so few properties of the optimal policy, so you're going to get incentive constraints which are tight, so you want to make agents in different between the two alternative.",
            "The second agent is going to explore any value which is already below the expectation of the of the second action.",
            "So really, you're sort of getting rid of all the low values immediately, and generally you sort of explore low values between high values and this is sort of the threshold that we are good.",
            "I'm going to talk about so the optimal algorithm is going to look like this.",
            "The first agent is going to recommend Action One, and we observe its reward.",
            "All the other actions agents when we sample both action, recommend the better action.",
            "And if we didn't some sample yet, the second action we're going to recommend action two if our one is less than the threshold of this agent.",
            "Otherwise we'll keep on asking for action.",
            "One right so so the higher the value of action one, the more we are delaying the first agent, which is going to sample.",
            "Action 2 in the intuition should come from the inherent tradeoff between each agent.",
            "Doesn't know why we we recommended the the second action did recommend because we know in which case you would like to follow order.",
            "We will recommend because we like him to explore, in which case it doesn't want to follow it.",
            "And by balancing those two things, when you do get the exploration going on.",
            "OK."
        ],
        [
            "So the main technical difficulties really to show that the threshold is exactly the optimal policy.",
            "It's built on a very delicate swap argument, in which case in if there is a known threshold, the.",
            "Think you can gain by slow keeping, but the point is that you need to to gain in two different places.",
            "One place that you need to gain or not close at least is a social welfare because you won't like to increase social welfare.",
            "But on the other hand side you need also to keep track of all for the incentives of the agents, right?",
            "So there is the two agents that you are going to swap between them and they should both maintain their their belief that they're doing the better action for the room.",
            "So this is sort of the thing that I'm not going to say much about."
        ],
        [
            "OK.",
            "So it's strange in some sense to talk about what's the performance of an optimal policy, but I think it's worthwhile to think it here.",
            "So what will happen in the when we are running this policy?",
            "So it's the action one is better.",
            "It's great.",
            "Only one agent will try action too and we have very low weekly if Action 2 is better than what you can show, is it the number of agents without going to do exploration depends on the prior, but only on the pile.",
            "So if the number of agents is going to Infinity really you have just a constant regret.",
            "Which comes from this part.",
            "So this is a constantly regret compared to what?",
            "What would have been if you knew everything in advance and it's independent from the number of agents."
        ],
        [
            "So the ultimate policies social policy in fairly sort of simple to compute it.",
            "I'm not going to go over it.",
            "Essentially what you do is you compute it under the assumption that there is an infinite number of agents, and then you need to sort of to take care of the truncation effect truncation, meaning that since there are only 100 people, some values or just too high in order to try to explore.",
            "So you compute it.",
            "The threshold with the infinite one, and then you're sort of correcting them for the fact that you really have a finite number of agents and set your threshold to be the minimum of the tool."
        ],
        [
            "OK, and and as I said, sort of the regret that you are going to have is is depending.",
            "Is a concept which is independent of T and here is sort of a way of bounding it right?",
            "So we had to.",
            "To expectations for the first argument with second action, and you can sort of bound.",
            "This is a rough upper bound on the number of agents which cause can do sort of an in an optimal action.",
            "Take the difference between the two expectation and divide them, sort of by this integral.",
            "So this is sort of the probability that the first action is below the expectation of the second one, and it is the worst action, so this probability.",
            "If you want that would control sort of you regret."
        ],
        [
            "OK, let me talk briefly about a few extension and then probably open the floor for questions."
        ],
        [
            "OK, so relaxing the is it the agents knowledge So what?",
            "I'll just have to know.",
            "So we assume that agents know the exact place in in line.",
            "So the first one knows it is the first second or does this second and sort of in some sense you would like to relax it in life, sort of.",
            "It's not really make sense, you know exactly where you are in line you can think.",
            "Sort of if you're selling something is like early adopter mass adoptation or later Doctor.",
            "If you're driving home, you know that you're before rush hour.",
            "UN golfed Abbatiale will after rush hour so you do know something about your place in line, but it doesn't have to be exact.",
            "Essentially the same properties hold so, so if you if you sort of think of.",
            "Taking the agents and dividing them into various number of blocks and in each block you sort of select randomly."
        ],
        [
            "What would happen that in the optimal policy in every block is sort of the first you try to convince her first agent to explore for the entire block.",
            "Since you block is sort of uniform, he's willing to do it and then sort of.",
            "You just gain because you can.",
            "You can induce more exploration because it has more uncertain T so blocks in only increase with social welfare and therefore reduce the regret.",
            "In extreme Point, which is still interesting, sort of what would happen if if they just have no idea where they are in line, think about the random permutation.",
            "So agents are not aware on the place in the queue.",
            "So in this case.",
            "If you think about it, sort of.",
            "The incentives of the agents in the planner sets are suddenly aligned because when there in there are no position.",
            "Is there summing over all possible positions?",
            "For their expectation and the planner is summing over all position to compute the social welfare.",
            "So since their incentives are aligned.",
            "What happens is the planner can simply run the optimal policy.",
            "Bye.",
            "No need to explain why.",
            "OK."
        ],
        [
            "So so far in the model, we assume that there isn't any money going around, right?",
            "So so we were trying to convince people to follow the action just based on their utilities and not by paying money.",
            "Assume you have money.",
            "Assume you can't pay people to do medical experiments or something right?",
            "You can sort of induce exploration by paying money.",
            "The nice thing is that the same policy states the same basic policy.",
            "The only point now is that the planner has it.",
            "His money is going to invest all the money that he has in the second agent to try to get the exploration as early as possible.",
            "Other than this, essentially you're going to get the same construction.",
            "It's going to be the same optimal policy.",
            "OK.",
            "This is what happens when you work with people in finance.",
            "So when when money costs money, OK, So what does it mean when money costs money?",
            "So so when the OK.",
            "So usually when you think you're making payments and payments are just coming from somewhere.",
            "But things that if you have the government and you want to put taxes there is the cost of putting taxes.",
            "So if you're going to take money then you're taking alone in your paying interests so.",
            "So again, the nice thing is the same basic strategy will will will remain.",
            "And what happens is this player is going to subsidize some of the exploration of the second agent.",
            "Other agents are going to be exactly as before.",
            "OK."
        ],
        [
            "Hey.",
            "OK. Two more extensions in which I wish they.",
            "Knew more about that I can tell you what they do know, right?",
            "OK.",
            "So one weakness in the model they describe is that I said once in action is realized every time you do the same action, you're going to get the exactly the same reward.",
            "It would have been nice to say that there is a prior over the expectation of an action.",
            "Let's say it's it's a bernouilli random variable, and each one is going to get a draw from this action.",
            "So if we have stochastic playoffs, we can get an approximate optimal policy.",
            "It's going to be the same policy in essentially the idea so that we can sort of break the sample into blocks of one over epsilon squared, and sort of when we are averaging over one of option squared agents, we're almost getting the deterministic one.",
            "The unfortunate thing is.",
            "I have no idea how to get the optimal policy in this case, like how.",
            "How would you get something like the git index that essentially will do the optimal tradeoff here between the exploration and exploitation?",
            "Another issue, sort of.",
            "I discard everything for for two actions and it's it's no coincidence like sound.",
            "If you go from 2.",
            "Actually even 2 three actions, a state space becomes richer, so so.",
            "For the optimal policy 443 actions, I'm not sure even how it looks like, but what we can do we can sort of get in approximation, right?",
            "We can increase the regret by a factor of a number of action.",
            "But sort of doing tournaments, sort of take the pill with two candidate based action and do a tournament between them and then do another tournament with the next guy in the next day.",
            "This will cost you a factor of a number of action in the regret.",
            "It's definitely not the optimal policy."
        ],
        [
            "OK.",
            "The last thing is sort of public recommendation.",
            "So in some setting, public accommodations are more meaningful than private ones.",
            "So if you think about the report cards, my first slide in the top, this is really public recommendation.",
            "Usually you put it up on the web and everyone can see it.",
            "So public accommodations are better than full information.",
            "So.",
            "OK, with the men observation again in public recommendation, is it?",
            "Yes you can.",
            "You can try to induce explosion in various extras, but because everything is public because the planner doesn't sort of controls in formation and gives different bits to different people.",
            "Essentially you can move all the explosion with people are willing to do to the second agent if Edge is number 5 is willing to do an explosion under certain condition then engine #2 is also willing to do.",
            "The exploration I don't know the same condition, so it gives a very simple characterization.",
            "So namely, the only exploration in the optimal policy, the only expression that you will get is from the second agent.",
            "But this is significant limitation.",
            "It really means that you can have a linear regret in the sense.",
            "In the optimal policy, under the public recommendation, so you're not going to get the socially optimal outcome that you would like to have.",
            "OK."
        ],
        [
            "Conclude, OK, So what I discovered discovered an optimal policy in a very limited in a very specific setting.",
            "It makes us exploration and exploitation in some sense.",
            "The exploitation is really using the past information using the information, whether you know that Action 2 is better or you would like to explore it for the first time.",
            "Any of the exploitation well, what we have?",
            "What we're doing.",
            "We're really gathering in the exploration.",
            "We're gathering new information in the new information is is one we sort of allows us to do more.",
            "Explorer Explorer exploration and exploitation.",
            "Furthermore, if you think it's a high level sort of what this research is trying to say is, although the I would say the widely public believe the the higher transparency will get the better things are going to be.",
            "I think that.",
            "Even if we ignore sort of the theoretical model that I described here, there is a risk in in transparency and the risk and transparency is essentially that it will cause people to become conservative.",
            "I think we saw it sort of theoretically in in our model, but it's an issue that does come sort of.",
            "To life in various settings.",
            "OK."
        ],
        [
            "And this points of Al concluding."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So today I'm going to talk about implementing the wisdom of the crowd.",
                    "label": 1
                },
                {
                    "sent": "This is sort of a work which is in between game theory, computer science, more more.",
                    "label": 0
                },
                {
                    "sent": "We will fit.",
                    "label": 0
                },
                {
                    "sent": "Twist probably told the game theorists over two quarters, Elon Kramer and multi Perry.",
                    "label": 0
                },
                {
                    "sent": "One is an economist, one is a former finance Department.",
                    "label": 0
                },
                {
                    "sent": "And sort of the end of this claim.",
                    "label": 0
                },
                {
                    "sent": "But I want to say is that I decided, sort of.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to give any proof, so I try to keep it in the high level and intuitive level.",
                    "label": 0
                },
                {
                    "sent": "Anyone who would like to know more is more than welcome to us questions later.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it is sort of the starting point of of where we started this research.",
                    "label": 0
                },
                {
                    "sent": "So many things there's like there is.",
                    "label": 0
                },
                {
                    "sent": "There is a tendency to believe the transparency is what we should have.",
                    "label": 0
                },
                {
                    "sent": "Like we started looking at the report cards report court system today exist for many things in healthcare and education, probably with professors.",
                    "label": 0
                },
                {
                    "sent": "Get the student reviews getting published.",
                    "label": 0
                },
                {
                    "sent": "And and there is the real reason why it exists, because people believe that if we publish it, it will be transparent if people will see it, it will improve the quality and it really needs to be.",
                    "label": 0
                },
                {
                    "sent": "This is one side of it and the other side of it is to provide information to other people who come.",
                    "label": 0
                },
                {
                    "sent": "Like anything which which involves people, which it becomes a game in gaming, the system in report cards is an issue.",
                    "label": 0
                },
                {
                    "sent": "For example, if you look at healthcare, then it's very good that hospitals have to report sort of.",
                    "label": 0
                },
                {
                    "sent": "How successful their operations are?",
                    "label": 0
                },
                {
                    "sent": "What's the death rate in a heart transplant?",
                    "label": 0
                },
                {
                    "sent": "But what you do find out very fast is that they're trying to game the system.",
                    "label": 1
                },
                {
                    "sent": "How do they gain the system?",
                    "label": 0
                },
                {
                    "sent": "They would opt in order to get the easier cases and try to avoid the hard cases.",
                    "label": 0
                },
                {
                    "sent": "This is 1 example.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is another example so.",
                    "label": 0
                },
                {
                    "sent": "I sort of assume how many people here use TripAdvisor way.",
                    "label": 0
                },
                {
                    "sent": "OK, that's very good cloud, so I don't need to really introduce the trip adviser to you.",
                    "label": 0
                },
                {
                    "sent": "So tribute to visors like recommendation site.",
                    "label": 0
                },
                {
                    "sent": "Most people, a few that are using it as sort of slightly unaware, sorta fulfill twist with really exist in the way that we all use it when you come to Barcelona, there are too many hotels you have.",
                    "label": 0
                },
                {
                    "sent": "There are too many restaurants when you need to go out for dinner, you're not going to go over all of them somehow.",
                    "label": 0
                },
                {
                    "sent": "What trip adviser has they have?",
                    "label": 0
                },
                {
                    "sent": "Sort of an algorithm with sort of.",
                    "label": 0
                },
                {
                    "sent": "Gives you a number people can understand the single number, so it gives the ranking between the different hotels between the different restaurants and this is the popularity index.",
                    "label": 0
                },
                {
                    "sent": "With TripAdvisor it gives you.",
                    "label": 0
                },
                {
                    "sent": "If you look if you look even slightly that you see it's not the average of what people reported, so the popularity index is a proprietary algorithm.",
                    "label": 0
                },
                {
                    "sent": "So just to be fair, I have no idea how exactly they do it, but it's also a self reinforcing algorithm, so if you look on research with people did in hotels, so the difference between being rated number 10 or #20 amounts to something like 10%.",
                    "label": 0
                },
                {
                    "sent": "In the in the hotel bookings that you're going to get, so it's very significant amount for the hotel, but also to sell something which is self reinforcing.",
                    "label": 0
                },
                {
                    "sent": "If you take a small restaurant which is just opened and got a few good reviews and you push it up, you're very likely as the trip adviser website you're going to get more reviews for that restaurant, so in fact you can.",
                    "label": 0
                },
                {
                    "sent": "You need to think that there is some exploration versus exploitation issue.",
                    "label": 0
                },
                {
                    "sent": "We should go here in.",
                    "label": 0
                },
                {
                    "sent": "Into here because somehow you do want to to elicit information from the people.",
                    "label": 0
                },
                {
                    "sent": "And here is sort of.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The most convincing example, and for this example we even have a video of the CEO saying it so ways used to be an Israeli startup.",
                    "label": 0
                },
                {
                    "sent": "Now it got bought by Google.",
                    "label": 0
                },
                {
                    "sent": "If you months ago and what it does is a real time navigation recommendation.",
                    "label": 1
                },
                {
                    "sent": "So basically you get into your car, you take your smartphone, turn it on and it gives you sort of the recommendation of how to drive home.",
                    "label": 0
                },
                {
                    "sent": "And it's based on real time information that it gets from other user.",
                    "label": 1
                },
                {
                    "sent": "Basically we are the traffic jam.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "How are you is the best way to drive?",
                    "label": 0
                },
                {
                    "sent": "Now here is the real dilemma.",
                    "label": 0
                },
                {
                    "sent": "From time to time they need to send people on route routes that we have no idea whether they are good or bad.",
                    "label": 1
                },
                {
                    "sent": "Because they need to do the exploration.",
                    "label": 0
                },
                {
                    "sent": "And in the seal just said, OK, we do it.",
                    "label": 0
                },
                {
                    "sent": "There is no choice, right?",
                    "label": 0
                },
                {
                    "sent": "Someone needs for the better good to stand on the fence so people will be able to walk over.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And when you think about it, it makes sense.",
                    "label": 0
                },
                {
                    "sent": "Like someone needs to do this exploration.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you see that your navigation system is always sending you on very long route, you're not going to use it.",
                    "label": 0
                },
                {
                    "sent": "In fact, what I suspect is that you have such a high sort of noise right in the navigation system.",
                    "label": 0
                },
                {
                    "sent": "In any case, that even if we just look at the time in which it didn't predict correctly, most of those times are not due to the fact that they're doing exploration.",
                    "label": 0
                },
                {
                    "sent": "Most of those times, because traffic conditions change from the time you.",
                    "label": 0
                },
                {
                    "sent": "You sort of started driving to the time that you got to the place.",
                    "label": 0
                },
                {
                    "sent": "And intuitively, so people would be people are willing to use this system and the reason why they are winning is because most of the time that would get good recommendation.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Leaves is what I want to talk today, so I would like to talk about agents with need to select between a few alternative fuel ternative's could be hotels like in the TripAdvisor case, traffic routes like in the ways example doctors like in report cards.",
                    "label": 1
                },
                {
                    "sent": "So this is sort of the issue.",
                    "label": 1
                },
                {
                    "sent": "Will assume that they have sort of known prior about the success.",
                    "label": 0
                },
                {
                    "sent": "So if you are driving every day from work to home, you have a very good prior.",
                    "label": 1
                },
                {
                    "sent": "How much time each route is going to take, but the variance is what you would really like to to to know.",
                    "label": 0
                },
                {
                    "sent": "We will have multiple agents without arriving in each one wouldn't just need to make one decision.",
                    "label": 0
                },
                {
                    "sent": "Each one is just taking one route.",
                    "label": 0
                },
                {
                    "sent": "Still, at home and the individual edges, of course, strategic in the sense you would like to get faster, you're not really into trying to exploring.",
                    "label": 0
                },
                {
                    "sent": "So you would be willing to take the advice of the system if you think that this is the best thing that you can do.",
                    "label": 0
                },
                {
                    "sent": "So the point of perspective, it will be trying to look for it is from the planner perspective is the one which is sort of controlling the information we would like to learn how to really to implement such a system.",
                    "label": 0
                },
                {
                    "sent": "So the goal of the planner is that everyone would be better off, right is the goal of a planner with everyone would get as fast as they can home, but he's looking at the sum of things and therefore there is tension between what he wants and what the individual people want.",
                    "label": 0
                },
                {
                    "sent": "You can think about the planner as a regulator or SoC when you're thinking about report card, but in many cases you can think that maximizing the user satisfaction even for.",
                    "label": 0
                },
                {
                    "sent": "Bill Wolfe site like trip adviser.",
                    "label": 0
                },
                {
                    "sent": "This is the real goal.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The main issue here is that agency will have a dual role they're both producing and consuming information.",
                    "label": 0
                },
                {
                    "sent": "They are consuming information and then through this consumption.",
                    "label": 0
                },
                {
                    "sent": "They are getting their utility, but also while they are consuming their producing new information that will help the GNU users that are going to come along.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is?",
                    "label": 0
                },
                {
                    "sent": "So the main research question that I would sort of schedule days.",
                    "label": 1
                },
                {
                    "sent": "How does the optimal Planner policy should look like?",
                    "label": 1
                },
                {
                    "sent": "So what is so first of all?",
                    "label": 0
                },
                {
                    "sent": "What is linear control?",
                    "label": 0
                },
                {
                    "sent": "So really, what he control, he controls the information.",
                    "label": 0
                },
                {
                    "sent": "He can sort of decide what he can tell about the other users about what he knows.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk with no more money incentives.",
                    "label": 0
                },
                {
                    "sent": "You can extend the result to monitor incentives.",
                    "label": 0
                },
                {
                    "sent": "I doubt if I do it at the end.",
                    "label": 1
                },
                {
                    "sent": "What the planet would like to do?",
                    "label": 0
                },
                {
                    "sent": "He would like to induce exploration.",
                    "label": 1
                },
                {
                    "sent": "He would like that at the end to guarantee that everyone is doing the better alternative.",
                    "label": 1
                },
                {
                    "sent": "What would look at would look sort of.",
                    "label": 0
                },
                {
                    "sent": "OK, so our goal is to find the optimal policy and will also try to measure how good is the optimal policy.",
                    "label": 0
                },
                {
                    "sent": "What do I mean by?",
                    "label": 0
                },
                {
                    "sent": "How good is the optimal policy?",
                    "label": 0
                },
                {
                    "sent": "How far is it from from a setting in which we knew everything?",
                    "label": 0
                },
                {
                    "sent": "So what is very great of the optimal policy in this setting?",
                    "label": 1
                },
                {
                    "sent": "And it can rebound the cost of exploration in some sense.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let me do it D2.",
                    "label": 0
                },
                {
                    "sent": "Trying to connect with what I'm going to talk today with a few themes that is very familiar to this community.",
                    "label": 0
                },
                {
                    "sent": "So assume that multi armed bandit sort of.",
                    "label": 0
                },
                {
                    "sent": "After seeing glasses session of an hour and a half, most people know what's multi armed.",
                    "label": 0
                },
                {
                    "sent": "Bandit is a very simple decision theoretic model.",
                    "label": 1
                },
                {
                    "sent": "We have multiple independent action and we have the real uncertainties regarding the reward.",
                    "label": 1
                },
                {
                    "sent": "The main issues is that there is a repeated interaction between selecting the action and relegating the reward.",
                    "label": 0
                },
                {
                    "sent": "And the main focus is with tradeoff between the exploration and exploitation.",
                    "label": 1
                },
                {
                    "sent": "So this is sort of a places which will be in some sense similar.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when you think about multi Arm Bandit is really there to two things, I think the cold community is almost all on the right hand side of the slide.",
                    "label": 0
                },
                {
                    "sent": "There is a Bayesian sighting in which we assume it prior over rewards and given the power of the rewards there are optimal algorithm like the Gittins index for the discounted return there is that your serial setting in which we are all interested in worst case bounds.",
                    "label": 1
                },
                {
                    "sent": "Worst case with would hold true for any reward sequence that we're going to observe.",
                    "label": 1
                },
                {
                    "sent": "And we measure the regret is with difference between the best action and the online performance and the goal is to get the varnishing regret varnishing as a function of the number of time steps.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now let's sort of contrast where where I'm going to talk today versus the classical setting.",
                    "label": 0
                },
                {
                    "sent": "So in the classical setting, the wave and certainty regarding rewards, right?",
                    "label": 1
                },
                {
                    "sent": "This is the main uncertainty in this drastic setting.",
                    "label": 0
                },
                {
                    "sent": "It comes from the distributions in that your server setting is because we don't know what the remaining reward sequences.",
                    "label": 0
                },
                {
                    "sent": "But we do have certainty about something we do have certainty when we perform an action, it's going to get performed.",
                    "label": 0
                },
                {
                    "sent": "In our setting there is sort of like another uncertain T. We haven't certainty regarding rewards is before, but we also have uncertainty about the execution of an action, because in some sense what I said is that yes, we can recommend you how to to drive home, but you then we'll look at the routing.",
                    "label": 0
                },
                {
                    "sent": "Sometimes when I use Waze and says it doesn't make sense and I just don't take that route right?",
                    "label": 0
                },
                {
                    "sent": "So we can recommend things, but you can't force things to happen, so we cannot force exploration, so will need sort of power somehow too.",
                    "label": 0
                },
                {
                    "sent": "Induce exploration without focusing it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why is all this interesting?",
                    "label": 1
                },
                {
                    "sent": "So this is sort of a more personal perspective.",
                    "label": 0
                },
                {
                    "sent": "Why is it interesting to me?",
                    "label": 1
                },
                {
                    "sent": "So I think includes, do you think incentives to the basic tradeoff between exploration and exploitation is something that I find very interesting?",
                    "label": 0
                },
                {
                    "sent": "And I think it's it could be a very fruitful, even especially for this community to think, sort of along those lines.",
                    "label": 0
                },
                {
                    "sent": "Adding a third dimension to the classical tradeoffs in which incentives.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you think about the machine right, there are no incentives.",
                    "label": 0
                },
                {
                    "sent": "But if you think about trying to implement the multi arm bent on on humans, you should think that incentives would come here in one way or another.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I'm going to.",
                    "label": 1
                },
                {
                    "sent": "Let's talk about action control about strategic agents in a related work with Nikolaj is a, Bianchi and.",
                    "label": 0
                },
                {
                    "sent": "And Fabrizio Germano, which is sort of.",
                    "label": 0
                },
                {
                    "sent": "For a long time we're playing around.",
                    "label": 0
                },
                {
                    "sent": "We never thought of God to write it up, but here is sort of the gust of ideas.",
                    "label": 1
                },
                {
                    "sent": "So I think the motivation is only the strongest thing that we can see.",
                    "label": 0
                },
                {
                    "sent": "Think about the classical expert advice, so the classical expert advice is a basic assumption in the beginning.",
                    "label": 0
                },
                {
                    "sent": "The experts really want to give the information right.",
                    "label": 0
                },
                {
                    "sent": "Experts do not have incentives.",
                    "label": 0
                },
                {
                    "sent": "Let's think about life.",
                    "label": 1
                },
                {
                    "sent": "So sometimes it's true expert do not have incentives, but in many settings experts do have incentives.",
                    "label": 0
                },
                {
                    "sent": "Anyone who sort of four rented or bought an apartment recently.",
                    "label": 0
                },
                {
                    "sent": "He knows that real estate agents do have incentives.",
                    "label": 0
                },
                {
                    "sent": "That incentives are not aligned with your incentives and not with the seller incentive, right?",
                    "label": 0
                },
                {
                    "sent": "They want to add a deal to go through somehow.",
                    "label": 0
                },
                {
                    "sent": "Coming from Israel Army Generals Army generals also usually have incentives like they're more likely to think that there is a solution using the army.",
                    "label": 0
                },
                {
                    "sent": "If you think about this life right, it's not a joke.",
                    "label": 0
                },
                {
                    "sent": "Where I come from, it's not, it's not OK. Criminal trials in the US think about juries.",
                    "label": 0
                },
                {
                    "sent": "People on Julie's many times have incentives.",
                    "label": 0
                },
                {
                    "sent": "Incentives is not that tight so everyone wanted.",
                    "label": 0
                },
                {
                    "sent": "If someone did, the crime should go to jail and if he didn't do anything he should go free.",
                    "label": 0
                },
                {
                    "sent": "But the title between false positive and false negative is very different for different people.",
                    "label": 0
                },
                {
                    "sent": "Alright, so when you set up a Julie, you need to be aware that this is this is an issue.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "So what could be a research agenda here?",
                    "label": 1
                },
                {
                    "sent": "And this is what we try to do.",
                    "label": 0
                },
                {
                    "sent": "So you would like to be biased there.",
                    "label": 0
                },
                {
                    "sent": "The experts.",
                    "label": 0
                },
                {
                    "sent": "Somehow you would like to be able to get a better prediction even when the experts are biased.",
                    "label": 0
                },
                {
                    "sent": "Get better tradition and more reliable one, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The good news is I think it's a very good motivation.",
                    "label": 0
                },
                {
                    "sent": "The bad news, but I don't have too much to say about it, at least now.",
                    "label": 0
                },
                {
                    "sent": "So now we can sort of go and continue, sort of.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Along Villa, so now I'm going to sort of before I can sort of say the result even I want to sort of set up the model.",
                    "label": 0
                },
                {
                    "sent": "So what is the model?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to have a very simplistic setting in this simplistic setting.",
                    "label": 0
                },
                {
                    "sent": "We just have two action for each agent.",
                    "label": 0
                },
                {
                    "sent": "Each agent has changes to choose between two alternatives.",
                    "label": 0
                },
                {
                    "sent": "You can think of between.",
                    "label": 0
                },
                {
                    "sent": "Selecting between two medical treatments, right?",
                    "label": 0
                },
                {
                    "sent": "Each action has a fixed but unknown reward.",
                    "label": 1
                },
                {
                    "sent": "So once we realized in action we know sort of.",
                    "label": 0
                },
                {
                    "sent": "What is reward is and we will.",
                    "label": 0
                },
                {
                    "sent": "We are going to do it in a Bayesian setting.",
                    "label": 1
                },
                {
                    "sent": "We will have a prior over the rewards.",
                    "label": 1
                },
                {
                    "sent": "It's well known everyone knows it and just for simplicity, let's assume that action one is a priority, the better one.",
                    "label": 0
                },
                {
                    "sent": "We will have a stream of agents T agents.",
                    "label": 0
                },
                {
                    "sent": "They will arrive one after the other sequentially.",
                    "label": 0
                },
                {
                    "sent": "And each one knows his place in the order so I know that I'm the first one, the second guide knows it is the second guy, etc.",
                    "label": 0
                },
                {
                    "sent": "Each agent will get a single chance to select an action and get the reward of the action that is selected.",
                    "label": 1
                },
                {
                    "sent": "We'll assume that the agents are risk neutral.",
                    "label": 0
                },
                {
                    "sent": "Basically they just would like to maximize the expectation of the of of the reward that they're going to get.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, we are fixing the averages.",
                    "label": 0
                },
                {
                    "sent": "The agents what are going to do?",
                    "label": 0
                },
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "They get some information during the process given all the information they receive, they can compute some posterior and they're going to choose a better action according to their posterior.",
                    "label": 0
                },
                {
                    "sent": "So the agents of two armed bandits, but they are fixed by saying that they maximize their utility.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main issue is sort of how to elicit things from those simply to arm bands, so we'd be looking at the plan so the planner is the one which would like to plan for.",
                    "label": 0
                },
                {
                    "sent": "So the planner really controls the information and you would like to maximize the expected some of payoff.",
                    "label": 1
                },
                {
                    "sent": "So he's like maximizing the social welfare.",
                    "label": 0
                },
                {
                    "sent": "The agents of incentive compatible in the sense that they are going to do whatever is in their best interest and where.",
                    "label": 0
                },
                {
                    "sent": "If they said no payments for now, we can sort of relax it later.",
                    "label": 0
                },
                {
                    "sent": "And it's not that important.",
                    "label": 0
                },
                {
                    "sent": "So what can the action plan or do so the planner can sort of tell a story to each one of the agents so he's the real estate agent and it says a very long story to tell about what happened in previously right and then sort of the agent does what he does and the planner observes the outcome.",
                    "label": 0
                },
                {
                    "sent": "So now we have iteration.",
                    "label": 0
                },
                {
                    "sent": "Each time the plan of sort of gives a message to the next agent and then the the agency is done going to do the action with sort of maximizes its own utility.",
                    "label": 0
                },
                {
                    "sent": "In order to complete it into a game theoretic setting, we do assume that the agents know the plan of policy.",
                    "label": 0
                },
                {
                    "sent": "So in some sense the planner cannot lie in the usual sense, right?",
                    "label": 0
                },
                {
                    "sent": "So I know that if you plan, it told me to do action one, it's really big 'cause he observed AB&C in his code and this is sort of why he's recommending it.",
                    "label": 0
                },
                {
                    "sent": "So, so in the sense the agents, when they come to make their decision, their decision is based also on the plane of policy on how to give the recommendation, and the goal is.",
                    "label": 1
                },
                {
                    "sent": "To maximize the sum of the payoff, this is the plan or goal, right?",
                    "label": 1
                },
                {
                    "sent": "So this is a social welfare maximization.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that also.",
                    "label": 0
                },
                {
                    "sent": "So, so I'm going to mainly discuss private recommendation for this.",
                    "label": 0
                },
                {
                    "sent": "I'm going to derive an optimal policy.",
                    "label": 1
                },
                {
                    "sent": "The exact optimal policy, and in addition to being exactly optimal, it will also had good performance in the sense that the total regret that you and care is only constant depends on the prior, and there's no dependent on the number of agents that show up.",
                    "label": 1
                },
                {
                    "sent": "Blue flame going through later today to mention some other models.",
                    "label": 0
                },
                {
                    "sent": "So when you don't know your place in the line or the inventor is money or there is more information over and accommodation are sort of observed by everyone who asks, but the main sort of what I think I'm going to talk about is a private recommendation and the fact that in this case we can sort of implement the optimal social welfare with relatively low cost.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so before going on.",
                    "label": 0
                },
                {
                    "sent": "I'm going to speak about a related, probably unrelated work and later, as explained to me, why is it unrelated and the main reason is because I think it's very interesting for those of you unfamiliar with it.",
                    "label": 0
                },
                {
                    "sent": "So this is information cascading.",
                    "label": 1
                },
                {
                    "sent": "So what happens in Informacion cascading?",
                    "label": 0
                },
                {
                    "sent": "So we think that there are two bins.",
                    "label": 0
                },
                {
                    "sent": "I hope you can see the color.",
                    "label": 0
                },
                {
                    "sent": "This is red and this is green.",
                    "label": 0
                },
                {
                    "sent": "And you know that in the Bender of either 2 green balls in three Red Bulls.",
                    "label": 0
                },
                {
                    "sent": "02 red balls and three green balls.",
                    "label": 0
                },
                {
                    "sent": "By probability 1/2 it's this one probability.",
                    "label": 0
                },
                {
                    "sent": "1/2 is this one, and some of.",
                    "label": 0
                },
                {
                    "sent": "You would like to know which case it is.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what happens is, is the following sort of scenario.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This guy comes.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He put in his hand into his hand into the bin and pulls out the board and now he needs to predict he needs to predict whether there are more red balls or more green balls.",
                    "label": 0
                },
                {
                    "sent": "So OK, so first guys, very easy, right?",
                    "label": 0
                },
                {
                    "sent": "He's so Red Bull more likely.",
                    "label": 0
                },
                {
                    "sent": "That is that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Majorities, red, so he's saying red.",
                    "label": 0
                },
                {
                    "sent": "Now they say.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second guy comes and he pulls another book.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if he pulls the green ball, let's assume that if he pulls the green Bolton is gone.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To say Green Solid trust himself more than the first guy.",
                    "label": 0
                },
                {
                    "sent": "Mike",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Without death.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If it sees a Red Bull now, now is even more confident.",
                    "label": 0
                },
                {
                    "sent": "The majority is red.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He's going to say right away.",
                    "label": 0
                },
                {
                    "sent": "The things becomes interesting with third.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The third guy comes up.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And he's seeing a green ball.",
                    "label": 0
                },
                {
                    "sent": "What should he say?",
                    "label": 0
                },
                {
                    "sent": "OK, so now this in some sense you know that the first guy said red, so it means that is so bad he is known as the second guy, said red.",
                    "label": 0
                },
                {
                    "sent": "So it means that is so red he's so green, but two Reds versus 1 green.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He's going to say red.",
                    "label": 0
                },
                {
                    "sent": "So what is there to form this point on?",
                    "label": 0
                },
                {
                    "sent": "Everyone is going to say read.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so so it means that there is a constant probability.",
                    "label": 0
                },
                {
                    "sent": "It's not that tiny.",
                    "label": 0
                },
                {
                    "sent": "That if we have a huge number of people, it doesn't make any difference.",
                    "label": 0
                },
                {
                    "sent": "They're all going to say the same.",
                    "label": 0
                },
                {
                    "sent": "They're all going to be included, correct?",
                    "label": 0
                },
                {
                    "sent": "And if they all said the signal with overwhelming probability.",
                    "label": 0
                },
                {
                    "sent": "We would have known the correct answer, so some information doesn't aggregate here.",
                    "label": 0
                },
                {
                    "sent": "So so now I want to sort of to explain why doesn't happen in our setting, hope.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm not confusing you too much, so here is sort of our setting.",
                    "label": 0
                },
                {
                    "sent": "Describe pictures so.",
                    "label": 0
                },
                {
                    "sent": "So the teacher here is the planner and what the planner.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is doing is agents of coming one by one in.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the teacher is sort of giving recommendation.",
                    "label": 0
                },
                {
                    "sent": "A private recommendation.",
                    "label": 0
                },
                {
                    "sent": "Oh you, you should do it.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the agent gets to choose whether to push the green button or the red button.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And after the agent pushed the button.",
                    "label": 0
                },
                {
                    "sent": "He gets the reward.",
                    "label": 0
                },
                {
                    "sent": "The planner observes a reward and the age.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go walks away so I'm like in the in formation cascading.",
                    "label": 0
                },
                {
                    "sent": "He really, the planner has all the information.",
                    "label": 0
                },
                {
                    "sent": "He is the one that aggregates information and he is one that discloses information and therefore sort of there isn't any real issue of cascading of information because the information is sort of channeled.",
                    "label": 0
                },
                {
                    "sent": "Four through this planet.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we want to start the describing our results in model so.",
                    "label": 0
                },
                {
                    "sent": "So let's start with a few simple observation, right?",
                    "label": 0
                },
                {
                    "sent": "So once, so since the planner controls information, the simplest policy is not to give any information.",
                    "label": 0
                },
                {
                    "sent": "If we don't give any information, everyone is going to do the better or your reaction.",
                    "label": 1
                },
                {
                    "sent": "Basically no, no exploracion.",
                    "label": 0
                },
                {
                    "sent": "OK, this doesn't look good.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other extreme.",
                    "label": 0
                },
                {
                    "sent": "Is full in formation so full in formation.",
                    "label": 0
                },
                {
                    "sent": "Still unclaimed, it's very easy to see, will have limited exploration.",
                    "label": 1
                },
                {
                    "sent": "Alright, so let's do very.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple example, suppose there's two options.",
                    "label": 0
                },
                {
                    "sent": "The first action is uniform between minus one and +2, and the second option is uniform fitting minus two and plus two now.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "If the first agent observes a value which is known negative, it's strictly positive everyone is going to do the first action right?",
                    "label": 0
                },
                {
                    "sent": "Although there is a fair chance of the second option is still better.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "So full information is not doing what we would like it and it is doing something that you would observe.",
                    "label": 0
                },
                {
                    "sent": "Also in practice, I think it causes people to be more conservative.",
                    "label": 0
                },
                {
                    "sent": "It causes people sort of to rely more on on what what is out there and not to try to do to explore new things.",
                    "label": 0
                },
                {
                    "sent": "But but if there are 100 people you want one of them to try the second a action because the second suppose the first action is 0.5.",
                    "label": 0
                },
                {
                    "sent": "The second action says still is a good probability to being above 0.5.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "The agents are coming 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "The first agent is going to do the yellow action.",
                    "label": 0
                },
                {
                    "sent": "Supposedly he observes 0.5 now in the full information, the planner is just telling everyone what the first agent received, so it tells everyone you know the yellow action would give you 0.5 every time you push the yellow action you get 0.5.",
                    "label": 0
                },
                {
                    "sent": "So from that point on the planner cannot convince anyone to do the blue action.",
                    "label": 0
                },
                {
                    "sent": "Although if there are many people you would like to someone to.",
                    "label": 0
                },
                {
                    "sent": "Try the yellow action.",
                    "label": 0
                },
                {
                    "sent": "You do have a probability of 1 / 8.",
                    "label": 0
                },
                {
                    "sent": "I think that the blue action is better, so you would like someone to try the blue action.",
                    "label": 0
                },
                {
                    "sent": "But if you're doing full information, you're not going to get anyone to agree to do it.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, before describing the result of.",
                    "label": 0
                },
                {
                    "sent": "We do need some technical condition and I sort of ascribe it would impossibility result.",
                    "label": 0
                },
                {
                    "sent": "So in some sense.",
                    "label": 0
                },
                {
                    "sent": "We cannot always guarantee exploration, and here is when we cannot suppose that sort of action one has a predefined payoff which is deterministic.",
                    "label": 0
                },
                {
                    "sent": "In action, Two has a lower expectation.",
                    "label": 0
                },
                {
                    "sent": "But there's sample ability of being better in sample building of being worse in some sense.",
                    "label": 0
                },
                {
                    "sent": "In this setting, the planner doesn't have any information you can sell to the agents, right?",
                    "label": 0
                },
                {
                    "sent": "Becausw.",
                    "label": 0
                },
                {
                    "sent": "Every agents know that all the engines before we would prefer the action one right.",
                    "label": 0
                },
                {
                    "sent": "The first active agent do action one, the second agent, regardless of what the planner tells him he knows what the plan of saw, and therefore he also do action one.",
                    "label": 0
                },
                {
                    "sent": "The third editing sort of so.",
                    "label": 0
                },
                {
                    "sent": "Everyone is going to do action one in this case, you plan or doesn't have any influence.",
                    "label": 0
                },
                {
                    "sent": "So the really mild assumption which we need to do is to require that there is some probability that the first action is works in the expectation of the second action.",
                    "label": 0
                },
                {
                    "sent": "So incense the planner there is away some scenario in which the planner can convince you to do the second action.",
                    "label": 0
                },
                {
                    "sent": "OK, so not willing to do the proof, but sort of if I did it for four, it's easier to think about full support for both action and no mask on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So here's how the algorithm is going to look.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the first agent, we don't have much of an influence is going to do the first action.",
                    "label": 0
                },
                {
                    "sent": "We're going to observe this reward for the second agent in Incels.",
                    "label": 0
                },
                {
                    "sent": "For each edge it will have a threshold, and once the reward is.",
                    "label": 0
                },
                {
                    "sent": "Below the flesh is OK.",
                    "label": 0
                },
                {
                    "sent": "If we already know the better action, we always recommend the better action.",
                    "label": 0
                },
                {
                    "sent": "If we observed only action once so far, then we have a threshold.",
                    "label": 0
                },
                {
                    "sent": "Depending on the value that we observe for action one, and this is sort of how are we splitting the exploration between the different agents, so agent is going to be the one to explore action too if he.",
                    "label": 0
                },
                {
                    "sent": "He's the first one to have this hold for him, and then we're going to recommend from action to otherwise action one right?",
                    "label": 0
                },
                {
                    "sent": "So in some sense, we are recommending action one until a certain agent, then a certain agent is going to be the first one who is going to be recommend to do action to and following him?",
                    "label": 0
                },
                {
                    "sent": "Everyone is going to do the better action.",
                    "label": 0
                },
                {
                    "sent": "In a few properties, sort of, the optimal policy is going to be.",
                    "label": 0
                },
                {
                    "sent": "Recommendations are going to be sufficient.",
                    "label": 0
                },
                {
                    "sent": "Essentially, I'm going to talk about it later.",
                    "label": 0
                },
                {
                    "sent": "It is revelation principle, right?",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "I don't need to sort of tell you anything about the past.",
                    "label": 0
                },
                {
                    "sent": "It's enough that tell you which actually is better for you to do.",
                    "label": 0
                },
                {
                    "sent": "The constraints of in the for the agents between the two actions are going to be tight.",
                    "label": 0
                },
                {
                    "sent": "This is also sort of fairly intuitive if since we want to maximize the exploration, will make it in such a way that a the agent doesn't care whether he does.",
                    "label": 0
                },
                {
                    "sent": "Action one or Action 2 and it will generally explore low values before- in.",
                    "label": 1
                },
                {
                    "sent": "Surreal intuition is really coming from the fact that.",
                    "label": 0
                },
                {
                    "sent": "The agent doesn't know why we recommended action to deal with it.",
                    "label": 0
                },
                {
                    "sent": "Did it come from here or did it come from here?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now this sort of to make sure that everyone sort of in line with what I'm going to do is in it.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample and I think through this example, the entire sort of algorithm would become fairly simple and obvious, right?",
                    "label": 0
                },
                {
                    "sent": "So let's do concrete example, right?",
                    "label": 0
                },
                {
                    "sent": "The first action is uniform between minus one and five, so it has a positive average value.",
                    "label": 0
                },
                {
                    "sent": "The second action is uniform between minus five and plus five, so zero expectation and think that the number of edges is huge.",
                    "label": 0
                },
                {
                    "sent": "So if you don't need to think about sort of effect of a small number of agents.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the picture that we start with.",
                    "label": 0
                },
                {
                    "sent": "So now we full conspiracy here like agents, one will choose the yellow action.",
                    "label": 0
                },
                {
                    "sent": "And now agents two will choose the blue action only for the yellow action is negative.",
                    "label": 0
                },
                {
                    "sent": "This is sort of what I already showed you.",
                    "label": 0
                },
                {
                    "sent": "So let's see how.",
                    "label": 0
                },
                {
                    "sent": "How can we solve this?",
                    "label": 0
                },
                {
                    "sent": "How can we overcome this problem?",
                    "label": 0
                },
                {
                    "sent": "How can we get convince sort of the second agents to do more exploration so?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is one way of doing it.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "This same picture.",
                    "label": 0
                },
                {
                    "sent": "So rather than telling the second agent the outcome of the first agent.",
                    "label": 0
                },
                {
                    "sent": "Let's just indicate that the reward is below 1.",
                    "label": 0
                },
                {
                    "sent": "Just telling the Daily World is below one don't end.",
                    "label": 0
                },
                {
                    "sent": "This is 0.5 or minus 0.5.",
                    "label": 0
                },
                {
                    "sent": "So now when when you convey the information that the reward of the first action is below 1.",
                    "label": 0
                },
                {
                    "sent": "The second agent is indifferent between doing action one and two.",
                    "label": 0
                },
                {
                    "sent": "Both have expectation 0, so let's say it does what we ask him to.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we were able to induce more exploration by doing a partial revelation, so this outcome is more efficient than the full transparency one, and we got more exploration for the second agent.",
                    "label": 0
                },
                {
                    "sent": "But now how can we do better right?",
                    "label": 0
                },
                {
                    "sent": "So now the third agent will come right over the third agent.",
                    "label": 0
                },
                {
                    "sent": "We need sort of to have a different story.",
                    "label": 0
                },
                {
                    "sent": "OK, four.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Found agents.",
                    "label": 0
                },
                {
                    "sent": "OK. Now now we can sort of user information that the 2nd and just give us.",
                    "label": 0
                },
                {
                    "sent": "So now we have two cases in which we can sort of try to convince this third agent.",
                    "label": 0
                },
                {
                    "sent": "One case is sort of maybe the second agent already did action too.",
                    "label": 0
                },
                {
                    "sent": "And then in which case we will be recommending the better action.",
                    "label": 1
                },
                {
                    "sent": "And it could be that.",
                    "label": 0
                },
                {
                    "sent": "The first award was too high.",
                    "label": 0
                },
                {
                    "sent": "So the first one is above 1.",
                    "label": 0
                },
                {
                    "sent": "So now we can sort of stress starting stretch it so it's clear that the third agent would love to do action too in case one and would not like to do it in case 2.",
                    "label": 0
                },
                {
                    "sent": "But now we can sort of stretch eggs until to the point in which he is indifferent.",
                    "label": 0
                },
                {
                    "sent": "And if you run, do the calculation.",
                    "label": 0
                },
                {
                    "sent": "In this example you get 3 point something, and then in a sense.",
                    "label": 0
                },
                {
                    "sent": "You do in this example you do Agent 4.",
                    "label": 0
                },
                {
                    "sent": "And in the magical way, under after agent for your guarantee to cover all the exploration and therefore agents.",
                    "label": 0
                },
                {
                    "sent": "5 in order always going to do the better option.",
                    "label": 0
                },
                {
                    "sent": "So in a sense.",
                    "label": 0
                },
                {
                    "sent": "Your entire regret is built on a constant number of agents that happened in the beginning.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Faith is doing sort of a short overview, sort of what is involved in this.",
                    "label": 0
                },
                {
                    "sent": "Solution, so the basic properties.",
                    "label": 0
                },
                {
                    "sent": "So first I said recommendations are always sufficient and the way you can think about it is I can send you a message and ask and then given this measure you compute the posterior and given the posterior you do better action.",
                    "label": 0
                },
                {
                    "sent": "But if you know my policy and you know that I can sort of do this for you right rather than sending you a message, I'll take the message we want to send.",
                    "label": 0
                },
                {
                    "sent": "You compute the posterior and just tell you the outcome.",
                    "label": 0
                },
                {
                    "sent": "So therefore I can always rely only on recommendations.",
                    "label": 0
                },
                {
                    "sent": "The second.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Salvation is that the optimal policies is a partition policy sort of partition policy.",
                    "label": 0
                },
                {
                    "sent": "In this, in the following sense, it recommends to the first agent always the first action, because this is the only thing that he is going to do.",
                    "label": 0
                },
                {
                    "sent": "If both actions are sampled, is going to always recommend the better one, and so now the only thing is when are you going to ask the first guy to try the second action?",
                    "label": 0
                },
                {
                    "sent": "So essentially you're going to have a partition.",
                    "label": 0
                },
                {
                    "sent": "Depending on the values of the 1st.",
                    "label": 0
                },
                {
                    "sent": "Of the first the action, sometimes you have, say, agent for those value for Engine 3 doesn't have to be continuous like this is Agent 40 might.",
                    "label": 0
                },
                {
                    "sent": "This might be again agent for maybe no exploration here Agent 5 in Soto.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what you need to keep usually need to keep track of 2 two constraints like you want it when you recommend action to it is better to do action too.",
                    "label": 0
                },
                {
                    "sent": "And when you recommend action One, it is better to do action one.",
                    "label": 0
                },
                {
                    "sent": "Someone in this setting it's sufficient to look only on action too.",
                    "label": 0
                },
                {
                    "sent": "'cause action one is a priority better and so intuitively, although you need to prove it every time you recommend action one the edges is like it's in some way to follow it because.",
                    "label": 0
                },
                {
                    "sent": "It's also the operator we think, So what you needed to make sure is that when you recommend action Two, it's really.",
                    "label": 0
                },
                {
                    "sent": "Better for the agent to follow the recommendation, because this is the worst uproar reaction.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So OK, so few properties of the optimal policy, so you're going to get incentive constraints which are tight, so you want to make agents in different between the two alternative.",
                    "label": 0
                },
                {
                    "sent": "The second agent is going to explore any value which is already below the expectation of the of the second action.",
                    "label": 0
                },
                {
                    "sent": "So really, you're sort of getting rid of all the low values immediately, and generally you sort of explore low values between high values and this is sort of the threshold that we are good.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about so the optimal algorithm is going to look like this.",
                    "label": 0
                },
                {
                    "sent": "The first agent is going to recommend Action One, and we observe its reward.",
                    "label": 0
                },
                {
                    "sent": "All the other actions agents when we sample both action, recommend the better action.",
                    "label": 0
                },
                {
                    "sent": "And if we didn't some sample yet, the second action we're going to recommend action two if our one is less than the threshold of this agent.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we'll keep on asking for action.",
                    "label": 0
                },
                {
                    "sent": "One right so so the higher the value of action one, the more we are delaying the first agent, which is going to sample.",
                    "label": 0
                },
                {
                    "sent": "Action 2 in the intuition should come from the inherent tradeoff between each agent.",
                    "label": 0
                },
                {
                    "sent": "Doesn't know why we we recommended the the second action did recommend because we know in which case you would like to follow order.",
                    "label": 0
                },
                {
                    "sent": "We will recommend because we like him to explore, in which case it doesn't want to follow it.",
                    "label": 0
                },
                {
                    "sent": "And by balancing those two things, when you do get the exploration going on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the main technical difficulties really to show that the threshold is exactly the optimal policy.",
                    "label": 0
                },
                {
                    "sent": "It's built on a very delicate swap argument, in which case in if there is a known threshold, the.",
                    "label": 0
                },
                {
                    "sent": "Think you can gain by slow keeping, but the point is that you need to to gain in two different places.",
                    "label": 0
                },
                {
                    "sent": "One place that you need to gain or not close at least is a social welfare because you won't like to increase social welfare.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand side you need also to keep track of all for the incentives of the agents, right?",
                    "label": 0
                },
                {
                    "sent": "So there is the two agents that you are going to swap between them and they should both maintain their their belief that they're doing the better action for the room.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the thing that I'm not going to say much about.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it's strange in some sense to talk about what's the performance of an optimal policy, but I think it's worthwhile to think it here.",
                    "label": 0
                },
                {
                    "sent": "So what will happen in the when we are running this policy?",
                    "label": 0
                },
                {
                    "sent": "So it's the action one is better.",
                    "label": 0
                },
                {
                    "sent": "It's great.",
                    "label": 0
                },
                {
                    "sent": "Only one agent will try action too and we have very low weekly if Action 2 is better than what you can show, is it the number of agents without going to do exploration depends on the prior, but only on the pile.",
                    "label": 0
                },
                {
                    "sent": "So if the number of agents is going to Infinity really you have just a constant regret.",
                    "label": 0
                },
                {
                    "sent": "Which comes from this part.",
                    "label": 0
                },
                {
                    "sent": "So this is a constantly regret compared to what?",
                    "label": 0
                },
                {
                    "sent": "What would have been if you knew everything in advance and it's independent from the number of agents.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the ultimate policies social policy in fairly sort of simple to compute it.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go over it.",
                    "label": 0
                },
                {
                    "sent": "Essentially what you do is you compute it under the assumption that there is an infinite number of agents, and then you need to sort of to take care of the truncation effect truncation, meaning that since there are only 100 people, some values or just too high in order to try to explore.",
                    "label": 0
                },
                {
                    "sent": "So you compute it.",
                    "label": 0
                },
                {
                    "sent": "The threshold with the infinite one, and then you're sort of correcting them for the fact that you really have a finite number of agents and set your threshold to be the minimum of the tool.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and and as I said, sort of the regret that you are going to have is is depending.",
                    "label": 0
                },
                {
                    "sent": "Is a concept which is independent of T and here is sort of a way of bounding it right?",
                    "label": 0
                },
                {
                    "sent": "So we had to.",
                    "label": 0
                },
                {
                    "sent": "To expectations for the first argument with second action, and you can sort of bound.",
                    "label": 0
                },
                {
                    "sent": "This is a rough upper bound on the number of agents which cause can do sort of an in an optimal action.",
                    "label": 0
                },
                {
                    "sent": "Take the difference between the two expectation and divide them, sort of by this integral.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the probability that the first action is below the expectation of the second one, and it is the worst action, so this probability.",
                    "label": 0
                },
                {
                    "sent": "If you want that would control sort of you regret.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, let me talk briefly about a few extension and then probably open the floor for questions.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so relaxing the is it the agents knowledge So what?",
                    "label": 0
                },
                {
                    "sent": "I'll just have to know.",
                    "label": 0
                },
                {
                    "sent": "So we assume that agents know the exact place in in line.",
                    "label": 0
                },
                {
                    "sent": "So the first one knows it is the first second or does this second and sort of in some sense you would like to relax it in life, sort of.",
                    "label": 0
                },
                {
                    "sent": "It's not really make sense, you know exactly where you are in line you can think.",
                    "label": 0
                },
                {
                    "sent": "Sort of if you're selling something is like early adopter mass adoptation or later Doctor.",
                    "label": 0
                },
                {
                    "sent": "If you're driving home, you know that you're before rush hour.",
                    "label": 0
                },
                {
                    "sent": "UN golfed Abbatiale will after rush hour so you do know something about your place in line, but it doesn't have to be exact.",
                    "label": 0
                },
                {
                    "sent": "Essentially the same properties hold so, so if you if you sort of think of.",
                    "label": 0
                },
                {
                    "sent": "Taking the agents and dividing them into various number of blocks and in each block you sort of select randomly.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What would happen that in the optimal policy in every block is sort of the first you try to convince her first agent to explore for the entire block.",
                    "label": 0
                },
                {
                    "sent": "Since you block is sort of uniform, he's willing to do it and then sort of.",
                    "label": 0
                },
                {
                    "sent": "You just gain because you can.",
                    "label": 0
                },
                {
                    "sent": "You can induce more exploration because it has more uncertain T so blocks in only increase with social welfare and therefore reduce the regret.",
                    "label": 0
                },
                {
                    "sent": "In extreme Point, which is still interesting, sort of what would happen if if they just have no idea where they are in line, think about the random permutation.",
                    "label": 0
                },
                {
                    "sent": "So agents are not aware on the place in the queue.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "If you think about it, sort of.",
                    "label": 0
                },
                {
                    "sent": "The incentives of the agents in the planner sets are suddenly aligned because when there in there are no position.",
                    "label": 0
                },
                {
                    "sent": "Is there summing over all possible positions?",
                    "label": 0
                },
                {
                    "sent": "For their expectation and the planner is summing over all position to compute the social welfare.",
                    "label": 0
                },
                {
                    "sent": "So since their incentives are aligned.",
                    "label": 0
                },
                {
                    "sent": "What happens is the planner can simply run the optimal policy.",
                    "label": 1
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "No need to explain why.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so far in the model, we assume that there isn't any money going around, right?",
                    "label": 0
                },
                {
                    "sent": "So so we were trying to convince people to follow the action just based on their utilities and not by paying money.",
                    "label": 0
                },
                {
                    "sent": "Assume you have money.",
                    "label": 0
                },
                {
                    "sent": "Assume you can't pay people to do medical experiments or something right?",
                    "label": 0
                },
                {
                    "sent": "You can sort of induce exploration by paying money.",
                    "label": 0
                },
                {
                    "sent": "The nice thing is that the same policy states the same basic policy.",
                    "label": 0
                },
                {
                    "sent": "The only point now is that the planner has it.",
                    "label": 0
                },
                {
                    "sent": "His money is going to invest all the money that he has in the second agent to try to get the exploration as early as possible.",
                    "label": 0
                },
                {
                    "sent": "Other than this, essentially you're going to get the same construction.",
                    "label": 0
                },
                {
                    "sent": "It's going to be the same optimal policy.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "This is what happens when you work with people in finance.",
                    "label": 0
                },
                {
                    "sent": "So when when money costs money, OK, So what does it mean when money costs money?",
                    "label": 0
                },
                {
                    "sent": "So so when the OK.",
                    "label": 0
                },
                {
                    "sent": "So usually when you think you're making payments and payments are just coming from somewhere.",
                    "label": 0
                },
                {
                    "sent": "But things that if you have the government and you want to put taxes there is the cost of putting taxes.",
                    "label": 0
                },
                {
                    "sent": "So if you're going to take money then you're taking alone in your paying interests so.",
                    "label": 0
                },
                {
                    "sent": "So again, the nice thing is the same basic strategy will will will remain.",
                    "label": 0
                },
                {
                    "sent": "And what happens is this player is going to subsidize some of the exploration of the second agent.",
                    "label": 1
                },
                {
                    "sent": "Other agents are going to be exactly as before.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "OK. Two more extensions in which I wish they.",
                    "label": 0
                },
                {
                    "sent": "Knew more about that I can tell you what they do know, right?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So one weakness in the model they describe is that I said once in action is realized every time you do the same action, you're going to get the exactly the same reward.",
                    "label": 0
                },
                {
                    "sent": "It would have been nice to say that there is a prior over the expectation of an action.",
                    "label": 0
                },
                {
                    "sent": "Let's say it's it's a bernouilli random variable, and each one is going to get a draw from this action.",
                    "label": 0
                },
                {
                    "sent": "So if we have stochastic playoffs, we can get an approximate optimal policy.",
                    "label": 0
                },
                {
                    "sent": "It's going to be the same policy in essentially the idea so that we can sort of break the sample into blocks of one over epsilon squared, and sort of when we are averaging over one of option squared agents, we're almost getting the deterministic one.",
                    "label": 0
                },
                {
                    "sent": "The unfortunate thing is.",
                    "label": 0
                },
                {
                    "sent": "I have no idea how to get the optimal policy in this case, like how.",
                    "label": 0
                },
                {
                    "sent": "How would you get something like the git index that essentially will do the optimal tradeoff here between the exploration and exploitation?",
                    "label": 0
                },
                {
                    "sent": "Another issue, sort of.",
                    "label": 0
                },
                {
                    "sent": "I discard everything for for two actions and it's it's no coincidence like sound.",
                    "label": 0
                },
                {
                    "sent": "If you go from 2.",
                    "label": 0
                },
                {
                    "sent": "Actually even 2 three actions, a state space becomes richer, so so.",
                    "label": 0
                },
                {
                    "sent": "For the optimal policy 443 actions, I'm not sure even how it looks like, but what we can do we can sort of get in approximation, right?",
                    "label": 1
                },
                {
                    "sent": "We can increase the regret by a factor of a number of action.",
                    "label": 0
                },
                {
                    "sent": "But sort of doing tournaments, sort of take the pill with two candidate based action and do a tournament between them and then do another tournament with the next guy in the next day.",
                    "label": 0
                },
                {
                    "sent": "This will cost you a factor of a number of action in the regret.",
                    "label": 0
                },
                {
                    "sent": "It's definitely not the optimal policy.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The last thing is sort of public recommendation.",
                    "label": 0
                },
                {
                    "sent": "So in some setting, public accommodations are more meaningful than private ones.",
                    "label": 0
                },
                {
                    "sent": "So if you think about the report cards, my first slide in the top, this is really public recommendation.",
                    "label": 0
                },
                {
                    "sent": "Usually you put it up on the web and everyone can see it.",
                    "label": 0
                },
                {
                    "sent": "So public accommodations are better than full information.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, with the men observation again in public recommendation, is it?",
                    "label": 0
                },
                {
                    "sent": "Yes you can.",
                    "label": 0
                },
                {
                    "sent": "You can try to induce explosion in various extras, but because everything is public because the planner doesn't sort of controls in formation and gives different bits to different people.",
                    "label": 0
                },
                {
                    "sent": "Essentially you can move all the explosion with people are willing to do to the second agent if Edge is number 5 is willing to do an explosion under certain condition then engine #2 is also willing to do.",
                    "label": 0
                },
                {
                    "sent": "The exploration I don't know the same condition, so it gives a very simple characterization.",
                    "label": 0
                },
                {
                    "sent": "So namely, the only exploration in the optimal policy, the only expression that you will get is from the second agent.",
                    "label": 1
                },
                {
                    "sent": "But this is significant limitation.",
                    "label": 0
                },
                {
                    "sent": "It really means that you can have a linear regret in the sense.",
                    "label": 0
                },
                {
                    "sent": "In the optimal policy, under the public recommendation, so you're not going to get the socially optimal outcome that you would like to have.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Conclude, OK, So what I discovered discovered an optimal policy in a very limited in a very specific setting.",
                    "label": 1
                },
                {
                    "sent": "It makes us exploration and exploitation in some sense.",
                    "label": 0
                },
                {
                    "sent": "The exploitation is really using the past information using the information, whether you know that Action 2 is better or you would like to explore it for the first time.",
                    "label": 0
                },
                {
                    "sent": "Any of the exploitation well, what we have?",
                    "label": 0
                },
                {
                    "sent": "What we're doing.",
                    "label": 0
                },
                {
                    "sent": "We're really gathering in the exploration.",
                    "label": 0
                },
                {
                    "sent": "We're gathering new information in the new information is is one we sort of allows us to do more.",
                    "label": 0
                },
                {
                    "sent": "Explorer Explorer exploration and exploitation.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, if you think it's a high level sort of what this research is trying to say is, although the I would say the widely public believe the the higher transparency will get the better things are going to be.",
                    "label": 0
                },
                {
                    "sent": "I think that.",
                    "label": 0
                },
                {
                    "sent": "Even if we ignore sort of the theoretical model that I described here, there is a risk in in transparency and the risk and transparency is essentially that it will cause people to become conservative.",
                    "label": 0
                },
                {
                    "sent": "I think we saw it sort of theoretically in in our model, but it's an issue that does come sort of.",
                    "label": 0
                },
                {
                    "sent": "To life in various settings.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this points of Al concluding.",
                    "label": 0
                }
            ]
        }
    }
}