{
    "id": "q6xvu2dpxibmlhsvhbgsigkgszwdkbxi",
    "title": "JigPheno: Semantic Feature Extraction from biological images",
    "info": {
        "author": [
            "Theofanis Karaletsos, Max Planck Institute for Biological Cybernetics, Max Planck Institute"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Bioinformatics",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_karaletsos_jigp/",
    "segmentation": [
        [
            "OK, um I'm going to talk about Chino.",
            "And this is joint work with Oliver John Wynn from Microsoft Research and custom booklet.",
            "And, um."
        ],
        [
            "Thank you.",
            "OK, So what we're dealing with in this work in this project are images and natural variation images.",
            "So what we want to assess is how do images of natural objects vary.",
            "So for instance, if you look here you see a bunch of tomatoes that look wildly different, and the human eye can see this very easily and can assess things, but it's quite difficult to quantify, and we know that natural variation."
        ],
        [
            "Has genetical and environmental factors and we could we could use this dependence on them later on?",
            "So let's go to a specific example of natural variation."
        ],
        [
            "Let's look at these copies.",
            "They're called in Latin Pacilio reticulata, which is not important, but you see a lot of variation going on here, which.",
            "Is difficult to assess exactly, so if."
        ],
        [
            "You look at them.",
            "One thing you could say about the variation is very sensible thing or they are about this long and they're about this high and one might want to look at their color histograms to assess the color distributions of each to do to extract various appearance traits."
        ],
        [
            "But the appearance traits were more interested in our appearance traits.",
            "Like for instance, these spots, more detailed phenotypes that we could extract from images to describe their variability."
        ],
        [
            "So I'll just briefly explain the underlying assumption that we have for a model.",
            "We believe that image variation is explained by latent variables that represent patches.",
            "So, for instance, assume we have a set of latent variables.",
            "Here, each latent variable is one of those mark patches I showed earlier, and we believe that.",
            "Based on these latent variables, images are generated.",
            "Taking these patches and putting them together and assume that there is a set of snips snips are single nucleotide polymorphism's.",
            "They're just the polymorphic markers in that are different than individuals.",
            "And we can assume that these."
        ],
        [
            "Regulate the expression of these patches.",
            "And in order to create these latent variables to design."
        ],
        [
            "And there is a couple of choices.",
            "We want them first and foremost, to be interpretable, so we want we want the phenotype that you can look at and you can interpret it rather than some abstract number an we want these patches of course to exhibit some translational invariances in order to not have to be at a specific spot.",
            "So we want them to be general in a way.",
            "And we want them to be robust in shape and appearance.",
            "So we want to really be able to quantify most anything that we can see in an image."
        ],
        [
            "And so the jiffy.",
            "Invariants, sort of.",
            "It doesn't look like that's actually true, and so it doesn't.",
            "It doesn't have to be complete translational invariant, but it could be in part because, for instance, it could be that interesting feature is saying these fish is on the head on the general space of the head, so it can't be.",
            "It mustn't be exactly on the same spot, because sometimes even the head may be shaped differently, but you want it to be generally there instead of saying at the at the back piece of the Organism so.",
            "We want some translation invariants and robustness towards it, but we don't want to have everything the same.",
            "I'm going to come back to this point.",
            "So our basic model is.",
            "Jack FINA here.",
            "We assume a latent image J, which we will call a jigsaw and this jigsaw is something like the blueprint that contains all these features that we're looking at.",
            "It contains all these pieces and we believe that."
        ],
        [
            "There is a latent variable which of the mappings which are describing how we have to cut out these pieces in order to generate these images, and we believe as well that there's there's this idea that these mappings have genetic causes that it's not a random process that generates these images, but there's some genetics behind this.",
            "And we solve this approach in 2 steps."
        ],
        [
            "And the first step is what I'm mostly going to talk about.",
            "And the first step is building up on work by John Wynn from the NIPS community in 2006.",
            "So the first step is we generate images based on this latent image and these mappings, and if we have two, for instance these are.",
            "This is a real jigsaw.",
            "These are real fish that I generated.",
            "With this.",
            "We can take these pieces and generate images and here we can see the mappings so we can see that these pieces are the same and they're nice and semantic and everything goes where it's supposed to go is the first step and then if we had many of these images."
        ],
        [
            "Say we observe many images and we look at them and each one of them has some genetic information.",
            "We can automatically associate the mappings with this genetic background via, say, standard Genome Wide Association study.",
            "And this is a possible application of this so."
        ],
        [
            "Now I'm going to go into the detail of the jigsaw model here and Jigsaw model is generated unsupervised model.",
            "The unsupervised part is actually important.",
            "And what we have is this latent image J for each pixel J.",
            "So the small J.",
            "So just all the pixels in this latent image and each pixel of the latent image has five distinct variables which are RGB for the color channels, and X&Y for the positional positional information.",
            "So these are Gaussian variables and then we believe that we generate a set of N images.",
            "And each image has a certain mapping ally with a prior on it.",
            "And each image is generated as something that has colors.",
            "So each image, each pixel in an image has these color channels as well as positional information.",
            "And this is the general model.",
            "It's very easy to write down, and I'm going to go over these terms in detail now.",
            "So the terms that I'm going to go over is first of all the basic model.",
            "The jigsaw model in the prior then the smoothness prior on the likelihood of the generated image given these things."
        ],
        [
            "So the jigsaw model is basically fairly simple to explain.",
            "We have prior on the sticks are which is a mixture.",
            "We factorize it into the positional part and the appearance part the positional part.",
            "We model as just prior of normal gamma distribution because we want it to be isotropic.",
            "Two independent normal gammas and the appearance part we, which is where we couple the color channels and we describe it with a multivariate Gaussian and the likelihood of generating an image based on the mapping and the jigsaw is just a multivariate Gaussian.",
            "Van"
        ],
        [
            "The like the.",
            "Smoothness Prior is a little bit more tricky.",
            "Because here we assume a Markov random field.",
            "To obtain smoothness on these mappings.",
            "So the Markov random field, make sure that we obtain these pieces.",
            "How does it work precisely?",
            "For an images we have for every image mapping matrix of the same size as the image and each node here corresponds to a pixel is a 2 dimensional shift vector and each shift vector tells us how we have to displace a pixel to obtain its mapping to this latent image, where we draw the color from.",
            "So in order to get smoothness to get pieces that are consistent patches, we have to ensure that the neighboring pixels are mapped in the same way so that they so that if they are neighboring in the image, there are also neighboring on this latent image.",
            "So This is why we put the Potts model prior which.",
            "We see here over the neighborhood of each pixel.",
            "It gives a penalty for mismatches.",
            "And if we look at this, this is just the formula that tells us how an image is generated based on, say, the Pixel P of image N is generated by looking up at the image N for the mapping matrix, L, pixel P and taking this position from the jigsaw.",
            "And this modular part is just, so we assume that this invariants is also kept at the boundaries of the jigsaw, so we don't care if it's across the boundaries.",
            "Um?"
        ],
        [
            "Yeah.",
            "Inference for this model is hard, so we have to do expectation maximization, inference 'cause it's not tractable in closed form.",
            "We approximate this into alternating steps.",
            "So the first step is the mappings on which we do map inference.",
            "Keeping the jigsaw fixed, and then the next step we fix the mappings and we update the jigsaw so the latent image.",
            "So this is the first step where we where we keep."
        ],
        [
            "Is fixed and we only update the mappings and in order to update the mappings we want to obtain those the maximize the likelihood of the image being generated by this mapping and the fixed jigsaw which corresponds to minimizing energy terms made up by the minus log of the likelihood of the image and the prior on the mappings.",
            "So we balance those two terms in order to obtain both a good reconstruction from the likelihood of the image.",
            "As well as smooth mappings.",
            "This is done."
        ],
        [
            "With the fairly standard technique in computer vision, it's a discrete optimization technique and we use graph cuts.",
            "The concrete algorithm is Alpha expansion.",
            "What you do here is it boils down to labeling problem.",
            "Every Pixel wants to get a certain shift vector.",
            "And every shift vector is a label.",
            "The space of all labels is every possible position on a latent image.",
            "So if we make the latent image bigger, we have a lot of possible labels.",
            "And if we make it smaller, we don't have them and.",
            "What we do here basically is we iterate over all possible labelings.",
            "We propose labels, we draw them.",
            "And we.",
            "This graph cut labels by.",
            "Let's just do it like this."
        ],
        [
            "Creates cuts and proposed and fixes new labels for nodes where they minimize the energy state and if we do this iteratively for all possible labels in the end we get a graph that has equally labeled patches.",
            "At different positions and these boundaries, these cuts correspond to edges of our pieces, so this is how we obtain the pieces, really.",
            "And um, this is."
        ],
        [
            "The computationally challenging part of the model and the second part the density update is fairly trivial given the mappings, because it's just fitting these cautions.",
            "So assuming you already have the mappings here, you just update your Gaussian variables and the updates for the normal gamma part are just given."
        ],
        [
            "By this formula and the multivariate part is with this it's normal vision update.",
            "And.",
            "So I'm I'm going to."
        ],
        [
            "Get back to the localization part of the image to the translation invariants, because this is actually the part that makes this model really work.",
            "For this application, So what we have here, we see that the jigsaw has five different variables at each pixel position, and assuming we drew this pixel from the jigsaw to generate this pixel of an image, we know that this pixel has a mean position as given by these given by these variables.",
            "And also it can stray from it a bit in different images.",
            "So this is captured by the variance.",
            "And this puts a cost basically on having a spot here versus having it here and mapping it to the same.",
            "Part of the latent image, so this drives the latent image to generate two different spots for say, this yellow and this yellow.",
            "And as we can see, if these images, all the images were generating at the same time from this latent image where perfectly aligned this this position with just be a gradient like this in in X direction like this, why position between zero and one?",
            "But since they're not perfectly aligned, it's a little bit more complicated.",
            "I can get into that, but here we can really control how far how much translation invariants we have at every given pixel.",
            "So every piece will have a concern."
        ],
        [
            "In variance, different pieces might have different invariances.",
            "Good question, yeah."
        ],
        [
            "Are you what kind of coordinates are you using are using your scaling?",
            "All the images of the same size using coordinate systems.",
            "So first the the images all scaled to have reference frame that corresponds to the real size of the fish.",
            "Because I don't want to capture how big the images suggest, but the reference frame here I obtained via a registration step which I will talk about later.",
            "But yeah, of course I have to register them and the coordinates I assume always between zero and one and I given by the pixel coordinates.",
            "After they have been mapped to a common reference frame.",
            "So the."
        ],
        [
            "This is an example for the learning step.",
            "In the beginning the learning looks fairly bad.",
            "In the first iteration, so the jigsaw mean is all over the place.",
            "The mappings are taken from everywhere in the reconstruction looks like it's being drawn from the prior, but we see."
        ],
        [
            "But if we go iteratively, few."
        ],
        [
            "Learn a few iterations.",
            "The jigsaw starts becoming sharper and it actually looks semantic.",
            "It starts looking like a fish and the fish."
        ],
        [
            "Actually start looking like fish as well the reconstructions."
        ],
        [
            "And we see that."
        ],
        [
            "While the energy converge."
        ],
        [
            "Jizz that we really have reconstructed them quite well and these this is not just for one fish."
        ],
        [
            "This is for do."
        ],
        [
            "Two different fish.",
            "This is just an example with very simple parameters very quickly to just illustrate learning.",
            "So what's happening here is we have two fish now in this very simple jig."
        ],
        [
            "So anet reconstructs."
        ],
        [
            "In both.",
            "Just taking diff."
        ],
        [
            "Pieces out of it."
        ],
        [
            "So during the inference, of course this also challenges.",
            "It's not just as easy as in this example, because this expectation maximization runs into local minima.",
            "The graph cuts does map inference, which also doesn't help with avoiding local minima.",
            "So we avoid these with clever initialization of our channels.",
            "With the jigsaw with informative priors if we need them.",
            "And most of all, by putting some noise on our mappings, so we make sure that during each iteration we don't.",
            "We keep some variable."
        ],
        [
            "So I'm going to get to the experiments.",
            "We took guppy fish as we saw this is our favorite.",
            "Dataset right now because we work with the biologists who work with this data set and they published a paper based on finding color spots on these fish by I.",
            "So they went over this whole process manually and then later did an Association study with it and we trained a jigsaw on 99 fish from them and it's strange 157."
        ],
        [
            "And this is from this paper and the features they found.",
            "I'm not sure if you can see exactly the numbers on these errors, but these numbers are the same over different images for features that look similar.",
            "So what you can see here, for instance, that this is spot 6.",
            "This is still spot 6.",
            "This is part 6, so they identify different semantic spots which they consider the phenotype.",
            "And ideally we would like to get these back and then unsupervised fashion from our model.",
            "And now we get to the Ridge."
        ],
        [
            "Stration part, which is the first thing we had to do, so we first took the mean fish as a reference frame.",
            "Just the mean.",
            "The superposition of all fish.",
            "And then we superposed all our fish using a jigsaw with a very high smoothness."
        ],
        [
            "Prior with a very high smoothness setting, which slightly improved the main fish, but it had tremendous effects on our faces themselves."
        ],
        [
            "So the fish.",
            "This is the same jigsaw, it's just squashed a bit so I fish are being registered and their shape is being learned completely and they're all mapped onto this common reference frame at the same time.",
            "So not only have we mapped into a common coordinate system, you can show this for different fish.",
            "They're all using the same Jackson.",
            "Their shape is very."
        ],
        [
            "With the smoothness power that is close to infinite.",
            "So basically we do not allow.",
            "Single pieces to be mapped somewhere else, except we allow slight deformations except in a very very constrained fashion.",
            "And these deformations we can actually quantify in her nest to give some."
        ],
        [
            "Nothing like a shape phenotype."
        ],
        [
            "We can see that every."
        ],
        [
            "Single fish is deformed in a different way.",
            "And the result is the following.",
            "It's it's a very important step for later learning to map them all on the same coordinate frame and itself.",
            "Also visual feature and later on our pieces then that we cut out will be cut out from this common coordinate frame.",
            "So."
        ],
        [
            "This is the jigsaw we obtained by train."
        ],
        [
            "On these 99 fish and it has a multitude of pieces.",
            "And if we look at reconstructions, they look a bit course because we used low resolution images because we care about the features, not the exact texture on each.",
            "At each position, if you look at different images."
        ],
        [
            "Different fish."
        ],
        [
            "They're being reconstructed very well by using completely different features completely."
        ],
        [
            "Meaning where they are different."
        ],
        [
            "Anne."
        ],
        [
            "And.",
            "If we go to this package."
        ],
        [
            "And compared with the jigsaw, what we obtain is this mapping which corresponds to the features that they found by hand.",
            "So we were actually able to reconstruct all the features that they found completely.",
            "And we checked them throughout the images and they were semantic, so it's always the same feature that is used in a certain context that they also found."
        ],
        [
            "And um, of course this we could use.",
            "Now for a genome wide Association study, these pieces which we are also in the process of doing, and this would allow us to complete Step 2.",
            "And this different other applications we could think of here.",
            "But"
        ],
        [
            "I will try to conclude.",
            "So what we did is we proposed an unsupervised generative model of biological images which we used to completely describe the appearance space of these images that we looked at.",
            "We demonstrated the application to phenotyping and we have an associated Association study that confirms the semantic meaning of these pieces that are unique in their semantic.",
            "It's important and future work is."
        ],
        [
            "We would like to implement a hierarchy piece learning into model that we don't have just one piece.",
            "What we have hierarchies of pieces.",
            "With different meanings and we would like to integrate the genetic information that we talked about directly into the model or any kind of background information that we have for these images and the strength of our model is that it's very, very flexible.",
            "It can be used on any image and.",
            "Yeah, that's it.",
            "Thank you."
        ],
        [
            "So you mentioned that this is a model for biological, but is there any reason that you put it use this?",
            "It seems like there actually might be a lot."
        ],
        [
            "Other object categories that would have this kind of structure right where you have the overall physical structure is similar and you have different.",
            "Different types of features that are proposed roughly formed on it like it seems like there might be even much more general applications for America so well.",
            "I mean, I'm very sure there are, and there's a very much interest in the vision community to do things like this, but I think the one strengthen the one specific type of interest that this application has is that we have biological prior knowledge for the pieces that we find here, we can really put semantics not in terms of how we can identify cows and differentiated them from something else.",
            "Who we can really put generate knowledge with this in an unsupervised way.",
            "So this is our favorite application that we want to go to and.",
            "I'm sure we will find others to mention.",
            "To get these features, you gotta make sure they're kinda far apart in your latent image, right?",
            "So is there something you do to make them spread out well?",
            "They were being spread out by applying this gradient in the initialization, so they want to spread out OK, you want to become far apart from each from each other, and the bigger you choose, the latent image to be.",
            "Of course, the father they will spread out, right?",
            "Yeah, because they're being drawn apart and I can basically the size of the jigsaw is an implicit regularization, so if you choose it really small label.",
            "More general, but they bring thrown apart by this prior on location.",
            "Face recognition all this Department.",
            "Algorithms like a train that you can just run a feature for wheat by later said training.",
            "Distinguished to us some background images.",
            "Trees are in the school now.",
            "Fire general concept.",
            "Discriminant process rating.",
            "OK, if we have supervised information given that we know what we're looking for, discriminative methods will work really well, obviously, and I think we could do that, but the generative process allows us to really quantify shape and appearance more accurately, at least because this is exactly what we want to get out.",
            "We want to get out the features we don't know yet.",
            "I'll priority.",
            "Just had images of fish and non fish.",
            "OK Trader descriptive model and not actually select features.",
            "Oh yeah sure.",
            "Kernels.",
            "Happy.",
            "So yeah, but I'm sure we could use this month to discriminate different object categories, especially since you have the smoothness prior completed, different coarseness into it.",
            "And if you put it quite course will learn the pieces.",
            "And if you put it smaller just learning small patches so that you can use to discriminate object classes.",
            "Similar techniques are already being used.",
            "I don't know if this answers your question.",
            "All those small patches that these tumors is different.",
            "Maybe not representing the clouds could be learned.",
            "Well, the mappings contain this information, right?",
            "Because every every mapping matrix uses a specific set of features instead of others.",
            "If you cluster them, of course you can get those the cluster to a specific cluster with the class or the other.",
            "The point is, like you're trying to identify certain features, right?",
            "Yeah, I mean, that's what you're interested in exactly.",
            "Especially that by using a discriminative method it might be able to identify the same features.",
            "Worthwhile trying if you have something better fishing on page you could just try to create a class religious discrimination.",
            "Since.",
            "You need to know the process first right here, so if you have one class and you just want to find some of each fish is a different class of like, well, yeah, so just because you did this.",
            "10 minutes and thank all the speakers that station again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, um I'm going to talk about Chino.",
                    "label": 0
                },
                {
                    "sent": "And this is joint work with Oliver John Wynn from Microsoft Research and custom booklet.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we're dealing with in this work in this project are images and natural variation images.",
                    "label": 1
                },
                {
                    "sent": "So what we want to assess is how do images of natural objects vary.",
                    "label": 1
                },
                {
                    "sent": "So for instance, if you look here you see a bunch of tomatoes that look wildly different, and the human eye can see this very easily and can assess things, but it's quite difficult to quantify, and we know that natural variation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Has genetical and environmental factors and we could we could use this dependence on them later on?",
                    "label": 0
                },
                {
                    "sent": "So let's go to a specific example of natural variation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's look at these copies.",
                    "label": 0
                },
                {
                    "sent": "They're called in Latin Pacilio reticulata, which is not important, but you see a lot of variation going on here, which.",
                    "label": 0
                },
                {
                    "sent": "Is difficult to assess exactly, so if.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You look at them.",
                    "label": 0
                },
                {
                    "sent": "One thing you could say about the variation is very sensible thing or they are about this long and they're about this high and one might want to look at their color histograms to assess the color distributions of each to do to extract various appearance traits.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the appearance traits were more interested in our appearance traits.",
                    "label": 0
                },
                {
                    "sent": "Like for instance, these spots, more detailed phenotypes that we could extract from images to describe their variability.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll just briefly explain the underlying assumption that we have for a model.",
                    "label": 0
                },
                {
                    "sent": "We believe that image variation is explained by latent variables that represent patches.",
                    "label": 1
                },
                {
                    "sent": "So, for instance, assume we have a set of latent variables.",
                    "label": 0
                },
                {
                    "sent": "Here, each latent variable is one of those mark patches I showed earlier, and we believe that.",
                    "label": 0
                },
                {
                    "sent": "Based on these latent variables, images are generated.",
                    "label": 0
                },
                {
                    "sent": "Taking these patches and putting them together and assume that there is a set of snips snips are single nucleotide polymorphism's.",
                    "label": 0
                },
                {
                    "sent": "They're just the polymorphic markers in that are different than individuals.",
                    "label": 0
                },
                {
                    "sent": "And we can assume that these.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regulate the expression of these patches.",
                    "label": 0
                },
                {
                    "sent": "And in order to create these latent variables to design.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there is a couple of choices.",
                    "label": 0
                },
                {
                    "sent": "We want them first and foremost, to be interpretable, so we want we want the phenotype that you can look at and you can interpret it rather than some abstract number an we want these patches of course to exhibit some translational invariances in order to not have to be at a specific spot.",
                    "label": 0
                },
                {
                    "sent": "So we want them to be general in a way.",
                    "label": 0
                },
                {
                    "sent": "And we want them to be robust in shape and appearance.",
                    "label": 1
                },
                {
                    "sent": "So we want to really be able to quantify most anything that we can see in an image.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the jiffy.",
                    "label": 0
                },
                {
                    "sent": "Invariants, sort of.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look like that's actually true, and so it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have to be complete translational invariant, but it could be in part because, for instance, it could be that interesting feature is saying these fish is on the head on the general space of the head, so it can't be.",
                    "label": 0
                },
                {
                    "sent": "It mustn't be exactly on the same spot, because sometimes even the head may be shaped differently, but you want it to be generally there instead of saying at the at the back piece of the Organism so.",
                    "label": 0
                },
                {
                    "sent": "We want some translation invariants and robustness towards it, but we don't want to have everything the same.",
                    "label": 0
                },
                {
                    "sent": "I'm going to come back to this point.",
                    "label": 0
                },
                {
                    "sent": "So our basic model is.",
                    "label": 0
                },
                {
                    "sent": "Jack FINA here.",
                    "label": 0
                },
                {
                    "sent": "We assume a latent image J, which we will call a jigsaw and this jigsaw is something like the blueprint that contains all these features that we're looking at.",
                    "label": 1
                },
                {
                    "sent": "It contains all these pieces and we believe that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a latent variable which of the mappings which are describing how we have to cut out these pieces in order to generate these images, and we believe as well that there's there's this idea that these mappings have genetic causes that it's not a random process that generates these images, but there's some genetics behind this.",
                    "label": 0
                },
                {
                    "sent": "And we solve this approach in 2 steps.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the first step is what I'm mostly going to talk about.",
                    "label": 0
                },
                {
                    "sent": "And the first step is building up on work by John Wynn from the NIPS community in 2006.",
                    "label": 0
                },
                {
                    "sent": "So the first step is we generate images based on this latent image and these mappings, and if we have two, for instance these are.",
                    "label": 1
                },
                {
                    "sent": "This is a real jigsaw.",
                    "label": 0
                },
                {
                    "sent": "These are real fish that I generated.",
                    "label": 0
                },
                {
                    "sent": "With this.",
                    "label": 0
                },
                {
                    "sent": "We can take these pieces and generate images and here we can see the mappings so we can see that these pieces are the same and they're nice and semantic and everything goes where it's supposed to go is the first step and then if we had many of these images.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Say we observe many images and we look at them and each one of them has some genetic information.",
                    "label": 0
                },
                {
                    "sent": "We can automatically associate the mappings with this genetic background via, say, standard Genome Wide Association study.",
                    "label": 0
                },
                {
                    "sent": "And this is a possible application of this so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to go into the detail of the jigsaw model here and Jigsaw model is generated unsupervised model.",
                    "label": 0
                },
                {
                    "sent": "The unsupervised part is actually important.",
                    "label": 0
                },
                {
                    "sent": "And what we have is this latent image J for each pixel J.",
                    "label": 0
                },
                {
                    "sent": "So the small J.",
                    "label": 0
                },
                {
                    "sent": "So just all the pixels in this latent image and each pixel of the latent image has five distinct variables which are RGB for the color channels, and X&Y for the positional positional information.",
                    "label": 0
                },
                {
                    "sent": "So these are Gaussian variables and then we believe that we generate a set of N images.",
                    "label": 0
                },
                {
                    "sent": "And each image has a certain mapping ally with a prior on it.",
                    "label": 0
                },
                {
                    "sent": "And each image is generated as something that has colors.",
                    "label": 0
                },
                {
                    "sent": "So each image, each pixel in an image has these color channels as well as positional information.",
                    "label": 0
                },
                {
                    "sent": "And this is the general model.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to write down, and I'm going to go over these terms in detail now.",
                    "label": 0
                },
                {
                    "sent": "So the terms that I'm going to go over is first of all the basic model.",
                    "label": 0
                },
                {
                    "sent": "The jigsaw model in the prior then the smoothness prior on the likelihood of the generated image given these things.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the jigsaw model is basically fairly simple to explain.",
                    "label": 1
                },
                {
                    "sent": "We have prior on the sticks are which is a mixture.",
                    "label": 0
                },
                {
                    "sent": "We factorize it into the positional part and the appearance part the positional part.",
                    "label": 1
                },
                {
                    "sent": "We model as just prior of normal gamma distribution because we want it to be isotropic.",
                    "label": 0
                },
                {
                    "sent": "Two independent normal gammas and the appearance part we, which is where we couple the color channels and we describe it with a multivariate Gaussian and the likelihood of generating an image based on the mapping and the jigsaw is just a multivariate Gaussian.",
                    "label": 1
                },
                {
                    "sent": "Van",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The like the.",
                    "label": 0
                },
                {
                    "sent": "Smoothness Prior is a little bit more tricky.",
                    "label": 0
                },
                {
                    "sent": "Because here we assume a Markov random field.",
                    "label": 0
                },
                {
                    "sent": "To obtain smoothness on these mappings.",
                    "label": 0
                },
                {
                    "sent": "So the Markov random field, make sure that we obtain these pieces.",
                    "label": 0
                },
                {
                    "sent": "How does it work precisely?",
                    "label": 0
                },
                {
                    "sent": "For an images we have for every image mapping matrix of the same size as the image and each node here corresponds to a pixel is a 2 dimensional shift vector and each shift vector tells us how we have to displace a pixel to obtain its mapping to this latent image, where we draw the color from.",
                    "label": 0
                },
                {
                    "sent": "So in order to get smoothness to get pieces that are consistent patches, we have to ensure that the neighboring pixels are mapped in the same way so that they so that if they are neighboring in the image, there are also neighboring on this latent image.",
                    "label": 0
                },
                {
                    "sent": "So This is why we put the Potts model prior which.",
                    "label": 0
                },
                {
                    "sent": "We see here over the neighborhood of each pixel.",
                    "label": 0
                },
                {
                    "sent": "It gives a penalty for mismatches.",
                    "label": 0
                },
                {
                    "sent": "And if we look at this, this is just the formula that tells us how an image is generated based on, say, the Pixel P of image N is generated by looking up at the image N for the mapping matrix, L, pixel P and taking this position from the jigsaw.",
                    "label": 0
                },
                {
                    "sent": "And this modular part is just, so we assume that this invariants is also kept at the boundaries of the jigsaw, so we don't care if it's across the boundaries.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Inference for this model is hard, so we have to do expectation maximization, inference 'cause it's not tractable in closed form.",
                    "label": 1
                },
                {
                    "sent": "We approximate this into alternating steps.",
                    "label": 0
                },
                {
                    "sent": "So the first step is the mappings on which we do map inference.",
                    "label": 1
                },
                {
                    "sent": "Keeping the jigsaw fixed, and then the next step we fix the mappings and we update the jigsaw so the latent image.",
                    "label": 0
                },
                {
                    "sent": "So this is the first step where we where we keep.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is fixed and we only update the mappings and in order to update the mappings we want to obtain those the maximize the likelihood of the image being generated by this mapping and the fixed jigsaw which corresponds to minimizing energy terms made up by the minus log of the likelihood of the image and the prior on the mappings.",
                    "label": 0
                },
                {
                    "sent": "So we balance those two terms in order to obtain both a good reconstruction from the likelihood of the image.",
                    "label": 0
                },
                {
                    "sent": "As well as smooth mappings.",
                    "label": 0
                },
                {
                    "sent": "This is done.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the fairly standard technique in computer vision, it's a discrete optimization technique and we use graph cuts.",
                    "label": 0
                },
                {
                    "sent": "The concrete algorithm is Alpha expansion.",
                    "label": 0
                },
                {
                    "sent": "What you do here is it boils down to labeling problem.",
                    "label": 0
                },
                {
                    "sent": "Every Pixel wants to get a certain shift vector.",
                    "label": 0
                },
                {
                    "sent": "And every shift vector is a label.",
                    "label": 0
                },
                {
                    "sent": "The space of all labels is every possible position on a latent image.",
                    "label": 0
                },
                {
                    "sent": "So if we make the latent image bigger, we have a lot of possible labels.",
                    "label": 0
                },
                {
                    "sent": "And if we make it smaller, we don't have them and.",
                    "label": 0
                },
                {
                    "sent": "What we do here basically is we iterate over all possible labelings.",
                    "label": 0
                },
                {
                    "sent": "We propose labels, we draw them.",
                    "label": 0
                },
                {
                    "sent": "And we.",
                    "label": 0
                },
                {
                    "sent": "This graph cut labels by.",
                    "label": 0
                },
                {
                    "sent": "Let's just do it like this.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Creates cuts and proposed and fixes new labels for nodes where they minimize the energy state and if we do this iteratively for all possible labels in the end we get a graph that has equally labeled patches.",
                    "label": 0
                },
                {
                    "sent": "At different positions and these boundaries, these cuts correspond to edges of our pieces, so this is how we obtain the pieces, really.",
                    "label": 0
                },
                {
                    "sent": "And um, this is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The computationally challenging part of the model and the second part the density update is fairly trivial given the mappings, because it's just fitting these cautions.",
                    "label": 0
                },
                {
                    "sent": "So assuming you already have the mappings here, you just update your Gaussian variables and the updates for the normal gamma part are just given.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By this formula and the multivariate part is with this it's normal vision update.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So I'm I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get back to the localization part of the image to the translation invariants, because this is actually the part that makes this model really work.",
                    "label": 0
                },
                {
                    "sent": "For this application, So what we have here, we see that the jigsaw has five different variables at each pixel position, and assuming we drew this pixel from the jigsaw to generate this pixel of an image, we know that this pixel has a mean position as given by these given by these variables.",
                    "label": 1
                },
                {
                    "sent": "And also it can stray from it a bit in different images.",
                    "label": 0
                },
                {
                    "sent": "So this is captured by the variance.",
                    "label": 0
                },
                {
                    "sent": "And this puts a cost basically on having a spot here versus having it here and mapping it to the same.",
                    "label": 0
                },
                {
                    "sent": "Part of the latent image, so this drives the latent image to generate two different spots for say, this yellow and this yellow.",
                    "label": 0
                },
                {
                    "sent": "And as we can see, if these images, all the images were generating at the same time from this latent image where perfectly aligned this this position with just be a gradient like this in in X direction like this, why position between zero and one?",
                    "label": 0
                },
                {
                    "sent": "But since they're not perfectly aligned, it's a little bit more complicated.",
                    "label": 1
                },
                {
                    "sent": "I can get into that, but here we can really control how far how much translation invariants we have at every given pixel.",
                    "label": 0
                },
                {
                    "sent": "So every piece will have a concern.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In variance, different pieces might have different invariances.",
                    "label": 0
                },
                {
                    "sent": "Good question, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are you what kind of coordinates are you using are using your scaling?",
                    "label": 0
                },
                {
                    "sent": "All the images of the same size using coordinate systems.",
                    "label": 0
                },
                {
                    "sent": "So first the the images all scaled to have reference frame that corresponds to the real size of the fish.",
                    "label": 0
                },
                {
                    "sent": "Because I don't want to capture how big the images suggest, but the reference frame here I obtained via a registration step which I will talk about later.",
                    "label": 0
                },
                {
                    "sent": "But yeah, of course I have to register them and the coordinates I assume always between zero and one and I given by the pixel coordinates.",
                    "label": 0
                },
                {
                    "sent": "After they have been mapped to a common reference frame.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an example for the learning step.",
                    "label": 0
                },
                {
                    "sent": "In the beginning the learning looks fairly bad.",
                    "label": 0
                },
                {
                    "sent": "In the first iteration, so the jigsaw mean is all over the place.",
                    "label": 0
                },
                {
                    "sent": "The mappings are taken from everywhere in the reconstruction looks like it's being drawn from the prior, but we see.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if we go iteratively, few.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learn a few iterations.",
                    "label": 0
                },
                {
                    "sent": "The jigsaw starts becoming sharper and it actually looks semantic.",
                    "label": 0
                },
                {
                    "sent": "It starts looking like a fish and the fish.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually start looking like fish as well the reconstructions.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we see that.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "While the energy converge.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jizz that we really have reconstructed them quite well and these this is not just for one fish.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is for do.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two different fish.",
                    "label": 0
                },
                {
                    "sent": "This is just an example with very simple parameters very quickly to just illustrate learning.",
                    "label": 0
                },
                {
                    "sent": "So what's happening here is we have two fish now in this very simple jig.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So anet reconstructs.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In both.",
                    "label": 0
                },
                {
                    "sent": "Just taking diff.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pieces out of it.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So during the inference, of course this also challenges.",
                    "label": 0
                },
                {
                    "sent": "It's not just as easy as in this example, because this expectation maximization runs into local minima.",
                    "label": 0
                },
                {
                    "sent": "The graph cuts does map inference, which also doesn't help with avoiding local minima.",
                    "label": 0
                },
                {
                    "sent": "So we avoid these with clever initialization of our channels.",
                    "label": 0
                },
                {
                    "sent": "With the jigsaw with informative priors if we need them.",
                    "label": 0
                },
                {
                    "sent": "And most of all, by putting some noise on our mappings, so we make sure that during each iteration we don't.",
                    "label": 0
                },
                {
                    "sent": "We keep some variable.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to get to the experiments.",
                    "label": 0
                },
                {
                    "sent": "We took guppy fish as we saw this is our favorite.",
                    "label": 0
                },
                {
                    "sent": "Dataset right now because we work with the biologists who work with this data set and they published a paper based on finding color spots on these fish by I.",
                    "label": 0
                },
                {
                    "sent": "So they went over this whole process manually and then later did an Association study with it and we trained a jigsaw on 99 fish from them and it's strange 157.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is from this paper and the features they found.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if you can see exactly the numbers on these errors, but these numbers are the same over different images for features that look similar.",
                    "label": 0
                },
                {
                    "sent": "So what you can see here, for instance, that this is spot 6.",
                    "label": 0
                },
                {
                    "sent": "This is still spot 6.",
                    "label": 0
                },
                {
                    "sent": "This is part 6, so they identify different semantic spots which they consider the phenotype.",
                    "label": 0
                },
                {
                    "sent": "And ideally we would like to get these back and then unsupervised fashion from our model.",
                    "label": 0
                },
                {
                    "sent": "And now we get to the Ridge.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stration part, which is the first thing we had to do, so we first took the mean fish as a reference frame.",
                    "label": 0
                },
                {
                    "sent": "Just the mean.",
                    "label": 0
                },
                {
                    "sent": "The superposition of all fish.",
                    "label": 0
                },
                {
                    "sent": "And then we superposed all our fish using a jigsaw with a very high smoothness.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior with a very high smoothness setting, which slightly improved the main fish, but it had tremendous effects on our faces themselves.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the fish.",
                    "label": 0
                },
                {
                    "sent": "This is the same jigsaw, it's just squashed a bit so I fish are being registered and their shape is being learned completely and they're all mapped onto this common reference frame at the same time.",
                    "label": 0
                },
                {
                    "sent": "So not only have we mapped into a common coordinate system, you can show this for different fish.",
                    "label": 1
                },
                {
                    "sent": "They're all using the same Jackson.",
                    "label": 0
                },
                {
                    "sent": "Their shape is very.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the smoothness power that is close to infinite.",
                    "label": 0
                },
                {
                    "sent": "So basically we do not allow.",
                    "label": 0
                },
                {
                    "sent": "Single pieces to be mapped somewhere else, except we allow slight deformations except in a very very constrained fashion.",
                    "label": 0
                },
                {
                    "sent": "And these deformations we can actually quantify in her nest to give some.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nothing like a shape phenotype.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can see that every.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single fish is deformed in a different way.",
                    "label": 0
                },
                {
                    "sent": "And the result is the following.",
                    "label": 0
                },
                {
                    "sent": "It's it's a very important step for later learning to map them all on the same coordinate frame and itself.",
                    "label": 0
                },
                {
                    "sent": "Also visual feature and later on our pieces then that we cut out will be cut out from this common coordinate frame.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the jigsaw we obtained by train.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On these 99 fish and it has a multitude of pieces.",
                    "label": 0
                },
                {
                    "sent": "And if we look at reconstructions, they look a bit course because we used low resolution images because we care about the features, not the exact texture on each.",
                    "label": 0
                },
                {
                    "sent": "At each position, if you look at different images.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different fish.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They're being reconstructed very well by using completely different features completely.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Meaning where they are different.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If we go to this package.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And compared with the jigsaw, what we obtain is this mapping which corresponds to the features that they found by hand.",
                    "label": 0
                },
                {
                    "sent": "So we were actually able to reconstruct all the features that they found completely.",
                    "label": 0
                },
                {
                    "sent": "And we checked them throughout the images and they were semantic, so it's always the same feature that is used in a certain context that they also found.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And um, of course this we could use.",
                    "label": 0
                },
                {
                    "sent": "Now for a genome wide Association study, these pieces which we are also in the process of doing, and this would allow us to complete Step 2.",
                    "label": 0
                },
                {
                    "sent": "And this different other applications we could think of here.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will try to conclude.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we proposed an unsupervised generative model of biological images which we used to completely describe the appearance space of these images that we looked at.",
                    "label": 0
                },
                {
                    "sent": "We demonstrated the application to phenotyping and we have an associated Association study that confirms the semantic meaning of these pieces that are unique in their semantic.",
                    "label": 0
                },
                {
                    "sent": "It's important and future work is.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We would like to implement a hierarchy piece learning into model that we don't have just one piece.",
                    "label": 0
                },
                {
                    "sent": "What we have hierarchies of pieces.",
                    "label": 0
                },
                {
                    "sent": "With different meanings and we would like to integrate the genetic information that we talked about directly into the model or any kind of background information that we have for these images and the strength of our model is that it's very, very flexible.",
                    "label": 0
                },
                {
                    "sent": "It can be used on any image and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you mentioned that this is a model for biological, but is there any reason that you put it use this?",
                    "label": 0
                },
                {
                    "sent": "It seems like there actually might be a lot.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other object categories that would have this kind of structure right where you have the overall physical structure is similar and you have different.",
                    "label": 0
                },
                {
                    "sent": "Different types of features that are proposed roughly formed on it like it seems like there might be even much more general applications for America so well.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm very sure there are, and there's a very much interest in the vision community to do things like this, but I think the one strengthen the one specific type of interest that this application has is that we have biological prior knowledge for the pieces that we find here, we can really put semantics not in terms of how we can identify cows and differentiated them from something else.",
                    "label": 0
                },
                {
                    "sent": "Who we can really put generate knowledge with this in an unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "So this is our favorite application that we want to go to and.",
                    "label": 0
                },
                {
                    "sent": "I'm sure we will find others to mention.",
                    "label": 0
                },
                {
                    "sent": "To get these features, you gotta make sure they're kinda far apart in your latent image, right?",
                    "label": 0
                },
                {
                    "sent": "So is there something you do to make them spread out well?",
                    "label": 0
                },
                {
                    "sent": "They were being spread out by applying this gradient in the initialization, so they want to spread out OK, you want to become far apart from each from each other, and the bigger you choose, the latent image to be.",
                    "label": 0
                },
                {
                    "sent": "Of course, the father they will spread out, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, because they're being drawn apart and I can basically the size of the jigsaw is an implicit regularization, so if you choose it really small label.",
                    "label": 0
                },
                {
                    "sent": "More general, but they bring thrown apart by this prior on location.",
                    "label": 0
                },
                {
                    "sent": "Face recognition all this Department.",
                    "label": 0
                },
                {
                    "sent": "Algorithms like a train that you can just run a feature for wheat by later said training.",
                    "label": 0
                },
                {
                    "sent": "Distinguished to us some background images.",
                    "label": 0
                },
                {
                    "sent": "Trees are in the school now.",
                    "label": 0
                },
                {
                    "sent": "Fire general concept.",
                    "label": 0
                },
                {
                    "sent": "Discriminant process rating.",
                    "label": 0
                },
                {
                    "sent": "OK, if we have supervised information given that we know what we're looking for, discriminative methods will work really well, obviously, and I think we could do that, but the generative process allows us to really quantify shape and appearance more accurately, at least because this is exactly what we want to get out.",
                    "label": 0
                },
                {
                    "sent": "We want to get out the features we don't know yet.",
                    "label": 0
                },
                {
                    "sent": "I'll priority.",
                    "label": 0
                },
                {
                    "sent": "Just had images of fish and non fish.",
                    "label": 0
                },
                {
                    "sent": "OK Trader descriptive model and not actually select features.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah sure.",
                    "label": 0
                },
                {
                    "sent": "Kernels.",
                    "label": 0
                },
                {
                    "sent": "Happy.",
                    "label": 0
                },
                {
                    "sent": "So yeah, but I'm sure we could use this month to discriminate different object categories, especially since you have the smoothness prior completed, different coarseness into it.",
                    "label": 0
                },
                {
                    "sent": "And if you put it quite course will learn the pieces.",
                    "label": 0
                },
                {
                    "sent": "And if you put it smaller just learning small patches so that you can use to discriminate object classes.",
                    "label": 0
                },
                {
                    "sent": "Similar techniques are already being used.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this answers your question.",
                    "label": 0
                },
                {
                    "sent": "All those small patches that these tumors is different.",
                    "label": 0
                },
                {
                    "sent": "Maybe not representing the clouds could be learned.",
                    "label": 0
                },
                {
                    "sent": "Well, the mappings contain this information, right?",
                    "label": 0
                },
                {
                    "sent": "Because every every mapping matrix uses a specific set of features instead of others.",
                    "label": 0
                },
                {
                    "sent": "If you cluster them, of course you can get those the cluster to a specific cluster with the class or the other.",
                    "label": 0
                },
                {
                    "sent": "The point is, like you're trying to identify certain features, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, that's what you're interested in exactly.",
                    "label": 0
                },
                {
                    "sent": "Especially that by using a discriminative method it might be able to identify the same features.",
                    "label": 0
                },
                {
                    "sent": "Worthwhile trying if you have something better fishing on page you could just try to create a class religious discrimination.",
                    "label": 0
                },
                {
                    "sent": "Since.",
                    "label": 0
                },
                {
                    "sent": "You need to know the process first right here, so if you have one class and you just want to find some of each fish is a different class of like, well, yeah, so just because you did this.",
                    "label": 0
                },
                {
                    "sent": "10 minutes and thank all the speakers that station again.",
                    "label": 0
                }
            ]
        }
    }
}