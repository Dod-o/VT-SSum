{
    "id": "khd6d27y4w67wubgvaj3z6ce62scpwv4",
    "title": "Robots learning from human teachers",
    "info": {
        "author": [
            "Andrea Thomaz, College of Computing, Georgia Institute of Technology"
        ],
        "published": "July 28, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Economics",
            "Top->Social Sciences->Psychology",
            "Top->Medicine->Neuroscience",
            "Top->Technology->Engineering->Electrical Engineering->Control Engineering"
        ]
    },
    "url": "http://videolectures.net/rldm2015_thomaz_human_teachers/",
    "segmentation": [
        [
            "Any robot?"
        ],
        [
            "Whose functional goal has to do with interacting with people in an environment that was designed for humans.",
            "So if you're going to put your robot into one of these environments so you have to think about those social implications and how it's going to get its job done so."
        ],
        [
            "IOS is hard, so a lot of the successes to date of robots have relied on structured environments and tasks that can be repeated and programmed once and as soon as we start to think about human environments like office buildings or homes or hospitals, then we have humans and humans are dynamic and humans are not structured and so we have to start thinking about how we're going to get robots to be able to function in these dynamic environments.",
            "So one of the things that we."
        ],
        [
            "Been thinking about our goal is to have robots that can function in new or changing environments by interacting with end users in order to learn what to do.",
            "And so that's what I'm gonna talk about today.",
            "So to motivate that just a little bit, here's some pictures of kind of motivating examples of what we might think of and to dig into just a couple of."
        ],
        [
            "One that's really popular right now is manufacturing, and there's a big push towards more flexible manufacturing where you want to have robots that can be retasked on the fly.",
            "Too big to do something new today or this week or this month as opposed to currently a lot of robots that have been successful in manufacturing have to be programmed once and deployed for really long time in order to be cost effective.",
            "So then it's only things like cars and airplanes that you see that being really used.",
            "So if you had a robot that was easy, easily trainable on the on the factory floor by a co-worker, then this would be an interesting."
        ],
        [
            "Application one that we can all think about is having a service robot in your home.",
            "You want the robot to clean your kitchen?",
            "I know everybody would like to not clean their kitchen again and so the problem there is that the task is going to be slightly different in every home.",
            "We kind of could define it at a high level, but the details are going to have to be filled in by the end user.",
            "So an only the end user can actually specify that correctly, not me.",
            "The robot designers sitting in a lab.",
            "So what we need here?"
        ],
        [
            "Is interactive machine learning, and so that's what I'm going to tell you about today.",
            "What we need to consider in addresses, the problem of how a robot can take this general problem of being able to build a policy or a model of a task in a given environment, which we can define really broadly, is just, you know.",
            "The robot needs to know what to do in a given state.",
            "And so this is very similar to a lot of the problem formulations that we've been talking about, and what I want to talk about is how we can structure the problem of end user providing the input to this kind of modeling problem.",
            "So there's been quite a bit of related work in the field or in the literature about adding human input to machine learning algorithms, and the interesting 1 interesting way to think about it is the kind of input that the person is providing, so there's kind of been two big focuses in the type of input that you ask people to provide a machine learning algorithm.",
            "So on the one hand, you can ask a person to provide demonstrations where in a given state the person is showing.",
            "Exactly what action to be providing, so the input that the person is giving is examples of actions.",
            "On the other hand, we can think about the person providing what you can call critique, where it's watching, the learning behavior, and providing labels as to whether or not a particular action was good or bad.",
            "So what my life has been doing is thinking about."
        ],
        [
            "These things, these interactions with machine learning algorithms holistically and saying hey, if you bring in people off the street and have them interact across a variety of different ways with machine learning algorithms, what is that like in the the punch line that we've come back too many times?",
            "Is that algorithms need to use the information that people are good at providing?",
            "And so today I want to give you a couple of couple of examples across."
        ],
        [
            "Of these, each of these kinds of human input about what I mean by using the information that people are good at providing.",
            "So I'll start off with talking a little bit about critique and then and then go into."
        ],
        [
            "Two demonstrations.",
            "So, assuming that people have just a high level feedback signal, what should the agent do with that?",
            "So this is."
        ],
        [
            "Related to everything we've been talking about here so far, we have this.",
            "We have reinforcement learning problem here and now.",
            "The question we're asking is is how we can."
        ],
        [
            "Best incorporate a human into this feedback loop.",
            "And so the talk that we just heard nicely fits nicely set up for the problem that we're going to.",
            "We're going to talk about here.",
            "So one of."
        ],
        [
            "First things you might think of doing is reward shaping, where the human is going to.",
            "We're going to take the humans critique, rewards and justice.",
            "Roll those into the feedback signal that you're getting from the environment, and so one of the first experiments that I did in this domain looked at putting this in front of people.",
            "We had hundreds of people interact with this sophies kitchen game and asked, you know whether or not this is something people can actually do.",
            "An it turns out."
        ],
        [
            "The people aren't very accurate at reward shaping and they anticipate what people with the agent might do and give rewards about things the agent never did and and such things.",
            "But you can change the interface in the algorithm to kind of get them to do the right thing a little bit more so if you give them a guidance.",
            "Channel they will actually make their feedback channel more informative and things like that, so we could actually get the learning performance of the of the agent with this reward shaping from hundreds of users on the Internet to work pretty well but but despite the."
        ],
        [
            "Fact that we were able to massage the input channel to work in this kind of rewards or shaping context, we sort of came to a similar conclusion as the previous talk that there's something that just wasn't quite right about the way we're thinking about about this whole way, or the reward shaping was working, but we came to an alternative conclusion that.",
            "Maybe instead of, instead of converting peoples Rewards in peoples feedback into a reward signal signal or a number at all, we should just take it at face value as a critique on the policy.",
            "So instead of saying so when people say that's right here, that's wrong.",
            "They're not saying No 5 or minus .2.",
            "They're actually just saying that was right and that was wrong, and so we can think of this as policy shaping instead of reward shaping.",
            "So I'll quickly talk about this as this is.",
            "Older work, that's all."
        ],
        [
            "Maybe been presented, but we have a approach called advise where we're thinking about separately modeling peoples feedback policy and the agents learned policy and then we can try to combine those.",
            "So for a given state that the agent is in, it takes an action and the human can say that was correct or incorrect now and we can assume that the human might have some noise in that feedback channel, they might be delayed.",
            "They might just hit the wrong button or any number of reasons the person might have a noisy signal, but we're going to model that with some probability C, so we have the probability that the human is correct, but I can estimate for a state action pair, the probability that the human believes that this was the correct action.",
            "If I take the number of times that I got a label saying that this was correct, an times 1 minus the the number of times that I was told that some other action.",
            "Was correct, so now I have the probability that the person believes that this is the correct action, so this is their feedback."
        ],
        [
            "Policy and not for the agents policy I can use.",
            "I can use an approach of a Bayesian reinforcement learning approach, right?",
            "Also get a distribution over the agents belief and what the correct Q value is.",
            "So now I have these two."
        ],
        [
            "Sources of information about the policy and we can.",
            "We can basically have the agent take the take the action that's going to give the that's going to optimize both of these at once so.",
            "Basically it ends up being a tradeoff between using the agent when you have feedback from the person, you'll take good advantage of it in the beginning, and when you don't have any.",
            "When the person hasn't said anything yet, then you're going to rely on your own information so."
        ],
        [
            "Please, some experiments that we've done here.",
            "We're in the arcade games of PAC Man and Frogger, where we were playing around with the different parameters, like the likelihood that you actually get feedback in any particular time step, and the correctness of that feedback.",
            "So we used an Oracle to test these to test these parameters, and we compare it against some of the state of the art."
        ],
        [
            "Algorithms that come closest to doing policy shaping but still actually take that number and put it into the reward signal.",
            "If you're familiar with these."
        ],
        [
            "So just quickly we did experiments in four different with four different cell it settings of likelihood and correctness.",
            "And takeaway is that our approach always a performs kind of at or above the baseline and never does worse than them."
        ],
        [
            "Baseline and here's just a pull out.",
            "A couple of examples on the left were showing the ideal feedback, so you got feedback all the time and it's always correct and what we see here is that our approach is able to take advantage of that correct feedback early on in the process, and so the green line is our advise algorithm, and so we do better early on.",
            "And if you take a more worse scenario where you have less likely feedback and it's maybe only 80% correct, then we see that we don't.",
            "We don't get that big advantage of taking of taking the lead in the beginning, but we also don't do any worse."
        ],
        [
            "So our approach is robust to this.",
            "This one parameter that we have so with critique interactions we have shown that reward shaping at least needs modification in order to in order to be effective.",
            "And maybe a better idea is to think of it as policy shaping, where instead of thinking of actually so we don't convert people's feedback to a number at all, we actually just think of it as advice on the policy.",
            "So."
        ],
        [
            "So now I want to take a look at the other interaction scenario and this is the one that my lab has been working on for a lot of different years and for a minute it's not going to feel like reinforcement.",
            "It hasn't been as related to reinforcement learning, but just recently it's coming back to being reinforcement learning relevant, so we'll take a slight departure from reinforcement learning and then get back to it.",
            "So two things that I want to emphasize about learning from human.",
            "The demonstrations side of learning from humans.",
            "One is that we want to think about how we can quickly and efficiently get demonstrations from people, because we don't want to waste peoples time, they don't have a lot of time and the thing that we've been focused on lately is really asking what should we really be getting from these demonstrations, and so those are the two questions I want to answer today."
        ],
        [
            "OK, so let's talk about how to get good demos so."
        ],
        [
            "The field of learning from demonstration is 30 year old field that's aimed at allowing people to demonstrate tasks rather than program controllers on robots, so are usually talking about motor skills and a lot of the we have upper torso humanoid robots, so we're talking about learning manipulation motor skills.",
            "For the most part."
        ],
        [
            "And the typical input for this kind of skill learning is give a full trajectory demonstration of the skill where the state space is either if we're talking about a manipulation task, the state space is either the full kinematic chain of the arm or the end effector only, or the end effector with respect to some element in the task environment.",
            "So you are usually using the state space.",
            "That is, the end effectors 7 degree of freedom pose with respect to some target.",
            "Object in the environment, but the traditional thing you would do is record all of that state from the from the beginning of the end of the."
        ],
        [
            "Stration so it would look like this.",
            "This is our robot, Simon.",
            "And the person is trying to demonstrate to Simon how to close the lid of this box.",
            "And this is after they've done a practice session and we have a whole thing that they go through.",
            "But since this is a new task, they haven't taught the robot before.",
            "They're having a little trouble figuring out the kinematics of the seven degree of freedom arm.",
            "And it looks kind of silly, but it's actually a lot of people have difficulty.",
            "So even if you've had experience even working with this robot when you're teaching it something new, you might often have trouble deciding exactly how you want to show it.",
            "And the real problem is that all of that information got recorded as part of the demonstration, so that's annoying.",
            "If you are, try."
        ],
        [
            "And to learn a model of that of that skill.",
            "So an alternative to this is to let people provide keyframes and which is a sparse trajectory that when you a sparse sequence of these poses so it's a sparse trajectory in the same state space that when they when you string them together it completes the skill."
        ],
        [
            "So here's somebody doing the same task with keyframes.",
            "Alright.",
            "So he's having similar difficulties with the kinematics of the robot and figuring out what to do.",
            "I mean 7 degrees of freedom is a lot to control all at once, and if you're doing.",
            "But the great thing is, is that not all of that wasn't recorded, we just got the poses that were."
        ],
        [
            "And and that was in that, and that's nice.",
            "So we did an experiment with 34 people, had them teach the robot a variety of different skills.",
            "Some had to do with objects, some didn't, and we have them teach with keyframes an trajectories, and it turns out that people."
        ],
        [
            "Are positive towards both types of interaction.",
            "They were perfectly happy to give us terrable trajectory demonstrations, but it was hard to give a noise free trajectory demo and they they gave us much cleaner, nicer data with the keyframe demonstration.",
            "So we've been focusing a lot on."
        ],
        [
            "Keyframe demonstrations and saying well, how do we?",
            "How do we best utilized this first trajectory as input to a skill learning problem?",
            "So the first thing we."
        ],
        [
            "Doing is looking at simplest approaches to take several of these demonstrations here.",
            "They're pictured as all having the same number of keyframes.",
            "They don't have to have the same number of key frames, but we can take and cluster them in.",
            "In this case, we're looking at the keyframes as that.",
            "Again.",
            "Each of these points is a 7 degree of freedom, position and orientation with respect to a target object, so you."
        ],
        [
            "And cluster those and then we have a multi variate Gaussian distribution of in in this pose space and So what we do then to recreate the skill is take the mean of each of these Gaussians and do a 5th order spline in between them to create kind of smooth trajectory that represents the average of what you've seen.",
            "And so in this sense, a good demonstration or the optimal model would capture as much as much variance as possible along the different dimensions of this of these multi very of these multivariate Gaussians.",
            "So good demonstrations should be ones that show us as much variance as possible and so one of my."
        ],
        [
            "For her PhD thesis, one of my former students, my attack Mac, did some active learning queries in order to get the robot to really, quickly and efficiently get these kinds of good demonstrations that show you a lot of variance in dimensions that are going to be useful.",
            "So I'll just show you two of them."
        ],
        [
            "So a label query is one that simply distorts the skill in a couple of dimensions, and then we have a query selection algorithm that will go through and consider doing a distortion along every dimension of every Gaussian and has a cost function based on information.",
            "It's a combination of information gain and reachability, so if I perturb one of the one of the Gaussians, now I change the space of the skill that my arm has to go through in all of the other.",
            "In all the other dimensions, and so I may inadvertently, if I make a perturbation in the beginning, I may inadvertently make the end state unreachable, so that also has to factor into our query selection algorithm.",
            "But after I've selected a couple of queries, now I have a new trajectory that I create and I just ask the question.",
            "Can I do this, and if so I got to I get to extend my model significantly."
        ],
        [
            "So it looks like this, so here she's showing two keyframe demonstrations of pouring something from 1 Cup to another.",
            "So a simple task.",
            "So now the person got to easily provide a couple of useful demonstrations to the robot and all they had to do was say yes or no and so."
        ],
        [
            "Feature queries is another kind of label of query that we've done where instead of producing a whole trajectory and asking, will focus in on the particular query that you want to make and say if you have a, you can ask a question out about a particular feature or particular dimension at a time, so you might take a dimension that's highly varied and ask does position matter, and in which case you could just increase the variance.",
            "To the Max if position doesn't matter, you might take one that is highly invariant and say does it have to be this and if the person says yes then you know not to ask anymore questions about that."
        ],
        [
            "Doesn't matter.",
            "So that so one nice thing about that is that the robots actually using its embodiment to help ask those questions.",
            "So if you were to pose that question in text, you have to say you know at the end it does.",
            "My does the orientation of my hand have to be plus minus 10 degrees about the X axis, and instead you can use your embodiment to say, does my?",
            "Does the physician have to be like this an an so that's one thing that makes it nice to do this kind of embodied queries as you got?",
            "To use the people's intuition about that, OK so."
        ],
        [
            "So now we've talked about a little bit about how to efficiently get good inputs from people, but now I'm going to talk about what we should actually be getting from these demonstrations at all.",
            "'cause this is sort of a more recent realization in my lab an about a year or so after bunches of people coming in and giving these demonstrations and doing a lot of experiments with trajectories and keyframes, and kind of trying to figure out how to best get people to give input to robots.",
            "We started to realize that the there's that we were not kind of focusing on the right aspect of these demonstrations in.",
            "Here's what here's what I mean."
        ],
        [
            "So here this person is giving getting the PR 2 to close this box again just to provide some consistency and it's using this Phantom Omni tetele operate the robot too.",
            "Close the box.",
            "And it's a little hard to do this teleoperation with the Phantom Omni, so it takes a couple of swings before the person gets the box to be actually closed.",
            "Then you have to click it closed and so then after each demonstration we had people watch it.",
            "To tell if they wanted.",
            "If so, they're watching this demonstration and this time the box closes on the 1st swing.",
            "But of course you know the robot keeps going to give.",
            "The other swings and then clicks it closed and so then the person is asked, do you want to keep this demonstration and they say yes, an that really frustrated us or like no.",
            "It did two extra swings.",
            "Why would you keep this demonstration?",
            "But over and over we see that people focus on the goal.",
            "They don't really care that it did two extra swings.",
            "They care that the box closed.",
            "And clearly if I'm teaching this robot to close this box, the only thing I really need to show is that the box closed, and so if the box closed then that's a good demo an you know.",
            "Obviously we look in developmental psychology, human psychology, literature people are goal oriented.",
            "This makes perfect sense, but.",
            "We had not come to in the skill learning literature and doing motor skill learning with robots were very focused on getting good demonstrations and modeling and optimizing the whole thing.",
            "So now we've been really focused on."
        ],
        [
            "The fact that what keyframes do in a demonstration is let people focus on saliency so they let you give a really good goal demonstration, even if it's just showing you which parts of the trajectory I really cared about.",
            "And so now we've been some of our latest work has been focusing on different ways to represent this objective.",
            "So if a person is saying start like this, go here.",
            "Go here, go here.",
            "Now.",
            "My question, as a modeling question isn't is really just what are they talking about?",
            "When they say go here, which part of the state space do they care about here and what is it that I actually need to try to optimize here?",
            "And so we've been thinking about this modeling problem across a few different feature spaces."
        ],
        [
            "We could be thinking of it as a visual goal, so if I have we have an RGB D camera facing the workspace and we can get a nice high dimensional view of the target object of attention and so we could take a snapshot of that target object of attention at each of the keyframes and try to model that as an objective function."
        ],
        [
            "Another option is a haptic objective so our robot has a 6 Axis force sensor at the wrist and it could be that what the what is really important at some of these salient points is the is how the manipulation action feels."
        ],
        [
            "And the final way that we're representing goals is to treat them as pose constraints in for a motion planner, so it could be that I actually want the pose of the hand to go through these sparse points, but I don't really care what it does in between so."
        ],
        [
            "I have, you know.",
            "And obviously another answer is that the objective is multimodal, and it's actually all of these things, and it may be each one of these things at different points in the skill an so we currently have different students working on projects that along these different dimensions.",
            "But in the end, I think that it would be great to have this be a multimodal objective function that the person is helping the robot to define."
        ],
        [
            "OK, so I'll just tell you about a couple of these.",
            "Let's look at that."
        ],
        [
            "Optic goal model.",
            "So one of my PhD students, Vivian Xu, is looking at how we can build a model of what an app would an action object pair feels like paying attention to this."
        ],
        [
            "6 Axis force plate at the wrist, and so the basic."
        ],
        [
            "Pipeline is that you give the robot a demo using this keyframe demonstrations and then you let the robot explore the environment and it gets some it you can move the object around to make sure that it gets slightly different experience so it gets a little bit of variance in its experience of repeating that action and then you can build up in a model of what you felt across that experience, so we've."
        ],
        [
            "And us with a bunch of different objects and several different actions like lifting lids and and scooping things and closing that box and taking the cap off of a bottle."
        ],
        [
            "And here's an example of.",
            "Vivian.",
            "Showing the robot how to lift the lid.",
            "This is our new robot, Curie.",
            "It's not that new.",
            "Yes.",
            "So in that process, it's the same as we were talking about before, so it's learning a sequence of poses in this end effector space with respect to a target object, and now it's going to repeat that trajectory.",
            "But when it's repeating the trajectory, it."
        ],
        [
            "Recording the force data.",
            "So it's repeating this trajectory that it's learned in the position space or in the end effector space in order to get a bunch of experience, and so she's moving the object around a little to put it in places that it's for sure going to fail, or it's not going to fail.",
            "Until we get."
        ],
        [
            "10 successful trajectories in 1010 unsuccessful trajectories.",
            "The interesting thing about the unsuccessful ones is that there near misses, so they actually are useful in a later classification task.",
            "So I should say that we take these set of 10 trajectories and build up a hidden Markov model of the force data for success.",
            "Anna different hidden Markov model for the first data for failure, and then if I have some new execution, I can look at the force data off that new execution and look at the relative likelihood that it came from.",
            "My success."
        ],
        [
            "Or failed trajectory.",
            "So we did that kind of testing with a bunch."
        ],
        [
            "New objects in the robot was able to correctly identify six out of seven of the action object pairs.",
            "It got confused on that twisting of that lift lid thought that it had succeeded, but it didn't."
        ],
        [
            "But I'll show you what that looks like.",
            "So here's the robot trying to decide if it's successfully.",
            "Lifted this lid.",
            "So now it classifies.",
            "That forced trajectory.",
            "And it did not do it."
        ],
        [
            "We can't end on failure so.",
            "OK.",
            "So it currently takes that full trajectory or waits until it has the full trajectory to add to query and decide if it has succeeded or not."
        ],
        [
            "But you could clearly be doing an incremental recognition to notice earlier on, so, especially in that failure case there, the force was very different after you don't have this heavy lid that you're holding anymore, so it would have been able to tell detect failure earlier, and so this is where now we have this objective function that we are starting to use in a policy search kind of way.",
            "So this is where.",
            "Some of these objectives are now now that we get them from people, we can take them and start to use them again in a reinforcement learning process and so having this ability to online detect success or failure in a way that a person has described for us is interesting.",
            "OK, so I'm going to tell you one last example, cutting into my questions just a little bit, but I think I can do it quickly so."
        ],
        [
            "The last project I'll tell you about is some really Newark or it's some work on using keyframe in trajectory demonstrations together.",
            "And to think of them as constraints for a motion planner.",
            "So the keyframe demo highlights salient parts of the skill, but the trajectory demo shows us the dynamics of the skills, so the keyframes you stop every time, so I know nothing about what velocity you want to be doing.",
            "So if I take."
        ],
        [
            "The two together I can get geometric constraints and dynamic constraints and give those to a motion planner.",
            "So I take 2 demonstrations, one keyframe and one trajectory."
        ],
        [
            "Do some nearest neighbor kind of matching to get the part of the trajectory that best aligns with each keyframe and now I have this nice constraint for each of the poses that is opposed plus velocity constraint and now we hand that to.",
            "This is in collaboration with said trainer Versus Lab at CMU, so we had this to the CRT planner to get."
        ],
        [
            "To get the motion out of it.",
            "So here's my grad student, Teska Fitzgerald, giving a demonstration of hitting this ball on a string.",
            "So this is the keyframe demonstration.",
            "Says choose two keyframes.",
            "Start here and here so."
        ],
        [
            "Now she can show a slow version of this with a trajectory that hits the ball lightly.",
            "Or a slightly faster demo.",
            "And now."
        ],
        [
            "Now when I take those two different, so that's two different constraints that I get for different kind of velocity constraints.",
            "On that ending keyframe.",
            "And if I pass the slow one to the motion planner I get something like this and I passed the fast one to the motion planner.",
            "I got something like this so you can tell that we passed it to a planner because it did this thing that was never demonstrated, but I think this really highlights what we think we should get from demonstrations.",
            "Is that goal so we don't?",
            "Actually, I don't actually care if the robot does a back end or if you do you provide another keyframe that shows you know I don't want you to go back and I want you to come here.",
            "So, but this is the level of detail of providing goals and metadata that I think that people are going to be good at providing and that we're going to."
        ],
        [
            "That we should really be focusing on.",
            "OK, I'm going to end there."
        ],
        [
            "Her and."
        ],
        [
            "Thank all of my wonderful students and I think we have some."
        ],
        [
            "Time for questions.",
            "So I have a question, I'm curious in your work, how, how important.",
            "How useful is it for you to?",
            "To run, say questions through your subjects where you ask them, you know what were you trying to tell the robot?",
            "It seems like there are two modalities to the research where you make a hypothesis and you feed it in as a reward or.",
            "Trajectory, but it seems like presumably you also just you have these direct kind of Q&A's with yeah with yeah that's a really good point so we do we do so I both work with human factors experts and try to kind of design interesting things that we could get out of people in terms of what they're focusing on, but.",
            "So my background being in robotics and machine learning, I'm usually focused most on what do we, what is their data look like when we actually use it in the models that we want to use it in, but one thing.",
            "Is so one example is we ask people what they are actually trying to show with keyframes we've got people to describe a little bit what they were trying to say with key frames and we did get them too.",
            "That's where we did get out that people had two different kinds of keyframes that they were providing and the one hand they were providing these goal keyframes an on the other hand there providing waypoint keyframes so if they felt like it was important to go over this object they might provide this waypoint, but maybe this was the actual goal so they.",
            "A lot of people had these two different kinds of keyframes that they would be talking about, so we do get people to describe strategies and, and I think that's a it's definitely a good part of the work to try to get just people to tell us what they want.",
            "So so very nice.",
            "I have a comment and a question about shaping so the original view of shaping which Skinner.",
            "Can't use the term was was that.",
            "It's a successive approximation.",
            "To the ultimate problem.",
            "And I mean the way shaping is used in in computational reinforcement is very different from that and I'm just wondering if.",
            "The original form is something that could really serve some useful ends in what you're doing, so the idea is that you're really changing the problem.",
            "As the agent is learning right starting with something easy.",
            "And then converging.",
            "To the problem that you actually want solved.",
            "And so in demonstrations, perhaps start with something simple and successively.",
            "Make it more difficult approaching the final final.",
            "I think that's a really good point an I mean, one way that we've been thinking of it as yeah, shaping or scaffolding and in the in the affordance modeling work in particular, you kind of learn the original and then kind of move the object around to show the boundaries of failure.",
            "So that maybe that starts to get at this idea a little bit.",
            "But I think I think it also, you know, I think people have done a little bit of there's a little bit of Matt Taylor's here.",
            "He's done some work on thinking about how to structure problems progressively.",
            "I don't know how good people are going to be at knowing what the robot needs to know next, but I think that it's a.",
            "It's an animal.",
            "Training is shaping as an essential.",
            "It's shaping in that successive approximation senses, and it is an essential thing to do to get an animal to.",
            "To do what you want them to do right and then you?",
            "But how much so an expert would be really good at doing that, and I don't know that I don't know how well non experts are going to be able to do it and I don't know if they're going to be able to do it in ways that make a lot of sense.",
            "Then I think you got to these scaling issues alot.",
            "Interesting.",
            "Just wanted to say actually to Andy that even with animals, people don't use shaping that much anymore for the same reason we're too slow.",
            "We don't give the feedback well enough.",
            "Exactly the same problem, so maybe it's easier with a robot 'cause he has patience more than a rat.",
            "Great.",
            "Let's thank all the speakers again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any robot?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whose functional goal has to do with interacting with people in an environment that was designed for humans.",
                    "label": 0
                },
                {
                    "sent": "So if you're going to put your robot into one of these environments so you have to think about those social implications and how it's going to get its job done so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "IOS is hard, so a lot of the successes to date of robots have relied on structured environments and tasks that can be repeated and programmed once and as soon as we start to think about human environments like office buildings or homes or hospitals, then we have humans and humans are dynamic and humans are not structured and so we have to start thinking about how we're going to get robots to be able to function in these dynamic environments.",
                    "label": 0
                },
                {
                    "sent": "So one of the things that we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Been thinking about our goal is to have robots that can function in new or changing environments by interacting with end users in order to learn what to do.",
                    "label": 1
                },
                {
                    "sent": "And so that's what I'm gonna talk about today.",
                    "label": 0
                },
                {
                    "sent": "So to motivate that just a little bit, here's some pictures of kind of motivating examples of what we might think of and to dig into just a couple of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One that's really popular right now is manufacturing, and there's a big push towards more flexible manufacturing where you want to have robots that can be retasked on the fly.",
                    "label": 0
                },
                {
                    "sent": "Too big to do something new today or this week or this month as opposed to currently a lot of robots that have been successful in manufacturing have to be programmed once and deployed for really long time in order to be cost effective.",
                    "label": 1
                },
                {
                    "sent": "So then it's only things like cars and airplanes that you see that being really used.",
                    "label": 0
                },
                {
                    "sent": "So if you had a robot that was easy, easily trainable on the on the factory floor by a co-worker, then this would be an interesting.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Application one that we can all think about is having a service robot in your home.",
                    "label": 0
                },
                {
                    "sent": "You want the robot to clean your kitchen?",
                    "label": 0
                },
                {
                    "sent": "I know everybody would like to not clean their kitchen again and so the problem there is that the task is going to be slightly different in every home.",
                    "label": 0
                },
                {
                    "sent": "We kind of could define it at a high level, but the details are going to have to be filled in by the end user.",
                    "label": 0
                },
                {
                    "sent": "So an only the end user can actually specify that correctly, not me.",
                    "label": 0
                },
                {
                    "sent": "The robot designers sitting in a lab.",
                    "label": 1
                },
                {
                    "sent": "So what we need here?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is interactive machine learning, and so that's what I'm going to tell you about today.",
                    "label": 1
                },
                {
                    "sent": "What we need to consider in addresses, the problem of how a robot can take this general problem of being able to build a policy or a model of a task in a given environment, which we can define really broadly, is just, you know.",
                    "label": 1
                },
                {
                    "sent": "The robot needs to know what to do in a given state.",
                    "label": 0
                },
                {
                    "sent": "And so this is very similar to a lot of the problem formulations that we've been talking about, and what I want to talk about is how we can structure the problem of end user providing the input to this kind of modeling problem.",
                    "label": 0
                },
                {
                    "sent": "So there's been quite a bit of related work in the field or in the literature about adding human input to machine learning algorithms, and the interesting 1 interesting way to think about it is the kind of input that the person is providing, so there's kind of been two big focuses in the type of input that you ask people to provide a machine learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "So on the one hand, you can ask a person to provide demonstrations where in a given state the person is showing.",
                    "label": 0
                },
                {
                    "sent": "Exactly what action to be providing, so the input that the person is giving is examples of actions.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we can think about the person providing what you can call critique, where it's watching, the learning behavior, and providing labels as to whether or not a particular action was good or bad.",
                    "label": 0
                },
                {
                    "sent": "So what my life has been doing is thinking about.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These things, these interactions with machine learning algorithms holistically and saying hey, if you bring in people off the street and have them interact across a variety of different ways with machine learning algorithms, what is that like in the the punch line that we've come back too many times?",
                    "label": 0
                },
                {
                    "sent": "Is that algorithms need to use the information that people are good at providing?",
                    "label": 1
                },
                {
                    "sent": "And so today I want to give you a couple of couple of examples across.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of these, each of these kinds of human input about what I mean by using the information that people are good at providing.",
                    "label": 0
                },
                {
                    "sent": "So I'll start off with talking a little bit about critique and then and then go into.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two demonstrations.",
                    "label": 0
                },
                {
                    "sent": "So, assuming that people have just a high level feedback signal, what should the agent do with that?",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Related to everything we've been talking about here so far, we have this.",
                    "label": 0
                },
                {
                    "sent": "We have reinforcement learning problem here and now.",
                    "label": 1
                },
                {
                    "sent": "The question we're asking is is how we can.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best incorporate a human into this feedback loop.",
                    "label": 0
                },
                {
                    "sent": "And so the talk that we just heard nicely fits nicely set up for the problem that we're going to.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk about here.",
                    "label": 0
                },
                {
                    "sent": "So one of.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First things you might think of doing is reward shaping, where the human is going to.",
                    "label": 1
                },
                {
                    "sent": "We're going to take the humans critique, rewards and justice.",
                    "label": 0
                },
                {
                    "sent": "Roll those into the feedback signal that you're getting from the environment, and so one of the first experiments that I did in this domain looked at putting this in front of people.",
                    "label": 0
                },
                {
                    "sent": "We had hundreds of people interact with this sophies kitchen game and asked, you know whether or not this is something people can actually do.",
                    "label": 1
                },
                {
                    "sent": "An it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The people aren't very accurate at reward shaping and they anticipate what people with the agent might do and give rewards about things the agent never did and and such things.",
                    "label": 1
                },
                {
                    "sent": "But you can change the interface in the algorithm to kind of get them to do the right thing a little bit more so if you give them a guidance.",
                    "label": 0
                },
                {
                    "sent": "Channel they will actually make their feedback channel more informative and things like that, so we could actually get the learning performance of the of the agent with this reward shaping from hundreds of users on the Internet to work pretty well but but despite the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fact that we were able to massage the input channel to work in this kind of rewards or shaping context, we sort of came to a similar conclusion as the previous talk that there's something that just wasn't quite right about the way we're thinking about about this whole way, or the reward shaping was working, but we came to an alternative conclusion that.",
                    "label": 0
                },
                {
                    "sent": "Maybe instead of, instead of converting peoples Rewards in peoples feedback into a reward signal signal or a number at all, we should just take it at face value as a critique on the policy.",
                    "label": 0
                },
                {
                    "sent": "So instead of saying so when people say that's right here, that's wrong.",
                    "label": 0
                },
                {
                    "sent": "They're not saying No 5 or minus .2.",
                    "label": 0
                },
                {
                    "sent": "They're actually just saying that was right and that was wrong, and so we can think of this as policy shaping instead of reward shaping.",
                    "label": 1
                },
                {
                    "sent": "So I'll quickly talk about this as this is.",
                    "label": 0
                },
                {
                    "sent": "Older work, that's all.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe been presented, but we have a approach called advise where we're thinking about separately modeling peoples feedback policy and the agents learned policy and then we can try to combine those.",
                    "label": 0
                },
                {
                    "sent": "So for a given state that the agent is in, it takes an action and the human can say that was correct or incorrect now and we can assume that the human might have some noise in that feedback channel, they might be delayed.",
                    "label": 0
                },
                {
                    "sent": "They might just hit the wrong button or any number of reasons the person might have a noisy signal, but we're going to model that with some probability C, so we have the probability that the human is correct, but I can estimate for a state action pair, the probability that the human believes that this was the correct action.",
                    "label": 0
                },
                {
                    "sent": "If I take the number of times that I got a label saying that this was correct, an times 1 minus the the number of times that I was told that some other action.",
                    "label": 1
                },
                {
                    "sent": "Was correct, so now I have the probability that the person believes that this is the correct action, so this is their feedback.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Policy and not for the agents policy I can use.",
                    "label": 1
                },
                {
                    "sent": "I can use an approach of a Bayesian reinforcement learning approach, right?",
                    "label": 0
                },
                {
                    "sent": "Also get a distribution over the agents belief and what the correct Q value is.",
                    "label": 0
                },
                {
                    "sent": "So now I have these two.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sources of information about the policy and we can.",
                    "label": 0
                },
                {
                    "sent": "We can basically have the agent take the take the action that's going to give the that's going to optimize both of these at once so.",
                    "label": 0
                },
                {
                    "sent": "Basically it ends up being a tradeoff between using the agent when you have feedback from the person, you'll take good advantage of it in the beginning, and when you don't have any.",
                    "label": 0
                },
                {
                    "sent": "When the person hasn't said anything yet, then you're going to rely on your own information so.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Please, some experiments that we've done here.",
                    "label": 0
                },
                {
                    "sent": "We're in the arcade games of PAC Man and Frogger, where we were playing around with the different parameters, like the likelihood that you actually get feedback in any particular time step, and the correctness of that feedback.",
                    "label": 0
                },
                {
                    "sent": "So we used an Oracle to test these to test these parameters, and we compare it against some of the state of the art.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithms that come closest to doing policy shaping but still actually take that number and put it into the reward signal.",
                    "label": 0
                },
                {
                    "sent": "If you're familiar with these.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just quickly we did experiments in four different with four different cell it settings of likelihood and correctness.",
                    "label": 0
                },
                {
                    "sent": "And takeaway is that our approach always a performs kind of at or above the baseline and never does worse than them.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Baseline and here's just a pull out.",
                    "label": 0
                },
                {
                    "sent": "A couple of examples on the left were showing the ideal feedback, so you got feedback all the time and it's always correct and what we see here is that our approach is able to take advantage of that correct feedback early on in the process, and so the green line is our advise algorithm, and so we do better early on.",
                    "label": 0
                },
                {
                    "sent": "And if you take a more worse scenario where you have less likely feedback and it's maybe only 80% correct, then we see that we don't.",
                    "label": 0
                },
                {
                    "sent": "We don't get that big advantage of taking of taking the lead in the beginning, but we also don't do any worse.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our approach is robust to this.",
                    "label": 0
                },
                {
                    "sent": "This one parameter that we have so with critique interactions we have shown that reward shaping at least needs modification in order to in order to be effective.",
                    "label": 1
                },
                {
                    "sent": "And maybe a better idea is to think of it as policy shaping, where instead of thinking of actually so we don't convert people's feedback to a number at all, we actually just think of it as advice on the policy.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I want to take a look at the other interaction scenario and this is the one that my lab has been working on for a lot of different years and for a minute it's not going to feel like reinforcement.",
                    "label": 0
                },
                {
                    "sent": "It hasn't been as related to reinforcement learning, but just recently it's coming back to being reinforcement learning relevant, so we'll take a slight departure from reinforcement learning and then get back to it.",
                    "label": 0
                },
                {
                    "sent": "So two things that I want to emphasize about learning from human.",
                    "label": 0
                },
                {
                    "sent": "The demonstrations side of learning from humans.",
                    "label": 0
                },
                {
                    "sent": "One is that we want to think about how we can quickly and efficiently get demonstrations from people, because we don't want to waste peoples time, they don't have a lot of time and the thing that we've been focused on lately is really asking what should we really be getting from these demonstrations, and so those are the two questions I want to answer today.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's talk about how to get good demos so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The field of learning from demonstration is 30 year old field that's aimed at allowing people to demonstrate tasks rather than program controllers on robots, so are usually talking about motor skills and a lot of the we have upper torso humanoid robots, so we're talking about learning manipulation motor skills.",
                    "label": 0
                },
                {
                    "sent": "For the most part.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the typical input for this kind of skill learning is give a full trajectory demonstration of the skill where the state space is either if we're talking about a manipulation task, the state space is either the full kinematic chain of the arm or the end effector only, or the end effector with respect to some element in the task environment.",
                    "label": 0
                },
                {
                    "sent": "So you are usually using the state space.",
                    "label": 0
                },
                {
                    "sent": "That is, the end effectors 7 degree of freedom pose with respect to some target.",
                    "label": 0
                },
                {
                    "sent": "Object in the environment, but the traditional thing you would do is record all of that state from the from the beginning of the end of the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stration so it would look like this.",
                    "label": 0
                },
                {
                    "sent": "This is our robot, Simon.",
                    "label": 0
                },
                {
                    "sent": "And the person is trying to demonstrate to Simon how to close the lid of this box.",
                    "label": 0
                },
                {
                    "sent": "And this is after they've done a practice session and we have a whole thing that they go through.",
                    "label": 0
                },
                {
                    "sent": "But since this is a new task, they haven't taught the robot before.",
                    "label": 0
                },
                {
                    "sent": "They're having a little trouble figuring out the kinematics of the seven degree of freedom arm.",
                    "label": 0
                },
                {
                    "sent": "And it looks kind of silly, but it's actually a lot of people have difficulty.",
                    "label": 0
                },
                {
                    "sent": "So even if you've had experience even working with this robot when you're teaching it something new, you might often have trouble deciding exactly how you want to show it.",
                    "label": 0
                },
                {
                    "sent": "And the real problem is that all of that information got recorded as part of the demonstration, so that's annoying.",
                    "label": 0
                },
                {
                    "sent": "If you are, try.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to learn a model of that of that skill.",
                    "label": 0
                },
                {
                    "sent": "So an alternative to this is to let people provide keyframes and which is a sparse trajectory that when you a sparse sequence of these poses so it's a sparse trajectory in the same state space that when they when you string them together it completes the skill.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's somebody doing the same task with keyframes.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So he's having similar difficulties with the kinematics of the robot and figuring out what to do.",
                    "label": 0
                },
                {
                    "sent": "I mean 7 degrees of freedom is a lot to control all at once, and if you're doing.",
                    "label": 0
                },
                {
                    "sent": "But the great thing is, is that not all of that wasn't recorded, we just got the poses that were.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And and that was in that, and that's nice.",
                    "label": 0
                },
                {
                    "sent": "So we did an experiment with 34 people, had them teach the robot a variety of different skills.",
                    "label": 1
                },
                {
                    "sent": "Some had to do with objects, some didn't, and we have them teach with keyframes an trajectories, and it turns out that people.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are positive towards both types of interaction.",
                    "label": 0
                },
                {
                    "sent": "They were perfectly happy to give us terrable trajectory demonstrations, but it was hard to give a noise free trajectory demo and they they gave us much cleaner, nicer data with the keyframe demonstration.",
                    "label": 0
                },
                {
                    "sent": "So we've been focusing a lot on.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Keyframe demonstrations and saying well, how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we best utilized this first trajectory as input to a skill learning problem?",
                    "label": 0
                },
                {
                    "sent": "So the first thing we.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing is looking at simplest approaches to take several of these demonstrations here.",
                    "label": 0
                },
                {
                    "sent": "They're pictured as all having the same number of keyframes.",
                    "label": 0
                },
                {
                    "sent": "They don't have to have the same number of key frames, but we can take and cluster them in.",
                    "label": 0
                },
                {
                    "sent": "In this case, we're looking at the keyframes as that.",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "Each of these points is a 7 degree of freedom, position and orientation with respect to a target object, so you.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And cluster those and then we have a multi variate Gaussian distribution of in in this pose space and So what we do then to recreate the skill is take the mean of each of these Gaussians and do a 5th order spline in between them to create kind of smooth trajectory that represents the average of what you've seen.",
                    "label": 0
                },
                {
                    "sent": "And so in this sense, a good demonstration or the optimal model would capture as much as much variance as possible along the different dimensions of this of these multi very of these multivariate Gaussians.",
                    "label": 1
                },
                {
                    "sent": "So good demonstrations should be ones that show us as much variance as possible and so one of my.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For her PhD thesis, one of my former students, my attack Mac, did some active learning queries in order to get the robot to really, quickly and efficiently get these kinds of good demonstrations that show you a lot of variance in dimensions that are going to be useful.",
                    "label": 0
                },
                {
                    "sent": "So I'll just show you two of them.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a label query is one that simply distorts the skill in a couple of dimensions, and then we have a query selection algorithm that will go through and consider doing a distortion along every dimension of every Gaussian and has a cost function based on information.",
                    "label": 0
                },
                {
                    "sent": "It's a combination of information gain and reachability, so if I perturb one of the one of the Gaussians, now I change the space of the skill that my arm has to go through in all of the other.",
                    "label": 0
                },
                {
                    "sent": "In all the other dimensions, and so I may inadvertently, if I make a perturbation in the beginning, I may inadvertently make the end state unreachable, so that also has to factor into our query selection algorithm.",
                    "label": 0
                },
                {
                    "sent": "But after I've selected a couple of queries, now I have a new trajectory that I create and I just ask the question.",
                    "label": 0
                },
                {
                    "sent": "Can I do this, and if so I got to I get to extend my model significantly.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it looks like this, so here she's showing two keyframe demonstrations of pouring something from 1 Cup to another.",
                    "label": 0
                },
                {
                    "sent": "So a simple task.",
                    "label": 0
                },
                {
                    "sent": "So now the person got to easily provide a couple of useful demonstrations to the robot and all they had to do was say yes or no and so.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feature queries is another kind of label of query that we've done where instead of producing a whole trajectory and asking, will focus in on the particular query that you want to make and say if you have a, you can ask a question out about a particular feature or particular dimension at a time, so you might take a dimension that's highly varied and ask does position matter, and in which case you could just increase the variance.",
                    "label": 0
                },
                {
                    "sent": "To the Max if position doesn't matter, you might take one that is highly invariant and say does it have to be this and if the person says yes then you know not to ask anymore questions about that.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So that so one nice thing about that is that the robots actually using its embodiment to help ask those questions.",
                    "label": 0
                },
                {
                    "sent": "So if you were to pose that question in text, you have to say you know at the end it does.",
                    "label": 0
                },
                {
                    "sent": "My does the orientation of my hand have to be plus minus 10 degrees about the X axis, and instead you can use your embodiment to say, does my?",
                    "label": 0
                },
                {
                    "sent": "Does the physician have to be like this an an so that's one thing that makes it nice to do this kind of embodied queries as you got?",
                    "label": 0
                },
                {
                    "sent": "To use the people's intuition about that, OK so.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we've talked about a little bit about how to efficiently get good inputs from people, but now I'm going to talk about what we should actually be getting from these demonstrations at all.",
                    "label": 1
                },
                {
                    "sent": "'cause this is sort of a more recent realization in my lab an about a year or so after bunches of people coming in and giving these demonstrations and doing a lot of experiments with trajectories and keyframes, and kind of trying to figure out how to best get people to give input to robots.",
                    "label": 0
                },
                {
                    "sent": "We started to realize that the there's that we were not kind of focusing on the right aspect of these demonstrations in.",
                    "label": 0
                },
                {
                    "sent": "Here's what here's what I mean.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here this person is giving getting the PR 2 to close this box again just to provide some consistency and it's using this Phantom Omni tetele operate the robot too.",
                    "label": 0
                },
                {
                    "sent": "Close the box.",
                    "label": 0
                },
                {
                    "sent": "And it's a little hard to do this teleoperation with the Phantom Omni, so it takes a couple of swings before the person gets the box to be actually closed.",
                    "label": 0
                },
                {
                    "sent": "Then you have to click it closed and so then after each demonstration we had people watch it.",
                    "label": 0
                },
                {
                    "sent": "To tell if they wanted.",
                    "label": 0
                },
                {
                    "sent": "If so, they're watching this demonstration and this time the box closes on the 1st swing.",
                    "label": 0
                },
                {
                    "sent": "But of course you know the robot keeps going to give.",
                    "label": 0
                },
                {
                    "sent": "The other swings and then clicks it closed and so then the person is asked, do you want to keep this demonstration and they say yes, an that really frustrated us or like no.",
                    "label": 0
                },
                {
                    "sent": "It did two extra swings.",
                    "label": 0
                },
                {
                    "sent": "Why would you keep this demonstration?",
                    "label": 0
                },
                {
                    "sent": "But over and over we see that people focus on the goal.",
                    "label": 0
                },
                {
                    "sent": "They don't really care that it did two extra swings.",
                    "label": 0
                },
                {
                    "sent": "They care that the box closed.",
                    "label": 0
                },
                {
                    "sent": "And clearly if I'm teaching this robot to close this box, the only thing I really need to show is that the box closed, and so if the box closed then that's a good demo an you know.",
                    "label": 0
                },
                {
                    "sent": "Obviously we look in developmental psychology, human psychology, literature people are goal oriented.",
                    "label": 0
                },
                {
                    "sent": "This makes perfect sense, but.",
                    "label": 0
                },
                {
                    "sent": "We had not come to in the skill learning literature and doing motor skill learning with robots were very focused on getting good demonstrations and modeling and optimizing the whole thing.",
                    "label": 0
                },
                {
                    "sent": "So now we've been really focused on.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The fact that what keyframes do in a demonstration is let people focus on saliency so they let you give a really good goal demonstration, even if it's just showing you which parts of the trajectory I really cared about.",
                    "label": 0
                },
                {
                    "sent": "And so now we've been some of our latest work has been focusing on different ways to represent this objective.",
                    "label": 0
                },
                {
                    "sent": "So if a person is saying start like this, go here.",
                    "label": 1
                },
                {
                    "sent": "Go here, go here.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "My question, as a modeling question isn't is really just what are they talking about?",
                    "label": 0
                },
                {
                    "sent": "When they say go here, which part of the state space do they care about here and what is it that I actually need to try to optimize here?",
                    "label": 0
                },
                {
                    "sent": "And so we've been thinking about this modeling problem across a few different feature spaces.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We could be thinking of it as a visual goal, so if I have we have an RGB D camera facing the workspace and we can get a nice high dimensional view of the target object of attention and so we could take a snapshot of that target object of attention at each of the keyframes and try to model that as an objective function.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another option is a haptic objective so our robot has a 6 Axis force sensor at the wrist and it could be that what the what is really important at some of these salient points is the is how the manipulation action feels.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the final way that we're representing goals is to treat them as pose constraints in for a motion planner, so it could be that I actually want the pose of the hand to go through these sparse points, but I don't really care what it does in between so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have, you know.",
                    "label": 0
                },
                {
                    "sent": "And obviously another answer is that the objective is multimodal, and it's actually all of these things, and it may be each one of these things at different points in the skill an so we currently have different students working on projects that along these different dimensions.",
                    "label": 0
                },
                {
                    "sent": "But in the end, I think that it would be great to have this be a multimodal objective function that the person is helping the robot to define.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'll just tell you about a couple of these.",
                    "label": 0
                },
                {
                    "sent": "Let's look at that.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optic goal model.",
                    "label": 0
                },
                {
                    "sent": "So one of my PhD students, Vivian Xu, is looking at how we can build a model of what an app would an action object pair feels like paying attention to this.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "6 Axis force plate at the wrist, and so the basic.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pipeline is that you give the robot a demo using this keyframe demonstrations and then you let the robot explore the environment and it gets some it you can move the object around to make sure that it gets slightly different experience so it gets a little bit of variance in its experience of repeating that action and then you can build up in a model of what you felt across that experience, so we've.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And us with a bunch of different objects and several different actions like lifting lids and and scooping things and closing that box and taking the cap off of a bottle.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's an example of.",
                    "label": 0
                },
                {
                    "sent": "Vivian.",
                    "label": 0
                },
                {
                    "sent": "Showing the robot how to lift the lid.",
                    "label": 0
                },
                {
                    "sent": "This is our new robot, Curie.",
                    "label": 0
                },
                {
                    "sent": "It's not that new.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So in that process, it's the same as we were talking about before, so it's learning a sequence of poses in this end effector space with respect to a target object, and now it's going to repeat that trajectory.",
                    "label": 0
                },
                {
                    "sent": "But when it's repeating the trajectory, it.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recording the force data.",
                    "label": 0
                },
                {
                    "sent": "So it's repeating this trajectory that it's learned in the position space or in the end effector space in order to get a bunch of experience, and so she's moving the object around a little to put it in places that it's for sure going to fail, or it's not going to fail.",
                    "label": 0
                },
                {
                    "sent": "Until we get.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 successful trajectories in 1010 unsuccessful trajectories.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing about the unsuccessful ones is that there near misses, so they actually are useful in a later classification task.",
                    "label": 0
                },
                {
                    "sent": "So I should say that we take these set of 10 trajectories and build up a hidden Markov model of the force data for success.",
                    "label": 0
                },
                {
                    "sent": "Anna different hidden Markov model for the first data for failure, and then if I have some new execution, I can look at the force data off that new execution and look at the relative likelihood that it came from.",
                    "label": 0
                },
                {
                    "sent": "My success.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or failed trajectory.",
                    "label": 0
                },
                {
                    "sent": "So we did that kind of testing with a bunch.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New objects in the robot was able to correctly identify six out of seven of the action object pairs.",
                    "label": 0
                },
                {
                    "sent": "It got confused on that twisting of that lift lid thought that it had succeeded, but it didn't.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I'll show you what that looks like.",
                    "label": 0
                },
                {
                    "sent": "So here's the robot trying to decide if it's successfully.",
                    "label": 0
                },
                {
                    "sent": "Lifted this lid.",
                    "label": 0
                },
                {
                    "sent": "So now it classifies.",
                    "label": 0
                },
                {
                    "sent": "That forced trajectory.",
                    "label": 0
                },
                {
                    "sent": "And it did not do it.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can't end on failure so.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it currently takes that full trajectory or waits until it has the full trajectory to add to query and decide if it has succeeded or not.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you could clearly be doing an incremental recognition to notice earlier on, so, especially in that failure case there, the force was very different after you don't have this heavy lid that you're holding anymore, so it would have been able to tell detect failure earlier, and so this is where now we have this objective function that we are starting to use in a policy search kind of way.",
                    "label": 0
                },
                {
                    "sent": "So this is where.",
                    "label": 0
                },
                {
                    "sent": "Some of these objectives are now now that we get them from people, we can take them and start to use them again in a reinforcement learning process and so having this ability to online detect success or failure in a way that a person has described for us is interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to tell you one last example, cutting into my questions just a little bit, but I think I can do it quickly so.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last project I'll tell you about is some really Newark or it's some work on using keyframe in trajectory demonstrations together.",
                    "label": 0
                },
                {
                    "sent": "And to think of them as constraints for a motion planner.",
                    "label": 0
                },
                {
                    "sent": "So the keyframe demo highlights salient parts of the skill, but the trajectory demo shows us the dynamics of the skills, so the keyframes you stop every time, so I know nothing about what velocity you want to be doing.",
                    "label": 1
                },
                {
                    "sent": "So if I take.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two together I can get geometric constraints and dynamic constraints and give those to a motion planner.",
                    "label": 0
                },
                {
                    "sent": "So I take 2 demonstrations, one keyframe and one trajectory.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do some nearest neighbor kind of matching to get the part of the trajectory that best aligns with each keyframe and now I have this nice constraint for each of the poses that is opposed plus velocity constraint and now we hand that to.",
                    "label": 0
                },
                {
                    "sent": "This is in collaboration with said trainer Versus Lab at CMU, so we had this to the CRT planner to get.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To get the motion out of it.",
                    "label": 0
                },
                {
                    "sent": "So here's my grad student, Teska Fitzgerald, giving a demonstration of hitting this ball on a string.",
                    "label": 0
                },
                {
                    "sent": "So this is the keyframe demonstration.",
                    "label": 0
                },
                {
                    "sent": "Says choose two keyframes.",
                    "label": 0
                },
                {
                    "sent": "Start here and here so.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now she can show a slow version of this with a trajectory that hits the ball lightly.",
                    "label": 0
                },
                {
                    "sent": "Or a slightly faster demo.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now when I take those two different, so that's two different constraints that I get for different kind of velocity constraints.",
                    "label": 0
                },
                {
                    "sent": "On that ending keyframe.",
                    "label": 0
                },
                {
                    "sent": "And if I pass the slow one to the motion planner I get something like this and I passed the fast one to the motion planner.",
                    "label": 0
                },
                {
                    "sent": "I got something like this so you can tell that we passed it to a planner because it did this thing that was never demonstrated, but I think this really highlights what we think we should get from demonstrations.",
                    "label": 0
                },
                {
                    "sent": "Is that goal so we don't?",
                    "label": 0
                },
                {
                    "sent": "Actually, I don't actually care if the robot does a back end or if you do you provide another keyframe that shows you know I don't want you to go back and I want you to come here.",
                    "label": 0
                },
                {
                    "sent": "So, but this is the level of detail of providing goals and metadata that I think that people are going to be good at providing and that we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That we should really be focusing on.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to end there.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Her and.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank all of my wonderful students and I think we have some.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time for questions.",
                    "label": 0
                },
                {
                    "sent": "So I have a question, I'm curious in your work, how, how important.",
                    "label": 0
                },
                {
                    "sent": "How useful is it for you to?",
                    "label": 0
                },
                {
                    "sent": "To run, say questions through your subjects where you ask them, you know what were you trying to tell the robot?",
                    "label": 0
                },
                {
                    "sent": "It seems like there are two modalities to the research where you make a hypothesis and you feed it in as a reward or.",
                    "label": 0
                },
                {
                    "sent": "Trajectory, but it seems like presumably you also just you have these direct kind of Q&A's with yeah with yeah that's a really good point so we do we do so I both work with human factors experts and try to kind of design interesting things that we could get out of people in terms of what they're focusing on, but.",
                    "label": 0
                },
                {
                    "sent": "So my background being in robotics and machine learning, I'm usually focused most on what do we, what is their data look like when we actually use it in the models that we want to use it in, but one thing.",
                    "label": 0
                },
                {
                    "sent": "Is so one example is we ask people what they are actually trying to show with keyframes we've got people to describe a little bit what they were trying to say with key frames and we did get them too.",
                    "label": 0
                },
                {
                    "sent": "That's where we did get out that people had two different kinds of keyframes that they were providing and the one hand they were providing these goal keyframes an on the other hand there providing waypoint keyframes so if they felt like it was important to go over this object they might provide this waypoint, but maybe this was the actual goal so they.",
                    "label": 0
                },
                {
                    "sent": "A lot of people had these two different kinds of keyframes that they would be talking about, so we do get people to describe strategies and, and I think that's a it's definitely a good part of the work to try to get just people to tell us what they want.",
                    "label": 0
                },
                {
                    "sent": "So so very nice.",
                    "label": 0
                },
                {
                    "sent": "I have a comment and a question about shaping so the original view of shaping which Skinner.",
                    "label": 0
                },
                {
                    "sent": "Can't use the term was was that.",
                    "label": 0
                },
                {
                    "sent": "It's a successive approximation.",
                    "label": 0
                },
                {
                    "sent": "To the ultimate problem.",
                    "label": 0
                },
                {
                    "sent": "And I mean the way shaping is used in in computational reinforcement is very different from that and I'm just wondering if.",
                    "label": 0
                },
                {
                    "sent": "The original form is something that could really serve some useful ends in what you're doing, so the idea is that you're really changing the problem.",
                    "label": 0
                },
                {
                    "sent": "As the agent is learning right starting with something easy.",
                    "label": 0
                },
                {
                    "sent": "And then converging.",
                    "label": 0
                },
                {
                    "sent": "To the problem that you actually want solved.",
                    "label": 0
                },
                {
                    "sent": "And so in demonstrations, perhaps start with something simple and successively.",
                    "label": 0
                },
                {
                    "sent": "Make it more difficult approaching the final final.",
                    "label": 0
                },
                {
                    "sent": "I think that's a really good point an I mean, one way that we've been thinking of it as yeah, shaping or scaffolding and in the in the affordance modeling work in particular, you kind of learn the original and then kind of move the object around to show the boundaries of failure.",
                    "label": 0
                },
                {
                    "sent": "So that maybe that starts to get at this idea a little bit.",
                    "label": 0
                },
                {
                    "sent": "But I think I think it also, you know, I think people have done a little bit of there's a little bit of Matt Taylor's here.",
                    "label": 0
                },
                {
                    "sent": "He's done some work on thinking about how to structure problems progressively.",
                    "label": 0
                },
                {
                    "sent": "I don't know how good people are going to be at knowing what the robot needs to know next, but I think that it's a.",
                    "label": 0
                },
                {
                    "sent": "It's an animal.",
                    "label": 0
                },
                {
                    "sent": "Training is shaping as an essential.",
                    "label": 0
                },
                {
                    "sent": "It's shaping in that successive approximation senses, and it is an essential thing to do to get an animal to.",
                    "label": 0
                },
                {
                    "sent": "To do what you want them to do right and then you?",
                    "label": 0
                },
                {
                    "sent": "But how much so an expert would be really good at doing that, and I don't know that I don't know how well non experts are going to be able to do it and I don't know if they're going to be able to do it in ways that make a lot of sense.",
                    "label": 0
                },
                {
                    "sent": "Then I think you got to these scaling issues alot.",
                    "label": 0
                },
                {
                    "sent": "Interesting.",
                    "label": 0
                },
                {
                    "sent": "Just wanted to say actually to Andy that even with animals, people don't use shaping that much anymore for the same reason we're too slow.",
                    "label": 0
                },
                {
                    "sent": "We don't give the feedback well enough.",
                    "label": 0
                },
                {
                    "sent": "Exactly the same problem, so maybe it's easier with a robot 'cause he has patience more than a rat.",
                    "label": 0
                },
                {
                    "sent": "Great.",
                    "label": 0
                },
                {
                    "sent": "Let's thank all the speakers again.",
                    "label": 0
                }
            ]
        }
    }
}