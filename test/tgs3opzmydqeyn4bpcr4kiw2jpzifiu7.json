{
    "id": "tgs3opzmydqeyn4bpcr4kiw2jpzifiu7",
    "title": "Fast Online Learning through Offline Initialization for Time-sensitive Recommendation",
    "info": {
        "author": [
            "Bee-Chung Chen, LinkedIn Corporation"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2010_chen_folt/",
    "segmentation": [
        [
            "Thank you for coming and this is joint work with Deepak Agrawal and Pradeep Delangle at Yahoo Labs."
        ],
        [
            "So I don't think I need to address that.",
            "Recommender systems are useful applications.",
            "I think everyone come here.",
            "If you believe that this is useful, at least we have a lot of applications in movie recommendation and also say news article recommendation.",
            "And you can also recommends a product or friends or whatever you want to recommend.",
            "So the goal really is that for each user right we want to provide a list of items.",
            "That the user might like.",
            "So one common approach is that what we can build a model to predict the rating that a user would give to a unrated item right based on the past activities of all the users and all the ratings.",
            "And then if we have this model then it's pretty easy.",
            "We just recommend the items with the highest predicted ratings to the user and here ratings can be explicit like.",
            "Movie ratings or implicit like click or no click?",
            "So this approach is quite successful when there are enough passer ratings for each user and each item specifically, well, metric factorization is a very successful method in this space.",
            "First matters are very fine grained models.",
            "That means each item and user has a set of factors that need to be learned from the rating data OK, and if you have new item or a new user right, you do not have these factors so that it is challenging to make good recommendation for new users and new items.",
            "And this is generally called the cold start problem."
        ],
        [
            "So let's take an example.",
            "So this is Yahoo front page and this is the Today module and in this module we recommend stories to users, and those stories are popular today, so those stories are new stories right?",
            "By definition or by the design of this module, we want to recommend new items.",
            "But usually we do not have factors or historical data right to build factory model for.",
            "For those new stories."
        ],
        [
            "So the other example of this kind of time sensitive items.",
            "So for example news stories, trending queries.",
            "So if you look at this here, there's a trending now module which recommend queries that you might like, but and those queries are trending query.",
            "That means that happens in real time.",
            "And also updates tweets or events right?",
            "Those are kind of time sensitive items.",
            "Challenges one is that we need to build real time data pipeline right?",
            "That can continuously collect data.",
            "From these new items, the ratings of these new items and use that to update the model, but that's not something I want to address here.",
            "What we want to address is the modeling challenges, because this is online because we receive data in online manner and we want to update or another very quickly.",
            "So there are two basic requirements.",
            "One is the learning needs to be very fast.",
            "That is, we want to learn good models for new items using very little data as little as possible.",
            "A few ideas.",
            "One is that probably if we build online model, we want to have a natural gas that is without any rating, right?",
            "We want to.",
            "Guess the rating to some good extent.",
            "And also we also run the online model learning to converge very fast very quickly.",
            "An another requirement is the computation.",
            "It also to be very quite fast.",
            "That is, we want to build good model using little time, right?",
            "And so that means efficient and scaleable and parallelizable algorithms."
        ],
        [
            "So let's think about a few possible approaches, right?",
            "One is.",
            "What we call offline feature based regression?",
            "But is you capture whatever you know about user and items by features, features, user features.",
            "XI, for example, includes age, gender, location and whatever we know about users.",
            "Item features include, for example, the category of the item source or entity or keywords extracted from the item, and then we just build a machine learning model.",
            "Pick whatever you want you like.",
            "Right model using those features to predict the rating.",
            "Right here I show one example.",
            "Watch feature based model which is you predict the rating that user I would give item J as a linear weighted sum right?",
            "And in this particular model we have a weight for each pair of user feature and item feature.",
            "OK so basically we take the cross product user features an item features and then you have a weight associated with each entry right?",
            "In these metrics, and then you just do a weighted stuff that will be your prediction.",
            "And this is just one example and we will see this example.",
            "Is this particular model is.",
            "Really good.",
            "And I would use metrics form right to describe this model, which is a quadratic quadratic form.",
            "And well, if you look at this model then you would find a problem that is users having same feature vectors, right?",
            "Get the same recommendation.",
            "Basically if 2 user I have the same feature vector then the model cannot distinguish between the two user even if we know a lot of about the user.",
            "For example, we observe the rating of 1 user for a long period of time, but.",
            "The feature cannot may not capture that, so that's why usually this feature based regression method or sometimes called content based color filtering is not very accurate."
        ],
        [
            "So what people do is do do the collaboratory filtering methods so there are many methods.",
            "For example similarity based method but.",
            "The current trend is that factorization methods seem to be much better than similarity based, so I will only look at this factorization based method.",
            "So basically for each user an item, right we have a vector of factors.",
            "Factors are learned from rating data.",
            "OK, so features right by my technologies.",
            "This features are given or we observed and factors are learned from data.",
            "OK, and what you do is you model the rating that user I give item J as a inner product of two vectors right?",
            "And the first one is the user factor vector.",
            "OK, so that's a set of weights.",
            "We model weights that we give to each user and we also have the corresponding.",
            "We also have a vector of factors for each item and then we do prediction, just do a.",
            "Product right and you can think about this from a metrics form.",
            "That basically you decompose your rating metrics into.",
            "Low rank approximation OK, and This is why it is called metrics factorization method.",
            "This method is pretty good if you have data for every user and every item.",
            "But if like in our code start setting we have many new item comes in then we don't have those factors then one approach is that probably we can rebuild the model right every time we receive a data point, but rebuilding this model right is kind of very time consuming.",
            "Probably we can rebuild the model, say once an hour or Wednesday, but doing that one day.",
            "Right?",
            "We would have a lot of new items coming, so there are also many hybrid methods, but there is little attention to fast on line procedures in the literature and that is the focus of this talk."
        ],
        [
            "A simple way to address that is that OK, let's.",
            "Still predict the ratings that user I gives 2 item J as inner product of two vectors and the first is the item factor for user an.",
            "Let's say we use historical data right to determine this user factors.",
            "Right, so in the online setting, this actually you can think of them as features because they are given.",
            "And what we?",
            "Need to learn is that well.",
            "After we receive data right, we want to update this item factor very quickly, OK, and then if you look at this, the first part is fixed or determined by offline training and the second part is actually the regression weight right?",
            "So then this is just a online regression model you after you receive a rating right?",
            "You may just quickly update your model.",
            "And if you want, you can use just features for this UI.",
            "But if you want to use factors then, well, this is not learned online, but it can be updated periodically, for example daily.",
            "But this beta, these beta these parameters associated with items need to be updated very quickly because we have many new items coming into the system.",
            "This approach is promising.",
            "But took problems.",
            "We need to address 1.",
            "Is that what should be the initial point of the model right?",
            "You can initialize that by zero right?",
            "All the initial weight to be 0, but that's not going to be the best that you can do, so I really want to find a good initial point right after online model so that it can converge fast to the true model parameter and also when the beta the dimensionality of data is large.",
            "That means the length.",
            "Of these beta vectors large then the convergence can be slow, so one idea is that probably we can reduce the dimensionality of this data so that learning can be fast."
        ],
        [
            "And this is our solution and I think everything about the model is in this slide.",
            "So let me go through this slowly so.",
            "This is the regular on line model formulation, right?",
            "You predict the rating of item I user I valuating that user I gave to item J as inner product of two part and the first part is determined offline and the second part is something we want to learn for each item and equivalently you can write down these like a basic model so that the initial point right initial point at least.",
            "On my model would be given us the prior mean and they may have a prior covariance matrix.",
            "OK, and if and idea to find a good initial point is that well if we have features right then we can use features to predict the initial value of these items factors.",
            "Then here we use a linear regression and then this is because this is a multi dimensional vector so the regression weight writes actually.",
            "Metrics right?",
            "So you have a metric weight and based on the available item features, for example category keywords, right?",
            "We predict the initial rating, the initial, the image, that initial item factor values OK. And if we just replace this data by this new formula that you get this equivalent form that is you predict the rating right first by a regression of features, right?",
            "And then if this, if this regression is.",
            "100% accuracy, then there's no need for online learning, right?",
            "But if this is not accurate than we can model right the rest issues or the arrows, or the correction terms right for using an online learning?",
            "OK, notice that the dimensionality of Vijay is the same as dimensionality of data J right, which can be high dimensional.",
            "Then the idea is that probably we can reduce the dimensionality so that the online learning can be faster.",
            "So one way to do that is a linear projection.",
            "So just like PCA piece of principal component analysis right, you project hiding space into a low dimensional space and then then you reduce dimensionality now here.",
            "You are similar idea.",
            "We use a linear projection matrix to project from the high dimensional space of this VJ.",
            "The original space of vectors to a little bit dimensional space so that these Theta J is has much lower dimensionality than these Vijay.",
            "OK, and then we put the initial point of Theta J to be from zero and have a uncorrelated prior.",
            "So if you workout formula basically if you do go back to look at the original.",
            "Factor right?",
            "We want to determine.",
            "It basically has predicted by the regression and has a low rank approximation of the variance covariance matrix.",
            "OK, and this be an A are determined by using historical data or in offline training and in the online part right?",
            "Since AMD has been already determined then.",
            "Well the first part will be just a constant offset.",
            "Just do the computation and get constant offset.",
            "And the second part would equivalently to be a feature vector.",
            "The new feature vector, right?",
            "You do a projection, you get a new feature vector, and then you have a low dimensional model to learn.",
            "And since this low dimensional it can be updated very very quickly.",
            "And there's another question left that is OK. We do dimensionality reduction right then?",
            "What should be the dimensionality that reduced to?",
            "How do we determine this case?",
            "Which is the dimensionality of these?",
            "Small dimensional.",
            "Item sector.",
            "So the idea is simple, we just maintain an example of methods of models, and each model correspond to a candidate key value and then we just pick the best one right in on line manners.",
            "Basically keep a moving window and then we just measure the performance in the moving window and pick the model that has the highest accuracy in that moving window."
        ],
        [
            "So this is a summary, so here is offline model and then this offline model is trend periodically.",
            "We periodically rebuild the offline model using historical data on old items and output right consists of the.",
            "Regression weight metrics, right?",
            "These are the regression rate metrics and the prior variance component, right?",
            "And also the user factor here we consider users are older user.",
            "We do not consider new user coming in but but measures that can be handled symmetrically.",
            "OK, and we're offering training is based on EM algorithm.",
            "So basically you look at this this UUI&J are the hidden variables but you do not observe these factors from the data.",
            "So these are the hidden variables and in the eastep you compute the posterior distribution of these hidden variables and then in the M step right you find the.",
            "Regression weights that maximize the expected log likelihood of your data and expectation is taken over the posterior distribution you computed in step, and we do this iteratively until it converges OK and in the online part is become very simple because the first part because all these are constant or determined in offline, you only need to learn a single vector of vectors for each item, and then this low dimensional is.",
            "Very fast and you can do this.",
            "You can do model update for each item separately and so it's easily to paralyze the entire algorithm.",
            "So so yeah, it's very fast."
        ],
        [
            "So let's look at some experimental results.",
            "We apply this model to three datasets.",
            "One is the my Yahoo data set and then move against data set and also Yahoo front page details that we did not apply this to Netflix because there are no features in Netflix and our model use the features to do a good initial point so.",
            "We do not apply that to Netflix."
        ],
        [
            "In the first set of result we compare different kind of dimensionality reduction methods.",
            "So the first one is the vanilla on my model that do not have any dimensionality reduction and the second model is the purely offline model.",
            "Just use features and then we compare two methods to principal component methods that reduce that optionality that is not using the ratings and then the last one is our method.",
            "And here Y axis is the lift in test log likelihood represent the accuracy of the model, so higher the better.",
            "So you can see all the OR method.",
            "Is much better than others because we are using a supervised way to determine the projection matrix."
        ],
        [
            "And this plot shows the effectiveness of these online selection of number of factors.",
            "So you can see in the very beginning right?",
            "For one factor model perform the best and then the three factor model catches up and then later this more complex model catches up right and these circles are the performance of our selection algorithm.",
            "So as you can see, most of the time we pick the best model."
        ],
        [
            "And also apply to many lands.",
            "And because of time just say on that is much better than."
        ],
        [
            "Others Yep, but Movielens dimensionality is not very effective and then this would need to be investigated."
        ],
        [
            "And on Yahoo Front page this RC curve, the higher the better.",
            "We also see that the new method is better than others."
        ],
        [
            "So in conclusion, recommending time sensitive items is a challenging problem.",
            "At most collaborative filtering method do not work well in this situation.",
            "Our approach is to periodically rebuild the offline model that uses features to predict the initial point of the online learning, and we also reduce the dimensionality for online learning and then the online part is very fast because the dimensionality is low.",
            "And also it is easily parallelizable and also provide a method for online selection.",
            "So if you think about this, what we do is that we use whatever computation power we can to broad to find a good initialization for online model.",
            "And we believe that is a interesting and promising direction for future research.",
            "Thank you.",
            "Chris, let me ask you.",
            "So did you consider instead of using the metrics Bay, just having another two sets of user factors the other set of a much lower dimensionality?",
            "So OK, so Yahoo Dot propose a method that is, you have two set of factors right?",
            "One is low dimensionality, another is potentially large.",
            "Is that right?",
            "Yes, the large one for the regression problem, the left hand side, huh?",
            "For the for the online component used lower dimensionality for the user factor.",
            "Instead, the item factor itself will be of lower them.",
            "They mention yes yeah, but that is a legitimate approach to try, but let's see.",
            "I think this is kind of a special case of our model because you if you think about that dimensionality reduction right then.",
            "Basically you reduce large dimension to smaller one, and if you just set that B2B diagonal just that's just a special case.",
            "Yeah, potentially for their speed up.",
            "OK.",
            "So you said in the beginning that computing the model.",
            "The factorization model is very expensive, but in fact it's not that expensive because you only need to consider, for instance, if you add a new item, you'll soon the users.",
            "Yes, have rated and also.",
            "Very little affect on the other items.",
            "So Yep.",
            "So.",
            "Yeah, So what do you propose is actually the third potential method, right?",
            "That is just just do online learning, right?",
            "So you just keep the original user user factor that is trained offline, right?",
            "And you only update the iconfactory, right?",
            "Price of the service to the.",
            "Users that have rated not.",
            "Yes, yes, so that is also an alternative and.",
            "If you do not update users factor right and they only update the item factor, but you do not do initialization that what we do and you do not do.",
            "Like we do then you would see worse performance.",
            "Some of the.",
            "Yes, maybe just a special case, right?",
            "Just you nischal eyes by zero that you do not do that reduction.",
            "Right, and that is worse than then.",
            "OK, so let's say again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for coming and this is joint work with Deepak Agrawal and Pradeep Delangle at Yahoo Labs.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I don't think I need to address that.",
                    "label": 0
                },
                {
                    "sent": "Recommender systems are useful applications.",
                    "label": 1
                },
                {
                    "sent": "I think everyone come here.",
                    "label": 0
                },
                {
                    "sent": "If you believe that this is useful, at least we have a lot of applications in movie recommendation and also say news article recommendation.",
                    "label": 0
                },
                {
                    "sent": "And you can also recommends a product or friends or whatever you want to recommend.",
                    "label": 1
                },
                {
                    "sent": "So the goal really is that for each user right we want to provide a list of items.",
                    "label": 0
                },
                {
                    "sent": "That the user might like.",
                    "label": 1
                },
                {
                    "sent": "So one common approach is that what we can build a model to predict the rating that a user would give to a unrated item right based on the past activities of all the users and all the ratings.",
                    "label": 1
                },
                {
                    "sent": "And then if we have this model then it's pretty easy.",
                    "label": 1
                },
                {
                    "sent": "We just recommend the items with the highest predicted ratings to the user and here ratings can be explicit like.",
                    "label": 0
                },
                {
                    "sent": "Movie ratings or implicit like click or no click?",
                    "label": 1
                },
                {
                    "sent": "So this approach is quite successful when there are enough passer ratings for each user and each item specifically, well, metric factorization is a very successful method in this space.",
                    "label": 0
                },
                {
                    "sent": "First matters are very fine grained models.",
                    "label": 0
                },
                {
                    "sent": "That means each item and user has a set of factors that need to be learned from the rating data OK, and if you have new item or a new user right, you do not have these factors so that it is challenging to make good recommendation for new users and new items.",
                    "label": 0
                },
                {
                    "sent": "And this is generally called the cold start problem.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's take an example.",
                    "label": 0
                },
                {
                    "sent": "So this is Yahoo front page and this is the Today module and in this module we recommend stories to users, and those stories are popular today, so those stories are new stories right?",
                    "label": 1
                },
                {
                    "sent": "By definition or by the design of this module, we want to recommend new items.",
                    "label": 0
                },
                {
                    "sent": "But usually we do not have factors or historical data right to build factory model for.",
                    "label": 0
                },
                {
                    "sent": "For those new stories.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the other example of this kind of time sensitive items.",
                    "label": 0
                },
                {
                    "sent": "So for example news stories, trending queries.",
                    "label": 1
                },
                {
                    "sent": "So if you look at this here, there's a trending now module which recommend queries that you might like, but and those queries are trending query.",
                    "label": 0
                },
                {
                    "sent": "That means that happens in real time.",
                    "label": 0
                },
                {
                    "sent": "And also updates tweets or events right?",
                    "label": 0
                },
                {
                    "sent": "Those are kind of time sensitive items.",
                    "label": 0
                },
                {
                    "sent": "Challenges one is that we need to build real time data pipeline right?",
                    "label": 0
                },
                {
                    "sent": "That can continuously collect data.",
                    "label": 0
                },
                {
                    "sent": "From these new items, the ratings of these new items and use that to update the model, but that's not something I want to address here.",
                    "label": 0
                },
                {
                    "sent": "What we want to address is the modeling challenges, because this is online because we receive data in online manner and we want to update or another very quickly.",
                    "label": 0
                },
                {
                    "sent": "So there are two basic requirements.",
                    "label": 0
                },
                {
                    "sent": "One is the learning needs to be very fast.",
                    "label": 0
                },
                {
                    "sent": "That is, we want to learn good models for new items using very little data as little as possible.",
                    "label": 1
                },
                {
                    "sent": "A few ideas.",
                    "label": 0
                },
                {
                    "sent": "One is that probably if we build online model, we want to have a natural gas that is without any rating, right?",
                    "label": 0
                },
                {
                    "sent": "We want to.",
                    "label": 0
                },
                {
                    "sent": "Guess the rating to some good extent.",
                    "label": 0
                },
                {
                    "sent": "And also we also run the online model learning to converge very fast very quickly.",
                    "label": 0
                },
                {
                    "sent": "An another requirement is the computation.",
                    "label": 1
                },
                {
                    "sent": "It also to be very quite fast.",
                    "label": 0
                },
                {
                    "sent": "That is, we want to build good model using little time, right?",
                    "label": 0
                },
                {
                    "sent": "And so that means efficient and scaleable and parallelizable algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's think about a few possible approaches, right?",
                    "label": 0
                },
                {
                    "sent": "One is.",
                    "label": 0
                },
                {
                    "sent": "What we call offline feature based regression?",
                    "label": 0
                },
                {
                    "sent": "But is you capture whatever you know about user and items by features, features, user features.",
                    "label": 0
                },
                {
                    "sent": "XI, for example, includes age, gender, location and whatever we know about users.",
                    "label": 1
                },
                {
                    "sent": "Item features include, for example, the category of the item source or entity or keywords extracted from the item, and then we just build a machine learning model.",
                    "label": 0
                },
                {
                    "sent": "Pick whatever you want you like.",
                    "label": 0
                },
                {
                    "sent": "Right model using those features to predict the rating.",
                    "label": 0
                },
                {
                    "sent": "Right here I show one example.",
                    "label": 1
                },
                {
                    "sent": "Watch feature based model which is you predict the rating that user I would give item J as a linear weighted sum right?",
                    "label": 1
                },
                {
                    "sent": "And in this particular model we have a weight for each pair of user feature and item feature.",
                    "label": 0
                },
                {
                    "sent": "OK so basically we take the cross product user features an item features and then you have a weight associated with each entry right?",
                    "label": 0
                },
                {
                    "sent": "In these metrics, and then you just do a weighted stuff that will be your prediction.",
                    "label": 0
                },
                {
                    "sent": "And this is just one example and we will see this example.",
                    "label": 0
                },
                {
                    "sent": "Is this particular model is.",
                    "label": 0
                },
                {
                    "sent": "Really good.",
                    "label": 1
                },
                {
                    "sent": "And I would use metrics form right to describe this model, which is a quadratic quadratic form.",
                    "label": 0
                },
                {
                    "sent": "And well, if you look at this model then you would find a problem that is users having same feature vectors, right?",
                    "label": 0
                },
                {
                    "sent": "Get the same recommendation.",
                    "label": 1
                },
                {
                    "sent": "Basically if 2 user I have the same feature vector then the model cannot distinguish between the two user even if we know a lot of about the user.",
                    "label": 0
                },
                {
                    "sent": "For example, we observe the rating of 1 user for a long period of time, but.",
                    "label": 0
                },
                {
                    "sent": "The feature cannot may not capture that, so that's why usually this feature based regression method or sometimes called content based color filtering is not very accurate.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what people do is do do the collaboratory filtering methods so there are many methods.",
                    "label": 0
                },
                {
                    "sent": "For example similarity based method but.",
                    "label": 0
                },
                {
                    "sent": "The current trend is that factorization methods seem to be much better than similarity based, so I will only look at this factorization based method.",
                    "label": 0
                },
                {
                    "sent": "So basically for each user an item, right we have a vector of factors.",
                    "label": 1
                },
                {
                    "sent": "Factors are learned from rating data.",
                    "label": 0
                },
                {
                    "sent": "OK, so features right by my technologies.",
                    "label": 1
                },
                {
                    "sent": "This features are given or we observed and factors are learned from data.",
                    "label": 1
                },
                {
                    "sent": "OK, and what you do is you model the rating that user I give item J as a inner product of two vectors right?",
                    "label": 0
                },
                {
                    "sent": "And the first one is the user factor vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a set of weights.",
                    "label": 0
                },
                {
                    "sent": "We model weights that we give to each user and we also have the corresponding.",
                    "label": 0
                },
                {
                    "sent": "We also have a vector of factors for each item and then we do prediction, just do a.",
                    "label": 0
                },
                {
                    "sent": "Product right and you can think about this from a metrics form.",
                    "label": 0
                },
                {
                    "sent": "That basically you decompose your rating metrics into.",
                    "label": 0
                },
                {
                    "sent": "Low rank approximation OK, and This is why it is called metrics factorization method.",
                    "label": 1
                },
                {
                    "sent": "This method is pretty good if you have data for every user and every item.",
                    "label": 0
                },
                {
                    "sent": "But if like in our code start setting we have many new item comes in then we don't have those factors then one approach is that probably we can rebuild the model right every time we receive a data point, but rebuilding this model right is kind of very time consuming.",
                    "label": 0
                },
                {
                    "sent": "Probably we can rebuild the model, say once an hour or Wednesday, but doing that one day.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "We would have a lot of new items coming, so there are also many hybrid methods, but there is little attention to fast on line procedures in the literature and that is the focus of this talk.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A simple way to address that is that OK, let's.",
                    "label": 0
                },
                {
                    "sent": "Still predict the ratings that user I gives 2 item J as inner product of two vectors and the first is the item factor for user an.",
                    "label": 1
                },
                {
                    "sent": "Let's say we use historical data right to determine this user factors.",
                    "label": 0
                },
                {
                    "sent": "Right, so in the online setting, this actually you can think of them as features because they are given.",
                    "label": 0
                },
                {
                    "sent": "And what we?",
                    "label": 0
                },
                {
                    "sent": "Need to learn is that well.",
                    "label": 0
                },
                {
                    "sent": "After we receive data right, we want to update this item factor very quickly, OK, and then if you look at this, the first part is fixed or determined by offline training and the second part is actually the regression weight right?",
                    "label": 0
                },
                {
                    "sent": "So then this is just a online regression model you after you receive a rating right?",
                    "label": 0
                },
                {
                    "sent": "You may just quickly update your model.",
                    "label": 0
                },
                {
                    "sent": "And if you want, you can use just features for this UI.",
                    "label": 0
                },
                {
                    "sent": "But if you want to use factors then, well, this is not learned online, but it can be updated periodically, for example daily.",
                    "label": 1
                },
                {
                    "sent": "But this beta, these beta these parameters associated with items need to be updated very quickly because we have many new items coming into the system.",
                    "label": 0
                },
                {
                    "sent": "This approach is promising.",
                    "label": 0
                },
                {
                    "sent": "But took problems.",
                    "label": 0
                },
                {
                    "sent": "We need to address 1.",
                    "label": 0
                },
                {
                    "sent": "Is that what should be the initial point of the model right?",
                    "label": 1
                },
                {
                    "sent": "You can initialize that by zero right?",
                    "label": 0
                },
                {
                    "sent": "All the initial weight to be 0, but that's not going to be the best that you can do, so I really want to find a good initial point right after online model so that it can converge fast to the true model parameter and also when the beta the dimensionality of data is large.",
                    "label": 0
                },
                {
                    "sent": "That means the length.",
                    "label": 0
                },
                {
                    "sent": "Of these beta vectors large then the convergence can be slow, so one idea is that probably we can reduce the dimensionality of this data so that learning can be fast.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is our solution and I think everything about the model is in this slide.",
                    "label": 0
                },
                {
                    "sent": "So let me go through this slowly so.",
                    "label": 0
                },
                {
                    "sent": "This is the regular on line model formulation, right?",
                    "label": 0
                },
                {
                    "sent": "You predict the rating of item I user I valuating that user I gave to item J as inner product of two part and the first part is determined offline and the second part is something we want to learn for each item and equivalently you can write down these like a basic model so that the initial point right initial point at least.",
                    "label": 1
                },
                {
                    "sent": "On my model would be given us the prior mean and they may have a prior covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, and if and idea to find a good initial point is that well if we have features right then we can use features to predict the initial value of these items factors.",
                    "label": 0
                },
                {
                    "sent": "Then here we use a linear regression and then this is because this is a multi dimensional vector so the regression weight writes actually.",
                    "label": 0
                },
                {
                    "sent": "Metrics right?",
                    "label": 0
                },
                {
                    "sent": "So you have a metric weight and based on the available item features, for example category keywords, right?",
                    "label": 0
                },
                {
                    "sent": "We predict the initial rating, the initial, the image, that initial item factor values OK. And if we just replace this data by this new formula that you get this equivalent form that is you predict the rating right first by a regression of features, right?",
                    "label": 0
                },
                {
                    "sent": "And then if this, if this regression is.",
                    "label": 0
                },
                {
                    "sent": "100% accuracy, then there's no need for online learning, right?",
                    "label": 0
                },
                {
                    "sent": "But if this is not accurate than we can model right the rest issues or the arrows, or the correction terms right for using an online learning?",
                    "label": 0
                },
                {
                    "sent": "OK, notice that the dimensionality of Vijay is the same as dimensionality of data J right, which can be high dimensional.",
                    "label": 0
                },
                {
                    "sent": "Then the idea is that probably we can reduce the dimensionality so that the online learning can be faster.",
                    "label": 0
                },
                {
                    "sent": "So one way to do that is a linear projection.",
                    "label": 0
                },
                {
                    "sent": "So just like PCA piece of principal component analysis right, you project hiding space into a low dimensional space and then then you reduce dimensionality now here.",
                    "label": 0
                },
                {
                    "sent": "You are similar idea.",
                    "label": 0
                },
                {
                    "sent": "We use a linear projection matrix to project from the high dimensional space of this VJ.",
                    "label": 0
                },
                {
                    "sent": "The original space of vectors to a little bit dimensional space so that these Theta J is has much lower dimensionality than these Vijay.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we put the initial point of Theta J to be from zero and have a uncorrelated prior.",
                    "label": 0
                },
                {
                    "sent": "So if you workout formula basically if you do go back to look at the original.",
                    "label": 0
                },
                {
                    "sent": "Factor right?",
                    "label": 0
                },
                {
                    "sent": "We want to determine.",
                    "label": 0
                },
                {
                    "sent": "It basically has predicted by the regression and has a low rank approximation of the variance covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, and this be an A are determined by using historical data or in offline training and in the online part right?",
                    "label": 0
                },
                {
                    "sent": "Since AMD has been already determined then.",
                    "label": 0
                },
                {
                    "sent": "Well the first part will be just a constant offset.",
                    "label": 0
                },
                {
                    "sent": "Just do the computation and get constant offset.",
                    "label": 0
                },
                {
                    "sent": "And the second part would equivalently to be a feature vector.",
                    "label": 0
                },
                {
                    "sent": "The new feature vector, right?",
                    "label": 0
                },
                {
                    "sent": "You do a projection, you get a new feature vector, and then you have a low dimensional model to learn.",
                    "label": 0
                },
                {
                    "sent": "And since this low dimensional it can be updated very very quickly.",
                    "label": 0
                },
                {
                    "sent": "And there's another question left that is OK. We do dimensionality reduction right then?",
                    "label": 0
                },
                {
                    "sent": "What should be the dimensionality that reduced to?",
                    "label": 0
                },
                {
                    "sent": "How do we determine this case?",
                    "label": 0
                },
                {
                    "sent": "Which is the dimensionality of these?",
                    "label": 0
                },
                {
                    "sent": "Small dimensional.",
                    "label": 0
                },
                {
                    "sent": "Item sector.",
                    "label": 0
                },
                {
                    "sent": "So the idea is simple, we just maintain an example of methods of models, and each model correspond to a candidate key value and then we just pick the best one right in on line manners.",
                    "label": 0
                },
                {
                    "sent": "Basically keep a moving window and then we just measure the performance in the moving window and pick the model that has the highest accuracy in that moving window.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a summary, so here is offline model and then this offline model is trend periodically.",
                    "label": 0
                },
                {
                    "sent": "We periodically rebuild the offline model using historical data on old items and output right consists of the.",
                    "label": 1
                },
                {
                    "sent": "Regression weight metrics, right?",
                    "label": 0
                },
                {
                    "sent": "These are the regression rate metrics and the prior variance component, right?",
                    "label": 0
                },
                {
                    "sent": "And also the user factor here we consider users are older user.",
                    "label": 0
                },
                {
                    "sent": "We do not consider new user coming in but but measures that can be handled symmetrically.",
                    "label": 0
                },
                {
                    "sent": "OK, and we're offering training is based on EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "So basically you look at this this UUI&J are the hidden variables but you do not observe these factors from the data.",
                    "label": 0
                },
                {
                    "sent": "So these are the hidden variables and in the eastep you compute the posterior distribution of these hidden variables and then in the M step right you find the.",
                    "label": 0
                },
                {
                    "sent": "Regression weights that maximize the expected log likelihood of your data and expectation is taken over the posterior distribution you computed in step, and we do this iteratively until it converges OK and in the online part is become very simple because the first part because all these are constant or determined in offline, you only need to learn a single vector of vectors for each item, and then this low dimensional is.",
                    "label": 0
                },
                {
                    "sent": "Very fast and you can do this.",
                    "label": 0
                },
                {
                    "sent": "You can do model update for each item separately and so it's easily to paralyze the entire algorithm.",
                    "label": 0
                },
                {
                    "sent": "So so yeah, it's very fast.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at some experimental results.",
                    "label": 0
                },
                {
                    "sent": "We apply this model to three datasets.",
                    "label": 0
                },
                {
                    "sent": "One is the my Yahoo data set and then move against data set and also Yahoo front page details that we did not apply this to Netflix because there are no features in Netflix and our model use the features to do a good initial point so.",
                    "label": 0
                },
                {
                    "sent": "We do not apply that to Netflix.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the first set of result we compare different kind of dimensionality reduction methods.",
                    "label": 1
                },
                {
                    "sent": "So the first one is the vanilla on my model that do not have any dimensionality reduction and the second model is the purely offline model.",
                    "label": 0
                },
                {
                    "sent": "Just use features and then we compare two methods to principal component methods that reduce that optionality that is not using the ratings and then the last one is our method.",
                    "label": 1
                },
                {
                    "sent": "And here Y axis is the lift in test log likelihood represent the accuracy of the model, so higher the better.",
                    "label": 0
                },
                {
                    "sent": "So you can see all the OR method.",
                    "label": 0
                },
                {
                    "sent": "Is much better than others because we are using a supervised way to determine the projection matrix.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this plot shows the effectiveness of these online selection of number of factors.",
                    "label": 1
                },
                {
                    "sent": "So you can see in the very beginning right?",
                    "label": 0
                },
                {
                    "sent": "For one factor model perform the best and then the three factor model catches up and then later this more complex model catches up right and these circles are the performance of our selection algorithm.",
                    "label": 1
                },
                {
                    "sent": "So as you can see, most of the time we pick the best model.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also apply to many lands.",
                    "label": 0
                },
                {
                    "sent": "And because of time just say on that is much better than.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Others Yep, but Movielens dimensionality is not very effective and then this would need to be investigated.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on Yahoo Front page this RC curve, the higher the better.",
                    "label": 0
                },
                {
                    "sent": "We also see that the new method is better than others.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, recommending time sensitive items is a challenging problem.",
                    "label": 1
                },
                {
                    "sent": "At most collaborative filtering method do not work well in this situation.",
                    "label": 1
                },
                {
                    "sent": "Our approach is to periodically rebuild the offline model that uses features to predict the initial point of the online learning, and we also reduce the dimensionality for online learning and then the online part is very fast because the dimensionality is low.",
                    "label": 1
                },
                {
                    "sent": "And also it is easily parallelizable and also provide a method for online selection.",
                    "label": 0
                },
                {
                    "sent": "So if you think about this, what we do is that we use whatever computation power we can to broad to find a good initialization for online model.",
                    "label": 0
                },
                {
                    "sent": "And we believe that is a interesting and promising direction for future research.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Chris, let me ask you.",
                    "label": 0
                },
                {
                    "sent": "So did you consider instead of using the metrics Bay, just having another two sets of user factors the other set of a much lower dimensionality?",
                    "label": 0
                },
                {
                    "sent": "So OK, so Yahoo Dot propose a method that is, you have two set of factors right?",
                    "label": 0
                },
                {
                    "sent": "One is low dimensionality, another is potentially large.",
                    "label": 0
                },
                {
                    "sent": "Is that right?",
                    "label": 0
                },
                {
                    "sent": "Yes, the large one for the regression problem, the left hand side, huh?",
                    "label": 0
                },
                {
                    "sent": "For the for the online component used lower dimensionality for the user factor.",
                    "label": 0
                },
                {
                    "sent": "Instead, the item factor itself will be of lower them.",
                    "label": 0
                },
                {
                    "sent": "They mention yes yeah, but that is a legitimate approach to try, but let's see.",
                    "label": 0
                },
                {
                    "sent": "I think this is kind of a special case of our model because you if you think about that dimensionality reduction right then.",
                    "label": 0
                },
                {
                    "sent": "Basically you reduce large dimension to smaller one, and if you just set that B2B diagonal just that's just a special case.",
                    "label": 0
                },
                {
                    "sent": "Yeah, potentially for their speed up.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So you said in the beginning that computing the model.",
                    "label": 0
                },
                {
                    "sent": "The factorization model is very expensive, but in fact it's not that expensive because you only need to consider, for instance, if you add a new item, you'll soon the users.",
                    "label": 0
                },
                {
                    "sent": "Yes, have rated and also.",
                    "label": 0
                },
                {
                    "sent": "Very little affect on the other items.",
                    "label": 0
                },
                {
                    "sent": "So Yep.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, So what do you propose is actually the third potential method, right?",
                    "label": 0
                },
                {
                    "sent": "That is just just do online learning, right?",
                    "label": 0
                },
                {
                    "sent": "So you just keep the original user user factor that is trained offline, right?",
                    "label": 0
                },
                {
                    "sent": "And you only update the iconfactory, right?",
                    "label": 0
                },
                {
                    "sent": "Price of the service to the.",
                    "label": 0
                },
                {
                    "sent": "Users that have rated not.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, so that is also an alternative and.",
                    "label": 0
                },
                {
                    "sent": "If you do not update users factor right and they only update the item factor, but you do not do initialization that what we do and you do not do.",
                    "label": 0
                },
                {
                    "sent": "Like we do then you would see worse performance.",
                    "label": 0
                },
                {
                    "sent": "Some of the.",
                    "label": 0
                },
                {
                    "sent": "Yes, maybe just a special case, right?",
                    "label": 0
                },
                {
                    "sent": "Just you nischal eyes by zero that you do not do that reduction.",
                    "label": 0
                },
                {
                    "sent": "Right, and that is worse than then.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's say again.",
                    "label": 0
                }
            ]
        }
    }
}