{
    "id": "2rq73ai3lklr6riftzovhd4t5ajcipju",
    "title": "No-Free-Lunch Theorems for Transfer Learning",
    "info": {
        "author": [
            "Shai Ben-David, David R. Cheriton School of Computer Science, University of Waterloo"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Structured Data"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_ben_david_nflt/",
    "segmentation": [
        [
            "It's not in the sense of trying to tell you that you cannot do transfer learning with another station, but more in the direction of.",
            "Pointing out the challenges that they think this is this would advance and should they attacked them and try to solve it because I feel the same domain adaptation of transfer learning is one of those areas which are becoming more and more important in real life contracting since we saw so clearly in grown up dogs.",
            "But in terms of the theory, we really don't have satisfactory fearing to support it and what I'm basically going to say today is that the theory that we have so far.",
            "In full file file sort of supporting that kind of application security.",
            "So.",
            "OK."
        ],
        [
            "So I'm going to give some.",
            "General principles and then introduce that.",
            "I think that the main point that I want to introduce is that in order to do an domain adaptation or transfer learning, we must have measures of the relatedness.",
            "So we're going to do some tests.",
            "Measures that we have today and then.",
            "Try to claim that they are not sufficient.",
            "Then we need more formalism to measure task correctly.",
            "Then I'll show some lower bounds and some results that shows the freezing carbon tools that we have.",
            "We cannot do too well and then we talk about some open questions.",
            "OK, so."
        ],
        [
            "The goal, I think, of the hearing here is to figure out when and how the men of the patient is going to succeed.",
            "And then to develop some kind of theoretical background for this, why do we need?",
            "How much time?",
            "Should try to convince you of things, but I think that if we have theoretical bankers don't then we have some type of.",
            "Success guarantees because nowadays you can say here is the algorithm that they use and give it my application and it works nicely on application but now come on elephants uses algorithm.",
            "There's no guarantee that this algorithm will work as well on his application, even if it's on the same application in this instance.",
            "So that always gives us some kind of.",
            "Confidence in our methods.",
            "It helps us understand that when can we when should be inside ministration and when it is.",
            "Pointless, it says.",
            "Choose device running paradigm.",
            "So.",
            "Smarty choose between them.",
            "And of course, if we have theoretical understanding that drive you algorithm.",
            "So hope that you're convinced."
        ],
        [
            "In some a point in time to do rain.",
            "So I think that's the point that I'm trying to.",
            "When I'm my few attempts work with professionals to apply machine learning to count as a consultant to Wear hospital and try to help them and they were very frustrating.",
            "So what they say is they know will give you a lot of data and we will fit into your machine and you will turn off the wheels of your machine and please give back to us some insight, full results and.",
            "If it doesn't work, try it doesn't work, then we can give you more data.",
            "We have lots of things and then if it still doesn't work, then we'll try another consultant.",
            "And I think that's what is missing is understanding of how machine learning works is a really important role of prior knowledge.",
            "We cannot do any learning without domain knowledge about this stuff is not trying to learn so."
        ],
        [
            "Learning requires prior knowledge, I think is something that.",
            "Is not always.",
            "I think you emphasize enough for clearing up, specially not for people that expect this will solve their problems, and so that's basically no learning is possible without applying for analogies and a freelance phenomena that we know from our first class in the machine learning.",
            "I hope that sort of thing they show you in the classroom machine learning.",
            "That's what I do.",
            "And then.",
            "For straightforward precipitation prediction tasks, we know that this prior knowledge takes the form of some inductive bias.",
            "We have some.",
            "Prior knowledge is with info classification task and take the form of some hypothesis class.",
            "We search forward in your classifier, protecting poses some violence from the problem or we use something special tournament and the kernel should somehow extract prior knowledge about their problem and even the choice of features in some tool for incorporating prior knowledge into the solution.",
            "But without prior knowledge we notice we cannot do notification.",
            "Now if we're trying to do more complex.",
            "Like Semi supervised learning.",
            "Send that we need more types of prior knowledge, so if you want to do semisupervised learning for example and notice the famous supervised learning should be in some sense easier than the manifestation because we have unlabeled data from the same problem that you are saying that you have to label.",
            "It should be easier than having unlimited data from a different role.",
            "And already in sentences beginning.",
            "It's not clear how to realize how to add assumptions.",
            "We need assumptions that relates there.",
            "Distribution of the unlabeled data through the language.",
            "So we have we have some and all free lunch stealing from semi supervised learning that shows that without very strong assumptions about how the distribution of under the data related to the labels, there is no hope that semi supervised learning will do anything better than if you just throw away all your animals.",
            "And this is only effects.",
            "Those are made in the patient where we're trying to do a more difficult.",
            "This is coming from.",
            "Not the same task label data folder from another domain domain at the station or in in France for learning.",
            "The prior knowledge that we need is my knowledge.",
            "About the relationship between the shooter and the question is.",
            "Claim that I will be trying to promote is that without very clear formalization of this prior knowledge that we cannot give you any guarantee of success of the medication.",
            "So we need some way of quantifying the relationship between the training distribution and then tested solution."
        ],
        [
            "So let me zoom down a little bit to something more concrete, so the basic conventions I'm going to use this for me or learning problems is distribution over some domain and labels.",
            "So for simplicity, let's assume the labels are binary only 01 and we have a distribution over domain enables, or if not in terministic labels in service solution and we're trying to predict labels in this decision.",
            "And then.",
            "The learner of the dementia patient problem has access to two sources, so it has access to labels.",
            "We have two problems.",
            "We have the problem S which is helpful for us and we have the problem.",
            "See for target.",
            "Each of these problems is a distribution over points with labels.",
            "So you have two distributions over extra CR one and we assume that what the learner has is a sample of the source distribution with the labels.",
            "And the sample.",
            "Of the target distribution without delay.",
            "So this is a clean.",
            "So maybe the pension tax, which in which you don't have any labels from that activity.",
            "Target distribution you only have labels from the South and you have to help you have unlabeled data from the target.",
            "So we different little bit talking about labels for both distributions are maybe a lot from the souls of very few from the sun.",
            "So this is the scenario going to analyze, and in most of the conclusion we can push them also to this scenario in which we have also some examples from the service, but everything is more clear when we take an extreme situation so that the situation is going to analyze and learn.",
            "Our task is to predict the labels of the points which are they labeled by there.",
            "Target distribution.",
            "So we have both and targets labeled examples from the South end of examples of Italian and you want to produce labels.",
            "So of course."
        ],
        [
            "The main question is how should we model there?",
            "Prior knowledge about their relatedness between the two problems and.",
            "Maybe the most obvious desired relatedness is to say that that's acquired this assumption.",
            "To say the labels involved paths are the same.",
            "And that's the core values that I'm saying that it says that the conditional there if you're given a point X.",
            "Zero is the same in both the domain distribution and targeting solution.",
            "This is a very looks like a very strong assumption.",
            "If you remember the like a talk in the morning of.",
            "And in order to have data that shows you this kind of behavior, what he was doing, it was actually taking two samples from the same problem, because when we take samples from two different problems, it is hard to believe that we will have this kind of assumption.",
            "So if you even consider their simplest domain adaptation tasks as soon as I'm trying to try to train from infection on my email.",
            "So I guess the income I have the all the.",
            "Incoming emails or something like in the book and they.",
            "Label them from, not someone I want to build a strong field and I want to exposing two peers email.",
            "Now clearly the distribution of emails that he gets is different than mine in French, right?",
            "Some of them.",
            "You don't get any Hebrew, nothing in April.",
            "Yeah, so we have a different distribution of the domain, but we cannot truly say that both of us are going to make the same markings of the labels given the same the same right?",
            "Maybe when you get something from eBay Newmarket's Farm and I am very interested in what even is advertising and marketing.",
            "Both of us are going to mark similarly some no stomach is very strong, but definitely maybe a certain function if we are able to do anything with another place, and maybe the easiest situation in which the labels of this thing.",
            "So what I'm going to claim is that this assumption, although it looks too strong to be realistic, it is 2 weeks to give you any advantage.",
            "So this is kind of there.",
            "Wrong assumption, you're paying a lot in terms of everything yourself from reality and in return you are getting almost nothing in terms of being able to guarantee.",
            "So that's one of the things I want to emphasize, so here is the first example."
        ],
        [
            "Why is this a very simple thing?",
            "I mean, if you think about it for two minutes, that's the first example.",
            "You see why it assumption that the labels in both tasks are the same notified, so I have here 2 tax.",
            "The blue task enter enter.",
            "And what I wrote here is the density.",
            "So my domain is their line.",
            "That's my domain.",
            "And this is the density function of red tasks required skill.",
            "And this is the density function of the blue task Quincy.",
            "And both of them have the same neighbors.",
            "Once at the neighbors, the neighbors out one all the way through here and zero.",
            "So we do have the covariate shift assumption.",
            "Most of his passes here points here.",
            "There ever will be one, and if in Singapore and feels a little busy.",
            "That's the distributions of different that's happened here.",
            "If I'm not raining on the best solution, I'm going to only see points from here and not going to think point from this night.",
            "All the points that I'm going to see are going to be labeled one, so I'm going to come up with the assumption that the constant function run is a good predictor.",
            "Now I try to take this point, some function one, and then flying through the blue tack and I'll be complete failure, because in this this side where the blue task is generating points.",
            "The label is always filled.",
            "Whatever they have, the coverage is assumption now.",
            "What is the answer of the people are doing provider?",
            "This saying oh but the two distributions need to have the same support.",
            "One has to be an absolutely continuous introspective the other, but then I can very easily corrected because instead of playing with their density, here is zero and cellular assumes that you have 1000 points.",
            "Then I'll assume the density here is 1 / 10,000,000.",
            "It's not zero, it's absolutely continuous.",
            "It's just so small that you're certain size doesn't have anything there.",
            "So that the requirement of being absolute computer suspected other doesn't value much.",
            "Definitely cannot give you any guarantee which is independent of the distribution.",
            "So OK, so that's the simplest example.",
            "Why is the covariance seems doesn't do it also?",
            "Doesn't give us a lot of profit, but what's the solution?",
            "What went wrong here?",
            "What do we want to?",
            "Yeah.",
            "Right, I want to say this is what happened.",
            "Here is if I look at their distributions and compare them at the end of the unlabeled distribution, teams are very powerful.",
            "So what I add to what I have to add, the provider chooses assumption.",
            "That is, I just look at the densities of the unlabeled solutions.",
            "They should not be so this joint.",
            "So let's try to impose this result so.",
            "The conclusion is, as you said, that we also need some relatedness of the unlabeled."
        ],
        [
            "It's not enough to just reason is enable distributions honestly.",
            "So let us see how I'm going to measure relatedness between the unlabeled distribution so.",
            "How do we measure to see what we're trying to do now is to have some?",
            "Hey.",
            "Quantitative way of measuring how close are the two unable distribution?",
            "So the simplest way to do it or the most natural way is to do it with the same total combination or the L1D social relations between two distributions is the Supreme of all measurable sets of the difference of the measure of the weight distribution gives to himself and the weight of the other distribution gains to himself.",
            "Another very common way of measuring the difference between two distributions is a killer.",
            "It turns out that those tools are not very useful.",
            "And not very useful for several reasons.",
            "One important reason is that if your domain is infinite, then we know that there is no way you can estimate the KL, divergent or the total variance from a finite number.",
            "Remember whether we're in the situation we're sitting in what we have, we have a label sample from the source distribution we have in our neighbors and sample from the targeted solution.",
            "We want to somehow estimate how far they are because they want to do with the patient.",
            "And we just included this for the medication we need to make sure the distributions are similar, right?",
            "But if we try to estimate tails aversion or social value for the final samples, there is the thelander tells you that they could be.",
            "Very far apart and no final sample will be able to detect things of interest.",
            "This is a 2 sample problem and that's something which has been investigated a lot and you will just take it.",
            "You cannot do it from the final sample.",
            "You cannot measure the care distance folder, so we need some more.",
            "Relax notion of distance between distribution and the one that we saw."
        ],
        [
            "Just sitting there in the paper one also in 2004.",
            "I wasn't born and I was working on a different problem and the problem of change detection.",
            "So the problem there is assumed that you get a stream of data.",
            "And you want to be able to detect when the source that generates inventor suddenly changes.",
            "That's also an important thing.",
            "I mean, you are watching this market of houses, the real estate market and you want to detect that something is happening.",
            "Suddenly the market begins to heat up and prices are going up.",
            "How can we detect change in the stream?",
            "And that brings us to the problem of you have a sample of what happened last week.",
            "You have a sample of what happened this week.",
            "We want to tell how these two samples likely to have been generated by the Stranger solution.",
            "Weather generated by two different.",
            "So in order to answer this problem, introducing emotional, for instance, so this is a distance between two distributions, and we think that begins with a solution has is parameterized by some massive substance.",
            "So the VHH in the class of subsets or cash to pay for something.",
            "30 H between two distributions, and I use them US and you came here too.",
            "Remind you that we want we want to measure resistances within the Android distribution of the source of the target is defined by Y minus twice the minimum error.",
            "That ain't.",
            "That's when it is trying to distinguish between the two distributions, so this relates to the kind of thing that you mentioned.",
            "So let's I have some class of predictors that they want to use for my problem.",
            "I want to detect spam and say I'm trying to detect it with a linear classifier.",
            "Now I have the distributions of email or.",
            "Maybe solution and here this solution.",
            "I want to measure how different out now I'm going to do it in.",
            "Kind of a funny way, but I'm going to try to find is how well can a linear separator separate between the unlabeled images I got in the unlabeled innocent people if they can be well separated.",
            "If some linear Hospice can tell me very easily this email came from him.",
            "This payment from you then what does it say about the distributions?",
            "Are there closer out of different?",
            "So I can easily detect if a point is coming from under division and from the other.",
            "Then what is tells me about the distance within the solution.",
            "Have everything so therefore my distance is 1 -- 0.",
            "So if I make it the big arrow.",
            "It doesn't make sense.",
            "If I make if I can easily infect then.",
            "The distance is 1.",
            "Can easily detect then we ever is zero and distancing one if it's very hard to detect and I'm making a lot of errors in the distance between two.",
            "Distribution is small.",
            "OK so that's the way we measure distances in a way of measuring the distance with respect to the class wins which we are going to training.",
            "So we are using our prior knowledge about the problem when we measure the distance between two distribution and that's the more relaxed measure, then the KL distance.",
            "So the variance distance.",
            "And then.",
            "OK, so."
        ],
        [
            "Here is an example of how I measured.",
            "It isn't so assume that I want to measure the distance between the blue distributions and the resolution with respect to the class of passphrases.",
            "So here I can find a halfway between separated easily, and in this case I cannot find a hard place.",
            "It will separate them easily, and indeed the distance here is not consistent.",
            "Because this is his .5, because my arrow is .25.",
            "So I have a special way of measuring distances in unable to solutions and now what I'm trying to say is that.",
            "You remember we tried the comparatives assumptions.",
            "Things are both of the same labels.",
            "We see that it doesn't work because of situations which distributions are the same are very different.",
            "Now we have a way of measuring similarity between distributions as it helps.",
            "So let us see if it solves our problem before we just think it's just very bad.",
            "Copying."
        ],
        [
            "From that 04 thanks for the point is that you remember I told you that for the KL, Eastern and for the total variance instance, there's no way that you can estimate the distance from sample.",
            "No final sample with the fight in here we can prove that for this kind of instance we can estimate and from some final samples we have an exponentially.",
            "If you have a sample size and then the probability that the empirical distance between the distribution is different then the truth interesting distribution goes down exponentially.",
            "Faster example.",
            "So we get this nice properties at this kind of distance can be estimated from final stuff.",
            "So that is server problem.",
            "So now what I'm going to show you, it's right now we're going to make."
        ],
        [
            "S stronger claim.",
            "They're going to require.",
            "First of all, the two distributions have the same labeling the covariate shift assumption, and on top of it, we're also going to require that the two unlabeled distributions are indistinguishable.",
            "So now it seems that we are in a better state to guarantee and success of dementia patients right?",
            "And now I'm going to show you exactly since not the case.",
            "So what is in this example so?",
            "But I have, yeah, two distributions that is just there.",
            "Say the density function of the peas and associates solution and the target distribution of the unlabeled points.",
            "The labels written here under so labels are exactly the same 010101, But the density is over distribution.",
            "Not in line one.",
            "Distribution puts the weight on the even intervals and the other solutions put all the rights on their Holdings.",
            "So these two distributions are quite different, But what happens if I try to measure them with respect to my distance?",
            "OK, so let me hope this idea here OK?",
            "So first of all, the comparisons poles and cause in both task and have the same labeling.",
            "Same happening in most.",
            "Secondly, the distance if I tried out so the question is, what is my class?",
            "You never write my new distance depends on the classification.",
            "So to make things very simple here and transparent, my class of authorities in just initial segment.",
            "So I'm trying to sing.",
            "How well can initial segments separate between dissolution addition?",
            "And the answer is initial segments cannot.",
            "Separate between them, they can only.",
            "I mean, if I take in this segment up to here, then the blue distributions will have slightly more weight in their yellow.",
            "If I think it's up to this point and the registration we have slightly more weighted, but there's no initial segment in which I will see a big difference in the weight of the initial segments of the building solution and their registration, so that the new distance that I defined since.",
            "So.",
            "Miss the difference between these two distributions, so the distance between the two distributions in small, the covariate shift?",
            "Also, what about our billing need to use labels from 1 task to protect the advertised?",
            "If I'm training on restart?",
            "See what happens.",
            "All the weight of my distributions is about zero point.",
            "So if I'm getting a training data which is labeled from here, what will be the label that I will see?",
            "Only civil because all the way to split about zero point.",
            "So if I just trained in this and come up with the conclusion that we need to.",
            "0.",
            "Constant zero predictor, but however the concept here is the thing to do here is very badly because this guy is only speaking points for the label is mine.",
            "So we tried to rectify the problem.",
            "We sent them into place and provide safety is not enough.",
            "We need to say that the food distributions are similar.",
            "We try to fix the problem.",
            "We define the notion of similarity between solutions and get through distributions that for this similarity look similar and still there is the failure of the medication.",
            "I am misled to think that the true function is zero and this is going to make a big error here when this guy is just something from the ones instead of something from the view.",
            "So we need another component.",
            "What I'm saying is that what is the component is missing.",
            "The component is missing.",
            "Is something about how the labels of the two tasks.",
            "Calling each other.",
            "But now you have to.",
            "If I was not in the cloud, I would jump and say what do you mean?",
            "You need another assumption about how the label product we make the strongest possible assumption.",
            "We said that the labels are exactly the same as the covariance system.",
            "But we will see that this is one of the longest function we need a different kind of assumption about the relationship between the neighbors.",
            "So what is the assumption that we will have the fear?"
        ],
        [
            "An assumption is that so we introduced another parameter and this is the parameter that is going to measure the agreement between labels, but with respect for my class of apologies age.",
            "So what is the agreement between labels with respect to sacrifice?",
            "It is the minimum overall apologies in my class.",
            "Off the error that causes snakes online distribution and the errors in opposing snakes in the other.",
            "So what I'm introducing here, and you measure of relatedness between the problem these related that has to do with the fixed class of opponents age and what is it saying thanks.",
            "What is I'm trying to find one hypothesis that will go ahead and do a good job on both distribution.",
            "How well can I do?",
            "I'm trying to find one fix typos in the class.",
            "That will minimize and the and I'm doing it.",
            "Same opponent is performing on P and performing on fumes.",
            "So the question is, I'll say there's two types of similar with respect to age.",
            "If I can find in a chair for this, the Singleton instance has a good job on both of them.",
            "No.",
            "It doesn't necessarily mean that we've been able to find such an opponent.",
            "Maybe I'm.",
            "Pushing the logical reasoning here, it's too fast, but one what you should jump now and say.",
            "I mean you solve your problem.",
            "There's nothing left to be done.",
            "I'm trying to look for authorities.",
            "And thanks on the data from.",
            "That and then use it to predict until and.",
            "I assume that there exists to help all these that does well on both of them simultaneously.",
            "But the problem is that having seen only data from Pi, have no clue which of the headphones that asked nicely on team is going to do well on cue as well.",
            "I just notice there exists.",
            "So that's the way that I'm going to measure the similarity of the agreement between the labels of the tool distribution.",
            "And now with this new parameter we are able to religion."
        ],
        [
            "No.",
            "So.",
            "The founders regarding these NIPS 2006 paper.",
            "Says that OK, so let me just explain to you what it is something.",
            "So I have here.",
            "2 tasks that targeting the source.",
            "What I want to estimate is the error of her properties on the target.",
            "And now because it shows me that I can estimate the error of supposing just based on data that I can see.",
            "So the error of opposing the target is bounded by the error on the sample, so I have it enabled.",
            "Sample is coming from the source.",
            "Plus this distance between the two unable distributions that we said that we can estimate it from unlike this point.",
            "Plus this Lambda.",
            "So if the two is the two tasks are related with respect to this measure that there exists an iPod.",
            "This is that when on both of them then the nice thing here is trying to following if there exists to happen.",
            "If it does nicely on both of them, then every I promise that as well on the source will also do well on the target.",
            "How how do I know this time?",
            "Right?",
            "Right now it's not even.",
            "I mean, in order to do things in human resources and they're trying to, I don't know.",
            "I don't know, it just is a way of expressing my assumption about relatedness is important.",
            "It's like when the provider shifts assumption when you assume that both packs have the same labeling, so there's no way you can check it because there's no labeling from the target, but it says this is my.",
            "This is my belief as domain extra things might believe about this problem and we believe provided the disabilities correct, can you give me about right?",
            "I want to.",
            "I want to advise the user.",
            "In other words, circumstances can use a manifestation.",
            "So what I'm saying.",
            "Instead of the very strong assumption that says you can use it only when you believe that things are exactly the same.",
            "Here and thank you can use it when you believe that with the class of the Internet use, there may be a predictor that goes well on both in solution.",
            "But the nice thing about these values sense if there exists a predictor, does not that valuable solution, then every potential that will do well on one will also do well on the other without making any properties.",
            "Yes.",
            "No, so the only thing it was missing then open.",
            "The only thing which is missing is the term that goes down with the sample because what we have here is we watch where you actually uses them.",
            "An error here, not the true error.",
            "And here you have the empirical measure of the distance, not the true L and through measures.",
            "So you have here another term which goes down like this way with me.",
            "Right?",
            "The sound will be very low.",
            "Drink this bound is in some sense is the only found that we have for domain adaptation that guarantees success.",
            "On the other hand, it looks like a not so.",
            "And you know nothing to celebrate, because as you said, this notice looks a bit loose.",
            "So if I repeat.",
            "I was saying that if I had that, if it was the same distribution, what is going to happen if both of them at the same distribution 'cause I'm going to find that the arrow of age on T?",
            "It is less than equal to the Arrow Agency, which is OK.",
            "This is the same thing plus the distance between them, which is 0 which is also nice.",
            "But what I have here is.",
            "Twice the error of the best predictor nature necessarily.",
            "It's not necessarily at my age, but it's twice the best as I can do so.",
            "I have this kind of factor that is annoying.",
            "Anne.",
            "OK, so that was in the.",
            "You know aims to do what I'm going through.",
            "Our conclusions now is that we can show that you cannot get it off.",
            "So we can.",
            "So then, that's the kind of games I'm going to play.",
            "For now, I want to show you that it's bound is an enthusiastic is maybe about it, and we can show that there is a matching lower bound that in some sense all those terms are really needed there.",
            "Unless you come up with a different tool to model relationships.",
            "But if all you know about the relationship between the two sides is this kind of.",
            "Imagine.",
            "And then we can show that this is up to the first of two.",
            "It's the best one.",
            "Correct?",
            "Alright.",
            "So.",
            "Right, so so an option.",
            "So when the moment they have some similar bound that instead of using this using something similar, which is the error of the best hypothesis on S is her own team and the error of the best sources of things on it.",
            "So you can play some games here.",
            "And where was this taken care of?",
            "This would cause cause yeah, so it is very very similar flavor but slightly different.",
            "OK, so so this is where we are we have about we have a guarantee that sound is in some sense based on if you believe there is a good thing on this then this is what you can do.",
            "Things you want your computer so there is a positive.",
            "OK, so.",
            "Candy's bounty improved natural question, OK, so."
        ],
        [
            "The first thing that I wanted to check here, if you say I'm using here, we were talking about 3 parameters 3.",
            "Measures of relatedness between the two to the first one we talked about was the comparative suspension.",
            "We sold it on its own because I restrict assumption doesn't buy you anything.",
            "Then we talked about the Lambda existence of a mutual good, usually good apology and there was the distance between distributions of the age.",
            "So we have three parameters, the question is.",
            "Which how many of them do I need to have simultaneous streams in order to guarantee that reminder patient work?",
            "So it turns out that the comparative doesn't contribute anything?",
            "I mean this there is not sufficient provider changed.",
            "And then this is the distance is not sufficient.",
            "We've already seen it.",
            "The distance between the two distributions are small.",
            "We assume Cooper's shift, for example with the.",
            "Up and down there going there.",
            "So these two do not suffice, and also I'll show you in a minute.",
            "So even if we introduce those who you measure, the comparatives remains useless.",
            "Even in combination with this measure, so we already saw the comparative with this assumption is not sufficient, and I'll just show you that provides users assumption is not."
        ],
        [
            "And then we will go into more, maybe more interesting question.",
            "So now the kind of thing that I'll do now is I'll show you our grammar straight, the failure of combinations of assumptions on a very, very simple example, but.",
            "The fact that those assumptions already breakdown on very simple assumption.",
            "Indicates this and we can generalize it to a more general case, but basically it should give you the flavor of why those assumptions.",
            "No surprise.",
            "So here I'm going to show you that you're going to have covariate shift, perhaps more Lambda budget needs more Lambda.",
            "It means that I have a hypothesis, works well on those information simultaneously and still.",
            "That's the code.",
            "There is a good approach is from one domain which completely fails on the other.",
            "So what is happening here?",
            "Anything for my?",
            "And blue points now a caravan by label.",
            "So blue points are 0.00 label and the red ones are the one labeled.",
            "So let us just make sure that we have the comparative suspension, so we both both tax label this point one label.",
            "This is zero and label this is one or both of the same labeling in real property.",
            "Now we want to make sure that we have more Lambda.",
            "What does it mean in small Lambda is that I have an assumption.",
            "My assumption spaces definition segments to make life simple.",
            "I have an initial segment and these are segments that behaves nicely make small errors on both distribution.",
            "What is going to be the initial segment actually succeed pretty well on both distribution.",
            "Initial segment groups runs all the way to the end of the user segments and heals up.",
            "Something so easily for segments that.",
            "Hello on both together is pretty small.",
            "What is going to be?",
            "So anybody was still on sleep.",
            "So it's going to be like if I take this and something like this initial segment, then it predicts one up to here and see more from here on.",
            "It will make no error on the target distribution because it is on the road to the right, and here it will make that a small.",
            "So I have those two assumptions, but still why we committed to patient?",
            "Same cause.",
            "If I just see the sampling from this distribution, what am I going to see?",
            "I'm going to see 1.1 something else and someone.",
            "No I can't.",
            "I have to choose.",
            "What is my best?",
            "I can't really say something right.",
            "The next question to ask me what will they also do in this case?",
            "If you would have listened to the talk in the morning.",
            "What was the option?",
            "What did you do?",
            "Yeah, OK. Yeah, that's all.",
            "So OK, so problem is funnel and we we we feel at this point this task.",
            "We want to predict this stuff we see here unlabeled points.",
            "We don't know what the label as if we just see the labels here, we're going to be introduced to output the old one assumption, because if you want it better on the radio.",
            "But I see here if you will, but they only count as on here in here I have to extract the Terminal 1.",
            "But I think about a lot of points in this area in the target.",
            "Hi.",
            "Yeah, we wanna do.",
            "We waiting remember we talked about in the morning we talked a lot about that in waiting in here if I see the unlabeled data from the target, I can really weigh my sample.",
            "I can just by seeing her there.",
            "I see a lot of unlabeled examples here.",
            "I can say, oh, there is something funny happening here.",
            "The target is really putting a lot of weight here, so I should not just treat it as a small epsilon.",
            "Ignore it, I should stop my initial signal here.",
            "Will that help?",
            "If your help in this case that we did have in general, right so we waited is something that people really advocate for them at the station.",
            "Get the unlabeled data from the other distribution.",
            "Now when you look at your sample distributions, put weight accordingly to match the other pieces.",
            "Now we will help us, so I hope this is what I put in the next slide."
        ],
        [
            "Right, so yeah, before I talk about this, notice that we have making here issues apps to this point.",
            "We all we're doing is we're just training on the source and then using it for the target, but our training our appointment didn't depend at all on the island of examples of this often target.",
            "This is one of those things that you suggested.",
            "Why not just train on the source and use it for the target and pray that it will work right?",
            "That's what we were doing so far.",
            "Now we are switching.",
            "We're doing something adaptive.",
            "We're not using the best economies on the source, but we're using apologies.",
            "That's really takes into account the fact that we have some unlabeled data that will set up blue enterprise imports.",
            "Right, so we are switching from conservative conservative domain adaptation adaptive algorithm that really takes the new data from target solution into account.",
            "OK, so.",
            "Can we do better by being productive?",
            "Intuitively, we should should help us.",
            "And so the idea of imposing, fighting and the important thing it says, use the target unlabeled samples to reweigh the training samples and choose age that behaves nice with respect to this.",
            "Do waiting of the summer.",
            "So if we never, that's exactly what we saw here."
        ],
        [
            "If we we just see samples from here, we see some few zeros.",
            "You tend to ignore them because there are only a few of them, but now we see a lot of unlabeled data in this area, then will give them all.",
            "This is important.",
            "When will that work?",
            "So you can guess just from the tone of my question.",
            "OK, so.",
            "Here is a case wedding."
        ],
        [
            "Just waiting is saying that because the films that labels here are all one.",
            "Now, the neighbors here or one.",
            "But what does the soul see the so see exactly the same picture, and so before it seems once here refusal on sale.",
            "Lots of ones here and then it goes and sees all there.",
            "Lots of lots of frontier.",
            "So it will say oh, but it doesn't seem to work, suggesting oh, he says, the target really gives a lot of important to this area.",
            "Target groups are not important in this area, so I should really listen to what this area is telling me.",
            "Telling me 0 so I'll make my support this here.",
            "And home.",
            "I predict all those points to be 0 and I feel this.",
            "I was doing the important sampling you see because.",
            "What now this one they always want?",
            "The L in the target is done because if I do.",
            "If I do, we waiting in his me a lot of important to this guy so I'll stop my initial segment.",
            "Here is a big O predict deal from here onwards.",
            "Right, but I can think yes, someone is following listening, but I can fix the comparative easily with this with the traits of this or before.",
            "Because in this area where they can have, if you know these two things and the truth will bring both of them will have labels.",
            "Red, blue, red, blue, red, blue.",
            "But this guy will concentrate on their Blues and this guy in position with the rent.",
            "So I can always fix the compliance things almost for free.",
            "I will also have the small number.",
            "No, I mean no, not now.",
            "Yes.",
            "He doesn't.",
            "It doesn't do enough damage.",
            "Then fix it doesn't really change, but what I'm saying is 1 conclusions we may conclude from here.",
            "So we waiting on its own is maybe adventurous idea because you paying a lot of attention to this area without knowing whether in this area you're labeled agree or don't agree with what we see in the training data.",
            "Maybe the waiting is also good idea.",
            "Maybe there's a better idea.",
            "Maybe we we should their search for a bit earlier.",
            "So what I want to show you now is that nothing will work.",
            "It doesn't matter what you just write, why.",
            "And then we're almost there because.",
            "Look at this situation."
        ],
        [
            "And so we sell 2 examples."
        ],
        [
            "We saw this target.",
            "Now notice that from the point of view of the learner, what does the learner see?",
            "The learner says the labels.",
            "Here the neighbors here were the same in both examples.",
            "And then Learner sees unlabeled data from this distribution, unlabeled data from the solution are the same faulty inferences price.",
            "So from the point of view of the learner, you cannot distinguish between these two cases between 10 people.",
            "So whatever idea not idea, wonderful again that only comes up.",
            "An error on T classes ever onto prime within one, so at least on one of them will they can ever have.",
            "So no matter what you come up with, there will be a dissolution.",
            "On which you are going to do your beautiful trick and make an air of 1/2, which is not that good is predicting his talking points.",
            "So what this is, it's not, the problem was not that the waiting was a better year.",
            "The problem is that we don't have enough information if we just make those assumptions and so.",
            "And to do better than.",
            "What we need from the London was in here my landing small, but the distance within this distribution.",
            "My bound it says it goes.",
            "The distance is small in land Lakes Mall is driving and not.",
            "I'm creating a lot of cultures that as with everything I own children.",
            "The sound is right if I know that both and this morning the distances, but here Lambda is small but the distance is easy, solution is big and in that case there waiting was supposed to help us.",
            "If we see that we cannot guarantee success of their waiting and we can do the guarantee of success of any other three.",
            "We really need both assumption, both the Lambda entities.",
            "So.",
            "Alright, so you guys put this comment in the fridge."
        ],
        [
            "Site."
        ],
        [
            "Anyway, so in a similar fashion without, I don't know.",
            "It's too tired, but it's the same kind of tricks you know once you see this trick.",
            "Once you can apply it again, we can really show that the balance that we have is in some sense cannot be improved unless you come up with a new notion of relatedness with a new type of assumption of relatedness within this sub."
        ],
        [
            "So.",
            "No domain in the patient is possible without assuming relatedness between that numbers in solution.",
            "So that's taking over Korea seems without point even point.",
            "Anne and we can come up with examples that demonstrate that this assumption is not the side.",
            "No algorithm will succeed if you only have the Lambda assumption and not too late for them.",
            "So they all the exams will be seen so far, so that that.",
            "Their conservative assumptions just trained on the source windows.",
            "This is what I'm saying is that in the same way when we produce two matching painting frames, we can show that it is not a problem of the conservative approach.",
            "Any approach will fail if you don't take care of simultaneously of both the unable distance between distributions and the Lambda instances regulators.",
            "Both of them are required in order to guarantee.",
            "Regardless of what algorithm used in particularly waiting.",
            "So."
        ],
        [
            "The major remaining open question is OK. Can we seem so we can show that our bound is optimal after samples too.",
            "So maybe you can still get rid of this structure, so I don't know it.",
            "I think more important is find new relationship parameters.",
            "That's.",
            "Will be more useful and tell us why do we succeed in the meditation when we're doing this?",
            "What was the thing you were predicting?",
            "How do you .5 senses?",
            "Why does this work now?",
            "Can we come up with some kind of general notion of relatedness that will explain when going into fashion when works, and then when the note which will be better than those two parameters that can work with now an?",
            "And then.",
            "Maybe come up with different adaptive algorithms, but again, it's all depends on having a good.",
            "User friendly.",
            "Useful relatedness note.",
            "So we have to come up with new notions of connectedness and those notions of correctness should clarify two things.",
            "On one hand, when you go to the biology or you go to the data, the information retrieval person, it would make sense to this.",
            "Because you want to tell them that this assumption holds in your situation, and if your intention is, you know.",
            "There exists an outcast S cannon such as blah blah blah blah blah.",
            "It would not make sense to them.",
            "They will not have intuition about.",
            "And on the other hand, you want these assumptions will be such that it is useful to show to develop algorithms and to drive.",
            "So there's a lot through.",
            "Clearly we think works in practice and as I was trying to demonstrate, their clearance hearing is well well behind.",
            "In trying to explain why it was.",
            "So I mean, this could be some type of assumptions that you want to make, but if you look at like the gene prediction problem, you don't have the such a clear geometry.",
            "Not in many problems you don't have.",
            "I mean not all problems are on the real line.",
            "Maybe first of all, I really encourage you to think such assumptions, and so if you're problem has a.",
            "You know Euclidean domain.",
            "Then sometimes you know we can pull things like that.",
            "We can pull this over your prison domain.",
            "Nearest neighbor works very well and just depends on the Lipschitz condition of how the label change.",
            "So in some situations we do have found that you can base on smoothness assumptions and if they work at least for you.",
            "But there are two things we have to be able to show.",
            "It is just one counterexample.",
            "I mean I'm very good at coming up with something that will not be able to.",
            "And the other thing is we want think this will work for other domains where things are not completed like all the meaning the microbiology problems is a really hard problem but but that's kind of the challenges that.",
            "Right?",
            "Alright, so that's all the questions here.",
            "One question is what can you do when you have only very few targets labels, and I think my point is very few target table and all those examples will extend, so just needed to be quicker.",
            "The other question is if I have a lot of targets and the loss of so when should I combine them and when will this combination gives me an advantage and less than like the multi task learning problem is another problem.",
            "Very interesting problem but it has a flat roof system.",
            "Different things.",
            "Wonderful.",
            "Oh yeah.",
            "Yeah but yeah, that would help.",
            "That's what happened at the very very strong assumption is because the people don't realize.",
            "I mean, they say the tales of urgency is not too large and just want to say they look to me similar, but the child offenders can think on points that you don't think that that's basically half of our achieved plus scales or gotten small.",
            "It's actually in saying that it's the same problem.",
            "So the two are the same problem.",
            "They can do it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's not in the sense of trying to tell you that you cannot do transfer learning with another station, but more in the direction of.",
                    "label": 0
                },
                {
                    "sent": "Pointing out the challenges that they think this is this would advance and should they attacked them and try to solve it because I feel the same domain adaptation of transfer learning is one of those areas which are becoming more and more important in real life contracting since we saw so clearly in grown up dogs.",
                    "label": 1
                },
                {
                    "sent": "But in terms of the theory, we really don't have satisfactory fearing to support it and what I'm basically going to say today is that the theory that we have so far.",
                    "label": 0
                },
                {
                    "sent": "In full file file sort of supporting that kind of application security.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to give some.",
                    "label": 0
                },
                {
                    "sent": "General principles and then introduce that.",
                    "label": 0
                },
                {
                    "sent": "I think that the main point that I want to introduce is that in order to do an domain adaptation or transfer learning, we must have measures of the relatedness.",
                    "label": 1
                },
                {
                    "sent": "So we're going to do some tests.",
                    "label": 0
                },
                {
                    "sent": "Measures that we have today and then.",
                    "label": 0
                },
                {
                    "sent": "Try to claim that they are not sufficient.",
                    "label": 0
                },
                {
                    "sent": "Then we need more formalism to measure task correctly.",
                    "label": 0
                },
                {
                    "sent": "Then I'll show some lower bounds and some results that shows the freezing carbon tools that we have.",
                    "label": 0
                },
                {
                    "sent": "We cannot do too well and then we talk about some open questions.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The goal, I think, of the hearing here is to figure out when and how the men of the patient is going to succeed.",
                    "label": 1
                },
                {
                    "sent": "And then to develop some kind of theoretical background for this, why do we need?",
                    "label": 0
                },
                {
                    "sent": "How much time?",
                    "label": 0
                },
                {
                    "sent": "Should try to convince you of things, but I think that if we have theoretical bankers don't then we have some type of.",
                    "label": 0
                },
                {
                    "sent": "Success guarantees because nowadays you can say here is the algorithm that they use and give it my application and it works nicely on application but now come on elephants uses algorithm.",
                    "label": 0
                },
                {
                    "sent": "There's no guarantee that this algorithm will work as well on his application, even if it's on the same application in this instance.",
                    "label": 0
                },
                {
                    "sent": "So that always gives us some kind of.",
                    "label": 0
                },
                {
                    "sent": "Confidence in our methods.",
                    "label": 0
                },
                {
                    "sent": "It helps us understand that when can we when should be inside ministration and when it is.",
                    "label": 0
                },
                {
                    "sent": "Pointless, it says.",
                    "label": 0
                },
                {
                    "sent": "Choose device running paradigm.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Smarty choose between them.",
                    "label": 0
                },
                {
                    "sent": "And of course, if we have theoretical understanding that drive you algorithm.",
                    "label": 0
                },
                {
                    "sent": "So hope that you're convinced.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In some a point in time to do rain.",
                    "label": 0
                },
                {
                    "sent": "So I think that's the point that I'm trying to.",
                    "label": 0
                },
                {
                    "sent": "When I'm my few attempts work with professionals to apply machine learning to count as a consultant to Wear hospital and try to help them and they were very frustrating.",
                    "label": 0
                },
                {
                    "sent": "So what they say is they know will give you a lot of data and we will fit into your machine and you will turn off the wheels of your machine and please give back to us some insight, full results and.",
                    "label": 0
                },
                {
                    "sent": "If it doesn't work, try it doesn't work, then we can give you more data.",
                    "label": 1
                },
                {
                    "sent": "We have lots of things and then if it still doesn't work, then we'll try another consultant.",
                    "label": 0
                },
                {
                    "sent": "And I think that's what is missing is understanding of how machine learning works is a really important role of prior knowledge.",
                    "label": 0
                },
                {
                    "sent": "We cannot do any learning without domain knowledge about this stuff is not trying to learn so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning requires prior knowledge, I think is something that.",
                    "label": 1
                },
                {
                    "sent": "Is not always.",
                    "label": 0
                },
                {
                    "sent": "I think you emphasize enough for clearing up, specially not for people that expect this will solve their problems, and so that's basically no learning is possible without applying for analogies and a freelance phenomena that we know from our first class in the machine learning.",
                    "label": 0
                },
                {
                    "sent": "I hope that sort of thing they show you in the classroom machine learning.",
                    "label": 0
                },
                {
                    "sent": "That's what I do.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "For straightforward precipitation prediction tasks, we know that this prior knowledge takes the form of some inductive bias.",
                    "label": 1
                },
                {
                    "sent": "We have some.",
                    "label": 0
                },
                {
                    "sent": "Prior knowledge is with info classification task and take the form of some hypothesis class.",
                    "label": 0
                },
                {
                    "sent": "We search forward in your classifier, protecting poses some violence from the problem or we use something special tournament and the kernel should somehow extract prior knowledge about their problem and even the choice of features in some tool for incorporating prior knowledge into the solution.",
                    "label": 0
                },
                {
                    "sent": "But without prior knowledge we notice we cannot do notification.",
                    "label": 0
                },
                {
                    "sent": "Now if we're trying to do more complex.",
                    "label": 0
                },
                {
                    "sent": "Like Semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Send that we need more types of prior knowledge, so if you want to do semisupervised learning for example and notice the famous supervised learning should be in some sense easier than the manifestation because we have unlabeled data from the same problem that you are saying that you have to label.",
                    "label": 0
                },
                {
                    "sent": "It should be easier than having unlimited data from a different role.",
                    "label": 0
                },
                {
                    "sent": "And already in sentences beginning.",
                    "label": 0
                },
                {
                    "sent": "It's not clear how to realize how to add assumptions.",
                    "label": 0
                },
                {
                    "sent": "We need assumptions that relates there.",
                    "label": 0
                },
                {
                    "sent": "Distribution of the unlabeled data through the language.",
                    "label": 0
                },
                {
                    "sent": "So we have we have some and all free lunch stealing from semi supervised learning that shows that without very strong assumptions about how the distribution of under the data related to the labels, there is no hope that semi supervised learning will do anything better than if you just throw away all your animals.",
                    "label": 0
                },
                {
                    "sent": "And this is only effects.",
                    "label": 0
                },
                {
                    "sent": "Those are made in the patient where we're trying to do a more difficult.",
                    "label": 0
                },
                {
                    "sent": "This is coming from.",
                    "label": 0
                },
                {
                    "sent": "Not the same task label data folder from another domain domain at the station or in in France for learning.",
                    "label": 0
                },
                {
                    "sent": "The prior knowledge that we need is my knowledge.",
                    "label": 1
                },
                {
                    "sent": "About the relationship between the shooter and the question is.",
                    "label": 1
                },
                {
                    "sent": "Claim that I will be trying to promote is that without very clear formalization of this prior knowledge that we cannot give you any guarantee of success of the medication.",
                    "label": 0
                },
                {
                    "sent": "So we need some way of quantifying the relationship between the training distribution and then tested solution.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me zoom down a little bit to something more concrete, so the basic conventions I'm going to use this for me or learning problems is distribution over some domain and labels.",
                    "label": 0
                },
                {
                    "sent": "So for simplicity, let's assume the labels are binary only 01 and we have a distribution over domain enables, or if not in terministic labels in service solution and we're trying to predict labels in this decision.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "The learner of the dementia patient problem has access to two sources, so it has access to labels.",
                    "label": 1
                },
                {
                    "sent": "We have two problems.",
                    "label": 0
                },
                {
                    "sent": "We have the problem S which is helpful for us and we have the problem.",
                    "label": 0
                },
                {
                    "sent": "See for target.",
                    "label": 0
                },
                {
                    "sent": "Each of these problems is a distribution over points with labels.",
                    "label": 1
                },
                {
                    "sent": "So you have two distributions over extra CR one and we assume that what the learner has is a sample of the source distribution with the labels.",
                    "label": 0
                },
                {
                    "sent": "And the sample.",
                    "label": 0
                },
                {
                    "sent": "Of the target distribution without delay.",
                    "label": 0
                },
                {
                    "sent": "So this is a clean.",
                    "label": 0
                },
                {
                    "sent": "So maybe the pension tax, which in which you don't have any labels from that activity.",
                    "label": 0
                },
                {
                    "sent": "Target distribution you only have labels from the South and you have to help you have unlabeled data from the target.",
                    "label": 0
                },
                {
                    "sent": "So we different little bit talking about labels for both distributions are maybe a lot from the souls of very few from the sun.",
                    "label": 0
                },
                {
                    "sent": "So this is the scenario going to analyze, and in most of the conclusion we can push them also to this scenario in which we have also some examples from the service, but everything is more clear when we take an extreme situation so that the situation is going to analyze and learn.",
                    "label": 0
                },
                {
                    "sent": "Our task is to predict the labels of the points which are they labeled by there.",
                    "label": 1
                },
                {
                    "sent": "Target distribution.",
                    "label": 0
                },
                {
                    "sent": "So we have both and targets labeled examples from the South end of examples of Italian and you want to produce labels.",
                    "label": 0
                },
                {
                    "sent": "So of course.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main question is how should we model there?",
                    "label": 1
                },
                {
                    "sent": "Prior knowledge about their relatedness between the two problems and.",
                    "label": 1
                },
                {
                    "sent": "Maybe the most obvious desired relatedness is to say that that's acquired this assumption.",
                    "label": 1
                },
                {
                    "sent": "To say the labels involved paths are the same.",
                    "label": 0
                },
                {
                    "sent": "And that's the core values that I'm saying that it says that the conditional there if you're given a point X.",
                    "label": 0
                },
                {
                    "sent": "Zero is the same in both the domain distribution and targeting solution.",
                    "label": 1
                },
                {
                    "sent": "This is a very looks like a very strong assumption.",
                    "label": 0
                },
                {
                    "sent": "If you remember the like a talk in the morning of.",
                    "label": 0
                },
                {
                    "sent": "And in order to have data that shows you this kind of behavior, what he was doing, it was actually taking two samples from the same problem, because when we take samples from two different problems, it is hard to believe that we will have this kind of assumption.",
                    "label": 0
                },
                {
                    "sent": "So if you even consider their simplest domain adaptation tasks as soon as I'm trying to try to train from infection on my email.",
                    "label": 0
                },
                {
                    "sent": "So I guess the income I have the all the.",
                    "label": 0
                },
                {
                    "sent": "Incoming emails or something like in the book and they.",
                    "label": 0
                },
                {
                    "sent": "Label them from, not someone I want to build a strong field and I want to exposing two peers email.",
                    "label": 0
                },
                {
                    "sent": "Now clearly the distribution of emails that he gets is different than mine in French, right?",
                    "label": 0
                },
                {
                    "sent": "Some of them.",
                    "label": 0
                },
                {
                    "sent": "You don't get any Hebrew, nothing in April.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we have a different distribution of the domain, but we cannot truly say that both of us are going to make the same markings of the labels given the same the same right?",
                    "label": 1
                },
                {
                    "sent": "Maybe when you get something from eBay Newmarket's Farm and I am very interested in what even is advertising and marketing.",
                    "label": 0
                },
                {
                    "sent": "Both of us are going to mark similarly some no stomach is very strong, but definitely maybe a certain function if we are able to do anything with another place, and maybe the easiest situation in which the labels of this thing.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to claim is that this assumption, although it looks too strong to be realistic, it is 2 weeks to give you any advantage.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of there.",
                    "label": 0
                },
                {
                    "sent": "Wrong assumption, you're paying a lot in terms of everything yourself from reality and in return you are getting almost nothing in terms of being able to guarantee.",
                    "label": 0
                },
                {
                    "sent": "So that's one of the things I want to emphasize, so here is the first example.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is this a very simple thing?",
                    "label": 0
                },
                {
                    "sent": "I mean, if you think about it for two minutes, that's the first example.",
                    "label": 0
                },
                {
                    "sent": "You see why it assumption that the labels in both tasks are the same notified, so I have here 2 tax.",
                    "label": 0
                },
                {
                    "sent": "The blue task enter enter.",
                    "label": 0
                },
                {
                    "sent": "And what I wrote here is the density.",
                    "label": 0
                },
                {
                    "sent": "So my domain is their line.",
                    "label": 0
                },
                {
                    "sent": "That's my domain.",
                    "label": 0
                },
                {
                    "sent": "And this is the density function of red tasks required skill.",
                    "label": 0
                },
                {
                    "sent": "And this is the density function of the blue task Quincy.",
                    "label": 0
                },
                {
                    "sent": "And both of them have the same neighbors.",
                    "label": 0
                },
                {
                    "sent": "Once at the neighbors, the neighbors out one all the way through here and zero.",
                    "label": 0
                },
                {
                    "sent": "So we do have the covariate shift assumption.",
                    "label": 1
                },
                {
                    "sent": "Most of his passes here points here.",
                    "label": 0
                },
                {
                    "sent": "There ever will be one, and if in Singapore and feels a little busy.",
                    "label": 0
                },
                {
                    "sent": "That's the distributions of different that's happened here.",
                    "label": 0
                },
                {
                    "sent": "If I'm not raining on the best solution, I'm going to only see points from here and not going to think point from this night.",
                    "label": 0
                },
                {
                    "sent": "All the points that I'm going to see are going to be labeled one, so I'm going to come up with the assumption that the constant function run is a good predictor.",
                    "label": 0
                },
                {
                    "sent": "Now I try to take this point, some function one, and then flying through the blue tack and I'll be complete failure, because in this this side where the blue task is generating points.",
                    "label": 0
                },
                {
                    "sent": "The label is always filled.",
                    "label": 0
                },
                {
                    "sent": "Whatever they have, the coverage is assumption now.",
                    "label": 0
                },
                {
                    "sent": "What is the answer of the people are doing provider?",
                    "label": 0
                },
                {
                    "sent": "This saying oh but the two distributions need to have the same support.",
                    "label": 0
                },
                {
                    "sent": "One has to be an absolutely continuous introspective the other, but then I can very easily corrected because instead of playing with their density, here is zero and cellular assumes that you have 1000 points.",
                    "label": 0
                },
                {
                    "sent": "Then I'll assume the density here is 1 / 10,000,000.",
                    "label": 0
                },
                {
                    "sent": "It's not zero, it's absolutely continuous.",
                    "label": 0
                },
                {
                    "sent": "It's just so small that you're certain size doesn't have anything there.",
                    "label": 0
                },
                {
                    "sent": "So that the requirement of being absolute computer suspected other doesn't value much.",
                    "label": 0
                },
                {
                    "sent": "Definitely cannot give you any guarantee which is independent of the distribution.",
                    "label": 0
                },
                {
                    "sent": "So OK, so that's the simplest example.",
                    "label": 0
                },
                {
                    "sent": "Why is the covariance seems doesn't do it also?",
                    "label": 0
                },
                {
                    "sent": "Doesn't give us a lot of profit, but what's the solution?",
                    "label": 0
                },
                {
                    "sent": "What went wrong here?",
                    "label": 0
                },
                {
                    "sent": "What do we want to?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, I want to say this is what happened.",
                    "label": 0
                },
                {
                    "sent": "Here is if I look at their distributions and compare them at the end of the unlabeled distribution, teams are very powerful.",
                    "label": 0
                },
                {
                    "sent": "So what I add to what I have to add, the provider chooses assumption.",
                    "label": 0
                },
                {
                    "sent": "That is, I just look at the densities of the unlabeled solutions.",
                    "label": 0
                },
                {
                    "sent": "They should not be so this joint.",
                    "label": 0
                },
                {
                    "sent": "So let's try to impose this result so.",
                    "label": 0
                },
                {
                    "sent": "The conclusion is, as you said, that we also need some relatedness of the unlabeled.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not enough to just reason is enable distributions honestly.",
                    "label": 0
                },
                {
                    "sent": "So let us see how I'm going to measure relatedness between the unlabeled distribution so.",
                    "label": 0
                },
                {
                    "sent": "How do we measure to see what we're trying to do now is to have some?",
                    "label": 0
                },
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "Quantitative way of measuring how close are the two unable distribution?",
                    "label": 0
                },
                {
                    "sent": "So the simplest way to do it or the most natural way is to do it with the same total combination or the L1D social relations between two distributions is the Supreme of all measurable sets of the difference of the measure of the weight distribution gives to himself and the weight of the other distribution gains to himself.",
                    "label": 0
                },
                {
                    "sent": "Another very common way of measuring the difference between two distributions is a killer.",
                    "label": 0
                },
                {
                    "sent": "It turns out that those tools are not very useful.",
                    "label": 0
                },
                {
                    "sent": "And not very useful for several reasons.",
                    "label": 0
                },
                {
                    "sent": "One important reason is that if your domain is infinite, then we know that there is no way you can estimate the KL, divergent or the total variance from a finite number.",
                    "label": 0
                },
                {
                    "sent": "Remember whether we're in the situation we're sitting in what we have, we have a label sample from the source distribution we have in our neighbors and sample from the targeted solution.",
                    "label": 0
                },
                {
                    "sent": "We want to somehow estimate how far they are because they want to do with the patient.",
                    "label": 0
                },
                {
                    "sent": "And we just included this for the medication we need to make sure the distributions are similar, right?",
                    "label": 0
                },
                {
                    "sent": "But if we try to estimate tails aversion or social value for the final samples, there is the thelander tells you that they could be.",
                    "label": 0
                },
                {
                    "sent": "Very far apart and no final sample will be able to detect things of interest.",
                    "label": 0
                },
                {
                    "sent": "This is a 2 sample problem and that's something which has been investigated a lot and you will just take it.",
                    "label": 0
                },
                {
                    "sent": "You cannot do it from the final sample.",
                    "label": 0
                },
                {
                    "sent": "You cannot measure the care distance folder, so we need some more.",
                    "label": 0
                },
                {
                    "sent": "Relax notion of distance between distribution and the one that we saw.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just sitting there in the paper one also in 2004.",
                    "label": 0
                },
                {
                    "sent": "I wasn't born and I was working on a different problem and the problem of change detection.",
                    "label": 0
                },
                {
                    "sent": "So the problem there is assumed that you get a stream of data.",
                    "label": 0
                },
                {
                    "sent": "And you want to be able to detect when the source that generates inventor suddenly changes.",
                    "label": 0
                },
                {
                    "sent": "That's also an important thing.",
                    "label": 0
                },
                {
                    "sent": "I mean, you are watching this market of houses, the real estate market and you want to detect that something is happening.",
                    "label": 0
                },
                {
                    "sent": "Suddenly the market begins to heat up and prices are going up.",
                    "label": 0
                },
                {
                    "sent": "How can we detect change in the stream?",
                    "label": 0
                },
                {
                    "sent": "And that brings us to the problem of you have a sample of what happened last week.",
                    "label": 0
                },
                {
                    "sent": "You have a sample of what happened this week.",
                    "label": 0
                },
                {
                    "sent": "We want to tell how these two samples likely to have been generated by the Stranger solution.",
                    "label": 0
                },
                {
                    "sent": "Weather generated by two different.",
                    "label": 0
                },
                {
                    "sent": "So in order to answer this problem, introducing emotional, for instance, so this is a distance between two distributions, and we think that begins with a solution has is parameterized by some massive substance.",
                    "label": 0
                },
                {
                    "sent": "So the VHH in the class of subsets or cash to pay for something.",
                    "label": 1
                },
                {
                    "sent": "30 H between two distributions, and I use them US and you came here too.",
                    "label": 0
                },
                {
                    "sent": "Remind you that we want we want to measure resistances within the Android distribution of the source of the target is defined by Y minus twice the minimum error.",
                    "label": 0
                },
                {
                    "sent": "That ain't.",
                    "label": 1
                },
                {
                    "sent": "That's when it is trying to distinguish between the two distributions, so this relates to the kind of thing that you mentioned.",
                    "label": 0
                },
                {
                    "sent": "So let's I have some class of predictors that they want to use for my problem.",
                    "label": 1
                },
                {
                    "sent": "I want to detect spam and say I'm trying to detect it with a linear classifier.",
                    "label": 1
                },
                {
                    "sent": "Now I have the distributions of email or.",
                    "label": 0
                },
                {
                    "sent": "Maybe solution and here this solution.",
                    "label": 0
                },
                {
                    "sent": "I want to measure how different out now I'm going to do it in.",
                    "label": 0
                },
                {
                    "sent": "Kind of a funny way, but I'm going to try to find is how well can a linear separator separate between the unlabeled images I got in the unlabeled innocent people if they can be well separated.",
                    "label": 0
                },
                {
                    "sent": "If some linear Hospice can tell me very easily this email came from him.",
                    "label": 0
                },
                {
                    "sent": "This payment from you then what does it say about the distributions?",
                    "label": 0
                },
                {
                    "sent": "Are there closer out of different?",
                    "label": 0
                },
                {
                    "sent": "So I can easily detect if a point is coming from under division and from the other.",
                    "label": 0
                },
                {
                    "sent": "Then what is tells me about the distance within the solution.",
                    "label": 0
                },
                {
                    "sent": "Have everything so therefore my distance is 1 -- 0.",
                    "label": 0
                },
                {
                    "sent": "So if I make it the big arrow.",
                    "label": 0
                },
                {
                    "sent": "It doesn't make sense.",
                    "label": 0
                },
                {
                    "sent": "If I make if I can easily infect then.",
                    "label": 0
                },
                {
                    "sent": "The distance is 1.",
                    "label": 0
                },
                {
                    "sent": "Can easily detect then we ever is zero and distancing one if it's very hard to detect and I'm making a lot of errors in the distance between two.",
                    "label": 0
                },
                {
                    "sent": "Distribution is small.",
                    "label": 0
                },
                {
                    "sent": "OK so that's the way we measure distances in a way of measuring the distance with respect to the class wins which we are going to training.",
                    "label": 0
                },
                {
                    "sent": "So we are using our prior knowledge about the problem when we measure the distance between two distribution and that's the more relaxed measure, then the KL distance.",
                    "label": 0
                },
                {
                    "sent": "So the variance distance.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is an example of how I measured.",
                    "label": 0
                },
                {
                    "sent": "It isn't so assume that I want to measure the distance between the blue distributions and the resolution with respect to the class of passphrases.",
                    "label": 0
                },
                {
                    "sent": "So here I can find a halfway between separated easily, and in this case I cannot find a hard place.",
                    "label": 0
                },
                {
                    "sent": "It will separate them easily, and indeed the distance here is not consistent.",
                    "label": 0
                },
                {
                    "sent": "Because this is his .5, because my arrow is .25.",
                    "label": 0
                },
                {
                    "sent": "So I have a special way of measuring distances in unable to solutions and now what I'm trying to say is that.",
                    "label": 0
                },
                {
                    "sent": "You remember we tried the comparatives assumptions.",
                    "label": 0
                },
                {
                    "sent": "Things are both of the same labels.",
                    "label": 1
                },
                {
                    "sent": "We see that it doesn't work because of situations which distributions are the same are very different.",
                    "label": 0
                },
                {
                    "sent": "Now we have a way of measuring similarity between distributions as it helps.",
                    "label": 0
                },
                {
                    "sent": "So let us see if it solves our problem before we just think it's just very bad.",
                    "label": 0
                },
                {
                    "sent": "Copying.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From that 04 thanks for the point is that you remember I told you that for the KL, Eastern and for the total variance instance, there's no way that you can estimate the distance from sample.",
                    "label": 0
                },
                {
                    "sent": "No final sample with the fight in here we can prove that for this kind of instance we can estimate and from some final samples we have an exponentially.",
                    "label": 0
                },
                {
                    "sent": "If you have a sample size and then the probability that the empirical distance between the distribution is different then the truth interesting distribution goes down exponentially.",
                    "label": 0
                },
                {
                    "sent": "Faster example.",
                    "label": 0
                },
                {
                    "sent": "So we get this nice properties at this kind of distance can be estimated from final stuff.",
                    "label": 0
                },
                {
                    "sent": "So that is server problem.",
                    "label": 0
                },
                {
                    "sent": "So now what I'm going to show you, it's right now we're going to make.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "S stronger claim.",
                    "label": 0
                },
                {
                    "sent": "They're going to require.",
                    "label": 0
                },
                {
                    "sent": "First of all, the two distributions have the same labeling the covariate shift assumption, and on top of it, we're also going to require that the two unlabeled distributions are indistinguishable.",
                    "label": 1
                },
                {
                    "sent": "So now it seems that we are in a better state to guarantee and success of dementia patients right?",
                    "label": 0
                },
                {
                    "sent": "And now I'm going to show you exactly since not the case.",
                    "label": 0
                },
                {
                    "sent": "So what is in this example so?",
                    "label": 0
                },
                {
                    "sent": "But I have, yeah, two distributions that is just there.",
                    "label": 0
                },
                {
                    "sent": "Say the density function of the peas and associates solution and the target distribution of the unlabeled points.",
                    "label": 0
                },
                {
                    "sent": "The labels written here under so labels are exactly the same 010101, But the density is over distribution.",
                    "label": 0
                },
                {
                    "sent": "Not in line one.",
                    "label": 0
                },
                {
                    "sent": "Distribution puts the weight on the even intervals and the other solutions put all the rights on their Holdings.",
                    "label": 0
                },
                {
                    "sent": "So these two distributions are quite different, But what happens if I try to measure them with respect to my distance?",
                    "label": 0
                },
                {
                    "sent": "OK, so let me hope this idea here OK?",
                    "label": 0
                },
                {
                    "sent": "So first of all, the comparisons poles and cause in both task and have the same labeling.",
                    "label": 0
                },
                {
                    "sent": "Same happening in most.",
                    "label": 0
                },
                {
                    "sent": "Secondly, the distance if I tried out so the question is, what is my class?",
                    "label": 0
                },
                {
                    "sent": "You never write my new distance depends on the classification.",
                    "label": 1
                },
                {
                    "sent": "So to make things very simple here and transparent, my class of authorities in just initial segment.",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to sing.",
                    "label": 0
                },
                {
                    "sent": "How well can initial segments separate between dissolution addition?",
                    "label": 1
                },
                {
                    "sent": "And the answer is initial segments cannot.",
                    "label": 0
                },
                {
                    "sent": "Separate between them, they can only.",
                    "label": 0
                },
                {
                    "sent": "I mean, if I take in this segment up to here, then the blue distributions will have slightly more weight in their yellow.",
                    "label": 1
                },
                {
                    "sent": "If I think it's up to this point and the registration we have slightly more weighted, but there's no initial segment in which I will see a big difference in the weight of the initial segments of the building solution and their registration, so that the new distance that I defined since.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Miss the difference between these two distributions, so the distance between the two distributions in small, the covariate shift?",
                    "label": 0
                },
                {
                    "sent": "Also, what about our billing need to use labels from 1 task to protect the advertised?",
                    "label": 0
                },
                {
                    "sent": "If I'm training on restart?",
                    "label": 0
                },
                {
                    "sent": "See what happens.",
                    "label": 0
                },
                {
                    "sent": "All the weight of my distributions is about zero point.",
                    "label": 0
                },
                {
                    "sent": "So if I'm getting a training data which is labeled from here, what will be the label that I will see?",
                    "label": 0
                },
                {
                    "sent": "Only civil because all the way to split about zero point.",
                    "label": 0
                },
                {
                    "sent": "So if I just trained in this and come up with the conclusion that we need to.",
                    "label": 0
                },
                {
                    "sent": "0.",
                    "label": 0
                },
                {
                    "sent": "Constant zero predictor, but however the concept here is the thing to do here is very badly because this guy is only speaking points for the label is mine.",
                    "label": 0
                },
                {
                    "sent": "So we tried to rectify the problem.",
                    "label": 0
                },
                {
                    "sent": "We sent them into place and provide safety is not enough.",
                    "label": 0
                },
                {
                    "sent": "We need to say that the food distributions are similar.",
                    "label": 0
                },
                {
                    "sent": "We try to fix the problem.",
                    "label": 0
                },
                {
                    "sent": "We define the notion of similarity between solutions and get through distributions that for this similarity look similar and still there is the failure of the medication.",
                    "label": 0
                },
                {
                    "sent": "I am misled to think that the true function is zero and this is going to make a big error here when this guy is just something from the ones instead of something from the view.",
                    "label": 0
                },
                {
                    "sent": "So we need another component.",
                    "label": 0
                },
                {
                    "sent": "What I'm saying is that what is the component is missing.",
                    "label": 0
                },
                {
                    "sent": "The component is missing.",
                    "label": 0
                },
                {
                    "sent": "Is something about how the labels of the two tasks.",
                    "label": 0
                },
                {
                    "sent": "Calling each other.",
                    "label": 0
                },
                {
                    "sent": "But now you have to.",
                    "label": 0
                },
                {
                    "sent": "If I was not in the cloud, I would jump and say what do you mean?",
                    "label": 0
                },
                {
                    "sent": "You need another assumption about how the label product we make the strongest possible assumption.",
                    "label": 0
                },
                {
                    "sent": "We said that the labels are exactly the same as the covariance system.",
                    "label": 0
                },
                {
                    "sent": "But we will see that this is one of the longest function we need a different kind of assumption about the relationship between the neighbors.",
                    "label": 0
                },
                {
                    "sent": "So what is the assumption that we will have the fear?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An assumption is that so we introduced another parameter and this is the parameter that is going to measure the agreement between labels, but with respect for my class of apologies age.",
                    "label": 0
                },
                {
                    "sent": "So what is the agreement between labels with respect to sacrifice?",
                    "label": 0
                },
                {
                    "sent": "It is the minimum overall apologies in my class.",
                    "label": 0
                },
                {
                    "sent": "Off the error that causes snakes online distribution and the errors in opposing snakes in the other.",
                    "label": 0
                },
                {
                    "sent": "So what I'm introducing here, and you measure of relatedness between the problem these related that has to do with the fixed class of opponents age and what is it saying thanks.",
                    "label": 0
                },
                {
                    "sent": "What is I'm trying to find one hypothesis that will go ahead and do a good job on both distribution.",
                    "label": 0
                },
                {
                    "sent": "How well can I do?",
                    "label": 0
                },
                {
                    "sent": "I'm trying to find one fix typos in the class.",
                    "label": 1
                },
                {
                    "sent": "That will minimize and the and I'm doing it.",
                    "label": 0
                },
                {
                    "sent": "Same opponent is performing on P and performing on fumes.",
                    "label": 0
                },
                {
                    "sent": "So the question is, I'll say there's two types of similar with respect to age.",
                    "label": 1
                },
                {
                    "sent": "If I can find in a chair for this, the Singleton instance has a good job on both of them.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "It doesn't necessarily mean that we've been able to find such an opponent.",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm.",
                    "label": 0
                },
                {
                    "sent": "Pushing the logical reasoning here, it's too fast, but one what you should jump now and say.",
                    "label": 0
                },
                {
                    "sent": "I mean you solve your problem.",
                    "label": 0
                },
                {
                    "sent": "There's nothing left to be done.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to look for authorities.",
                    "label": 0
                },
                {
                    "sent": "And thanks on the data from.",
                    "label": 1
                },
                {
                    "sent": "That and then use it to predict until and.",
                    "label": 0
                },
                {
                    "sent": "I assume that there exists to help all these that does well on both of them simultaneously.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that having seen only data from Pi, have no clue which of the headphones that asked nicely on team is going to do well on cue as well.",
                    "label": 0
                },
                {
                    "sent": "I just notice there exists.",
                    "label": 0
                },
                {
                    "sent": "So that's the way that I'm going to measure the similarity of the agreement between the labels of the tool distribution.",
                    "label": 0
                },
                {
                    "sent": "And now with this new parameter we are able to religion.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The founders regarding these NIPS 2006 paper.",
                    "label": 0
                },
                {
                    "sent": "Says that OK, so let me just explain to you what it is something.",
                    "label": 0
                },
                {
                    "sent": "So I have here.",
                    "label": 0
                },
                {
                    "sent": "2 tasks that targeting the source.",
                    "label": 1
                },
                {
                    "sent": "What I want to estimate is the error of her properties on the target.",
                    "label": 1
                },
                {
                    "sent": "And now because it shows me that I can estimate the error of supposing just based on data that I can see.",
                    "label": 0
                },
                {
                    "sent": "So the error of opposing the target is bounded by the error on the sample, so I have it enabled.",
                    "label": 0
                },
                {
                    "sent": "Sample is coming from the source.",
                    "label": 0
                },
                {
                    "sent": "Plus this distance between the two unable distributions that we said that we can estimate it from unlike this point.",
                    "label": 0
                },
                {
                    "sent": "Plus this Lambda.",
                    "label": 0
                },
                {
                    "sent": "So if the two is the two tasks are related with respect to this measure that there exists an iPod.",
                    "label": 0
                },
                {
                    "sent": "This is that when on both of them then the nice thing here is trying to following if there exists to happen.",
                    "label": 0
                },
                {
                    "sent": "If it does nicely on both of them, then every I promise that as well on the source will also do well on the target.",
                    "label": 0
                },
                {
                    "sent": "How how do I know this time?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Right now it's not even.",
                    "label": 0
                },
                {
                    "sent": "I mean, in order to do things in human resources and they're trying to, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't know, it just is a way of expressing my assumption about relatedness is important.",
                    "label": 0
                },
                {
                    "sent": "It's like when the provider shifts assumption when you assume that both packs have the same labeling, so there's no way you can check it because there's no labeling from the target, but it says this is my.",
                    "label": 0
                },
                {
                    "sent": "This is my belief as domain extra things might believe about this problem and we believe provided the disabilities correct, can you give me about right?",
                    "label": 0
                },
                {
                    "sent": "I want to.",
                    "label": 0
                },
                {
                    "sent": "I want to advise the user.",
                    "label": 0
                },
                {
                    "sent": "In other words, circumstances can use a manifestation.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying.",
                    "label": 0
                },
                {
                    "sent": "Instead of the very strong assumption that says you can use it only when you believe that things are exactly the same.",
                    "label": 0
                },
                {
                    "sent": "Here and thank you can use it when you believe that with the class of the Internet use, there may be a predictor that goes well on both in solution.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing about these values sense if there exists a predictor, does not that valuable solution, then every potential that will do well on one will also do well on the other without making any properties.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "No, so the only thing it was missing then open.",
                    "label": 0
                },
                {
                    "sent": "The only thing which is missing is the term that goes down with the sample because what we have here is we watch where you actually uses them.",
                    "label": 0
                },
                {
                    "sent": "An error here, not the true error.",
                    "label": 0
                },
                {
                    "sent": "And here you have the empirical measure of the distance, not the true L and through measures.",
                    "label": 0
                },
                {
                    "sent": "So you have here another term which goes down like this way with me.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "The sound will be very low.",
                    "label": 1
                },
                {
                    "sent": "Drink this bound is in some sense is the only found that we have for domain adaptation that guarantees success.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it looks like a not so.",
                    "label": 0
                },
                {
                    "sent": "And you know nothing to celebrate, because as you said, this notice looks a bit loose.",
                    "label": 0
                },
                {
                    "sent": "So if I repeat.",
                    "label": 0
                },
                {
                    "sent": "I was saying that if I had that, if it was the same distribution, what is going to happen if both of them at the same distribution 'cause I'm going to find that the arrow of age on T?",
                    "label": 0
                },
                {
                    "sent": "It is less than equal to the Arrow Agency, which is OK.",
                    "label": 0
                },
                {
                    "sent": "This is the same thing plus the distance between them, which is 0 which is also nice.",
                    "label": 0
                },
                {
                    "sent": "But what I have here is.",
                    "label": 0
                },
                {
                    "sent": "Twice the error of the best predictor nature necessarily.",
                    "label": 0
                },
                {
                    "sent": "It's not necessarily at my age, but it's twice the best as I can do so.",
                    "label": 0
                },
                {
                    "sent": "I have this kind of factor that is annoying.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was in the.",
                    "label": 0
                },
                {
                    "sent": "You know aims to do what I'm going through.",
                    "label": 0
                },
                {
                    "sent": "Our conclusions now is that we can show that you cannot get it off.",
                    "label": 0
                },
                {
                    "sent": "So we can.",
                    "label": 0
                },
                {
                    "sent": "So then, that's the kind of games I'm going to play.",
                    "label": 0
                },
                {
                    "sent": "For now, I want to show you that it's bound is an enthusiastic is maybe about it, and we can show that there is a matching lower bound that in some sense all those terms are really needed there.",
                    "label": 0
                },
                {
                    "sent": "Unless you come up with a different tool to model relationships.",
                    "label": 0
                },
                {
                    "sent": "But if all you know about the relationship between the two sides is this kind of.",
                    "label": 0
                },
                {
                    "sent": "Imagine.",
                    "label": 0
                },
                {
                    "sent": "And then we can show that this is up to the first of two.",
                    "label": 0
                },
                {
                    "sent": "It's the best one.",
                    "label": 0
                },
                {
                    "sent": "Correct?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Right, so so an option.",
                    "label": 0
                },
                {
                    "sent": "So when the moment they have some similar bound that instead of using this using something similar, which is the error of the best hypothesis on S is her own team and the error of the best sources of things on it.",
                    "label": 0
                },
                {
                    "sent": "So you can play some games here.",
                    "label": 0
                },
                {
                    "sent": "And where was this taken care of?",
                    "label": 0
                },
                {
                    "sent": "This would cause cause yeah, so it is very very similar flavor but slightly different.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this is where we are we have about we have a guarantee that sound is in some sense based on if you believe there is a good thing on this then this is what you can do.",
                    "label": 0
                },
                {
                    "sent": "Things you want your computer so there is a positive.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Candy's bounty improved natural question, OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first thing that I wanted to check here, if you say I'm using here, we were talking about 3 parameters 3.",
                    "label": 0
                },
                {
                    "sent": "Measures of relatedness between the two to the first one we talked about was the comparative suspension.",
                    "label": 0
                },
                {
                    "sent": "We sold it on its own because I restrict assumption doesn't buy you anything.",
                    "label": 0
                },
                {
                    "sent": "Then we talked about the Lambda existence of a mutual good, usually good apology and there was the distance between distributions of the age.",
                    "label": 0
                },
                {
                    "sent": "So we have three parameters, the question is.",
                    "label": 0
                },
                {
                    "sent": "Which how many of them do I need to have simultaneous streams in order to guarantee that reminder patient work?",
                    "label": 0
                },
                {
                    "sent": "So it turns out that the comparative doesn't contribute anything?",
                    "label": 0
                },
                {
                    "sent": "I mean this there is not sufficient provider changed.",
                    "label": 0
                },
                {
                    "sent": "And then this is the distance is not sufficient.",
                    "label": 0
                },
                {
                    "sent": "We've already seen it.",
                    "label": 0
                },
                {
                    "sent": "The distance between the two distributions are small.",
                    "label": 0
                },
                {
                    "sent": "We assume Cooper's shift, for example with the.",
                    "label": 0
                },
                {
                    "sent": "Up and down there going there.",
                    "label": 0
                },
                {
                    "sent": "So these two do not suffice, and also I'll show you in a minute.",
                    "label": 0
                },
                {
                    "sent": "So even if we introduce those who you measure, the comparatives remains useless.",
                    "label": 0
                },
                {
                    "sent": "Even in combination with this measure, so we already saw the comparative with this assumption is not sufficient, and I'll just show you that provides users assumption is not.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we will go into more, maybe more interesting question.",
                    "label": 0
                },
                {
                    "sent": "So now the kind of thing that I'll do now is I'll show you our grammar straight, the failure of combinations of assumptions on a very, very simple example, but.",
                    "label": 0
                },
                {
                    "sent": "The fact that those assumptions already breakdown on very simple assumption.",
                    "label": 0
                },
                {
                    "sent": "Indicates this and we can generalize it to a more general case, but basically it should give you the flavor of why those assumptions.",
                    "label": 0
                },
                {
                    "sent": "No surprise.",
                    "label": 0
                },
                {
                    "sent": "So here I'm going to show you that you're going to have covariate shift, perhaps more Lambda budget needs more Lambda.",
                    "label": 0
                },
                {
                    "sent": "It means that I have a hypothesis, works well on those information simultaneously and still.",
                    "label": 0
                },
                {
                    "sent": "That's the code.",
                    "label": 0
                },
                {
                    "sent": "There is a good approach is from one domain which completely fails on the other.",
                    "label": 0
                },
                {
                    "sent": "So what is happening here?",
                    "label": 0
                },
                {
                    "sent": "Anything for my?",
                    "label": 0
                },
                {
                    "sent": "And blue points now a caravan by label.",
                    "label": 0
                },
                {
                    "sent": "So blue points are 0.00 label and the red ones are the one labeled.",
                    "label": 0
                },
                {
                    "sent": "So let us just make sure that we have the comparative suspension, so we both both tax label this point one label.",
                    "label": 1
                },
                {
                    "sent": "This is zero and label this is one or both of the same labeling in real property.",
                    "label": 0
                },
                {
                    "sent": "Now we want to make sure that we have more Lambda.",
                    "label": 0
                },
                {
                    "sent": "What does it mean in small Lambda is that I have an assumption.",
                    "label": 0
                },
                {
                    "sent": "My assumption spaces definition segments to make life simple.",
                    "label": 0
                },
                {
                    "sent": "I have an initial segment and these are segments that behaves nicely make small errors on both distribution.",
                    "label": 0
                },
                {
                    "sent": "What is going to be the initial segment actually succeed pretty well on both distribution.",
                    "label": 0
                },
                {
                    "sent": "Initial segment groups runs all the way to the end of the user segments and heals up.",
                    "label": 0
                },
                {
                    "sent": "Something so easily for segments that.",
                    "label": 0
                },
                {
                    "sent": "Hello on both together is pretty small.",
                    "label": 0
                },
                {
                    "sent": "What is going to be?",
                    "label": 0
                },
                {
                    "sent": "So anybody was still on sleep.",
                    "label": 0
                },
                {
                    "sent": "So it's going to be like if I take this and something like this initial segment, then it predicts one up to here and see more from here on.",
                    "label": 0
                },
                {
                    "sent": "It will make no error on the target distribution because it is on the road to the right, and here it will make that a small.",
                    "label": 1
                },
                {
                    "sent": "So I have those two assumptions, but still why we committed to patient?",
                    "label": 0
                },
                {
                    "sent": "Same cause.",
                    "label": 0
                },
                {
                    "sent": "If I just see the sampling from this distribution, what am I going to see?",
                    "label": 0
                },
                {
                    "sent": "I'm going to see 1.1 something else and someone.",
                    "label": 0
                },
                {
                    "sent": "No I can't.",
                    "label": 0
                },
                {
                    "sent": "I have to choose.",
                    "label": 0
                },
                {
                    "sent": "What is my best?",
                    "label": 0
                },
                {
                    "sent": "I can't really say something right.",
                    "label": 0
                },
                {
                    "sent": "The next question to ask me what will they also do in this case?",
                    "label": 0
                },
                {
                    "sent": "If you would have listened to the talk in the morning.",
                    "label": 0
                },
                {
                    "sent": "What was the option?",
                    "label": 0
                },
                {
                    "sent": "What did you do?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK. Yeah, that's all.",
                    "label": 0
                },
                {
                    "sent": "So OK, so problem is funnel and we we we feel at this point this task.",
                    "label": 0
                },
                {
                    "sent": "We want to predict this stuff we see here unlabeled points.",
                    "label": 0
                },
                {
                    "sent": "We don't know what the label as if we just see the labels here, we're going to be introduced to output the old one assumption, because if you want it better on the radio.",
                    "label": 0
                },
                {
                    "sent": "But I see here if you will, but they only count as on here in here I have to extract the Terminal 1.",
                    "label": 0
                },
                {
                    "sent": "But I think about a lot of points in this area in the target.",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we wanna do.",
                    "label": 0
                },
                {
                    "sent": "We waiting remember we talked about in the morning we talked a lot about that in waiting in here if I see the unlabeled data from the target, I can really weigh my sample.",
                    "label": 0
                },
                {
                    "sent": "I can just by seeing her there.",
                    "label": 0
                },
                {
                    "sent": "I see a lot of unlabeled examples here.",
                    "label": 0
                },
                {
                    "sent": "I can say, oh, there is something funny happening here.",
                    "label": 0
                },
                {
                    "sent": "The target is really putting a lot of weight here, so I should not just treat it as a small epsilon.",
                    "label": 0
                },
                {
                    "sent": "Ignore it, I should stop my initial signal here.",
                    "label": 0
                },
                {
                    "sent": "Will that help?",
                    "label": 0
                },
                {
                    "sent": "If your help in this case that we did have in general, right so we waited is something that people really advocate for them at the station.",
                    "label": 0
                },
                {
                    "sent": "Get the unlabeled data from the other distribution.",
                    "label": 0
                },
                {
                    "sent": "Now when you look at your sample distributions, put weight accordingly to match the other pieces.",
                    "label": 0
                },
                {
                    "sent": "Now we will help us, so I hope this is what I put in the next slide.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so yeah, before I talk about this, notice that we have making here issues apps to this point.",
                    "label": 0
                },
                {
                    "sent": "We all we're doing is we're just training on the source and then using it for the target, but our training our appointment didn't depend at all on the island of examples of this often target.",
                    "label": 0
                },
                {
                    "sent": "This is one of those things that you suggested.",
                    "label": 0
                },
                {
                    "sent": "Why not just train on the source and use it for the target and pray that it will work right?",
                    "label": 1
                },
                {
                    "sent": "That's what we were doing so far.",
                    "label": 0
                },
                {
                    "sent": "Now we are switching.",
                    "label": 0
                },
                {
                    "sent": "We're doing something adaptive.",
                    "label": 0
                },
                {
                    "sent": "We're not using the best economies on the source, but we're using apologies.",
                    "label": 0
                },
                {
                    "sent": "That's really takes into account the fact that we have some unlabeled data that will set up blue enterprise imports.",
                    "label": 0
                },
                {
                    "sent": "Right, so we are switching from conservative conservative domain adaptation adaptive algorithm that really takes the new data from target solution into account.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 1
                },
                {
                    "sent": "Can we do better by being productive?",
                    "label": 1
                },
                {
                    "sent": "Intuitively, we should should help us.",
                    "label": 0
                },
                {
                    "sent": "And so the idea of imposing, fighting and the important thing it says, use the target unlabeled samples to reweigh the training samples and choose age that behaves nice with respect to this.",
                    "label": 1
                },
                {
                    "sent": "Do waiting of the summer.",
                    "label": 0
                },
                {
                    "sent": "So if we never, that's exactly what we saw here.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we we just see samples from here, we see some few zeros.",
                    "label": 0
                },
                {
                    "sent": "You tend to ignore them because there are only a few of them, but now we see a lot of unlabeled data in this area, then will give them all.",
                    "label": 0
                },
                {
                    "sent": "This is important.",
                    "label": 0
                },
                {
                    "sent": "When will that work?",
                    "label": 0
                },
                {
                    "sent": "So you can guess just from the tone of my question.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Here is a case wedding.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just waiting is saying that because the films that labels here are all one.",
                    "label": 0
                },
                {
                    "sent": "Now, the neighbors here or one.",
                    "label": 0
                },
                {
                    "sent": "But what does the soul see the so see exactly the same picture, and so before it seems once here refusal on sale.",
                    "label": 0
                },
                {
                    "sent": "Lots of ones here and then it goes and sees all there.",
                    "label": 0
                },
                {
                    "sent": "Lots of lots of frontier.",
                    "label": 0
                },
                {
                    "sent": "So it will say oh, but it doesn't seem to work, suggesting oh, he says, the target really gives a lot of important to this area.",
                    "label": 0
                },
                {
                    "sent": "Target groups are not important in this area, so I should really listen to what this area is telling me.",
                    "label": 0
                },
                {
                    "sent": "Telling me 0 so I'll make my support this here.",
                    "label": 0
                },
                {
                    "sent": "And home.",
                    "label": 0
                },
                {
                    "sent": "I predict all those points to be 0 and I feel this.",
                    "label": 0
                },
                {
                    "sent": "I was doing the important sampling you see because.",
                    "label": 0
                },
                {
                    "sent": "What now this one they always want?",
                    "label": 0
                },
                {
                    "sent": "The L in the target is done because if I do.",
                    "label": 0
                },
                {
                    "sent": "If I do, we waiting in his me a lot of important to this guy so I'll stop my initial segment.",
                    "label": 0
                },
                {
                    "sent": "Here is a big O predict deal from here onwards.",
                    "label": 0
                },
                {
                    "sent": "Right, but I can think yes, someone is following listening, but I can fix the comparative easily with this with the traits of this or before.",
                    "label": 0
                },
                {
                    "sent": "Because in this area where they can have, if you know these two things and the truth will bring both of them will have labels.",
                    "label": 0
                },
                {
                    "sent": "Red, blue, red, blue, red, blue.",
                    "label": 0
                },
                {
                    "sent": "But this guy will concentrate on their Blues and this guy in position with the rent.",
                    "label": 0
                },
                {
                    "sent": "So I can always fix the compliance things almost for free.",
                    "label": 0
                },
                {
                    "sent": "I will also have the small number.",
                    "label": 0
                },
                {
                    "sent": "No, I mean no, not now.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "He doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't do enough damage.",
                    "label": 0
                },
                {
                    "sent": "Then fix it doesn't really change, but what I'm saying is 1 conclusions we may conclude from here.",
                    "label": 0
                },
                {
                    "sent": "So we waiting on its own is maybe adventurous idea because you paying a lot of attention to this area without knowing whether in this area you're labeled agree or don't agree with what we see in the training data.",
                    "label": 0
                },
                {
                    "sent": "Maybe the waiting is also good idea.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's a better idea.",
                    "label": 0
                },
                {
                    "sent": "Maybe we we should their search for a bit earlier.",
                    "label": 0
                },
                {
                    "sent": "So what I want to show you now is that nothing will work.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter what you just write, why.",
                    "label": 0
                },
                {
                    "sent": "And then we're almost there because.",
                    "label": 0
                },
                {
                    "sent": "Look at this situation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we sell 2 examples.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We saw this target.",
                    "label": 0
                },
                {
                    "sent": "Now notice that from the point of view of the learner, what does the learner see?",
                    "label": 1
                },
                {
                    "sent": "The learner says the labels.",
                    "label": 0
                },
                {
                    "sent": "Here the neighbors here were the same in both examples.",
                    "label": 0
                },
                {
                    "sent": "And then Learner sees unlabeled data from this distribution, unlabeled data from the solution are the same faulty inferences price.",
                    "label": 0
                },
                {
                    "sent": "So from the point of view of the learner, you cannot distinguish between these two cases between 10 people.",
                    "label": 0
                },
                {
                    "sent": "So whatever idea not idea, wonderful again that only comes up.",
                    "label": 1
                },
                {
                    "sent": "An error on T classes ever onto prime within one, so at least on one of them will they can ever have.",
                    "label": 0
                },
                {
                    "sent": "So no matter what you come up with, there will be a dissolution.",
                    "label": 0
                },
                {
                    "sent": "On which you are going to do your beautiful trick and make an air of 1/2, which is not that good is predicting his talking points.",
                    "label": 0
                },
                {
                    "sent": "So what this is, it's not, the problem was not that the waiting was a better year.",
                    "label": 1
                },
                {
                    "sent": "The problem is that we don't have enough information if we just make those assumptions and so.",
                    "label": 0
                },
                {
                    "sent": "And to do better than.",
                    "label": 0
                },
                {
                    "sent": "What we need from the London was in here my landing small, but the distance within this distribution.",
                    "label": 0
                },
                {
                    "sent": "My bound it says it goes.",
                    "label": 0
                },
                {
                    "sent": "The distance is small in land Lakes Mall is driving and not.",
                    "label": 0
                },
                {
                    "sent": "I'm creating a lot of cultures that as with everything I own children.",
                    "label": 0
                },
                {
                    "sent": "The sound is right if I know that both and this morning the distances, but here Lambda is small but the distance is easy, solution is big and in that case there waiting was supposed to help us.",
                    "label": 0
                },
                {
                    "sent": "If we see that we cannot guarantee success of their waiting and we can do the guarantee of success of any other three.",
                    "label": 0
                },
                {
                    "sent": "We really need both assumption, both the Lambda entities.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Alright, so you guys put this comment in the fridge.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Site.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, so in a similar fashion without, I don't know.",
                    "label": 0
                },
                {
                    "sent": "It's too tired, but it's the same kind of tricks you know once you see this trick.",
                    "label": 0
                },
                {
                    "sent": "Once you can apply it again, we can really show that the balance that we have is in some sense cannot be improved unless you come up with a new notion of relatedness with a new type of assumption of relatedness within this sub.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "No domain in the patient is possible without assuming relatedness between that numbers in solution.",
                    "label": 1
                },
                {
                    "sent": "So that's taking over Korea seems without point even point.",
                    "label": 1
                },
                {
                    "sent": "Anne and we can come up with examples that demonstrate that this assumption is not the side.",
                    "label": 0
                },
                {
                    "sent": "No algorithm will succeed if you only have the Lambda assumption and not too late for them.",
                    "label": 0
                },
                {
                    "sent": "So they all the exams will be seen so far, so that that.",
                    "label": 0
                },
                {
                    "sent": "Their conservative assumptions just trained on the source windows.",
                    "label": 0
                },
                {
                    "sent": "This is what I'm saying is that in the same way when we produce two matching painting frames, we can show that it is not a problem of the conservative approach.",
                    "label": 0
                },
                {
                    "sent": "Any approach will fail if you don't take care of simultaneously of both the unable distance between distributions and the Lambda instances regulators.",
                    "label": 0
                },
                {
                    "sent": "Both of them are required in order to guarantee.",
                    "label": 0
                },
                {
                    "sent": "Regardless of what algorithm used in particularly waiting.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The major remaining open question is OK. Can we seem so we can show that our bound is optimal after samples too.",
                    "label": 1
                },
                {
                    "sent": "So maybe you can still get rid of this structure, so I don't know it.",
                    "label": 0
                },
                {
                    "sent": "I think more important is find new relationship parameters.",
                    "label": 0
                },
                {
                    "sent": "That's.",
                    "label": 0
                },
                {
                    "sent": "Will be more useful and tell us why do we succeed in the meditation when we're doing this?",
                    "label": 0
                },
                {
                    "sent": "What was the thing you were predicting?",
                    "label": 0
                },
                {
                    "sent": "How do you .5 senses?",
                    "label": 0
                },
                {
                    "sent": "Why does this work now?",
                    "label": 0
                },
                {
                    "sent": "Can we come up with some kind of general notion of relatedness that will explain when going into fashion when works, and then when the note which will be better than those two parameters that can work with now an?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Maybe come up with different adaptive algorithms, but again, it's all depends on having a good.",
                    "label": 1
                },
                {
                    "sent": "User friendly.",
                    "label": 0
                },
                {
                    "sent": "Useful relatedness note.",
                    "label": 1
                },
                {
                    "sent": "So we have to come up with new notions of connectedness and those notions of correctness should clarify two things.",
                    "label": 0
                },
                {
                    "sent": "On one hand, when you go to the biology or you go to the data, the information retrieval person, it would make sense to this.",
                    "label": 0
                },
                {
                    "sent": "Because you want to tell them that this assumption holds in your situation, and if your intention is, you know.",
                    "label": 0
                },
                {
                    "sent": "There exists an outcast S cannon such as blah blah blah blah blah.",
                    "label": 0
                },
                {
                    "sent": "It would not make sense to them.",
                    "label": 0
                },
                {
                    "sent": "They will not have intuition about.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, you want these assumptions will be such that it is useful to show to develop algorithms and to drive.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot through.",
                    "label": 0
                },
                {
                    "sent": "Clearly we think works in practice and as I was trying to demonstrate, their clearance hearing is well well behind.",
                    "label": 0
                },
                {
                    "sent": "In trying to explain why it was.",
                    "label": 0
                },
                {
                    "sent": "So I mean, this could be some type of assumptions that you want to make, but if you look at like the gene prediction problem, you don't have the such a clear geometry.",
                    "label": 0
                },
                {
                    "sent": "Not in many problems you don't have.",
                    "label": 0
                },
                {
                    "sent": "I mean not all problems are on the real line.",
                    "label": 0
                },
                {
                    "sent": "Maybe first of all, I really encourage you to think such assumptions, and so if you're problem has a.",
                    "label": 0
                },
                {
                    "sent": "You know Euclidean domain.",
                    "label": 0
                },
                {
                    "sent": "Then sometimes you know we can pull things like that.",
                    "label": 0
                },
                {
                    "sent": "We can pull this over your prison domain.",
                    "label": 0
                },
                {
                    "sent": "Nearest neighbor works very well and just depends on the Lipschitz condition of how the label change.",
                    "label": 0
                },
                {
                    "sent": "So in some situations we do have found that you can base on smoothness assumptions and if they work at least for you.",
                    "label": 0
                },
                {
                    "sent": "But there are two things we have to be able to show.",
                    "label": 0
                },
                {
                    "sent": "It is just one counterexample.",
                    "label": 0
                },
                {
                    "sent": "I mean I'm very good at coming up with something that will not be able to.",
                    "label": 0
                },
                {
                    "sent": "And the other thing is we want think this will work for other domains where things are not completed like all the meaning the microbiology problems is a really hard problem but but that's kind of the challenges that.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's all the questions here.",
                    "label": 0
                },
                {
                    "sent": "One question is what can you do when you have only very few targets labels, and I think my point is very few target table and all those examples will extend, so just needed to be quicker.",
                    "label": 0
                },
                {
                    "sent": "The other question is if I have a lot of targets and the loss of so when should I combine them and when will this combination gives me an advantage and less than like the multi task learning problem is another problem.",
                    "label": 0
                },
                {
                    "sent": "Very interesting problem but it has a flat roof system.",
                    "label": 0
                },
                {
                    "sent": "Different things.",
                    "label": 0
                },
                {
                    "sent": "Wonderful.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah but yeah, that would help.",
                    "label": 0
                },
                {
                    "sent": "That's what happened at the very very strong assumption is because the people don't realize.",
                    "label": 0
                },
                {
                    "sent": "I mean, they say the tales of urgency is not too large and just want to say they look to me similar, but the child offenders can think on points that you don't think that that's basically half of our achieved plus scales or gotten small.",
                    "label": 0
                },
                {
                    "sent": "It's actually in saying that it's the same problem.",
                    "label": 0
                },
                {
                    "sent": "So the two are the same problem.",
                    "label": 0
                },
                {
                    "sent": "They can do it.",
                    "label": 0
                }
            ]
        }
    }
}