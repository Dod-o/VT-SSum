{
    "id": "7ucv45zzonovipaedh7c67vjty3pik5f",
    "title": "Theoretical neuroscience and deep learning theory",
    "info": {
        "author": [
            "Surya Ganguli, Department of Applied Physics, Stanford University"
        ],
        "published": "Aug. 23, 2016",
        "recorded": "August 2016",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2016_ganguli_theoretical_neuroscience/",
    "segmentation": [
        [
            "Yeah, it's great to be here.",
            "So yeah, I was going to talk about a mixture of computational neuroscience and deep learning theory because I think the two subjects are going to be much more aligned going forward in the future, and I think it'll be interesting to mix ideas between the two field."
        ],
        [
            "So theoretical neuroscience?",
            "Why do I think it's such an exciting field at the moment?",
            "It's because we have access to a wider range wide array of recording technologies.",
            "Now that really allow us to peer into the immense complexity of neural systems across multiple scales of spatial and temporal organization, and we'd like to try to make sense of all of this data that neuroscientists are measuring, and so we need tools to confront this kind of complexity and to extract from it conceptual models of how the brain works.",
            "So it's useful to turn to tools from the physical and mathematical Sciences that have themselves been developed to confront complexity in other disciplines, to understand other disciplines.",
            "But of course, neural systems aren't simply a tangled web of complexity that exists for its own sake.",
            "They've of course evolved over millions of years to solve important computational problems, so it can be really useful also to turn to fields like machine learning and the engineering Sciences, both as a source of inspiration as to what kinds of problems neural systems might be solving.",
            "And also using methods to just attack and analyze data of course.",
            "So."
        ],
        [
            "What kinds of problems do theoretical neuroscientists work on?",
            "I can give you a very biased sample if the problem is that.",
            "For example, I'm working on the lab, you know.",
            "Oftentimes when you want to work in the field of neuroscience, the final arbiter of whether or not work is useful is doesn't make useful predictions experimentally testable predictions, just like in some cases the final arbiter of whether or not work is good in machine learning is does it work?",
            "Can you win a competition?",
            "Can you do something that you've never done before?",
            "So the yardstick for measuring progress is a little bit different in neuroscience, so.",
            "What are the types of things that we're working on so we're working on trying to understand processing in the retinal circuit.",
            "So actually the retina is already a deep neural network.",
            "You have a layer of photoreceptors, a layer of bipolar cells.",
            "Can you guys see the arrows?",
            "Yeah, great, you have lateral connections to the horizontal and amacrine cells, and then you have the ganglion cells over here, and what neuroscientists can do is they can control the photoreceptors and record from the ganglion cells, but it's very difficult to record from the interior of the circuit.",
            "And we'd like to have computational methods to essentially computationally fill in the interior of the circuit, and we've been able to do that using various methods, some of which include deep learning, and then we can look inside our deep learning models and find cells that actually mimic the response properties of cells that are actually recorded in the interior of the retina.",
            "The few times for neuro, scientists can do that.",
            "With the Clendenin lab, we're trying to unravel the way that the fly C and so now we can do or the clandestine lab at Stanford can do whole brain optical imaging in the family so they can record optically many, many neurons in the fly and we can just use systems identification methods to discover how the fly, for example, detects motion.",
            "Flies are really good at detecting motion, which is why it's really hard for us to swap them because they immediately go away.",
            "So we discovered recently.",
            "Actually the algorithm for motion detection and actually remarkably.",
            "A flies essentially detect oriented space time energy in its receptive field in the same way that vertebrate visual cortical neurons detect motion.",
            "So it seems now the fly visual circuits in the vertebral circuits evolved independently, so this suggests a remarkable convergent evolution in the algorithm for motion detection.",
            "We've also been looking at grid cells grid cells.",
            "You know, Bruno mentioned navigation and smaller animals.",
            "These grid cells.",
            "These are cell.",
            "I don't know if you must have heard about them.",
            "There's sort of the most recent Nobel Prize in neurophysiology.",
            "These are cells that fire if and only if the mouse appears at the vertices of a hexagonal grid.",
            "In a small environment.",
            "So you could ask, well who ordered that?",
            "Would a deep learning model ever discover a grid cells as a natural consequence of trying to solve it task?",
            "That's actually a major open question.",
            "We actually don't know.",
            "The functional reason for why these grid cells exist, we just know that they do exist.",
            "What we showed is that a natural question is what is the origins of stability of this grid?",
            "Like pattern.",
            "There's two possibilities.",
            "The mouse is doing a very accurate path integration, so it's integrating its own velocity signals to figure out where it is, and then based on that the cell is firing or two.",
            "The rat mouse is internal estimate position is continuously getting corrected by landmarks and what we actually showed is that it's the latter.",
            "We showed that this spiking pattern becomes much more incoherent.",
            "Each time the mouse encounters each time the mouse is spent further and further time away from a landmark or a boundary, and each time it hits the boundary, the spike pattern becomes more coherent.",
            "Essentially an interesting enough when you hit a boundary, you receive no positional information parallel to the boundary, but you do receive positional information, perpendicular boundary, and remarkably, this makes a prediction that errors are only corrected perpendicular to the boundary but not parallel, and that's what we actually found, so this was published recently in Neuron with the Shenoy lab we've been looking at.",
            "I think one of the most.",
            "One of the biggest sort of conceptual elephants residing within almost all neurophysiology experiments which is the following.",
            "We record from about 100 neurons in the brain.",
            "OK, maybe 1000 now with optical imaging in brain regions, say invertebrates in monkeys that can contain 10 to the six to 10 to the 9th neurons.",
            "OK, we can sometimes decode behavior from these neurons.",
            "We can.",
            "We can sometimes recover the state space dynamics of the circuit that makes sense by doing, say, dimensionality reduction.",
            "So natural question is how could we have gotten so successful?",
            "So we have a theory actually for or could it be worse?",
            "Are we completely misleading ourselves by making scientific inferences in such an undersampled measurement regime?",
            "So what we recently showed is that the act of recording a subset of neurons in the brain can actually be thought of as the act of recording the same number of random linear combinations of all neurons in the relevant brain circuit.",
            "So the act of doing neurophysiology is like doing a random projection under certain conditions.",
            "And then we know from random projection theory that if you have a curve nonlinear manifold, you don't need that many random projections to preserve its geometry.",
            "And this actually makes some testable predictions that we then tested in the mkak brain as to how geometrically distorted the state space dynamics of the mkak brain gets as we reduce the number of neurons and it predicted exactly the scaling relations that would be predicted by random projection theory.",
            "So in the ramen lab, you know things that we've done, are, you know, we all think that synaptic plasticity is underlies the basis of our ability to learn and remember right?",
            "Our ability to learn and remember depends crucially in our ability to modify synapses in our brain.",
            "So a natural consequence of that is if we could somehow enhance the ability of our synapses to be plastic, then we might be able to become smarter.",
            "It could be a potential route to cognitive enhancement.",
            "People have actually tried this in mice.",
            "They either through genetic perturbations or pharmacological perturbations, they make synapses more plastic, and you get mixed responses.",
            "Sometimes the mice get smarter, sometimes they don't get smarter.",
            "So here in this in this work, in a collaboration with Jennifer Ammons lab in college classes lab at Stanford, they actually modified the synapses in the mouse's brain to make them more plastic.",
            "And they found that the mouse could either be smarter or Dumber, depending on prior experience.",
            "So there's a strong history dependent effect in synaptic plasticity that plays a role in whether or not enhancing plasticity enhances learning, and we've developed theoretical theory of why that can happen, which will talk about sort of at the end of the talk.",
            "So these are the kinds of things that we do on a day to day basis.",
            "Because we're under the constraint of having to interact very closely to experimentalists and work with the data that they have, yeah.",
            "Yeah.",
            "It was like change.",
            "No, it wasn't like changing the learning rate.",
            "So you have potentiation and depression.",
            "And depression so potentiation strengthening Synapse depression is weakening a synapse.",
            "It led to enhanced depression, but not necessarily enhanced potentiation.",
            "So.",
            "Yeah, so patterns of activity that would have led to potentiation than the wild type mouse.",
            "Or would not have led to potentiation or depression in the wild type mouse led to depression in the knockout genetic knockout mouse?",
            "So that's the actual perturbation, so there's all sorts of ways to perturb plasticity in the brain and look at its effects.",
            "There's actually a long literature on that.",
            "OK, so."
        ],
        [
            "No, the other thing that's extremely important to keep in mind when you think about applications of deep learning to neurobiology is that oftentimes biological data is operating in a very high dimensional regime.",
            "In the following technical sense.",
            "So there's of course been a dramatic change in the way that we do experiments across many, many fields, including biology in general.",
            "The classical scenario would be it was incredibly difficult to take measurements, so we would take we would decide carefully ahead of time which variables were relevant to a problem so that the number of variables we simultaneously measure is the dimensionality of the data, and then we do as many, many repeated experiments as possible for those variables and we get low dimensional data or many points living in a low dimensional space, and it was really easy to understand.",
            "It's easy to statistics in that scenario, but of course high throughput experiments now allow us to simultaneously measure hundreds to thousands of neurons.",
            "But not under that many experimental conditions because you have limited time with which you can measure from a biological sample.",
            "Without that biological sample safe, it's an animal that gets tired.",
            "If it's a cell, it dies, so you can't measure that many trials, so you get data living in a very high dimensional space and you don't have that many data points, so we can't play the tricks of throwing lots and lots of data to deep neural network that the regime of limited data is essential in biology to conquer, and this is a big challenge for machine learning applications to biology.",
            "We've been actually thinking about how much data do you need to learn particular problems by using a nice analogy between machine learning and statistical physics where maximizing the log likelihood is like minimizing an energy function.",
            "The parameters are like thermal the parameters in the model you're trying to learn are like thermal degrees of freedom, and the data is the data.",
            "It's some quenched interactions that you're stuck with and you ask how low can the energy get, or how high can the log likelihood get.",
            "And we can actually compute that analytically in various cases.",
            "For example in compressed sensing.",
            "And so I'd like to just advertise this work before I move on to deep learning.",
            "There's a principle that that kind of permeates machine learning, which is maximum likelihood, right?",
            "It's a very good principle in this setting.",
            "In fact, there are theorems that are saying in low dimensional statistics, maximum likelihood is the optimal thing to do, because you have theorems like the Cramer Lat Row bound saying you can't do better than X and you can show that the maximum likelihood that estimator saturates X.",
            "But in the high dimensional setting, these theorems don't hold, so it could be the case that there could be something better than you can do that you could do.",
            "Then maximum likelihood, and actually recently we figured out what's the optimal convex inference function that you could possibly do.",
            "And it turns out that what it is is it's smoothing the log likelihood function with respect to the parameters where the amount of smoothing increases as the amount of data decreases, and it's a particular non Luther NEO smoothing operation so that when the amount of data is very little, the smooth log likelihood function becomes just a quadratic quadratic bowl.",
            "So quadratic inference is actually optimal in very high dimensions, is not related to the well known and used regularize maximum so.",
            "OK, so there's no guarantee that a particular regularised maximum likelihood will be the optimal convex optimization problem you want to solve.",
            "This gives you what the optimal convex algorithm optimization problem you want to solve when the log likelihood function is is log concave or yeah.",
            "There's a generalization of this to map inference, so so you know, there's this common idea that if you know the correct distribution then you should do a map inference, right?",
            "But actually even that's wrong in high dimensions, it turns out map is not the optimal thing to do.",
            "If you want to solve an optimization problem, there's better optimization problems to solve than map.",
            "And again you want to smooth the prior.",
            "So here's an interesting situation where even if you know the correct prior, the thing you want to optimize is not the log prior.",
            "But the smooth log prior.",
            "And now, of course, the best thing you can ever do is compute the posterior mean, because that's the minimum mean squared error estimator parameters, but often can't.",
            "You can't.",
            "You can't do the high dimensional integrals to compute the posterior mean, so this is restricted to situations where you want to solve a convex optimization problem.",
            "So I just wanted to advertise that here because it's an interesting counterexample to the notion that maximum likelihood and map are always the best thing to do when you know when you have the correct distributional assumptions in high dimensions.",
            "Of course, the theorems that guarantee that don't hold, and there's something better you can do, and we've recently found it.",
            "Um?",
            "OK, so."
        ],
        [
            "And in case if you're interested in the interplay between statistical physics and you're a science in machine learning, we wrote about a 70 page kind of review article outlining a whole bunch of topics from spin glasses, neural networks, learning theory, random matrix, 3 random projections, compressed sensing, and so on.",
            "It kind of forms the basis for a lot of theoretical basis for a lot of the things that we think about."
        ],
        [
            "OK, but if we want to go further, if we want to go sort of beyond very specific biological systems to sort of more general theories.",
            "How do we make progress?",
            "So I think now is a really interesting time where there can be a new type of alliance between theoretical neuroscience and theoretical slash, applied machine learning and the motivation for the alliance.",
            "We kind of.",
            "We kind of outlined the logic that I'm going to give it to you in this current opinion piece, but the motivation is the following.",
            "We we, at least in neuroscience, are in it because we want to understand how the brain works.",
            "OK, but the natural question is what does it mean to understand how a brain or in neural circuit works?",
            "We don't actually have a good answer to that question, despite the fact that we're working in this field.",
            "Approximal version of that is well, what if we can understand how the connectivity and dynamics of a neural circuit gives rise to some emergent behavior?",
            "Or and learning, of course, is extremely important.",
            "So another facet of it is how did neural activity and synaptic learning rules conspire to self organize useful connectivity that subserves behavior?",
            "OK, physicists, when they've traditionally looked at this, have often tried to understand the nature of dynamics and random networks.",
            "But of course these random networks have no function, so we'd like to try to understand networks that actually do something OK, so the field of machine learning, as you know, has generated a plethora of learn neural networks that all do very interesting things.",
            "Oftentimes interesting things that we know of no other way to do in any other artificial system.",
            "OK. Now neuroscience through various brain initiatives that you may have heard about is promising an even bigger explosion of data where we can record many, many neurons sometimes get the connectivity between all the neurons that you've recorded from a natural question that US theorists are sort of scratching our heads is what are we going to do when we get all that data?",
            "How will we understand it, OK?",
            "In the in the networks that you guys are generating, we actually know everything about these networks.",
            "We know their entire connectivity, we know their dynamics, we know they're learning rule, we know their entire developmental experience from when they were little babies with random weights to big bad networks with trained weights, right?",
            "Because we know there we know their training data, they were exposed to, yet we still don't have a meaningful understanding of how they learn and how they work.",
            "And so I think this is a really intriguing warm up problem.",
            "For us to think about before we attack the brain.",
            "Or simultaneously now, I don't think for a second that if we understand how these artificial networks work, will understand how the brain works.",
            "I think the principles are very different.",
            "The details are very different, but I think the methods that we might use to arrive at that understanding might generalize to help us design experiments in neuroscience to arrive at a different but related understanding.",
            "In real neurobiological systems.",
            "So how might we do that?",
            "So let me give you some eggs."
        ],
        [
            "Samples OK of this, so this is kind of going to be the shape of things to come in.",
            "The interaction between machine learning and neuroscience.",
            "So here's an example where you take a complicated the basic basic framework is you take a complicated behavioral task.",
            "You record many many neurons in a brain, and you get complicated neural dynamics at the end of the day, and you really don't understand the complicated neural dynamics because all you have is time series of neurons.",
            "So what you could do is you could also train a neural network to solve the same task, so the behavior alone.",
            "Has has embedded itself into the weights of the network and then and then you can compare the dynamics of the network to the dynamics of the brain and if they match.",
            "Then you have a handle on trying trying to understand what kind of neural computation might be going on in the brain.",
            "So this is an example of a success story in that respect where a monkey was asked to do a context dependent discrimination task where some dots are moving right, some dots are moving left, some dots are red, some dots are green, and the monkey supposed to report on certain context what the majority color is, and in other contexts what the majority direction is.",
            "And remarkably, the monkey can do this.",
            "And there was some very interesting context dependent dynamics that occur in the circuit and that could be re capitulated by a model train to solve the task and actually revealed a principle in new principle for doing context dependent integration.",
            "There was an emergent property of the circuit rather than just a gating mechanism that you'd find, for example, finding LCM right.",
            "This is just this is just a vanilla RNN.",
            "It wasn't analysis team.",
            "Ellis teams are a step backwards from my perspective.",
            "From the perspective of modeling neuroscience, but that's.",
            "It's any work.",
            "OK, I can.",
            "I can give you I.",
            "Well, no, but I mean individual neurons don't have forget gates and right gates and read gates right?",
            "So if we want to compare the dynamics of an STM and understand how function emerges from individual neurons that are not that smart LS teams can't answer that question right?",
            "Center with Bruno's talk about all the Mountaineer dynamics going on with Android.",
            "I mean, even if that's their right, it's relatively well modeled by threshold nonlinearities and temporal filters.",
            "In a two layer neural network, but not with forget gates that can be trained overtime and Bruno's vigorously nodding his head.",
            "So I'll stop there.",
            "Yeah, yeah.",
            "Yeah, yeah.",
            "Yeah, it's the interpretability issue is with LS teams in regards to the application.",
            "In neuroscience is an issue.",
            "Of course they work great in lots of tasks, so I mean they should be.",
            "They should be studied, but any methods to improve training in vanilla RNN would be incredibly useful for for applications in neuroscience."
        ],
        [
            "Another example is Dan Yamens and Jim to Carlos work, where they trained networks to solve an image recognition task.",
            "The same image recognition actually a different image recognition task, and then they compared neural activity in different layers to neural activity recorded from it in V4.",
            "And it turns out activity in the deep layers kind of mimicked activity in it in activity in the middle layers mimicked activity in V4.",
            "So that's actually it's a fascinating advance, right?",
            "But it begs the question, well, we don't actually understand what this model is doing, right?",
            "Can we extract principles for what's going on here?",
            "So, So what might?",
            "What might would be able to do?",
            "I can think of several approaches, but one would be.",
            "Let's say you train millions of networks to solve the same tasks.",
            "They're all going to be different due to vagaries in the initialization and training algorithm or whatnot, but there must be some computation.",
            "There must be something common across all of the networks designed to solve a particular task, and there will be other things.",
            "Other observables that are variable across the set of networks designed to solve a task.",
            "What are the computational invariants across a set of networks designed to solve the task?",
            "Maybe those are the observables that we should focus on in measuring in the real brain, and the latter of observables that are variable across a set of networks and solve a task might be observables that are not that important to measure in a real brain, because those observables could be historical accidents of learning evolution or adaptation right in your science, right?",
            "We're being faced with a huge magnitude of details and we don't know which details are important.",
            "Or form the essence of the computation.",
            "The brain region is trying to do even in those cases where we're lucky to know what the computational brain is trying to do and which details are just not important, right?",
            "So we need a theory of what's important and what's not important.",
            "Another, another approach might be we need a hierarchy of simpler models.",
            "You know model reduction might be a way to understand what's going on, so we need theories like that.",
            "We don't have those theories yet.",
            "I'm not.",
            "I'm not aware of any general theories that we have yet, but we've been thinking."
        ],
        [
            "About some other theories related to this, so you could, for example, my postdoc Joshua sold extreme kind of likes to.",
            "Categorized some of the deepest puzzles of deep learning into kind of three categories, right?",
            "One is trainability, right?",
            "So if you're solving some task, if a good network solution exists with small training error.",
            "How do you find it?",
            "And Moreover, why does it take so long to find it?",
            "IE.",
            "What makes a learning problem difficult and we've been thinking about?",
            "We've been thinking about that and I'll talk about that.",
            "The other is expressivity, right?",
            "So what is it that a deep network can express that shallow networks cannot and various people have been working on that as well?",
            "And we've had some recent results where we actually connect the notion of deep neural networks to the theory of chaos.",
            "Now I don't know if that's good news or bad news.",
            "I mean Chaos theory is hard, and what we're showing is that deep networks are related to that, but I think it's I think we can work around it.",
            "And then the other interesting thing is generalizability.",
            "This is most probably the most profound problem.",
            "What principles to deep networks use to place probability or make decisions and regions of input space where you have very very little data?",
            "And of course there for classifiers there's arguments like the VC dimension and VC dimension based generalization bounds and things like that, but we'd like a more geometric theory that tells us.",
            "You know, given limited data, how does it propagate labels?",
            "What are the principles that it uses?",
            "We don't really have a theory for that.",
            "We've done a little bit of work in how to learn generative models far away from the training data.",
            "By destroying the training data quite a lot and trying to trying to recover that destruction.",
            "This is motivated by ideas, anonymous dynamics and trying to reverse the flow of time in a diffusion process.",
            "So for the deep learning theory, part of the talk, I'll focus on this and then I'll move to neuroscience, but you'll see what I mean by what might be considered.",
            "Progress in terms of trying to get a theory that could help both machine learning and neuroscience."
        ],
        [
            "So this is actually where it all started.",
            "I kind of showed up.",
            "At Stanford, I started talking to Jay McClelland.",
            "This part of the talk it equally called the Misadventures and applied physicist wandering around the psychology Department.",
            "So J kind of whispered into my ear all these interesting phenomena that infants do.",
            "And more generally, the idea of semantic cognition, and this is also work with Andrew Sachs, who used to be a grad student with us.",
            "Now as a postdoc at Harvard."
        ],
        [
            "So what is semantic cognition?",
            "OK, so semantic cognition relates to our ability to learn, recognize, comprehend and produce inferences about objects and properties in the external world.",
            "That are not present in our current perceptual stimulus, right?",
            "So, for example, does a cat have fur or do birds fly right?",
            "You can all answer these questions, despite the fact that there is no cat or bird in the room.",
            "And so our ability to do this likely relies on our ability to form internal representations of categories in the world, right?",
            "We never see the same stimulus twice, so once we see a novel stimulus, we categorize it into a stimulus category.",
            "And then we use that categorical representation to both answer questions and take actions, right?",
            "So these categorical internal representations are the basis for our ability to act in a world that never repeats itself, ever, OK?",
            "So there's been a lot of."
        ],
        [
            "Work in psychology about probing semantic cognition in infants and, in particular, probing its development.",
            "So for example, looking time studies, can an infant distinguish between two categories of objects and at what age?",
            "So you can actually show.",
            "Let's say you want to detect whether an infant can detect differences between cows and horses, right?",
            "So you show up, you show a sequence of pictures of cows.",
            "The first time, the Infancies the cow, it looks a lot, and then the looking time goes down.",
            "Then you show the first horse, and if the infant is old enough, the looking time will go up a lot.",
            "But if the infant is not old enough for looking, time will stay the same.",
            "So the fact that the looking time goes up suggests that the infant can discriminate between horses and cows and realize that this is a member of a novel category, not their original category, and so for every categorical distinction, you can figure out at what age it's learned, and then if you create a a tree of categorical distinctions, an infant can learn where the hide up the tree corresponds to the earliest age at.",
            "You know, the higher up, higher up the distinction arises in the tree corresponds to how early the infant can do it.",
            "You see a remarkable semantic tree that looks a lot like the way we would categorize the world as adults.",
            "I'll show you examples of that.",
            "You know there's also property verification task and Canary move.",
            "Can it's saying there's different response latency's and so the response latency tells you that there are certain central and peripheral properties.",
            "Two categories category membership queries is a Sparrow.",
            "Bird is an ostrich, a bird.",
            "This one gets answered much more quickly than this one, which suggests that are typical and atypical category members.",
            "And of course, the most interesting thing is generalization.",
            "You can measure patterns of inductive generalization in infants, and these patterns of inductive generalization change overtime.",
            "Infants tend to overgeneralize 1st and then learn the correct pattern of generalization.",
            "So I'm really going to focus on the development of knowledge and infants, though.",
            "We've attacked all of these questions."
        ],
        [
            "So this is an example of an infant.",
            "This is actually my son.",
            "Let's face it, he doesn't have a lot going for him.",
            "Alright, he's short.",
            "He's bald, he's still living with his parents.",
            "It's not potty trained, right?",
            "But he does have going for him, and all infants have going for them.",
            "Is that they're incredible learning machines, right?",
            "They can soak up all this knowledge and ultimately like to learn that.",
            "Learn what's going on there."
        ],
        [
            "OK, so I'm going to so J McClellan wrote this beautiful book.",
            "If you haven't seen it before.",
            "It's called semantic cognition.",
            "It's a fantastic book to 1st learn all about this stuff.",
            "Jay was doing kind of deep networks before they became popular.",
            "Or rather the first time they became popular and so so one of the things is the progressive definition of concept.",
            "So this is just I don't intend for you to read.",
            "This is just to show off how much work J income.",
            "Co did, but I wanted to focus on this progressive differentiation of concepts, which is this idea that infants learn coarse grained discriminations 1st and then learn finer scale scale discrimination.",
            "So for example plants versus animals and then different types of animals get learned later in different types of plants get learned later and this holds even if you control for perceptual similarity.",
            "OK."
        ],
        [
            "So how did Jay model this?",
            "Well, J model this using a deep neural network, so he he had a toy data set where we had it.",
            "He had a bunch of.",
            "He had a bunch of objects OK and he had just A1 hot representation so but nothing as long as you have any orthogonal representation here, you're fine and he had a bunch of questions that you can ask the network and you had a bunch of properties.",
            "So for example, a Canary can grow, it can move, and so on, right?",
            "And you just trained the network to spit out this input output map and he looked at the internal representations of this network.",
            "The Inter representations of the objects in this network as a function of developmental time."
        ],
        [
            "And he looked at two ways of looking at it.",
            "One is multi dimensional scaling.",
            "So he plotted the internal representations in a geometry preserving way as a function of developmental time.",
            "And you see, just like in an infant, the animals separate from the plants 1st and then the fish separate later and the birds separate later and so on.",
            "The trees and Flowers separate later and then finally individual items separate.",
            "And also this is a hierarchical clustering, you viewer slowly the network learns the structure of the data set.",
            "OK, so what's happening is the semantic similarity of the items is getting embedded in the neural representations of the network.",
            "OK so intra."
        ],
        [
            "Only this has been observed in the brain, not over development, but at the end point of development.",
            "I don't know if you guys have seen this before, but this is So what people did was they showed many, many images.",
            "The same set of images to both humans and monkeys.",
            "They measured neural responses in monkey inferotemporal cortex.",
            "This is high brain level area that contains the face cells and so on.",
            "They measured many many neurons an measure.",
            "The similarity or dot product between neural activity patterns in the monkey.",
            "For pairs of objects and this is the similarity matrix that did so.",
            "Sorry, this is for the monkey and then for the human they did the same thing, except they did multi voxel fMRI activity patterns, and they did the same thing, and despite the very different nature of both the species and the measurement apparatus, they got very similar.",
            "Similarity matrices and this."
        ],
        [
            "The same picture using hierarchical clustering.",
            "So actually I want to talk about this today, but we recently proving a theorem that if you train these neural networks from random initial conditions, the dynamics at the level of similarity matrices is contractive so that the similarity matrix is an approximate invariant of learning, but?"
        ],
        [
            "Cardless this is empirical demonstration that monkeys and humans, at least at the level of similarity matrices, see the world in the same way, which is kind of remarkable.",
            "So what were the question we're addressing is over developmental time.",
            "How does the structure get embedded in the network?"
        ],
        [
            "Let me skip this slide OK?"
        ],
        [
            "So when I first saw when I first saw this result, I was both."
        ],
        [
            "Founded and highly disturbed, astounded because I was like this is really cool.",
            "The network is behaving qualitatively like an infant.",
            "But this is really striking.",
            "I mean I don't understand why this is happening, that's why it was disturbed.",
            "So we wanted to understand how this works.",
            "So we asked a series of math."
        ],
        [
            "Questions what are the mathematical principles underlying the hierarchical self organization of internal representations in this network?",
            "For example, what are the relative low rolls of the non linearity in the input output transfer function of this network or the learning rule of the input statistics?",
            "Is is the network exploiting nonlinearities to learn very high order social structure in the data and that's why you get this highly nonlinear learning dynamics?",
            "Or could it be something simpler than that?",
            "And also there's this notion in neuroscience of a coherent category of psychology of a current category.",
            "For example, the set of all dogs is like a coherent category, right?",
            "It's so coherent that we have a name for it, but the set of all things that are blue is just intuitively not a coherent category, right?",
            "And we don't ever learn a word for that, and so there's a notion of of coherent versus incoherent categories, and we'd like a mathematical understanding of category coherence as well, and how it relates to learning speed.",
            "And also how?",
            "Why are some properties learn quicker than others and how can we explain changing patterns of inductive generalization for this talk?",
            "I'm just going to focus on this in this category.",
            "Currents and learning dynamics."
        ],
        [
            "So when you look at these train networks, they actually don't explore the nonlinear regime of the transfer function that much, so we hypothesize that maybe even a linear network could exhibit this kind of dynamics.",
            "Now, of course, a linear deep network is still a linear network because the composition of linear functions is linear, so linear deep networks of course don't gain any expressive capacity with depth.",
            "However, their learning dynamics changes dramatically with depth."
        ],
        [
            "To see that, imagine what you would what would happen if you trained a linear deep network on a certain input output training set.",
            "Right, so So what should we do?",
            "Oh, I don't have the error function here, So what should be doing is you'd be.",
            "You'd be minimizing an error function that roughly looked like.",
            "The error is the output minus one layer of weights times one layer of weights times the input squared.",
            "Right?",
            "So this error function is actually quartic in the weights, which means the gradient is cubic in the weights, and because there's products of weights, this is actually a nonconvex learning dynamics.",
            "If you of course had only one layer of weights, then the error function be quartic and quadratic in the weights would be a convex optimization problem, and the learning dynamics would be linear, but everything changes when you add a second layer of weights.",
            "Exactly, yeah, this is W one and this is W2 layer one layer 2.",
            "So if you write down the learning dynamics."
        ],
        [
            "If you work in the limit of batch gradient descent with slow learning rates, small learning rates.",
            "You can actually write down a continuous time evolution.",
            "Of the learning dynamics of the network and you can understand exactly how the input statistics drives the learning because the network input output response is linear, the learning dynamic is only sensitive to 2nd order statistics in the input output data.",
            "In particular, the input covariance matrix and the input output covariance matrix.",
            "That's what drives the learning dynamics, and we'd like to understand just have a general analytical solution to the learning dynamics."
        ],
        [
            "And so it turns out you can organize the learning dynamics through the singular if we work."
        ],
        [
            "Situation where the input is white and right, which we often do in practice, then all that drives the learning dynamics is the input output covariance matrix.",
            "And it turns out."
        ],
        [
            "The singular value decomposition of the input output covariance matrix drives the learning OK, so you all know singular value decomposition."
        ],
        [
            "Once you have the singular value decomposition of the input output covariance matrix, you can write down an analytical formula for the learning dynamics.",
            "In particular, the product of the weights from layer one to two and layer two to three as a function of time.",
            "For certain initial conditions, behaves like.",
            "The time dependent SVD.",
            "Of the input output covariance matrix, where the time dependent coefficients start from small random initial conditions.",
            "Because we started the weights from small, random or any random initial conditions.",
            "And then the the coefficients or the time dependent single values.",
            "Traverse a sigmoidal type learning curve where it stays flat for some period of time and then it suddenly makes a transition to the correct singular value.",
            "OK, and the time of this transition is occurs at one over the singular value, so just at a very, very high level.",
            "What's happening is stronger statistical structure in the data is learned earlier.",
            "OK, that makes intuitive sense for this particular problem.",
            "It turns out the strength of statistical structure is determined by the singular value of an input output covariance matrix, and the time is just one over the singular value.",
            "It's as simple as it can possibly be.",
            "Of the input output covariance matrix."
        ],
        [
            "So this matrix right here.",
            "So I take the training data and I correlate each neuron in the training data with each output neuron.",
            "Each input neuron in the training data with each output neuron in the training data.",
            "Yeah, that's a matrix.",
            "I am not something that matrix.",
            "Yeah, exactly, it's it's it's."
        ],
        [
            "One by three by one matrix, and I'm writing down a theory."
        ],
        [
            "For the product of the weights W2, one times W 3, one which is also N3 by N1.",
            "Which singular value do you mean?",
            "All of them all of them.",
            "So every single mode of this connectivity?",
            "Undergoes its own independent dynamics, an each of them transitions at a certain time, right?",
            "So this explains the existence of plateaus.",
            "In the in the error function right because whenever a singular value is wrong, there's an error and whether a single value transitions to a correct answer.",
            "There's a drop in the error.",
            "Right so intuitively, what's the OR?"
        ],
        [
            "Version of these plateaus.",
            "It turns out, if you look at the dynamics of learning in the network, the vector field and weight space actually has these saddle points in them.",
            "Where this might be the manifold of correct weights, OK?",
            "And there's a.",
            "There's a saddle point here where the dynamics and weight space gets attracted to the saddle point along the stable manifold, but then gets repulsed along the unstable manifold.",
            "The time it takes to get attracted to the stable manifold is what determines the time you're stuck in the plateau, and then the repulsion is fairly rapid.",
            "So actually it's actually not just it's this hyperbolic part that's slow, and then once you once you escape the vicinity of the saddle point, the learning is very rapid, so saddle points will become important later.",
            "OK, so just."
        ],
        [
            "To summarize this theory again, stronger statistical structure is learn faster, where again this fiscal structure, singular value, and the.",
            "This is the learning time is one over singular vector, and what's the pattern?",
            "What's the knowledge about the external world that gets learned?",
            "Well, the singular vectors get are what gets learned.",
            "OK, so now the next question is what does all this have to do with the hierarchical differentiation of concepts?",
            "That's what we started off with.",
            "OK, so now."
        ],
        [
            "OK, so.",
            "So the interesting thing about JS work, he didn't analyze a specific data set but but but what we'd like is a general theory for arbitrary datasets.",
            "So can we, can we move beyond specific datasets to get general principles of what happens when a neural network is exposed to hierarchical structure?",
            "And I think this will be So what we look at is we consider it a neural network trained with data generated by the hierarchical generative model, and this is."
        ],
        [
            "I think part of a more general principle that I think will be required to push theory forward in deep learning and also in neuroscience is that we have these two very different methods for modeling, right?",
            "Both data and brains, right?",
            "We have hierarchical generative models that are statistical models for generating data there really beautiful because we understand exactly the assumptions that go in into the generation of data and then we have neural networks that we train.",
            "And what we'd like is, we'd like to come up with a bridge between these two worlds where we can understand how the structure of a hierarchical generative model is embedded overtime into the weights of a neural network.",
            "And we, if we have a deeper understanding of that, then will of course have a much deeper understanding of both learning dynamics and expressivity of neural networks.",
            "So this is probably the simplest situation where we can get that kind of understanding.",
            "So what kind of hierarchical Gen?"
        ],
        [
            "Model are we going to consider we're going to consider a hierarchical generative model that looks that mimics the process of evolution that generated the toy data set that Jay was working with?",
            "So consider just a bunch of.",
            "So imagine that the different items or in your training data, say the different animals and plants are sitting at the leaves of a tree, and you have different properties like has wings or doesn't have wings that diffuses down the tree, and these are like speciation events where on one branch it might flip another branch it doesn't.",
            "OK, so you generate features through this branching diffusion process down a tree.",
            "And you get feature vectors for each each object.",
            "So clearly what will happen is the similarity structure of items that are close together on the tree will be higher than items that are further apart on the tree."
        ],
        [
            "So.",
            "All we need to understand in order to understand learning dynamics in these networks is understand the singular value decomposition of hierarchically structured data.",
            "That's all we need.",
            "OK, it turns out we can compute all of that analytically, and it sort of makes intuitive sense at the end of the day.",
            "So assume that we have many, many features that are generated, right?",
            "So we don't have to worry about Stochastic City with respect to finite number of features that stochastic is weak as soon as the number of features becomes order 100.",
            "OK, so if we look at the single if we look at the singular vectors of the input output covariance matrix, you have two types of singular vectors, the right or input singular vectors on the left or output singular vectors.",
            "The input singular vectors are functions on the input space, which are just the the animals.",
            "So their functions on the leaves of the tree.",
            "OK, the singular vector with the largest singular value is just a DC mode that doesn't make any distinctions along the tree.",
            "The next singular vector with the next largest singular value is a singular vector that is positive on all of these nodes and negative on all of these nodes.",
            "So this singular vector can make categorical distinctions at the broadest categorical level.",
            "The next singular vectors comes in a degenerate pair and they make distinctions finer scale distinctions between, say that despair or despair in despair, and then you have the singular vectors.",
            "The smallest singular values that make the finer scale distinctions.",
            "So if you look at the similarity structure of data generated from this model, it has this blocks within blocks, hierarchical structure, and these are actually the eigenvectors of this hierarchical matrix.",
            "OK, so now and then, if you look at."
        ],
        [
            "Actually the eigen values we have a theory for the OR the singular values.",
            "We have a theory for the singular values and it matches simulations and so on.",
            "But but basically what happens is the singular values are decreasing function of the hierarchy level.",
            "OK.",
            "So now when you put the two results together you can immediately see."
        ],
        [
            "What happens?",
            "Any network must exhibit progressive differentiation of concepts on any data set generated by this class of hierarchical diffusion processes.",
            "Basically the network learns input output modes in a time that's one over the singular value, and the singular values of broader hierarchical distinctions are larger than those of finer hierarchical distinctions, and the input output modes are singular.",
            "Vectors correspond exactly to hierarchical distinctions in the underlying tree, so at the end of the day."
        ],
        [
            "Hey, we can come up with an analytic formula that we can plot for the learning dynamics of this network.",
            "So this is multi dimensional scaling of the learning dynamics in the linear network and as you can."
        ],
        [
            "See it recapitulates in qualitative structure the empirically observed learning dynamics and the nonlinear network, right?",
            "So I would say that this is sort of the difference between simulation and theory, where here we kind of understand a lot better the principles of this striking phenomenon that was going on here.",
            "So."
        ],
        [
            "OK, so you need actually even deep linear networks show this, but shallow networks with no hidden layers do not show this actually.",
            "And a surprise was actually that only the 2nd order statistics of this hierarchical structure data are sufficient to drive this nonlinear hierarchical differentiation process on weight space.",
            "Yep."
        ],
        [
            "Deep linear networks.",
            "Yeah, yeah.",
            "What happens if your data was not balanced like you have way more say fish?",
            "Oh yeah, yeah that's a very interesting.",
            "So then what happens is we?"
        ],
        [
            "Looked at that too that distorts the singular vectors and places more concentration on the objects that have more frequency.",
            "Well, actually showing example of that in a different concept where we get rid of hierarchy, but we put in different frequencies.",
            "That's coming next.",
            "So actually."
        ],
        [
            "We can we can look at a lot of phenomena in psychology now, like illusory correlations and learning.",
            "So for example.",
            "You could ask a child does a worm have bones right?",
            "And every single child will say yes or warm has bones if they're young enough and if they're old enough, they'll say no.",
            "So they make these illusory correlations and they overgeneralized you know.",
            "But we can come up with analytical explanations for why that happens in these networks, and a whole bunch of stuff I just wanted to focus on category coherence which relates to Erin's Question.",
            "So."
        ],
        [
            "So OK, so yeah, so we can answer questions like why are some properties easier to learn?",
            "Why are some?"
        ],
        [
            "Items more typical."
        ],
        [
            "Members of a category.",
            "How does inductive."
        ],
        [
            "Analyzation work going to skip all of that, but I'm going to."
        ],
        [
            "Category coherence, because this is something that was kind of bedeviling psychology to it to some extent.",
            "So what is a category and what makes it coherent?",
            "So simple proposal is a category is a subset of objects sharing a subset of features, right?",
            "This is like a very simple barebone definition of a category, right?",
            "So kind of a Gordian knot then, is how do you learn a category?",
            "Well, in order to learn a category you need to identify the objects that belong to the category.",
            "But in order to do that you need to know which features are important for the category.",
            "On the other hand, if you could identify the features that are important for the category, well, in order to do that, you must know which objects belong to the category, right?",
            "And we've already talked about the notion of coherent categories like the set of all things that are dogs and incoherent categories, a set of all things that are blue.",
            "So the question is, how do you solve this problem?",
            "And in this crowd it's not going to be surprising that neural networks can kind of bootstrap and simultaneously solve both problems at once, but how does it do that?",
            "What's a theory for how it does that?"
        ],
        [
            "OK, so this is again my son and he's getting lots of experiences throughout his life.",
            "My lab decided to give him a pink Unicorn as a gift.",
            "My lab is also trying to make pink unicorns, my lab mascot.",
            "Against my wishes, but I don't know if I have any leverage, I think anyways, it's not.",
            "You gotta pick your battles.",
            "I'm not going to battle this one.",
            "Yosho knows where you are and knows what I'm talking about, so.",
            "Anyway, so you see a sequence of items overtime, so you see a stream of experience where you see a subset of objects with a subset of features and you have to construct a current representation over it over that stream of experience.",
            "So here's for example a data matrix where you have a bunch of features and a bunch of objects and some features have the object, in which case you see a yellow dot and some they don't, in which case you see a blue dot, so I don't understand how babies learn, but we can under."
        ],
        [
            "And how these neural networks learn?",
            "And so when this neural network was exposed to this data?"
        ],
        [
            "Let's see, will this work?",
            "OK, the movie did not work, but I'm prepared for."
        ],
        [
            "As it turned out that this is a, this is a snapshot of how the internal representation Scott learned from this data set.",
            "So blue is early in time and yellow is later in time.",
            "So basically one group of objects shot out, right?",
            "So these each point is an object, so there's 1000 objects.",
            "One group of objects shot out very quickly.",
            "One group of objects shot outs more slowly.",
            "And because of this yellow, this is the last set of objects to shoot out, and a whole bunch of objects were discarded.",
            "They didn't get learned.",
            "OK, so why did this happen?",
            "You can now look at the weight matrix of this network and re permute the objects intelligently based on the weight."
        ],
        [
            "Matrix and you show that once you re permute the features and objects you find out that there were actually a preponderance of of objects with a subset of features, so there was a big category of small category in a smaller category, right?",
            "And it turns out that these the largest category was the one learned first.",
            "The second largest was learned 2nd and the smallest was learned last.",
            "So now, but we'd like to make this much more quantitative.",
            "We'd like to have a theory for how.",
            "The size of a category determines how quickly it's learns.",
            "And Moreover, what's the smallest size detectable category yet?",
            "This is this is associative learning where.",
            "Where the?"
        ],
        [
            "Well yeah, so so basically.",
            "I mean, it's the same scenario that Jay was looking at where you get objects and properties right?",
            "So whether or not you want to call that supervisor, you don't get category labels right?",
            "So basically what you do is you're seeing this matrix, huh?",
            "No, no, you get object identity in the input.",
            "It's like.",
            "You have a different species of dogs.",
            "Yeah, features are like.",
            "The features you get the features.",
            "Yeah, so literally.",
            "I have a network with 1000 inputs which is A1 hot encoding of object identity.",
            "No, that's object identity.",
            "No, no, the label.",
            "There's only three labels in this data set."
        ],
        [
            "Whether you're in this category, this category of this category.",
            "Baby cluster categories, but it gives her label category.",
            "It never gets access to a number 1, two, or three that says which category, man, yeah?",
            "There's one 2000.",
            "It gets access to 1000, yeah, but that's the sensory input.",
            "And it gets access for each of those.",
            "What is the feature vector for that thing?",
            "So then it discovers in.",
            "I don't know what you want to call it, but it discovers the statistical structure of the input in the sense that there are special subsets of objects and special subsets of category of features that Co occur together, right?",
            "OK, so we have an analytic theory."
        ],
        [
            "For this learning dynamics that depends on random matrix theory, and I won't go into the details of that.",
            "But actually here's a."
        ],
        [
            "Here's a question.",
            "OK, it stands to reason that if I make this block smaller, maybe the network will never learn it right?",
            "There might be a minimum size that I need this block to be.",
            "How big do you think this needs to be?",
            "So here's 1000 objects.",
            "And 1600 features.",
            "How big do you think this block or how small do you think this block can get before you can't see it anymore?",
            "Before this neural network cannot learn it anymore?",
            "What do you think?",
            "Depends how long you train.",
            "So we're learning a linear network, so I could train it forever and it would get to the same answer.",
            "Or by the way, this is a non convex optimization problem that baldeon brunette showed along time ago.",
            "Like you know, in the last Millennium that.",
            "It literally was the last Millennium.",
            "It's OK, it's not more than 16 years ago.",
            "That even though this is a non convex optimization problem.",
            "It has no local minima, it just has saddle points, which is why I could answer Yoshi's question the way I did, because it's a linear network, you train it forever, you'll always get to the same answer.",
            "So it's not an issue of of training time, so it's an issue of statistical detectability.",
            "So do you think let's say you had 30 objects and 20 features, could you detect it out of 1000 and 1600?",
            "This is a stupid linear network, right?",
            "Yeah.",
            "Yeah.",
            "Not for this one because it's linear, but what happens is for this network then."
        ],
        [
            "Number of neurons in the hidden layer will give you an upper bound of the number of categories you can learn.",
            "It turns out for this kind of a data set, so it's all about the number of neurons in the hidden layer that matters.",
            "Alright, let me just tell you that."
        ],
        [
            "Theory it's actually a little bit surprising.",
            "I wouldn't have guessed it immediately, but we worked out.",
            "You can view this matrix as a low rank matrix plus annoys matrix, and there's well established statistical theorems about how the eigenvectors and eigenvalues of low rank matrices get perturbed when you add noise to them.",
            "And when you work through all those theories and translated into this framework, you get a very simple result, OK?",
            "So P is the probability that if you're within this cluster, features present and if you're outside this cluster, the probability of features present is Q, so there's a signal to noise ratio that governs this problem, which is the P -- Q divided by the standard deviation of the of the noise and the outside.",
            "OK, then there's the size of the category.",
            "It turns out it only depends on the shape of the category through its area, so it's the number of objects that belong in the category times the number of features that belong in the category.",
            "OK, and the threshold for detectability is just that the signal to noise ratio times this category side size is only bigger than the square root of the size of the universe.",
            "Essentially, where the universe is the product of the number of objects and number of features.",
            "So the way you I guess set up the data set and run these yellow boxes.",
            "It seems like each category has like strictly non overlapping features.",
            "Is that yeah yeah, so actually.",
            "So that's what I'm saying is trying to dissociate frequency affects from hierarchy effects.",
            "So here we worked out exactly what happens when you sorry.",
            "So you have to go back further.",
            "Here's where we."
        ],
        [
            "Worked out exactly when you have equal frequencies, but hierarchy and you get this hierarchical structure in the singular vectors.",
            "Here we worked out what happens if you have no hierarchy but different frequencies and."
        ],
        [
            "And then there's a more complicated scenario.",
            "When you mix the two, but you can work it out.",
            "Ultimately, the end of the day frequency affects and hockey affects conspire to determine what gets learned and how fast.",
            "Right?"
        ],
        [
            "In"
        ],
        [
            "So one thing I would love."
        ],
        [
            "From the deep learning community is toy models for the tasks that you guys are solving right?",
            "Because we have no mathematical control over what's in the image.",
            "Net database, right?",
            "I don't know how to describe it mathematically, but I would love a mathematical model of what you think is in that day that captures the essence of what you think is in that database.",
            "And then we can start to reason about how a neural network will respond to that mathematical model of data.",
            "I think that's the route for progress forward in understanding train networks in deep learning.",
            "Now, because of the culture of the field is so focused on winning competitions, it's hard to get stuff like that published.",
            "But in the history of science, a deeper understanding of science is always lead to better engineering in the long term.",
            "So I think it's shortsighted to focus on winning competitions all the time and not try to get understanding.",
            "Anyway, I wasn't I didn't mean to say that, but I just want to throw that out there as a debate point for this field, right?",
            "No.",
            "Joshua must have picked students were of his mind like mine anyway, but it's it's.",
            "I could go on and on about my opinions on various things, but I'll try to."
        ],
        [
            "Anyway, it it takes all.",
            "It takes different kinds of people to do different kinds of things, so alright, so OK, Now we've been."
        ],
        [
            "Analyzing these deep networks, but the question is, can we learn anything about about practically training non linear networks better?",
            "And I'll give this short shrift because it's published, but basically we'd like to answer for even deeper networks, right?",
            "The dynamics of learning right?",
            "It's very nontrivial.",
            "You have these plateaus and sudden transitions.",
            "How does training time scale with depth?",
            "How should the learning rate scale with depth?",
            "How do different weight initializations impact loading speed?",
            "These are very practical questions, right?",
            "And we'd like to have a theory for that.",
            "And so when we analyze the learning dynamics of these deep linear networks, we found remarkably a class of random initial conditions that would allow training time to be independent of depth.",
            "OK, now what do I mean by training time?",
            "If I make the network infinitely deep, of course that the real Clock time.",
            "To train, the network will grow with depth because the computational time to compute one gradient grows with depth.",
            "But you might think that there's a more adverse scaling with the number of gradient evaluations also grows as you train the network, and it turns out the latter is doesn't have to be true for a particular class of initializations.",
            "You can make the learning time independent of depth where time is measured in number of gradient evaluations."
        ],
        [
            "It's still a linear network, but then we show it for the nonlinear network and we have intuition showing empirically for the nonlinear network and we have intuition Y. Alright, so that we never would have discovered this had we not had a deeper understanding of linear networks, so I'll skip the details of that, but I'll just show."
        ],
        [
            "You the so basically the magic recipes to choose random orthogonal weights OK, and so if you have random orthogonal weights, the training time is independent of depth.",
            "The optimal learning rate.",
            "So let me not talk about that.",
            "OK, but you know another idea that actually Joshua sort of involved in was a nice idea was scaled random Gaussian initializations to combat the vanishing exploding gradient problem.",
            "But remarkably, if both networks have the same scaling but you choose random Gaussian weights instead of random orthogonal weights.",
            "There's a very, very different scaling with depth.",
            "The number of gradient evaluations grows linearly with depth around depth 510.",
            "It doesn't really make much of a difference, but at much deeper networks there's of course a huge difference.",
            "OK, so what's the intuition?",
            "The."
        ],
        [
            "Well.",
            "There's so much more I want to get to, but the intuition is.",
            "The idea behind using a scaled random Gaussian matrix is that the norm of a random vector is preserved after propagating through a random Gaussian matrix matrix.",
            "But if you take products of random Gaussian matrices and look at the product, it behaves in a very weird non Tropic way where it preserves norms by projecting error vectors into a low dimensional space and then amplifying them.",
            "And it's.",
            "So basically if you look at the singular value distribution of products of large numbers of random matrices.",
            "You get this very anisotropic singular value distribution.",
            "That doesn't happen for products of orthogonal matrices.",
            "Now in a non linear network the same."
        ],
        [
            "Thing actually empirically happens.",
            "So in a non linear network.",
            "What you care about is the end to end Jacobian that Jacobian will receive a contribution from the weights and then a diagonal contribution from the non linearity.",
            "Then the weights and the non linearity and so on.",
            "And that's sort of the end to end Jacobian that determines how input perturbations change lead to output perturbations.",
            "If the weights are orthogonal right, then this this property that the singular value distribution of products of many many large random jacobian's.",
            "Remains within a range.",
            "Let's order one.",
            "It doesn't explode or decay that actually holds true with scaled orthogonal initializations but not scaled Gaussian initializations.",
            "So the essential idea behind this rapid training result holds true even in nonlinear networks, and we actually see."
        ],
        [
            "Kind of training advantages and nonlinear networks.",
            "Of course, there's been a lot of work since in terms of trying to impose orthogonality while you're training as well, and you know there's lots of ways to combine that.",
            "But basically orthogonal is a lot better than Gaussian in general for a variety of tasks.",
            "OK, so that's sort of something practical that came out of a deeper scientific understanding.",
            "So."
        ],
        [
            "OK, did you talk about the saddlepoint stuff before you didn't OK?",
            "Alright, so so.",
            "So."
        ],
        [
            "OK, so in a really fun collaboration with me and Yasha, which started when you invited me to come and give a talk here, we talked about the Saddle Point story for the linear networks and other reasons actually coming from physics that we believe that saddle that local minima should not be a problem.",
            "So basically it's often thought.",
            "That local minima at high error stand as a major impediment to non convex optimization, right?",
            "And it's true that if you just draw a generic random lens error landscape over low dimensions, it will be riddled with local minima.",
            "For example, here's a cartoon description of approaching folding energy landscape, and there's lots of local minima.",
            "OK, but we know that our geometric intuition derived from living and moving within a low dimensional world doesn't generalize very well to high dimensional situations.",
            "And it turns out if you just draw generic random landscape over high dimensional spaces, local minimum at high error are exponentially rare in the dimensionality.",
            "Instead, saddle points proliferate and in collaboration the ushers lab.",
            "We developed an algorithm that can rapidly escape these saddle points so they were kind of birds on this, where we used kind of different techniques to come to similar conclusions.",
            "But the basic idea is the fall."
        ],
        [
            "Doing so, it's motivated by some work by Brian Dean and Physical Review Letters, 2007, where they looked at just a random error landscape.",
            "OK. Over high dimension, so you just do a single draw of a Gaussian process over N variables and that's your random error landscape OK. Let X be a critical point where the gradient vanish is let Y be its errorlevel.",
            "Clarified the functions of deterministic functions of deterministic functions from, yeah?",
            "Exactly so, so the picture would be.",
            "Here is so the picture would be once and for all.",
            "I draw a random function, but over N variables not not one variable, and then I fix that function and I look at the the statistics of local local extrema.",
            "OK, so for a fixed function I look at all the local extrema and that's what I'm looking at here.",
            "OK, I can take each local extrema more critical point where the gradient vanish is and I can plot it in a 2 dimensional feature space.",
            "One axis is the error level, right?",
            "So how high is the critical point on the error landscape and the other axis will be the fraction of negative eigenvalues of the Hessian or the number of negative curvature directions in the vicinity of that critical point.",
            "Right, and you might think a priority that critical points could appear just anywhere in this 2 dimensional feature space, but Brandy and showed no.",
            "It turns out that the critical points concentrate on a monotonically increasing curve.",
            "What are the ramifications of this observation?",
            "Well, OK, So what does curve mean?",
            "So here is the global minimum.",
            "It by definition occurs at the lowest energy and the fraction of negative eigenvalues is zero.",
            "It's a, it's a local minimum.",
            "All directions curve up.",
            "Here is the global maximum.",
            "It's the highest error or energy and in all directions curve down.",
            "And then intermediate what's happening is is a critical point gets higher and higher, it develops more and more negative curvature directions.",
            "So what this means is that there are no local minima at high error, right?",
            "That means that's this region at high error.",
            "There are no local minima.",
            "And if you're a local minimum, your error level is close to that of the global minimum.",
            "OK. Now physicists are used to this idea.",
            "That there's this notion of universality.",
            "There are certain questions whose answers don't depend on the details.",
            "OK, they oftentimes only depend on the dimensionality and symmetry of the problem.",
            "OK, so a physicist could just stop there and say this will be true for neural networks, don't you?",
            "Don't even need to do the simulation, it'll be true because neural networks are also error landscapes over high dimensional spaces and and all that matters is that you're in high dimensions and the essential intuition is if you have a critical point over a million variables, what are the chances that the function curves up in all 1,000,000 dimensions?",
            "The answer is extremely unlikely unless you're all the way near the bottom.",
            "In which case there's nowhere to go but up, right?",
            "OK, so we could stop there and we wouldn't have to write a paper, but of course computer scientists are very sceptical of physicists.",
            "And it's true you should be, I mean, but of course I mean to make an impact in computer science, we have to travel over to the other side and show that this is true even in the scenarios that you guys care about.",
            "And so you know, we worked with Yasha and so."
        ],
        [
            "Talented students in his lab where they actually tried to plug."
        ],
        [
            "This prediction this physics prediction.",
            "And."
        ],
        [
            "What they found, remarkably is that this is exactly what happens.",
            "So it turns out Newton's method is attracted to saddle points.",
            "That's not entirely obvious immediately, but if you think about a little bit, it is true.",
            "So Newton's method is attracted to critical points of any index, or any F fraction, negative curvature, eigenvalues, and So what happens is the critical points do indeed concentrated, monotonically increasing curve.",
            "So actually maybe you should trust physicists in any case.",
            "So natural question is, what can we do about this?"
        ],
        [
            "Why is Newtons method attracted to saddle point?",
            "So Newton's method is going downhill but multiplying by the inverse Hessian.",
            "So if they have seen as a negative eigenvalue, that gives you an extra negative sign which points you back uphill.",
            "Right, so very simple fix is to just take the absolute value of the Hessian, where we define that to be the Hessian, but with all eigenvalues replaced with their absolute value, the eigenvectors unchanged.",
            "And so that fixes this problem.",
            "And there's actually a way you can derive it, used by minimizing a linear approximation to F of X within a trust region in which the linear and quadratic approximations agree.",
            "This is an approximate derivation, so this is a very different way to use curvature information.",
            "The curvature is not used to approximate the landscape, the curvature is used to determine the boundary of a trust region."
        ],
        [
            "OK, and so this actually works relatively well so.",
            "So here's the.",
            "So this is called the saddle Free Newton method, and so it behaves pretty well actually.",
            "So this is stochastic gradient descent on a deep autoencoder problem and a recurrent neural network problem.",
            "And the error plateaus after some time.",
            "So when you see a plateau, you might think OK, I'm stuck at a local minimum, but actually this plateau is an illusion is an illusory local minimum.",
            "I mean, when you switch to stochastic gradient descent, you rapidly drop again.",
            "So I saddle free Newton, you rapidly drop again.",
            "OK, so it turns out that when you look at the landscape when you're rapidly dropping, you do see negative curvature directions and saddle free is actually utilizing the negative curvature directions, and in a plot that I don't have here, this is an algorithm that actually works better in higher dimensions, which is consistent with the idea that saddle points proliferate more in higher dimensions than in lower dimensions.",
            "Of course, this is kind of a second order method, so more work it remains to be done in combining this with approximations to the Hessian and so on to make it competition tractable and scale up in higher dimensions.",
            "Thank you also, you might be working on that now or maybe not.",
            "Not much somebody should work on that.",
            "I'm too lazy to do that.",
            "OK so."
        ],
        [
            "Just a classic version of this that doesn't require storing, but we but we have stochastic 2nd order method where we yeah.",
            "Yeah, so we use a low dimensional approximate subspace, yeah?",
            "It was like 40 times.",
            "Yeah.",
            "Yeah.",
            "Yeah, so yeah, so there's more approximations required to try to make it practical, but at least it overturned."
        ],
        [
            "Sort of, this conventional wisdom that local minima are the issue, right?",
            "So again, a deeper scientific understanding of the problem, the geometry of error landscapes could potentially lead to better learning algorithms, though though this hasn't been brought to total fruition yet.",
            "For this for this idea."
        ],
        [
            "OK, so expressivity right.",
            "So the other thing is the brain can do all sorts of things that simpler systems cannot do.",
            "We kind of saw this Chomsky hierarchy right where we had regular expressions, context free grammars and computable functions.",
            "And there was a corresponding finite state machine, pushdown automata and Turing machines, right?",
            "So the more complex a machine is, the more complicated tasks it can do.",
            "That's almost tautologically true, right?",
            "So now we're working not at the level of the Chomsky hierarchy anymore, but we're looking at architectures.",
            "OK, So what can a deep architecture do that a shallow 1 cannot?",
            "And so there's been a lot of beautiful work on this."
        ],
        [
            "Actually so OK.",
            "So the work I'm I'm going to talk about that we just did recently is work with my grad student Ben Poole Sherman Illyrian.",
            "It's a collaboration with my postdoc Joshua, who's now at Google and might throw an intern at Google."
        ],
        [
            "So here's the here's the basic idea.",
            "So again, the question is, why do we need depth?",
            "Well, universal function approximations suggests that we can get any function with a very very wide network, right?",
            "So, so why do we need depth?",
            "Well, these universal function approximations are kind of hokey because they provide no guarantees on the size of the hidden layer required to approximate a function.",
            "Well, that size could potentially be exponentially large in the input dimension.",
            "So the overall idea is that there might exist certain special functions that can that can be computed efficiently.",
            "Using a deep network that's polynomial in the number of input dimensions, but not by a shallow network that might require exponential number of neurons, and so this idea goes back to intellectual traditions and Boolean circuit theory where they ask similar questions for finite depth logic gates and so, for example, the parity function.",
            "The function that asks other number of bits in a binary string order.",
            "Even that function can be computed in a polynomial number of logic gates in the size of the bit string.",
            "If you allow multiple layers of logic gates.",
            "But if you allow only one layer of logic gates, you have to be exponential in the width."
        ],
        [
            "OK, so in some very nice work that Joshua did.",
            "Actually they showed a similar type of result where for Relu networks they showed that the number of linear regions can grow exponentially with depth and the way they did it as they came up with a specific network that recursively chop subspace using opposing reluz and each layer chops up each space.",
            "Each part of space once, and so the number of linear regions grows exponentially with depth."
        ],
        [
            "A similar result can be shown for some product networks where basically you can show that in these sum product networks where you take you compute products of monomial's and then sum them.",
            "Then you'll get a complicated polynomial in the top layer an if you use the distributive property to expand it.",
            "The number of monomials can grow exponentially with depth, and because it's a sum product network.",
            "If you want to get us number of monomial's with only one layer, you'll need then exponentially many this for the same number of monomial's in the deep network you will need exponentially many neurons in the in the shallow sum product networks.",
            "OK, so."
        ],
        [
            "So so so now.",
            "This raises very natural open questions, right?",
            "So first of all, are these sort of natural?",
            "Are these the kinds of functions we want to compute from the perspective of AI?",
            "In what sense are they natural?",
            "And one might argue they're not really natural, but they're very good examples of exponential expressivity.",
            "Another question is, are these functions in some sense rare?",
            "Curiosity's, or is this phenomenon much more generic?",
            "In some sense, can any function computed by a generic deep network not be efficiently computable by a shallow network?",
            "So we would like a theory of deep neural expressivity that demonstrates this for arbitrary nonlinearities and some natural general measure of functional complexity.",
            "So in in deep learning and neuroscience in neural network theory in general we often talk about curvature in a colloquial sense, right?",
            "So we thought why not actually use the natural mathematical language of curvature, which is Romanian geometry to try to attack."
        ],
        [
            "Question so another way to think about it is.",
            "The theoretical techniques that are available to prior works both dictated the nature of the non linearity that that could be analyzed and the measure of functional complexity that was focused on.",
            "So what we're going to do is we're going to combine a different set of tools for money and geometry and dynamical mean field theory that enable us to analyze arbitrary nonlinearities.",
            "And we focus on the curvature of a deep function as a measure of functional complexity.",
            "What we can show is that even in generic random deep networks, measures of functional curvature grow exponentially with depth, but not with.",
            "And Moreover, the origins of this exponential growth can be traced to chaos theory, it turns out."
        ],
        [
            "And another way to think about expressivity, kind of a dual approach is this notion of disentangle in which is actually captured.",
            "The imagination of both neuro scientists and machine learning people alike, and the idea is, well, we have.",
            "We have multiple stages of visual processing as Bruno very nicely outlined.",
            "And a question is, well, why do we need these multiple stages?",
            "In principle all the information about what we want to do is in the retina we have data processing inequality that say any further processing only destroys information.",
            "So why do you need anything beyond the retina?",
            "And we all know that the basic idea is that maybe what you want to do is you want to reformat the information to make it simpler so that a simple readout can solve the task later on.",
            "So basically, if you imagine, for example.",
            "The manifold of face under different positions, orientations, illumination scales.",
            "Each of those images will create a neural activity pattern in the retina in V1 and so on, and that neural activity pattern might be a very highly convoluted, say red manifold, and then another face under all sorts of positions, orientation, scalings and so on might be another highly convoluted blue manifold, and the goal of the ventral visual stream and maybe also deep neural network is to take these manifolds and flatten them out right to the point where a simple linear readout could discriminate between faces.",
            "OK, so this is a very appealing and intuitive idea.",
            "But the question is, how can we mathematically mathematically formalize this notion of dissent angling, and how do we use this mathematical formulation to quantitatively assess the distant angling power of deep versus shallow networks, and what we can show is that deep networks can disentangle manifolds whose curvature grows exponentially with depth, so it's actually quite remarkable how depth can lead to disentangle in power.",
            "So the.",
            "So I have to get very short so I wasn't so all the technical details are on the slides, but I wasn't planning on going through the technical details I wanted to.",
            "I'll talk about it.",
            "I'll talk about it.",
            "Yeah, exactly talk about it.",
            "So let me just give you a very high level view of so I'm going to skip a lot of slides, which I was planning on doing anyways.",
            "But let me just give you the high level take home messages and every all the details are in the paper and you will have the slides you know from the website."
        ],
        [
            "So here's the basic idea.",
            "The basic idea is we look at random neural networks and we want to show that a random deep network and do something that no shallow network whatsoever can do.",
            "Even if you train the shallow network, that's the idea.",
            "So we're going to look at random neural network, so the where the weights are all ID and the biases are all ID.",
            "And what's going to happen is if the weights and we're going to have some arbitrary non linearity FI.",
            "The running example that I'm going to use a sigmoidal non linearity, but like a teenage but everything I say generalizes to other nonlinearities.",
            "Railways are slightly different, but we can handle those two.",
            "And.",
            "Basically what happens is this.",
            "In order to chaos phase transition in these networks where if the variance of the weights gets very large then what happens is the neural networks explore the nonlinear regime right?",
            "And So what happens is you get linear expansion due to due to the large weights.",
            "And then you get nonlinear suppression due to the curvature in the non linearity.",
            "So then what happens is you and in different layers you get expansion in different dimensions and then then contraction along the coordinate axes.",
            "So you get expansion contraction, expansion, contraction and what you do is you get a very highly curved response response.",
            "OK so here's the basic idea.",
            "OK so basically you have this intuitive notion of chaosan."
        ],
        [
            "You can look at it so the basic questions we ask is if you have a pair of points they become more similar or different overtime and how fast we can answer the question, and then if we have a smooth manifold we can answer the question of how does it, how does its curvature in volume change?",
            "OK, so here's the basic idea.",
            "Let me just give you the numerical result first."
        ],
        [
            "So here's an example of.",
            "So what we're going to do is we're going to."
        ],
        [
            "A simple manifold in the input of circle.",
            "We could have chosen other manifolds, but for simplicity we choose a circle and we propagate it through the network and we ask how does it.",
            "How does this geometry change?",
            "OK, so."
        ],
        [
            "This is just a PCA plot and what happens is.",
            "So if the weights are small, the circle propagates through the layers and it's roughly in a linear regime, so nothing too much happens if the weights if the variance of the weights gets larger, the circle gets more ruffled, and if there is some way that gets even larger, the circle gets even more ruffled.",
            "OK, so now what seems to be happening here is that the radius of curvature of the circle is getting tighter and tighter, and a natural conjecture might be is that the radius of curvature is getting exponentially smaller with depth.",
            "OK, at least that's what this visual representation is suggesting.",
            "It turns out that that's a complete.",
            "That's the completely wrong picture.",
            "Right?",
            "That's not actually what's happening at this tightening radius of curvature.",
            "Is an artifact of trying to fit a fundamentally high dimensional object into a low dimensional space.",
            "OK, and so this should give a cautionary tale about visualization using, say, PCA.",
            "This is not only a problem of linear dimensionality reduction."
        ],
        [
            "Also a problem with nonlinear dimensionality reduction.",
            "So TC is very popular and so this is this is a network in the very chaotic regime.",
            "So a circle in layer.",
            "So it gets more and more convoluted, and again the radius of curvature is getting tighter OK. Alright, that's not actually what's happening, so we worked out the mathematical theory of what's actually happening without resorting to dimensionality reduction."
        ],
        [
            "What we basically did was we came up with nonlinear propagation equations for computing how curvature and length propagate through the network.",
            "So if you have a manifold right, it has some coordinate and some embedding space and you can."
        ],
        [
            "Find curvature so there's a well known notion of of Gaussian or extrinsic curvature, which is at any point on the manifold.",
            "The manifold has a tangent vector and acceleration vector.",
            "That in an N dimensional space, the tangent vector and acceleration vectors span a 2 dimensional subspace, and there's a unique circle called the osculating circle that has the same tangent and acceleration vectors.",
            "The curve at that point.",
            "That circle has a radius and the extrinsic Gaussian curvature is one over that radius.",
            "So intuitively tighter radii of curvature.",
            "Correspond to higher curvature, right?",
            "That's very intuitive.",
            "So this is our geometric measure of curvature.",
            "It has a particular formula in terms of velocity, acceleration, vector and what we did was we came up with nonlinear."
        ],
        [
            "Recursion relations that ask how does curvature Kappa propagate through the network?",
            "OK, Chi is like the stretching factor of the Jacobian in the chaotic regime, Chi is.",
            "Is.",
            "Less than one.",
            "So it's bigger than one, so it's stretching things.",
            "Actually, before we do that, let's imagine what happens to us."
        ],
        [
            "Circle as you just linearly expand it.",
            "OK, that's an important addition you need.",
            "First, if you linearly expand a circle.",
            "Its length or circumference of course gets bigger.",
            "But its radius also gets bigger, which means its curvature gets smaller.",
            "So under linear expansion you expand length, but you sacrifice curvature.",
            "OK.",
            "It turns out non linear networks.",
            "What they actually do is they expand length without sacrificing curvature.",
            "OK, the way you can see that."
        ],
        [
            "By analyzing these nonlinear recursion relations that we derived, and we find that any curvature in the input gets attenuated by an expansion, so Chi is the expansion factor.",
            "If Kise bigger than one, then the expansion will decrease curvature.",
            "But Chi two is the average curvature of your non linearity when you average over the distribution of inputs and that gets added in.",
            "So the non linearity adds in new curvature.",
            "So what you have is you have a leaky integrator of curvature.",
            "That's kind of ateco message of what these random deep networks doing.",
            "They attenuate for any curvature in the input manifold, but added new curvature due to the non linearity.",
            "So with this leaky integration, you get a stable fixed point.",
            "But you do expand the length.",
            "OK, so what's intuitively happening is the input manifold is getting stretched.",
            "It's getting stretched and curved, stretched and curved, stretched and curved, so it becomes like a tangled spaghetti.",
            "That's exploring a longer, tangled spaghetti that's exploring all of N dimensional.",
            "The hidden representation space.",
            "So you're actually getting a space filling curve.",
            "OK, so this is the kind of geometric picture of what's going on where you don't have to rely on visualization from nonlinear dimensionality reduction.",
            "You can just directly confront the complexity of the curve using Romanian geometry in high dimensional spaces.",
            "And So what happens is so."
        ],
        [
            "OK, so just to just to show you this is the match between theory and experiment for curvature for length.",
            "And this grassmannian length, the solid lines are theory.",
            "The error bars are numerical simulations from actual nonlinear networks, and you can see the whole point of this slide is just that there's a nice match, which suggests I'm not full of crab and that this picture is really true.",
            "So what happens is so the.",
            "So what happens is."
        ],
        [
            "This picture is an artifact of trying to take a very long space filling curve where each wiggle has the same radius of curvature as the depth grows and trying to fit it into a low dimensional space.",
            "An artifact of that is that the radius of curvature gets smaller in the TSG plot.",
            "OK, hope that intuitively makes sense, so I think I have about 4 minutes left, so let me know OK?"
        ],
        [
            "Just in tangling, right?",
            "This is subject near and dear to Yoshi's heart, actually.",
            "So how do we deal with this in tangling?",
            "How do we quantify curvature?",
            "So if we have, say, a linear classifier in the top layer, the decision boundary within the top layer is a linear hyperplane.",
            "We can back propagate it to become and it will become a curved.",
            "Surface.",
            "In the input space it will be an N -- 1 dimensional surface, so it's a manifold with codimension one.",
            "That manifold will have some nonlinear equation defining it.",
            "Right, and what we can do is we can look at the gradient vector, right?",
            "That's normal to it and look at any tangent vector, the gradient and the tangents planet span a 2 dimensional surface hyperplane in input space.",
            "The intersection of the two dimensional hyperplane with the N -- 1 dimensional decision boundary gives you a curve.",
            "That curve has a Gaussian curvature.",
            "We can maximize the Gaussian curvature over the choice of the tangent vector and then do successive machinations while remaining.",
            "Orthogonality, the previous ones.",
            "And we get a subset of principle curvatures, right?",
            "So a 1 dimensional curve had one curvature and N -- 1 dimensional manifold has N -- 1 curvatures and they arise as the eigenvalues of a particular normalized Hessian."
        ],
        [
            "And we can just show we don't have a theory for this.",
            "It's much more complicated, but we can show numerically.",
            "That is, you back propagate the decision boundary into the previous layers.",
            "Its curvature grows exponentially with depth.",
            "OK, so basically.",
            "Yeah, even exponentially curved manifolds can be flattened to hyperplanes even in random deep networks.",
            "OK, so let me skip this summary so again."
        ],
        [
            "I skipped a lot, but almost everything I've talked about so far is published, so you can find it.",
            "My website is not up to date, but you can find it somewhere in my website and some on the archive OK Now."
        ],
        [
            "Just wanted to connect back to neuroscience.",
            "There's this famous line in Hamlet.",
            "There are more things in heaven and Earth, Horatio, than are dreamt of in your philosophy.",
            "There are more things in the brain that are dreamt of in the techniques that we use right now.",
            "And I think some of the important ones are that the brain we're asking a lot of our networks in deep learning.",
            "We are asking them to start from random initial weights.",
            "And become structured.",
            "OK, that might be a lot to ask for, because the brain does not do that right.",
            "The brain has extremely rich structure before learning even occurs, and that structure is encoded by development.",
            "There's beautiful migration patterns of neurons that set up all sorts of structures in the brain.",
            "The cortex, which is the most phylogenetically recent part of our brain.",
            "You know Bruno alluded to this has a plethora of cell types.",
            "So plethora of cell types.",
            "It has six layers and it has kind of a Canonical circuit microarchitecture that now is well worked out where inputs come in.",
            "So this is, say, a lower area and this is a higher area, so Bruno was drawing this van Essen type diagram with the different brain regions each.",
            "Each diagram was a box but within each box you have this layered structure where you have multiple layers.",
            "Inputs come into one layer propagate through the system and come out through another layer and go to the higher.",
            "Layer higher brain area.",
            "So there's bottom up input from the lower area to the higher area, and there's top down differentiated input.",
            "It's a different type of input from the higher area to the lower area, and a lot is known about the detailed dynamics of this Circuit of the neurons, about the connectivity and so on.",
            "Not everything, of course, it's by no means complete, but we're learning a lot, so an interesting challenge I think for every deep learning lab here, every grad student postdoc here should go back to your deep learning lab and maybe do some Journal clubs on these papers on these papers, OK?",
            "Because we actually in neuroscience, we don't have a good theory for what the structure is good for.",
            "We have sort of these inchoate theories, but maybe if we have an army of grad students and postdocs trying to.",
            "Trying to actually build in cortical structure.",
            "Into the networks that there start training from, they might start getting intuitions about what this kind of structure is good for, right?",
            "So at the very least, I mean, it might be completely fruitless, because it might be hard to.",
            "To discover the functional reason for this architecture, simply by instantiating this architecture in Erelu network right may be too much to ask for, but at the very least, I think Journal clubs in all the machine learning labs doing deep learning in the world on these three papers could be useful.",
            "I don't know, that's a speculation."
        ],
        [
            "OK, the other thing is you know, the other thing is nested loop architectures.",
            "OK, this is a prominent motif.",
            "Across all of the brain where you have fast dumb loops and slower smart loops.",
            "So for example, this shows up a lot of the time in motor control, so in motor control, if you're trying to do some task and I perturb your arm, you will have a stretch reflex that occurs within 25 milliseconds in that stretch.",
            "Reflex is dumb, all it does is it counteracts the perturbation that I gave you.",
            "And that start to occur through a muscle to spinal cord loop.",
            "Then about 50 to 100 milliseconds later, there's a smart or low latency stretch response that shows up, and that's a little bit smarter.",
            "It not only takes into account the perturbation that I gave you, but it takes into account the task that you're trying to do.",
            "OK, so for example, if I'm trying to move this way and you perturb me this way, the short latency response will will push back a little bit and the longer supports will push back even more.",
            "But if I'm perturbing if I perturb you this way, the short length, responsible pushback, and the long runs long latency response will not be there because it didn't need to be there, so it's a smarter response that knows about all your other joint angles it knows about the task, and so on.",
            "Then after 100 milliseconds, you're kind of screwed, because the entire brain can.",
            "Your visual feedback can be about 100 to 200 milliseconds, and then cortical loops through the entire brain can feedback to muscle.",
            "So basically you have a fast dumb loop, a slower, slightly smarter loop, and, uh, even slower, very smart loop.",
            "And then finally you have visual awareness and consciousness that can then determine your actions.",
            "So I don't think deep learning has played around with the computational power of nested loop.",
            "I mean you guys have with, you know, hierarchical are Hmm's and so on.",
            "But I think there's more to be gained there."
        ],
        [
            "The other thing, the other thing where there's more things in heaven and earth is synapsin's.",
            "OK, this is the final slide.",
            "So if you ask a theorist or a deep learning specialist, what is a synapse from neuron item, you're on J.",
            "The answer you'll get it so it's easy.",
            "It's just WI J if you have continuous analogue variables, it's JJ.",
            "If you have a Boltzmann machine, but regardless, it's just a number, it's you know and if you map it to biology, neuro scientists in their neural models think of it as the size of a postsynaptic potential induced by presynaptic spike.",
            "If you ask in your biologist and molecular biologists water synapses, you'll get a completely different answer.",
            "It's almost unrecognizable to us.",
            "It turns out within synapses, as a plethora of 2nd Messenger Cascades AMPA, MDA, so on.",
            "And, for example, here's a network of kinases and phosphatases.",
            "These are molecules that can attach phosphoryl groups to each other or not, and they essentially form a big computing network and this computing network hides within the postsynaptic density of every single, say hippocampal CA three neuron, and it's a different network in different brain regions and different brain like higher order brain regions have slower synapses, lower brain regions have faster synapses, so there's a lot of diversity in synaptic strength, and this is probably the biggest Gulf.",
            "Between theory and experiment and the semantic complexity probably plays a role.",
            "We actually have a theory for the role that the synaptic complexity plays and."
        ],
        [
            "You know what we show is that when you have synaptic weights with a finite or distinguishable number of synaptic strengths, then you need to promote your notion of a synapse from a single number to an entire dynamical system in its own right in order to have reasonable memory capacity.",
            "So we've worked out a theory for the memory capacity of these complex enough."
        ],
        [
            "This is where this is sort of memory is a function of time.",
            "Since you stored the memory and there's a bound.",
            "And what happens is the memory capacity of the system grows as the square root of the number of synapses, but it grows linearly in the complexity of the internal dynamics of the synapse.",
            "So it's much better to have a small number of complex synapses in this scenario than a large number of simple synapses.",
            "You can read all about this in our NIPS 2014 paper.",
            "OK, so."
        ],
        [
            "So I think a theory of complex synapses could have dividends in neurobiology, in mathematics and in technology."
        ],
        [
            "We've actually applied this to you."
        ],
        [
            "Biology data and this was work done by postdoctoral here."
        ],
        [
            "So again, just to summarize, right, we've talked about these things.",
            "Trainability expressively generalizability.",
            "There are other questions that we're starting to attack and starting to think about really interpret ability, right.",
            "Once we have a trade network, how do we understand what it does?",
            "How is the training data embedded in the weights and biological plausibility is very important, right?",
            "Nothing.",
            "How do we do things where we operate within the constraints of neurobiology?",
            "And again, this is a bunch of references, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, it's great to be here.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I was going to talk about a mixture of computational neuroscience and deep learning theory because I think the two subjects are going to be much more aligned going forward in the future, and I think it'll be interesting to mix ideas between the two field.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So theoretical neuroscience?",
                    "label": 0
                },
                {
                    "sent": "Why do I think it's such an exciting field at the moment?",
                    "label": 0
                },
                {
                    "sent": "It's because we have access to a wider range wide array of recording technologies.",
                    "label": 0
                },
                {
                    "sent": "Now that really allow us to peer into the immense complexity of neural systems across multiple scales of spatial and temporal organization, and we'd like to try to make sense of all of this data that neuroscientists are measuring, and so we need tools to confront this kind of complexity and to extract from it conceptual models of how the brain works.",
                    "label": 0
                },
                {
                    "sent": "So it's useful to turn to tools from the physical and mathematical Sciences that have themselves been developed to confront complexity in other disciplines, to understand other disciplines.",
                    "label": 1
                },
                {
                    "sent": "But of course, neural systems aren't simply a tangled web of complexity that exists for its own sake.",
                    "label": 0
                },
                {
                    "sent": "They've of course evolved over millions of years to solve important computational problems, so it can be really useful also to turn to fields like machine learning and the engineering Sciences, both as a source of inspiration as to what kinds of problems neural systems might be solving.",
                    "label": 1
                },
                {
                    "sent": "And also using methods to just attack and analyze data of course.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What kinds of problems do theoretical neuroscientists work on?",
                    "label": 0
                },
                {
                    "sent": "I can give you a very biased sample if the problem is that.",
                    "label": 0
                },
                {
                    "sent": "For example, I'm working on the lab, you know.",
                    "label": 0
                },
                {
                    "sent": "Oftentimes when you want to work in the field of neuroscience, the final arbiter of whether or not work is useful is doesn't make useful predictions experimentally testable predictions, just like in some cases the final arbiter of whether or not work is good in machine learning is does it work?",
                    "label": 0
                },
                {
                    "sent": "Can you win a competition?",
                    "label": 0
                },
                {
                    "sent": "Can you do something that you've never done before?",
                    "label": 0
                },
                {
                    "sent": "So the yardstick for measuring progress is a little bit different in neuroscience, so.",
                    "label": 0
                },
                {
                    "sent": "What are the types of things that we're working on so we're working on trying to understand processing in the retinal circuit.",
                    "label": 0
                },
                {
                    "sent": "So actually the retina is already a deep neural network.",
                    "label": 1
                },
                {
                    "sent": "You have a layer of photoreceptors, a layer of bipolar cells.",
                    "label": 0
                },
                {
                    "sent": "Can you guys see the arrows?",
                    "label": 0
                },
                {
                    "sent": "Yeah, great, you have lateral connections to the horizontal and amacrine cells, and then you have the ganglion cells over here, and what neuroscientists can do is they can control the photoreceptors and record from the ganglion cells, but it's very difficult to record from the interior of the circuit.",
                    "label": 0
                },
                {
                    "sent": "And we'd like to have computational methods to essentially computationally fill in the interior of the circuit, and we've been able to do that using various methods, some of which include deep learning, and then we can look inside our deep learning models and find cells that actually mimic the response properties of cells that are actually recorded in the interior of the retina.",
                    "label": 0
                },
                {
                    "sent": "The few times for neuro, scientists can do that.",
                    "label": 0
                },
                {
                    "sent": "With the Clendenin lab, we're trying to unravel the way that the fly C and so now we can do or the clandestine lab at Stanford can do whole brain optical imaging in the family so they can record optically many, many neurons in the fly and we can just use systems identification methods to discover how the fly, for example, detects motion.",
                    "label": 1
                },
                {
                    "sent": "Flies are really good at detecting motion, which is why it's really hard for us to swap them because they immediately go away.",
                    "label": 0
                },
                {
                    "sent": "So we discovered recently.",
                    "label": 0
                },
                {
                    "sent": "Actually the algorithm for motion detection and actually remarkably.",
                    "label": 0
                },
                {
                    "sent": "A flies essentially detect oriented space time energy in its receptive field in the same way that vertebrate visual cortical neurons detect motion.",
                    "label": 0
                },
                {
                    "sent": "So it seems now the fly visual circuits in the vertebral circuits evolved independently, so this suggests a remarkable convergent evolution in the algorithm for motion detection.",
                    "label": 0
                },
                {
                    "sent": "We've also been looking at grid cells grid cells.",
                    "label": 0
                },
                {
                    "sent": "You know, Bruno mentioned navigation and smaller animals.",
                    "label": 0
                },
                {
                    "sent": "These grid cells.",
                    "label": 0
                },
                {
                    "sent": "These are cell.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you must have heard about them.",
                    "label": 0
                },
                {
                    "sent": "There's sort of the most recent Nobel Prize in neurophysiology.",
                    "label": 0
                },
                {
                    "sent": "These are cells that fire if and only if the mouse appears at the vertices of a hexagonal grid.",
                    "label": 0
                },
                {
                    "sent": "In a small environment.",
                    "label": 0
                },
                {
                    "sent": "So you could ask, well who ordered that?",
                    "label": 0
                },
                {
                    "sent": "Would a deep learning model ever discover a grid cells as a natural consequence of trying to solve it task?",
                    "label": 0
                },
                {
                    "sent": "That's actually a major open question.",
                    "label": 0
                },
                {
                    "sent": "We actually don't know.",
                    "label": 0
                },
                {
                    "sent": "The functional reason for why these grid cells exist, we just know that they do exist.",
                    "label": 0
                },
                {
                    "sent": "What we showed is that a natural question is what is the origins of stability of this grid?",
                    "label": 0
                },
                {
                    "sent": "Like pattern.",
                    "label": 0
                },
                {
                    "sent": "There's two possibilities.",
                    "label": 0
                },
                {
                    "sent": "The mouse is doing a very accurate path integration, so it's integrating its own velocity signals to figure out where it is, and then based on that the cell is firing or two.",
                    "label": 0
                },
                {
                    "sent": "The rat mouse is internal estimate position is continuously getting corrected by landmarks and what we actually showed is that it's the latter.",
                    "label": 0
                },
                {
                    "sent": "We showed that this spiking pattern becomes much more incoherent.",
                    "label": 0
                },
                {
                    "sent": "Each time the mouse encounters each time the mouse is spent further and further time away from a landmark or a boundary, and each time it hits the boundary, the spike pattern becomes more coherent.",
                    "label": 1
                },
                {
                    "sent": "Essentially an interesting enough when you hit a boundary, you receive no positional information parallel to the boundary, but you do receive positional information, perpendicular boundary, and remarkably, this makes a prediction that errors are only corrected perpendicular to the boundary but not parallel, and that's what we actually found, so this was published recently in Neuron with the Shenoy lab we've been looking at.",
                    "label": 0
                },
                {
                    "sent": "I think one of the most.",
                    "label": 0
                },
                {
                    "sent": "One of the biggest sort of conceptual elephants residing within almost all neurophysiology experiments which is the following.",
                    "label": 0
                },
                {
                    "sent": "We record from about 100 neurons in the brain.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe 1000 now with optical imaging in brain regions, say invertebrates in monkeys that can contain 10 to the six to 10 to the 9th neurons.",
                    "label": 0
                },
                {
                    "sent": "OK, we can sometimes decode behavior from these neurons.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 1
                },
                {
                    "sent": "We can sometimes recover the state space dynamics of the circuit that makes sense by doing, say, dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "So natural question is how could we have gotten so successful?",
                    "label": 0
                },
                {
                    "sent": "So we have a theory actually for or could it be worse?",
                    "label": 0
                },
                {
                    "sent": "Are we completely misleading ourselves by making scientific inferences in such an undersampled measurement regime?",
                    "label": 0
                },
                {
                    "sent": "So what we recently showed is that the act of recording a subset of neurons in the brain can actually be thought of as the act of recording the same number of random linear combinations of all neurons in the relevant brain circuit.",
                    "label": 0
                },
                {
                    "sent": "So the act of doing neurophysiology is like doing a random projection under certain conditions.",
                    "label": 0
                },
                {
                    "sent": "And then we know from random projection theory that if you have a curve nonlinear manifold, you don't need that many random projections to preserve its geometry.",
                    "label": 0
                },
                {
                    "sent": "And this actually makes some testable predictions that we then tested in the mkak brain as to how geometrically distorted the state space dynamics of the mkak brain gets as we reduce the number of neurons and it predicted exactly the scaling relations that would be predicted by random projection theory.",
                    "label": 0
                },
                {
                    "sent": "So in the ramen lab, you know things that we've done, are, you know, we all think that synaptic plasticity is underlies the basis of our ability to learn and remember right?",
                    "label": 0
                },
                {
                    "sent": "Our ability to learn and remember depends crucially in our ability to modify synapses in our brain.",
                    "label": 0
                },
                {
                    "sent": "So a natural consequence of that is if we could somehow enhance the ability of our synapses to be plastic, then we might be able to become smarter.",
                    "label": 0
                },
                {
                    "sent": "It could be a potential route to cognitive enhancement.",
                    "label": 0
                },
                {
                    "sent": "People have actually tried this in mice.",
                    "label": 0
                },
                {
                    "sent": "They either through genetic perturbations or pharmacological perturbations, they make synapses more plastic, and you get mixed responses.",
                    "label": 1
                },
                {
                    "sent": "Sometimes the mice get smarter, sometimes they don't get smarter.",
                    "label": 0
                },
                {
                    "sent": "So here in this in this work, in a collaboration with Jennifer Ammons lab in college classes lab at Stanford, they actually modified the synapses in the mouse's brain to make them more plastic.",
                    "label": 0
                },
                {
                    "sent": "And they found that the mouse could either be smarter or Dumber, depending on prior experience.",
                    "label": 0
                },
                {
                    "sent": "So there's a strong history dependent effect in synaptic plasticity that plays a role in whether or not enhancing plasticity enhances learning, and we've developed theoretical theory of why that can happen, which will talk about sort of at the end of the talk.",
                    "label": 0
                },
                {
                    "sent": "So these are the kinds of things that we do on a day to day basis.",
                    "label": 0
                },
                {
                    "sent": "Because we're under the constraint of having to interact very closely to experimentalists and work with the data that they have, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It was like change.",
                    "label": 0
                },
                {
                    "sent": "No, it wasn't like changing the learning rate.",
                    "label": 0
                },
                {
                    "sent": "So you have potentiation and depression.",
                    "label": 0
                },
                {
                    "sent": "And depression so potentiation strengthening Synapse depression is weakening a synapse.",
                    "label": 0
                },
                {
                    "sent": "It led to enhanced depression, but not necessarily enhanced potentiation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so patterns of activity that would have led to potentiation than the wild type mouse.",
                    "label": 0
                },
                {
                    "sent": "Or would not have led to potentiation or depression in the wild type mouse led to depression in the knockout genetic knockout mouse?",
                    "label": 0
                },
                {
                    "sent": "So that's the actual perturbation, so there's all sorts of ways to perturb plasticity in the brain and look at its effects.",
                    "label": 0
                },
                {
                    "sent": "There's actually a long literature on that.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, the other thing that's extremely important to keep in mind when you think about applications of deep learning to neurobiology is that oftentimes biological data is operating in a very high dimensional regime.",
                    "label": 0
                },
                {
                    "sent": "In the following technical sense.",
                    "label": 0
                },
                {
                    "sent": "So there's of course been a dramatic change in the way that we do experiments across many, many fields, including biology in general.",
                    "label": 0
                },
                {
                    "sent": "The classical scenario would be it was incredibly difficult to take measurements, so we would take we would decide carefully ahead of time which variables were relevant to a problem so that the number of variables we simultaneously measure is the dimensionality of the data, and then we do as many, many repeated experiments as possible for those variables and we get low dimensional data or many points living in a low dimensional space, and it was really easy to understand.",
                    "label": 1
                },
                {
                    "sent": "It's easy to statistics in that scenario, but of course high throughput experiments now allow us to simultaneously measure hundreds to thousands of neurons.",
                    "label": 0
                },
                {
                    "sent": "But not under that many experimental conditions because you have limited time with which you can measure from a biological sample.",
                    "label": 0
                },
                {
                    "sent": "Without that biological sample safe, it's an animal that gets tired.",
                    "label": 1
                },
                {
                    "sent": "If it's a cell, it dies, so you can't measure that many trials, so you get data living in a very high dimensional space and you don't have that many data points, so we can't play the tricks of throwing lots and lots of data to deep neural network that the regime of limited data is essential in biology to conquer, and this is a big challenge for machine learning applications to biology.",
                    "label": 0
                },
                {
                    "sent": "We've been actually thinking about how much data do you need to learn particular problems by using a nice analogy between machine learning and statistical physics where maximizing the log likelihood is like minimizing an energy function.",
                    "label": 1
                },
                {
                    "sent": "The parameters are like thermal the parameters in the model you're trying to learn are like thermal degrees of freedom, and the data is the data.",
                    "label": 1
                },
                {
                    "sent": "It's some quenched interactions that you're stuck with and you ask how low can the energy get, or how high can the log likelihood get.",
                    "label": 0
                },
                {
                    "sent": "And we can actually compute that analytically in various cases.",
                    "label": 0
                },
                {
                    "sent": "For example in compressed sensing.",
                    "label": 0
                },
                {
                    "sent": "And so I'd like to just advertise this work before I move on to deep learning.",
                    "label": 0
                },
                {
                    "sent": "There's a principle that that kind of permeates machine learning, which is maximum likelihood, right?",
                    "label": 0
                },
                {
                    "sent": "It's a very good principle in this setting.",
                    "label": 0
                },
                {
                    "sent": "In fact, there are theorems that are saying in low dimensional statistics, maximum likelihood is the optimal thing to do, because you have theorems like the Cramer Lat Row bound saying you can't do better than X and you can show that the maximum likelihood that estimator saturates X.",
                    "label": 0
                },
                {
                    "sent": "But in the high dimensional setting, these theorems don't hold, so it could be the case that there could be something better than you can do that you could do.",
                    "label": 0
                },
                {
                    "sent": "Then maximum likelihood, and actually recently we figured out what's the optimal convex inference function that you could possibly do.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that what it is is it's smoothing the log likelihood function with respect to the parameters where the amount of smoothing increases as the amount of data decreases, and it's a particular non Luther NEO smoothing operation so that when the amount of data is very little, the smooth log likelihood function becomes just a quadratic quadratic bowl.",
                    "label": 0
                },
                {
                    "sent": "So quadratic inference is actually optimal in very high dimensions, is not related to the well known and used regularize maximum so.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's no guarantee that a particular regularised maximum likelihood will be the optimal convex optimization problem you want to solve.",
                    "label": 0
                },
                {
                    "sent": "This gives you what the optimal convex algorithm optimization problem you want to solve when the log likelihood function is is log concave or yeah.",
                    "label": 0
                },
                {
                    "sent": "There's a generalization of this to map inference, so so you know, there's this common idea that if you know the correct distribution then you should do a map inference, right?",
                    "label": 0
                },
                {
                    "sent": "But actually even that's wrong in high dimensions, it turns out map is not the optimal thing to do.",
                    "label": 0
                },
                {
                    "sent": "If you want to solve an optimization problem, there's better optimization problems to solve than map.",
                    "label": 0
                },
                {
                    "sent": "And again you want to smooth the prior.",
                    "label": 0
                },
                {
                    "sent": "So here's an interesting situation where even if you know the correct prior, the thing you want to optimize is not the log prior.",
                    "label": 0
                },
                {
                    "sent": "But the smooth log prior.",
                    "label": 0
                },
                {
                    "sent": "And now, of course, the best thing you can ever do is compute the posterior mean, because that's the minimum mean squared error estimator parameters, but often can't.",
                    "label": 0
                },
                {
                    "sent": "You can't.",
                    "label": 0
                },
                {
                    "sent": "You can't do the high dimensional integrals to compute the posterior mean, so this is restricted to situations where you want to solve a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So I just wanted to advertise that here because it's an interesting counterexample to the notion that maximum likelihood and map are always the best thing to do when you know when you have the correct distributional assumptions in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "Of course, the theorems that guarantee that don't hold, and there's something better you can do, and we've recently found it.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in case if you're interested in the interplay between statistical physics and you're a science in machine learning, we wrote about a 70 page kind of review article outlining a whole bunch of topics from spin glasses, neural networks, learning theory, random matrix, 3 random projections, compressed sensing, and so on.",
                    "label": 0
                },
                {
                    "sent": "It kind of forms the basis for a lot of theoretical basis for a lot of the things that we think about.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but if we want to go further, if we want to go sort of beyond very specific biological systems to sort of more general theories.",
                    "label": 0
                },
                {
                    "sent": "How do we make progress?",
                    "label": 0
                },
                {
                    "sent": "So I think now is a really interesting time where there can be a new type of alliance between theoretical neuroscience and theoretical slash, applied machine learning and the motivation for the alliance.",
                    "label": 1
                },
                {
                    "sent": "We kind of.",
                    "label": 0
                },
                {
                    "sent": "We kind of outlined the logic that I'm going to give it to you in this current opinion piece, but the motivation is the following.",
                    "label": 0
                },
                {
                    "sent": "We we, at least in neuroscience, are in it because we want to understand how the brain works.",
                    "label": 0
                },
                {
                    "sent": "OK, but the natural question is what does it mean to understand how a brain or in neural circuit works?",
                    "label": 1
                },
                {
                    "sent": "We don't actually have a good answer to that question, despite the fact that we're working in this field.",
                    "label": 0
                },
                {
                    "sent": "Approximal version of that is well, what if we can understand how the connectivity and dynamics of a neural circuit gives rise to some emergent behavior?",
                    "label": 1
                },
                {
                    "sent": "Or and learning, of course, is extremely important.",
                    "label": 0
                },
                {
                    "sent": "So another facet of it is how did neural activity and synaptic learning rules conspire to self organize useful connectivity that subserves behavior?",
                    "label": 1
                },
                {
                    "sent": "OK, physicists, when they've traditionally looked at this, have often tried to understand the nature of dynamics and random networks.",
                    "label": 1
                },
                {
                    "sent": "But of course these random networks have no function, so we'd like to try to understand networks that actually do something OK, so the field of machine learning, as you know, has generated a plethora of learn neural networks that all do very interesting things.",
                    "label": 0
                },
                {
                    "sent": "Oftentimes interesting things that we know of no other way to do in any other artificial system.",
                    "label": 0
                },
                {
                    "sent": "OK. Now neuroscience through various brain initiatives that you may have heard about is promising an even bigger explosion of data where we can record many, many neurons sometimes get the connectivity between all the neurons that you've recorded from a natural question that US theorists are sort of scratching our heads is what are we going to do when we get all that data?",
                    "label": 0
                },
                {
                    "sent": "How will we understand it, OK?",
                    "label": 1
                },
                {
                    "sent": "In the in the networks that you guys are generating, we actually know everything about these networks.",
                    "label": 0
                },
                {
                    "sent": "We know their entire connectivity, we know their dynamics, we know they're learning rule, we know their entire developmental experience from when they were little babies with random weights to big bad networks with trained weights, right?",
                    "label": 0
                },
                {
                    "sent": "Because we know there we know their training data, they were exposed to, yet we still don't have a meaningful understanding of how they learn and how they work.",
                    "label": 0
                },
                {
                    "sent": "And so I think this is a really intriguing warm up problem.",
                    "label": 0
                },
                {
                    "sent": "For us to think about before we attack the brain.",
                    "label": 0
                },
                {
                    "sent": "Or simultaneously now, I don't think for a second that if we understand how these artificial networks work, will understand how the brain works.",
                    "label": 0
                },
                {
                    "sent": "I think the principles are very different.",
                    "label": 0
                },
                {
                    "sent": "The details are very different, but I think the methods that we might use to arrive at that understanding might generalize to help us design experiments in neuroscience to arrive at a different but related understanding.",
                    "label": 0
                },
                {
                    "sent": "In real neurobiological systems.",
                    "label": 0
                },
                {
                    "sent": "So how might we do that?",
                    "label": 0
                },
                {
                    "sent": "So let me give you some eggs.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Samples OK of this, so this is kind of going to be the shape of things to come in.",
                    "label": 1
                },
                {
                    "sent": "The interaction between machine learning and neuroscience.",
                    "label": 0
                },
                {
                    "sent": "So here's an example where you take a complicated the basic basic framework is you take a complicated behavioral task.",
                    "label": 0
                },
                {
                    "sent": "You record many many neurons in a brain, and you get complicated neural dynamics at the end of the day, and you really don't understand the complicated neural dynamics because all you have is time series of neurons.",
                    "label": 0
                },
                {
                    "sent": "So what you could do is you could also train a neural network to solve the same task, so the behavior alone.",
                    "label": 0
                },
                {
                    "sent": "Has has embedded itself into the weights of the network and then and then you can compare the dynamics of the network to the dynamics of the brain and if they match.",
                    "label": 0
                },
                {
                    "sent": "Then you have a handle on trying trying to understand what kind of neural computation might be going on in the brain.",
                    "label": 0
                },
                {
                    "sent": "So this is an example of a success story in that respect where a monkey was asked to do a context dependent discrimination task where some dots are moving right, some dots are moving left, some dots are red, some dots are green, and the monkey supposed to report on certain context what the majority color is, and in other contexts what the majority direction is.",
                    "label": 1
                },
                {
                    "sent": "And remarkably, the monkey can do this.",
                    "label": 0
                },
                {
                    "sent": "And there was some very interesting context dependent dynamics that occur in the circuit and that could be re capitulated by a model train to solve the task and actually revealed a principle in new principle for doing context dependent integration.",
                    "label": 0
                },
                {
                    "sent": "There was an emergent property of the circuit rather than just a gating mechanism that you'd find, for example, finding LCM right.",
                    "label": 0
                },
                {
                    "sent": "This is just this is just a vanilla RNN.",
                    "label": 0
                },
                {
                    "sent": "It wasn't analysis team.",
                    "label": 0
                },
                {
                    "sent": "Ellis teams are a step backwards from my perspective.",
                    "label": 0
                },
                {
                    "sent": "From the perspective of modeling neuroscience, but that's.",
                    "label": 0
                },
                {
                    "sent": "It's any work.",
                    "label": 0
                },
                {
                    "sent": "OK, I can.",
                    "label": 0
                },
                {
                    "sent": "I can give you I.",
                    "label": 0
                },
                {
                    "sent": "Well, no, but I mean individual neurons don't have forget gates and right gates and read gates right?",
                    "label": 0
                },
                {
                    "sent": "So if we want to compare the dynamics of an STM and understand how function emerges from individual neurons that are not that smart LS teams can't answer that question right?",
                    "label": 0
                },
                {
                    "sent": "Center with Bruno's talk about all the Mountaineer dynamics going on with Android.",
                    "label": 0
                },
                {
                    "sent": "I mean, even if that's their right, it's relatively well modeled by threshold nonlinearities and temporal filters.",
                    "label": 0
                },
                {
                    "sent": "In a two layer neural network, but not with forget gates that can be trained overtime and Bruno's vigorously nodding his head.",
                    "label": 0
                },
                {
                    "sent": "So I'll stop there.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's the interpretability issue is with LS teams in regards to the application.",
                    "label": 0
                },
                {
                    "sent": "In neuroscience is an issue.",
                    "label": 0
                },
                {
                    "sent": "Of course they work great in lots of tasks, so I mean they should be.",
                    "label": 0
                },
                {
                    "sent": "They should be studied, but any methods to improve training in vanilla RNN would be incredibly useful for for applications in neuroscience.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another example is Dan Yamens and Jim to Carlos work, where they trained networks to solve an image recognition task.",
                    "label": 0
                },
                {
                    "sent": "The same image recognition actually a different image recognition task, and then they compared neural activity in different layers to neural activity recorded from it in V4.",
                    "label": 0
                },
                {
                    "sent": "And it turns out activity in the deep layers kind of mimicked activity in it in activity in the middle layers mimicked activity in V4.",
                    "label": 0
                },
                {
                    "sent": "So that's actually it's a fascinating advance, right?",
                    "label": 0
                },
                {
                    "sent": "But it begs the question, well, we don't actually understand what this model is doing, right?",
                    "label": 0
                },
                {
                    "sent": "Can we extract principles for what's going on here?",
                    "label": 0
                },
                {
                    "sent": "So, So what might?",
                    "label": 0
                },
                {
                    "sent": "What might would be able to do?",
                    "label": 0
                },
                {
                    "sent": "I can think of several approaches, but one would be.",
                    "label": 0
                },
                {
                    "sent": "Let's say you train millions of networks to solve the same tasks.",
                    "label": 0
                },
                {
                    "sent": "They're all going to be different due to vagaries in the initialization and training algorithm or whatnot, but there must be some computation.",
                    "label": 0
                },
                {
                    "sent": "There must be something common across all of the networks designed to solve a particular task, and there will be other things.",
                    "label": 0
                },
                {
                    "sent": "Other observables that are variable across the set of networks designed to solve a task.",
                    "label": 0
                },
                {
                    "sent": "What are the computational invariants across a set of networks designed to solve the task?",
                    "label": 0
                },
                {
                    "sent": "Maybe those are the observables that we should focus on in measuring in the real brain, and the latter of observables that are variable across a set of networks and solve a task might be observables that are not that important to measure in a real brain, because those observables could be historical accidents of learning evolution or adaptation right in your science, right?",
                    "label": 0
                },
                {
                    "sent": "We're being faced with a huge magnitude of details and we don't know which details are important.",
                    "label": 0
                },
                {
                    "sent": "Or form the essence of the computation.",
                    "label": 0
                },
                {
                    "sent": "The brain region is trying to do even in those cases where we're lucky to know what the computational brain is trying to do and which details are just not important, right?",
                    "label": 0
                },
                {
                    "sent": "So we need a theory of what's important and what's not important.",
                    "label": 0
                },
                {
                    "sent": "Another, another approach might be we need a hierarchy of simpler models.",
                    "label": 0
                },
                {
                    "sent": "You know model reduction might be a way to understand what's going on, so we need theories like that.",
                    "label": 0
                },
                {
                    "sent": "We don't have those theories yet.",
                    "label": 0
                },
                {
                    "sent": "I'm not.",
                    "label": 0
                },
                {
                    "sent": "I'm not aware of any general theories that we have yet, but we've been thinking.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About some other theories related to this, so you could, for example, my postdoc Joshua sold extreme kind of likes to.",
                    "label": 0
                },
                {
                    "sent": "Categorized some of the deepest puzzles of deep learning into kind of three categories, right?",
                    "label": 1
                },
                {
                    "sent": "One is trainability, right?",
                    "label": 1
                },
                {
                    "sent": "So if you're solving some task, if a good network solution exists with small training error.",
                    "label": 1
                },
                {
                    "sent": "How do you find it?",
                    "label": 0
                },
                {
                    "sent": "And Moreover, why does it take so long to find it?",
                    "label": 1
                },
                {
                    "sent": "IE.",
                    "label": 1
                },
                {
                    "sent": "What makes a learning problem difficult and we've been thinking about?",
                    "label": 0
                },
                {
                    "sent": "We've been thinking about that and I'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "The other is expressivity, right?",
                    "label": 1
                },
                {
                    "sent": "So what is it that a deep network can express that shallow networks cannot and various people have been working on that as well?",
                    "label": 0
                },
                {
                    "sent": "And we've had some recent results where we actually connect the notion of deep neural networks to the theory of chaos.",
                    "label": 0
                },
                {
                    "sent": "Now I don't know if that's good news or bad news.",
                    "label": 0
                },
                {
                    "sent": "I mean Chaos theory is hard, and what we're showing is that deep networks are related to that, but I think it's I think we can work around it.",
                    "label": 0
                },
                {
                    "sent": "And then the other interesting thing is generalizability.",
                    "label": 0
                },
                {
                    "sent": "This is most probably the most profound problem.",
                    "label": 0
                },
                {
                    "sent": "What principles to deep networks use to place probability or make decisions and regions of input space where you have very very little data?",
                    "label": 1
                },
                {
                    "sent": "And of course there for classifiers there's arguments like the VC dimension and VC dimension based generalization bounds and things like that, but we'd like a more geometric theory that tells us.",
                    "label": 0
                },
                {
                    "sent": "You know, given limited data, how does it propagate labels?",
                    "label": 0
                },
                {
                    "sent": "What are the principles that it uses?",
                    "label": 0
                },
                {
                    "sent": "We don't really have a theory for that.",
                    "label": 0
                },
                {
                    "sent": "We've done a little bit of work in how to learn generative models far away from the training data.",
                    "label": 0
                },
                {
                    "sent": "By destroying the training data quite a lot and trying to trying to recover that destruction.",
                    "label": 0
                },
                {
                    "sent": "This is motivated by ideas, anonymous dynamics and trying to reverse the flow of time in a diffusion process.",
                    "label": 0
                },
                {
                    "sent": "So for the deep learning theory, part of the talk, I'll focus on this and then I'll move to neuroscience, but you'll see what I mean by what might be considered.",
                    "label": 0
                },
                {
                    "sent": "Progress in terms of trying to get a theory that could help both machine learning and neuroscience.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is actually where it all started.",
                    "label": 0
                },
                {
                    "sent": "I kind of showed up.",
                    "label": 0
                },
                {
                    "sent": "At Stanford, I started talking to Jay McClelland.",
                    "label": 1
                },
                {
                    "sent": "This part of the talk it equally called the Misadventures and applied physicist wandering around the psychology Department.",
                    "label": 1
                },
                {
                    "sent": "So J kind of whispered into my ear all these interesting phenomena that infants do.",
                    "label": 0
                },
                {
                    "sent": "And more generally, the idea of semantic cognition, and this is also work with Andrew Sachs, who used to be a grad student with us.",
                    "label": 0
                },
                {
                    "sent": "Now as a postdoc at Harvard.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is semantic cognition?",
                    "label": 1
                },
                {
                    "sent": "OK, so semantic cognition relates to our ability to learn, recognize, comprehend and produce inferences about objects and properties in the external world.",
                    "label": 1
                },
                {
                    "sent": "That are not present in our current perceptual stimulus, right?",
                    "label": 0
                },
                {
                    "sent": "So, for example, does a cat have fur or do birds fly right?",
                    "label": 0
                },
                {
                    "sent": "You can all answer these questions, despite the fact that there is no cat or bird in the room.",
                    "label": 0
                },
                {
                    "sent": "And so our ability to do this likely relies on our ability to form internal representations of categories in the world, right?",
                    "label": 1
                },
                {
                    "sent": "We never see the same stimulus twice, so once we see a novel stimulus, we categorize it into a stimulus category.",
                    "label": 0
                },
                {
                    "sent": "And then we use that categorical representation to both answer questions and take actions, right?",
                    "label": 0
                },
                {
                    "sent": "So these categorical internal representations are the basis for our ability to act in a world that never repeats itself, ever, OK?",
                    "label": 0
                },
                {
                    "sent": "So there's been a lot of.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work in psychology about probing semantic cognition in infants and, in particular, probing its development.",
                    "label": 0
                },
                {
                    "sent": "So for example, looking time studies, can an infant distinguish between two categories of objects and at what age?",
                    "label": 1
                },
                {
                    "sent": "So you can actually show.",
                    "label": 0
                },
                {
                    "sent": "Let's say you want to detect whether an infant can detect differences between cows and horses, right?",
                    "label": 0
                },
                {
                    "sent": "So you show up, you show a sequence of pictures of cows.",
                    "label": 0
                },
                {
                    "sent": "The first time, the Infancies the cow, it looks a lot, and then the looking time goes down.",
                    "label": 0
                },
                {
                    "sent": "Then you show the first horse, and if the infant is old enough, the looking time will go up a lot.",
                    "label": 0
                },
                {
                    "sent": "But if the infant is not old enough for looking, time will stay the same.",
                    "label": 0
                },
                {
                    "sent": "So the fact that the looking time goes up suggests that the infant can discriminate between horses and cows and realize that this is a member of a novel category, not their original category, and so for every categorical distinction, you can figure out at what age it's learned, and then if you create a a tree of categorical distinctions, an infant can learn where the hide up the tree corresponds to the earliest age at.",
                    "label": 0
                },
                {
                    "sent": "You know, the higher up, higher up the distinction arises in the tree corresponds to how early the infant can do it.",
                    "label": 0
                },
                {
                    "sent": "You see a remarkable semantic tree that looks a lot like the way we would categorize the world as adults.",
                    "label": 0
                },
                {
                    "sent": "I'll show you examples of that.",
                    "label": 1
                },
                {
                    "sent": "You know there's also property verification task and Canary move.",
                    "label": 1
                },
                {
                    "sent": "Can it's saying there's different response latency's and so the response latency tells you that there are certain central and peripheral properties.",
                    "label": 1
                },
                {
                    "sent": "Two categories category membership queries is a Sparrow.",
                    "label": 0
                },
                {
                    "sent": "Bird is an ostrich, a bird.",
                    "label": 0
                },
                {
                    "sent": "This one gets answered much more quickly than this one, which suggests that are typical and atypical category members.",
                    "label": 0
                },
                {
                    "sent": "And of course, the most interesting thing is generalization.",
                    "label": 0
                },
                {
                    "sent": "You can measure patterns of inductive generalization in infants, and these patterns of inductive generalization change overtime.",
                    "label": 0
                },
                {
                    "sent": "Infants tend to overgeneralize 1st and then learn the correct pattern of generalization.",
                    "label": 0
                },
                {
                    "sent": "So I'm really going to focus on the development of knowledge and infants, though.",
                    "label": 0
                },
                {
                    "sent": "We've attacked all of these questions.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example of an infant.",
                    "label": 0
                },
                {
                    "sent": "This is actually my son.",
                    "label": 0
                },
                {
                    "sent": "Let's face it, he doesn't have a lot going for him.",
                    "label": 0
                },
                {
                    "sent": "Alright, he's short.",
                    "label": 0
                },
                {
                    "sent": "He's bald, he's still living with his parents.",
                    "label": 0
                },
                {
                    "sent": "It's not potty trained, right?",
                    "label": 0
                },
                {
                    "sent": "But he does have going for him, and all infants have going for them.",
                    "label": 0
                },
                {
                    "sent": "Is that they're incredible learning machines, right?",
                    "label": 0
                },
                {
                    "sent": "They can soak up all this knowledge and ultimately like to learn that.",
                    "label": 0
                },
                {
                    "sent": "Learn what's going on there.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to so J McClellan wrote this beautiful book.",
                    "label": 0
                },
                {
                    "sent": "If you haven't seen it before.",
                    "label": 0
                },
                {
                    "sent": "It's called semantic cognition.",
                    "label": 0
                },
                {
                    "sent": "It's a fantastic book to 1st learn all about this stuff.",
                    "label": 0
                },
                {
                    "sent": "Jay was doing kind of deep networks before they became popular.",
                    "label": 0
                },
                {
                    "sent": "Or rather the first time they became popular and so so one of the things is the progressive definition of concept.",
                    "label": 0
                },
                {
                    "sent": "So this is just I don't intend for you to read.",
                    "label": 0
                },
                {
                    "sent": "This is just to show off how much work J income.",
                    "label": 0
                },
                {
                    "sent": "Co did, but I wanted to focus on this progressive differentiation of concepts, which is this idea that infants learn coarse grained discriminations 1st and then learn finer scale scale discrimination.",
                    "label": 0
                },
                {
                    "sent": "So for example plants versus animals and then different types of animals get learned later in different types of plants get learned later and this holds even if you control for perceptual similarity.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how did Jay model this?",
                    "label": 0
                },
                {
                    "sent": "Well, J model this using a deep neural network, so he he had a toy data set where we had it.",
                    "label": 0
                },
                {
                    "sent": "He had a bunch of.",
                    "label": 0
                },
                {
                    "sent": "He had a bunch of objects OK and he had just A1 hot representation so but nothing as long as you have any orthogonal representation here, you're fine and he had a bunch of questions that you can ask the network and you had a bunch of properties.",
                    "label": 0
                },
                {
                    "sent": "So for example, a Canary can grow, it can move, and so on, right?",
                    "label": 0
                },
                {
                    "sent": "And you just trained the network to spit out this input output map and he looked at the internal representations of this network.",
                    "label": 0
                },
                {
                    "sent": "The Inter representations of the objects in this network as a function of developmental time.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And he looked at two ways of looking at it.",
                    "label": 0
                },
                {
                    "sent": "One is multi dimensional scaling.",
                    "label": 0
                },
                {
                    "sent": "So he plotted the internal representations in a geometry preserving way as a function of developmental time.",
                    "label": 1
                },
                {
                    "sent": "And you see, just like in an infant, the animals separate from the plants 1st and then the fish separate later and the birds separate later and so on.",
                    "label": 0
                },
                {
                    "sent": "The trees and Flowers separate later and then finally individual items separate.",
                    "label": 0
                },
                {
                    "sent": "And also this is a hierarchical clustering, you viewer slowly the network learns the structure of the data set.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's happening is the semantic similarity of the items is getting embedded in the neural representations of the network.",
                    "label": 0
                },
                {
                    "sent": "OK so intra.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only this has been observed in the brain, not over development, but at the end point of development.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you guys have seen this before, but this is So what people did was they showed many, many images.",
                    "label": 0
                },
                {
                    "sent": "The same set of images to both humans and monkeys.",
                    "label": 0
                },
                {
                    "sent": "They measured neural responses in monkey inferotemporal cortex.",
                    "label": 0
                },
                {
                    "sent": "This is high brain level area that contains the face cells and so on.",
                    "label": 0
                },
                {
                    "sent": "They measured many many neurons an measure.",
                    "label": 0
                },
                {
                    "sent": "The similarity or dot product between neural activity patterns in the monkey.",
                    "label": 0
                },
                {
                    "sent": "For pairs of objects and this is the similarity matrix that did so.",
                    "label": 0
                },
                {
                    "sent": "Sorry, this is for the monkey and then for the human they did the same thing, except they did multi voxel fMRI activity patterns, and they did the same thing, and despite the very different nature of both the species and the measurement apparatus, they got very similar.",
                    "label": 0
                },
                {
                    "sent": "Similarity matrices and this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same picture using hierarchical clustering.",
                    "label": 0
                },
                {
                    "sent": "So actually I want to talk about this today, but we recently proving a theorem that if you train these neural networks from random initial conditions, the dynamics at the level of similarity matrices is contractive so that the similarity matrix is an approximate invariant of learning, but?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cardless this is empirical demonstration that monkeys and humans, at least at the level of similarity matrices, see the world in the same way, which is kind of remarkable.",
                    "label": 0
                },
                {
                    "sent": "So what were the question we're addressing is over developmental time.",
                    "label": 0
                },
                {
                    "sent": "How does the structure get embedded in the network?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me skip this slide OK?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when I first saw when I first saw this result, I was both.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Founded and highly disturbed, astounded because I was like this is really cool.",
                    "label": 0
                },
                {
                    "sent": "The network is behaving qualitatively like an infant.",
                    "label": 0
                },
                {
                    "sent": "But this is really striking.",
                    "label": 0
                },
                {
                    "sent": "I mean I don't understand why this is happening, that's why it was disturbed.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to understand how this works.",
                    "label": 0
                },
                {
                    "sent": "So we asked a series of math.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Questions what are the mathematical principles underlying the hierarchical self organization of internal representations in this network?",
                    "label": 1
                },
                {
                    "sent": "For example, what are the relative low rolls of the non linearity in the input output transfer function of this network or the learning rule of the input statistics?",
                    "label": 0
                },
                {
                    "sent": "Is is the network exploiting nonlinearities to learn very high order social structure in the data and that's why you get this highly nonlinear learning dynamics?",
                    "label": 0
                },
                {
                    "sent": "Or could it be something simpler than that?",
                    "label": 0
                },
                {
                    "sent": "And also there's this notion in neuroscience of a coherent category of psychology of a current category.",
                    "label": 0
                },
                {
                    "sent": "For example, the set of all dogs is like a coherent category, right?",
                    "label": 0
                },
                {
                    "sent": "It's so coherent that we have a name for it, but the set of all things that are blue is just intuitively not a coherent category, right?",
                    "label": 0
                },
                {
                    "sent": "And we don't ever learn a word for that, and so there's a notion of of coherent versus incoherent categories, and we'd like a mathematical understanding of category coherence as well, and how it relates to learning speed.",
                    "label": 0
                },
                {
                    "sent": "And also how?",
                    "label": 0
                },
                {
                    "sent": "Why are some properties learn quicker than others and how can we explain changing patterns of inductive generalization for this talk?",
                    "label": 1
                },
                {
                    "sent": "I'm just going to focus on this in this category.",
                    "label": 0
                },
                {
                    "sent": "Currents and learning dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you look at these train networks, they actually don't explore the nonlinear regime of the transfer function that much, so we hypothesize that maybe even a linear network could exhibit this kind of dynamics.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, a linear deep network is still a linear network because the composition of linear functions is linear, so linear deep networks of course don't gain any expressive capacity with depth.",
                    "label": 0
                },
                {
                    "sent": "However, their learning dynamics changes dramatically with depth.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To see that, imagine what you would what would happen if you trained a linear deep network on a certain input output training set.",
                    "label": 0
                },
                {
                    "sent": "Right, so So what should we do?",
                    "label": 0
                },
                {
                    "sent": "Oh, I don't have the error function here, So what should be doing is you'd be.",
                    "label": 0
                },
                {
                    "sent": "You'd be minimizing an error function that roughly looked like.",
                    "label": 0
                },
                {
                    "sent": "The error is the output minus one layer of weights times one layer of weights times the input squared.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So this error function is actually quartic in the weights, which means the gradient is cubic in the weights, and because there's products of weights, this is actually a nonconvex learning dynamics.",
                    "label": 0
                },
                {
                    "sent": "If you of course had only one layer of weights, then the error function be quartic and quadratic in the weights would be a convex optimization problem, and the learning dynamics would be linear, but everything changes when you add a second layer of weights.",
                    "label": 0
                },
                {
                    "sent": "Exactly, yeah, this is W one and this is W2 layer one layer 2.",
                    "label": 0
                },
                {
                    "sent": "So if you write down the learning dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you work in the limit of batch gradient descent with slow learning rates, small learning rates.",
                    "label": 0
                },
                {
                    "sent": "You can actually write down a continuous time evolution.",
                    "label": 0
                },
                {
                    "sent": "Of the learning dynamics of the network and you can understand exactly how the input statistics drives the learning because the network input output response is linear, the learning dynamic is only sensitive to 2nd order statistics in the input output data.",
                    "label": 0
                },
                {
                    "sent": "In particular, the input covariance matrix and the input output covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "That's what drives the learning dynamics, and we'd like to understand just have a general analytical solution to the learning dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so it turns out you can organize the learning dynamics through the singular if we work.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Situation where the input is white and right, which we often do in practice, then all that drives the learning dynamics is the input output covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "And it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The singular value decomposition of the input output covariance matrix drives the learning OK, so you all know singular value decomposition.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once you have the singular value decomposition of the input output covariance matrix, you can write down an analytical formula for the learning dynamics.",
                    "label": 1
                },
                {
                    "sent": "In particular, the product of the weights from layer one to two and layer two to three as a function of time.",
                    "label": 1
                },
                {
                    "sent": "For certain initial conditions, behaves like.",
                    "label": 1
                },
                {
                    "sent": "The time dependent SVD.",
                    "label": 1
                },
                {
                    "sent": "Of the input output covariance matrix, where the time dependent coefficients start from small random initial conditions.",
                    "label": 1
                },
                {
                    "sent": "Because we started the weights from small, random or any random initial conditions.",
                    "label": 0
                },
                {
                    "sent": "And then the the coefficients or the time dependent single values.",
                    "label": 1
                },
                {
                    "sent": "Traverse a sigmoidal type learning curve where it stays flat for some period of time and then it suddenly makes a transition to the correct singular value.",
                    "label": 0
                },
                {
                    "sent": "OK, and the time of this transition is occurs at one over the singular value, so just at a very, very high level.",
                    "label": 0
                },
                {
                    "sent": "What's happening is stronger statistical structure in the data is learned earlier.",
                    "label": 0
                },
                {
                    "sent": "OK, that makes intuitive sense for this particular problem.",
                    "label": 0
                },
                {
                    "sent": "It turns out the strength of statistical structure is determined by the singular value of an input output covariance matrix, and the time is just one over the singular value.",
                    "label": 1
                },
                {
                    "sent": "It's as simple as it can possibly be.",
                    "label": 0
                },
                {
                    "sent": "Of the input output covariance matrix.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this matrix right here.",
                    "label": 0
                },
                {
                    "sent": "So I take the training data and I correlate each neuron in the training data with each output neuron.",
                    "label": 0
                },
                {
                    "sent": "Each input neuron in the training data with each output neuron in the training data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's a matrix.",
                    "label": 0
                },
                {
                    "sent": "I am not something that matrix.",
                    "label": 0
                },
                {
                    "sent": "Yeah, exactly, it's it's it's.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One by three by one matrix, and I'm writing down a theory.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the product of the weights W2, one times W 3, one which is also N3 by N1.",
                    "label": 0
                },
                {
                    "sent": "Which singular value do you mean?",
                    "label": 0
                },
                {
                    "sent": "All of them all of them.",
                    "label": 0
                },
                {
                    "sent": "So every single mode of this connectivity?",
                    "label": 0
                },
                {
                    "sent": "Undergoes its own independent dynamics, an each of them transitions at a certain time, right?",
                    "label": 0
                },
                {
                    "sent": "So this explains the existence of plateaus.",
                    "label": 0
                },
                {
                    "sent": "In the in the error function right because whenever a singular value is wrong, there's an error and whether a single value transitions to a correct answer.",
                    "label": 0
                },
                {
                    "sent": "There's a drop in the error.",
                    "label": 0
                },
                {
                    "sent": "Right so intuitively, what's the OR?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Version of these plateaus.",
                    "label": 0
                },
                {
                    "sent": "It turns out, if you look at the dynamics of learning in the network, the vector field and weight space actually has these saddle points in them.",
                    "label": 0
                },
                {
                    "sent": "Where this might be the manifold of correct weights, OK?",
                    "label": 0
                },
                {
                    "sent": "And there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a saddle point here where the dynamics and weight space gets attracted to the saddle point along the stable manifold, but then gets repulsed along the unstable manifold.",
                    "label": 1
                },
                {
                    "sent": "The time it takes to get attracted to the stable manifold is what determines the time you're stuck in the plateau, and then the repulsion is fairly rapid.",
                    "label": 0
                },
                {
                    "sent": "So actually it's actually not just it's this hyperbolic part that's slow, and then once you once you escape the vicinity of the saddle point, the learning is very rapid, so saddle points will become important later.",
                    "label": 0
                },
                {
                    "sent": "OK, so just.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To summarize this theory again, stronger statistical structure is learn faster, where again this fiscal structure, singular value, and the.",
                    "label": 0
                },
                {
                    "sent": "This is the learning time is one over singular vector, and what's the pattern?",
                    "label": 0
                },
                {
                    "sent": "What's the knowledge about the external world that gets learned?",
                    "label": 0
                },
                {
                    "sent": "Well, the singular vectors get are what gets learned.",
                    "label": 0
                },
                {
                    "sent": "OK, so now the next question is what does all this have to do with the hierarchical differentiation of concepts?",
                    "label": 1
                },
                {
                    "sent": "That's what we started off with.",
                    "label": 0
                },
                {
                    "sent": "OK, so now.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So the interesting thing about JS work, he didn't analyze a specific data set but but but what we'd like is a general theory for arbitrary datasets.",
                    "label": 0
                },
                {
                    "sent": "So can we, can we move beyond specific datasets to get general principles of what happens when a neural network is exposed to hierarchical structure?",
                    "label": 1
                },
                {
                    "sent": "And I think this will be So what we look at is we consider it a neural network trained with data generated by the hierarchical generative model, and this is.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think part of a more general principle that I think will be required to push theory forward in deep learning and also in neuroscience is that we have these two very different methods for modeling, right?",
                    "label": 0
                },
                {
                    "sent": "Both data and brains, right?",
                    "label": 0
                },
                {
                    "sent": "We have hierarchical generative models that are statistical models for generating data there really beautiful because we understand exactly the assumptions that go in into the generation of data and then we have neural networks that we train.",
                    "label": 0
                },
                {
                    "sent": "And what we'd like is, we'd like to come up with a bridge between these two worlds where we can understand how the structure of a hierarchical generative model is embedded overtime into the weights of a neural network.",
                    "label": 0
                },
                {
                    "sent": "And we, if we have a deeper understanding of that, then will of course have a much deeper understanding of both learning dynamics and expressivity of neural networks.",
                    "label": 0
                },
                {
                    "sent": "So this is probably the simplest situation where we can get that kind of understanding.",
                    "label": 0
                },
                {
                    "sent": "So what kind of hierarchical Gen?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model are we going to consider we're going to consider a hierarchical generative model that looks that mimics the process of evolution that generated the toy data set that Jay was working with?",
                    "label": 0
                },
                {
                    "sent": "So consider just a bunch of.",
                    "label": 0
                },
                {
                    "sent": "So imagine that the different items or in your training data, say the different animals and plants are sitting at the leaves of a tree, and you have different properties like has wings or doesn't have wings that diffuses down the tree, and these are like speciation events where on one branch it might flip another branch it doesn't.",
                    "label": 0
                },
                {
                    "sent": "OK, so you generate features through this branching diffusion process down a tree.",
                    "label": 1
                },
                {
                    "sent": "And you get feature vectors for each each object.",
                    "label": 0
                },
                {
                    "sent": "So clearly what will happen is the similarity structure of items that are close together on the tree will be higher than items that are further apart on the tree.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "All we need to understand in order to understand learning dynamics in these networks is understand the singular value decomposition of hierarchically structured data.",
                    "label": 0
                },
                {
                    "sent": "That's all we need.",
                    "label": 0
                },
                {
                    "sent": "OK, it turns out we can compute all of that analytically, and it sort of makes intuitive sense at the end of the day.",
                    "label": 0
                },
                {
                    "sent": "So assume that we have many, many features that are generated, right?",
                    "label": 0
                },
                {
                    "sent": "So we don't have to worry about Stochastic City with respect to finite number of features that stochastic is weak as soon as the number of features becomes order 100.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we look at the single if we look at the singular vectors of the input output covariance matrix, you have two types of singular vectors, the right or input singular vectors on the left or output singular vectors.",
                    "label": 0
                },
                {
                    "sent": "The input singular vectors are functions on the input space, which are just the the animals.",
                    "label": 0
                },
                {
                    "sent": "So their functions on the leaves of the tree.",
                    "label": 0
                },
                {
                    "sent": "OK, the singular vector with the largest singular value is just a DC mode that doesn't make any distinctions along the tree.",
                    "label": 0
                },
                {
                    "sent": "The next singular vector with the next largest singular value is a singular vector that is positive on all of these nodes and negative on all of these nodes.",
                    "label": 0
                },
                {
                    "sent": "So this singular vector can make categorical distinctions at the broadest categorical level.",
                    "label": 0
                },
                {
                    "sent": "The next singular vectors comes in a degenerate pair and they make distinctions finer scale distinctions between, say that despair or despair in despair, and then you have the singular vectors.",
                    "label": 0
                },
                {
                    "sent": "The smallest singular values that make the finer scale distinctions.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the similarity structure of data generated from this model, it has this blocks within blocks, hierarchical structure, and these are actually the eigenvectors of this hierarchical matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so now and then, if you look at.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually the eigen values we have a theory for the OR the singular values.",
                    "label": 0
                },
                {
                    "sent": "We have a theory for the singular values and it matches simulations and so on.",
                    "label": 0
                },
                {
                    "sent": "But but basically what happens is the singular values are decreasing function of the hierarchy level.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now when you put the two results together you can immediately see.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What happens?",
                    "label": 0
                },
                {
                    "sent": "Any network must exhibit progressive differentiation of concepts on any data set generated by this class of hierarchical diffusion processes.",
                    "label": 1
                },
                {
                    "sent": "Basically the network learns input output modes in a time that's one over the singular value, and the singular values of broader hierarchical distinctions are larger than those of finer hierarchical distinctions, and the input output modes are singular.",
                    "label": 1
                },
                {
                    "sent": "Vectors correspond exactly to hierarchical distinctions in the underlying tree, so at the end of the day.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey, we can come up with an analytic formula that we can plot for the learning dynamics of this network.",
                    "label": 0
                },
                {
                    "sent": "So this is multi dimensional scaling of the learning dynamics in the linear network and as you can.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See it recapitulates in qualitative structure the empirically observed learning dynamics and the nonlinear network, right?",
                    "label": 0
                },
                {
                    "sent": "So I would say that this is sort of the difference between simulation and theory, where here we kind of understand a lot better the principles of this striking phenomenon that was going on here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so you need actually even deep linear networks show this, but shallow networks with no hidden layers do not show this actually.",
                    "label": 0
                },
                {
                    "sent": "And a surprise was actually that only the 2nd order statistics of this hierarchical structure data are sufficient to drive this nonlinear hierarchical differentiation process on weight space.",
                    "label": 1
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Deep linear networks.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "What happens if your data was not balanced like you have way more say fish?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, yeah that's a very interesting.",
                    "label": 0
                },
                {
                    "sent": "So then what happens is we?",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looked at that too that distorts the singular vectors and places more concentration on the objects that have more frequency.",
                    "label": 0
                },
                {
                    "sent": "Well, actually showing example of that in a different concept where we get rid of hierarchy, but we put in different frequencies.",
                    "label": 0
                },
                {
                    "sent": "That's coming next.",
                    "label": 0
                },
                {
                    "sent": "So actually.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can we can look at a lot of phenomena in psychology now, like illusory correlations and learning.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "You could ask a child does a worm have bones right?",
                    "label": 0
                },
                {
                    "sent": "And every single child will say yes or warm has bones if they're young enough and if they're old enough, they'll say no.",
                    "label": 0
                },
                {
                    "sent": "So they make these illusory correlations and they overgeneralized you know.",
                    "label": 1
                },
                {
                    "sent": "But we can come up with analytical explanations for why that happens in these networks, and a whole bunch of stuff I just wanted to focus on category coherence which relates to Erin's Question.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so yeah, so we can answer questions like why are some properties easier to learn?",
                    "label": 0
                },
                {
                    "sent": "Why are some?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Items more typical.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Members of a category.",
                    "label": 0
                },
                {
                    "sent": "How does inductive.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Analyzation work going to skip all of that, but I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Category coherence, because this is something that was kind of bedeviling psychology to it to some extent.",
                    "label": 0
                },
                {
                    "sent": "So what is a category and what makes it coherent?",
                    "label": 1
                },
                {
                    "sent": "So simple proposal is a category is a subset of objects sharing a subset of features, right?",
                    "label": 1
                },
                {
                    "sent": "This is like a very simple barebone definition of a category, right?",
                    "label": 1
                },
                {
                    "sent": "So kind of a Gordian knot then, is how do you learn a category?",
                    "label": 1
                },
                {
                    "sent": "Well, in order to learn a category you need to identify the objects that belong to the category.",
                    "label": 0
                },
                {
                    "sent": "But in order to do that you need to know which features are important for the category.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, if you could identify the features that are important for the category, well, in order to do that, you must know which objects belong to the category, right?",
                    "label": 0
                },
                {
                    "sent": "And we've already talked about the notion of coherent categories like the set of all things that are dogs and incoherent categories, a set of all things that are blue.",
                    "label": 1
                },
                {
                    "sent": "So the question is, how do you solve this problem?",
                    "label": 0
                },
                {
                    "sent": "And in this crowd it's not going to be surprising that neural networks can kind of bootstrap and simultaneously solve both problems at once, but how does it do that?",
                    "label": 0
                },
                {
                    "sent": "What's a theory for how it does that?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is again my son and he's getting lots of experiences throughout his life.",
                    "label": 0
                },
                {
                    "sent": "My lab decided to give him a pink Unicorn as a gift.",
                    "label": 0
                },
                {
                    "sent": "My lab is also trying to make pink unicorns, my lab mascot.",
                    "label": 0
                },
                {
                    "sent": "Against my wishes, but I don't know if I have any leverage, I think anyways, it's not.",
                    "label": 0
                },
                {
                    "sent": "You gotta pick your battles.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to battle this one.",
                    "label": 0
                },
                {
                    "sent": "Yosho knows where you are and knows what I'm talking about, so.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so you see a sequence of items overtime, so you see a stream of experience where you see a subset of objects with a subset of features and you have to construct a current representation over it over that stream of experience.",
                    "label": 1
                },
                {
                    "sent": "So here's for example a data matrix where you have a bunch of features and a bunch of objects and some features have the object, in which case you see a yellow dot and some they don't, in which case you see a blue dot, so I don't understand how babies learn, but we can under.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how these neural networks learn?",
                    "label": 0
                },
                {
                    "sent": "And so when this neural network was exposed to this data?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see, will this work?",
                    "label": 0
                },
                {
                    "sent": "OK, the movie did not work, but I'm prepared for.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As it turned out that this is a, this is a snapshot of how the internal representation Scott learned from this data set.",
                    "label": 1
                },
                {
                    "sent": "So blue is early in time and yellow is later in time.",
                    "label": 0
                },
                {
                    "sent": "So basically one group of objects shot out, right?",
                    "label": 0
                },
                {
                    "sent": "So these each point is an object, so there's 1000 objects.",
                    "label": 1
                },
                {
                    "sent": "One group of objects shot out very quickly.",
                    "label": 0
                },
                {
                    "sent": "One group of objects shot outs more slowly.",
                    "label": 0
                },
                {
                    "sent": "And because of this yellow, this is the last set of objects to shoot out, and a whole bunch of objects were discarded.",
                    "label": 0
                },
                {
                    "sent": "They didn't get learned.",
                    "label": 0
                },
                {
                    "sent": "OK, so why did this happen?",
                    "label": 0
                },
                {
                    "sent": "You can now look at the weight matrix of this network and re permute the objects intelligently based on the weight.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Matrix and you show that once you re permute the features and objects you find out that there were actually a preponderance of of objects with a subset of features, so there was a big category of small category in a smaller category, right?",
                    "label": 1
                },
                {
                    "sent": "And it turns out that these the largest category was the one learned first.",
                    "label": 0
                },
                {
                    "sent": "The second largest was learned 2nd and the smallest was learned last.",
                    "label": 0
                },
                {
                    "sent": "So now, but we'd like to make this much more quantitative.",
                    "label": 0
                },
                {
                    "sent": "We'd like to have a theory for how.",
                    "label": 1
                },
                {
                    "sent": "The size of a category determines how quickly it's learns.",
                    "label": 0
                },
                {
                    "sent": "And Moreover, what's the smallest size detectable category yet?",
                    "label": 0
                },
                {
                    "sent": "This is this is associative learning where.",
                    "label": 0
                },
                {
                    "sent": "Where the?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well yeah, so so basically.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's the same scenario that Jay was looking at where you get objects and properties right?",
                    "label": 0
                },
                {
                    "sent": "So whether or not you want to call that supervisor, you don't get category labels right?",
                    "label": 0
                },
                {
                    "sent": "So basically what you do is you're seeing this matrix, huh?",
                    "label": 0
                },
                {
                    "sent": "No, no, you get object identity in the input.",
                    "label": 0
                },
                {
                    "sent": "It's like.",
                    "label": 0
                },
                {
                    "sent": "You have a different species of dogs.",
                    "label": 0
                },
                {
                    "sent": "Yeah, features are like.",
                    "label": 0
                },
                {
                    "sent": "The features you get the features.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so literally.",
                    "label": 0
                },
                {
                    "sent": "I have a network with 1000 inputs which is A1 hot encoding of object identity.",
                    "label": 0
                },
                {
                    "sent": "No, that's object identity.",
                    "label": 0
                },
                {
                    "sent": "No, no, the label.",
                    "label": 0
                },
                {
                    "sent": "There's only three labels in this data set.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Whether you're in this category, this category of this category.",
                    "label": 0
                },
                {
                    "sent": "Baby cluster categories, but it gives her label category.",
                    "label": 0
                },
                {
                    "sent": "It never gets access to a number 1, two, or three that says which category, man, yeah?",
                    "label": 0
                },
                {
                    "sent": "There's one 2000.",
                    "label": 0
                },
                {
                    "sent": "It gets access to 1000, yeah, but that's the sensory input.",
                    "label": 0
                },
                {
                    "sent": "And it gets access for each of those.",
                    "label": 0
                },
                {
                    "sent": "What is the feature vector for that thing?",
                    "label": 1
                },
                {
                    "sent": "So then it discovers in.",
                    "label": 1
                },
                {
                    "sent": "I don't know what you want to call it, but it discovers the statistical structure of the input in the sense that there are special subsets of objects and special subsets of category of features that Co occur together, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so we have an analytic theory.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this learning dynamics that depends on random matrix theory, and I won't go into the details of that.",
                    "label": 0
                },
                {
                    "sent": "But actually here's a.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's a question.",
                    "label": 0
                },
                {
                    "sent": "OK, it stands to reason that if I make this block smaller, maybe the network will never learn it right?",
                    "label": 0
                },
                {
                    "sent": "There might be a minimum size that I need this block to be.",
                    "label": 0
                },
                {
                    "sent": "How big do you think this needs to be?",
                    "label": 0
                },
                {
                    "sent": "So here's 1000 objects.",
                    "label": 0
                },
                {
                    "sent": "And 1600 features.",
                    "label": 0
                },
                {
                    "sent": "How big do you think this block or how small do you think this block can get before you can't see it anymore?",
                    "label": 0
                },
                {
                    "sent": "Before this neural network cannot learn it anymore?",
                    "label": 0
                },
                {
                    "sent": "What do you think?",
                    "label": 0
                },
                {
                    "sent": "Depends how long you train.",
                    "label": 0
                },
                {
                    "sent": "So we're learning a linear network, so I could train it forever and it would get to the same answer.",
                    "label": 0
                },
                {
                    "sent": "Or by the way, this is a non convex optimization problem that baldeon brunette showed along time ago.",
                    "label": 0
                },
                {
                    "sent": "Like you know, in the last Millennium that.",
                    "label": 0
                },
                {
                    "sent": "It literally was the last Millennium.",
                    "label": 0
                },
                {
                    "sent": "It's OK, it's not more than 16 years ago.",
                    "label": 0
                },
                {
                    "sent": "That even though this is a non convex optimization problem.",
                    "label": 1
                },
                {
                    "sent": "It has no local minima, it just has saddle points, which is why I could answer Yoshi's question the way I did, because it's a linear network, you train it forever, you'll always get to the same answer.",
                    "label": 0
                },
                {
                    "sent": "So it's not an issue of of training time, so it's an issue of statistical detectability.",
                    "label": 0
                },
                {
                    "sent": "So do you think let's say you had 30 objects and 20 features, could you detect it out of 1000 and 1600?",
                    "label": 0
                },
                {
                    "sent": "This is a stupid linear network, right?",
                    "label": 1
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Not for this one because it's linear, but what happens is for this network then.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Number of neurons in the hidden layer will give you an upper bound of the number of categories you can learn.",
                    "label": 0
                },
                {
                    "sent": "It turns out for this kind of a data set, so it's all about the number of neurons in the hidden layer that matters.",
                    "label": 0
                },
                {
                    "sent": "Alright, let me just tell you that.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Theory it's actually a little bit surprising.",
                    "label": 0
                },
                {
                    "sent": "I wouldn't have guessed it immediately, but we worked out.",
                    "label": 0
                },
                {
                    "sent": "You can view this matrix as a low rank matrix plus annoys matrix, and there's well established statistical theorems about how the eigenvectors and eigenvalues of low rank matrices get perturbed when you add noise to them.",
                    "label": 0
                },
                {
                    "sent": "And when you work through all those theories and translated into this framework, you get a very simple result, OK?",
                    "label": 0
                },
                {
                    "sent": "So P is the probability that if you're within this cluster, features present and if you're outside this cluster, the probability of features present is Q, so there's a signal to noise ratio that governs this problem, which is the P -- Q divided by the standard deviation of the of the noise and the outside.",
                    "label": 1
                },
                {
                    "sent": "OK, then there's the size of the category.",
                    "label": 0
                },
                {
                    "sent": "It turns out it only depends on the shape of the category through its area, so it's the number of objects that belong in the category times the number of features that belong in the category.",
                    "label": 1
                },
                {
                    "sent": "OK, and the threshold for detectability is just that the signal to noise ratio times this category side size is only bigger than the square root of the size of the universe.",
                    "label": 0
                },
                {
                    "sent": "Essentially, where the universe is the product of the number of objects and number of features.",
                    "label": 1
                },
                {
                    "sent": "So the way you I guess set up the data set and run these yellow boxes.",
                    "label": 0
                },
                {
                    "sent": "It seems like each category has like strictly non overlapping features.",
                    "label": 0
                },
                {
                    "sent": "Is that yeah yeah, so actually.",
                    "label": 0
                },
                {
                    "sent": "So that's what I'm saying is trying to dissociate frequency affects from hierarchy effects.",
                    "label": 0
                },
                {
                    "sent": "So here we worked out exactly what happens when you sorry.",
                    "label": 0
                },
                {
                    "sent": "So you have to go back further.",
                    "label": 0
                },
                {
                    "sent": "Here's where we.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Worked out exactly when you have equal frequencies, but hierarchy and you get this hierarchical structure in the singular vectors.",
                    "label": 0
                },
                {
                    "sent": "Here we worked out what happens if you have no hierarchy but different frequencies and.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then there's a more complicated scenario.",
                    "label": 0
                },
                {
                    "sent": "When you mix the two, but you can work it out.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, the end of the day frequency affects and hockey affects conspire to determine what gets learned and how fast.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one thing I would love.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the deep learning community is toy models for the tasks that you guys are solving right?",
                    "label": 0
                },
                {
                    "sent": "Because we have no mathematical control over what's in the image.",
                    "label": 0
                },
                {
                    "sent": "Net database, right?",
                    "label": 0
                },
                {
                    "sent": "I don't know how to describe it mathematically, but I would love a mathematical model of what you think is in that day that captures the essence of what you think is in that database.",
                    "label": 0
                },
                {
                    "sent": "And then we can start to reason about how a neural network will respond to that mathematical model of data.",
                    "label": 0
                },
                {
                    "sent": "I think that's the route for progress forward in understanding train networks in deep learning.",
                    "label": 0
                },
                {
                    "sent": "Now, because of the culture of the field is so focused on winning competitions, it's hard to get stuff like that published.",
                    "label": 0
                },
                {
                    "sent": "But in the history of science, a deeper understanding of science is always lead to better engineering in the long term.",
                    "label": 0
                },
                {
                    "sent": "So I think it's shortsighted to focus on winning competitions all the time and not try to get understanding.",
                    "label": 0
                },
                {
                    "sent": "Anyway, I wasn't I didn't mean to say that, but I just want to throw that out there as a debate point for this field, right?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Joshua must have picked students were of his mind like mine anyway, but it's it's.",
                    "label": 0
                },
                {
                    "sent": "I could go on and on about my opinions on various things, but I'll try to.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, it it takes all.",
                    "label": 0
                },
                {
                    "sent": "It takes different kinds of people to do different kinds of things, so alright, so OK, Now we've been.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Analyzing these deep networks, but the question is, can we learn anything about about practically training non linear networks better?",
                    "label": 0
                },
                {
                    "sent": "And I'll give this short shrift because it's published, but basically we'd like to answer for even deeper networks, right?",
                    "label": 0
                },
                {
                    "sent": "The dynamics of learning right?",
                    "label": 1
                },
                {
                    "sent": "It's very nontrivial.",
                    "label": 0
                },
                {
                    "sent": "You have these plateaus and sudden transitions.",
                    "label": 1
                },
                {
                    "sent": "How does training time scale with depth?",
                    "label": 1
                },
                {
                    "sent": "How should the learning rate scale with depth?",
                    "label": 1
                },
                {
                    "sent": "How do different weight initializations impact loading speed?",
                    "label": 0
                },
                {
                    "sent": "These are very practical questions, right?",
                    "label": 0
                },
                {
                    "sent": "And we'd like to have a theory for that.",
                    "label": 0
                },
                {
                    "sent": "And so when we analyze the learning dynamics of these deep linear networks, we found remarkably a class of random initial conditions that would allow training time to be independent of depth.",
                    "label": 0
                },
                {
                    "sent": "OK, now what do I mean by training time?",
                    "label": 0
                },
                {
                    "sent": "If I make the network infinitely deep, of course that the real Clock time.",
                    "label": 0
                },
                {
                    "sent": "To train, the network will grow with depth because the computational time to compute one gradient grows with depth.",
                    "label": 0
                },
                {
                    "sent": "But you might think that there's a more adverse scaling with the number of gradient evaluations also grows as you train the network, and it turns out the latter is doesn't have to be true for a particular class of initializations.",
                    "label": 0
                },
                {
                    "sent": "You can make the learning time independent of depth where time is measured in number of gradient evaluations.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's still a linear network, but then we show it for the nonlinear network and we have intuition showing empirically for the nonlinear network and we have intuition Y. Alright, so that we never would have discovered this had we not had a deeper understanding of linear networks, so I'll skip the details of that, but I'll just show.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You the so basically the magic recipes to choose random orthogonal weights OK, and so if you have random orthogonal weights, the training time is independent of depth.",
                    "label": 0
                },
                {
                    "sent": "The optimal learning rate.",
                    "label": 0
                },
                {
                    "sent": "So let me not talk about that.",
                    "label": 0
                },
                {
                    "sent": "OK, but you know another idea that actually Joshua sort of involved in was a nice idea was scaled random Gaussian initializations to combat the vanishing exploding gradient problem.",
                    "label": 1
                },
                {
                    "sent": "But remarkably, if both networks have the same scaling but you choose random Gaussian weights instead of random orthogonal weights.",
                    "label": 0
                },
                {
                    "sent": "There's a very, very different scaling with depth.",
                    "label": 0
                },
                {
                    "sent": "The number of gradient evaluations grows linearly with depth around depth 510.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really make much of a difference, but at much deeper networks there's of course a huge difference.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the intuition?",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "There's so much more I want to get to, but the intuition is.",
                    "label": 0
                },
                {
                    "sent": "The idea behind using a scaled random Gaussian matrix is that the norm of a random vector is preserved after propagating through a random Gaussian matrix matrix.",
                    "label": 1
                },
                {
                    "sent": "But if you take products of random Gaussian matrices and look at the product, it behaves in a very weird non Tropic way where it preserves norms by projecting error vectors into a low dimensional space and then amplifying them.",
                    "label": 0
                },
                {
                    "sent": "And it's.",
                    "label": 1
                },
                {
                    "sent": "So basically if you look at the singular value distribution of products of large numbers of random matrices.",
                    "label": 0
                },
                {
                    "sent": "You get this very anisotropic singular value distribution.",
                    "label": 0
                },
                {
                    "sent": "That doesn't happen for products of orthogonal matrices.",
                    "label": 0
                },
                {
                    "sent": "Now in a non linear network the same.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing actually empirically happens.",
                    "label": 0
                },
                {
                    "sent": "So in a non linear network.",
                    "label": 0
                },
                {
                    "sent": "What you care about is the end to end Jacobian that Jacobian will receive a contribution from the weights and then a diagonal contribution from the non linearity.",
                    "label": 0
                },
                {
                    "sent": "Then the weights and the non linearity and so on.",
                    "label": 0
                },
                {
                    "sent": "And that's sort of the end to end Jacobian that determines how input perturbations change lead to output perturbations.",
                    "label": 0
                },
                {
                    "sent": "If the weights are orthogonal right, then this this property that the singular value distribution of products of many many large random jacobian's.",
                    "label": 0
                },
                {
                    "sent": "Remains within a range.",
                    "label": 0
                },
                {
                    "sent": "Let's order one.",
                    "label": 0
                },
                {
                    "sent": "It doesn't explode or decay that actually holds true with scaled orthogonal initializations but not scaled Gaussian initializations.",
                    "label": 0
                },
                {
                    "sent": "So the essential idea behind this rapid training result holds true even in nonlinear networks, and we actually see.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of training advantages and nonlinear networks.",
                    "label": 0
                },
                {
                    "sent": "Of course, there's been a lot of work since in terms of trying to impose orthogonality while you're training as well, and you know there's lots of ways to combine that.",
                    "label": 0
                },
                {
                    "sent": "But basically orthogonal is a lot better than Gaussian in general for a variety of tasks.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's sort of something practical that came out of a deeper scientific understanding.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, did you talk about the saddlepoint stuff before you didn't OK?",
                    "label": 0
                },
                {
                    "sent": "Alright, so so.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in a really fun collaboration with me and Yasha, which started when you invited me to come and give a talk here, we talked about the Saddle Point story for the linear networks and other reasons actually coming from physics that we believe that saddle that local minima should not be a problem.",
                    "label": 0
                },
                {
                    "sent": "So basically it's often thought.",
                    "label": 0
                },
                {
                    "sent": "That local minima at high error stand as a major impediment to non convex optimization, right?",
                    "label": 1
                },
                {
                    "sent": "And it's true that if you just draw a generic random lens error landscape over low dimensions, it will be riddled with local minima.",
                    "label": 0
                },
                {
                    "sent": "For example, here's a cartoon description of approaching folding energy landscape, and there's lots of local minima.",
                    "label": 0
                },
                {
                    "sent": "OK, but we know that our geometric intuition derived from living and moving within a low dimensional world doesn't generalize very well to high dimensional situations.",
                    "label": 1
                },
                {
                    "sent": "And it turns out if you just draw generic random landscape over high dimensional spaces, local minimum at high error are exponentially rare in the dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Instead, saddle points proliferate and in collaboration the ushers lab.",
                    "label": 0
                },
                {
                    "sent": "We developed an algorithm that can rapidly escape these saddle points so they were kind of birds on this, where we used kind of different techniques to come to similar conclusions.",
                    "label": 0
                },
                {
                    "sent": "But the basic idea is the fall.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing so, it's motivated by some work by Brian Dean and Physical Review Letters, 2007, where they looked at just a random error landscape.",
                    "label": 1
                },
                {
                    "sent": "OK. Over high dimension, so you just do a single draw of a Gaussian process over N variables and that's your random error landscape OK. Let X be a critical point where the gradient vanish is let Y be its errorlevel.",
                    "label": 1
                },
                {
                    "sent": "Clarified the functions of deterministic functions of deterministic functions from, yeah?",
                    "label": 0
                },
                {
                    "sent": "Exactly so, so the picture would be.",
                    "label": 0
                },
                {
                    "sent": "Here is so the picture would be once and for all.",
                    "label": 0
                },
                {
                    "sent": "I draw a random function, but over N variables not not one variable, and then I fix that function and I look at the the statistics of local local extrema.",
                    "label": 0
                },
                {
                    "sent": "OK, so for a fixed function I look at all the local extrema and that's what I'm looking at here.",
                    "label": 0
                },
                {
                    "sent": "OK, I can take each local extrema more critical point where the gradient vanish is and I can plot it in a 2 dimensional feature space.",
                    "label": 0
                },
                {
                    "sent": "One axis is the error level, right?",
                    "label": 0
                },
                {
                    "sent": "So how high is the critical point on the error landscape and the other axis will be the fraction of negative eigenvalues of the Hessian or the number of negative curvature directions in the vicinity of that critical point.",
                    "label": 0
                },
                {
                    "sent": "Right, and you might think a priority that critical points could appear just anywhere in this 2 dimensional feature space, but Brandy and showed no.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the critical points concentrate on a monotonically increasing curve.",
                    "label": 0
                },
                {
                    "sent": "What are the ramifications of this observation?",
                    "label": 0
                },
                {
                    "sent": "Well, OK, So what does curve mean?",
                    "label": 1
                },
                {
                    "sent": "So here is the global minimum.",
                    "label": 0
                },
                {
                    "sent": "It by definition occurs at the lowest energy and the fraction of negative eigenvalues is zero.",
                    "label": 0
                },
                {
                    "sent": "It's a, it's a local minimum.",
                    "label": 0
                },
                {
                    "sent": "All directions curve up.",
                    "label": 0
                },
                {
                    "sent": "Here is the global maximum.",
                    "label": 0
                },
                {
                    "sent": "It's the highest error or energy and in all directions curve down.",
                    "label": 0
                },
                {
                    "sent": "And then intermediate what's happening is is a critical point gets higher and higher, it develops more and more negative curvature directions.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that there are no local minima at high error, right?",
                    "label": 0
                },
                {
                    "sent": "That means that's this region at high error.",
                    "label": 0
                },
                {
                    "sent": "There are no local minima.",
                    "label": 0
                },
                {
                    "sent": "And if you're a local minimum, your error level is close to that of the global minimum.",
                    "label": 0
                },
                {
                    "sent": "OK. Now physicists are used to this idea.",
                    "label": 0
                },
                {
                    "sent": "That there's this notion of universality.",
                    "label": 0
                },
                {
                    "sent": "There are certain questions whose answers don't depend on the details.",
                    "label": 0
                },
                {
                    "sent": "OK, they oftentimes only depend on the dimensionality and symmetry of the problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so a physicist could just stop there and say this will be true for neural networks, don't you?",
                    "label": 0
                },
                {
                    "sent": "Don't even need to do the simulation, it'll be true because neural networks are also error landscapes over high dimensional spaces and and all that matters is that you're in high dimensions and the essential intuition is if you have a critical point over a million variables, what are the chances that the function curves up in all 1,000,000 dimensions?",
                    "label": 0
                },
                {
                    "sent": "The answer is extremely unlikely unless you're all the way near the bottom.",
                    "label": 0
                },
                {
                    "sent": "In which case there's nowhere to go but up, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so we could stop there and we wouldn't have to write a paper, but of course computer scientists are very sceptical of physicists.",
                    "label": 0
                },
                {
                    "sent": "And it's true you should be, I mean, but of course I mean to make an impact in computer science, we have to travel over to the other side and show that this is true even in the scenarios that you guys care about.",
                    "label": 0
                },
                {
                    "sent": "And so you know, we worked with Yasha and so.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talented students in his lab where they actually tried to plug.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This prediction this physics prediction.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What they found, remarkably is that this is exactly what happens.",
                    "label": 0
                },
                {
                    "sent": "So it turns out Newton's method is attracted to saddle points.",
                    "label": 0
                },
                {
                    "sent": "That's not entirely obvious immediately, but if you think about a little bit, it is true.",
                    "label": 0
                },
                {
                    "sent": "So Newton's method is attracted to critical points of any index, or any F fraction, negative curvature, eigenvalues, and So what happens is the critical points do indeed concentrated, monotonically increasing curve.",
                    "label": 0
                },
                {
                    "sent": "So actually maybe you should trust physicists in any case.",
                    "label": 0
                },
                {
                    "sent": "So natural question is, what can we do about this?",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is Newtons method attracted to saddle point?",
                    "label": 0
                },
                {
                    "sent": "So Newton's method is going downhill but multiplying by the inverse Hessian.",
                    "label": 0
                },
                {
                    "sent": "So if they have seen as a negative eigenvalue, that gives you an extra negative sign which points you back uphill.",
                    "label": 0
                },
                {
                    "sent": "Right, so very simple fix is to just take the absolute value of the Hessian, where we define that to be the Hessian, but with all eigenvalues replaced with their absolute value, the eigenvectors unchanged.",
                    "label": 0
                },
                {
                    "sent": "And so that fixes this problem.",
                    "label": 0
                },
                {
                    "sent": "And there's actually a way you can derive it, used by minimizing a linear approximation to F of X within a trust region in which the linear and quadratic approximations agree.",
                    "label": 1
                },
                {
                    "sent": "This is an approximate derivation, so this is a very different way to use curvature information.",
                    "label": 0
                },
                {
                    "sent": "The curvature is not used to approximate the landscape, the curvature is used to determine the boundary of a trust region.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so this actually works relatively well so.",
                    "label": 0
                },
                {
                    "sent": "So here's the.",
                    "label": 0
                },
                {
                    "sent": "So this is called the saddle Free Newton method, and so it behaves pretty well actually.",
                    "label": 0
                },
                {
                    "sent": "So this is stochastic gradient descent on a deep autoencoder problem and a recurrent neural network problem.",
                    "label": 0
                },
                {
                    "sent": "And the error plateaus after some time.",
                    "label": 0
                },
                {
                    "sent": "So when you see a plateau, you might think OK, I'm stuck at a local minimum, but actually this plateau is an illusion is an illusory local minimum.",
                    "label": 0
                },
                {
                    "sent": "I mean, when you switch to stochastic gradient descent, you rapidly drop again.",
                    "label": 1
                },
                {
                    "sent": "So I saddle free Newton, you rapidly drop again.",
                    "label": 0
                },
                {
                    "sent": "OK, so it turns out that when you look at the landscape when you're rapidly dropping, you do see negative curvature directions and saddle free is actually utilizing the negative curvature directions, and in a plot that I don't have here, this is an algorithm that actually works better in higher dimensions, which is consistent with the idea that saddle points proliferate more in higher dimensions than in lower dimensions.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is kind of a second order method, so more work it remains to be done in combining this with approximations to the Hessian and so on to make it competition tractable and scale up in higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "Thank you also, you might be working on that now or maybe not.",
                    "label": 0
                },
                {
                    "sent": "Not much somebody should work on that.",
                    "label": 0
                },
                {
                    "sent": "I'm too lazy to do that.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just a classic version of this that doesn't require storing, but we but we have stochastic 2nd order method where we yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we use a low dimensional approximate subspace, yeah?",
                    "label": 0
                },
                {
                    "sent": "It was like 40 times.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah, so there's more approximations required to try to make it practical, but at least it overturned.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of, this conventional wisdom that local minima are the issue, right?",
                    "label": 0
                },
                {
                    "sent": "So again, a deeper scientific understanding of the problem, the geometry of error landscapes could potentially lead to better learning algorithms, though though this hasn't been brought to total fruition yet.",
                    "label": 0
                },
                {
                    "sent": "For this for this idea.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so expressivity right.",
                    "label": 0
                },
                {
                    "sent": "So the other thing is the brain can do all sorts of things that simpler systems cannot do.",
                    "label": 0
                },
                {
                    "sent": "We kind of saw this Chomsky hierarchy right where we had regular expressions, context free grammars and computable functions.",
                    "label": 0
                },
                {
                    "sent": "And there was a corresponding finite state machine, pushdown automata and Turing machines, right?",
                    "label": 0
                },
                {
                    "sent": "So the more complex a machine is, the more complicated tasks it can do.",
                    "label": 0
                },
                {
                    "sent": "That's almost tautologically true, right?",
                    "label": 0
                },
                {
                    "sent": "So now we're working not at the level of the Chomsky hierarchy anymore, but we're looking at architectures.",
                    "label": 0
                },
                {
                    "sent": "OK, So what can a deep architecture do that a shallow 1 cannot?",
                    "label": 0
                },
                {
                    "sent": "And so there's been a lot of beautiful work on this.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually so OK.",
                    "label": 0
                },
                {
                    "sent": "So the work I'm I'm going to talk about that we just did recently is work with my grad student Ben Poole Sherman Illyrian.",
                    "label": 0
                },
                {
                    "sent": "It's a collaboration with my postdoc Joshua, who's now at Google and might throw an intern at Google.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "So again, the question is, why do we need depth?",
                    "label": 0
                },
                {
                    "sent": "Well, universal function approximations suggests that we can get any function with a very very wide network, right?",
                    "label": 0
                },
                {
                    "sent": "So, so why do we need depth?",
                    "label": 1
                },
                {
                    "sent": "Well, these universal function approximations are kind of hokey because they provide no guarantees on the size of the hidden layer required to approximate a function.",
                    "label": 1
                },
                {
                    "sent": "Well, that size could potentially be exponentially large in the input dimension.",
                    "label": 0
                },
                {
                    "sent": "So the overall idea is that there might exist certain special functions that can that can be computed efficiently.",
                    "label": 1
                },
                {
                    "sent": "Using a deep network that's polynomial in the number of input dimensions, but not by a shallow network that might require exponential number of neurons, and so this idea goes back to intellectual traditions and Boolean circuit theory where they ask similar questions for finite depth logic gates and so, for example, the parity function.",
                    "label": 0
                },
                {
                    "sent": "The function that asks other number of bits in a binary string order.",
                    "label": 0
                },
                {
                    "sent": "Even that function can be computed in a polynomial number of logic gates in the size of the bit string.",
                    "label": 0
                },
                {
                    "sent": "If you allow multiple layers of logic gates.",
                    "label": 0
                },
                {
                    "sent": "But if you allow only one layer of logic gates, you have to be exponential in the width.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in some very nice work that Joshua did.",
                    "label": 0
                },
                {
                    "sent": "Actually they showed a similar type of result where for Relu networks they showed that the number of linear regions can grow exponentially with depth and the way they did it as they came up with a specific network that recursively chop subspace using opposing reluz and each layer chops up each space.",
                    "label": 1
                },
                {
                    "sent": "Each part of space once, and so the number of linear regions grows exponentially with depth.",
                    "label": 1
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A similar result can be shown for some product networks where basically you can show that in these sum product networks where you take you compute products of monomial's and then sum them.",
                    "label": 0
                },
                {
                    "sent": "Then you'll get a complicated polynomial in the top layer an if you use the distributive property to expand it.",
                    "label": 0
                },
                {
                    "sent": "The number of monomials can grow exponentially with depth, and because it's a sum product network.",
                    "label": 1
                },
                {
                    "sent": "If you want to get us number of monomial's with only one layer, you'll need then exponentially many this for the same number of monomial's in the deep network you will need exponentially many neurons in the in the shallow sum product networks.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so so now.",
                    "label": 0
                },
                {
                    "sent": "This raises very natural open questions, right?",
                    "label": 0
                },
                {
                    "sent": "So first of all, are these sort of natural?",
                    "label": 0
                },
                {
                    "sent": "Are these the kinds of functions we want to compute from the perspective of AI?",
                    "label": 1
                },
                {
                    "sent": "In what sense are they natural?",
                    "label": 0
                },
                {
                    "sent": "And one might argue they're not really natural, but they're very good examples of exponential expressivity.",
                    "label": 0
                },
                {
                    "sent": "Another question is, are these functions in some sense rare?",
                    "label": 0
                },
                {
                    "sent": "Curiosity's, or is this phenomenon much more generic?",
                    "label": 1
                },
                {
                    "sent": "In some sense, can any function computed by a generic deep network not be efficiently computable by a shallow network?",
                    "label": 1
                },
                {
                    "sent": "So we would like a theory of deep neural expressivity that demonstrates this for arbitrary nonlinearities and some natural general measure of functional complexity.",
                    "label": 1
                },
                {
                    "sent": "So in in deep learning and neuroscience in neural network theory in general we often talk about curvature in a colloquial sense, right?",
                    "label": 0
                },
                {
                    "sent": "So we thought why not actually use the natural mathematical language of curvature, which is Romanian geometry to try to attack.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Question so another way to think about it is.",
                    "label": 0
                },
                {
                    "sent": "The theoretical techniques that are available to prior works both dictated the nature of the non linearity that that could be analyzed and the measure of functional complexity that was focused on.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is we're going to combine a different set of tools for money and geometry and dynamical mean field theory that enable us to analyze arbitrary nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "And we focus on the curvature of a deep function as a measure of functional complexity.",
                    "label": 1
                },
                {
                    "sent": "What we can show is that even in generic random deep networks, measures of functional curvature grow exponentially with depth, but not with.",
                    "label": 1
                },
                {
                    "sent": "And Moreover, the origins of this exponential growth can be traced to chaos theory, it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And another way to think about expressivity, kind of a dual approach is this notion of disentangle in which is actually captured.",
                    "label": 0
                },
                {
                    "sent": "The imagination of both neuro scientists and machine learning people alike, and the idea is, well, we have.",
                    "label": 0
                },
                {
                    "sent": "We have multiple stages of visual processing as Bruno very nicely outlined.",
                    "label": 0
                },
                {
                    "sent": "And a question is, well, why do we need these multiple stages?",
                    "label": 0
                },
                {
                    "sent": "In principle all the information about what we want to do is in the retina we have data processing inequality that say any further processing only destroys information.",
                    "label": 0
                },
                {
                    "sent": "So why do you need anything beyond the retina?",
                    "label": 0
                },
                {
                    "sent": "And we all know that the basic idea is that maybe what you want to do is you want to reformat the information to make it simpler so that a simple readout can solve the task later on.",
                    "label": 0
                },
                {
                    "sent": "So basically, if you imagine, for example.",
                    "label": 0
                },
                {
                    "sent": "The manifold of face under different positions, orientations, illumination scales.",
                    "label": 0
                },
                {
                    "sent": "Each of those images will create a neural activity pattern in the retina in V1 and so on, and that neural activity pattern might be a very highly convoluted, say red manifold, and then another face under all sorts of positions, orientation, scalings and so on might be another highly convoluted blue manifold, and the goal of the ventral visual stream and maybe also deep neural network is to take these manifolds and flatten them out right to the point where a simple linear readout could discriminate between faces.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very appealing and intuitive idea.",
                    "label": 0
                },
                {
                    "sent": "But the question is, how can we mathematically mathematically formalize this notion of dissent angling, and how do we use this mathematical formulation to quantitatively assess the distant angling power of deep versus shallow networks, and what we can show is that deep networks can disentangle manifolds whose curvature grows exponentially with depth, so it's actually quite remarkable how depth can lead to disentangle in power.",
                    "label": 1
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "So I have to get very short so I wasn't so all the technical details are on the slides, but I wasn't planning on going through the technical details I wanted to.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about it.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, exactly talk about it.",
                    "label": 0
                },
                {
                    "sent": "So let me just give you a very high level view of so I'm going to skip a lot of slides, which I was planning on doing anyways.",
                    "label": 0
                },
                {
                    "sent": "But let me just give you the high level take home messages and every all the details are in the paper and you will have the slides you know from the website.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is we look at random neural networks and we want to show that a random deep network and do something that no shallow network whatsoever can do.",
                    "label": 0
                },
                {
                    "sent": "Even if you train the shallow network, that's the idea.",
                    "label": 0
                },
                {
                    "sent": "So we're going to look at random neural network, so the where the weights are all ID and the biases are all ID.",
                    "label": 0
                },
                {
                    "sent": "And what's going to happen is if the weights and we're going to have some arbitrary non linearity FI.",
                    "label": 0
                },
                {
                    "sent": "The running example that I'm going to use a sigmoidal non linearity, but like a teenage but everything I say generalizes to other nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "Railways are slightly different, but we can handle those two.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Basically what happens is this.",
                    "label": 0
                },
                {
                    "sent": "In order to chaos phase transition in these networks where if the variance of the weights gets very large then what happens is the neural networks explore the nonlinear regime right?",
                    "label": 0
                },
                {
                    "sent": "And So what happens is you get linear expansion due to due to the large weights.",
                    "label": 0
                },
                {
                    "sent": "And then you get nonlinear suppression due to the curvature in the non linearity.",
                    "label": 0
                },
                {
                    "sent": "So then what happens is you and in different layers you get expansion in different dimensions and then then contraction along the coordinate axes.",
                    "label": 0
                },
                {
                    "sent": "So you get expansion contraction, expansion, contraction and what you do is you get a very highly curved response response.",
                    "label": 0
                },
                {
                    "sent": "OK so here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "OK so basically you have this intuitive notion of chaosan.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can look at it so the basic questions we ask is if you have a pair of points they become more similar or different overtime and how fast we can answer the question, and then if we have a smooth manifold we can answer the question of how does it, how does its curvature in volume change?",
                    "label": 1
                },
                {
                    "sent": "OK, so here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "Let me just give you the numerical result first.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example of.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is we're going to.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A simple manifold in the input of circle.",
                    "label": 0
                },
                {
                    "sent": "We could have chosen other manifolds, but for simplicity we choose a circle and we propagate it through the network and we ask how does it.",
                    "label": 0
                },
                {
                    "sent": "How does this geometry change?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is just a PCA plot and what happens is.",
                    "label": 0
                },
                {
                    "sent": "So if the weights are small, the circle propagates through the layers and it's roughly in a linear regime, so nothing too much happens if the weights if the variance of the weights gets larger, the circle gets more ruffled, and if there is some way that gets even larger, the circle gets even more ruffled.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what seems to be happening here is that the radius of curvature of the circle is getting tighter and tighter, and a natural conjecture might be is that the radius of curvature is getting exponentially smaller with depth.",
                    "label": 0
                },
                {
                    "sent": "OK, at least that's what this visual representation is suggesting.",
                    "label": 0
                },
                {
                    "sent": "It turns out that that's a complete.",
                    "label": 0
                },
                {
                    "sent": "That's the completely wrong picture.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "That's not actually what's happening at this tightening radius of curvature.",
                    "label": 0
                },
                {
                    "sent": "Is an artifact of trying to fit a fundamentally high dimensional object into a low dimensional space.",
                    "label": 0
                },
                {
                    "sent": "OK, and so this should give a cautionary tale about visualization using, say, PCA.",
                    "label": 0
                },
                {
                    "sent": "This is not only a problem of linear dimensionality reduction.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also a problem with nonlinear dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "So TC is very popular and so this is this is a network in the very chaotic regime.",
                    "label": 0
                },
                {
                    "sent": "So a circle in layer.",
                    "label": 0
                },
                {
                    "sent": "So it gets more and more convoluted, and again the radius of curvature is getting tighter OK. Alright, that's not actually what's happening, so we worked out the mathematical theory of what's actually happening without resorting to dimensionality reduction.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we basically did was we came up with nonlinear propagation equations for computing how curvature and length propagate through the network.",
                    "label": 0
                },
                {
                    "sent": "So if you have a manifold right, it has some coordinate and some embedding space and you can.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Find curvature so there's a well known notion of of Gaussian or extrinsic curvature, which is at any point on the manifold.",
                    "label": 1
                },
                {
                    "sent": "The manifold has a tangent vector and acceleration vector.",
                    "label": 0
                },
                {
                    "sent": "That in an N dimensional space, the tangent vector and acceleration vectors span a 2 dimensional subspace, and there's a unique circle called the osculating circle that has the same tangent and acceleration vectors.",
                    "label": 1
                },
                {
                    "sent": "The curve at that point.",
                    "label": 1
                },
                {
                    "sent": "That circle has a radius and the extrinsic Gaussian curvature is one over that radius.",
                    "label": 0
                },
                {
                    "sent": "So intuitively tighter radii of curvature.",
                    "label": 0
                },
                {
                    "sent": "Correspond to higher curvature, right?",
                    "label": 0
                },
                {
                    "sent": "That's very intuitive.",
                    "label": 0
                },
                {
                    "sent": "So this is our geometric measure of curvature.",
                    "label": 0
                },
                {
                    "sent": "It has a particular formula in terms of velocity, acceleration, vector and what we did was we came up with nonlinear.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recursion relations that ask how does curvature Kappa propagate through the network?",
                    "label": 0
                },
                {
                    "sent": "OK, Chi is like the stretching factor of the Jacobian in the chaotic regime, Chi is.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Less than one.",
                    "label": 0
                },
                {
                    "sent": "So it's bigger than one, so it's stretching things.",
                    "label": 0
                },
                {
                    "sent": "Actually, before we do that, let's imagine what happens to us.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Circle as you just linearly expand it.",
                    "label": 0
                },
                {
                    "sent": "OK, that's an important addition you need.",
                    "label": 0
                },
                {
                    "sent": "First, if you linearly expand a circle.",
                    "label": 0
                },
                {
                    "sent": "Its length or circumference of course gets bigger.",
                    "label": 0
                },
                {
                    "sent": "But its radius also gets bigger, which means its curvature gets smaller.",
                    "label": 0
                },
                {
                    "sent": "So under linear expansion you expand length, but you sacrifice curvature.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "It turns out non linear networks.",
                    "label": 0
                },
                {
                    "sent": "What they actually do is they expand length without sacrificing curvature.",
                    "label": 0
                },
                {
                    "sent": "OK, the way you can see that.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By analyzing these nonlinear recursion relations that we derived, and we find that any curvature in the input gets attenuated by an expansion, so Chi is the expansion factor.",
                    "label": 0
                },
                {
                    "sent": "If Kise bigger than one, then the expansion will decrease curvature.",
                    "label": 0
                },
                {
                    "sent": "But Chi two is the average curvature of your non linearity when you average over the distribution of inputs and that gets added in.",
                    "label": 0
                },
                {
                    "sent": "So the non linearity adds in new curvature.",
                    "label": 0
                },
                {
                    "sent": "So what you have is you have a leaky integrator of curvature.",
                    "label": 1
                },
                {
                    "sent": "That's kind of ateco message of what these random deep networks doing.",
                    "label": 0
                },
                {
                    "sent": "They attenuate for any curvature in the input manifold, but added new curvature due to the non linearity.",
                    "label": 1
                },
                {
                    "sent": "So with this leaky integration, you get a stable fixed point.",
                    "label": 0
                },
                {
                    "sent": "But you do expand the length.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's intuitively happening is the input manifold is getting stretched.",
                    "label": 0
                },
                {
                    "sent": "It's getting stretched and curved, stretched and curved, stretched and curved, so it becomes like a tangled spaghetti.",
                    "label": 0
                },
                {
                    "sent": "That's exploring a longer, tangled spaghetti that's exploring all of N dimensional.",
                    "label": 0
                },
                {
                    "sent": "The hidden representation space.",
                    "label": 0
                },
                {
                    "sent": "So you're actually getting a space filling curve.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the kind of geometric picture of what's going on where you don't have to rely on visualization from nonlinear dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "You can just directly confront the complexity of the curve using Romanian geometry in high dimensional spaces.",
                    "label": 0
                },
                {
                    "sent": "And So what happens is so.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just to just to show you this is the match between theory and experiment for curvature for length.",
                    "label": 1
                },
                {
                    "sent": "And this grassmannian length, the solid lines are theory.",
                    "label": 1
                },
                {
                    "sent": "The error bars are numerical simulations from actual nonlinear networks, and you can see the whole point of this slide is just that there's a nice match, which suggests I'm not full of crab and that this picture is really true.",
                    "label": 0
                },
                {
                    "sent": "So what happens is so the.",
                    "label": 0
                },
                {
                    "sent": "So what happens is.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This picture is an artifact of trying to take a very long space filling curve where each wiggle has the same radius of curvature as the depth grows and trying to fit it into a low dimensional space.",
                    "label": 0
                },
                {
                    "sent": "An artifact of that is that the radius of curvature gets smaller in the TSG plot.",
                    "label": 0
                },
                {
                    "sent": "OK, hope that intuitively makes sense, so I think I have about 4 minutes left, so let me know OK?",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just in tangling, right?",
                    "label": 0
                },
                {
                    "sent": "This is subject near and dear to Yoshi's heart, actually.",
                    "label": 0
                },
                {
                    "sent": "So how do we deal with this in tangling?",
                    "label": 0
                },
                {
                    "sent": "How do we quantify curvature?",
                    "label": 0
                },
                {
                    "sent": "So if we have, say, a linear classifier in the top layer, the decision boundary within the top layer is a linear hyperplane.",
                    "label": 1
                },
                {
                    "sent": "We can back propagate it to become and it will become a curved.",
                    "label": 0
                },
                {
                    "sent": "Surface.",
                    "label": 0
                },
                {
                    "sent": "In the input space it will be an N -- 1 dimensional surface, so it's a manifold with codimension one.",
                    "label": 0
                },
                {
                    "sent": "That manifold will have some nonlinear equation defining it.",
                    "label": 0
                },
                {
                    "sent": "Right, and what we can do is we can look at the gradient vector, right?",
                    "label": 0
                },
                {
                    "sent": "That's normal to it and look at any tangent vector, the gradient and the tangents planet span a 2 dimensional surface hyperplane in input space.",
                    "label": 0
                },
                {
                    "sent": "The intersection of the two dimensional hyperplane with the N -- 1 dimensional decision boundary gives you a curve.",
                    "label": 0
                },
                {
                    "sent": "That curve has a Gaussian curvature.",
                    "label": 0
                },
                {
                    "sent": "We can maximize the Gaussian curvature over the choice of the tangent vector and then do successive machinations while remaining.",
                    "label": 0
                },
                {
                    "sent": "Orthogonality, the previous ones.",
                    "label": 0
                },
                {
                    "sent": "And we get a subset of principle curvatures, right?",
                    "label": 1
                },
                {
                    "sent": "So a 1 dimensional curve had one curvature and N -- 1 dimensional manifold has N -- 1 curvatures and they arise as the eigenvalues of a particular normalized Hessian.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we can just show we don't have a theory for this.",
                    "label": 0
                },
                {
                    "sent": "It's much more complicated, but we can show numerically.",
                    "label": 0
                },
                {
                    "sent": "That is, you back propagate the decision boundary into the previous layers.",
                    "label": 0
                },
                {
                    "sent": "Its curvature grows exponentially with depth.",
                    "label": 1
                },
                {
                    "sent": "OK, so basically.",
                    "label": 0
                },
                {
                    "sent": "Yeah, even exponentially curved manifolds can be flattened to hyperplanes even in random deep networks.",
                    "label": 1
                },
                {
                    "sent": "OK, so let me skip this summary so again.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I skipped a lot, but almost everything I've talked about so far is published, so you can find it.",
                    "label": 0
                },
                {
                    "sent": "My website is not up to date, but you can find it somewhere in my website and some on the archive OK Now.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just wanted to connect back to neuroscience.",
                    "label": 0
                },
                {
                    "sent": "There's this famous line in Hamlet.",
                    "label": 0
                },
                {
                    "sent": "There are more things in heaven and Earth, Horatio, than are dreamt of in your philosophy.",
                    "label": 1
                },
                {
                    "sent": "There are more things in the brain that are dreamt of in the techniques that we use right now.",
                    "label": 1
                },
                {
                    "sent": "And I think some of the important ones are that the brain we're asking a lot of our networks in deep learning.",
                    "label": 0
                },
                {
                    "sent": "We are asking them to start from random initial weights.",
                    "label": 0
                },
                {
                    "sent": "And become structured.",
                    "label": 0
                },
                {
                    "sent": "OK, that might be a lot to ask for, because the brain does not do that right.",
                    "label": 0
                },
                {
                    "sent": "The brain has extremely rich structure before learning even occurs, and that structure is encoded by development.",
                    "label": 0
                },
                {
                    "sent": "There's beautiful migration patterns of neurons that set up all sorts of structures in the brain.",
                    "label": 0
                },
                {
                    "sent": "The cortex, which is the most phylogenetically recent part of our brain.",
                    "label": 0
                },
                {
                    "sent": "You know Bruno alluded to this has a plethora of cell types.",
                    "label": 0
                },
                {
                    "sent": "So plethora of cell types.",
                    "label": 0
                },
                {
                    "sent": "It has six layers and it has kind of a Canonical circuit microarchitecture that now is well worked out where inputs come in.",
                    "label": 0
                },
                {
                    "sent": "So this is, say, a lower area and this is a higher area, so Bruno was drawing this van Essen type diagram with the different brain regions each.",
                    "label": 0
                },
                {
                    "sent": "Each diagram was a box but within each box you have this layered structure where you have multiple layers.",
                    "label": 0
                },
                {
                    "sent": "Inputs come into one layer propagate through the system and come out through another layer and go to the higher.",
                    "label": 0
                },
                {
                    "sent": "Layer higher brain area.",
                    "label": 0
                },
                {
                    "sent": "So there's bottom up input from the lower area to the higher area, and there's top down differentiated input.",
                    "label": 0
                },
                {
                    "sent": "It's a different type of input from the higher area to the lower area, and a lot is known about the detailed dynamics of this Circuit of the neurons, about the connectivity and so on.",
                    "label": 0
                },
                {
                    "sent": "Not everything, of course, it's by no means complete, but we're learning a lot, so an interesting challenge I think for every deep learning lab here, every grad student postdoc here should go back to your deep learning lab and maybe do some Journal clubs on these papers on these papers, OK?",
                    "label": 0
                },
                {
                    "sent": "Because we actually in neuroscience, we don't have a good theory for what the structure is good for.",
                    "label": 0
                },
                {
                    "sent": "We have sort of these inchoate theories, but maybe if we have an army of grad students and postdocs trying to.",
                    "label": 1
                },
                {
                    "sent": "Trying to actually build in cortical structure.",
                    "label": 0
                },
                {
                    "sent": "Into the networks that there start training from, they might start getting intuitions about what this kind of structure is good for, right?",
                    "label": 0
                },
                {
                    "sent": "So at the very least, I mean, it might be completely fruitless, because it might be hard to.",
                    "label": 0
                },
                {
                    "sent": "To discover the functional reason for this architecture, simply by instantiating this architecture in Erelu network right may be too much to ask for, but at the very least, I think Journal clubs in all the machine learning labs doing deep learning in the world on these three papers could be useful.",
                    "label": 0
                },
                {
                    "sent": "I don't know, that's a speculation.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the other thing is you know, the other thing is nested loop architectures.",
                    "label": 1
                },
                {
                    "sent": "OK, this is a prominent motif.",
                    "label": 0
                },
                {
                    "sent": "Across all of the brain where you have fast dumb loops and slower smart loops.",
                    "label": 0
                },
                {
                    "sent": "So for example, this shows up a lot of the time in motor control, so in motor control, if you're trying to do some task and I perturb your arm, you will have a stretch reflex that occurs within 25 milliseconds in that stretch.",
                    "label": 0
                },
                {
                    "sent": "Reflex is dumb, all it does is it counteracts the perturbation that I gave you.",
                    "label": 0
                },
                {
                    "sent": "And that start to occur through a muscle to spinal cord loop.",
                    "label": 0
                },
                {
                    "sent": "Then about 50 to 100 milliseconds later, there's a smart or low latency stretch response that shows up, and that's a little bit smarter.",
                    "label": 0
                },
                {
                    "sent": "It not only takes into account the perturbation that I gave you, but it takes into account the task that you're trying to do.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example, if I'm trying to move this way and you perturb me this way, the short latency response will will push back a little bit and the longer supports will push back even more.",
                    "label": 0
                },
                {
                    "sent": "But if I'm perturbing if I perturb you this way, the short length, responsible pushback, and the long runs long latency response will not be there because it didn't need to be there, so it's a smarter response that knows about all your other joint angles it knows about the task, and so on.",
                    "label": 0
                },
                {
                    "sent": "Then after 100 milliseconds, you're kind of screwed, because the entire brain can.",
                    "label": 0
                },
                {
                    "sent": "Your visual feedback can be about 100 to 200 milliseconds, and then cortical loops through the entire brain can feedback to muscle.",
                    "label": 0
                },
                {
                    "sent": "So basically you have a fast dumb loop, a slower, slightly smarter loop, and, uh, even slower, very smart loop.",
                    "label": 0
                },
                {
                    "sent": "And then finally you have visual awareness and consciousness that can then determine your actions.",
                    "label": 1
                },
                {
                    "sent": "So I don't think deep learning has played around with the computational power of nested loop.",
                    "label": 0
                },
                {
                    "sent": "I mean you guys have with, you know, hierarchical are Hmm's and so on.",
                    "label": 0
                },
                {
                    "sent": "But I think there's more to be gained there.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other thing, the other thing where there's more things in heaven and earth is synapsin's.",
                    "label": 1
                },
                {
                    "sent": "OK, this is the final slide.",
                    "label": 0
                },
                {
                    "sent": "So if you ask a theorist or a deep learning specialist, what is a synapse from neuron item, you're on J.",
                    "label": 1
                },
                {
                    "sent": "The answer you'll get it so it's easy.",
                    "label": 0
                },
                {
                    "sent": "It's just WI J if you have continuous analogue variables, it's JJ.",
                    "label": 0
                },
                {
                    "sent": "If you have a Boltzmann machine, but regardless, it's just a number, it's you know and if you map it to biology, neuro scientists in their neural models think of it as the size of a postsynaptic potential induced by presynaptic spike.",
                    "label": 0
                },
                {
                    "sent": "If you ask in your biologist and molecular biologists water synapses, you'll get a completely different answer.",
                    "label": 0
                },
                {
                    "sent": "It's almost unrecognizable to us.",
                    "label": 0
                },
                {
                    "sent": "It turns out within synapses, as a plethora of 2nd Messenger Cascades AMPA, MDA, so on.",
                    "label": 0
                },
                {
                    "sent": "And, for example, here's a network of kinases and phosphatases.",
                    "label": 0
                },
                {
                    "sent": "These are molecules that can attach phosphoryl groups to each other or not, and they essentially form a big computing network and this computing network hides within the postsynaptic density of every single, say hippocampal CA three neuron, and it's a different network in different brain regions and different brain like higher order brain regions have slower synapses, lower brain regions have faster synapses, so there's a lot of diversity in synaptic strength, and this is probably the biggest Gulf.",
                    "label": 0
                },
                {
                    "sent": "Between theory and experiment and the semantic complexity probably plays a role.",
                    "label": 0
                },
                {
                    "sent": "We actually have a theory for the role that the synaptic complexity plays and.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know what we show is that when you have synaptic weights with a finite or distinguishable number of synaptic strengths, then you need to promote your notion of a synapse from a single number to an entire dynamical system in its own right in order to have reasonable memory capacity.",
                    "label": 0
                },
                {
                    "sent": "So we've worked out a theory for the memory capacity of these complex enough.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is where this is sort of memory is a function of time.",
                    "label": 0
                },
                {
                    "sent": "Since you stored the memory and there's a bound.",
                    "label": 0
                },
                {
                    "sent": "And what happens is the memory capacity of the system grows as the square root of the number of synapses, but it grows linearly in the complexity of the internal dynamics of the synapse.",
                    "label": 1
                },
                {
                    "sent": "So it's much better to have a small number of complex synapses in this scenario than a large number of simple synapses.",
                    "label": 1
                },
                {
                    "sent": "You can read all about this in our NIPS 2014 paper.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I think a theory of complex synapses could have dividends in neurobiology, in mathematics and in technology.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've actually applied this to you.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Biology data and this was work done by postdoctoral here.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, just to summarize, right, we've talked about these things.",
                    "label": 0
                },
                {
                    "sent": "Trainability expressively generalizability.",
                    "label": 0
                },
                {
                    "sent": "There are other questions that we're starting to attack and starting to think about really interpret ability, right.",
                    "label": 0
                },
                {
                    "sent": "Once we have a trade network, how do we understand what it does?",
                    "label": 0
                },
                {
                    "sent": "How is the training data embedded in the weights and biological plausibility is very important, right?",
                    "label": 0
                },
                {
                    "sent": "Nothing.",
                    "label": 0
                },
                {
                    "sent": "How do we do things where we operate within the constraints of neurobiology?",
                    "label": 0
                },
                {
                    "sent": "And again, this is a bunch of references, thanks.",
                    "label": 0
                }
            ]
        }
    }
}